I0420 05:49:54.762182      20 e2e.go:129] Starting e2e run "6979b115-fb28-4782-b91c-53cfcb275f02" on Ginkgo node 1
{"msg":"Test Suite starting","total":346,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1650433794 - Will randomize all specs
Will run 346 of 6432 specs

E0420 05:49:56.317658      20 progress.go:119] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp [::1]:8099: connect: connection refused
Apr 20 05:49:56.318: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 05:49:56.320: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr 20 05:49:56.338: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Apr 20 05:49:56.362: INFO: 9 / 9 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr 20 05:49:56.362: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Apr 20 05:49:56.362: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr 20 05:49:56.369: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
Apr 20 05:49:56.369: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'konnectivity-agent' (0 seconds elapsed)
Apr 20 05:49:56.369: INFO: e2e test version: v1.22.2
Apr 20 05:49:56.379: INFO: kube-apiserver version: v1.22.2
Apr 20 05:49:56.379: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 05:49:56.384: INFO: Cluster IP family: ipv4
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:49:56.385: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename downward-api
W0420 05:49:56.421904      20 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+
Apr 20 05:49:56.422: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr 20 05:49:56.429: INFO: Waiting up to 5m0s for pod "downwardapi-volume-62d975cb-a062-48e1-8b96-290e6c9c4c04" in namespace "downward-api-5734" to be "Succeeded or Failed"
Apr 20 05:49:56.432: INFO: Pod "downwardapi-volume-62d975cb-a062-48e1-8b96-290e6c9c4c04": Phase="Pending", Reason="", readiness=false. Elapsed: 2.383832ms
Apr 20 05:49:58.436: INFO: Pod "downwardapi-volume-62d975cb-a062-48e1-8b96-290e6c9c4c04": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006646626s
Apr 20 05:50:00.443: INFO: Pod "downwardapi-volume-62d975cb-a062-48e1-8b96-290e6c9c4c04": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01337533s
Apr 20 05:50:02.449: INFO: Pod "downwardapi-volume-62d975cb-a062-48e1-8b96-290e6c9c4c04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019896407s
STEP: Saw pod success
Apr 20 05:50:02.449: INFO: Pod "downwardapi-volume-62d975cb-a062-48e1-8b96-290e6c9c4c04" satisfied condition "Succeeded or Failed"
Apr 20 05:50:02.452: INFO: Trying to get logs from node node22-wriki pod downwardapi-volume-62d975cb-a062-48e1-8b96-290e6c9c4c04 container client-container: <nil>
STEP: delete the pod
Apr 20 05:50:02.499: INFO: Waiting for pod downwardapi-volume-62d975cb-a062-48e1-8b96-290e6c9c4c04 to disappear
Apr 20 05:50:02.501: INFO: Pod downwardapi-volume-62d975cb-a062-48e1-8b96-290e6c9c4c04 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:50:02.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5734" for this suite.

• [SLOW TEST:6.125 seconds]
[sig-storage] Downward API volume
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":346,"completed":1,"skipped":5,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:50:02.512: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:142
[It] should run and stop simple daemon [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 20 05:50:02.608: INFO: Number of nodes with available pods: 0
Apr 20 05:50:02.608: INFO: Node node22-07idr is running more than one daemon pod
Apr 20 05:50:03.616: INFO: Number of nodes with available pods: 0
Apr 20 05:50:03.616: INFO: Node node22-07idr is running more than one daemon pod
Apr 20 05:50:04.616: INFO: Number of nodes with available pods: 0
Apr 20 05:50:04.616: INFO: Node node22-07idr is running more than one daemon pod
Apr 20 05:50:05.616: INFO: Number of nodes with available pods: 0
Apr 20 05:50:05.616: INFO: Node node22-07idr is running more than one daemon pod
Apr 20 05:50:06.616: INFO: Number of nodes with available pods: 0
Apr 20 05:50:06.616: INFO: Node node22-07idr is running more than one daemon pod
Apr 20 05:50:07.619: INFO: Number of nodes with available pods: 1
Apr 20 05:50:07.619: INFO: Node node22-07idr is running more than one daemon pod
Apr 20 05:50:08.616: INFO: Number of nodes with available pods: 3
Apr 20 05:50:08.616: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Apr 20 05:50:08.633: INFO: Number of nodes with available pods: 2
Apr 20 05:50:08.633: INFO: Node node22-wriki is running more than one daemon pod
Apr 20 05:50:09.640: INFO: Number of nodes with available pods: 2
Apr 20 05:50:09.640: INFO: Node node22-wriki is running more than one daemon pod
Apr 20 05:50:10.641: INFO: Number of nodes with available pods: 2
Apr 20 05:50:10.642: INFO: Node node22-wriki is running more than one daemon pod
Apr 20 05:50:11.640: INFO: Number of nodes with available pods: 3
Apr 20 05:50:11.640: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:108
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9540, will wait for the garbage collector to delete the pods
Apr 20 05:50:11.706: INFO: Deleting DaemonSet.extensions daemon-set took: 10.678591ms
Apr 20 05:50:11.806: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.46648ms
Apr 20 05:50:14.513: INFO: Number of nodes with available pods: 0
Apr 20 05:50:14.513: INFO: Number of running nodes: 0, number of available pods: 0
Apr 20 05:50:14.516: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"3528"},"items":null}

Apr 20 05:50:14.519: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"3528"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:50:14.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9540" for this suite.

• [SLOW TEST:12.025 seconds]
[sig-apps] Daemon set [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":346,"completed":2,"skipped":21,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:50:14.538: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: validating api versions
Apr 20 05:50:14.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-2775 api-versions'
Apr 20 05:50:14.622: INFO: stderr: ""
Apr 20 05:50:14.622: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\ndiscovery.k8s.io/v1beta1\nevents.k8s.io/v1\nevents.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\nnode.k8s.io/v1beta1\npolicy/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:50:14.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2775" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":346,"completed":3,"skipped":44,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:50:14.631: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating the pod
Apr 20 05:50:14.670: INFO: The status of Pod annotationupdate2807b866-4fd8-4f66-b3d4-e8028ae7c8ca is Pending, waiting for it to be Running (with Ready = true)
Apr 20 05:50:16.675: INFO: The status of Pod annotationupdate2807b866-4fd8-4f66-b3d4-e8028ae7c8ca is Running (Ready = true)
Apr 20 05:50:17.197: INFO: Successfully updated pod "annotationupdate2807b866-4fd8-4f66-b3d4-e8028ae7c8ca"
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:50:21.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-894" for this suite.

• [SLOW TEST:6.596 seconds]
[sig-storage] Downward API volume
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":346,"completed":4,"skipped":97,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:50:21.231: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-449e4bfd-384c-4105-a286-734a9f7659d1
STEP: Creating a pod to test consume secrets
Apr 20 05:50:21.273: INFO: Waiting up to 5m0s for pod "pod-secrets-7ac3280c-b6dc-4b5a-a8ad-264616410f68" in namespace "secrets-5262" to be "Succeeded or Failed"
Apr 20 05:50:21.276: INFO: Pod "pod-secrets-7ac3280c-b6dc-4b5a-a8ad-264616410f68": Phase="Pending", Reason="", readiness=false. Elapsed: 3.12801ms
Apr 20 05:50:23.281: INFO: Pod "pod-secrets-7ac3280c-b6dc-4b5a-a8ad-264616410f68": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008007766s
Apr 20 05:50:25.287: INFO: Pod "pod-secrets-7ac3280c-b6dc-4b5a-a8ad-264616410f68": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013769433s
Apr 20 05:50:27.290: INFO: Pod "pod-secrets-7ac3280c-b6dc-4b5a-a8ad-264616410f68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017459915s
STEP: Saw pod success
Apr 20 05:50:27.290: INFO: Pod "pod-secrets-7ac3280c-b6dc-4b5a-a8ad-264616410f68" satisfied condition "Succeeded or Failed"
Apr 20 05:50:27.292: INFO: Trying to get logs from node node22-hwh1v pod pod-secrets-7ac3280c-b6dc-4b5a-a8ad-264616410f68 container secret-volume-test: <nil>
STEP: delete the pod
Apr 20 05:50:27.320: INFO: Waiting for pod pod-secrets-7ac3280c-b6dc-4b5a-a8ad-264616410f68 to disappear
Apr 20 05:50:27.322: INFO: Pod pod-secrets-7ac3280c-b6dc-4b5a-a8ad-264616410f68 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:50:27.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5262" for this suite.

• [SLOW TEST:6.098 seconds]
[sig-storage] Secrets
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":346,"completed":5,"skipped":180,"failed":0}
S
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:50:27.330: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 05:50:27.359: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr 20 05:50:27.365: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 20 05:50:32.369: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 20 05:50:32.369: INFO: Creating deployment "test-rolling-update-deployment"
Apr 20 05:50:32.374: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr 20 05:50:32.378: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Apr 20 05:50:34.389: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr 20 05:50:34.391: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Apr 20 05:50:34.397: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-9781  28b042ad-5ef4-4389-8319-bf2021cea0ef 3752 1 2022-04-20 05:50:32 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  [{e2e.test Update apps/v1 2022-04-20 05:50:32 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-20 05:50:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.32 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002191688 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-04-20 05:50:32 +0000 UTC,LastTransitionTime:2022-04-20 05:50:32 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-585b757574" has successfully progressed.,LastUpdateTime:2022-04-20 05:50:33 +0000 UTC,LastTransitionTime:2022-04-20 05:50:32 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 20 05:50:34.399: INFO: New ReplicaSet "test-rolling-update-deployment-585b757574" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-585b757574  deployment-9781  2f99d666-4685-4867-93eb-104c7ce3fdbb 3742 1 2022-04-20 05:50:32 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:585b757574] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 28b042ad-5ef4-4389-8319-bf2021cea0ef 0xc002191b57 0xc002191b58}] []  [{kube-controller-manager Update apps/v1 2022-04-20 05:50:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"28b042ad-5ef4-4389-8319-bf2021cea0ef\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-20 05:50:33 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 585b757574,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:585b757574] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.32 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002191c08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 20 05:50:34.399: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr 20 05:50:34.400: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-9781  f3d643fd-664a-4ee2-9f9d-aff968fd05c2 3751 2 2022-04-20 05:50:27 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 28b042ad-5ef4-4389-8319-bf2021cea0ef 0xc002191a37 0xc002191a38}] []  [{e2e.test Update apps/v1 2022-04-20 05:50:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-20 05:50:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"28b042ad-5ef4-4389-8319-bf2021cea0ef\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-04-20 05:50:33 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc002191af8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 20 05:50:34.402: INFO: Pod "test-rolling-update-deployment-585b757574-6sxfq" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-585b757574-6sxfq test-rolling-update-deployment-585b757574- deployment-9781  596bd895-2ba5-4338-8d77-83c7ebdf2076 3741 0 2022-04-20 05:50:32 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:585b757574] map[cni.projectcalico.org/podIP:10.233.2.8/32 cni.projectcalico.org/podIPs:10.233.2.8/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-585b757574 2f99d666-4685-4867-93eb-104c7ce3fdbb 0xc0024d2067 0xc0024d2068}] []  [{calico Update v1 2022-04-20 05:50:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-04-20 05:50:32 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2f99d666-4685-4867-93eb-104c7ce3fdbb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-04-20 05:50:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.2.8\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-slgg5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.32,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-slgg5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-wriki,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 05:50:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 05:50:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 05:50:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 05:50:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.99.219,PodIP:10.233.2.8,StartTime:2022-04-20 05:50:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-20 05:50:33 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.32,ImageID:k8s.gcr.io/e2e-test-images/agnhost@sha256:758db666ac7028534dba72e7e9bb1e57bb81b8196f976f7a5cc351ef8b3529e1,ContainerID:containerd://c605f0ae5ae08abf1aa71c34913dbdcbf6534822127457d4e3a8e4d7804844bf,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.2.8,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:50:34.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9781" for this suite.

• [SLOW TEST:7.080 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":346,"completed":6,"skipped":181,"failed":0}
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should run through the lifecycle of a ServiceAccount [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:50:34.411: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a ServiceAccount
STEP: watching for the ServiceAccount to be added
STEP: patching the ServiceAccount
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector)
STEP: deleting the ServiceAccount
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:50:34.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1526" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","total":346,"completed":7,"skipped":188,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:50:34.492: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:50:36.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-952" for this suite.
•{"msg":"PASSED [sig-node] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":346,"completed":8,"skipped":221,"failed":0}
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:50:36.547: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 05:50:36.580: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Apr 20 05:50:39.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-4225 --namespace=crd-publish-openapi-4225 create -f -'
Apr 20 05:50:39.675: INFO: stderr: ""
Apr 20 05:50:39.675: INFO: stdout: "e2e-test-crd-publish-openapi-4597-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr 20 05:50:39.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-4225 --namespace=crd-publish-openapi-4225 delete e2e-test-crd-publish-openapi-4597-crds test-foo'
Apr 20 05:50:39.758: INFO: stderr: ""
Apr 20 05:50:39.758: INFO: stdout: "e2e-test-crd-publish-openapi-4597-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Apr 20 05:50:39.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-4225 --namespace=crd-publish-openapi-4225 apply -f -'
Apr 20 05:50:39.902: INFO: stderr: ""
Apr 20 05:50:39.902: INFO: stdout: "e2e-test-crd-publish-openapi-4597-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr 20 05:50:39.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-4225 --namespace=crd-publish-openapi-4225 delete e2e-test-crd-publish-openapi-4597-crds test-foo'
Apr 20 05:50:39.956: INFO: stderr: ""
Apr 20 05:50:39.956: INFO: stdout: "e2e-test-crd-publish-openapi-4597-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Apr 20 05:50:39.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-4225 --namespace=crd-publish-openapi-4225 create -f -'
Apr 20 05:50:40.091: INFO: rc: 1
Apr 20 05:50:40.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-4225 --namespace=crd-publish-openapi-4225 apply -f -'
Apr 20 05:50:40.219: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Apr 20 05:50:40.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-4225 --namespace=crd-publish-openapi-4225 create -f -'
Apr 20 05:50:40.343: INFO: rc: 1
Apr 20 05:50:40.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-4225 --namespace=crd-publish-openapi-4225 apply -f -'
Apr 20 05:50:40.460: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Apr 20 05:50:40.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-4225 explain e2e-test-crd-publish-openapi-4597-crds'
Apr 20 05:50:40.591: INFO: stderr: ""
Apr 20 05:50:40.591: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4597-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Apr 20 05:50:40.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-4225 explain e2e-test-crd-publish-openapi-4597-crds.metadata'
Apr 20 05:50:40.720: INFO: stderr: ""
Apr 20 05:50:40.720: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4597-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     NOT return a 409 - instead, it will either return 201 Created or 500 with\n     Reason ServerTimeout indicating a unique name could not be found in the\n     time allotted, and the client should retry (optionally after the time\n     indicated in the Retry-After header).\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only.\n\n     DEPRECATED Kubernetes will stop propagating this field in 1.20 release and\n     the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Apr 20 05:50:40.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-4225 explain e2e-test-crd-publish-openapi-4597-crds.spec'
Apr 20 05:50:40.843: INFO: stderr: ""
Apr 20 05:50:40.843: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4597-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Apr 20 05:50:40.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-4225 explain e2e-test-crd-publish-openapi-4597-crds.spec.bars'
Apr 20 05:50:40.969: INFO: stderr: ""
Apr 20 05:50:40.969: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4597-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Apr 20 05:50:40.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-4225 explain e2e-test-crd-publish-openapi-4597-crds.spec.bars2'
Apr 20 05:50:41.091: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:50:43.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4225" for this suite.

• [SLOW TEST:7.272 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":346,"completed":9,"skipped":222,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:50:43.821: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name cm-test-opt-del-c5b12c75-4440-41e6-96e4-c521609084a2
STEP: Creating configMap with name cm-test-opt-upd-8f525394-3657-4c85-94a6-8a6deebe9bf5
STEP: Creating the pod
Apr 20 05:50:43.877: INFO: The status of Pod pod-projected-configmaps-645aeb87-d3e2-4552-af8a-37c8da2b614f is Pending, waiting for it to be Running (with Ready = true)
Apr 20 05:50:45.886: INFO: The status of Pod pod-projected-configmaps-645aeb87-d3e2-4552-af8a-37c8da2b614f is Running (Ready = true)
STEP: Deleting configmap cm-test-opt-del-c5b12c75-4440-41e6-96e4-c521609084a2
STEP: Updating configmap cm-test-opt-upd-8f525394-3657-4c85-94a6-8a6deebe9bf5
STEP: Creating configMap with name cm-test-opt-create-b995dece-f169-428c-9119-83e59b6e853b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:50:47.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7365" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":10,"skipped":230,"failed":0}
SSS
------------------------------
[sig-node] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:50:47.946: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with secret that has name secret-emptykey-test-f53cfbdf-22d7-4344-9af9-f62c5e889f75
[AfterEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:50:47.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8762" for this suite.
•{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","total":346,"completed":11,"skipped":233,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:50:47.984: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:54
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod busybox-81bb689a-8242-474f-b940-ca02b1020a67 in namespace container-probe-4696
Apr 20 05:50:52.020: INFO: Started pod busybox-81bb689a-8242-474f-b940-ca02b1020a67 in namespace container-probe-4696
STEP: checking the pod's current state and verifying that restartCount is present
Apr 20 05:50:52.022: INFO: Initial restart count of pod busybox-81bb689a-8242-474f-b940-ca02b1020a67 is 0
Apr 20 05:51:40.148: INFO: Restart count of pod container-probe-4696/busybox-81bb689a-8242-474f-b940-ca02b1020a67 is now 1 (48.12593315s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:51:40.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4696" for this suite.

• [SLOW TEST:52.184 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":346,"completed":12,"skipped":246,"failed":0}
SSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should list, patch and delete a collection of StatefulSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:51:40.168: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:92
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:107
STEP: Creating service test in namespace statefulset-3375
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 05:51:40.219: INFO: Found 0 stateful pods, waiting for 1
Apr 20 05:51:50.224: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet
Apr 20 05:51:50.251: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 20 05:51:50.252: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Pending - Ready=false
Apr 20 05:52:00.257: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 20 05:52:00.257: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets
STEP: Delete all of the StatefulSets
STEP: Verify that StatefulSets have been deleted
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:118
Apr 20 05:52:00.280: INFO: Deleting all statefulset in ns statefulset-3375
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:52:00.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3375" for this suite.

• [SLOW TEST:20.124 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:97
    should list, patch and delete a collection of StatefulSets [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","total":346,"completed":13,"skipped":250,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should run through the lifecycle of Pods and PodStatus [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:52:00.295: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:188
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a Pod with a static label
STEP: watching for Pod to be ready
Apr 20 05:52:00.389: INFO: observed Pod pod-test in namespace pods-6088 in phase Pending with labels: map[test-pod-static:true] & conditions []
Apr 20 05:52:00.390: INFO: observed Pod pod-test in namespace pods-6088 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-04-20 05:52:00 +0000 UTC  }]
Apr 20 05:52:00.400: INFO: observed Pod pod-test in namespace pods-6088 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-04-20 05:52:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-04-20 05:52:00 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-04-20 05:52:00 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-04-20 05:52:00 +0000 UTC  }]
Apr 20 05:52:00.791: INFO: observed Pod pod-test in namespace pods-6088 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-04-20 05:52:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-04-20 05:52:00 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-04-20 05:52:00 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-04-20 05:52:00 +0000 UTC  }]
Apr 20 05:52:01.581: INFO: Found Pod pod-test in namespace pods-6088 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-04-20 05:52:00 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-04-20 05:52:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-04-20 05:52:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-04-20 05:52:00 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data
Apr 20 05:52:01.593: INFO: observed event type ADDED
STEP: getting the Pod and ensuring that it's patched
STEP: replacing the Pod's status Ready condition to False
STEP: check the Pod again to ensure its Ready conditions are False
STEP: deleting the Pod via a Collection with a LabelSelector
STEP: watching for the Pod to be deleted
Apr 20 05:52:01.618: INFO: observed event type ADDED
Apr 20 05:52:01.618: INFO: observed event type MODIFIED
Apr 20 05:52:01.618: INFO: observed event type MODIFIED
Apr 20 05:52:01.618: INFO: observed event type MODIFIED
Apr 20 05:52:01.619: INFO: observed event type MODIFIED
Apr 20 05:52:01.619: INFO: observed event type MODIFIED
Apr 20 05:52:01.619: INFO: observed event type MODIFIED
Apr 20 05:52:01.619: INFO: observed event type MODIFIED
Apr 20 05:52:03.586: INFO: observed event type MODIFIED
Apr 20 05:52:03.729: INFO: observed event type MODIFIED
Apr 20 05:52:04.585: INFO: observed event type MODIFIED
Apr 20 05:52:04.592: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:52:04.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6088" for this suite.
•{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","total":346,"completed":14,"skipped":291,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should complete a service status lifecycle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:52:04.618: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should complete a service status lifecycle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a Service
STEP: watching for the Service to be added
Apr 20 05:52:04.664: INFO: Found Service test-service-f7466 in namespace services-7609 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Apr 20 05:52:04.664: INFO: Service test-service-f7466 created
STEP: Getting /status
Apr 20 05:52:04.666: INFO: Service test-service-f7466 has LoadBalancer: {[]}
STEP: patching the ServiceStatus
STEP: watching for the Service to be patched
Apr 20 05:52:04.672: INFO: observed Service test-service-f7466 in namespace services-7609 with annotations: map[] & LoadBalancer: {[]}
Apr 20 05:52:04.672: INFO: Found Service test-service-f7466 in namespace services-7609 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Apr 20 05:52:04.672: INFO: Service test-service-f7466 has service status patched
STEP: updating the ServiceStatus
Apr 20 05:52:04.678: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated
Apr 20 05:52:04.683: INFO: Observed Service test-service-f7466 in namespace services-7609 with annotations: map[] & Conditions: {[]}
Apr 20 05:52:04.683: INFO: Observed event: &Service{ObjectMeta:{test-service-f7466  services-7609  16590799-09e8-4133-9225-eae58373c319 4358 0 2022-04-20 05:52:04 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] []  [{e2e.test Update v1 2022-04-20 05:52:04 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-04-20 05:52:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.98.57.240,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.98.57.240],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Apr 20 05:52:04.683: INFO: Found Service test-service-f7466 in namespace services-7609 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 20 05:52:04.683: INFO: Service test-service-f7466 has service status updated
STEP: patching the service
STEP: watching for the Service to be patched
Apr 20 05:52:04.699: INFO: observed Service test-service-f7466 in namespace services-7609 with labels: map[test-service-static:true]
Apr 20 05:52:04.699: INFO: observed Service test-service-f7466 in namespace services-7609 with labels: map[test-service-static:true]
Apr 20 05:52:04.699: INFO: observed Service test-service-f7466 in namespace services-7609 with labels: map[test-service-static:true]
Apr 20 05:52:04.699: INFO: Found Service test-service-f7466 in namespace services-7609 with labels: map[test-service:patched test-service-static:true]
Apr 20 05:52:04.699: INFO: Service test-service-f7466 patched
STEP: deleting the service
STEP: watching for the Service to be deleted
Apr 20 05:52:04.714: INFO: Observed event: ADDED
Apr 20 05:52:04.714: INFO: Observed event: MODIFIED
Apr 20 05:52:04.714: INFO: Observed event: MODIFIED
Apr 20 05:52:04.714: INFO: Observed event: MODIFIED
Apr 20 05:52:04.714: INFO: Found Service test-service-f7466 in namespace services-7609 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Apr 20 05:52:04.715: INFO: Service test-service-f7466 deleted
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:52:04.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7609" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753
•{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","total":346,"completed":15,"skipped":305,"failed":0}
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:52:04.723: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0420 05:52:14.782254      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr 20 05:52:14.782: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:52:14.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4500" for this suite.

• [SLOW TEST:10.081 seconds]
[sig-api-machinery] Garbage collector
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":346,"completed":16,"skipped":309,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:52:14.805: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-upd-38a779b9-4972-4208-afc6-4375ff2a7422
STEP: Creating the pod
Apr 20 05:52:14.858: INFO: The status of Pod pod-configmaps-61bd04ff-d18f-483a-932f-bd5e372fb1e2 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 05:52:16.863: INFO: The status of Pod pod-configmaps-61bd04ff-d18f-483a-932f-bd5e372fb1e2 is Running (Ready = true)
STEP: Updating configmap configmap-test-upd-38a779b9-4972-4208-afc6-4375ff2a7422
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:52:20.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6587" for this suite.

• [SLOW TEST:6.099 seconds]
[sig-storage] ConfigMap
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":17,"skipped":345,"failed":0}
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] version v1
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:52:20.905: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 05:52:20.940: INFO: Creating pod...
Apr 20 05:52:20.956: INFO: Pod Quantity: 1 Status: Pending
Apr 20 05:52:21.960: INFO: Pod Quantity: 1 Status: Pending
Apr 20 05:52:22.961: INFO: Pod Status: Running
Apr 20 05:52:22.961: INFO: Creating service...
Apr 20 05:52:22.972: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2184/pods/agnhost/proxy/some/path/with/DELETE
Apr 20 05:52:22.990: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 20 05:52:22.990: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2184/pods/agnhost/proxy/some/path/with/GET
Apr 20 05:52:22.994: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Apr 20 05:52:22.994: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2184/pods/agnhost/proxy/some/path/with/HEAD
Apr 20 05:52:23.006: INFO: http.Client request:HEAD | StatusCode:200
Apr 20 05:52:23.006: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2184/pods/agnhost/proxy/some/path/with/OPTIONS
Apr 20 05:52:23.009: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 20 05:52:23.009: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2184/pods/agnhost/proxy/some/path/with/PATCH
Apr 20 05:52:23.012: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 20 05:52:23.012: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2184/pods/agnhost/proxy/some/path/with/POST
Apr 20 05:52:23.015: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 20 05:52:23.015: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2184/pods/agnhost/proxy/some/path/with/PUT
Apr 20 05:52:23.018: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Apr 20 05:52:23.018: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2184/services/test-service/proxy/some/path/with/DELETE
Apr 20 05:52:23.021: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 20 05:52:23.021: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2184/services/test-service/proxy/some/path/with/GET
Apr 20 05:52:23.026: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Apr 20 05:52:23.026: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2184/services/test-service/proxy/some/path/with/HEAD
Apr 20 05:52:23.031: INFO: http.Client request:HEAD | StatusCode:200
Apr 20 05:52:23.031: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2184/services/test-service/proxy/some/path/with/OPTIONS
Apr 20 05:52:23.035: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 20 05:52:23.035: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2184/services/test-service/proxy/some/path/with/PATCH
Apr 20 05:52:23.038: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 20 05:52:23.038: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2184/services/test-service/proxy/some/path/with/POST
Apr 20 05:52:23.042: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 20 05:52:23.042: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2184/services/test-service/proxy/some/path/with/PUT
Apr 20 05:52:23.045: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:52:23.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2184" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","total":346,"completed":18,"skipped":351,"failed":0}
SSSS
------------------------------
[sig-network] Ingress API 
  should support creating Ingress API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Ingress API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:52:23.054: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename ingress
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support creating Ingress API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting /apis
STEP: getting /apis/networking.k8s.io
STEP: getting /apis/networking.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Apr 20 05:52:23.101: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Apr 20 05:52:23.103: INFO: starting watch
STEP: patching
STEP: updating
Apr 20 05:52:23.114: INFO: waiting for watch events with expected annotations
Apr 20 05:52:23.114: INFO: saw patched and updated annotations
STEP: patching /status
STEP: updating /status
STEP: get /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] Ingress API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:52:23.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-532" for this suite.
•{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","total":346,"completed":19,"skipped":355,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:52:23.151: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test override command
Apr 20 05:52:23.181: INFO: Waiting up to 5m0s for pod "client-containers-a14cb0e6-9fb7-4efd-8a8c-ca4c7535e208" in namespace "containers-3764" to be "Succeeded or Failed"
Apr 20 05:52:23.184: INFO: Pod "client-containers-a14cb0e6-9fb7-4efd-8a8c-ca4c7535e208": Phase="Pending", Reason="", readiness=false. Elapsed: 2.645687ms
Apr 20 05:52:25.190: INFO: Pod "client-containers-a14cb0e6-9fb7-4efd-8a8c-ca4c7535e208": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008331236s
Apr 20 05:52:27.194: INFO: Pod "client-containers-a14cb0e6-9fb7-4efd-8a8c-ca4c7535e208": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012863257s
Apr 20 05:52:29.198: INFO: Pod "client-containers-a14cb0e6-9fb7-4efd-8a8c-ca4c7535e208": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016750719s
STEP: Saw pod success
Apr 20 05:52:29.198: INFO: Pod "client-containers-a14cb0e6-9fb7-4efd-8a8c-ca4c7535e208" satisfied condition "Succeeded or Failed"
Apr 20 05:52:29.200: INFO: Trying to get logs from node node22-07idr pod client-containers-a14cb0e6-9fb7-4efd-8a8c-ca4c7535e208 container agnhost-container: <nil>
STEP: delete the pod
Apr 20 05:52:29.228: INFO: Waiting for pod client-containers-a14cb0e6-9fb7-4efd-8a8c-ca4c7535e208 to disappear
Apr 20 05:52:29.231: INFO: Pod client-containers-a14cb0e6-9fb7-4efd-8a8c-ca4c7535e208 no longer exists
[AfterEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:52:29.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3764" for this suite.

• [SLOW TEST:6.089 seconds]
[sig-node] Docker Containers
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]","total":346,"completed":20,"skipped":376,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:52:29.240: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: set up a multi version CRD
Apr 20 05:52:29.274: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:52:44.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6217" for this suite.

• [SLOW TEST:15.574 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":346,"completed":21,"skipped":397,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease 
  lease API should be available [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Lease
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:52:44.814: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename lease-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] lease API should be available [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-node] Lease
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:52:44.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-5237" for this suite.
•{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","total":346,"completed":22,"skipped":416,"failed":0}
SSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:52:44.898: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:164
Apr 20 05:52:44.927: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 20 05:53:44.950: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 05:53:44.952: INFO: Starting informer...
STEP: Starting pod...
Apr 20 05:53:45.169: INFO: Pod is running on node22-wriki. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Apr 20 05:53:45.184: INFO: Pod wasn't evicted. Proceeding
Apr 20 05:53:45.184: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Apr 20 05:55:00.218: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:55:00.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-1541" for this suite.

• [SLOW TEST:135.331 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","total":346,"completed":23,"skipped":421,"failed":0}
SSSSSSSSS
------------------------------
[sig-instrumentation] Events API 
  should delete a collection of events [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:55:00.230: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/instrumentation/events.go:81
[It] should delete a collection of events [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create set of events
STEP: get a list of Events with a label in the current namespace
STEP: delete a list of events
Apr 20 05:55:00.277: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity
[AfterEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:55:00.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8645" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","total":346,"completed":24,"skipped":430,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:55:00.299: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-9925
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-9925
STEP: creating replication controller externalsvc in namespace services-9925
I0420 05:55:00.368499      20 runners.go:190] Created replication controller with name: externalsvc, namespace: services-9925, replica count: 2
I0420 05:55:03.419098      20 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Apr 20 05:55:03.446: INFO: Creating new exec pod
Apr 20 05:55:05.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-9925 exec execpod45vwv -- /bin/sh -x -c nslookup clusterip-service.services-9925.svc.cluster.local'
Apr 20 05:55:05.641: INFO: stderr: "+ nslookup clusterip-service.services-9925.svc.cluster.local\n"
Apr 20 05:55:05.641: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-9925.svc.cluster.local\tcanonical name = externalsvc.services-9925.svc.cluster.local.\nName:\texternalsvc.services-9925.svc.cluster.local\nAddress: 10.105.139.119\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-9925, will wait for the garbage collector to delete the pods
Apr 20 05:55:05.700: INFO: Deleting ReplicationController externalsvc took: 5.552405ms
Apr 20 05:55:05.800: INFO: Terminating ReplicationController externalsvc pods took: 100.424961ms
Apr 20 05:55:07.320: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:55:07.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9925" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:7.057 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":346,"completed":25,"skipped":450,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  Replace and Patch tests [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:55:07.357: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] Replace and Patch tests [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 05:55:07.402: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 20 05:55:12.406: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: Scaling up "test-rs" replicaset 
Apr 20 05:55:12.413: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet
Apr 20 05:55:12.433: INFO: observed ReplicaSet test-rs in namespace replicaset-796 with ReadyReplicas 1, AvailableReplicas 1
Apr 20 05:55:12.439: INFO: observed ReplicaSet test-rs in namespace replicaset-796 with ReadyReplicas 1, AvailableReplicas 1
Apr 20 05:55:12.450: INFO: observed ReplicaSet test-rs in namespace replicaset-796 with ReadyReplicas 1, AvailableReplicas 1
Apr 20 05:55:12.463: INFO: observed ReplicaSet test-rs in namespace replicaset-796 with ReadyReplicas 1, AvailableReplicas 1
Apr 20 05:55:13.880: INFO: observed ReplicaSet test-rs in namespace replicaset-796 with ReadyReplicas 2, AvailableReplicas 2
Apr 20 05:55:14.268: INFO: observed Replicaset test-rs in namespace replicaset-796 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:55:14.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-796" for this suite.

• [SLOW TEST:6.924 seconds]
[sig-apps] ReplicaSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","total":346,"completed":26,"skipped":471,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:55:14.283: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr 20 05:55:14.380: INFO: Waiting up to 5m0s for pod "downwardapi-volume-df4e702d-ac93-4fc0-b950-2e2e025514ad" in namespace "projected-5034" to be "Succeeded or Failed"
Apr 20 05:55:14.383: INFO: Pod "downwardapi-volume-df4e702d-ac93-4fc0-b950-2e2e025514ad": Phase="Pending", Reason="", readiness=false. Elapsed: 3.131683ms
Apr 20 05:55:16.385: INFO: Pod "downwardapi-volume-df4e702d-ac93-4fc0-b950-2e2e025514ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005788541s
STEP: Saw pod success
Apr 20 05:55:16.385: INFO: Pod "downwardapi-volume-df4e702d-ac93-4fc0-b950-2e2e025514ad" satisfied condition "Succeeded or Failed"
Apr 20 05:55:16.388: INFO: Trying to get logs from node node22-wriki pod downwardapi-volume-df4e702d-ac93-4fc0-b950-2e2e025514ad container client-container: <nil>
STEP: delete the pod
Apr 20 05:55:16.426: INFO: Waiting for pod downwardapi-volume-df4e702d-ac93-4fc0-b950-2e2e025514ad to disappear
Apr 20 05:55:16.428: INFO: Pod downwardapi-volume-df4e702d-ac93-4fc0-b950-2e2e025514ad no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:55:16.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5034" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":346,"completed":27,"skipped":533,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:55:16.436: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/init_container.go:162
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
Apr 20 05:55:16.469: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:55:18.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1471" for this suite.
•{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":346,"completed":28,"skipped":543,"failed":0}

------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:55:18.991: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Performing setup for networking test in namespace pod-network-test-1955
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 20 05:55:19.025: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 20 05:55:19.053: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 05:55:21.068: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 20 05:55:23.057: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 20 05:55:25.060: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 20 05:55:27.057: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 20 05:55:29.060: INFO: The status of Pod netserver-0 is Running (Ready = true)
Apr 20 05:55:29.065: INFO: The status of Pod netserver-1 is Running (Ready = true)
Apr 20 05:55:29.069: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Apr 20 05:55:31.082: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Apr 20 05:55:31.082: INFO: Breadth first check of 10.233.1.9 on host 10.100.118.168...
Apr 20 05:55:31.084: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.2.20:9080/dial?request=hostname&protocol=http&host=10.233.1.9&port=8083&tries=1'] Namespace:pod-network-test-1955 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 05:55:31.084: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 05:55:31.151: INFO: Waiting for responses: map[]
Apr 20 05:55:31.151: INFO: reached 10.233.1.9 after 0/1 tries
Apr 20 05:55:31.151: INFO: Breadth first check of 10.233.0.17 on host 10.100.125.144...
Apr 20 05:55:31.155: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.2.20:9080/dial?request=hostname&protocol=http&host=10.233.0.17&port=8083&tries=1'] Namespace:pod-network-test-1955 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 05:55:31.155: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 05:55:31.225: INFO: Waiting for responses: map[]
Apr 20 05:55:31.225: INFO: reached 10.233.0.17 after 0/1 tries
Apr 20 05:55:31.225: INFO: Breadth first check of 10.233.2.19 on host 10.100.99.219...
Apr 20 05:55:31.228: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.2.20:9080/dial?request=hostname&protocol=http&host=10.233.2.19&port=8083&tries=1'] Namespace:pod-network-test-1955 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 05:55:31.228: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 05:55:31.293: INFO: Waiting for responses: map[]
Apr 20 05:55:31.293: INFO: reached 10.233.2.19 after 0/1 tries
Apr 20 05:55:31.293: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:55:31.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1955" for this suite.

• [SLOW TEST:12.311 seconds]
[sig-network] Networking
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/networking.go:30
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","total":346,"completed":29,"skipped":543,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:55:31.303: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service in namespace services-2588
Apr 20 05:55:31.348: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Apr 20 05:55:33.354: INFO: The status of Pod kube-proxy-mode-detector is Running (Ready = true)
Apr 20 05:55:33.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-2588 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Apr 20 05:55:33.494: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Apr 20 05:55:33.494: INFO: stdout: "iptables"
Apr 20 05:55:33.494: INFO: proxyMode: iptables
Apr 20 05:55:33.505: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Apr 20 05:55:33.508: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-2588
STEP: creating replication controller affinity-clusterip-timeout in namespace services-2588
I0420 05:55:33.532128      20 runners.go:190] Created replication controller with name: affinity-clusterip-timeout, namespace: services-2588, replica count: 3
I0420 05:55:36.582975      20 runners.go:190] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 20 05:55:36.588: INFO: Creating new exec pod
Apr 20 05:55:39.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-2588 exec execpod-affinityvksgj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Apr 20 05:55:39.733: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-timeout 80\n+ echo hostName\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Apr 20 05:55:39.733: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 20 05:55:39.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-2588 exec execpod-affinityvksgj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.109.148.42 80'
Apr 20 05:55:39.845: INFO: stderr: "+ nc -v -t -w 2 10.109.148.42 80\n+ echo hostName\nConnection to 10.109.148.42 80 port [tcp/http] succeeded!\n"
Apr 20 05:55:39.845: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 20 05:55:39.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-2588 exec execpod-affinityvksgj -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.109.148.42:80/ ; done'
Apr 20 05:55:40.029: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.148.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.148.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.148.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.148.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.148.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.148.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.148.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.148.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.148.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.148.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.148.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.148.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.148.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.148.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.148.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.148.42:80/\n"
Apr 20 05:55:40.029: INFO: stdout: "\naffinity-clusterip-timeout-rknbn\naffinity-clusterip-timeout-rknbn\naffinity-clusterip-timeout-rknbn\naffinity-clusterip-timeout-rknbn\naffinity-clusterip-timeout-rknbn\naffinity-clusterip-timeout-rknbn\naffinity-clusterip-timeout-rknbn\naffinity-clusterip-timeout-rknbn\naffinity-clusterip-timeout-rknbn\naffinity-clusterip-timeout-rknbn\naffinity-clusterip-timeout-rknbn\naffinity-clusterip-timeout-rknbn\naffinity-clusterip-timeout-rknbn\naffinity-clusterip-timeout-rknbn\naffinity-clusterip-timeout-rknbn\naffinity-clusterip-timeout-rknbn"
Apr 20 05:55:40.029: INFO: Received response from host: affinity-clusterip-timeout-rknbn
Apr 20 05:55:40.029: INFO: Received response from host: affinity-clusterip-timeout-rknbn
Apr 20 05:55:40.029: INFO: Received response from host: affinity-clusterip-timeout-rknbn
Apr 20 05:55:40.029: INFO: Received response from host: affinity-clusterip-timeout-rknbn
Apr 20 05:55:40.029: INFO: Received response from host: affinity-clusterip-timeout-rknbn
Apr 20 05:55:40.029: INFO: Received response from host: affinity-clusterip-timeout-rknbn
Apr 20 05:55:40.029: INFO: Received response from host: affinity-clusterip-timeout-rknbn
Apr 20 05:55:40.029: INFO: Received response from host: affinity-clusterip-timeout-rknbn
Apr 20 05:55:40.029: INFO: Received response from host: affinity-clusterip-timeout-rknbn
Apr 20 05:55:40.029: INFO: Received response from host: affinity-clusterip-timeout-rknbn
Apr 20 05:55:40.029: INFO: Received response from host: affinity-clusterip-timeout-rknbn
Apr 20 05:55:40.029: INFO: Received response from host: affinity-clusterip-timeout-rknbn
Apr 20 05:55:40.029: INFO: Received response from host: affinity-clusterip-timeout-rknbn
Apr 20 05:55:40.029: INFO: Received response from host: affinity-clusterip-timeout-rknbn
Apr 20 05:55:40.029: INFO: Received response from host: affinity-clusterip-timeout-rknbn
Apr 20 05:55:40.029: INFO: Received response from host: affinity-clusterip-timeout-rknbn
Apr 20 05:55:40.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-2588 exec execpod-affinityvksgj -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.109.148.42:80/'
Apr 20 05:55:40.158: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.109.148.42:80/\n"
Apr 20 05:55:40.158: INFO: stdout: "affinity-clusterip-timeout-rknbn"
Apr 20 05:56:00.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-2588 exec execpod-affinityvksgj -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.109.148.42:80/'
Apr 20 05:56:00.271: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.109.148.42:80/\n"
Apr 20 05:56:00.271: INFO: stdout: "affinity-clusterip-timeout-x55bs"
Apr 20 05:56:00.271: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-2588, will wait for the garbage collector to delete the pods
Apr 20 05:56:00.345: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 5.18596ms
Apr 20 05:56:00.445: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 100.464093ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:56:02.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2588" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:31.233 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","total":346,"completed":30,"skipped":558,"failed":0}
SSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:56:02.537: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:52
STEP: create the container to handle the HTTPGet hook request.
Apr 20 05:56:02.607: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 20 05:56:04.612: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the pod with lifecycle hook
Apr 20 05:56:04.624: INFO: The status of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 20 05:56:06.628: INFO: The status of Pod pod-with-prestop-exec-hook is Running (Ready = true)
STEP: delete the pod with lifecycle hook
Apr 20 05:56:06.638: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 20 05:56:06.640: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 20 05:56:08.641: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 20 05:56:08.645: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 20 05:56:10.641: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 20 05:56:10.647: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:56:10.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-448" for this suite.

• [SLOW TEST:8.126 seconds]
[sig-node] Container Lifecycle Hook
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:43
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":346,"completed":31,"skipped":565,"failed":0}
S
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:56:10.664: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8964 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8964;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8964 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8964;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8964.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8964.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8964.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8964.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8964.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8964.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8964.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8964.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8964.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8964.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8964.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8964.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8964.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 151.188.104.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.104.188.151_udp@PTR;check="$$(dig +tcp +noall +answer +search 151.188.104.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.104.188.151_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8964 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8964;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8964 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8964;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8964.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8964.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8964.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8964.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8964.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8964.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8964.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8964.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8964.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8964.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8964.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8964.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8964.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 151.188.104.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.104.188.151_udp@PTR;check="$$(dig +tcp +noall +answer +search 151.188.104.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.104.188.151_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 20 05:56:18.778: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8964/dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf: the server could not find the requested resource (get pods dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf)
Apr 20 05:56:18.781: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8964/dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf: the server could not find the requested resource (get pods dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf)
Apr 20 05:56:18.785: INFO: Unable to read wheezy_udp@dns-test-service.dns-8964 from pod dns-8964/dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf: the server could not find the requested resource (get pods dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf)
Apr 20 05:56:18.788: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8964 from pod dns-8964/dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf: the server could not find the requested resource (get pods dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf)
Apr 20 05:56:18.790: INFO: Unable to read wheezy_udp@dns-test-service.dns-8964.svc from pod dns-8964/dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf: the server could not find the requested resource (get pods dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf)
Apr 20 05:56:18.793: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8964.svc from pod dns-8964/dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf: the server could not find the requested resource (get pods dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf)
Apr 20 05:56:18.796: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8964.svc from pod dns-8964/dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf: the server could not find the requested resource (get pods dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf)
Apr 20 05:56:18.799: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8964.svc from pod dns-8964/dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf: the server could not find the requested resource (get pods dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf)
Apr 20 05:56:18.818: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8964/dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf: the server could not find the requested resource (get pods dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf)
Apr 20 05:56:18.821: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8964/dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf: the server could not find the requested resource (get pods dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf)
Apr 20 05:56:18.823: INFO: Unable to read jessie_udp@dns-test-service.dns-8964 from pod dns-8964/dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf: the server could not find the requested resource (get pods dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf)
Apr 20 05:56:18.826: INFO: Unable to read jessie_tcp@dns-test-service.dns-8964 from pod dns-8964/dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf: the server could not find the requested resource (get pods dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf)
Apr 20 05:56:18.828: INFO: Unable to read jessie_udp@dns-test-service.dns-8964.svc from pod dns-8964/dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf: the server could not find the requested resource (get pods dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf)
Apr 20 05:56:18.831: INFO: Unable to read jessie_tcp@dns-test-service.dns-8964.svc from pod dns-8964/dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf: the server could not find the requested resource (get pods dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf)
Apr 20 05:56:18.833: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8964.svc from pod dns-8964/dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf: the server could not find the requested resource (get pods dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf)
Apr 20 05:56:18.836: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8964.svc from pod dns-8964/dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf: the server could not find the requested resource (get pods dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf)
Apr 20 05:56:18.850: INFO: Lookups using dns-8964/dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8964 wheezy_tcp@dns-test-service.dns-8964 wheezy_udp@dns-test-service.dns-8964.svc wheezy_tcp@dns-test-service.dns-8964.svc wheezy_udp@_http._tcp.dns-test-service.dns-8964.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8964.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8964 jessie_tcp@dns-test-service.dns-8964 jessie_udp@dns-test-service.dns-8964.svc jessie_tcp@dns-test-service.dns-8964.svc jessie_udp@_http._tcp.dns-test-service.dns-8964.svc jessie_tcp@_http._tcp.dns-test-service.dns-8964.svc]

Apr 20 05:56:23.938: INFO: DNS probes using dns-8964/dns-test-67c23d2d-84df-4a2c-8c55-8b81d823cbcf succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:56:24.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8964" for this suite.

• [SLOW TEST:13.375 seconds]
[sig-network] DNS
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":346,"completed":32,"skipped":566,"failed":0}
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:56:24.042: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-5870.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-5870.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5870.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-5870.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-5870.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5870.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 20 05:56:26.132: INFO: DNS probes using dns-5870/dns-test-b9d1b534-ddb1-4ecc-a2c8-1324d830fe65 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:56:26.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5870" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [LinuxOnly] [Conformance]","total":346,"completed":33,"skipped":570,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should test the lifecycle of a ReplicationController [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:56:26.188: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should test the lifecycle of a ReplicationController [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a ReplicationController
STEP: waiting for RC to be added
STEP: waiting for available Replicas
STEP: patching ReplicationController
STEP: waiting for RC to be modified
STEP: patching ReplicationController status
STEP: waiting for RC to be modified
STEP: waiting for available Replicas
STEP: fetching ReplicationController status
STEP: patching ReplicationController scale
STEP: waiting for RC to be modified
STEP: waiting for ReplicationController's scale to be the max amount
STEP: fetching ReplicationController; ensuring that it's patched
STEP: updating ReplicationController status
STEP: waiting for RC to be modified
STEP: listing all ReplicationControllers
STEP: checking that ReplicationController has expected values
STEP: deleting ReplicationControllers by collection
STEP: waiting for ReplicationController to have a DELETED watchEvent
[AfterEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:56:29.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6413" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","total":346,"completed":34,"skipped":636,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:56:29.180: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/endpointslice.go:49
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: referencing a single matching pod
STEP: referencing matching pods with named port
STEP: creating empty Endpoints and EndpointSlices for no matching Pods
STEP: recreating EndpointSlices after they've been deleted
Apr 20 05:56:49.372: INFO: EndpointSlice for Service endpointslice-5117/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:56:59.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-5117" for this suite.

• [SLOW TEST:30.219 seconds]
[sig-network] EndpointSlice
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","total":346,"completed":35,"skipped":659,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange 
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] LimitRange
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:56:59.400: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename limitrange
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a LimitRange
STEP: Setting up watch
STEP: Submitting a LimitRange
Apr 20 05:56:59.444: INFO: observed the limitRanges list
STEP: Verifying LimitRange creation was observed
STEP: Fetching the LimitRange to ensure it has proper values
Apr 20 05:56:59.451: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Apr 20 05:56:59.451: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements
STEP: Ensuring Pod has resource requirements applied from LimitRange
Apr 20 05:56:59.466: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Apr 20 05:56:59.466: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements
STEP: Ensuring Pod has merged resource requirements applied from LimitRange
Apr 20 05:56:59.478: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Apr 20 05:56:59.478: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources
STEP: Failing to create a Pod with more than max resources
STEP: Updating a LimitRange
STEP: Verifying LimitRange updating is effective
STEP: Creating a Pod with less than former min resources
STEP: Failing to create a Pod with more than max resources
STEP: Deleting a LimitRange
STEP: Verifying the LimitRange was deleted
Apr 20 05:57:06.521: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources
[AfterEach] [sig-scheduling] LimitRange
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:57:06.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-5885" for this suite.

• [SLOW TEST:7.140 seconds]
[sig-scheduling] LimitRange
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","total":346,"completed":36,"skipped":679,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:57:06.541: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 20 05:57:06.570: INFO: Waiting up to 5m0s for pod "pod-db2dd730-2d2e-4e7e-ba31-e5a82b28e75a" in namespace "emptydir-9548" to be "Succeeded or Failed"
Apr 20 05:57:06.572: INFO: Pod "pod-db2dd730-2d2e-4e7e-ba31-e5a82b28e75a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.150086ms
Apr 20 05:57:08.577: INFO: Pod "pod-db2dd730-2d2e-4e7e-ba31-e5a82b28e75a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006403984s
STEP: Saw pod success
Apr 20 05:57:08.577: INFO: Pod "pod-db2dd730-2d2e-4e7e-ba31-e5a82b28e75a" satisfied condition "Succeeded or Failed"
Apr 20 05:57:08.579: INFO: Trying to get logs from node node22-wriki pod pod-db2dd730-2d2e-4e7e-ba31-e5a82b28e75a container test-container: <nil>
STEP: delete the pod
Apr 20 05:57:08.595: INFO: Waiting for pod pod-db2dd730-2d2e-4e7e-ba31-e5a82b28e75a to disappear
Apr 20 05:57:08.597: INFO: Pod pod-db2dd730-2d2e-4e7e-ba31-e5a82b28e75a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:57:08.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9548" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":37,"skipped":700,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:57:08.606: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service in namespace services-839
STEP: creating service affinity-clusterip-transition in namespace services-839
STEP: creating replication controller affinity-clusterip-transition in namespace services-839
I0420 05:57:08.651830      20 runners.go:190] Created replication controller with name: affinity-clusterip-transition, namespace: services-839, replica count: 3
I0420 05:57:11.702594      20 runners.go:190] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 20 05:57:11.709: INFO: Creating new exec pod
Apr 20 05:57:14.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-839 exec execpod-affinitybzz54 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Apr 20 05:57:14.887: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Apr 20 05:57:14.887: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 20 05:57:14.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-839 exec execpod-affinitybzz54 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.106.71.109 80'
Apr 20 05:57:15.031: INFO: stderr: "+ nc -v -t -w 2 10.106.71.109 80\n+ echo hostName\nConnection to 10.106.71.109 80 port [tcp/http] succeeded!\n"
Apr 20 05:57:15.031: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 20 05:57:15.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-839 exec execpod-affinitybzz54 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.106.71.109:80/ ; done'
Apr 20 05:57:15.242: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n"
Apr 20 05:57:15.242: INFO: stdout: "\naffinity-clusterip-transition-9hpcz\naffinity-clusterip-transition-nprqh\naffinity-clusterip-transition-ck5qh\naffinity-clusterip-transition-ck5qh\naffinity-clusterip-transition-9hpcz\naffinity-clusterip-transition-ck5qh\naffinity-clusterip-transition-ck5qh\naffinity-clusterip-transition-nprqh\naffinity-clusterip-transition-ck5qh\naffinity-clusterip-transition-9hpcz\naffinity-clusterip-transition-nprqh\naffinity-clusterip-transition-ck5qh\naffinity-clusterip-transition-9hpcz\naffinity-clusterip-transition-ck5qh\naffinity-clusterip-transition-nprqh\naffinity-clusterip-transition-9hpcz"
Apr 20 05:57:15.242: INFO: Received response from host: affinity-clusterip-transition-9hpcz
Apr 20 05:57:15.242: INFO: Received response from host: affinity-clusterip-transition-nprqh
Apr 20 05:57:15.242: INFO: Received response from host: affinity-clusterip-transition-ck5qh
Apr 20 05:57:15.242: INFO: Received response from host: affinity-clusterip-transition-ck5qh
Apr 20 05:57:15.242: INFO: Received response from host: affinity-clusterip-transition-9hpcz
Apr 20 05:57:15.242: INFO: Received response from host: affinity-clusterip-transition-ck5qh
Apr 20 05:57:15.242: INFO: Received response from host: affinity-clusterip-transition-ck5qh
Apr 20 05:57:15.242: INFO: Received response from host: affinity-clusterip-transition-nprqh
Apr 20 05:57:15.242: INFO: Received response from host: affinity-clusterip-transition-ck5qh
Apr 20 05:57:15.242: INFO: Received response from host: affinity-clusterip-transition-9hpcz
Apr 20 05:57:15.242: INFO: Received response from host: affinity-clusterip-transition-nprqh
Apr 20 05:57:15.242: INFO: Received response from host: affinity-clusterip-transition-ck5qh
Apr 20 05:57:15.242: INFO: Received response from host: affinity-clusterip-transition-9hpcz
Apr 20 05:57:15.242: INFO: Received response from host: affinity-clusterip-transition-ck5qh
Apr 20 05:57:15.242: INFO: Received response from host: affinity-clusterip-transition-nprqh
Apr 20 05:57:15.242: INFO: Received response from host: affinity-clusterip-transition-9hpcz
Apr 20 05:57:15.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-839 exec execpod-affinitybzz54 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.106.71.109:80/ ; done'
Apr 20 05:57:15.443: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.71.109:80/\n"
Apr 20 05:57:15.443: INFO: stdout: "\naffinity-clusterip-transition-ck5qh\naffinity-clusterip-transition-ck5qh\naffinity-clusterip-transition-ck5qh\naffinity-clusterip-transition-ck5qh\naffinity-clusterip-transition-ck5qh\naffinity-clusterip-transition-ck5qh\naffinity-clusterip-transition-ck5qh\naffinity-clusterip-transition-ck5qh\naffinity-clusterip-transition-ck5qh\naffinity-clusterip-transition-ck5qh\naffinity-clusterip-transition-ck5qh\naffinity-clusterip-transition-ck5qh\naffinity-clusterip-transition-ck5qh\naffinity-clusterip-transition-ck5qh\naffinity-clusterip-transition-ck5qh\naffinity-clusterip-transition-ck5qh"
Apr 20 05:57:15.443: INFO: Received response from host: affinity-clusterip-transition-ck5qh
Apr 20 05:57:15.443: INFO: Received response from host: affinity-clusterip-transition-ck5qh
Apr 20 05:57:15.443: INFO: Received response from host: affinity-clusterip-transition-ck5qh
Apr 20 05:57:15.443: INFO: Received response from host: affinity-clusterip-transition-ck5qh
Apr 20 05:57:15.443: INFO: Received response from host: affinity-clusterip-transition-ck5qh
Apr 20 05:57:15.443: INFO: Received response from host: affinity-clusterip-transition-ck5qh
Apr 20 05:57:15.443: INFO: Received response from host: affinity-clusterip-transition-ck5qh
Apr 20 05:57:15.443: INFO: Received response from host: affinity-clusterip-transition-ck5qh
Apr 20 05:57:15.443: INFO: Received response from host: affinity-clusterip-transition-ck5qh
Apr 20 05:57:15.443: INFO: Received response from host: affinity-clusterip-transition-ck5qh
Apr 20 05:57:15.443: INFO: Received response from host: affinity-clusterip-transition-ck5qh
Apr 20 05:57:15.443: INFO: Received response from host: affinity-clusterip-transition-ck5qh
Apr 20 05:57:15.443: INFO: Received response from host: affinity-clusterip-transition-ck5qh
Apr 20 05:57:15.443: INFO: Received response from host: affinity-clusterip-transition-ck5qh
Apr 20 05:57:15.443: INFO: Received response from host: affinity-clusterip-transition-ck5qh
Apr 20 05:57:15.443: INFO: Received response from host: affinity-clusterip-transition-ck5qh
Apr 20 05:57:15.443: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-839, will wait for the garbage collector to delete the pods
Apr 20 05:57:15.511: INFO: Deleting ReplicationController affinity-clusterip-transition took: 4.861364ms
Apr 20 05:57:15.617: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 106.250487ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:57:17.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-839" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:9.102 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","total":346,"completed":38,"skipped":741,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events 
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-instrumentation] Events
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:57:17.709: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a test event
STEP: listing all events in all namespaces
STEP: patching the test event
STEP: fetching the test event
STEP: deleting the test event
STEP: listing all events in all namespaces
[AfterEach] [sig-instrumentation] Events
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:57:17.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-3474" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","total":346,"completed":39,"skipped":756,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount projected service account token [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:57:17.838: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount projected service account token [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test service account token: 
Apr 20 05:57:17.872: INFO: Waiting up to 5m0s for pod "test-pod-561ec89e-0455-4790-bf64-0c201612d2f8" in namespace "svcaccounts-7887" to be "Succeeded or Failed"
Apr 20 05:57:17.881: INFO: Pod "test-pod-561ec89e-0455-4790-bf64-0c201612d2f8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.973802ms
Apr 20 05:57:19.885: INFO: Pod "test-pod-561ec89e-0455-4790-bf64-0c201612d2f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012988014s
STEP: Saw pod success
Apr 20 05:57:19.885: INFO: Pod "test-pod-561ec89e-0455-4790-bf64-0c201612d2f8" satisfied condition "Succeeded or Failed"
Apr 20 05:57:19.887: INFO: Trying to get logs from node node22-wriki pod test-pod-561ec89e-0455-4790-bf64-0c201612d2f8 container agnhost-container: <nil>
STEP: delete the pod
Apr 20 05:57:19.901: INFO: Waiting for pod test-pod-561ec89e-0455-4790-bf64-0c201612d2f8 to disappear
Apr 20 05:57:19.903: INFO: Pod test-pod-561ec89e-0455-4790-bf64-0c201612d2f8 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:57:19.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7887" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","total":346,"completed":40,"skipped":772,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:57:19.913: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:188
[It] should be updated [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
STEP: submitting the pod to kubernetes
Apr 20 05:57:19.957: INFO: The status of Pod pod-update-74fbfbcd-3dc7-447f-a10e-6dad62b2dc9b is Pending, waiting for it to be Running (with Ready = true)
Apr 20 05:57:21.962: INFO: The status of Pod pod-update-74fbfbcd-3dc7-447f-a10e-6dad62b2dc9b is Running (Ready = true)
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 20 05:57:22.478: INFO: Successfully updated pod "pod-update-74fbfbcd-3dc7-447f-a10e-6dad62b2dc9b"
STEP: verifying the updated pod is in kubernetes
Apr 20 05:57:22.483: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:57:22.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2352" for this suite.
•{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","total":346,"completed":41,"skipped":809,"failed":0}
SSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:57:22.492: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test substitution in container's command
Apr 20 05:57:22.530: INFO: Waiting up to 5m0s for pod "var-expansion-431af06e-93ca-40d1-aeb7-3fc1bdd97bd5" in namespace "var-expansion-7848" to be "Succeeded or Failed"
Apr 20 05:57:22.532: INFO: Pod "var-expansion-431af06e-93ca-40d1-aeb7-3fc1bdd97bd5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.313388ms
Apr 20 05:57:24.539: INFO: Pod "var-expansion-431af06e-93ca-40d1-aeb7-3fc1bdd97bd5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009220257s
STEP: Saw pod success
Apr 20 05:57:24.539: INFO: Pod "var-expansion-431af06e-93ca-40d1-aeb7-3fc1bdd97bd5" satisfied condition "Succeeded or Failed"
Apr 20 05:57:24.541: INFO: Trying to get logs from node node22-hwh1v pod var-expansion-431af06e-93ca-40d1-aeb7-3fc1bdd97bd5 container dapi-container: <nil>
STEP: delete the pod
Apr 20 05:57:24.566: INFO: Waiting for pod var-expansion-431af06e-93ca-40d1-aeb7-3fc1bdd97bd5 to disappear
Apr 20 05:57:24.569: INFO: Pod var-expansion-431af06e-93ca-40d1-aeb7-3fc1bdd97bd5 no longer exists
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:57:24.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7848" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":346,"completed":42,"skipped":816,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:57:24.576: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 05:57:24.610: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Apr 20 05:57:27.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-4606 --namespace=crd-publish-openapi-4606 create -f -'
Apr 20 05:57:27.601: INFO: stderr: ""
Apr 20 05:57:27.601: INFO: stdout: "e2e-test-crd-publish-openapi-5856-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr 20 05:57:27.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-4606 --namespace=crd-publish-openapi-4606 delete e2e-test-crd-publish-openapi-5856-crds test-cr'
Apr 20 05:57:27.694: INFO: stderr: ""
Apr 20 05:57:27.694: INFO: stdout: "e2e-test-crd-publish-openapi-5856-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Apr 20 05:57:27.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-4606 --namespace=crd-publish-openapi-4606 apply -f -'
Apr 20 05:57:27.830: INFO: stderr: ""
Apr 20 05:57:27.830: INFO: stdout: "e2e-test-crd-publish-openapi-5856-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr 20 05:57:27.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-4606 --namespace=crd-publish-openapi-4606 delete e2e-test-crd-publish-openapi-5856-crds test-cr'
Apr 20 05:57:27.884: INFO: stderr: ""
Apr 20 05:57:27.884: INFO: stdout: "e2e-test-crd-publish-openapi-5856-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Apr 20 05:57:27.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-4606 explain e2e-test-crd-publish-openapi-5856-crds'
Apr 20 05:57:28.015: INFO: stderr: ""
Apr 20 05:57:28.015: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5856-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:57:30.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4606" for this suite.

• [SLOW TEST:6.185 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":346,"completed":43,"skipped":824,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:57:30.761: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward api env vars
Apr 20 05:57:30.802: INFO: Waiting up to 5m0s for pod "downward-api-b4e7c839-657e-4894-949c-6d22534fabc5" in namespace "downward-api-6493" to be "Succeeded or Failed"
Apr 20 05:57:30.805: INFO: Pod "downward-api-b4e7c839-657e-4894-949c-6d22534fabc5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.611698ms
Apr 20 05:57:32.819: INFO: Pod "downward-api-b4e7c839-657e-4894-949c-6d22534fabc5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016729435s
Apr 20 05:57:34.825: INFO: Pod "downward-api-b4e7c839-657e-4894-949c-6d22534fabc5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022883396s
STEP: Saw pod success
Apr 20 05:57:34.825: INFO: Pod "downward-api-b4e7c839-657e-4894-949c-6d22534fabc5" satisfied condition "Succeeded or Failed"
Apr 20 05:57:34.827: INFO: Trying to get logs from node node22-wriki pod downward-api-b4e7c839-657e-4894-949c-6d22534fabc5 container dapi-container: <nil>
STEP: delete the pod
Apr 20 05:57:34.843: INFO: Waiting for pod downward-api-b4e7c839-657e-4894-949c-6d22534fabc5 to disappear
Apr 20 05:57:34.845: INFO: Pod downward-api-b4e7c839-657e-4894-949c-6d22534fabc5 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:57:34.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6493" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":346,"completed":44,"skipped":854,"failed":0}
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:57:34.852: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-7e06c8dc-57ef-4c8d-8e0b-75785f50b03f
STEP: Creating a pod to test consume configMaps
Apr 20 05:57:34.892: INFO: Waiting up to 5m0s for pod "pod-configmaps-3ec76a14-7e6b-47c5-80c3-937be327ed9a" in namespace "configmap-346" to be "Succeeded or Failed"
Apr 20 05:57:34.894: INFO: Pod "pod-configmaps-3ec76a14-7e6b-47c5-80c3-937be327ed9a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041655ms
Apr 20 05:57:36.898: INFO: Pod "pod-configmaps-3ec76a14-7e6b-47c5-80c3-937be327ed9a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006294122s
STEP: Saw pod success
Apr 20 05:57:36.898: INFO: Pod "pod-configmaps-3ec76a14-7e6b-47c5-80c3-937be327ed9a" satisfied condition "Succeeded or Failed"
Apr 20 05:57:36.900: INFO: Trying to get logs from node node22-wriki pod pod-configmaps-3ec76a14-7e6b-47c5-80c3-937be327ed9a container configmap-volume-test: <nil>
STEP: delete the pod
Apr 20 05:57:36.917: INFO: Waiting for pod pod-configmaps-3ec76a14-7e6b-47c5-80c3-937be327ed9a to disappear
Apr 20 05:57:36.919: INFO: Pod pod-configmaps-3ec76a14-7e6b-47c5-80c3-937be327ed9a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:57:36.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-346" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":346,"completed":45,"skipped":859,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:57:36.927: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr 20 05:57:36.983: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9520a076-ad51-4e48-915f-c17f3c8a93d9" in namespace "downward-api-8191" to be "Succeeded or Failed"
Apr 20 05:57:36.991: INFO: Pod "downwardapi-volume-9520a076-ad51-4e48-915f-c17f3c8a93d9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.493334ms
Apr 20 05:57:38.997: INFO: Pod "downwardapi-volume-9520a076-ad51-4e48-915f-c17f3c8a93d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014790375s
STEP: Saw pod success
Apr 20 05:57:38.998: INFO: Pod "downwardapi-volume-9520a076-ad51-4e48-915f-c17f3c8a93d9" satisfied condition "Succeeded or Failed"
Apr 20 05:57:39.000: INFO: Trying to get logs from node node22-wriki pod downwardapi-volume-9520a076-ad51-4e48-915f-c17f3c8a93d9 container client-container: <nil>
STEP: delete the pod
Apr 20 05:57:39.013: INFO: Waiting for pod downwardapi-volume-9520a076-ad51-4e48-915f-c17f3c8a93d9 to disappear
Apr 20 05:57:39.016: INFO: Pod downwardapi-volume-9520a076-ad51-4e48-915f-c17f3c8a93d9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:57:39.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8191" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":346,"completed":46,"skipped":868,"failed":0}
SSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:57:39.023: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/init_container.go:162
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
Apr 20 05:57:39.051: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:57:42.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3828" for this suite.
•{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":346,"completed":47,"skipped":872,"failed":0}
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:57:42.170: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 20 05:57:42.206: INFO: Waiting up to 5m0s for pod "pod-c2951eb2-5621-4cca-8d32-690827945015" in namespace "emptydir-3658" to be "Succeeded or Failed"
Apr 20 05:57:42.214: INFO: Pod "pod-c2951eb2-5621-4cca-8d32-690827945015": Phase="Pending", Reason="", readiness=false. Elapsed: 7.763281ms
Apr 20 05:57:44.219: INFO: Pod "pod-c2951eb2-5621-4cca-8d32-690827945015": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013005398s
STEP: Saw pod success
Apr 20 05:57:44.219: INFO: Pod "pod-c2951eb2-5621-4cca-8d32-690827945015" satisfied condition "Succeeded or Failed"
Apr 20 05:57:44.221: INFO: Trying to get logs from node node22-hwh1v pod pod-c2951eb2-5621-4cca-8d32-690827945015 container test-container: <nil>
STEP: delete the pod
Apr 20 05:57:44.235: INFO: Waiting for pod pod-c2951eb2-5621-4cca-8d32-690827945015 to disappear
Apr 20 05:57:44.237: INFO: Pod pod-c2951eb2-5621-4cca-8d32-690827945015 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:57:44.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3658" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":48,"skipped":876,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:57:44.245: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward api env vars
Apr 20 05:57:44.302: INFO: Waiting up to 5m0s for pod "downward-api-b55bdd82-8753-4aff-b4e8-3aa8d1cf9f0c" in namespace "downward-api-3173" to be "Succeeded or Failed"
Apr 20 05:57:44.305: INFO: Pod "downward-api-b55bdd82-8753-4aff-b4e8-3aa8d1cf9f0c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.731338ms
Apr 20 05:57:46.310: INFO: Pod "downward-api-b55bdd82-8753-4aff-b4e8-3aa8d1cf9f0c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008058828s
STEP: Saw pod success
Apr 20 05:57:46.310: INFO: Pod "downward-api-b55bdd82-8753-4aff-b4e8-3aa8d1cf9f0c" satisfied condition "Succeeded or Failed"
Apr 20 05:57:46.313: INFO: Trying to get logs from node node22-hwh1v pod downward-api-b55bdd82-8753-4aff-b4e8-3aa8d1cf9f0c container dapi-container: <nil>
STEP: delete the pod
Apr 20 05:57:46.333: INFO: Waiting for pod downward-api-b55bdd82-8753-4aff-b4e8-3aa8d1cf9f0c to disappear
Apr 20 05:57:46.337: INFO: Pod downward-api-b55bdd82-8753-4aff-b4e8-3aa8d1cf9f0c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:57:46.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3173" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":346,"completed":49,"skipped":893,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:57:46.347: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr 20 05:57:46.384: INFO: Waiting up to 5m0s for pod "downwardapi-volume-94e63716-f48f-4b58-acf1-2914c8effd35" in namespace "downward-api-6690" to be "Succeeded or Failed"
Apr 20 05:57:46.386: INFO: Pod "downwardapi-volume-94e63716-f48f-4b58-acf1-2914c8effd35": Phase="Pending", Reason="", readiness=false. Elapsed: 1.587423ms
Apr 20 05:57:48.392: INFO: Pod "downwardapi-volume-94e63716-f48f-4b58-acf1-2914c8effd35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007220433s
STEP: Saw pod success
Apr 20 05:57:48.392: INFO: Pod "downwardapi-volume-94e63716-f48f-4b58-acf1-2914c8effd35" satisfied condition "Succeeded or Failed"
Apr 20 05:57:48.394: INFO: Trying to get logs from node node22-hwh1v pod downwardapi-volume-94e63716-f48f-4b58-acf1-2914c8effd35 container client-container: <nil>
STEP: delete the pod
Apr 20 05:57:48.407: INFO: Waiting for pod downwardapi-volume-94e63716-f48f-4b58-acf1-2914c8effd35 to disappear
Apr 20 05:57:48.409: INFO: Pod downwardapi-volume-94e63716-f48f-4b58-acf1-2914c8effd35 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:57:48.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6690" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":346,"completed":50,"skipped":915,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:57:48.417: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Creating a NodePort Service
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota
STEP: Ensuring resource quota status captures service creation
STEP: Deleting Services
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:57:59.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7816" for this suite.

• [SLOW TEST:11.198 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":346,"completed":51,"skipped":924,"failed":0}
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:57:59.615: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:58:27.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2445" for this suite.

• [SLOW TEST:28.086 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":346,"completed":52,"skipped":925,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery 
  should validate PreferredVersion for each APIGroup [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Discovery
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:58:27.703: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename discovery
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Discovery
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:39
STEP: Setting up server cert
[It] should validate PreferredVersion for each APIGroup [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 05:58:28.063: INFO: Checking APIGroup: apiregistration.k8s.io
Apr 20 05:58:28.064: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Apr 20 05:58:28.064: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Apr 20 05:58:28.064: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Apr 20 05:58:28.064: INFO: Checking APIGroup: apps
Apr 20 05:58:28.065: INFO: PreferredVersion.GroupVersion: apps/v1
Apr 20 05:58:28.065: INFO: Versions found [{apps/v1 v1}]
Apr 20 05:58:28.065: INFO: apps/v1 matches apps/v1
Apr 20 05:58:28.065: INFO: Checking APIGroup: events.k8s.io
Apr 20 05:58:28.066: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Apr 20 05:58:28.066: INFO: Versions found [{events.k8s.io/v1 v1} {events.k8s.io/v1beta1 v1beta1}]
Apr 20 05:58:28.066: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Apr 20 05:58:28.066: INFO: Checking APIGroup: authentication.k8s.io
Apr 20 05:58:28.066: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Apr 20 05:58:28.066: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Apr 20 05:58:28.066: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Apr 20 05:58:28.066: INFO: Checking APIGroup: authorization.k8s.io
Apr 20 05:58:28.067: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Apr 20 05:58:28.067: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Apr 20 05:58:28.067: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Apr 20 05:58:28.067: INFO: Checking APIGroup: autoscaling
Apr 20 05:58:28.068: INFO: PreferredVersion.GroupVersion: autoscaling/v1
Apr 20 05:58:28.068: INFO: Versions found [{autoscaling/v1 v1} {autoscaling/v2beta1 v2beta1} {autoscaling/v2beta2 v2beta2}]
Apr 20 05:58:28.068: INFO: autoscaling/v1 matches autoscaling/v1
Apr 20 05:58:28.068: INFO: Checking APIGroup: batch
Apr 20 05:58:28.068: INFO: PreferredVersion.GroupVersion: batch/v1
Apr 20 05:58:28.068: INFO: Versions found [{batch/v1 v1} {batch/v1beta1 v1beta1}]
Apr 20 05:58:28.068: INFO: batch/v1 matches batch/v1
Apr 20 05:58:28.068: INFO: Checking APIGroup: certificates.k8s.io
Apr 20 05:58:28.069: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Apr 20 05:58:28.069: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Apr 20 05:58:28.069: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Apr 20 05:58:28.069: INFO: Checking APIGroup: networking.k8s.io
Apr 20 05:58:28.070: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Apr 20 05:58:28.070: INFO: Versions found [{networking.k8s.io/v1 v1}]
Apr 20 05:58:28.070: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Apr 20 05:58:28.070: INFO: Checking APIGroup: policy
Apr 20 05:58:28.070: INFO: PreferredVersion.GroupVersion: policy/v1
Apr 20 05:58:28.070: INFO: Versions found [{policy/v1 v1} {policy/v1beta1 v1beta1}]
Apr 20 05:58:28.070: INFO: policy/v1 matches policy/v1
Apr 20 05:58:28.070: INFO: Checking APIGroup: rbac.authorization.k8s.io
Apr 20 05:58:28.071: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Apr 20 05:58:28.071: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Apr 20 05:58:28.071: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Apr 20 05:58:28.071: INFO: Checking APIGroup: storage.k8s.io
Apr 20 05:58:28.072: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Apr 20 05:58:28.072: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Apr 20 05:58:28.072: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Apr 20 05:58:28.072: INFO: Checking APIGroup: admissionregistration.k8s.io
Apr 20 05:58:28.072: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Apr 20 05:58:28.072: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Apr 20 05:58:28.072: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Apr 20 05:58:28.072: INFO: Checking APIGroup: apiextensions.k8s.io
Apr 20 05:58:28.073: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Apr 20 05:58:28.073: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Apr 20 05:58:28.073: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Apr 20 05:58:28.073: INFO: Checking APIGroup: scheduling.k8s.io
Apr 20 05:58:28.074: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Apr 20 05:58:28.074: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Apr 20 05:58:28.074: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Apr 20 05:58:28.074: INFO: Checking APIGroup: coordination.k8s.io
Apr 20 05:58:28.074: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Apr 20 05:58:28.074: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Apr 20 05:58:28.074: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Apr 20 05:58:28.074: INFO: Checking APIGroup: node.k8s.io
Apr 20 05:58:28.075: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Apr 20 05:58:28.075: INFO: Versions found [{node.k8s.io/v1 v1} {node.k8s.io/v1beta1 v1beta1}]
Apr 20 05:58:28.075: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Apr 20 05:58:28.075: INFO: Checking APIGroup: discovery.k8s.io
Apr 20 05:58:28.075: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Apr 20 05:58:28.075: INFO: Versions found [{discovery.k8s.io/v1 v1} {discovery.k8s.io/v1beta1 v1beta1}]
Apr 20 05:58:28.075: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Apr 20 05:58:28.075: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Apr 20 05:58:28.076: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta1
Apr 20 05:58:28.076: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Apr 20 05:58:28.076: INFO: flowcontrol.apiserver.k8s.io/v1beta1 matches flowcontrol.apiserver.k8s.io/v1beta1
Apr 20 05:58:28.076: INFO: Checking APIGroup: crd.projectcalico.org
Apr 20 05:58:28.076: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
Apr 20 05:58:28.076: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
Apr 20 05:58:28.076: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
[AfterEach] [sig-api-machinery] Discovery
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:58:28.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-5797" for this suite.
•{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","total":346,"completed":53,"skipped":939,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:58:28.086: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr 20 05:58:28.121: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5aefa861-3fb1-418c-bf2a-1f513dba6a6b" in namespace "projected-1909" to be "Succeeded or Failed"
Apr 20 05:58:28.123: INFO: Pod "downwardapi-volume-5aefa861-3fb1-418c-bf2a-1f513dba6a6b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.958601ms
Apr 20 05:58:30.127: INFO: Pod "downwardapi-volume-5aefa861-3fb1-418c-bf2a-1f513dba6a6b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006669253s
STEP: Saw pod success
Apr 20 05:58:30.128: INFO: Pod "downwardapi-volume-5aefa861-3fb1-418c-bf2a-1f513dba6a6b" satisfied condition "Succeeded or Failed"
Apr 20 05:58:30.129: INFO: Trying to get logs from node node22-wriki pod downwardapi-volume-5aefa861-3fb1-418c-bf2a-1f513dba6a6b container client-container: <nil>
STEP: delete the pod
Apr 20 05:58:30.145: INFO: Waiting for pod downwardapi-volume-5aefa861-3fb1-418c-bf2a-1f513dba6a6b to disappear
Apr 20 05:58:30.147: INFO: Pod downwardapi-volume-5aefa861-3fb1-418c-bf2a-1f513dba6a6b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:58:30.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1909" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":54,"skipped":948,"failed":0}
SSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:58:30.155: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Kubectl run pod
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1524
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-1
Apr 20 05:58:30.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-5254 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-1'
Apr 20 05:58:30.240: INFO: stderr: ""
Apr 20 05:58:30.240: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1528
Apr 20 05:58:30.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-5254 delete pods e2e-test-httpd-pod'
Apr 20 05:58:32.257: INFO: stderr: ""
Apr 20 05:58:32.257: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:58:32.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5254" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":346,"completed":55,"skipped":951,"failed":0}
SS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:58:32.274: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward api env vars
Apr 20 05:58:32.310: INFO: Waiting up to 5m0s for pod "downward-api-36cc4446-4a4c-462e-a264-a80b30b285bb" in namespace "downward-api-4188" to be "Succeeded or Failed"
Apr 20 05:58:32.312: INFO: Pod "downward-api-36cc4446-4a4c-462e-a264-a80b30b285bb": Phase="Pending", Reason="", readiness=false. Elapsed: 1.761449ms
Apr 20 05:58:34.317: INFO: Pod "downward-api-36cc4446-4a4c-462e-a264-a80b30b285bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006885602s
STEP: Saw pod success
Apr 20 05:58:34.317: INFO: Pod "downward-api-36cc4446-4a4c-462e-a264-a80b30b285bb" satisfied condition "Succeeded or Failed"
Apr 20 05:58:34.319: INFO: Trying to get logs from node node22-wriki pod downward-api-36cc4446-4a4c-462e-a264-a80b30b285bb container dapi-container: <nil>
STEP: delete the pod
Apr 20 05:58:34.334: INFO: Waiting for pod downward-api-36cc4446-4a4c-462e-a264-a80b30b285bb to disappear
Apr 20 05:58:34.336: INFO: Pod downward-api-36cc4446-4a4c-462e-a264-a80b30b285bb no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:58:34.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4188" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":346,"completed":56,"skipped":953,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:58:34.342: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap configmap-3019/configmap-test-168a2aa3-ab90-43b4-bc0c-7c795cb6e13f
STEP: Creating a pod to test consume configMaps
Apr 20 05:58:34.385: INFO: Waiting up to 5m0s for pod "pod-configmaps-762988f8-d18c-446b-ba2b-a6cffc18b0dc" in namespace "configmap-3019" to be "Succeeded or Failed"
Apr 20 05:58:34.388: INFO: Pod "pod-configmaps-762988f8-d18c-446b-ba2b-a6cffc18b0dc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.083563ms
Apr 20 05:58:36.391: INFO: Pod "pod-configmaps-762988f8-d18c-446b-ba2b-a6cffc18b0dc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006282712s
STEP: Saw pod success
Apr 20 05:58:36.391: INFO: Pod "pod-configmaps-762988f8-d18c-446b-ba2b-a6cffc18b0dc" satisfied condition "Succeeded or Failed"
Apr 20 05:58:36.393: INFO: Trying to get logs from node node22-wriki pod pod-configmaps-762988f8-d18c-446b-ba2b-a6cffc18b0dc container env-test: <nil>
STEP: delete the pod
Apr 20 05:58:36.412: INFO: Waiting for pod pod-configmaps-762988f8-d18c-446b-ba2b-a6cffc18b0dc to disappear
Apr 20 05:58:36.413: INFO: Pod pod-configmaps-762988f8-d18c-446b-ba2b-a6cffc18b0dc no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:58:36.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3019" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":346,"completed":57,"skipped":971,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:58:36.423: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod pod-subpath-test-downwardapi-2wzp
STEP: Creating a pod to test atomic-volume-subpath
Apr 20 05:58:36.483: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-2wzp" in namespace "subpath-8787" to be "Succeeded or Failed"
Apr 20 05:58:36.489: INFO: Pod "pod-subpath-test-downwardapi-2wzp": Phase="Pending", Reason="", readiness=false. Elapsed: 5.259744ms
Apr 20 05:58:38.497: INFO: Pod "pod-subpath-test-downwardapi-2wzp": Phase="Running", Reason="", readiness=true. Elapsed: 2.014035548s
Apr 20 05:58:40.503: INFO: Pod "pod-subpath-test-downwardapi-2wzp": Phase="Running", Reason="", readiness=true. Elapsed: 4.019932835s
Apr 20 05:58:42.509: INFO: Pod "pod-subpath-test-downwardapi-2wzp": Phase="Running", Reason="", readiness=true. Elapsed: 6.025585551s
Apr 20 05:58:44.515: INFO: Pod "pod-subpath-test-downwardapi-2wzp": Phase="Running", Reason="", readiness=true. Elapsed: 8.03141449s
Apr 20 05:58:46.518: INFO: Pod "pod-subpath-test-downwardapi-2wzp": Phase="Running", Reason="", readiness=true. Elapsed: 10.035185948s
Apr 20 05:58:48.524: INFO: Pod "pod-subpath-test-downwardapi-2wzp": Phase="Running", Reason="", readiness=true. Elapsed: 12.040699887s
Apr 20 05:58:50.529: INFO: Pod "pod-subpath-test-downwardapi-2wzp": Phase="Running", Reason="", readiness=true. Elapsed: 14.045960415s
Apr 20 05:58:52.535: INFO: Pod "pod-subpath-test-downwardapi-2wzp": Phase="Running", Reason="", readiness=true. Elapsed: 16.051615079s
Apr 20 05:58:54.541: INFO: Pod "pod-subpath-test-downwardapi-2wzp": Phase="Running", Reason="", readiness=true. Elapsed: 18.058101295s
Apr 20 05:58:56.545: INFO: Pod "pod-subpath-test-downwardapi-2wzp": Phase="Running", Reason="", readiness=true. Elapsed: 20.061286191s
Apr 20 05:58:58.551: INFO: Pod "pod-subpath-test-downwardapi-2wzp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.067452629s
STEP: Saw pod success
Apr 20 05:58:58.551: INFO: Pod "pod-subpath-test-downwardapi-2wzp" satisfied condition "Succeeded or Failed"
Apr 20 05:58:58.553: INFO: Trying to get logs from node node22-wriki pod pod-subpath-test-downwardapi-2wzp container test-container-subpath-downwardapi-2wzp: <nil>
STEP: delete the pod
Apr 20 05:58:58.570: INFO: Waiting for pod pod-subpath-test-downwardapi-2wzp to disappear
Apr 20 05:58:58.573: INFO: Pod pod-subpath-test-downwardapi-2wzp no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-2wzp
Apr 20 05:58:58.573: INFO: Deleting pod "pod-subpath-test-downwardapi-2wzp" in namespace "subpath-8787"
[AfterEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:58:58.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8787" for this suite.

• [SLOW TEST:22.160 seconds]
[sig-storage] Subpath
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [LinuxOnly] [Conformance]","total":346,"completed":58,"skipped":1026,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:58:58.586: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 05:58:58.631: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Apr 20 05:59:01.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-4485 --namespace=crd-publish-openapi-4485 create -f -'
Apr 20 05:59:01.687: INFO: stderr: ""
Apr 20 05:59:01.687: INFO: stdout: "e2e-test-crd-publish-openapi-1337-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr 20 05:59:01.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-4485 --namespace=crd-publish-openapi-4485 delete e2e-test-crd-publish-openapi-1337-crds test-cr'
Apr 20 05:59:01.777: INFO: stderr: ""
Apr 20 05:59:01.777: INFO: stdout: "e2e-test-crd-publish-openapi-1337-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Apr 20 05:59:01.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-4485 --namespace=crd-publish-openapi-4485 apply -f -'
Apr 20 05:59:01.935: INFO: stderr: ""
Apr 20 05:59:01.935: INFO: stdout: "e2e-test-crd-publish-openapi-1337-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr 20 05:59:01.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-4485 --namespace=crd-publish-openapi-4485 delete e2e-test-crd-publish-openapi-1337-crds test-cr'
Apr 20 05:59:01.988: INFO: stderr: ""
Apr 20 05:59:01.988: INFO: stdout: "e2e-test-crd-publish-openapi-1337-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Apr 20 05:59:01.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-4485 explain e2e-test-crd-publish-openapi-1337-crds'
Apr 20 05:59:02.125: INFO: stderr: ""
Apr 20 05:59:02.125: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1337-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:59:04.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4485" for this suite.

• [SLOW TEST:6.272 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":346,"completed":59,"skipped":1053,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:59:04.859: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test env composition
Apr 20 05:59:04.895: INFO: Waiting up to 5m0s for pod "var-expansion-d6700458-9c4a-4d18-b7f5-10bab93c7952" in namespace "var-expansion-6180" to be "Succeeded or Failed"
Apr 20 05:59:04.898: INFO: Pod "var-expansion-d6700458-9c4a-4d18-b7f5-10bab93c7952": Phase="Pending", Reason="", readiness=false. Elapsed: 2.395499ms
Apr 20 05:59:06.901: INFO: Pod "var-expansion-d6700458-9c4a-4d18-b7f5-10bab93c7952": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005749323s
STEP: Saw pod success
Apr 20 05:59:06.901: INFO: Pod "var-expansion-d6700458-9c4a-4d18-b7f5-10bab93c7952" satisfied condition "Succeeded or Failed"
Apr 20 05:59:06.903: INFO: Trying to get logs from node node22-wriki pod var-expansion-d6700458-9c4a-4d18-b7f5-10bab93c7952 container dapi-container: <nil>
STEP: delete the pod
Apr 20 05:59:06.919: INFO: Waiting for pod var-expansion-d6700458-9c4a-4d18-b7f5-10bab93c7952 to disappear
Apr 20 05:59:06.921: INFO: Pod var-expansion-d6700458-9c4a-4d18-b7f5-10bab93c7952 no longer exists
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:59:06.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6180" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":346,"completed":60,"skipped":1069,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:59:06.930: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service nodeport-test with type=NodePort in namespace services-5819
STEP: creating replication controller nodeport-test in namespace services-5819
I0420 05:59:06.988147      20 runners.go:190] Created replication controller with name: nodeport-test, namespace: services-5819, replica count: 2
I0420 05:59:10.039576      20 runners.go:190] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 20 05:59:10.039: INFO: Creating new exec pod
Apr 20 05:59:13.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-5819 exec execpodkqzx9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Apr 20 05:59:13.192: INFO: stderr: "+ nc -v -t -w 2 nodeport-test 80\n+ echo hostName\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Apr 20 05:59:13.192: INFO: stdout: "nodeport-test-gxhnq"
Apr 20 05:59:13.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-5819 exec execpodkqzx9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.103.168.75 80'
Apr 20 05:59:13.291: INFO: stderr: "+ nc -v -t -w 2 10.103.168.75 80\n+ echo hostName\nConnection to 10.103.168.75 80 port [tcp/http] succeeded!\n"
Apr 20 05:59:13.291: INFO: stdout: "nodeport-test-5w8ll"
Apr 20 05:59:13.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-5819 exec execpodkqzx9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.125.144 31483'
Apr 20 05:59:13.412: INFO: stderr: "+ nc -v -t -w 2 10.100.125.144 31483\n+ echo hostName\nConnection to 10.100.125.144 31483 port [tcp/*] succeeded!\n"
Apr 20 05:59:13.412: INFO: stdout: "nodeport-test-gxhnq"
Apr 20 05:59:13.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-5819 exec execpodkqzx9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.99.219 31483'
Apr 20 05:59:13.534: INFO: stderr: "+ nc -v -t -w 2 10.100.99.219 31483\n+ echo hostName\nConnection to 10.100.99.219 31483 port [tcp/*] succeeded!\n"
Apr 20 05:59:13.534: INFO: stdout: ""
Apr 20 05:59:14.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-5819 exec execpodkqzx9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.99.219 31483'
Apr 20 05:59:14.653: INFO: stderr: "+ nc -v -t -w 2 10.100.99.219 31483\n+ echo hostName\nConnection to 10.100.99.219 31483 port [tcp/*] succeeded!\n"
Apr 20 05:59:14.653: INFO: stdout: "nodeport-test-gxhnq"
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 05:59:14.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5819" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:7.742 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":346,"completed":61,"skipped":1110,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 05:59:14.675: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:54
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod busybox-ee22c224-ad01-4667-971d-7497f738f549 in namespace container-probe-8714
Apr 20 05:59:16.773: INFO: Started pod busybox-ee22c224-ad01-4667-971d-7497f738f549 in namespace container-probe-8714
STEP: checking the pod's current state and verifying that restartCount is present
Apr 20 05:59:16.775: INFO: Initial restart count of pod busybox-ee22c224-ad01-4667-971d-7497f738f549 is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:03:17.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8714" for this suite.

• [SLOW TEST:242.798 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":346,"completed":62,"skipped":1206,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] HostPort 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] HostPort
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:03:17.474: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename hostport
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] HostPort
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/hostport.go:47
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled
Apr 20 06:03:17.524: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:03:19.532: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.100.125.144 on the node which pod1 resides and expect scheduled
Apr 20 06:03:19.541: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:03:21.544: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.100.125.144 but use UDP protocol on the node which pod2 resides
Apr 20 06:03:21.555: INFO: The status of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:03:23.563: INFO: The status of Pod pod3 is Running (Ready = true)
Apr 20 06:03:23.570: INFO: The status of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:03:25.577: INFO: The status of Pod e2e-host-exec is Running (Ready = true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323
Apr 20 06:03:25.579: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.100.125.144 http://127.0.0.1:54323/hostname] Namespace:hostport-8166 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 06:03:25.579: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.100.125.144, port: 54323
Apr 20 06:03:25.682: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.100.125.144:54323/hostname] Namespace:hostport-8166 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 06:03:25.682: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.100.125.144, port: 54323 UDP
Apr 20 06:03:25.750: INFO: ExecWithOptions {Command:[/bin/sh -c nc -vuz -w 5 10.100.125.144 54323] Namespace:hostport-8166 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 06:03:25.750: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
[AfterEach] [sig-network] HostPort
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:03:30.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-8166" for this suite.

• [SLOW TEST:13.351 seconds]
[sig-network] HostPort
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","total":346,"completed":63,"skipped":1252,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Events
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:03:30.826: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Apr 20 06:03:32.880: INFO: &Pod{ObjectMeta:{send-events-e7967abd-6588-4c9d-98fd-51b8f6180c7c  events-9298  4beb86b2-f4b8-4e85-b269-481105abc4e5 8752 0 2022-04-20 06:03:30 +0000 UTC <nil> <nil> map[name:foo time:862117248] map[cni.projectcalico.org/podIP:10.233.2.41/32 cni.projectcalico.org/podIPs:10.233.2.41/32] [] []  [{e2e.test Update v1 2022-04-20 06:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:time":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"p\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":80,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-04-20 06:03:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-04-20 06:03:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.2.41\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fpjm5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:p,Image:k8s.gcr.io/e2e-test-images/agnhost:2.32,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fpjm5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-wriki,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:03:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:03:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:03:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:03:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.99.219,PodIP:10.233.2.41,StartTime:2022-04-20 06:03:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-20 06:03:31 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.32,ImageID:k8s.gcr.io/e2e-test-images/agnhost@sha256:758db666ac7028534dba72e7e9bb1e57bb81b8196f976f7a5cc351ef8b3529e1,ContainerID:containerd://630799e6c3f8ec7d7761d4bd37343ed04e96a02a9146ed0d441a395509243686,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.2.41,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Apr 20 06:03:34.889: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Apr 20 06:03:36.892: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [sig-node] Events
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:03:36.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-9298" for this suite.

• [SLOW TEST:6.082 seconds]
[sig-node] Events
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/framework.go:23
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]","total":346,"completed":64,"skipped":1291,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:03:36.910: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating the pod
Apr 20 06:03:36.965: INFO: The status of Pod labelsupdatef0d18800-b76e-430a-b2e9-cce9123e9fb5 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:03:38.971: INFO: The status of Pod labelsupdatef0d18800-b76e-430a-b2e9-cce9123e9fb5 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:03:40.972: INFO: The status of Pod labelsupdatef0d18800-b76e-430a-b2e9-cce9123e9fb5 is Running (Ready = true)
Apr 20 06:03:41.507: INFO: Successfully updated pod "labelsupdatef0d18800-b76e-430a-b2e9-cce9123e9fb5"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:03:43.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2402" for this suite.

• [SLOW TEST:6.622 seconds]
[sig-storage] Projected downwardAPI
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":346,"completed":65,"skipped":1334,"failed":0}
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:03:43.533: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should add annotations for pods in rc  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating Agnhost RC
Apr 20 06:03:43.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-2492 create -f -'
Apr 20 06:03:43.728: INFO: stderr: ""
Apr 20 06:03:43.728: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Apr 20 06:03:44.734: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 20 06:03:44.734: INFO: Found 0 / 1
Apr 20 06:03:45.734: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 20 06:03:45.734: INFO: Found 1 / 1
Apr 20 06:03:45.734: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Apr 20 06:03:45.736: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 20 06:03:45.736: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 20 06:03:45.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-2492 patch pod agnhost-primary-cv6gw -p {"metadata":{"annotations":{"x":"y"}}}'
Apr 20 06:03:45.790: INFO: stderr: ""
Apr 20 06:03:45.790: INFO: stdout: "pod/agnhost-primary-cv6gw patched\n"
STEP: checking annotations
Apr 20 06:03:45.793: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 20 06:03:45.793: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:03:45.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2492" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":346,"completed":66,"skipped":1340,"failed":0}
SSSS
------------------------------
[sig-apps] CronJob 
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:03:45.799: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a ForbidConcurrent cronjob
STEP: Ensuring a job is scheduled
STEP: Ensuring exactly one is scheduled
STEP: Ensuring exactly one running job exists by listing jobs explicitly
STEP: Ensuring no more jobs are scheduled
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:09:01.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-2864" for this suite.

• [SLOW TEST:316.095 seconds]
[sig-apps] CronJob
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","total":346,"completed":67,"skipped":1344,"failed":0}
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:09:01.897: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:09:19.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6694" for this suite.

• [SLOW TEST:17.186 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":346,"completed":68,"skipped":1348,"failed":0}
SSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:09:19.084: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:82
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:09:19.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1499" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":346,"completed":69,"skipped":1354,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should validate Statefulset Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:09:19.140: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:92
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:107
STEP: Creating service test in namespace statefulset-7306
[It] should validate Statefulset Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating statefulset ss in namespace statefulset-7306
Apr 20 06:09:19.196: INFO: Found 0 stateful pods, waiting for 1
Apr 20 06:09:29.204: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label
STEP: Getting /status
Apr 20 06:09:29.226: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status
Apr 20 06:09:29.232: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated
Apr 20 06:09:29.237: INFO: Observed &StatefulSet event: ADDED
Apr 20 06:09:29.237: INFO: Found Statefulset ss in namespace statefulset-7306 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 20 06:09:29.237: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status
Apr 20 06:09:29.237: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Apr 20 06:09:29.246: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched
Apr 20 06:09:29.247: INFO: Observed &StatefulSet event: ADDED
Apr 20 06:09:29.247: INFO: Observed Statefulset ss in namespace statefulset-7306 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 20 06:09:29.247: INFO: Observed &StatefulSet event: MODIFIED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:118
Apr 20 06:09:29.247: INFO: Deleting all statefulset in ns statefulset-7306
Apr 20 06:09:29.249: INFO: Scaling statefulset ss to 0
Apr 20 06:09:39.267: INFO: Waiting for statefulset status.replicas updated to 0
Apr 20 06:09:39.269: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:09:39.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7306" for this suite.

• [SLOW TEST:20.149 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:97
    should validate Statefulset Status endpoints [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","total":346,"completed":70,"skipped":1366,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:09:39.290: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Apr 20 06:09:39.979: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 20 06:09:43.002: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:09:43.006: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:09:46.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-5330" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:7.803 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":346,"completed":71,"skipped":1396,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:09:47.095: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:54
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:09:47.248: INFO: The status of Pod test-webserver-dca8fa5b-a37e-48a0-8f9a-d78169b2dc32 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:09:49.254: INFO: The status of Pod test-webserver-dca8fa5b-a37e-48a0-8f9a-d78169b2dc32 is Running (Ready = false)
Apr 20 06:09:51.257: INFO: The status of Pod test-webserver-dca8fa5b-a37e-48a0-8f9a-d78169b2dc32 is Running (Ready = false)
Apr 20 06:09:53.254: INFO: The status of Pod test-webserver-dca8fa5b-a37e-48a0-8f9a-d78169b2dc32 is Running (Ready = false)
Apr 20 06:09:55.255: INFO: The status of Pod test-webserver-dca8fa5b-a37e-48a0-8f9a-d78169b2dc32 is Running (Ready = false)
Apr 20 06:09:57.252: INFO: The status of Pod test-webserver-dca8fa5b-a37e-48a0-8f9a-d78169b2dc32 is Running (Ready = false)
Apr 20 06:09:59.253: INFO: The status of Pod test-webserver-dca8fa5b-a37e-48a0-8f9a-d78169b2dc32 is Running (Ready = false)
Apr 20 06:10:01.254: INFO: The status of Pod test-webserver-dca8fa5b-a37e-48a0-8f9a-d78169b2dc32 is Running (Ready = false)
Apr 20 06:10:03.256: INFO: The status of Pod test-webserver-dca8fa5b-a37e-48a0-8f9a-d78169b2dc32 is Running (Ready = false)
Apr 20 06:10:05.255: INFO: The status of Pod test-webserver-dca8fa5b-a37e-48a0-8f9a-d78169b2dc32 is Running (Ready = false)
Apr 20 06:10:07.253: INFO: The status of Pod test-webserver-dca8fa5b-a37e-48a0-8f9a-d78169b2dc32 is Running (Ready = false)
Apr 20 06:10:09.251: INFO: The status of Pod test-webserver-dca8fa5b-a37e-48a0-8f9a-d78169b2dc32 is Running (Ready = true)
Apr 20 06:10:09.253: INFO: Container started at 2022-04-20 06:09:48 +0000 UTC, pod became ready at 2022-04-20 06:10:07 +0000 UTC
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:10:09.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1826" for this suite.

• [SLOW TEST:22.165 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":346,"completed":72,"skipped":1411,"failed":0}
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:10:09.262: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create and stop a working application  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating all guestbook components
Apr 20 06:10:09.299: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Apr 20 06:10:09.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-6380 create -f -'
Apr 20 06:10:09.538: INFO: stderr: ""
Apr 20 06:10:09.538: INFO: stdout: "service/agnhost-replica created\n"
Apr 20 06:10:09.538: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Apr 20 06:10:09.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-6380 create -f -'
Apr 20 06:10:09.694: INFO: stderr: ""
Apr 20 06:10:09.694: INFO: stdout: "service/agnhost-primary created\n"
Apr 20 06:10:09.695: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr 20 06:10:09.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-6380 create -f -'
Apr 20 06:10:09.863: INFO: stderr: ""
Apr 20 06:10:09.863: INFO: stdout: "service/frontend created\n"
Apr 20 06:10:09.863: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: k8s.gcr.io/e2e-test-images/agnhost:2.32
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Apr 20 06:10:09.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-6380 create -f -'
Apr 20 06:10:09.995: INFO: stderr: ""
Apr 20 06:10:09.995: INFO: stdout: "deployment.apps/frontend created\n"
Apr 20 06:10:09.995: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: k8s.gcr.io/e2e-test-images/agnhost:2.32
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 20 06:10:09.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-6380 create -f -'
Apr 20 06:10:10.157: INFO: stderr: ""
Apr 20 06:10:10.157: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Apr 20 06:10:10.157: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: k8s.gcr.io/e2e-test-images/agnhost:2.32
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 20 06:10:10.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-6380 create -f -'
Apr 20 06:10:10.293: INFO: stderr: ""
Apr 20 06:10:10.293: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app
Apr 20 06:10:10.293: INFO: Waiting for all frontend pods to be Running.
Apr 20 06:10:15.345: INFO: Waiting for frontend to serve content.
Apr 20 06:10:15.357: INFO: Trying to add a new entry to the guestbook.
Apr 20 06:10:15.368: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Apr 20 06:10:15.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-6380 delete --grace-period=0 --force -f -'
Apr 20 06:10:15.447: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 20 06:10:15.447: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources
Apr 20 06:10:15.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-6380 delete --grace-period=0 --force -f -'
Apr 20 06:10:15.531: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 20 06:10:15.531: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources
Apr 20 06:10:15.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-6380 delete --grace-period=0 --force -f -'
Apr 20 06:10:15.598: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 20 06:10:15.598: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 20 06:10:15.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-6380 delete --grace-period=0 --force -f -'
Apr 20 06:10:15.649: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 20 06:10:15.649: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 20 06:10:15.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-6380 delete --grace-period=0 --force -f -'
Apr 20 06:10:15.744: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 20 06:10:15.744: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources
Apr 20 06:10:15.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-6380 delete --grace-period=0 --force -f -'
Apr 20 06:10:15.868: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 20 06:10:15.868: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:10:15.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6380" for this suite.

• [SLOW TEST:6.616 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:339
    should create and stop a working application  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":346,"completed":73,"skipped":1421,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:10:15.878: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:54
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:11:15.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2282" for this suite.

• [SLOW TEST:60.052 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":346,"completed":74,"skipped":1450,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:11:15.933: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service multi-endpoint-test in namespace services-4425
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4425 to expose endpoints map[]
Apr 20 06:11:15.991: INFO: successfully validated that service multi-endpoint-test in namespace services-4425 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-4425
Apr 20 06:11:16.002: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:11:18.006: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4425 to expose endpoints map[pod1:[100]]
Apr 20 06:11:18.013: INFO: successfully validated that service multi-endpoint-test in namespace services-4425 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-4425
Apr 20 06:11:18.020: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:11:20.026: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4425 to expose endpoints map[pod1:[100] pod2:[101]]
Apr 20 06:11:20.036: INFO: successfully validated that service multi-endpoint-test in namespace services-4425 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods
Apr 20 06:11:20.036: INFO: Creating new exec pod
Apr 20 06:11:23.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-4425 exec execpod8294d -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Apr 20 06:11:23.179: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 80\n+ echo hostName\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Apr 20 06:11:23.179: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 20 06:11:23.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-4425 exec execpod8294d -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.101.202.8 80'
Apr 20 06:11:23.288: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.101.202.8 80\nConnection to 10.101.202.8 80 port [tcp/http] succeeded!\n"
Apr 20 06:11:23.288: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 20 06:11:23.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-4425 exec execpod8294d -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Apr 20 06:11:23.422: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Apr 20 06:11:23.422: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 20 06:11:23.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-4425 exec execpod8294d -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.101.202.8 81'
Apr 20 06:11:23.537: INFO: stderr: "+ nc -v -t -w 2 10.101.202.8 81\n+ echo hostName\nConnection to 10.101.202.8 81 port [tcp/*] succeeded!\n"
Apr 20 06:11:23.537: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-4425
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4425 to expose endpoints map[pod2:[101]]
Apr 20 06:11:23.566: INFO: successfully validated that service multi-endpoint-test in namespace services-4425 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-4425
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4425 to expose endpoints map[]
Apr 20 06:11:23.590: INFO: successfully validated that service multi-endpoint-test in namespace services-4425 exposes endpoints map[]
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:11:23.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4425" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:7.684 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":346,"completed":75,"skipped":1479,"failed":0}
SSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] 
  validates lower priority pod preemption by critical pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:11:23.617: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:90
Apr 20 06:11:23.659: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 20 06:12:23.695: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create pods that use 4/5 of node resources.
Apr 20 06:12:23.715: INFO: Created pod: pod0-0-sched-preemption-low-priority
Apr 20 06:12:23.720: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Apr 20 06:12:23.733: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Apr 20 06:12:23.742: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Apr 20 06:12:23.759: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Apr 20 06:12:23.780: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled.
STEP: Run a critical pod that use same resources as that of a lower priority pod
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:12:41.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-3004" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:78

• [SLOW TEST:78.276 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","total":346,"completed":76,"skipped":1483,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:12:41.896: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:52
STEP: create the container to handle the HTTPGet hook request.
Apr 20 06:12:41.965: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:12:43.971: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the pod with lifecycle hook
Apr 20 06:12:43.985: INFO: The status of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:12:45.992: INFO: The status of Pod pod-with-poststart-exec-hook is Running (Ready = true)
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 20 06:12:46.016: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 20 06:12:46.019: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 20 06:12:48.020: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 20 06:12:48.025: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 20 06:12:50.020: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 20 06:12:50.026: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:12:50.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9351" for this suite.

• [SLOW TEST:8.139 seconds]
[sig-node] Container Lifecycle Hook
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:43
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":346,"completed":77,"skipped":1526,"failed":0}
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] version v1
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:12:50.036: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-8wmk7 in namespace proxy-1608
I0420 06:12:50.114069      20 runners.go:190] Created replication controller with name: proxy-service-8wmk7, namespace: proxy-1608, replica count: 1
I0420 06:12:51.164826      20 runners.go:190] proxy-service-8wmk7 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0420 06:12:52.165645      20 runners.go:190] proxy-service-8wmk7 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 20 06:12:52.168: INFO: setup took 2.100980798s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Apr 20 06:12:52.200: INFO: (0) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">... (200; 31.346286ms)
Apr 20 06:12:52.206: INFO: (0) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/rewriteme">test</a> (200; 37.273013ms)
Apr 20 06:12:52.206: INFO: (0) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 37.550999ms)
Apr 20 06:12:52.213: INFO: (0) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname2/proxy/: bar (200; 43.708153ms)
Apr 20 06:12:52.213: INFO: (0) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 43.843788ms)
Apr 20 06:12:52.213: INFO: (0) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 43.790697ms)
Apr 20 06:12:52.213: INFO: (0) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 44.340197ms)
Apr 20 06:12:52.215: INFO: (0) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname1/proxy/: tls baz (200; 46.62559ms)
Apr 20 06:12:52.215: INFO: (0) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname1/proxy/: foo (200; 46.762619ms)
Apr 20 06:12:52.215: INFO: (0) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:462/proxy/: tls qux (200; 46.886923ms)
Apr 20 06:12:52.216: INFO: (0) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname2/proxy/: bar (200; 46.867525ms)
Apr 20 06:12:52.216: INFO: (0) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname2/proxy/: tls qux (200; 46.999794ms)
Apr 20 06:12:52.216: INFO: (0) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname1/proxy/: foo (200; 47.020192ms)
Apr 20 06:12:52.216: INFO: (0) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/tlsrewritem... (200; 47.275272ms)
Apr 20 06:12:52.216: INFO: (0) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:460/proxy/: tls baz (200; 47.287044ms)
Apr 20 06:12:52.216: INFO: (0) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">test<... (200; 47.126143ms)
Apr 20 06:12:52.233: INFO: (1) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 16.840224ms)
Apr 20 06:12:52.233: INFO: (1) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/rewriteme">test</a> (200; 16.570837ms)
Apr 20 06:12:52.233: INFO: (1) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">... (200; 17.0931ms)
Apr 20 06:12:52.233: INFO: (1) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">test<... (200; 17.387851ms)
Apr 20 06:12:52.239: INFO: (1) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 22.445828ms)
Apr 20 06:12:52.239: INFO: (1) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/tlsrewritem... (200; 22.474709ms)
Apr 20 06:12:52.239: INFO: (1) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname2/proxy/: bar (200; 22.341899ms)
Apr 20 06:12:52.239: INFO: (1) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 22.804507ms)
Apr 20 06:12:52.239: INFO: (1) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:460/proxy/: tls baz (200; 22.510928ms)
Apr 20 06:12:52.239: INFO: (1) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname1/proxy/: tls baz (200; 23.056336ms)
Apr 20 06:12:52.239: INFO: (1) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname2/proxy/: tls qux (200; 23.247499ms)
Apr 20 06:12:52.239: INFO: (1) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:462/proxy/: tls qux (200; 22.849188ms)
Apr 20 06:12:52.241: INFO: (1) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname1/proxy/: foo (200; 24.386155ms)
Apr 20 06:12:52.241: INFO: (1) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname1/proxy/: foo (200; 24.900174ms)
Apr 20 06:12:52.241: INFO: (1) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 24.692875ms)
Apr 20 06:12:52.243: INFO: (1) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname2/proxy/: bar (200; 26.187036ms)
Apr 20 06:12:52.253: INFO: (2) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:460/proxy/: tls baz (200; 9.967379ms)
Apr 20 06:12:52.259: INFO: (2) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">test<... (200; 16.196357ms)
Apr 20 06:12:52.260: INFO: (2) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 16.479678ms)
Apr 20 06:12:52.260: INFO: (2) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname2/proxy/: bar (200; 16.986281ms)
Apr 20 06:12:52.260: INFO: (2) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">... (200; 16.561186ms)
Apr 20 06:12:52.260: INFO: (2) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/rewriteme">test</a> (200; 16.928506ms)
Apr 20 06:12:52.260: INFO: (2) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname1/proxy/: foo (200; 16.876283ms)
Apr 20 06:12:52.260: INFO: (2) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:462/proxy/: tls qux (200; 17.095023ms)
Apr 20 06:12:52.260: INFO: (2) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/tlsrewritem... (200; 16.985915ms)
Apr 20 06:12:52.261: INFO: (2) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname2/proxy/: tls qux (200; 17.723509ms)
Apr 20 06:12:52.261: INFO: (2) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 17.240805ms)
Apr 20 06:12:52.262: INFO: (2) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname2/proxy/: bar (200; 19.157404ms)
Apr 20 06:12:52.262: INFO: (2) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname1/proxy/: tls baz (200; 18.88236ms)
Apr 20 06:12:52.263: INFO: (2) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 19.470446ms)
Apr 20 06:12:52.263: INFO: (2) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 19.555601ms)
Apr 20 06:12:52.264: INFO: (2) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname1/proxy/: foo (200; 20.241059ms)
Apr 20 06:12:52.275: INFO: (3) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:462/proxy/: tls qux (200; 10.885249ms)
Apr 20 06:12:52.275: INFO: (3) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 11.431499ms)
Apr 20 06:12:52.280: INFO: (3) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">... (200; 16.026757ms)
Apr 20 06:12:52.281: INFO: (3) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname1/proxy/: foo (200; 16.822237ms)
Apr 20 06:12:52.281: INFO: (3) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/rewriteme">test</a> (200; 16.669517ms)
Apr 20 06:12:52.281: INFO: (3) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">test<... (200; 16.704484ms)
Apr 20 06:12:52.284: INFO: (3) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 19.562653ms)
Apr 20 06:12:52.284: INFO: (3) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 19.455958ms)
Apr 20 06:12:52.284: INFO: (3) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 19.779274ms)
Apr 20 06:12:52.284: INFO: (3) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/tlsrewritem... (200; 19.75455ms)
Apr 20 06:12:52.284: INFO: (3) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname1/proxy/: tls baz (200; 19.95833ms)
Apr 20 06:12:52.284: INFO: (3) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:460/proxy/: tls baz (200; 19.806461ms)
Apr 20 06:12:52.285: INFO: (3) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname2/proxy/: tls qux (200; 20.712326ms)
Apr 20 06:12:52.285: INFO: (3) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname1/proxy/: foo (200; 20.700162ms)
Apr 20 06:12:52.285: INFO: (3) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname2/proxy/: bar (200; 21.397365ms)
Apr 20 06:12:52.286: INFO: (3) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname2/proxy/: bar (200; 21.594673ms)
Apr 20 06:12:52.298: INFO: (4) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:460/proxy/: tls baz (200; 12.058242ms)
Apr 20 06:12:52.299: INFO: (4) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/tlsrewritem... (200; 12.41289ms)
Apr 20 06:12:52.304: INFO: (4) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">... (200; 17.809556ms)
Apr 20 06:12:52.304: INFO: (4) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname1/proxy/: tls baz (200; 18.126216ms)
Apr 20 06:12:52.304: INFO: (4) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 18.127364ms)
Apr 20 06:12:52.304: INFO: (4) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname1/proxy/: foo (200; 18.437113ms)
Apr 20 06:12:52.305: INFO: (4) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:462/proxy/: tls qux (200; 18.555719ms)
Apr 20 06:12:52.305: INFO: (4) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 18.772332ms)
Apr 20 06:12:52.305: INFO: (4) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 18.961643ms)
Apr 20 06:12:52.305: INFO: (4) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">test<... (200; 18.535645ms)
Apr 20 06:12:52.305: INFO: (4) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/rewriteme">test</a> (200; 19.027681ms)
Apr 20 06:12:52.307: INFO: (4) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 21.311934ms)
Apr 20 06:12:52.308: INFO: (4) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname2/proxy/: tls qux (200; 21.727085ms)
Apr 20 06:12:52.308: INFO: (4) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname2/proxy/: bar (200; 22.214566ms)
Apr 20 06:12:52.309: INFO: (4) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname2/proxy/: bar (200; 22.471696ms)
Apr 20 06:12:52.316: INFO: (4) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname1/proxy/: foo (200; 29.359425ms)
Apr 20 06:12:52.327: INFO: (5) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/tlsrewritem... (200; 10.572766ms)
Apr 20 06:12:52.327: INFO: (5) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:462/proxy/: tls qux (200; 10.421405ms)
Apr 20 06:12:52.333: INFO: (5) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 16.322625ms)
Apr 20 06:12:52.333: INFO: (5) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname2/proxy/: bar (200; 16.782155ms)
Apr 20 06:12:52.333: INFO: (5) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 17.017647ms)
Apr 20 06:12:52.333: INFO: (5) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">... (200; 16.455103ms)
Apr 20 06:12:52.333: INFO: (5) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname2/proxy/: tls qux (200; 17.261374ms)
Apr 20 06:12:52.334: INFO: (5) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 16.841792ms)
Apr 20 06:12:52.334: INFO: (5) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:460/proxy/: tls baz (200; 17.066839ms)
Apr 20 06:12:52.336: INFO: (5) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">test<... (200; 19.680238ms)
Apr 20 06:12:52.337: INFO: (5) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/rewriteme">test</a> (200; 20.22282ms)
Apr 20 06:12:52.337: INFO: (5) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname1/proxy/: foo (200; 20.674834ms)
Apr 20 06:12:52.338: INFO: (5) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname2/proxy/: bar (200; 21.192282ms)
Apr 20 06:12:52.338: INFO: (5) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 21.106217ms)
Apr 20 06:12:52.338: INFO: (5) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname1/proxy/: tls baz (200; 21.455975ms)
Apr 20 06:12:52.338: INFO: (5) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname1/proxy/: foo (200; 21.791984ms)
Apr 20 06:12:52.350: INFO: (6) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 11.357429ms)
Apr 20 06:12:52.350: INFO: (6) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">... (200; 11.591392ms)
Apr 20 06:12:52.354: INFO: (6) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/rewriteme">test</a> (200; 15.18507ms)
Apr 20 06:12:52.357: INFO: (6) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/tlsrewritem... (200; 18.602751ms)
Apr 20 06:12:52.358: INFO: (6) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 19.063378ms)
Apr 20 06:12:52.358: INFO: (6) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname1/proxy/: tls baz (200; 18.940417ms)
Apr 20 06:12:52.358: INFO: (6) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname2/proxy/: bar (200; 19.402582ms)
Apr 20 06:12:52.358: INFO: (6) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname2/proxy/: tls qux (200; 19.554806ms)
Apr 20 06:12:52.358: INFO: (6) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:460/proxy/: tls baz (200; 19.379329ms)
Apr 20 06:12:52.358: INFO: (6) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 19.278682ms)
Apr 20 06:12:52.358: INFO: (6) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:462/proxy/: tls qux (200; 19.404805ms)
Apr 20 06:12:52.358: INFO: (6) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 19.325537ms)
Apr 20 06:12:52.359: INFO: (6) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">test<... (200; 20.682903ms)
Apr 20 06:12:52.363: INFO: (6) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname2/proxy/: bar (200; 24.495773ms)
Apr 20 06:12:52.363: INFO: (6) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname1/proxy/: foo (200; 24.593106ms)
Apr 20 06:12:52.363: INFO: (6) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname1/proxy/: foo (200; 24.350078ms)
Apr 20 06:12:52.379: INFO: (7) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 15.981842ms)
Apr 20 06:12:52.379: INFO: (7) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 15.932395ms)
Apr 20 06:12:52.381: INFO: (7) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/rewriteme">test</a> (200; 17.946071ms)
Apr 20 06:12:52.382: INFO: (7) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">... (200; 18.338978ms)
Apr 20 06:12:52.382: INFO: (7) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:460/proxy/: tls baz (200; 18.623447ms)
Apr 20 06:12:52.382: INFO: (7) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 18.726675ms)
Apr 20 06:12:52.383: INFO: (7) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname1/proxy/: foo (200; 19.104148ms)
Apr 20 06:12:52.383: INFO: (7) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">test<... (200; 19.203152ms)
Apr 20 06:12:52.383: INFO: (7) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:462/proxy/: tls qux (200; 19.539192ms)
Apr 20 06:12:52.383: INFO: (7) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname1/proxy/: tls baz (200; 19.466771ms)
Apr 20 06:12:52.383: INFO: (7) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/tlsrewritem... (200; 19.685626ms)
Apr 20 06:12:52.383: INFO: (7) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname2/proxy/: bar (200; 19.91684ms)
Apr 20 06:12:52.383: INFO: (7) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 19.904155ms)
Apr 20 06:12:52.383: INFO: (7) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname2/proxy/: tls qux (200; 19.977297ms)
Apr 20 06:12:52.384: INFO: (7) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname2/proxy/: bar (200; 20.307418ms)
Apr 20 06:12:52.384: INFO: (7) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname1/proxy/: foo (200; 20.6349ms)
Apr 20 06:12:52.399: INFO: (8) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname2/proxy/: tls qux (200; 14.841243ms)
Apr 20 06:12:52.399: INFO: (8) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/tlsrewritem... (200; 14.654533ms)
Apr 20 06:12:52.405: INFO: (8) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:462/proxy/: tls qux (200; 20.963444ms)
Apr 20 06:12:52.405: INFO: (8) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 21.227805ms)
Apr 20 06:12:52.406: INFO: (8) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">test<... (200; 21.285042ms)
Apr 20 06:12:52.406: INFO: (8) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/rewriteme">test</a> (200; 21.593486ms)
Apr 20 06:12:52.406: INFO: (8) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 21.720882ms)
Apr 20 06:12:52.406: INFO: (8) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 21.701486ms)
Apr 20 06:12:52.406: INFO: (8) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 21.79055ms)
Apr 20 06:12:52.406: INFO: (8) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:460/proxy/: tls baz (200; 22.083152ms)
Apr 20 06:12:52.407: INFO: (8) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">... (200; 22.157953ms)
Apr 20 06:12:52.408: INFO: (8) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname1/proxy/: foo (200; 23.371967ms)
Apr 20 06:12:52.408: INFO: (8) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname2/proxy/: bar (200; 23.402286ms)
Apr 20 06:12:52.408: INFO: (8) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname1/proxy/: foo (200; 23.400917ms)
Apr 20 06:12:52.408: INFO: (8) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname1/proxy/: tls baz (200; 23.686899ms)
Apr 20 06:12:52.408: INFO: (8) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname2/proxy/: bar (200; 23.916384ms)
Apr 20 06:12:52.423: INFO: (9) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 14.006961ms)
Apr 20 06:12:52.423: INFO: (9) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/tlsrewritem... (200; 13.949693ms)
Apr 20 06:12:52.423: INFO: (9) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 13.901727ms)
Apr 20 06:12:52.423: INFO: (9) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:462/proxy/: tls qux (200; 13.73743ms)
Apr 20 06:12:52.423: INFO: (9) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname2/proxy/: tls qux (200; 15.063864ms)
Apr 20 06:12:52.426: INFO: (9) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 16.8069ms)
Apr 20 06:12:52.426: INFO: (9) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">... (200; 17.03061ms)
Apr 20 06:12:52.426: INFO: (9) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">test<... (200; 17.51347ms)
Apr 20 06:12:52.427: INFO: (9) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname1/proxy/: foo (200; 17.863379ms)
Apr 20 06:12:52.427: INFO: (9) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 18.56405ms)
Apr 20 06:12:52.427: INFO: (9) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname1/proxy/: tls baz (200; 18.848208ms)
Apr 20 06:12:52.427: INFO: (9) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:460/proxy/: tls baz (200; 18.201713ms)
Apr 20 06:12:52.428: INFO: (9) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/rewriteme">test</a> (200; 19.794056ms)
Apr 20 06:12:52.428: INFO: (9) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname2/proxy/: bar (200; 19.188498ms)
Apr 20 06:12:52.429: INFO: (9) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname1/proxy/: foo (200; 19.864003ms)
Apr 20 06:12:52.429: INFO: (9) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname2/proxy/: bar (200; 19.543175ms)
Apr 20 06:12:52.438: INFO: (10) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:460/proxy/: tls baz (200; 8.786317ms)
Apr 20 06:12:52.438: INFO: (10) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 9.421872ms)
Apr 20 06:12:52.438: INFO: (10) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 9.179294ms)
Apr 20 06:12:52.444: INFO: (10) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/rewriteme">test</a> (200; 14.283652ms)
Apr 20 06:12:52.444: INFO: (10) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/tlsrewritem... (200; 14.739556ms)
Apr 20 06:12:52.444: INFO: (10) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">... (200; 14.866922ms)
Apr 20 06:12:52.444: INFO: (10) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:462/proxy/: tls qux (200; 14.434446ms)
Apr 20 06:12:52.444: INFO: (10) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname1/proxy/: foo (200; 15.081043ms)
Apr 20 06:12:52.444: INFO: (10) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 14.617107ms)
Apr 20 06:12:52.444: INFO: (10) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname2/proxy/: bar (200; 14.932679ms)
Apr 20 06:12:52.450: INFO: (10) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 20.253235ms)
Apr 20 06:12:52.450: INFO: (10) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">test<... (200; 20.212289ms)
Apr 20 06:12:52.450: INFO: (10) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname1/proxy/: foo (200; 20.548571ms)
Apr 20 06:12:52.450: INFO: (10) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname2/proxy/: bar (200; 20.580104ms)
Apr 20 06:12:52.450: INFO: (10) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname2/proxy/: tls qux (200; 20.84166ms)
Apr 20 06:12:52.450: INFO: (10) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname1/proxy/: tls baz (200; 20.566111ms)
Apr 20 06:12:52.460: INFO: (11) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 9.689392ms)
Apr 20 06:12:52.460: INFO: (11) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:460/proxy/: tls baz (200; 9.793676ms)
Apr 20 06:12:52.460: INFO: (11) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:462/proxy/: tls qux (200; 9.815917ms)
Apr 20 06:12:52.463: INFO: (11) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">test<... (200; 12.665559ms)
Apr 20 06:12:52.463: INFO: (11) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/tlsrewritem... (200; 12.79682ms)
Apr 20 06:12:52.463: INFO: (11) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 12.688085ms)
Apr 20 06:12:52.465: INFO: (11) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">... (200; 14.848637ms)
Apr 20 06:12:52.465: INFO: (11) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/rewriteme">test</a> (200; 14.786737ms)
Apr 20 06:12:52.467: INFO: (11) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname1/proxy/: foo (200; 16.62368ms)
Apr 20 06:12:52.467: INFO: (11) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname1/proxy/: tls baz (200; 16.463619ms)
Apr 20 06:12:52.467: INFO: (11) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 16.550554ms)
Apr 20 06:12:52.467: INFO: (11) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 16.583835ms)
Apr 20 06:12:52.469: INFO: (11) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname2/proxy/: tls qux (200; 18.717335ms)
Apr 20 06:12:52.469: INFO: (11) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname1/proxy/: foo (200; 18.885636ms)
Apr 20 06:12:52.470: INFO: (11) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname2/proxy/: bar (200; 19.358201ms)
Apr 20 06:12:52.470: INFO: (11) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname2/proxy/: bar (200; 19.084263ms)
Apr 20 06:12:52.480: INFO: (12) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:462/proxy/: tls qux (200; 10.674496ms)
Apr 20 06:12:52.486: INFO: (12) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname1/proxy/: foo (200; 15.801712ms)
Apr 20 06:12:52.486: INFO: (12) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 15.776139ms)
Apr 20 06:12:52.486: INFO: (12) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 15.873849ms)
Apr 20 06:12:52.486: INFO: (12) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/tlsrewritem... (200; 15.928337ms)
Apr 20 06:12:52.486: INFO: (12) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">... (200; 15.956617ms)
Apr 20 06:12:52.490: INFO: (12) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname2/proxy/: tls qux (200; 19.764897ms)
Apr 20 06:12:52.490: INFO: (12) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">test<... (200; 19.807108ms)
Apr 20 06:12:52.490: INFO: (12) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname2/proxy/: bar (200; 19.720093ms)
Apr 20 06:12:52.490: INFO: (12) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname2/proxy/: bar (200; 19.734991ms)
Apr 20 06:12:52.490: INFO: (12) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 20.02877ms)
Apr 20 06:12:52.490: INFO: (12) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname1/proxy/: tls baz (200; 20.105002ms)
Apr 20 06:12:52.490: INFO: (12) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:460/proxy/: tls baz (200; 19.934524ms)
Apr 20 06:12:52.490: INFO: (12) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/rewriteme">test</a> (200; 19.930322ms)
Apr 20 06:12:52.491: INFO: (12) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname1/proxy/: foo (200; 20.670884ms)
Apr 20 06:12:52.493: INFO: (12) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 23.385778ms)
Apr 20 06:12:52.505: INFO: (13) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/tlsrewritem... (200; 11.191638ms)
Apr 20 06:12:52.509: INFO: (13) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 15.756833ms)
Apr 20 06:12:52.512: INFO: (13) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">test<... (200; 18.112716ms)
Apr 20 06:12:52.512: INFO: (13) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">... (200; 17.854089ms)
Apr 20 06:12:52.512: INFO: (13) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname2/proxy/: bar (200; 18.081101ms)
Apr 20 06:12:52.512: INFO: (13) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:460/proxy/: tls baz (200; 18.232688ms)
Apr 20 06:12:52.512: INFO: (13) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 18.387147ms)
Apr 20 06:12:52.512: INFO: (13) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/rewriteme">test</a> (200; 18.390434ms)
Apr 20 06:12:52.512: INFO: (13) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:462/proxy/: tls qux (200; 18.621687ms)
Apr 20 06:12:52.512: INFO: (13) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname2/proxy/: tls qux (200; 19.001807ms)
Apr 20 06:12:52.512: INFO: (13) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 19.025476ms)
Apr 20 06:12:52.515: INFO: (13) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname1/proxy/: foo (200; 20.837242ms)
Apr 20 06:12:52.515: INFO: (13) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 21.047827ms)
Apr 20 06:12:52.515: INFO: (13) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname2/proxy/: bar (200; 21.269994ms)
Apr 20 06:12:52.515: INFO: (13) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname1/proxy/: foo (200; 21.835838ms)
Apr 20 06:12:52.516: INFO: (13) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname1/proxy/: tls baz (200; 22.736778ms)
Apr 20 06:12:52.527: INFO: (14) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:462/proxy/: tls qux (200; 10.374787ms)
Apr 20 06:12:52.533: INFO: (14) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 15.647172ms)
Apr 20 06:12:52.533: INFO: (14) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 16.014229ms)
Apr 20 06:12:52.533: INFO: (14) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:460/proxy/: tls baz (200; 15.993684ms)
Apr 20 06:12:52.533: INFO: (14) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/rewriteme">test</a> (200; 16.083622ms)
Apr 20 06:12:52.533: INFO: (14) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 16.276426ms)
Apr 20 06:12:52.533: INFO: (14) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/tlsrewritem... (200; 16.574232ms)
Apr 20 06:12:52.533: INFO: (14) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">... (200; 15.723212ms)
Apr 20 06:12:52.533: INFO: (14) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">test<... (200; 15.924655ms)
Apr 20 06:12:52.537: INFO: (14) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname1/proxy/: foo (200; 19.83363ms)
Apr 20 06:12:52.537: INFO: (14) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 19.328426ms)
Apr 20 06:12:52.537: INFO: (14) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname2/proxy/: tls qux (200; 19.951923ms)
Apr 20 06:12:52.537: INFO: (14) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname2/proxy/: bar (200; 19.804482ms)
Apr 20 06:12:52.537: INFO: (14) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname2/proxy/: bar (200; 19.953797ms)
Apr 20 06:12:52.537: INFO: (14) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname1/proxy/: tls baz (200; 19.881956ms)
Apr 20 06:12:52.538: INFO: (14) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname1/proxy/: foo (200; 20.672482ms)
Apr 20 06:12:52.550: INFO: (15) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">... (200; 11.532392ms)
Apr 20 06:12:52.550: INFO: (15) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:462/proxy/: tls qux (200; 11.852497ms)
Apr 20 06:12:52.556: INFO: (15) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:460/proxy/: tls baz (200; 17.802706ms)
Apr 20 06:12:52.556: INFO: (15) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 17.822024ms)
Apr 20 06:12:52.556: INFO: (15) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">test<... (200; 17.82387ms)
Apr 20 06:12:52.556: INFO: (15) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 17.810486ms)
Apr 20 06:12:52.556: INFO: (15) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/rewriteme">test</a> (200; 18.284636ms)
Apr 20 06:12:52.556: INFO: (15) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 18.292287ms)
Apr 20 06:12:52.556: INFO: (15) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname1/proxy/: tls baz (200; 18.372166ms)
Apr 20 06:12:52.559: INFO: (15) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/tlsrewritem... (200; 20.964264ms)
Apr 20 06:12:52.560: INFO: (15) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 21.050238ms)
Apr 20 06:12:52.561: INFO: (15) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname2/proxy/: tls qux (200; 22.335697ms)
Apr 20 06:12:52.561: INFO: (15) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname1/proxy/: foo (200; 22.36975ms)
Apr 20 06:12:52.561: INFO: (15) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname2/proxy/: bar (200; 22.385758ms)
Apr 20 06:12:52.561: INFO: (15) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname2/proxy/: bar (200; 22.418924ms)
Apr 20 06:12:52.561: INFO: (15) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname1/proxy/: foo (200; 22.702581ms)
Apr 20 06:12:52.574: INFO: (16) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/tlsrewritem... (200; 12.65213ms)
Apr 20 06:12:52.574: INFO: (16) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 12.643796ms)
Apr 20 06:12:52.574: INFO: (16) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 12.822939ms)
Apr 20 06:12:52.574: INFO: (16) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname1/proxy/: tls baz (200; 12.957409ms)
Apr 20 06:12:52.574: INFO: (16) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 13.098593ms)
Apr 20 06:12:52.578: INFO: (16) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">... (200; 16.83902ms)
Apr 20 06:12:52.578: INFO: (16) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/rewriteme">test</a> (200; 16.904161ms)
Apr 20 06:12:52.578: INFO: (16) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 17.134061ms)
Apr 20 06:12:52.578: INFO: (16) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">test<... (200; 17.206644ms)
Apr 20 06:12:52.581: INFO: (16) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname2/proxy/: tls qux (200; 19.713896ms)
Apr 20 06:12:52.581: INFO: (16) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:462/proxy/: tls qux (200; 19.623591ms)
Apr 20 06:12:52.581: INFO: (16) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname2/proxy/: bar (200; 19.690602ms)
Apr 20 06:12:52.581: INFO: (16) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:460/proxy/: tls baz (200; 19.791106ms)
Apr 20 06:12:52.581: INFO: (16) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname1/proxy/: foo (200; 20.029231ms)
Apr 20 06:12:52.582: INFO: (16) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname1/proxy/: foo (200; 20.388054ms)
Apr 20 06:12:52.582: INFO: (16) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname2/proxy/: bar (200; 20.90787ms)
Apr 20 06:12:52.596: INFO: (17) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 12.85043ms)
Apr 20 06:12:52.596: INFO: (17) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/tlsrewritem... (200; 12.754849ms)
Apr 20 06:12:52.596: INFO: (17) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:462/proxy/: tls qux (200; 13.07908ms)
Apr 20 06:12:52.596: INFO: (17) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:460/proxy/: tls baz (200; 12.995221ms)
Apr 20 06:12:52.599: INFO: (17) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">test<... (200; 16.166123ms)
Apr 20 06:12:52.599: INFO: (17) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 16.111464ms)
Apr 20 06:12:52.599: INFO: (17) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 16.300203ms)
Apr 20 06:12:52.599: INFO: (17) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">... (200; 16.035537ms)
Apr 20 06:12:52.599: INFO: (17) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/rewriteme">test</a> (200; 16.718602ms)
Apr 20 06:12:52.599: INFO: (17) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 16.200862ms)
Apr 20 06:12:52.600: INFO: (17) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname2/proxy/: tls qux (200; 17.49237ms)
Apr 20 06:12:52.600: INFO: (17) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname2/proxy/: bar (200; 17.327484ms)
Apr 20 06:12:52.602: INFO: (17) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname1/proxy/: foo (200; 18.843974ms)
Apr 20 06:12:52.602: INFO: (17) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname1/proxy/: foo (200; 19.085658ms)
Apr 20 06:12:52.602: INFO: (17) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname2/proxy/: bar (200; 19.30984ms)
Apr 20 06:12:52.602: INFO: (17) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname1/proxy/: tls baz (200; 19.289024ms)
Apr 20 06:12:52.614: INFO: (18) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:462/proxy/: tls qux (200; 11.072284ms)
Apr 20 06:12:52.614: INFO: (18) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/rewriteme">test</a> (200; 11.191773ms)
Apr 20 06:12:52.614: INFO: (18) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">... (200; 11.450292ms)
Apr 20 06:12:52.614: INFO: (18) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 11.147196ms)
Apr 20 06:12:52.621: INFO: (18) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname2/proxy/: bar (200; 17.843693ms)
Apr 20 06:12:52.621: INFO: (18) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname2/proxy/: bar (200; 18.031575ms)
Apr 20 06:12:52.621: INFO: (18) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/tlsrewritem... (200; 17.899753ms)
Apr 20 06:12:52.621: INFO: (18) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">test<... (200; 18.093418ms)
Apr 20 06:12:52.621: INFO: (18) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:460/proxy/: tls baz (200; 18.158333ms)
Apr 20 06:12:52.621: INFO: (18) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname2/proxy/: tls qux (200; 18.359558ms)
Apr 20 06:12:52.621: INFO: (18) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 18.155551ms)
Apr 20 06:12:52.622: INFO: (18) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 19.643424ms)
Apr 20 06:12:52.622: INFO: (18) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 19.747713ms)
Apr 20 06:12:52.626: INFO: (18) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname1/proxy/: foo (200; 23.10082ms)
Apr 20 06:12:52.626: INFO: (18) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname1/proxy/: foo (200; 23.682381ms)
Apr 20 06:12:52.626: INFO: (18) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname1/proxy/: tls baz (200; 23.531923ms)
Apr 20 06:12:52.637: INFO: (19) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5/proxy/rewriteme">test</a> (200; 10.778631ms)
Apr 20 06:12:52.642: INFO: (19) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 15.466183ms)
Apr 20 06:12:52.642: INFO: (19) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:443/proxy/tlsrewritem... (200; 15.903448ms)
Apr 20 06:12:52.642: INFO: (19) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 15.745043ms)
Apr 20 06:12:52.642: INFO: (19) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">... (200; 15.65944ms)
Apr 20 06:12:52.644: INFO: (19) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:162/proxy/: bar (200; 17.33893ms)
Apr 20 06:12:52.644: INFO: (19) /api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/: <a href="/api/v1/namespaces/proxy-1608/pods/proxy-service-8wmk7-5khs5:1080/proxy/rewriteme">test<... (200; 17.454689ms)
Apr 20 06:12:52.644: INFO: (19) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:460/proxy/: tls baz (200; 17.629367ms)
Apr 20 06:12:52.645: INFO: (19) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname1/proxy/: foo (200; 17.800309ms)
Apr 20 06:12:52.645: INFO: (19) /api/v1/namespaces/proxy-1608/pods/https:proxy-service-8wmk7-5khs5:462/proxy/: tls qux (200; 17.75814ms)
Apr 20 06:12:52.645: INFO: (19) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname2/proxy/: tls qux (200; 18.178371ms)
Apr 20 06:12:52.647: INFO: (19) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname2/proxy/: bar (200; 20.258795ms)
Apr 20 06:12:52.647: INFO: (19) /api/v1/namespaces/proxy-1608/services/http:proxy-service-8wmk7:portname2/proxy/: bar (200; 20.347824ms)
Apr 20 06:12:52.647: INFO: (19) /api/v1/namespaces/proxy-1608/pods/http:proxy-service-8wmk7-5khs5:160/proxy/: foo (200; 20.575231ms)
Apr 20 06:12:52.648: INFO: (19) /api/v1/namespaces/proxy-1608/services/proxy-service-8wmk7:portname1/proxy/: foo (200; 21.104275ms)
Apr 20 06:12:52.648: INFO: (19) /api/v1/namespaces/proxy-1608/services/https:proxy-service-8wmk7:tlsportname1/proxy/: tls baz (200; 21.227584ms)
STEP: deleting ReplicationController proxy-service-8wmk7 in namespace proxy-1608, will wait for the garbage collector to delete the pods
Apr 20 06:12:52.709: INFO: Deleting ReplicationController proxy-service-8wmk7 took: 5.730472ms
Apr 20 06:12:52.809: INFO: Terminating ReplicationController proxy-service-8wmk7 pods took: 100.560692ms
[AfterEach] version v1
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:12:54.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1608" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":346,"completed":78,"skipped":1535,"failed":0}
SSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:12:54.924: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap that has name configmap-test-emptyKey-77d3e686-a815-4404-9f06-d9eae4466bc1
[AfterEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:12:54.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3120" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":346,"completed":79,"skipped":1542,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be immutable if `immutable` field is set [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:12:55.005: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be immutable if `immutable` field is set [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:12:55.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1499" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","total":346,"completed":80,"skipped":1586,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:12:55.087: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod pod-subpath-test-projected-ftk5
STEP: Creating a pod to test atomic-volume-subpath
Apr 20 06:12:55.135: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-ftk5" in namespace "subpath-9517" to be "Succeeded or Failed"
Apr 20 06:12:55.150: INFO: Pod "pod-subpath-test-projected-ftk5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.899458ms
Apr 20 06:12:57.156: INFO: Pod "pod-subpath-test-projected-ftk5": Phase="Running", Reason="", readiness=true. Elapsed: 2.02099241s
Apr 20 06:12:59.163: INFO: Pod "pod-subpath-test-projected-ftk5": Phase="Running", Reason="", readiness=true. Elapsed: 4.027949416s
Apr 20 06:13:01.171: INFO: Pod "pod-subpath-test-projected-ftk5": Phase="Running", Reason="", readiness=true. Elapsed: 6.035664474s
Apr 20 06:13:03.176: INFO: Pod "pod-subpath-test-projected-ftk5": Phase="Running", Reason="", readiness=true. Elapsed: 8.040537483s
Apr 20 06:13:05.181: INFO: Pod "pod-subpath-test-projected-ftk5": Phase="Running", Reason="", readiness=true. Elapsed: 10.046036599s
Apr 20 06:13:07.194: INFO: Pod "pod-subpath-test-projected-ftk5": Phase="Running", Reason="", readiness=true. Elapsed: 12.058377976s
Apr 20 06:13:09.199: INFO: Pod "pod-subpath-test-projected-ftk5": Phase="Running", Reason="", readiness=true. Elapsed: 14.063875289s
Apr 20 06:13:11.207: INFO: Pod "pod-subpath-test-projected-ftk5": Phase="Running", Reason="", readiness=true. Elapsed: 16.071528587s
Apr 20 06:13:13.211: INFO: Pod "pod-subpath-test-projected-ftk5": Phase="Running", Reason="", readiness=true. Elapsed: 18.075951079s
Apr 20 06:13:15.219: INFO: Pod "pod-subpath-test-projected-ftk5": Phase="Running", Reason="", readiness=true. Elapsed: 20.083511177s
Apr 20 06:13:17.224: INFO: Pod "pod-subpath-test-projected-ftk5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.088593738s
STEP: Saw pod success
Apr 20 06:13:17.224: INFO: Pod "pod-subpath-test-projected-ftk5" satisfied condition "Succeeded or Failed"
Apr 20 06:13:17.226: INFO: Trying to get logs from node node22-hwh1v pod pod-subpath-test-projected-ftk5 container test-container-subpath-projected-ftk5: <nil>
STEP: delete the pod
Apr 20 06:13:17.261: INFO: Waiting for pod pod-subpath-test-projected-ftk5 to disappear
Apr 20 06:13:17.263: INFO: Pod pod-subpath-test-projected-ftk5 no longer exists
STEP: Deleting pod pod-subpath-test-projected-ftk5
Apr 20 06:13:17.263: INFO: Deleting pod "pod-subpath-test-projected-ftk5" in namespace "subpath-9517"
[AfterEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:13:17.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9517" for this suite.

• [SLOW TEST:22.188 seconds]
[sig-storage] Subpath
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [LinuxOnly] [Conformance]","total":346,"completed":81,"skipped":1637,"failed":0}
[sig-node] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:13:17.275: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:38
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:13:17.348: INFO: The status of Pod busybox-host-aliasesb46dc860-aa97-45d5-907a-cf0dd53df996 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:13:19.353: INFO: The status of Pod busybox-host-aliasesb46dc860-aa97-45d5-907a-cf0dd53df996 is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:13:19.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3080" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":82,"skipped":1637,"failed":0}
SSS
------------------------------
[sig-node] PodTemplates 
  should run the lifecycle of PodTemplates [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] PodTemplates
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:13:19.369: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run the lifecycle of PodTemplates [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-node] PodTemplates
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:13:19.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-1565" for this suite.
•{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","total":346,"completed":83,"skipped":1640,"failed":0}
SSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:13:19.422: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check is all data is printed  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:13:19.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-6503 version'
Apr 20 06:13:19.507: INFO: stderr: ""
Apr 20 06:13:19.507: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"22\", GitVersion:\"v1.22.2\", GitCommit:\"8b5a19147530eaac9476b0ab82980b4088bbc1b2\", GitTreeState:\"clean\", BuildDate:\"2021-09-15T21:38:50Z\", GoVersion:\"go1.16.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"22\", GitVersion:\"v1.22.2\", GitCommit:\"8b5a19147530eaac9476b0ab82980b4088bbc1b2\", GitTreeState:\"clean\", BuildDate:\"2021-09-15T21:32:41Z\", GoVersion:\"go1.16.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:13:19.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6503" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":346,"completed":84,"skipped":1643,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:13:19.516: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Kubectl label
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1318
STEP: creating the pod
Apr 20 06:13:19.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3412 create -f -'
Apr 20 06:13:19.694: INFO: stderr: ""
Apr 20 06:13:19.694: INFO: stdout: "pod/pause created\n"
Apr 20 06:13:19.694: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr 20 06:13:19.694: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-3412" to be "running and ready"
Apr 20 06:13:19.697: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.372614ms
Apr 20 06:13:21.701: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.006565341s
Apr 20 06:13:21.701: INFO: Pod "pause" satisfied condition "running and ready"
Apr 20 06:13:21.701: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: adding the label testing-label with value testing-label-value to a pod
Apr 20 06:13:21.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3412 label pods pause testing-label=testing-label-value'
Apr 20 06:13:21.760: INFO: stderr: ""
Apr 20 06:13:21.760: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Apr 20 06:13:21.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3412 get pod pause -L testing-label'
Apr 20 06:13:21.815: INFO: stderr: ""
Apr 20 06:13:21.815: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Apr 20 06:13:21.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3412 label pods pause testing-label-'
Apr 20 06:13:21.873: INFO: stderr: ""
Apr 20 06:13:21.873: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Apr 20 06:13:21.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3412 get pod pause -L testing-label'
Apr 20 06:13:21.918: INFO: stderr: ""
Apr 20 06:13:21.918: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1324
STEP: using delete to clean up resources
Apr 20 06:13:21.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3412 delete --grace-period=0 --force -f -'
Apr 20 06:13:21.981: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 20 06:13:21.981: INFO: stdout: "pod \"pause\" force deleted\n"
Apr 20 06:13:21.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3412 get rc,svc -l name=pause --no-headers'
Apr 20 06:13:22.033: INFO: stderr: "No resources found in kubectl-3412 namespace.\n"
Apr 20 06:13:22.033: INFO: stdout: ""
Apr 20 06:13:22.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3412 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 20 06:13:22.079: INFO: stderr: ""
Apr 20 06:13:22.079: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:13:22.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3412" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":346,"completed":85,"skipped":1654,"failed":0}

------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:13:22.087: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod pod-subpath-test-configmap-kf42
STEP: Creating a pod to test atomic-volume-subpath
Apr 20 06:13:22.162: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-kf42" in namespace "subpath-7797" to be "Succeeded or Failed"
Apr 20 06:13:22.166: INFO: Pod "pod-subpath-test-configmap-kf42": Phase="Pending", Reason="", readiness=false. Elapsed: 3.468346ms
Apr 20 06:13:24.172: INFO: Pod "pod-subpath-test-configmap-kf42": Phase="Running", Reason="", readiness=true. Elapsed: 2.009749983s
Apr 20 06:13:26.179: INFO: Pod "pod-subpath-test-configmap-kf42": Phase="Running", Reason="", readiness=true. Elapsed: 4.016481189s
Apr 20 06:13:28.183: INFO: Pod "pod-subpath-test-configmap-kf42": Phase="Running", Reason="", readiness=true. Elapsed: 6.021437813s
Apr 20 06:13:30.188: INFO: Pod "pod-subpath-test-configmap-kf42": Phase="Running", Reason="", readiness=true. Elapsed: 8.026258833s
Apr 20 06:13:32.203: INFO: Pod "pod-subpath-test-configmap-kf42": Phase="Running", Reason="", readiness=true. Elapsed: 10.04100182s
Apr 20 06:13:34.210: INFO: Pod "pod-subpath-test-configmap-kf42": Phase="Running", Reason="", readiness=true. Elapsed: 12.047633818s
Apr 20 06:13:36.217: INFO: Pod "pod-subpath-test-configmap-kf42": Phase="Running", Reason="", readiness=true. Elapsed: 14.055132159s
Apr 20 06:13:38.223: INFO: Pod "pod-subpath-test-configmap-kf42": Phase="Running", Reason="", readiness=true. Elapsed: 16.06108358s
Apr 20 06:13:40.230: INFO: Pod "pod-subpath-test-configmap-kf42": Phase="Running", Reason="", readiness=true. Elapsed: 18.067492678s
Apr 20 06:13:42.238: INFO: Pod "pod-subpath-test-configmap-kf42": Phase="Running", Reason="", readiness=true. Elapsed: 20.076283233s
Apr 20 06:13:44.246: INFO: Pod "pod-subpath-test-configmap-kf42": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.084015694s
STEP: Saw pod success
Apr 20 06:13:44.246: INFO: Pod "pod-subpath-test-configmap-kf42" satisfied condition "Succeeded or Failed"
Apr 20 06:13:44.248: INFO: Trying to get logs from node node22-hwh1v pod pod-subpath-test-configmap-kf42 container test-container-subpath-configmap-kf42: <nil>
STEP: delete the pod
Apr 20 06:13:44.265: INFO: Waiting for pod pod-subpath-test-configmap-kf42 to disappear
Apr 20 06:13:44.267: INFO: Pod pod-subpath-test-configmap-kf42 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-kf42
Apr 20 06:13:44.267: INFO: Deleting pod "pod-subpath-test-configmap-kf42" in namespace "subpath-7797"
[AfterEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:13:44.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7797" for this suite.

• [SLOW TEST:22.190 seconds]
[sig-storage] Subpath
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]","total":346,"completed":86,"skipped":1654,"failed":0}
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:13:44.277: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 20 06:13:44.628: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 20 06:13:47.669: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:13:47.674: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3275-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:13:50.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1778" for this suite.
STEP: Destroying namespace "webhook-1778-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.562 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":346,"completed":87,"skipped":1658,"failed":0}
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:13:50.840: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-5a28ac42-80e7-4bab-9b11-d1319da33051
STEP: Creating a pod to test consume configMaps
Apr 20 06:13:50.891: INFO: Waiting up to 5m0s for pod "pod-configmaps-87c0a7f0-e02a-4b88-a2c7-4e4a0ae2c351" in namespace "configmap-7974" to be "Succeeded or Failed"
Apr 20 06:13:50.893: INFO: Pod "pod-configmaps-87c0a7f0-e02a-4b88-a2c7-4e4a0ae2c351": Phase="Pending", Reason="", readiness=false. Elapsed: 1.76278ms
Apr 20 06:13:52.897: INFO: Pod "pod-configmaps-87c0a7f0-e02a-4b88-a2c7-4e4a0ae2c351": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005812313s
Apr 20 06:13:54.903: INFO: Pod "pod-configmaps-87c0a7f0-e02a-4b88-a2c7-4e4a0ae2c351": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011275385s
STEP: Saw pod success
Apr 20 06:13:54.903: INFO: Pod "pod-configmaps-87c0a7f0-e02a-4b88-a2c7-4e4a0ae2c351" satisfied condition "Succeeded or Failed"
Apr 20 06:13:54.905: INFO: Trying to get logs from node node22-hwh1v pod pod-configmaps-87c0a7f0-e02a-4b88-a2c7-4e4a0ae2c351 container agnhost-container: <nil>
STEP: delete the pod
Apr 20 06:13:54.919: INFO: Waiting for pod pod-configmaps-87c0a7f0-e02a-4b88-a2c7-4e4a0ae2c351 to disappear
Apr 20 06:13:54.921: INFO: Pod pod-configmaps-87c0a7f0-e02a-4b88-a2c7-4e4a0ae2c351 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:13:54.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7974" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":346,"completed":88,"skipped":1660,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:13:54.929: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:13:54.961: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: creating replication controller svc-latency-rc in namespace svc-latency-5838
I0420 06:13:54.995341      20 runners.go:190] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5838, replica count: 1
I0420 06:13:56.046073      20 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0420 06:13:57.046205      20 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 20 06:13:57.188: INFO: Created: latency-svc-q26nk
Apr 20 06:13:57.194: INFO: Got endpoints: latency-svc-q26nk [46.237557ms]
Apr 20 06:13:57.211: INFO: Created: latency-svc-qsf5j
Apr 20 06:13:57.219: INFO: Got endpoints: latency-svc-qsf5j [25.211898ms]
Apr 20 06:13:57.224: INFO: Created: latency-svc-8jjc9
Apr 20 06:13:57.228: INFO: Got endpoints: latency-svc-8jjc9 [33.688451ms]
Apr 20 06:13:57.244: INFO: Created: latency-svc-b9k8w
Apr 20 06:13:57.244: INFO: Got endpoints: latency-svc-b9k8w [25.04219ms]
Apr 20 06:13:57.248: INFO: Created: latency-svc-ntfh4
Apr 20 06:13:57.255: INFO: Got endpoints: latency-svc-ntfh4 [60.89852ms]
Apr 20 06:13:57.272: INFO: Created: latency-svc-x62z4
Apr 20 06:13:57.272: INFO: Got endpoints: latency-svc-x62z4 [78.09218ms]
Apr 20 06:13:57.286: INFO: Created: latency-svc-4qqxl
Apr 20 06:13:57.292: INFO: Got endpoints: latency-svc-4qqxl [97.659246ms]
Apr 20 06:13:57.297: INFO: Created: latency-svc-mh8w8
Apr 20 06:13:57.322: INFO: Got endpoints: latency-svc-mh8w8 [128.180137ms]
Apr 20 06:13:57.329: INFO: Created: latency-svc-8lr58
Apr 20 06:13:57.333: INFO: Got endpoints: latency-svc-8lr58 [139.354602ms]
Apr 20 06:13:57.340: INFO: Created: latency-svc-wksx2
Apr 20 06:13:57.344: INFO: Got endpoints: latency-svc-wksx2 [150.023942ms]
Apr 20 06:13:57.349: INFO: Created: latency-svc-bhnqp
Apr 20 06:13:57.355: INFO: Got endpoints: latency-svc-bhnqp [161.052667ms]
Apr 20 06:13:57.363: INFO: Created: latency-svc-v8vxr
Apr 20 06:13:57.385: INFO: Got endpoints: latency-svc-v8vxr [190.976679ms]
Apr 20 06:13:57.397: INFO: Created: latency-svc-2zvpn
Apr 20 06:13:57.400: INFO: Got endpoints: latency-svc-2zvpn [206.010084ms]
Apr 20 06:13:57.404: INFO: Created: latency-svc-wg9fd
Apr 20 06:13:57.411: INFO: Got endpoints: latency-svc-wg9fd [216.748987ms]
Apr 20 06:13:57.418: INFO: Created: latency-svc-59b9r
Apr 20 06:13:57.426: INFO: Got endpoints: latency-svc-59b9r [231.425198ms]
Apr 20 06:13:57.428: INFO: Created: latency-svc-t8m6t
Apr 20 06:13:57.446: INFO: Got endpoints: latency-svc-t8m6t [252.034151ms]
Apr 20 06:13:57.452: INFO: Created: latency-svc-5d7l6
Apr 20 06:13:57.460: INFO: Got endpoints: latency-svc-5d7l6 [265.886246ms]
Apr 20 06:13:57.469: INFO: Created: latency-svc-2cxdp
Apr 20 06:13:57.470: INFO: Got endpoints: latency-svc-2cxdp [241.548703ms]
Apr 20 06:13:57.485: INFO: Created: latency-svc-jljc2
Apr 20 06:13:57.485: INFO: Got endpoints: latency-svc-jljc2 [240.567503ms]
Apr 20 06:13:57.489: INFO: Created: latency-svc-nh2p2
Apr 20 06:13:57.495: INFO: Got endpoints: latency-svc-nh2p2 [239.949312ms]
Apr 20 06:13:57.501: INFO: Created: latency-svc-rljt6
Apr 20 06:13:57.506: INFO: Got endpoints: latency-svc-rljt6 [234.393048ms]
Apr 20 06:13:57.517: INFO: Created: latency-svc-xtzc6
Apr 20 06:13:57.520: INFO: Got endpoints: latency-svc-xtzc6 [227.910572ms]
Apr 20 06:13:57.522: INFO: Created: latency-svc-kffc7
Apr 20 06:13:57.532: INFO: Got endpoints: latency-svc-kffc7 [209.346173ms]
Apr 20 06:13:57.560: INFO: Created: latency-svc-z2pmt
Apr 20 06:13:57.571: INFO: Got endpoints: latency-svc-z2pmt [237.746837ms]
Apr 20 06:13:57.581: INFO: Created: latency-svc-q95d7
Apr 20 06:13:57.588: INFO: Got endpoints: latency-svc-q95d7 [243.543621ms]
Apr 20 06:13:57.592: INFO: Created: latency-svc-db4rs
Apr 20 06:13:57.597: INFO: Got endpoints: latency-svc-db4rs [241.859558ms]
Apr 20 06:13:57.606: INFO: Created: latency-svc-9qtgn
Apr 20 06:13:57.608: INFO: Got endpoints: latency-svc-9qtgn [223.395793ms]
Apr 20 06:13:57.621: INFO: Created: latency-svc-45ccl
Apr 20 06:13:57.629: INFO: Got endpoints: latency-svc-45ccl [228.405213ms]
Apr 20 06:13:57.633: INFO: Created: latency-svc-p9jlh
Apr 20 06:13:57.638: INFO: Got endpoints: latency-svc-p9jlh [227.214677ms]
Apr 20 06:13:57.648: INFO: Created: latency-svc-qkvdz
Apr 20 06:13:57.655: INFO: Got endpoints: latency-svc-qkvdz [229.246057ms]
Apr 20 06:13:57.664: INFO: Created: latency-svc-xgxf4
Apr 20 06:13:57.667: INFO: Got endpoints: latency-svc-xgxf4 [220.930247ms]
Apr 20 06:13:57.670: INFO: Created: latency-svc-ks6hg
Apr 20 06:13:57.678: INFO: Got endpoints: latency-svc-ks6hg [217.371999ms]
Apr 20 06:13:57.684: INFO: Created: latency-svc-l47fz
Apr 20 06:13:57.687: INFO: Got endpoints: latency-svc-l47fz [217.791779ms]
Apr 20 06:13:57.698: INFO: Created: latency-svc-cn9ff
Apr 20 06:13:57.720: INFO: Got endpoints: latency-svc-cn9ff [235.082604ms]
Apr 20 06:13:57.723: INFO: Created: latency-svc-78cxx
Apr 20 06:13:57.731: INFO: Got endpoints: latency-svc-78cxx [235.990523ms]
Apr 20 06:13:57.737: INFO: Created: latency-svc-tvv7p
Apr 20 06:13:57.742: INFO: Got endpoints: latency-svc-tvv7p [235.257003ms]
Apr 20 06:13:57.753: INFO: Created: latency-svc-xlbp2
Apr 20 06:13:57.758: INFO: Got endpoints: latency-svc-xlbp2 [238.162151ms]
Apr 20 06:13:57.761: INFO: Created: latency-svc-zvw9k
Apr 20 06:13:57.769: INFO: Got endpoints: latency-svc-zvw9k [237.334979ms]
Apr 20 06:13:57.773: INFO: Created: latency-svc-ljtll
Apr 20 06:13:57.784: INFO: Got endpoints: latency-svc-ljtll [212.729564ms]
Apr 20 06:13:57.811: INFO: Created: latency-svc-8m6t4
Apr 20 06:13:57.816: INFO: Got endpoints: latency-svc-8m6t4 [228.225889ms]
Apr 20 06:13:57.820: INFO: Created: latency-svc-xf89z
Apr 20 06:13:57.824: INFO: Got endpoints: latency-svc-xf89z [226.699997ms]
Apr 20 06:13:57.838: INFO: Created: latency-svc-66twv
Apr 20 06:13:57.846: INFO: Got endpoints: latency-svc-66twv [237.300118ms]
Apr 20 06:13:57.853: INFO: Created: latency-svc-7nkct
Apr 20 06:13:57.858: INFO: Got endpoints: latency-svc-7nkct [229.444173ms]
Apr 20 06:13:57.859: INFO: Created: latency-svc-9ptcv
Apr 20 06:13:57.877: INFO: Created: latency-svc-vxmgn
Apr 20 06:13:57.892: INFO: Created: latency-svc-p2cnm
Apr 20 06:13:57.894: INFO: Got endpoints: latency-svc-9ptcv [255.866637ms]
Apr 20 06:13:57.897: INFO: Created: latency-svc-vnfwx
Apr 20 06:13:57.908: INFO: Created: latency-svc-kxr87
Apr 20 06:13:57.925: INFO: Created: latency-svc-9dxb8
Apr 20 06:13:57.927: INFO: Created: latency-svc-dclpb
Apr 20 06:13:57.964: INFO: Got endpoints: latency-svc-vxmgn [308.90237ms]
Apr 20 06:13:57.964: INFO: Created: latency-svc-js7xl
Apr 20 06:13:57.993: INFO: Created: latency-svc-qjh42
Apr 20 06:13:57.993: INFO: Got endpoints: latency-svc-p2cnm [325.848804ms]
Apr 20 06:13:58.000: INFO: Created: latency-svc-j9lhh
Apr 20 06:13:58.008: INFO: Created: latency-svc-cd86z
Apr 20 06:13:58.020: INFO: Created: latency-svc-nflcj
Apr 20 06:13:58.026: INFO: Created: latency-svc-jsxhv
Apr 20 06:13:58.040: INFO: Created: latency-svc-jf4tf
Apr 20 06:13:58.041: INFO: Got endpoints: latency-svc-vnfwx [363.863437ms]
Apr 20 06:13:58.048: INFO: Created: latency-svc-dr5cw
Apr 20 06:13:58.055: INFO: Created: latency-svc-vgpxx
Apr 20 06:13:58.066: INFO: Created: latency-svc-vqvpf
Apr 20 06:13:58.082: INFO: Created: latency-svc-szw42
Apr 20 06:13:58.089: INFO: Got endpoints: latency-svc-kxr87 [401.236376ms]
Apr 20 06:13:58.095: INFO: Created: latency-svc-p2qvt
Apr 20 06:13:58.106: INFO: Created: latency-svc-2xj7d
Apr 20 06:13:58.139: INFO: Got endpoints: latency-svc-9dxb8 [419.679184ms]
Apr 20 06:13:58.167: INFO: Created: latency-svc-dmhf6
Apr 20 06:13:58.188: INFO: Got endpoints: latency-svc-dclpb [457.134434ms]
Apr 20 06:13:58.200: INFO: Created: latency-svc-xj6zm
Apr 20 06:13:58.238: INFO: Got endpoints: latency-svc-js7xl [496.010438ms]
Apr 20 06:13:58.252: INFO: Created: latency-svc-m4pnm
Apr 20 06:13:58.289: INFO: Got endpoints: latency-svc-qjh42 [530.920198ms]
Apr 20 06:13:58.307: INFO: Created: latency-svc-8wgm7
Apr 20 06:13:58.338: INFO: Got endpoints: latency-svc-j9lhh [568.807368ms]
Apr 20 06:13:58.350: INFO: Created: latency-svc-zhsf2
Apr 20 06:13:58.389: INFO: Got endpoints: latency-svc-cd86z [605.022342ms]
Apr 20 06:13:58.419: INFO: Created: latency-svc-zlmrx
Apr 20 06:13:58.438: INFO: Got endpoints: latency-svc-nflcj [622.478126ms]
Apr 20 06:13:58.461: INFO: Created: latency-svc-28dnl
Apr 20 06:13:58.488: INFO: Got endpoints: latency-svc-jsxhv [663.929822ms]
Apr 20 06:13:58.503: INFO: Created: latency-svc-dhmxb
Apr 20 06:13:58.539: INFO: Got endpoints: latency-svc-jf4tf [692.864737ms]
Apr 20 06:13:58.553: INFO: Created: latency-svc-htl9d
Apr 20 06:13:58.590: INFO: Got endpoints: latency-svc-dr5cw [731.597315ms]
Apr 20 06:13:58.609: INFO: Created: latency-svc-67x2g
Apr 20 06:13:58.639: INFO: Got endpoints: latency-svc-vgpxx [745.122283ms]
Apr 20 06:13:58.657: INFO: Created: latency-svc-4bbcm
Apr 20 06:13:58.689: INFO: Got endpoints: latency-svc-vqvpf [724.6315ms]
Apr 20 06:13:58.707: INFO: Created: latency-svc-w8jmj
Apr 20 06:13:58.742: INFO: Got endpoints: latency-svc-szw42 [749.028378ms]
Apr 20 06:13:58.759: INFO: Created: latency-svc-gw49t
Apr 20 06:13:58.789: INFO: Got endpoints: latency-svc-p2qvt [747.907278ms]
Apr 20 06:13:58.803: INFO: Created: latency-svc-hlnsj
Apr 20 06:13:58.838: INFO: Got endpoints: latency-svc-2xj7d [749.233275ms]
Apr 20 06:13:58.852: INFO: Created: latency-svc-dn9pm
Apr 20 06:13:58.890: INFO: Got endpoints: latency-svc-dmhf6 [750.123961ms]
Apr 20 06:13:58.907: INFO: Created: latency-svc-8drnr
Apr 20 06:13:58.938: INFO: Got endpoints: latency-svc-xj6zm [750.319496ms]
Apr 20 06:13:58.983: INFO: Created: latency-svc-vcf5w
Apr 20 06:13:58.993: INFO: Got endpoints: latency-svc-m4pnm [754.579459ms]
Apr 20 06:13:59.016: INFO: Created: latency-svc-ftx7m
Apr 20 06:13:59.037: INFO: Got endpoints: latency-svc-8wgm7 [748.012773ms]
Apr 20 06:13:59.051: INFO: Created: latency-svc-8dlt6
Apr 20 06:13:59.089: INFO: Got endpoints: latency-svc-zhsf2 [750.620236ms]
Apr 20 06:13:59.102: INFO: Created: latency-svc-258ph
Apr 20 06:13:59.138: INFO: Got endpoints: latency-svc-zlmrx [748.298393ms]
Apr 20 06:13:59.167: INFO: Created: latency-svc-m9l66
Apr 20 06:13:59.197: INFO: Got endpoints: latency-svc-28dnl [758.705941ms]
Apr 20 06:13:59.219: INFO: Created: latency-svc-n2clg
Apr 20 06:13:59.250: INFO: Got endpoints: latency-svc-dhmxb [761.767391ms]
Apr 20 06:13:59.262: INFO: Created: latency-svc-tm6rb
Apr 20 06:13:59.295: INFO: Got endpoints: latency-svc-htl9d [756.451527ms]
Apr 20 06:13:59.310: INFO: Created: latency-svc-hsqdb
Apr 20 06:13:59.339: INFO: Got endpoints: latency-svc-67x2g [748.649894ms]
Apr 20 06:13:59.349: INFO: Created: latency-svc-59wrd
Apr 20 06:13:59.391: INFO: Got endpoints: latency-svc-4bbcm [751.222547ms]
Apr 20 06:13:59.403: INFO: Created: latency-svc-7qljv
Apr 20 06:13:59.440: INFO: Got endpoints: latency-svc-w8jmj [751.017576ms]
Apr 20 06:13:59.454: INFO: Created: latency-svc-8qqsh
Apr 20 06:13:59.490: INFO: Got endpoints: latency-svc-gw49t [747.908772ms]
Apr 20 06:13:59.502: INFO: Created: latency-svc-gkjkr
Apr 20 06:13:59.540: INFO: Got endpoints: latency-svc-hlnsj [750.092918ms]
Apr 20 06:13:59.571: INFO: Created: latency-svc-tf6bf
Apr 20 06:13:59.589: INFO: Got endpoints: latency-svc-dn9pm [750.717005ms]
Apr 20 06:13:59.602: INFO: Created: latency-svc-gw5gb
Apr 20 06:13:59.639: INFO: Got endpoints: latency-svc-8drnr [748.936133ms]
Apr 20 06:13:59.650: INFO: Created: latency-svc-b784p
Apr 20 06:13:59.689: INFO: Got endpoints: latency-svc-vcf5w [750.447211ms]
Apr 20 06:13:59.700: INFO: Created: latency-svc-bg4sr
Apr 20 06:13:59.737: INFO: Got endpoints: latency-svc-ftx7m [744.558124ms]
Apr 20 06:13:59.748: INFO: Created: latency-svc-8glhc
Apr 20 06:13:59.789: INFO: Got endpoints: latency-svc-8dlt6 [752.139903ms]
Apr 20 06:13:59.801: INFO: Created: latency-svc-2hnd9
Apr 20 06:13:59.836: INFO: Got endpoints: latency-svc-258ph [747.192201ms]
Apr 20 06:13:59.852: INFO: Created: latency-svc-bcrgs
Apr 20 06:13:59.889: INFO: Got endpoints: latency-svc-m9l66 [751.476566ms]
Apr 20 06:13:59.900: INFO: Created: latency-svc-fgtbn
Apr 20 06:13:59.938: INFO: Got endpoints: latency-svc-n2clg [740.762803ms]
Apr 20 06:13:59.978: INFO: Created: latency-svc-h89q9
Apr 20 06:13:59.989: INFO: Got endpoints: latency-svc-tm6rb [739.270331ms]
Apr 20 06:14:00.000: INFO: Created: latency-svc-gv846
Apr 20 06:14:00.040: INFO: Got endpoints: latency-svc-hsqdb [744.338391ms]
Apr 20 06:14:00.054: INFO: Created: latency-svc-dv928
Apr 20 06:14:00.092: INFO: Got endpoints: latency-svc-59wrd [752.935724ms]
Apr 20 06:14:00.105: INFO: Created: latency-svc-xt5dr
Apr 20 06:14:00.139: INFO: Got endpoints: latency-svc-7qljv [747.832658ms]
Apr 20 06:14:00.154: INFO: Created: latency-svc-4ntpf
Apr 20 06:14:00.187: INFO: Got endpoints: latency-svc-8qqsh [747.462648ms]
Apr 20 06:14:00.202: INFO: Created: latency-svc-trpqg
Apr 20 06:14:00.255: INFO: Got endpoints: latency-svc-gkjkr [764.602614ms]
Apr 20 06:14:00.281: INFO: Created: latency-svc-rqr6x
Apr 20 06:14:00.287: INFO: Got endpoints: latency-svc-tf6bf [746.80965ms]
Apr 20 06:14:00.300: INFO: Created: latency-svc-zmmzg
Apr 20 06:14:00.338: INFO: Got endpoints: latency-svc-gw5gb [749.167441ms]
Apr 20 06:14:00.349: INFO: Created: latency-svc-rb5vz
Apr 20 06:14:00.386: INFO: Got endpoints: latency-svc-b784p [747.58692ms]
Apr 20 06:14:00.398: INFO: Created: latency-svc-bhq5f
Apr 20 06:14:00.440: INFO: Got endpoints: latency-svc-bg4sr [751.428574ms]
Apr 20 06:14:00.455: INFO: Created: latency-svc-cjmbh
Apr 20 06:14:00.491: INFO: Got endpoints: latency-svc-8glhc [753.273293ms]
Apr 20 06:14:00.500: INFO: Created: latency-svc-mj6d5
Apr 20 06:14:00.538: INFO: Got endpoints: latency-svc-2hnd9 [749.026586ms]
Apr 20 06:14:00.550: INFO: Created: latency-svc-dnsc7
Apr 20 06:14:00.589: INFO: Got endpoints: latency-svc-bcrgs [752.394369ms]
Apr 20 06:14:00.600: INFO: Created: latency-svc-m5s6z
Apr 20 06:14:00.638: INFO: Got endpoints: latency-svc-fgtbn [748.963872ms]
Apr 20 06:14:00.647: INFO: Created: latency-svc-96mnj
Apr 20 06:14:00.689: INFO: Got endpoints: latency-svc-h89q9 [751.213552ms]
Apr 20 06:14:00.704: INFO: Created: latency-svc-b5bpt
Apr 20 06:14:00.741: INFO: Got endpoints: latency-svc-gv846 [751.964478ms]
Apr 20 06:14:00.773: INFO: Created: latency-svc-hj9mp
Apr 20 06:14:00.789: INFO: Got endpoints: latency-svc-dv928 [748.955452ms]
Apr 20 06:14:00.799: INFO: Created: latency-svc-sc8pn
Apr 20 06:14:00.838: INFO: Got endpoints: latency-svc-xt5dr [745.623978ms]
Apr 20 06:14:00.870: INFO: Created: latency-svc-k6cjd
Apr 20 06:14:00.890: INFO: Got endpoints: latency-svc-4ntpf [751.028958ms]
Apr 20 06:14:00.913: INFO: Created: latency-svc-nqd67
Apr 20 06:14:00.946: INFO: Got endpoints: latency-svc-trpqg [758.945079ms]
Apr 20 06:14:00.956: INFO: Created: latency-svc-fwdfx
Apr 20 06:14:00.988: INFO: Got endpoints: latency-svc-rqr6x [733.157252ms]
Apr 20 06:14:01.009: INFO: Created: latency-svc-wdkcq
Apr 20 06:14:01.038: INFO: Got endpoints: latency-svc-zmmzg [751.285832ms]
Apr 20 06:14:01.051: INFO: Created: latency-svc-wnp8r
Apr 20 06:14:01.089: INFO: Got endpoints: latency-svc-rb5vz [750.289304ms]
Apr 20 06:14:01.101: INFO: Created: latency-svc-p88l7
Apr 20 06:14:01.139: INFO: Got endpoints: latency-svc-bhq5f [752.982027ms]
Apr 20 06:14:01.153: INFO: Created: latency-svc-97cmk
Apr 20 06:14:01.191: INFO: Got endpoints: latency-svc-cjmbh [750.539904ms]
Apr 20 06:14:01.206: INFO: Created: latency-svc-9s5dk
Apr 20 06:14:01.239: INFO: Got endpoints: latency-svc-mj6d5 [748.093415ms]
Apr 20 06:14:01.250: INFO: Created: latency-svc-xcpt4
Apr 20 06:14:01.292: INFO: Got endpoints: latency-svc-dnsc7 [753.723441ms]
Apr 20 06:14:01.309: INFO: Created: latency-svc-69zn9
Apr 20 06:14:01.339: INFO: Got endpoints: latency-svc-m5s6z [750.730556ms]
Apr 20 06:14:01.363: INFO: Created: latency-svc-vhp8z
Apr 20 06:14:01.397: INFO: Got endpoints: latency-svc-96mnj [758.24866ms]
Apr 20 06:14:01.410: INFO: Created: latency-svc-8cxcw
Apr 20 06:14:01.446: INFO: Got endpoints: latency-svc-b5bpt [757.091711ms]
Apr 20 06:14:01.472: INFO: Created: latency-svc-gljfj
Apr 20 06:14:01.490: INFO: Got endpoints: latency-svc-hj9mp [748.768541ms]
Apr 20 06:14:01.503: INFO: Created: latency-svc-9jlsf
Apr 20 06:14:01.538: INFO: Got endpoints: latency-svc-sc8pn [749.011588ms]
Apr 20 06:14:01.552: INFO: Created: latency-svc-hmw9v
Apr 20 06:14:01.590: INFO: Got endpoints: latency-svc-k6cjd [752.280535ms]
Apr 20 06:14:01.605: INFO: Created: latency-svc-swjjb
Apr 20 06:14:01.639: INFO: Got endpoints: latency-svc-nqd67 [749.311141ms]
Apr 20 06:14:01.655: INFO: Created: latency-svc-pmnlr
Apr 20 06:14:01.689: INFO: Got endpoints: latency-svc-fwdfx [742.294993ms]
Apr 20 06:14:01.731: INFO: Created: latency-svc-znpth
Apr 20 06:14:01.738: INFO: Got endpoints: latency-svc-wdkcq [749.688979ms]
Apr 20 06:14:01.752: INFO: Created: latency-svc-jl8c5
Apr 20 06:14:01.791: INFO: Got endpoints: latency-svc-wnp8r [752.443127ms]
Apr 20 06:14:01.809: INFO: Created: latency-svc-pdwlv
Apr 20 06:14:01.841: INFO: Got endpoints: latency-svc-p88l7 [752.650645ms]
Apr 20 06:14:01.855: INFO: Created: latency-svc-nxsgp
Apr 20 06:14:01.901: INFO: Got endpoints: latency-svc-97cmk [761.684407ms]
Apr 20 06:14:01.927: INFO: Created: latency-svc-qfbw7
Apr 20 06:14:01.946: INFO: Got endpoints: latency-svc-9s5dk [755.0935ms]
Apr 20 06:14:01.979: INFO: Created: latency-svc-kfdbk
Apr 20 06:14:01.986: INFO: Got endpoints: latency-svc-xcpt4 [747.260077ms]
Apr 20 06:14:02.011: INFO: Created: latency-svc-vrjqm
Apr 20 06:14:02.048: INFO: Got endpoints: latency-svc-69zn9 [755.873161ms]
Apr 20 06:14:02.062: INFO: Created: latency-svc-jd2x4
Apr 20 06:14:02.099: INFO: Got endpoints: latency-svc-vhp8z [759.016616ms]
Apr 20 06:14:02.139: INFO: Created: latency-svc-5dwfg
Apr 20 06:14:02.141: INFO: Got endpoints: latency-svc-8cxcw [743.481429ms]
Apr 20 06:14:02.192: INFO: Created: latency-svc-bnps2
Apr 20 06:14:02.195: INFO: Got endpoints: latency-svc-gljfj [748.37277ms]
Apr 20 06:14:02.230: INFO: Created: latency-svc-9qsh4
Apr 20 06:14:02.242: INFO: Got endpoints: latency-svc-9jlsf [751.319908ms]
Apr 20 06:14:02.303: INFO: Got endpoints: latency-svc-hmw9v [765.247318ms]
Apr 20 06:14:02.304: INFO: Created: latency-svc-zbv8r
Apr 20 06:14:02.324: INFO: Created: latency-svc-bvg89
Apr 20 06:14:02.346: INFO: Got endpoints: latency-svc-swjjb [755.48504ms]
Apr 20 06:14:02.366: INFO: Created: latency-svc-l7bqw
Apr 20 06:14:02.401: INFO: Got endpoints: latency-svc-pmnlr [761.679424ms]
Apr 20 06:14:02.419: INFO: Created: latency-svc-9frxk
Apr 20 06:14:02.446: INFO: Got endpoints: latency-svc-znpth [757.515835ms]
Apr 20 06:14:02.464: INFO: Created: latency-svc-px9p6
Apr 20 06:14:02.492: INFO: Got endpoints: latency-svc-jl8c5 [753.3452ms]
Apr 20 06:14:02.516: INFO: Created: latency-svc-ggcqw
Apr 20 06:14:02.565: INFO: Got endpoints: latency-svc-pdwlv [773.615865ms]
Apr 20 06:14:02.591: INFO: Created: latency-svc-vtngq
Apr 20 06:14:02.592: INFO: Got endpoints: latency-svc-nxsgp [750.265578ms]
Apr 20 06:14:02.647: INFO: Got endpoints: latency-svc-qfbw7 [745.809435ms]
Apr 20 06:14:02.677: INFO: Created: latency-svc-wkdgr
Apr 20 06:14:02.726: INFO: Created: latency-svc-wnq4l
Apr 20 06:14:02.727: INFO: Got endpoints: latency-svc-kfdbk [780.181194ms]
Apr 20 06:14:02.749: INFO: Got endpoints: latency-svc-vrjqm [762.828156ms]
Apr 20 06:14:02.766: INFO: Created: latency-svc-kb9v8
Apr 20 06:14:02.796: INFO: Got endpoints: latency-svc-jd2x4 [747.68046ms]
Apr 20 06:14:02.815: INFO: Created: latency-svc-7vhgk
Apr 20 06:14:02.838: INFO: Created: latency-svc-42q56
Apr 20 06:14:02.838: INFO: Got endpoints: latency-svc-5dwfg [739.558267ms]
Apr 20 06:14:02.859: INFO: Created: latency-svc-bgrwk
Apr 20 06:14:02.895: INFO: Got endpoints: latency-svc-bnps2 [754.008798ms]
Apr 20 06:14:02.907: INFO: Created: latency-svc-69fpw
Apr 20 06:14:02.945: INFO: Got endpoints: latency-svc-9qsh4 [749.972192ms]
Apr 20 06:14:02.982: INFO: Created: latency-svc-vzhvq
Apr 20 06:14:03.003: INFO: Got endpoints: latency-svc-zbv8r [761.097754ms]
Apr 20 06:14:03.027: INFO: Created: latency-svc-55n5c
Apr 20 06:14:03.086: INFO: Got endpoints: latency-svc-bvg89 [782.358135ms]
Apr 20 06:14:03.093: INFO: Got endpoints: latency-svc-l7bqw [747.018517ms]
Apr 20 06:14:03.126: INFO: Created: latency-svc-47l96
Apr 20 06:14:03.158: INFO: Got endpoints: latency-svc-9frxk [756.964211ms]
Apr 20 06:14:03.159: INFO: Created: latency-svc-txcx7
Apr 20 06:14:03.180: INFO: Created: latency-svc-v9fs4
Apr 20 06:14:03.210: INFO: Got endpoints: latency-svc-px9p6 [763.640329ms]
Apr 20 06:14:03.232: INFO: Created: latency-svc-kn5fz
Apr 20 06:14:03.240: INFO: Got endpoints: latency-svc-ggcqw [748.112007ms]
Apr 20 06:14:03.255: INFO: Created: latency-svc-hr2ng
Apr 20 06:14:03.288: INFO: Got endpoints: latency-svc-vtngq [723.465398ms]
Apr 20 06:14:03.300: INFO: Created: latency-svc-tdh9n
Apr 20 06:14:03.338: INFO: Got endpoints: latency-svc-wkdgr [746.703459ms]
Apr 20 06:14:03.355: INFO: Created: latency-svc-lzb9h
Apr 20 06:14:03.393: INFO: Got endpoints: latency-svc-wnq4l [745.306015ms]
Apr 20 06:14:03.415: INFO: Created: latency-svc-vbw82
Apr 20 06:14:03.439: INFO: Got endpoints: latency-svc-kb9v8 [712.248135ms]
Apr 20 06:14:03.456: INFO: Created: latency-svc-97bs8
Apr 20 06:14:03.501: INFO: Got endpoints: latency-svc-7vhgk [751.92801ms]
Apr 20 06:14:03.575: INFO: Got endpoints: latency-svc-42q56 [779.151417ms]
Apr 20 06:14:03.587: INFO: Created: latency-svc-pbmrp
Apr 20 06:14:03.604: INFO: Got endpoints: latency-svc-bgrwk [765.549282ms]
Apr 20 06:14:03.605: INFO: Created: latency-svc-778kr
Apr 20 06:14:03.626: INFO: Created: latency-svc-tvk8x
Apr 20 06:14:03.641: INFO: Got endpoints: latency-svc-69fpw [745.864335ms]
Apr 20 06:14:03.653: INFO: Created: latency-svc-w97zp
Apr 20 06:14:03.688: INFO: Got endpoints: latency-svc-vzhvq [742.99066ms]
Apr 20 06:14:03.698: INFO: Created: latency-svc-9z77t
Apr 20 06:14:03.740: INFO: Got endpoints: latency-svc-55n5c [736.703082ms]
Apr 20 06:14:03.753: INFO: Created: latency-svc-lcs76
Apr 20 06:14:03.789: INFO: Got endpoints: latency-svc-47l96 [703.577264ms]
Apr 20 06:14:03.800: INFO: Created: latency-svc-qn6sf
Apr 20 06:14:03.838: INFO: Got endpoints: latency-svc-txcx7 [745.441903ms]
Apr 20 06:14:03.854: INFO: Created: latency-svc-czmvk
Apr 20 06:14:03.891: INFO: Got endpoints: latency-svc-v9fs4 [732.743022ms]
Apr 20 06:14:03.905: INFO: Created: latency-svc-45x94
Apr 20 06:14:03.938: INFO: Got endpoints: latency-svc-kn5fz [727.086237ms]
Apr 20 06:14:03.955: INFO: Created: latency-svc-9f7q7
Apr 20 06:14:03.992: INFO: Got endpoints: latency-svc-hr2ng [751.59779ms]
Apr 20 06:14:04.002: INFO: Created: latency-svc-hltfk
Apr 20 06:14:04.039: INFO: Got endpoints: latency-svc-tdh9n [750.681278ms]
Apr 20 06:14:04.053: INFO: Created: latency-svc-lgm9h
Apr 20 06:14:04.090: INFO: Got endpoints: latency-svc-lzb9h [751.162171ms]
Apr 20 06:14:04.100: INFO: Created: latency-svc-t5rtk
Apr 20 06:14:04.140: INFO: Got endpoints: latency-svc-vbw82 [747.665438ms]
Apr 20 06:14:04.151: INFO: Created: latency-svc-vbzwn
Apr 20 06:14:04.188: INFO: Got endpoints: latency-svc-97bs8 [749.344256ms]
Apr 20 06:14:04.240: INFO: Got endpoints: latency-svc-pbmrp [738.275335ms]
Apr 20 06:14:04.249: INFO: Created: latency-svc-8rgsh
Apr 20 06:14:04.249: INFO: Created: latency-svc-8w9sv
Apr 20 06:14:04.289: INFO: Got endpoints: latency-svc-778kr [713.353929ms]
Apr 20 06:14:04.299: INFO: Created: latency-svc-vxntt
Apr 20 06:14:04.338: INFO: Got endpoints: latency-svc-tvk8x [734.34408ms]
Apr 20 06:14:04.349: INFO: Created: latency-svc-hmt5k
Apr 20 06:14:04.389: INFO: Got endpoints: latency-svc-w97zp [748.63719ms]
Apr 20 06:14:04.400: INFO: Created: latency-svc-lllv2
Apr 20 06:14:04.439: INFO: Got endpoints: latency-svc-9z77t [750.418433ms]
Apr 20 06:14:04.456: INFO: Created: latency-svc-f56zd
Apr 20 06:14:04.490: INFO: Got endpoints: latency-svc-lcs76 [749.543226ms]
Apr 20 06:14:04.502: INFO: Created: latency-svc-5dq6g
Apr 20 06:14:04.538: INFO: Got endpoints: latency-svc-qn6sf [748.332468ms]
Apr 20 06:14:04.548: INFO: Created: latency-svc-lrrb7
Apr 20 06:14:04.589: INFO: Got endpoints: latency-svc-czmvk [750.307066ms]
Apr 20 06:14:04.600: INFO: Created: latency-svc-nh6jn
Apr 20 06:14:04.638: INFO: Got endpoints: latency-svc-45x94 [747.072552ms]
Apr 20 06:14:04.651: INFO: Created: latency-svc-n6jh7
Apr 20 06:14:04.688: INFO: Got endpoints: latency-svc-9f7q7 [750.204506ms]
Apr 20 06:14:04.705: INFO: Created: latency-svc-f2vng
Apr 20 06:14:04.738: INFO: Got endpoints: latency-svc-hltfk [746.709022ms]
Apr 20 06:14:04.750: INFO: Created: latency-svc-pfgnh
Apr 20 06:14:04.787: INFO: Got endpoints: latency-svc-lgm9h [748.455341ms]
Apr 20 06:14:04.825: INFO: Created: latency-svc-6sddj
Apr 20 06:14:04.838: INFO: Got endpoints: latency-svc-t5rtk [748.358827ms]
Apr 20 06:14:04.867: INFO: Created: latency-svc-znmmb
Apr 20 06:14:04.889: INFO: Got endpoints: latency-svc-vbzwn [748.482227ms]
Apr 20 06:14:04.899: INFO: Created: latency-svc-4np8c
Apr 20 06:14:04.940: INFO: Got endpoints: latency-svc-8rgsh [751.413435ms]
Apr 20 06:14:04.953: INFO: Created: latency-svc-4hgk9
Apr 20 06:14:04.990: INFO: Got endpoints: latency-svc-8w9sv [750.466422ms]
Apr 20 06:14:05.008: INFO: Created: latency-svc-428vb
Apr 20 06:14:05.038: INFO: Got endpoints: latency-svc-vxntt [749.476554ms]
Apr 20 06:14:05.089: INFO: Got endpoints: latency-svc-hmt5k [750.954454ms]
Apr 20 06:14:05.139: INFO: Got endpoints: latency-svc-lllv2 [749.683757ms]
Apr 20 06:14:05.188: INFO: Got endpoints: latency-svc-f56zd [749.668374ms]
Apr 20 06:14:05.238: INFO: Got endpoints: latency-svc-5dq6g [748.563484ms]
Apr 20 06:14:05.287: INFO: Got endpoints: latency-svc-lrrb7 [749.587373ms]
Apr 20 06:14:05.338: INFO: Got endpoints: latency-svc-nh6jn [749.053722ms]
Apr 20 06:14:05.389: INFO: Got endpoints: latency-svc-n6jh7 [750.819439ms]
Apr 20 06:14:05.437: INFO: Got endpoints: latency-svc-f2vng [749.087333ms]
Apr 20 06:14:05.489: INFO: Got endpoints: latency-svc-pfgnh [750.710177ms]
Apr 20 06:14:05.541: INFO: Got endpoints: latency-svc-6sddj [753.462386ms]
Apr 20 06:14:05.589: INFO: Got endpoints: latency-svc-znmmb [751.016904ms]
Apr 20 06:14:05.639: INFO: Got endpoints: latency-svc-4np8c [749.94558ms]
Apr 20 06:14:05.689: INFO: Got endpoints: latency-svc-4hgk9 [748.782009ms]
Apr 20 06:14:05.739: INFO: Got endpoints: latency-svc-428vb [748.873002ms]
Apr 20 06:14:05.739: INFO: Latencies: [25.04219ms 25.211898ms 33.688451ms 60.89852ms 78.09218ms 97.659246ms 128.180137ms 139.354602ms 150.023942ms 161.052667ms 190.976679ms 206.010084ms 209.346173ms 212.729564ms 216.748987ms 217.371999ms 217.791779ms 220.930247ms 223.395793ms 226.699997ms 227.214677ms 227.910572ms 228.225889ms 228.405213ms 229.246057ms 229.444173ms 231.425198ms 234.393048ms 235.082604ms 235.257003ms 235.990523ms 237.300118ms 237.334979ms 237.746837ms 238.162151ms 239.949312ms 240.567503ms 241.548703ms 241.859558ms 243.543621ms 252.034151ms 255.866637ms 265.886246ms 308.90237ms 325.848804ms 363.863437ms 401.236376ms 419.679184ms 457.134434ms 496.010438ms 530.920198ms 568.807368ms 605.022342ms 622.478126ms 663.929822ms 692.864737ms 703.577264ms 712.248135ms 713.353929ms 723.465398ms 724.6315ms 727.086237ms 731.597315ms 732.743022ms 733.157252ms 734.34408ms 736.703082ms 738.275335ms 739.270331ms 739.558267ms 740.762803ms 742.294993ms 742.99066ms 743.481429ms 744.338391ms 744.558124ms 745.122283ms 745.306015ms 745.441903ms 745.623978ms 745.809435ms 745.864335ms 746.703459ms 746.709022ms 746.80965ms 747.018517ms 747.072552ms 747.192201ms 747.260077ms 747.462648ms 747.58692ms 747.665438ms 747.68046ms 747.832658ms 747.907278ms 747.908772ms 748.012773ms 748.093415ms 748.112007ms 748.298393ms 748.332468ms 748.358827ms 748.37277ms 748.455341ms 748.482227ms 748.563484ms 748.63719ms 748.649894ms 748.768541ms 748.782009ms 748.873002ms 748.936133ms 748.955452ms 748.963872ms 749.011588ms 749.026586ms 749.028378ms 749.053722ms 749.087333ms 749.167441ms 749.233275ms 749.311141ms 749.344256ms 749.476554ms 749.543226ms 749.587373ms 749.668374ms 749.683757ms 749.688979ms 749.94558ms 749.972192ms 750.092918ms 750.123961ms 750.204506ms 750.265578ms 750.289304ms 750.307066ms 750.319496ms 750.418433ms 750.447211ms 750.466422ms 750.539904ms 750.620236ms 750.681278ms 750.710177ms 750.717005ms 750.730556ms 750.819439ms 750.954454ms 751.016904ms 751.017576ms 751.028958ms 751.162171ms 751.213552ms 751.222547ms 751.285832ms 751.319908ms 751.413435ms 751.428574ms 751.476566ms 751.59779ms 751.92801ms 751.964478ms 752.139903ms 752.280535ms 752.394369ms 752.443127ms 752.650645ms 752.935724ms 752.982027ms 753.273293ms 753.3452ms 753.462386ms 753.723441ms 754.008798ms 754.579459ms 755.0935ms 755.48504ms 755.873161ms 756.451527ms 756.964211ms 757.091711ms 757.515835ms 758.24866ms 758.705941ms 758.945079ms 759.016616ms 761.097754ms 761.679424ms 761.684407ms 761.767391ms 762.828156ms 763.640329ms 764.602614ms 765.247318ms 765.549282ms 773.615865ms 779.151417ms 780.181194ms 782.358135ms]
Apr 20 06:14:05.739: INFO: 50 %ile: 748.332468ms
Apr 20 06:14:05.739: INFO: 90 %ile: 756.964211ms
Apr 20 06:14:05.739: INFO: 99 %ile: 780.181194ms
Apr 20 06:14:05.739: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:14:05.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-5838" for this suite.

• [SLOW TEST:10.819 seconds]
[sig-network] Service endpoints latency
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":346,"completed":89,"skipped":1672,"failed":0}
S
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:14:05.749: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0420 06:14:11.819575      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr 20 06:14:11.819: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:14:11.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7389" for this suite.

• [SLOW TEST:6.080 seconds]
[sig-api-machinery] Garbage collector
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":346,"completed":90,"skipped":1673,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:14:11.830: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-129bff56-84da-4eca-8d9f-e39e0e7866b5
STEP: Creating a pod to test consume configMaps
Apr 20 06:14:11.872: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-cf3155e9-4b31-463b-9880-93aac289821b" in namespace "projected-208" to be "Succeeded or Failed"
Apr 20 06:14:11.876: INFO: Pod "pod-projected-configmaps-cf3155e9-4b31-463b-9880-93aac289821b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.228791ms
Apr 20 06:14:13.887: INFO: Pod "pod-projected-configmaps-cf3155e9-4b31-463b-9880-93aac289821b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014179061s
STEP: Saw pod success
Apr 20 06:14:13.887: INFO: Pod "pod-projected-configmaps-cf3155e9-4b31-463b-9880-93aac289821b" satisfied condition "Succeeded or Failed"
Apr 20 06:14:13.891: INFO: Trying to get logs from node node22-hwh1v pod pod-projected-configmaps-cf3155e9-4b31-463b-9880-93aac289821b container agnhost-container: <nil>
STEP: delete the pod
Apr 20 06:14:13.945: INFO: Waiting for pod pod-projected-configmaps-cf3155e9-4b31-463b-9880-93aac289821b to disappear
Apr 20 06:14:13.955: INFO: Pod pod-projected-configmaps-cf3155e9-4b31-463b-9880-93aac289821b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:14:13.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-208" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":346,"completed":91,"skipped":1705,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:14:13.972: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name projected-secret-test-4574e657-6aa5-4100-9262-1b55a6f998c0
STEP: Creating a pod to test consume secrets
Apr 20 06:14:14.045: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-95dc4435-22d5-403a-a370-d2cc945ea6c8" in namespace "projected-8872" to be "Succeeded or Failed"
Apr 20 06:14:14.055: INFO: Pod "pod-projected-secrets-95dc4435-22d5-403a-a370-d2cc945ea6c8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.087145ms
Apr 20 06:14:16.062: INFO: Pod "pod-projected-secrets-95dc4435-22d5-403a-a370-d2cc945ea6c8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016150862s
STEP: Saw pod success
Apr 20 06:14:16.062: INFO: Pod "pod-projected-secrets-95dc4435-22d5-403a-a370-d2cc945ea6c8" satisfied condition "Succeeded or Failed"
Apr 20 06:14:16.064: INFO: Trying to get logs from node node22-wriki pod pod-projected-secrets-95dc4435-22d5-403a-a370-d2cc945ea6c8 container secret-volume-test: <nil>
STEP: delete the pod
Apr 20 06:14:16.077: INFO: Waiting for pod pod-projected-secrets-95dc4435-22d5-403a-a370-d2cc945ea6c8 to disappear
Apr 20 06:14:16.079: INFO: Pod pod-projected-secrets-95dc4435-22d5-403a-a370-d2cc945ea6c8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:14:16.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8872" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":346,"completed":92,"skipped":1712,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:14:16.088: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service in namespace services-2922
Apr 20 06:14:16.121: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:14:18.126: INFO: The status of Pod kube-proxy-mode-detector is Running (Ready = true)
Apr 20 06:14:18.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-2922 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Apr 20 06:14:18.252: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Apr 20 06:14:18.252: INFO: stdout: "iptables"
Apr 20 06:14:18.252: INFO: proxyMode: iptables
Apr 20 06:14:18.263: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Apr 20 06:14:18.265: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-2922
STEP: creating replication controller affinity-nodeport-timeout in namespace services-2922
I0420 06:14:18.287408      20 runners.go:190] Created replication controller with name: affinity-nodeport-timeout, namespace: services-2922, replica count: 3
I0420 06:14:21.337986      20 runners.go:190] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 20 06:14:21.344: INFO: Creating new exec pod
Apr 20 06:14:24.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-2922 exec execpod-affinity5tc6d -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Apr 20 06:14:24.494: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Apr 20 06:14:24.494: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 20 06:14:24.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-2922 exec execpod-affinity5tc6d -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.109.37.158 80'
Apr 20 06:14:24.610: INFO: stderr: "+ nc -v -t -w 2 10.109.37.158 80\n+ echo hostName\nConnection to 10.109.37.158 80 port [tcp/http] succeeded!\n"
Apr 20 06:14:24.610: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 20 06:14:24.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-2922 exec execpod-affinity5tc6d -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.118.168 30185'
Apr 20 06:14:24.722: INFO: stderr: "+ nc -v -t -w 2 10.100.118.168 30185\n+ echo hostName\nConnection to 10.100.118.168 30185 port [tcp/*] succeeded!\n"
Apr 20 06:14:24.722: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 20 06:14:24.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-2922 exec execpod-affinity5tc6d -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.125.144 30185'
Apr 20 06:14:24.842: INFO: stderr: "+ nc -v -t -w 2 10.100.125.144 30185\n+ echo hostName\nConnection to 10.100.125.144 30185 port [tcp/*] succeeded!\n"
Apr 20 06:14:24.842: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 20 06:14:24.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-2922 exec execpod-affinity5tc6d -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.100.118.168:30185/ ; done'
Apr 20 06:14:25.030: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30185/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30185/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30185/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30185/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30185/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30185/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30185/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30185/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30185/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30185/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30185/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30185/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30185/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30185/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30185/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30185/\n"
Apr 20 06:14:25.030: INFO: stdout: "\naffinity-nodeport-timeout-sc6pb\naffinity-nodeport-timeout-sc6pb\naffinity-nodeport-timeout-sc6pb\naffinity-nodeport-timeout-sc6pb\naffinity-nodeport-timeout-sc6pb\naffinity-nodeport-timeout-sc6pb\naffinity-nodeport-timeout-sc6pb\naffinity-nodeport-timeout-sc6pb\naffinity-nodeport-timeout-sc6pb\naffinity-nodeport-timeout-sc6pb\naffinity-nodeport-timeout-sc6pb\naffinity-nodeport-timeout-sc6pb\naffinity-nodeport-timeout-sc6pb\naffinity-nodeport-timeout-sc6pb\naffinity-nodeport-timeout-sc6pb\naffinity-nodeport-timeout-sc6pb"
Apr 20 06:14:25.030: INFO: Received response from host: affinity-nodeport-timeout-sc6pb
Apr 20 06:14:25.030: INFO: Received response from host: affinity-nodeport-timeout-sc6pb
Apr 20 06:14:25.030: INFO: Received response from host: affinity-nodeport-timeout-sc6pb
Apr 20 06:14:25.030: INFO: Received response from host: affinity-nodeport-timeout-sc6pb
Apr 20 06:14:25.030: INFO: Received response from host: affinity-nodeport-timeout-sc6pb
Apr 20 06:14:25.030: INFO: Received response from host: affinity-nodeport-timeout-sc6pb
Apr 20 06:14:25.030: INFO: Received response from host: affinity-nodeport-timeout-sc6pb
Apr 20 06:14:25.030: INFO: Received response from host: affinity-nodeport-timeout-sc6pb
Apr 20 06:14:25.030: INFO: Received response from host: affinity-nodeport-timeout-sc6pb
Apr 20 06:14:25.030: INFO: Received response from host: affinity-nodeport-timeout-sc6pb
Apr 20 06:14:25.030: INFO: Received response from host: affinity-nodeport-timeout-sc6pb
Apr 20 06:14:25.030: INFO: Received response from host: affinity-nodeport-timeout-sc6pb
Apr 20 06:14:25.030: INFO: Received response from host: affinity-nodeport-timeout-sc6pb
Apr 20 06:14:25.030: INFO: Received response from host: affinity-nodeport-timeout-sc6pb
Apr 20 06:14:25.030: INFO: Received response from host: affinity-nodeport-timeout-sc6pb
Apr 20 06:14:25.030: INFO: Received response from host: affinity-nodeport-timeout-sc6pb
Apr 20 06:14:25.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-2922 exec execpod-affinity5tc6d -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.100.118.168:30185/'
Apr 20 06:14:25.143: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.100.118.168:30185/\n"
Apr 20 06:14:25.143: INFO: stdout: "affinity-nodeport-timeout-sc6pb"
Apr 20 06:14:45.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-2922 exec execpod-affinity5tc6d -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.100.118.168:30185/'
Apr 20 06:14:45.288: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.100.118.168:30185/\n"
Apr 20 06:14:45.288: INFO: stdout: "affinity-nodeport-timeout-c6765"
Apr 20 06:14:45.288: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-2922, will wait for the garbage collector to delete the pods
Apr 20 06:14:45.376: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 5.361844ms
Apr 20 06:14:45.487: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 111.037662ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:14:47.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2922" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:31.233 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","total":346,"completed":93,"skipped":1734,"failed":0}
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:14:47.320: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0420 06:15:27.388567      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr 20 06:15:27.388: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Apr 20 06:15:27.388: INFO: Deleting pod "simpletest.rc-29r6l" in namespace "gc-3971"
Apr 20 06:15:27.413: INFO: Deleting pod "simpletest.rc-2c224" in namespace "gc-3971"
Apr 20 06:15:27.432: INFO: Deleting pod "simpletest.rc-78zb8" in namespace "gc-3971"
Apr 20 06:15:27.442: INFO: Deleting pod "simpletest.rc-8kct7" in namespace "gc-3971"
Apr 20 06:15:27.452: INFO: Deleting pod "simpletest.rc-hfpmg" in namespace "gc-3971"
Apr 20 06:15:27.464: INFO: Deleting pod "simpletest.rc-jfvcb" in namespace "gc-3971"
Apr 20 06:15:27.486: INFO: Deleting pod "simpletest.rc-t9ft4" in namespace "gc-3971"
Apr 20 06:15:27.499: INFO: Deleting pod "simpletest.rc-w8hz4" in namespace "gc-3971"
Apr 20 06:15:27.529: INFO: Deleting pod "simpletest.rc-wvwzg" in namespace "gc-3971"
Apr 20 06:15:27.546: INFO: Deleting pod "simpletest.rc-zdtgz" in namespace "gc-3971"
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:15:27.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3971" for this suite.

• [SLOW TEST:40.303 seconds]
[sig-api-machinery] Garbage collector
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":346,"completed":94,"skipped":1735,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:15:27.657: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-map-97186e2c-3cb8-4b42-b131-2ba6d2382826
STEP: Creating a pod to test consume configMaps
Apr 20 06:15:27.752: INFO: Waiting up to 5m0s for pod "pod-configmaps-27f77d61-fcae-44f6-b0d6-500b09fb5f12" in namespace "configmap-8495" to be "Succeeded or Failed"
Apr 20 06:15:27.755: INFO: Pod "pod-configmaps-27f77d61-fcae-44f6-b0d6-500b09fb5f12": Phase="Pending", Reason="", readiness=false. Elapsed: 1.982305ms
Apr 20 06:15:29.761: INFO: Pod "pod-configmaps-27f77d61-fcae-44f6-b0d6-500b09fb5f12": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008251152s
STEP: Saw pod success
Apr 20 06:15:29.761: INFO: Pod "pod-configmaps-27f77d61-fcae-44f6-b0d6-500b09fb5f12" satisfied condition "Succeeded or Failed"
Apr 20 06:15:29.763: INFO: Trying to get logs from node node22-wriki pod pod-configmaps-27f77d61-fcae-44f6-b0d6-500b09fb5f12 container agnhost-container: <nil>
STEP: delete the pod
Apr 20 06:15:29.779: INFO: Waiting for pod pod-configmaps-27f77d61-fcae-44f6-b0d6-500b09fb5f12 to disappear
Apr 20 06:15:29.780: INFO: Pod pod-configmaps-27f77d61-fcae-44f6-b0d6-500b09fb5f12 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:15:29.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8495" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":95,"skipped":1779,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should succeed in writing subpaths in container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:15:29.787: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
STEP: waiting for pod running
STEP: creating a file in subpath
Apr 20 06:15:31.832: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-2853 PodName:var-expansion-2b03b1e5-1a3b-4220-a722-936fe9177c04 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 06:15:31.832: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: test for file in mounted path
Apr 20 06:15:31.900: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-2853 PodName:var-expansion-2b03b1e5-1a3b-4220-a722-936fe9177c04 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 06:15:31.900: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: updating the annotation value
Apr 20 06:15:32.474: INFO: Successfully updated pod "var-expansion-2b03b1e5-1a3b-4220-a722-936fe9177c04"
STEP: waiting for annotated pod running
STEP: deleting the pod gracefully
Apr 20 06:15:32.476: INFO: Deleting pod "var-expansion-2b03b1e5-1a3b-4220-a722-936fe9177c04" in namespace "var-expansion-2853"
Apr 20 06:15:32.481: INFO: Wait up to 5m0s for pod "var-expansion-2b03b1e5-1a3b-4220-a722-936fe9177c04" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:16:06.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2853" for this suite.

• [SLOW TEST:36.710 seconds]
[sig-node] Variable Expansion
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","total":346,"completed":96,"skipped":1796,"failed":0}
S
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:16:06.498: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:82
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:16:10.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9531" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":346,"completed":97,"skipped":1797,"failed":0}
S
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:16:10.556: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr 20 06:16:10.595: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0a98c20a-efc7-49c7-aed2-c8d8972cb6dd" in namespace "downward-api-5126" to be "Succeeded or Failed"
Apr 20 06:16:10.597: INFO: Pod "downwardapi-volume-0a98c20a-efc7-49c7-aed2-c8d8972cb6dd": Phase="Pending", Reason="", readiness=false. Elapsed: 1.892566ms
Apr 20 06:16:12.603: INFO: Pod "downwardapi-volume-0a98c20a-efc7-49c7-aed2-c8d8972cb6dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007434887s
STEP: Saw pod success
Apr 20 06:16:12.603: INFO: Pod "downwardapi-volume-0a98c20a-efc7-49c7-aed2-c8d8972cb6dd" satisfied condition "Succeeded or Failed"
Apr 20 06:16:12.606: INFO: Trying to get logs from node node22-wriki pod downwardapi-volume-0a98c20a-efc7-49c7-aed2-c8d8972cb6dd container client-container: <nil>
STEP: delete the pod
Apr 20 06:16:12.627: INFO: Waiting for pod downwardapi-volume-0a98c20a-efc7-49c7-aed2-c8d8972cb6dd to disappear
Apr 20 06:16:12.629: INFO: Pod downwardapi-volume-0a98c20a-efc7-49c7-aed2-c8d8972cb6dd no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:16:12.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5126" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":98,"skipped":1798,"failed":0}
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:16:12.636: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Apr 20 06:16:12.703: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-3016  aa613a34-2e62-4669-92ca-7fe305eff40c 14954 0 2022-04-20 06:16:12 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2022-04-20 06:16:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 20 06:16:12.703: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-3016  aa613a34-2e62-4669-92ca-7fe305eff40c 14955 0 2022-04-20 06:16:12 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2022-04-20 06:16:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:16:12.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3016" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":346,"completed":99,"skipped":1799,"failed":0}

------------------------------
[sig-node] RuntimeClass 
   should support RuntimeClasses API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] RuntimeClass
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:16:12.715: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
[It]  should support RuntimeClasses API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting /apis
STEP: getting /apis/node.k8s.io
STEP: getting /apis/node.k8s.io/v1
STEP: creating
STEP: watching
Apr 20 06:16:12.777: INFO: starting watch
STEP: getting
STEP: listing
STEP: patching
STEP: updating
Apr 20 06:16:12.797: INFO: waiting for watch events with expected annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-node] RuntimeClass
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:16:12.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-4861" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","total":346,"completed":100,"skipped":1799,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:16:12.825: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:16:12.855: INFO: Got root ca configmap in namespace "svcaccounts-5648"
Apr 20 06:16:12.860: INFO: Deleted root ca configmap in namespace "svcaccounts-5648"
STEP: waiting for a new root ca configmap created
Apr 20 06:16:13.363: INFO: Recreated root ca configmap in namespace "svcaccounts-5648"
Apr 20 06:16:13.367: INFO: Updated root ca configmap in namespace "svcaccounts-5648"
STEP: waiting for the root ca configmap reconciled
Apr 20 06:16:13.871: INFO: Reconciled root ca configmap in namespace "svcaccounts-5648"
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:16:13.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5648" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","total":346,"completed":101,"skipped":1849,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:16:13.880: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr 20 06:16:13.917: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e2b7d531-45dd-4408-9faf-cec84b174470" in namespace "projected-2200" to be "Succeeded or Failed"
Apr 20 06:16:13.920: INFO: Pod "downwardapi-volume-e2b7d531-45dd-4408-9faf-cec84b174470": Phase="Pending", Reason="", readiness=false. Elapsed: 2.756768ms
Apr 20 06:16:15.925: INFO: Pod "downwardapi-volume-e2b7d531-45dd-4408-9faf-cec84b174470": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008296052s
STEP: Saw pod success
Apr 20 06:16:15.925: INFO: Pod "downwardapi-volume-e2b7d531-45dd-4408-9faf-cec84b174470" satisfied condition "Succeeded or Failed"
Apr 20 06:16:15.931: INFO: Trying to get logs from node node22-wriki pod downwardapi-volume-e2b7d531-45dd-4408-9faf-cec84b174470 container client-container: <nil>
STEP: delete the pod
Apr 20 06:16:15.945: INFO: Waiting for pod downwardapi-volume-e2b7d531-45dd-4408-9faf-cec84b174470 to disappear
Apr 20 06:16:15.947: INFO: Pod downwardapi-volume-e2b7d531-45dd-4408-9faf-cec84b174470 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:16:15.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2200" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":346,"completed":102,"skipped":1880,"failed":0}
SSSSSS
------------------------------
[sig-node] PodTemplates 
  should delete a collection of pod templates [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] PodTemplates
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:16:15.954: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a collection of pod templates [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create set of pod templates
Apr 20 06:16:15.985: INFO: created test-podtemplate-1
Apr 20 06:16:15.988: INFO: created test-podtemplate-2
Apr 20 06:16:15.991: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace
STEP: delete collection of pod templates
Apr 20 06:16:15.993: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity
Apr 20 06:16:16.006: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:16:16.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-1258" for this suite.
•{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","total":346,"completed":103,"skipped":1886,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:16:16.015: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating the pod
Apr 20 06:16:16.063: INFO: The status of Pod labelsupdatee058cf0c-2e72-4a4e-a3c6-43162a6520fb is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:16:18.069: INFO: The status of Pod labelsupdatee058cf0c-2e72-4a4e-a3c6-43162a6520fb is Running (Ready = true)
Apr 20 06:16:18.587: INFO: Successfully updated pod "labelsupdatee058cf0c-2e72-4a4e-a3c6-43162a6520fb"
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:16:22.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-475" for this suite.

• [SLOW TEST:6.601 seconds]
[sig-storage] Downward API volume
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":346,"completed":104,"skipped":1894,"failed":0}
[sig-apps] DisruptionController 
  should update/patch PodDisruptionBudget status [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:16:22.617: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:69
[It] should update/patch PodDisruptionBudget status [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Waiting for the pdb to be processed
STEP: Updating PodDisruptionBudget status
STEP: Waiting for all pods to be running
Apr 20 06:16:24.688: INFO: running pods: 0 < 1
STEP: locating a running pod
STEP: Waiting for the pdb to be processed
STEP: Patching PodDisruptionBudget status
STEP: Waiting for the pdb to be processed
[AfterEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:16:26.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-7821" for this suite.
•{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","total":346,"completed":105,"skipped":1894,"failed":0}
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:16:26.733: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-1181b7c2-aed3-4875-9158-4d3f2302abf1
STEP: Creating a pod to test consume configMaps
Apr 20 06:16:26.770: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7350001f-e185-4bf4-b408-d1626efddc34" in namespace "projected-3569" to be "Succeeded or Failed"
Apr 20 06:16:26.772: INFO: Pod "pod-projected-configmaps-7350001f-e185-4bf4-b408-d1626efddc34": Phase="Pending", Reason="", readiness=false. Elapsed: 2.154885ms
Apr 20 06:16:28.777: INFO: Pod "pod-projected-configmaps-7350001f-e185-4bf4-b408-d1626efddc34": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006993972s
STEP: Saw pod success
Apr 20 06:16:28.777: INFO: Pod "pod-projected-configmaps-7350001f-e185-4bf4-b408-d1626efddc34" satisfied condition "Succeeded or Failed"
Apr 20 06:16:28.783: INFO: Trying to get logs from node node22-wriki pod pod-projected-configmaps-7350001f-e185-4bf4-b408-d1626efddc34 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 20 06:16:28.801: INFO: Waiting for pod pod-projected-configmaps-7350001f-e185-4bf4-b408-d1626efddc34 to disappear
Apr 20 06:16:28.803: INFO: Pod pod-projected-configmaps-7350001f-e185-4bf4-b408-d1626efddc34 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:16:28.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3569" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":346,"completed":106,"skipped":1897,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:16:28.816: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting a starting resourceVersion
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:16:33.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8330" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":346,"completed":107,"skipped":1911,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:16:33.725: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:16:35.774: INFO: Deleting pod "var-expansion-1bf7b38a-59d3-4b44-a5c8-8970d1574aa8" in namespace "var-expansion-7520"
Apr 20 06:16:35.781: INFO: Wait up to 5m0s for pod "var-expansion-1bf7b38a-59d3-4b44-a5c8-8970d1574aa8" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:16:39.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7520" for this suite.

• [SLOW TEST:6.075 seconds]
[sig-node] Variable Expansion
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","total":346,"completed":108,"skipped":1931,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:16:39.803: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:16:39.830: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Creating first CR 
Apr 20 06:16:42.496: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-04-20T06:16:42Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-04-20T06:16:42Z]] name:name1 resourceVersion:15432 uid:cb88148b-0820-4e87-8d4f-3d8c460351b2] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Apr 20 06:16:52.505: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-04-20T06:16:52Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-04-20T06:16:52Z]] name:name2 resourceVersion:15473 uid:fd0288f8-d51d-4497-92f2-65173e7886e5] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Apr 20 06:17:02.524: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-04-20T06:16:42Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-04-20T06:17:02Z]] name:name1 resourceVersion:15505 uid:cb88148b-0820-4e87-8d4f-3d8c460351b2] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Apr 20 06:17:12.532: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-04-20T06:16:52Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-04-20T06:17:12Z]] name:name2 resourceVersion:15537 uid:fd0288f8-d51d-4497-92f2-65173e7886e5] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Apr 20 06:17:22.545: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-04-20T06:16:42Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-04-20T06:17:02Z]] name:name1 resourceVersion:15569 uid:cb88148b-0820-4e87-8d4f-3d8c460351b2] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Apr 20 06:17:32.564: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-04-20T06:16:52Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-04-20T06:17:12Z]] name:name2 resourceVersion:15603 uid:fd0288f8-d51d-4497-92f2-65173e7886e5] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:17:43.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-9463" for this suite.

• [SLOW TEST:63.310 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":346,"completed":109,"skipped":1951,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:17:43.116: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:17:44.113: INFO: The status of Pod pod-secrets-90fe10a9-2609-4755-882f-fbf95c85b297 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:17:46.120: INFO: The status of Pod pod-secrets-90fe10a9-2609-4755-882f-fbf95c85b297 is Running (Ready = true)
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:17:46.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2188" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":346,"completed":110,"skipped":1990,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] DisruptionController 
  should block an eviction until the PDB is updated to allow it [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:17:46.149: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:69
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pdb that targets all three pods in a test replica set
STEP: Waiting for the pdb to be processed
STEP: First trying to evict a pod which shouldn't be evictable
STEP: Waiting for all pods to be running
Apr 20 06:17:46.201: INFO: pods: 0 < 3
Apr 20 06:17:48.207: INFO: running pods: 2 < 3
STEP: locating a running pod
STEP: Updating the pdb to allow a pod to be evicted
STEP: Waiting for the pdb to be processed
STEP: Trying to evict the same pod we tried earlier which should now be evictable
STEP: Waiting for all pods to be running
STEP: Waiting for the pdb to observed all healthy pods
STEP: Patching the pdb to disallow a pod to be evicted
STEP: Waiting for the pdb to be processed
STEP: Waiting for all pods to be running
Apr 20 06:17:52.291: INFO: running pods: 2 < 3
STEP: locating a running pod
STEP: Deleting the pdb to allow a pod to be evicted
STEP: Waiting for the pdb to be deleted
STEP: Trying to evict the same pod we tried earlier which should now be evictable
STEP: Waiting for all pods to be running
[AfterEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:17:54.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-6239" for this suite.

• [SLOW TEST:8.181 seconds]
[sig-apps] DisruptionController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","total":346,"completed":111,"skipped":1998,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:17:54.332: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-map-b30a5c20-7f62-4a45-b982-0d25982f47f7
STEP: Creating a pod to test consume secrets
Apr 20 06:17:54.407: INFO: Waiting up to 5m0s for pod "pod-secrets-925db02c-4c1d-41b0-8d47-ff07f702d0cb" in namespace "secrets-8202" to be "Succeeded or Failed"
Apr 20 06:17:54.416: INFO: Pod "pod-secrets-925db02c-4c1d-41b0-8d47-ff07f702d0cb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.59325ms
Apr 20 06:17:56.419: INFO: Pod "pod-secrets-925db02c-4c1d-41b0-8d47-ff07f702d0cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011939522s
STEP: Saw pod success
Apr 20 06:17:56.419: INFO: Pod "pod-secrets-925db02c-4c1d-41b0-8d47-ff07f702d0cb" satisfied condition "Succeeded or Failed"
Apr 20 06:17:56.422: INFO: Trying to get logs from node node22-hwh1v pod pod-secrets-925db02c-4c1d-41b0-8d47-ff07f702d0cb container secret-volume-test: <nil>
STEP: delete the pod
Apr 20 06:17:56.450: INFO: Waiting for pod pod-secrets-925db02c-4c1d-41b0-8d47-ff07f702d0cb to disappear
Apr 20 06:17:56.452: INFO: Pod pod-secrets-925db02c-4c1d-41b0-8d47-ff07f702d0cb no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:17:56.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8202" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":346,"completed":112,"skipped":2019,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:17:56.462: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Update Demo
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:296
[It] should create and stop a replication controller  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a replication controller
Apr 20 06:17:56.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-2683 create -f -'
Apr 20 06:17:56.653: INFO: stderr: ""
Apr 20 06:17:56.654: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 20 06:17:56.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-2683 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 20 06:17:56.709: INFO: stderr: ""
Apr 20 06:17:56.709: INFO: stdout: "update-demo-nautilus-7qrct update-demo-nautilus-jhgkx "
Apr 20 06:17:56.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-2683 get pods update-demo-nautilus-7qrct -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 20 06:17:56.761: INFO: stderr: ""
Apr 20 06:17:56.761: INFO: stdout: ""
Apr 20 06:17:56.761: INFO: update-demo-nautilus-7qrct is created but not running
Apr 20 06:18:01.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-2683 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 20 06:18:01.828: INFO: stderr: ""
Apr 20 06:18:01.828: INFO: stdout: "update-demo-nautilus-7qrct update-demo-nautilus-jhgkx "
Apr 20 06:18:01.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-2683 get pods update-demo-nautilus-7qrct -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 20 06:18:01.887: INFO: stderr: ""
Apr 20 06:18:01.887: INFO: stdout: "true"
Apr 20 06:18:01.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-2683 get pods update-demo-nautilus-7qrct -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 20 06:18:01.945: INFO: stderr: ""
Apr 20 06:18:01.945: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.4"
Apr 20 06:18:01.945: INFO: validating pod update-demo-nautilus-7qrct
Apr 20 06:18:01.953: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 20 06:18:01.953: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 20 06:18:01.953: INFO: update-demo-nautilus-7qrct is verified up and running
Apr 20 06:18:01.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-2683 get pods update-demo-nautilus-jhgkx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 20 06:18:02.018: INFO: stderr: ""
Apr 20 06:18:02.018: INFO: stdout: "true"
Apr 20 06:18:02.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-2683 get pods update-demo-nautilus-jhgkx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 20 06:18:02.071: INFO: stderr: ""
Apr 20 06:18:02.071: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.4"
Apr 20 06:18:02.071: INFO: validating pod update-demo-nautilus-jhgkx
Apr 20 06:18:02.081: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 20 06:18:02.081: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 20 06:18:02.081: INFO: update-demo-nautilus-jhgkx is verified up and running
STEP: using delete to clean up resources
Apr 20 06:18:02.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-2683 delete --grace-period=0 --force -f -'
Apr 20 06:18:02.153: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 20 06:18:02.153: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 20 06:18:02.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-2683 get rc,svc -l name=update-demo --no-headers'
Apr 20 06:18:02.215: INFO: stderr: "No resources found in kubectl-2683 namespace.\n"
Apr 20 06:18:02.215: INFO: stdout: ""
Apr 20 06:18:02.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-2683 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 20 06:18:02.275: INFO: stderr: ""
Apr 20 06:18:02.275: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:18:02.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2683" for this suite.

• [SLOW TEST:5.825 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:294
    should create and stop a replication controller  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":346,"completed":113,"skipped":2053,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:18:02.289: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 20 06:18:02.331: INFO: Waiting up to 5m0s for pod "pod-c1727c8b-55c5-4610-8d3f-f6e51a830f2e" in namespace "emptydir-4267" to be "Succeeded or Failed"
Apr 20 06:18:02.334: INFO: Pod "pod-c1727c8b-55c5-4610-8d3f-f6e51a830f2e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.647315ms
Apr 20 06:18:04.341: INFO: Pod "pod-c1727c8b-55c5-4610-8d3f-f6e51a830f2e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010630739s
STEP: Saw pod success
Apr 20 06:18:04.341: INFO: Pod "pod-c1727c8b-55c5-4610-8d3f-f6e51a830f2e" satisfied condition "Succeeded or Failed"
Apr 20 06:18:04.343: INFO: Trying to get logs from node node22-wriki pod pod-c1727c8b-55c5-4610-8d3f-f6e51a830f2e container test-container: <nil>
STEP: delete the pod
Apr 20 06:18:04.374: INFO: Waiting for pod pod-c1727c8b-55c5-4610-8d3f-f6e51a830f2e to disappear
Apr 20 06:18:04.377: INFO: Pod pod-c1727c8b-55c5-4610-8d3f-f6e51a830f2e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:18:04.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4267" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":114,"skipped":2103,"failed":0}
SSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:18:04.386: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support --unix-socket=/path  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Starting the proxy
Apr 20 06:18:04.420: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-1660 proxy --unix-socket=/tmp/kubectl-proxy-unix236322345/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:18:04.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1660" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":346,"completed":115,"skipped":2106,"failed":0}

------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:18:04.471: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:142
[It] should retry creating failed daemon pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 20 06:18:04.529: INFO: Number of nodes with available pods: 0
Apr 20 06:18:04.529: INFO: Node node22-07idr is running more than one daemon pod
Apr 20 06:18:05.537: INFO: Number of nodes with available pods: 1
Apr 20 06:18:05.538: INFO: Node node22-07idr is running more than one daemon pod
Apr 20 06:18:06.536: INFO: Number of nodes with available pods: 3
Apr 20 06:18:06.536: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Apr 20 06:18:06.561: INFO: Number of nodes with available pods: 2
Apr 20 06:18:06.561: INFO: Node node22-07idr is running more than one daemon pod
Apr 20 06:18:07.576: INFO: Number of nodes with available pods: 3
Apr 20 06:18:07.576: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:108
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6784, will wait for the garbage collector to delete the pods
Apr 20 06:18:07.640: INFO: Deleting DaemonSet.extensions daemon-set took: 7.051843ms
Apr 20 06:18:07.741: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.841505ms
Apr 20 06:18:10.650: INFO: Number of nodes with available pods: 0
Apr 20 06:18:10.650: INFO: Number of running nodes: 0, number of available pods: 0
Apr 20 06:18:10.652: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"16125"},"items":null}

Apr 20 06:18:10.654: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"16125"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:18:10.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6784" for this suite.

• [SLOW TEST:6.200 seconds]
[sig-apps] Daemon set [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":346,"completed":116,"skipped":2106,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:18:10.673: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr 20 06:18:10.712: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7a180818-6473-4941-a8ca-711676937645" in namespace "projected-9582" to be "Succeeded or Failed"
Apr 20 06:18:10.715: INFO: Pod "downwardapi-volume-7a180818-6473-4941-a8ca-711676937645": Phase="Pending", Reason="", readiness=false. Elapsed: 2.826134ms
Apr 20 06:18:12.721: INFO: Pod "downwardapi-volume-7a180818-6473-4941-a8ca-711676937645": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009088423s
STEP: Saw pod success
Apr 20 06:18:12.721: INFO: Pod "downwardapi-volume-7a180818-6473-4941-a8ca-711676937645" satisfied condition "Succeeded or Failed"
Apr 20 06:18:12.724: INFO: Trying to get logs from node node22-wriki pod downwardapi-volume-7a180818-6473-4941-a8ca-711676937645 container client-container: <nil>
STEP: delete the pod
Apr 20 06:18:12.758: INFO: Waiting for pod downwardapi-volume-7a180818-6473-4941-a8ca-711676937645 to disappear
Apr 20 06:18:12.760: INFO: Pod downwardapi-volume-7a180818-6473-4941-a8ca-711676937645 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:18:12.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9582" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":117,"skipped":2155,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:18:12.772: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting the auto-created API token
STEP: reading a file in the container
Apr 20 06:18:15.345: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6014 pod-service-account-c64bda8f-c141-4034-94f4-a9eddf6f33a9 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Apr 20 06:18:15.459: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6014 pod-service-account-c64bda8f-c141-4034-94f4-a9eddf6f33a9 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Apr 20 06:18:15.572: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6014 pod-service-account-c64bda8f-c141-4034-94f4-a9eddf6f33a9 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:18:15.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6014" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":346,"completed":118,"skipped":2176,"failed":0}
SS
------------------------------
[sig-network] Services 
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:18:15.731: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service in namespace services-5983
STEP: creating service affinity-clusterip in namespace services-5983
STEP: creating replication controller affinity-clusterip in namespace services-5983
I0420 06:18:15.805700      20 runners.go:190] Created replication controller with name: affinity-clusterip, namespace: services-5983, replica count: 3
I0420 06:18:18.857194      20 runners.go:190] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 20 06:18:18.866: INFO: Creating new exec pod
Apr 20 06:18:21.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-5983 exec execpod-affinityzkxb4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Apr 20 06:18:22.020: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip 80\n+ echo hostName\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Apr 20 06:18:22.020: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 20 06:18:22.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-5983 exec execpod-affinityzkxb4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.104.58.91 80'
Apr 20 06:18:22.130: INFO: stderr: "+ nc -v -t -w 2 10.104.58.91 80\n+ echo hostName\nConnection to 10.104.58.91 80 port [tcp/http] succeeded!\n"
Apr 20 06:18:22.130: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 20 06:18:22.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-5983 exec execpod-affinityzkxb4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.104.58.91:80/ ; done'
Apr 20 06:18:22.312: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.58.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.58.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.58.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.58.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.58.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.58.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.58.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.58.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.58.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.58.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.58.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.58.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.58.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.58.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.58.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.104.58.91:80/\n"
Apr 20 06:18:22.312: INFO: stdout: "\naffinity-clusterip-nxn9c\naffinity-clusterip-nxn9c\naffinity-clusterip-nxn9c\naffinity-clusterip-nxn9c\naffinity-clusterip-nxn9c\naffinity-clusterip-nxn9c\naffinity-clusterip-nxn9c\naffinity-clusterip-nxn9c\naffinity-clusterip-nxn9c\naffinity-clusterip-nxn9c\naffinity-clusterip-nxn9c\naffinity-clusterip-nxn9c\naffinity-clusterip-nxn9c\naffinity-clusterip-nxn9c\naffinity-clusterip-nxn9c\naffinity-clusterip-nxn9c"
Apr 20 06:18:22.312: INFO: Received response from host: affinity-clusterip-nxn9c
Apr 20 06:18:22.312: INFO: Received response from host: affinity-clusterip-nxn9c
Apr 20 06:18:22.312: INFO: Received response from host: affinity-clusterip-nxn9c
Apr 20 06:18:22.312: INFO: Received response from host: affinity-clusterip-nxn9c
Apr 20 06:18:22.312: INFO: Received response from host: affinity-clusterip-nxn9c
Apr 20 06:18:22.312: INFO: Received response from host: affinity-clusterip-nxn9c
Apr 20 06:18:22.312: INFO: Received response from host: affinity-clusterip-nxn9c
Apr 20 06:18:22.312: INFO: Received response from host: affinity-clusterip-nxn9c
Apr 20 06:18:22.312: INFO: Received response from host: affinity-clusterip-nxn9c
Apr 20 06:18:22.312: INFO: Received response from host: affinity-clusterip-nxn9c
Apr 20 06:18:22.312: INFO: Received response from host: affinity-clusterip-nxn9c
Apr 20 06:18:22.312: INFO: Received response from host: affinity-clusterip-nxn9c
Apr 20 06:18:22.312: INFO: Received response from host: affinity-clusterip-nxn9c
Apr 20 06:18:22.312: INFO: Received response from host: affinity-clusterip-nxn9c
Apr 20 06:18:22.312: INFO: Received response from host: affinity-clusterip-nxn9c
Apr 20 06:18:22.312: INFO: Received response from host: affinity-clusterip-nxn9c
Apr 20 06:18:22.312: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-5983, will wait for the garbage collector to delete the pods
Apr 20 06:18:22.384: INFO: Deleting ReplicationController affinity-clusterip took: 4.681166ms
Apr 20 06:18:22.484: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.09047ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:18:24.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5983" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:8.995 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","total":346,"completed":119,"skipped":2178,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:18:24.727: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:18:24.759: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:18:25.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2033" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":346,"completed":120,"skipped":2180,"failed":0}
SSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:18:26.137: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/security_context.go:46
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:18:26.184: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-ffdb6979-07cd-43c4-8875-dfe790a60d81" in namespace "security-context-test-9179" to be "Succeeded or Failed"
Apr 20 06:18:26.186: INFO: Pod "alpine-nnp-false-ffdb6979-07cd-43c4-8875-dfe790a60d81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.189792ms
Apr 20 06:18:28.190: INFO: Pod "alpine-nnp-false-ffdb6979-07cd-43c4-8875-dfe790a60d81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006737435s
Apr 20 06:18:30.196: INFO: Pod "alpine-nnp-false-ffdb6979-07cd-43c4-8875-dfe790a60d81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012797986s
Apr 20 06:18:30.197: INFO: Pod "alpine-nnp-false-ffdb6979-07cd-43c4-8875-dfe790a60d81" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:18:30.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9179" for this suite.
•{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":121,"skipped":2186,"failed":0}
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:18:30.209: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-5ed9fe77-ee11-4bd5-8c37-d08bcbc7fa35
STEP: Creating a pod to test consume configMaps
Apr 20 06:18:30.247: INFO: Waiting up to 5m0s for pod "pod-configmaps-fde0d656-e3d4-489b-8903-c7e9edd0a3d3" in namespace "configmap-7307" to be "Succeeded or Failed"
Apr 20 06:18:30.250: INFO: Pod "pod-configmaps-fde0d656-e3d4-489b-8903-c7e9edd0a3d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.438309ms
Apr 20 06:18:32.254: INFO: Pod "pod-configmaps-fde0d656-e3d4-489b-8903-c7e9edd0a3d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006927057s
STEP: Saw pod success
Apr 20 06:18:32.255: INFO: Pod "pod-configmaps-fde0d656-e3d4-489b-8903-c7e9edd0a3d3" satisfied condition "Succeeded or Failed"
Apr 20 06:18:32.257: INFO: Trying to get logs from node node22-wriki pod pod-configmaps-fde0d656-e3d4-489b-8903-c7e9edd0a3d3 container agnhost-container: <nil>
STEP: delete the pod
Apr 20 06:18:32.271: INFO: Waiting for pod pod-configmaps-fde0d656-e3d4-489b-8903-c7e9edd0a3d3 to disappear
Apr 20 06:18:32.273: INFO: Pod pod-configmaps-fde0d656-e3d4-489b-8903-c7e9edd0a3d3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:18:32.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7307" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":346,"completed":122,"skipped":2187,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:18:32.283: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service endpoint-test2 in namespace services-6633
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6633 to expose endpoints map[]
Apr 20 06:18:32.356: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
Apr 20 06:18:33.364: INFO: successfully validated that service endpoint-test2 in namespace services-6633 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-6633
Apr 20 06:18:33.384: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:18:35.390: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6633 to expose endpoints map[pod1:[80]]
Apr 20 06:18:35.397: INFO: successfully validated that service endpoint-test2 in namespace services-6633 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1
Apr 20 06:18:35.397: INFO: Creating new exec pod
Apr 20 06:18:38.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-6633 exec execpodwzb9j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Apr 20 06:18:38.537: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ Connection to endpoint-test2 80 port [tcp/http] succeeded!\necho hostName\n"
Apr 20 06:18:38.537: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 20 06:18:38.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-6633 exec execpodwzb9j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.104.95.84 80'
Apr 20 06:18:38.659: INFO: stderr: "+ nc -v -t -w 2 10.104.95.84 80\n+ echo hostName\nConnection to 10.104.95.84 80 port [tcp/http] succeeded!\n"
Apr 20 06:18:38.660: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-6633
Apr 20 06:18:38.683: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:18:40.690: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6633 to expose endpoints map[pod1:[80] pod2:[80]]
Apr 20 06:18:40.700: INFO: successfully validated that service endpoint-test2 in namespace services-6633 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2
Apr 20 06:18:41.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-6633 exec execpodwzb9j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Apr 20 06:18:41.827: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Apr 20 06:18:41.827: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 20 06:18:41.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-6633 exec execpodwzb9j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.104.95.84 80'
Apr 20 06:18:41.944: INFO: stderr: "+ nc -v -t -w 2 10.104.95.84 80\n+ echo hostName\nConnection to 10.104.95.84 80 port [tcp/http] succeeded!\n"
Apr 20 06:18:41.944: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-6633
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6633 to expose endpoints map[pod2:[80]]
Apr 20 06:18:41.981: INFO: successfully validated that service endpoint-test2 in namespace services-6633 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2
Apr 20 06:18:42.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-6633 exec execpodwzb9j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Apr 20 06:18:43.109: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Apr 20 06:18:43.109: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 20 06:18:43.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-6633 exec execpodwzb9j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.104.95.84 80'
Apr 20 06:18:43.245: INFO: stderr: "+ nc -v -t -w 2 10.104.95.84 80\n+ echo hostName\nConnection to 10.104.95.84 80 port [tcp/http] succeeded!\n"
Apr 20 06:18:43.245: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-6633
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6633 to expose endpoints map[]
Apr 20 06:18:43.308: INFO: successfully validated that service endpoint-test2 in namespace services-6633 exposes endpoints map[]
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:18:43.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6633" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:11.057 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":346,"completed":123,"skipped":2219,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:18:43.340: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:18:43.375: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Apr 20 06:18:44.405: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:18:44.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-777" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":346,"completed":124,"skipped":2263,"failed":0}
SSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:18:44.416: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:92
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:107
STEP: Creating service test in namespace statefulset-9281
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a new StatefulSet
Apr 20 06:18:44.466: INFO: Found 0 stateful pods, waiting for 3
Apr 20 06:18:54.470: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 20 06:18:54.471: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 20 06:18:54.471: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 to k8s.gcr.io/e2e-test-images/httpd:2.4.39-1
Apr 20 06:18:54.496: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Apr 20 06:19:04.535: INFO: Updating stateful set ss2
Apr 20 06:19:04.540: INFO: Waiting for Pod statefulset-9281/ss2-2 to have revision ss2-5bbbc9fc94 update revision ss2-677d6db895
STEP: Restoring Pods to the correct revision when they are deleted
Apr 20 06:19:14.596: INFO: Found 1 stateful pods, waiting for 3
Apr 20 06:19:24.602: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 20 06:19:24.602: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 20 06:19:24.602: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Apr 20 06:19:24.624: INFO: Updating stateful set ss2
Apr 20 06:19:24.632: INFO: Waiting for Pod statefulset-9281/ss2-1 to have revision ss2-5bbbc9fc94 update revision ss2-677d6db895
Apr 20 06:19:34.658: INFO: Updating stateful set ss2
Apr 20 06:19:34.664: INFO: Waiting for StatefulSet statefulset-9281/ss2 to complete update
Apr 20 06:19:34.664: INFO: Waiting for Pod statefulset-9281/ss2-0 to have revision ss2-5bbbc9fc94 update revision ss2-677d6db895
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:118
Apr 20 06:19:44.671: INFO: Deleting all statefulset in ns statefulset-9281
Apr 20 06:19:44.673: INFO: Scaling statefulset ss2 to 0
Apr 20 06:19:54.690: INFO: Waiting for statefulset status.replicas updated to 0
Apr 20 06:19:54.692: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:19:54.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9281" for this suite.

• [SLOW TEST:70.298 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:97
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":346,"completed":125,"skipped":2269,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath 
  runs ReplicaSets to verify preemption running path [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:19:54.718: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:90
Apr 20 06:19:54.753: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 20 06:20:54.781: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:20:54.784: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename sched-preemption-path
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] PreemptionExecutionPath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:488
STEP: Finding an available node
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
Apr 20 06:20:56.855: INFO: found a healthy node: node22-wriki
[It] runs ReplicaSets to verify preemption running path [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:21:04.948: INFO: pods created so far: [1 1 1]
Apr 20 06:21:04.948: INFO: length of pods created so far: 3
Apr 20 06:21:06.962: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:21:13.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-1128" for this suite.
[AfterEach] PreemptionExecutionPath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:462
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:21:13.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-2353" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:78

• [SLOW TEST:79.331 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:451
    runs ReplicaSets to verify preemption running path [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","total":346,"completed":126,"skipped":2316,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should replace jobs when ReplaceConcurrent [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:21:14.050: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
[It] should replace jobs when ReplaceConcurrent [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a ReplaceConcurrent cronjob
STEP: Ensuring a job is scheduled
STEP: Ensuring exactly one is scheduled
STEP: Ensuring exactly one running job exists by listing jobs explicitly
STEP: Ensuring the job is replaced with a new one
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:23:00.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-6544" for this suite.

• [SLOW TEST:106.086 seconds]
[sig-apps] CronJob
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","total":346,"completed":127,"skipped":2395,"failed":0}
SS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:23:00.136: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name s-test-opt-del-42921c13-24bf-46b3-b853-0ad5ae460e17
STEP: Creating secret with name s-test-opt-upd-88c6c261-c33c-4f47-9d86-03dbe4795335
STEP: Creating the pod
Apr 20 06:23:00.184: INFO: The status of Pod pod-projected-secrets-360aa3ad-babd-428d-a793-69a928b7a97d is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:23:02.190: INFO: The status of Pod pod-projected-secrets-360aa3ad-babd-428d-a793-69a928b7a97d is Running (Ready = true)
STEP: Deleting secret s-test-opt-del-42921c13-24bf-46b3-b853-0ad5ae460e17
STEP: Updating secret s-test-opt-upd-88c6c261-c33c-4f47-9d86-03dbe4795335
STEP: Creating secret with name s-test-opt-create-764eb508-d6a3-4b2c-9925-10e013a4f492
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:23:04.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3743" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":128,"skipped":2397,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:23:04.325: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr 20 06:23:04.366: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2f874599-54dc-42bb-941e-025a4499badd" in namespace "projected-9019" to be "Succeeded or Failed"
Apr 20 06:23:04.369: INFO: Pod "downwardapi-volume-2f874599-54dc-42bb-941e-025a4499badd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.6619ms
Apr 20 06:23:06.372: INFO: Pod "downwardapi-volume-2f874599-54dc-42bb-941e-025a4499badd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006201775s
STEP: Saw pod success
Apr 20 06:23:06.372: INFO: Pod "downwardapi-volume-2f874599-54dc-42bb-941e-025a4499badd" satisfied condition "Succeeded or Failed"
Apr 20 06:23:06.374: INFO: Trying to get logs from node node22-07idr pod downwardapi-volume-2f874599-54dc-42bb-941e-025a4499badd container client-container: <nil>
STEP: delete the pod
Apr 20 06:23:06.396: INFO: Waiting for pod downwardapi-volume-2f874599-54dc-42bb-941e-025a4499badd to disappear
Apr 20 06:23:06.399: INFO: Pod downwardapi-volume-2f874599-54dc-42bb-941e-025a4499badd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:23:06.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9019" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":346,"completed":129,"skipped":2406,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:23:06.408: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 20 06:23:06.447: INFO: Waiting up to 5m0s for pod "pod-677bd93d-727f-437e-8fd1-ab803a689f77" in namespace "emptydir-1543" to be "Succeeded or Failed"
Apr 20 06:23:06.477: INFO: Pod "pod-677bd93d-727f-437e-8fd1-ab803a689f77": Phase="Pending", Reason="", readiness=false. Elapsed: 29.794426ms
Apr 20 06:23:08.484: INFO: Pod "pod-677bd93d-727f-437e-8fd1-ab803a689f77": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.037097273s
STEP: Saw pod success
Apr 20 06:23:08.485: INFO: Pod "pod-677bd93d-727f-437e-8fd1-ab803a689f77" satisfied condition "Succeeded or Failed"
Apr 20 06:23:08.487: INFO: Trying to get logs from node node22-wriki pod pod-677bd93d-727f-437e-8fd1-ab803a689f77 container test-container: <nil>
STEP: delete the pod
Apr 20 06:23:08.503: INFO: Waiting for pod pod-677bd93d-727f-437e-8fd1-ab803a689f77 to disappear
Apr 20 06:23:08.505: INFO: Pod pod-677bd93d-727f-437e-8fd1-ab803a689f77 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:23:08.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1543" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":130,"skipped":2423,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:23:08.515: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 20 06:23:08.550: INFO: Waiting up to 5m0s for pod "pod-7d0e9590-e39b-4e43-819a-38fba26574f3" in namespace "emptydir-5943" to be "Succeeded or Failed"
Apr 20 06:23:08.552: INFO: Pod "pod-7d0e9590-e39b-4e43-819a-38fba26574f3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.678447ms
Apr 20 06:23:10.559: INFO: Pod "pod-7d0e9590-e39b-4e43-819a-38fba26574f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007988147s
STEP: Saw pod success
Apr 20 06:23:10.559: INFO: Pod "pod-7d0e9590-e39b-4e43-819a-38fba26574f3" satisfied condition "Succeeded or Failed"
Apr 20 06:23:10.561: INFO: Trying to get logs from node node22-07idr pod pod-7d0e9590-e39b-4e43-819a-38fba26574f3 container test-container: <nil>
STEP: delete the pod
Apr 20 06:23:10.576: INFO: Waiting for pod pod-7d0e9590-e39b-4e43-819a-38fba26574f3 to disappear
Apr 20 06:23:10.578: INFO: Pod pod-7d0e9590-e39b-4e43-819a-38fba26574f3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:23:10.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5943" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":131,"skipped":2457,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:23:10.594: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:23:10.623: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:23:20.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3589" for this suite.

• [SLOW TEST:10.344 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:48
    listing custom resource definition objects works  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":346,"completed":132,"skipped":2459,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:23:20.938: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service in namespace services-4612
STEP: creating service affinity-nodeport in namespace services-4612
STEP: creating replication controller affinity-nodeport in namespace services-4612
I0420 06:23:22.894024      20 runners.go:190] Created replication controller with name: affinity-nodeport, namespace: services-4612, replica count: 3
I0420 06:23:25.945799      20 runners.go:190] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 20 06:23:25.956: INFO: Creating new exec pod
Apr 20 06:23:28.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-4612 exec execpod-affinitymrlt9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Apr 20 06:23:29.172: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport 80\n+ echo hostName\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Apr 20 06:23:29.172: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 20 06:23:29.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-4612 exec execpod-affinitymrlt9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.106.182.115 80'
Apr 20 06:23:29.311: INFO: stderr: "+ nc -v -t -w 2 10.106.182.115 80\n+ echo hostName\nConnection to 10.106.182.115 80 port [tcp/http] succeeded!\n"
Apr 20 06:23:29.311: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 20 06:23:29.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-4612 exec execpod-affinitymrlt9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.125.144 30811'
Apr 20 06:23:29.431: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.100.125.144 30811\nConnection to 10.100.125.144 30811 port [tcp/*] succeeded!\n"
Apr 20 06:23:29.431: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 20 06:23:29.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-4612 exec execpod-affinitymrlt9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.99.219 30811'
Apr 20 06:23:29.550: INFO: stderr: "+ nc -v -t -w 2 10.100.99.219 30811\n+ echo hostName\nConnection to 10.100.99.219 30811 port [tcp/*] succeeded!\n"
Apr 20 06:23:29.550: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 20 06:23:29.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-4612 exec execpod-affinitymrlt9 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.100.118.168:30811/ ; done'
Apr 20 06:23:29.742: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30811/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30811/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30811/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30811/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30811/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30811/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30811/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30811/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30811/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30811/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30811/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30811/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30811/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30811/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30811/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30811/\n"
Apr 20 06:23:29.742: INFO: stdout: "\naffinity-nodeport-cffpf\naffinity-nodeport-cffpf\naffinity-nodeport-cffpf\naffinity-nodeport-cffpf\naffinity-nodeport-cffpf\naffinity-nodeport-cffpf\naffinity-nodeport-cffpf\naffinity-nodeport-cffpf\naffinity-nodeport-cffpf\naffinity-nodeport-cffpf\naffinity-nodeport-cffpf\naffinity-nodeport-cffpf\naffinity-nodeport-cffpf\naffinity-nodeport-cffpf\naffinity-nodeport-cffpf\naffinity-nodeport-cffpf"
Apr 20 06:23:29.742: INFO: Received response from host: affinity-nodeport-cffpf
Apr 20 06:23:29.742: INFO: Received response from host: affinity-nodeport-cffpf
Apr 20 06:23:29.742: INFO: Received response from host: affinity-nodeport-cffpf
Apr 20 06:23:29.742: INFO: Received response from host: affinity-nodeport-cffpf
Apr 20 06:23:29.742: INFO: Received response from host: affinity-nodeport-cffpf
Apr 20 06:23:29.742: INFO: Received response from host: affinity-nodeport-cffpf
Apr 20 06:23:29.742: INFO: Received response from host: affinity-nodeport-cffpf
Apr 20 06:23:29.742: INFO: Received response from host: affinity-nodeport-cffpf
Apr 20 06:23:29.742: INFO: Received response from host: affinity-nodeport-cffpf
Apr 20 06:23:29.742: INFO: Received response from host: affinity-nodeport-cffpf
Apr 20 06:23:29.742: INFO: Received response from host: affinity-nodeport-cffpf
Apr 20 06:23:29.742: INFO: Received response from host: affinity-nodeport-cffpf
Apr 20 06:23:29.742: INFO: Received response from host: affinity-nodeport-cffpf
Apr 20 06:23:29.742: INFO: Received response from host: affinity-nodeport-cffpf
Apr 20 06:23:29.742: INFO: Received response from host: affinity-nodeport-cffpf
Apr 20 06:23:29.742: INFO: Received response from host: affinity-nodeport-cffpf
Apr 20 06:23:29.742: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-4612, will wait for the garbage collector to delete the pods
Apr 20 06:23:29.817: INFO: Deleting ReplicationController affinity-nodeport took: 6.778117ms
Apr 20 06:23:29.918: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.60078ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:23:32.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4612" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:11.212 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","total":346,"completed":133,"skipped":2525,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should list and delete a collection of ReplicaSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:23:32.156: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should list and delete a collection of ReplicaSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create a ReplicaSet
STEP: Verify that the required pods have come up
Apr 20 06:23:32.193: INFO: Pod name sample-pod: Found 0 pods out of 3
Apr 20 06:23:37.198: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running
Apr 20 06:23:37.201: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets
STEP: DeleteCollection of the ReplicaSets
STEP: After DeleteCollection verify that ReplicaSets have been deleted
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:23:37.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3049" for this suite.

• [SLOW TEST:5.089 seconds]
[sig-apps] ReplicaSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","total":346,"completed":134,"skipped":2589,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:23:37.248: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:54
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod liveness-5557adeb-b7ac-42eb-a0c5-df66f3496321 in namespace container-probe-3749
Apr 20 06:23:39.296: INFO: Started pod liveness-5557adeb-b7ac-42eb-a0c5-df66f3496321 in namespace container-probe-3749
STEP: checking the pod's current state and verifying that restartCount is present
Apr 20 06:23:39.298: INFO: Initial restart count of pod liveness-5557adeb-b7ac-42eb-a0c5-df66f3496321 is 0
Apr 20 06:23:59.360: INFO: Restart count of pod container-probe-3749/liveness-5557adeb-b7ac-42eb-a0c5-df66f3496321 is now 1 (20.061936297s elapsed)
Apr 20 06:24:19.413: INFO: Restart count of pod container-probe-3749/liveness-5557adeb-b7ac-42eb-a0c5-df66f3496321 is now 2 (40.114878942s elapsed)
Apr 20 06:24:39.471: INFO: Restart count of pod container-probe-3749/liveness-5557adeb-b7ac-42eb-a0c5-df66f3496321 is now 3 (1m0.173174968s elapsed)
Apr 20 06:24:59.525: INFO: Restart count of pod container-probe-3749/liveness-5557adeb-b7ac-42eb-a0c5-df66f3496321 is now 4 (1m20.226950522s elapsed)
Apr 20 06:26:11.719: INFO: Restart count of pod container-probe-3749/liveness-5557adeb-b7ac-42eb-a0c5-df66f3496321 is now 5 (2m32.420591009s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:26:11.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3749" for this suite.

• [SLOW TEST:154.489 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":346,"completed":135,"skipped":2635,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:26:11.738: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 20 06:26:12.165: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 20 06:26:15.187: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:26:15.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4825" for this suite.
STEP: Destroying namespace "webhook-4825-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":346,"completed":136,"skipped":2670,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:26:15.314: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 20 06:26:15.606: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 20 06:26:18.626: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:26:19.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7950" for this suite.
STEP: Destroying namespace "webhook-7950-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":346,"completed":137,"skipped":2694,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:26:19.824: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:345
Apr 20 06:26:19.854: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 20 06:27:19.880: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:27:19.883: INFO: Starting informer...
STEP: Starting pods...
Apr 20 06:27:20.099: INFO: Pod1 is running on node22-wriki. Tainting Node
Apr 20 06:27:22.317: INFO: Pod2 is running on node22-wriki. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Apr 20 06:27:28.421: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Apr 20 06:27:48.460: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:27:48.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-7360" for this suite.

• [SLOW TEST:88.665 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","total":346,"completed":138,"skipped":2739,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:27:48.489: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4835.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4835.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 20 06:27:50.597: INFO: DNS probes using dns-4835/dns-test-fa6b210b-d2ca-4d11-b008-d86bf6ab0ca1 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:27:50.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4835" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":346,"completed":139,"skipped":2752,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  should validate Deployment Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:27:50.636: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] should validate Deployment Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a Deployment
Apr 20 06:27:50.678: INFO: Creating simple deployment test-deployment-k9p7h
Apr 20 06:27:50.694: INFO: deployment "test-deployment-k9p7h" doesn't have the required revision set
STEP: Getting /status
Apr 20 06:27:52.717: INFO: Deployment test-deployment-k9p7h has Conditions: [{Available True 2022-04-20 06:27:51 +0000 UTC 2022-04-20 06:27:51 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-04-20 06:27:51 +0000 UTC 2022-04-20 06:27:50 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-k9p7h-794dd694d8" has successfully progressed.}]
STEP: updating Deployment Status
Apr 20 06:27:52.725: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63786032871, loc:(*time.Location)(0xa09bc80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786032871, loc:(*time.Location)(0xa09bc80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63786032871, loc:(*time.Location)(0xa09bc80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786032870, loc:(*time.Location)(0xa09bc80)}}, Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-k9p7h-794dd694d8\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated
Apr 20 06:27:52.728: INFO: Observed &Deployment event: ADDED
Apr 20 06:27:52.728: INFO: Observed Deployment test-deployment-k9p7h in namespace deployment-3846 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-04-20 06:27:50 +0000 UTC 2022-04-20 06:27:50 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-k9p7h-794dd694d8"}
Apr 20 06:27:52.728: INFO: Observed &Deployment event: MODIFIED
Apr 20 06:27:52.728: INFO: Observed Deployment test-deployment-k9p7h in namespace deployment-3846 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-04-20 06:27:50 +0000 UTC 2022-04-20 06:27:50 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-k9p7h-794dd694d8"}
Apr 20 06:27:52.728: INFO: Observed Deployment test-deployment-k9p7h in namespace deployment-3846 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-04-20 06:27:50 +0000 UTC 2022-04-20 06:27:50 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 20 06:27:52.728: INFO: Observed &Deployment event: MODIFIED
Apr 20 06:27:52.728: INFO: Observed Deployment test-deployment-k9p7h in namespace deployment-3846 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-04-20 06:27:50 +0000 UTC 2022-04-20 06:27:50 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 20 06:27:52.728: INFO: Observed Deployment test-deployment-k9p7h in namespace deployment-3846 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-04-20 06:27:50 +0000 UTC 2022-04-20 06:27:50 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-k9p7h-794dd694d8" is progressing.}
Apr 20 06:27:52.729: INFO: Observed &Deployment event: MODIFIED
Apr 20 06:27:52.729: INFO: Observed Deployment test-deployment-k9p7h in namespace deployment-3846 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-04-20 06:27:51 +0000 UTC 2022-04-20 06:27:51 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 20 06:27:52.729: INFO: Observed Deployment test-deployment-k9p7h in namespace deployment-3846 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-04-20 06:27:51 +0000 UTC 2022-04-20 06:27:50 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-k9p7h-794dd694d8" has successfully progressed.}
Apr 20 06:27:52.729: INFO: Observed &Deployment event: MODIFIED
Apr 20 06:27:52.729: INFO: Observed Deployment test-deployment-k9p7h in namespace deployment-3846 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-04-20 06:27:51 +0000 UTC 2022-04-20 06:27:51 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 20 06:27:52.729: INFO: Observed Deployment test-deployment-k9p7h in namespace deployment-3846 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-04-20 06:27:51 +0000 UTC 2022-04-20 06:27:50 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-k9p7h-794dd694d8" has successfully progressed.}
Apr 20 06:27:52.729: INFO: Found Deployment test-deployment-k9p7h in namespace deployment-3846 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 20 06:27:52.729: INFO: Deployment test-deployment-k9p7h has an updated status
STEP: patching the Statefulset Status
Apr 20 06:27:52.729: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Apr 20 06:27:52.738: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched
Apr 20 06:27:52.743: INFO: Observed &Deployment event: ADDED
Apr 20 06:27:52.743: INFO: Observed deployment test-deployment-k9p7h in namespace deployment-3846 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-04-20 06:27:50 +0000 UTC 2022-04-20 06:27:50 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-k9p7h-794dd694d8"}
Apr 20 06:27:52.743: INFO: Observed &Deployment event: MODIFIED
Apr 20 06:27:52.743: INFO: Observed deployment test-deployment-k9p7h in namespace deployment-3846 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-04-20 06:27:50 +0000 UTC 2022-04-20 06:27:50 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-k9p7h-794dd694d8"}
Apr 20 06:27:52.743: INFO: Observed deployment test-deployment-k9p7h in namespace deployment-3846 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-04-20 06:27:50 +0000 UTC 2022-04-20 06:27:50 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 20 06:27:52.743: INFO: Observed &Deployment event: MODIFIED
Apr 20 06:27:52.743: INFO: Observed deployment test-deployment-k9p7h in namespace deployment-3846 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-04-20 06:27:50 +0000 UTC 2022-04-20 06:27:50 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 20 06:27:52.743: INFO: Observed deployment test-deployment-k9p7h in namespace deployment-3846 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-04-20 06:27:50 +0000 UTC 2022-04-20 06:27:50 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-k9p7h-794dd694d8" is progressing.}
Apr 20 06:27:52.744: INFO: Observed &Deployment event: MODIFIED
Apr 20 06:27:52.744: INFO: Observed deployment test-deployment-k9p7h in namespace deployment-3846 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-04-20 06:27:51 +0000 UTC 2022-04-20 06:27:51 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 20 06:27:52.744: INFO: Observed deployment test-deployment-k9p7h in namespace deployment-3846 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-04-20 06:27:51 +0000 UTC 2022-04-20 06:27:50 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-k9p7h-794dd694d8" has successfully progressed.}
Apr 20 06:27:52.744: INFO: Observed &Deployment event: MODIFIED
Apr 20 06:27:52.744: INFO: Observed deployment test-deployment-k9p7h in namespace deployment-3846 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-04-20 06:27:51 +0000 UTC 2022-04-20 06:27:51 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 20 06:27:52.744: INFO: Observed deployment test-deployment-k9p7h in namespace deployment-3846 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-04-20 06:27:51 +0000 UTC 2022-04-20 06:27:50 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-k9p7h-794dd694d8" has successfully progressed.}
Apr 20 06:27:52.744: INFO: Observed deployment test-deployment-k9p7h in namespace deployment-3846 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 20 06:27:52.744: INFO: Observed &Deployment event: MODIFIED
Apr 20 06:27:52.744: INFO: Found deployment test-deployment-k9p7h in namespace deployment-3846 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Apr 20 06:27:52.744: INFO: Deployment test-deployment-k9p7h has a patched status
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Apr 20 06:27:52.748: INFO: Deployment "test-deployment-k9p7h":
&Deployment{ObjectMeta:{test-deployment-k9p7h  deployment-3846  2768ed29-3f54-4dd1-96a0-700499e79fc4 19778 1 2022-04-20 06:27:50 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 2022-04-20 06:27:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-04-20 06:27:52 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-04-20 06:27:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003f897e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-k9p7h-794dd694d8",LastUpdateTime:2022-04-20 06:27:52 +0000 UTC,LastTransitionTime:2022-04-20 06:27:52 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 20 06:27:52.753: INFO: New ReplicaSet "test-deployment-k9p7h-794dd694d8" of Deployment "test-deployment-k9p7h":
&ReplicaSet{ObjectMeta:{test-deployment-k9p7h-794dd694d8  deployment-3846  ff3dc6ca-0598-436e-85b6-fad187d4e36b 19771 1 2022-04-20 06:27:50 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:794dd694d8] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-k9p7h 2768ed29-3f54-4dd1-96a0-700499e79fc4 0xc003e09680 0xc003e09681}] []  [{kube-controller-manager Update apps/v1 2022-04-20 06:27:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2768ed29-3f54-4dd1-96a0-700499e79fc4\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-20 06:27:51 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 794dd694d8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:794dd694d8] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003e09728 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 20 06:27:52.757: INFO: Pod "test-deployment-k9p7h-794dd694d8-bnqst" is available:
&Pod{ObjectMeta:{test-deployment-k9p7h-794dd694d8-bnqst test-deployment-k9p7h-794dd694d8- deployment-3846  3532ae04-60fe-47fa-b374-bf352555e75d 19770 0 2022-04-20 06:27:50 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:794dd694d8] map[cni.projectcalico.org/podIP:10.233.2.101/32 cni.projectcalico.org/podIPs:10.233.2.101/32] [{apps/v1 ReplicaSet test-deployment-k9p7h-794dd694d8 ff3dc6ca-0598-436e-85b6-fad187d4e36b 0xc003f89be0 0xc003f89be1}] []  [{kube-controller-manager Update v1 2022-04-20 06:27:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ff3dc6ca-0598-436e-85b6-fad187d4e36b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-04-20 06:27:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-04-20 06:27:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.2.101\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zlwgc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zlwgc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-wriki,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:27:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:27:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:27:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:27:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.99.219,PodIP:10.233.2.101,StartTime:2022-04-20 06:27:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-20 06:27:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:containerd://0dbf0ce5fa73a5f10ce25de32c08cc7d7abfea8e626a4a7b410074becb64d679,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.2.101,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:27:52.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3846" for this suite.
•{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","total":346,"completed":140,"skipped":2771,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:27:52.766: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:188
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
STEP: submitting the pod to kubernetes
Apr 20 06:27:52.804: INFO: The status of Pod pod-update-activedeadlineseconds-f0e8fcb2-51e8-401a-8250-a326c4372b68 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:27:54.810: INFO: The status of Pod pod-update-activedeadlineseconds-f0e8fcb2-51e8-401a-8250-a326c4372b68 is Running (Ready = true)
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 20 06:27:55.325: INFO: Successfully updated pod "pod-update-activedeadlineseconds-f0e8fcb2-51e8-401a-8250-a326c4372b68"
Apr 20 06:27:55.325: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-f0e8fcb2-51e8-401a-8250-a326c4372b68" in namespace "pods-4608" to be "terminated due to deadline exceeded"
Apr 20 06:27:55.327: INFO: Pod "pod-update-activedeadlineseconds-f0e8fcb2-51e8-401a-8250-a326c4372b68": Phase="Running", Reason="", readiness=true. Elapsed: 2.199199ms
Apr 20 06:27:57.332: INFO: Pod "pod-update-activedeadlineseconds-f0e8fcb2-51e8-401a-8250-a326c4372b68": Phase="Running", Reason="", readiness=true. Elapsed: 2.007596s
Apr 20 06:27:59.338: INFO: Pod "pod-update-activedeadlineseconds-f0e8fcb2-51e8-401a-8250-a326c4372b68": Phase="Failed", Reason="DeadlineExceeded", readiness=true. Elapsed: 4.012925156s
Apr 20 06:27:59.338: INFO: Pod "pod-update-activedeadlineseconds-f0e8fcb2-51e8-401a-8250-a326c4372b68" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:27:59.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4608" for this suite.

• [SLOW TEST:6.585 seconds]
[sig-node] Pods
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":346,"completed":141,"skipped":2786,"failed":0}
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:27:59.352: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-map-8423d3f7-1097-4f77-a8b9-c60e262119a4
STEP: Creating a pod to test consume configMaps
Apr 20 06:27:59.391: INFO: Waiting up to 5m0s for pod "pod-configmaps-345225b7-2a3f-4f16-b01a-89229fa4e4d7" in namespace "configmap-8142" to be "Succeeded or Failed"
Apr 20 06:27:59.393: INFO: Pod "pod-configmaps-345225b7-2a3f-4f16-b01a-89229fa4e4d7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.64771ms
Apr 20 06:28:01.397: INFO: Pod "pod-configmaps-345225b7-2a3f-4f16-b01a-89229fa4e4d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005423597s
STEP: Saw pod success
Apr 20 06:28:01.397: INFO: Pod "pod-configmaps-345225b7-2a3f-4f16-b01a-89229fa4e4d7" satisfied condition "Succeeded or Failed"
Apr 20 06:28:01.400: INFO: Trying to get logs from node node22-wriki pod pod-configmaps-345225b7-2a3f-4f16-b01a-89229fa4e4d7 container agnhost-container: <nil>
STEP: delete the pod
Apr 20 06:28:01.429: INFO: Waiting for pod pod-configmaps-345225b7-2a3f-4f16-b01a-89229fa4e4d7 to disappear
Apr 20 06:28:01.432: INFO: Pod pod-configmaps-345225b7-2a3f-4f16-b01a-89229fa4e4d7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:28:01.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8142" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":346,"completed":142,"skipped":2788,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:28:01.441: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir volume type on tmpfs
Apr 20 06:28:01.484: INFO: Waiting up to 5m0s for pod "pod-7a0952bf-6a2a-4de5-8d61-e17e353e0b5e" in namespace "emptydir-6167" to be "Succeeded or Failed"
Apr 20 06:28:01.486: INFO: Pod "pod-7a0952bf-6a2a-4de5-8d61-e17e353e0b5e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.484134ms
Apr 20 06:28:03.492: INFO: Pod "pod-7a0952bf-6a2a-4de5-8d61-e17e353e0b5e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008201776s
STEP: Saw pod success
Apr 20 06:28:03.492: INFO: Pod "pod-7a0952bf-6a2a-4de5-8d61-e17e353e0b5e" satisfied condition "Succeeded or Failed"
Apr 20 06:28:03.495: INFO: Trying to get logs from node node22-wriki pod pod-7a0952bf-6a2a-4de5-8d61-e17e353e0b5e container test-container: <nil>
STEP: delete the pod
Apr 20 06:28:03.510: INFO: Waiting for pod pod-7a0952bf-6a2a-4de5-8d61-e17e353e0b5e to disappear
Apr 20 06:28:03.512: INFO: Pod pod-7a0952bf-6a2a-4de5-8d61-e17e353e0b5e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:28:03.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6167" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":143,"skipped":2825,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:28:03.522: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5516.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5516.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5516.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5516.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5516.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5516.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5516.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5516.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5516.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5516.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5516.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5516.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5516.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 201.84.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.84.201_udp@PTR;check="$$(dig +tcp +noall +answer +search 201.84.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.84.201_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5516.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5516.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5516.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5516.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5516.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5516.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5516.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5516.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5516.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5516.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5516.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5516.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5516.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 201.84.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.84.201_udp@PTR;check="$$(dig +tcp +noall +answer +search 201.84.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.84.201_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 20 06:28:05.610: INFO: Unable to read wheezy_udp@dns-test-service.dns-5516.svc.cluster.local from pod dns-5516/dns-test-2ea03110-d593-485a-b93e-73153c20ff26: the server could not find the requested resource (get pods dns-test-2ea03110-d593-485a-b93e-73153c20ff26)
Apr 20 06:28:05.613: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5516.svc.cluster.local from pod dns-5516/dns-test-2ea03110-d593-485a-b93e-73153c20ff26: the server could not find the requested resource (get pods dns-test-2ea03110-d593-485a-b93e-73153c20ff26)
Apr 20 06:28:05.616: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5516.svc.cluster.local from pod dns-5516/dns-test-2ea03110-d593-485a-b93e-73153c20ff26: the server could not find the requested resource (get pods dns-test-2ea03110-d593-485a-b93e-73153c20ff26)
Apr 20 06:28:05.618: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5516.svc.cluster.local from pod dns-5516/dns-test-2ea03110-d593-485a-b93e-73153c20ff26: the server could not find the requested resource (get pods dns-test-2ea03110-d593-485a-b93e-73153c20ff26)
Apr 20 06:28:05.636: INFO: Unable to read jessie_udp@dns-test-service.dns-5516.svc.cluster.local from pod dns-5516/dns-test-2ea03110-d593-485a-b93e-73153c20ff26: the server could not find the requested resource (get pods dns-test-2ea03110-d593-485a-b93e-73153c20ff26)
Apr 20 06:28:05.638: INFO: Unable to read jessie_tcp@dns-test-service.dns-5516.svc.cluster.local from pod dns-5516/dns-test-2ea03110-d593-485a-b93e-73153c20ff26: the server could not find the requested resource (get pods dns-test-2ea03110-d593-485a-b93e-73153c20ff26)
Apr 20 06:28:05.640: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5516.svc.cluster.local from pod dns-5516/dns-test-2ea03110-d593-485a-b93e-73153c20ff26: the server could not find the requested resource (get pods dns-test-2ea03110-d593-485a-b93e-73153c20ff26)
Apr 20 06:28:05.643: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5516.svc.cluster.local from pod dns-5516/dns-test-2ea03110-d593-485a-b93e-73153c20ff26: the server could not find the requested resource (get pods dns-test-2ea03110-d593-485a-b93e-73153c20ff26)
Apr 20 06:28:05.665: INFO: Lookups using dns-5516/dns-test-2ea03110-d593-485a-b93e-73153c20ff26 failed for: [wheezy_udp@dns-test-service.dns-5516.svc.cluster.local wheezy_tcp@dns-test-service.dns-5516.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5516.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5516.svc.cluster.local jessie_udp@dns-test-service.dns-5516.svc.cluster.local jessie_tcp@dns-test-service.dns-5516.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5516.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5516.svc.cluster.local]

Apr 20 06:28:10.728: INFO: DNS probes using dns-5516/dns-test-2ea03110-d593-485a-b93e-73153c20ff26 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:28:10.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5516" for this suite.

• [SLOW TEST:7.314 seconds]
[sig-network] DNS
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":346,"completed":144,"skipped":2856,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:28:10.838: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating secret secrets-4178/secret-test-79a10d80-73f2-492b-88ef-17fce30367ce
STEP: Creating a pod to test consume secrets
Apr 20 06:28:10.876: INFO: Waiting up to 5m0s for pod "pod-configmaps-dccd0ac2-099d-4f41-91ed-0459b86da504" in namespace "secrets-4178" to be "Succeeded or Failed"
Apr 20 06:28:10.879: INFO: Pod "pod-configmaps-dccd0ac2-099d-4f41-91ed-0459b86da504": Phase="Pending", Reason="", readiness=false. Elapsed: 2.762825ms
Apr 20 06:28:12.882: INFO: Pod "pod-configmaps-dccd0ac2-099d-4f41-91ed-0459b86da504": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006336156s
STEP: Saw pod success
Apr 20 06:28:12.882: INFO: Pod "pod-configmaps-dccd0ac2-099d-4f41-91ed-0459b86da504" satisfied condition "Succeeded or Failed"
Apr 20 06:28:12.885: INFO: Trying to get logs from node node22-wriki pod pod-configmaps-dccd0ac2-099d-4f41-91ed-0459b86da504 container env-test: <nil>
STEP: delete the pod
Apr 20 06:28:12.900: INFO: Waiting for pod pod-configmaps-dccd0ac2-099d-4f41-91ed-0459b86da504 to disappear
Apr 20 06:28:12.902: INFO: Pod pod-configmaps-dccd0ac2-099d-4f41-91ed-0459b86da504 no longer exists
[AfterEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:28:12.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4178" for this suite.
•{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":346,"completed":145,"skipped":2892,"failed":0}
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:28:12.910: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 20 06:28:13.261: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 20 06:28:16.282: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:28:16.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6595" for this suite.
STEP: Destroying namespace "webhook-6595-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":346,"completed":146,"skipped":2893,"failed":0}
SSSS
------------------------------
[sig-node] Secrets 
  should patch a secret [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:28:16.532: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a secret [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a secret
STEP: listing secrets in all namespaces to ensure that there are more than zero
STEP: patching the secret
STEP: deleting the secret using a LabelSelector
STEP: listing secrets in all namespaces, searching for label name and value in patch
[AfterEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:28:16.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5315" for this suite.
•{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","total":346,"completed":147,"skipped":2897,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:28:16.594: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-bc9c91b3-5ba9-41a8-8dbb-e058e9e0275f
STEP: Creating a pod to test consume secrets
Apr 20 06:28:16.653: INFO: Waiting up to 5m0s for pod "pod-secrets-95b7bed0-c5b7-4113-b37e-cef9ddd67fb6" in namespace "secrets-9850" to be "Succeeded or Failed"
Apr 20 06:28:16.656: INFO: Pod "pod-secrets-95b7bed0-c5b7-4113-b37e-cef9ddd67fb6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.736626ms
Apr 20 06:28:18.662: INFO: Pod "pod-secrets-95b7bed0-c5b7-4113-b37e-cef9ddd67fb6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008732743s
STEP: Saw pod success
Apr 20 06:28:18.662: INFO: Pod "pod-secrets-95b7bed0-c5b7-4113-b37e-cef9ddd67fb6" satisfied condition "Succeeded or Failed"
Apr 20 06:28:18.664: INFO: Trying to get logs from node node22-wriki pod pod-secrets-95b7bed0-c5b7-4113-b37e-cef9ddd67fb6 container secret-volume-test: <nil>
STEP: delete the pod
Apr 20 06:28:18.679: INFO: Waiting for pod pod-secrets-95b7bed0-c5b7-4113-b37e-cef9ddd67fb6 to disappear
Apr 20 06:28:18.687: INFO: Pod pod-secrets-95b7bed0-c5b7-4113-b37e-cef9ddd67fb6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:28:18.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9850" for this suite.
STEP: Destroying namespace "secret-namespace-4144" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":346,"completed":148,"skipped":2913,"failed":0}
SSSSSSS
------------------------------
[sig-node] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:28:18.704: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:188
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Apr 20 06:28:18.742: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying pod deletion was observed
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:28:23.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5391" for this suite.
•{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","total":346,"completed":149,"skipped":2920,"failed":0}
S
------------------------------
[sig-api-machinery] server version 
  should find the server version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] server version
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:28:23.589: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename server-version
STEP: Waiting for a default service account to be provisioned in namespace
[It] should find the server version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Request ServerVersion
STEP: Confirm major version
Apr 20 06:28:23.624: INFO: Major version: 1
STEP: Confirm minor version
Apr 20 06:28:23.624: INFO: cleanMinorVersion: 22
Apr 20 06:28:23.624: INFO: Minor version: 22
[AfterEach] [sig-api-machinery] server version
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:28:23.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-6911" for this suite.
•{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","total":346,"completed":150,"skipped":2921,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:28:23.633: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Given a Pod with a 'name' label pod-adoption-release is created
Apr 20 06:28:23.668: INFO: The status of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:28:25.671: INFO: The status of Pod pod-adoption-release is Running (Ready = true)
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Apr 20 06:28:26.689: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:28:27.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7713" for this suite.
•{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":346,"completed":151,"skipped":2930,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:28:27.715: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 20 06:28:28.056: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 20 06:28:31.083: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:28:31.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1842" for this suite.
STEP: Destroying namespace "webhook-1842-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":346,"completed":152,"skipped":2968,"failed":0}
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:28:31.139: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-map-d778faed-9e81-4f94-ab66-8083575c4261
STEP: Creating a pod to test consume configMaps
Apr 20 06:28:31.179: INFO: Waiting up to 5m0s for pod "pod-configmaps-e2f7388a-c9e7-4546-888f-b838aef4f809" in namespace "configmap-8678" to be "Succeeded or Failed"
Apr 20 06:28:31.181: INFO: Pod "pod-configmaps-e2f7388a-c9e7-4546-888f-b838aef4f809": Phase="Pending", Reason="", readiness=false. Elapsed: 1.741265ms
Apr 20 06:28:33.186: INFO: Pod "pod-configmaps-e2f7388a-c9e7-4546-888f-b838aef4f809": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006958843s
STEP: Saw pod success
Apr 20 06:28:33.186: INFO: Pod "pod-configmaps-e2f7388a-c9e7-4546-888f-b838aef4f809" satisfied condition "Succeeded or Failed"
Apr 20 06:28:33.189: INFO: Trying to get logs from node node22-hwh1v pod pod-configmaps-e2f7388a-c9e7-4546-888f-b838aef4f809 container agnhost-container: <nil>
STEP: delete the pod
Apr 20 06:28:33.214: INFO: Waiting for pod pod-configmaps-e2f7388a-c9e7-4546-888f-b838aef4f809 to disappear
Apr 20 06:28:33.217: INFO: Pod pod-configmaps-e2f7388a-c9e7-4546-888f-b838aef4f809 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:28:33.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8678" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":346,"completed":153,"skipped":2970,"failed":0}
SSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:28:33.224: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Apr 20 06:28:35.785: INFO: Successfully updated pod "adopt-release--1-cbfhd"
STEP: Checking that the Job readopts the Pod
Apr 20 06:28:35.785: INFO: Waiting up to 15m0s for pod "adopt-release--1-cbfhd" in namespace "job-2944" to be "adopted"
Apr 20 06:28:35.787: INFO: Pod "adopt-release--1-cbfhd": Phase="Running", Reason="", readiness=true. Elapsed: 2.484509ms
Apr 20 06:28:37.795: INFO: Pod "adopt-release--1-cbfhd": Phase="Running", Reason="", readiness=true. Elapsed: 2.009702497s
Apr 20 06:28:37.795: INFO: Pod "adopt-release--1-cbfhd" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Apr 20 06:28:38.305: INFO: Successfully updated pod "adopt-release--1-cbfhd"
STEP: Checking that the Job releases the Pod
Apr 20 06:28:38.305: INFO: Waiting up to 15m0s for pod "adopt-release--1-cbfhd" in namespace "job-2944" to be "released"
Apr 20 06:28:38.309: INFO: Pod "adopt-release--1-cbfhd": Phase="Running", Reason="", readiness=true. Elapsed: 3.598637ms
Apr 20 06:28:40.316: INFO: Pod "adopt-release--1-cbfhd": Phase="Running", Reason="", readiness=true. Elapsed: 2.010634499s
Apr 20 06:28:40.316: INFO: Pod "adopt-release--1-cbfhd" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:28:40.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2944" for this suite.

• [SLOW TEST:7.103 seconds]
[sig-apps] Job
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":346,"completed":154,"skipped":2974,"failed":0}
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:28:40.328: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-527b9a7e-e7bc-41b4-b208-ea0a8deb7f79
STEP: Creating a pod to test consume configMaps
Apr 20 06:28:40.367: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c3402ab7-b517-4ed7-baad-cbc0d05319cb" in namespace "projected-7065" to be "Succeeded or Failed"
Apr 20 06:28:40.370: INFO: Pod "pod-projected-configmaps-c3402ab7-b517-4ed7-baad-cbc0d05319cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.581118ms
Apr 20 06:28:42.375: INFO: Pod "pod-projected-configmaps-c3402ab7-b517-4ed7-baad-cbc0d05319cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007880483s
STEP: Saw pod success
Apr 20 06:28:42.376: INFO: Pod "pod-projected-configmaps-c3402ab7-b517-4ed7-baad-cbc0d05319cb" satisfied condition "Succeeded or Failed"
Apr 20 06:28:42.378: INFO: Trying to get logs from node node22-wriki pod pod-projected-configmaps-c3402ab7-b517-4ed7-baad-cbc0d05319cb container agnhost-container: <nil>
STEP: delete the pod
Apr 20 06:28:42.416: INFO: Waiting for pod pod-projected-configmaps-c3402ab7-b517-4ed7-baad-cbc0d05319cb to disappear
Apr 20 06:28:42.418: INFO: Pod pod-projected-configmaps-c3402ab7-b517-4ed7-baad-cbc0d05319cb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:28:42.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7065" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":346,"completed":155,"skipped":2975,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:28:42.427: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Apr 20 06:28:42.485: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-77  1674e529-2436-42af-a539-e135e5e7be35 20624 0 2022-04-20 06:28:42 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-04-20 06:28:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 20 06:28:42.486: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-77  1674e529-2436-42af-a539-e135e5e7be35 20625 0 2022-04-20 06:28:42 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-04-20 06:28:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 20 06:28:42.486: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-77  1674e529-2436-42af-a539-e135e5e7be35 20626 0 2022-04-20 06:28:42 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-04-20 06:28:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Apr 20 06:28:52.508: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-77  1674e529-2436-42af-a539-e135e5e7be35 20694 0 2022-04-20 06:28:42 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-04-20 06:28:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 20 06:28:52.508: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-77  1674e529-2436-42af-a539-e135e5e7be35 20695 0 2022-04-20 06:28:42 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-04-20 06:28:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 20 06:28:52.508: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-77  1674e529-2436-42af-a539-e135e5e7be35 20696 0 2022-04-20 06:28:42 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-04-20 06:28:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:28:52.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-77" for this suite.

• [SLOW TEST:10.090 seconds]
[sig-api-machinery] Watchers
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":346,"completed":156,"skipped":3043,"failed":0}
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:28:52.518: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with secret that has name projected-secret-test-7cb6c478-b622-48ab-a899-b87643311751
STEP: Creating a pod to test consume secrets
Apr 20 06:28:52.561: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6415482f-6639-4f03-9048-12f037d4692e" in namespace "projected-859" to be "Succeeded or Failed"
Apr 20 06:28:52.563: INFO: Pod "pod-projected-secrets-6415482f-6639-4f03-9048-12f037d4692e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.215344ms
Apr 20 06:28:54.569: INFO: Pod "pod-projected-secrets-6415482f-6639-4f03-9048-12f037d4692e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007707939s
STEP: Saw pod success
Apr 20 06:28:54.569: INFO: Pod "pod-projected-secrets-6415482f-6639-4f03-9048-12f037d4692e" satisfied condition "Succeeded or Failed"
Apr 20 06:28:54.571: INFO: Trying to get logs from node node22-07idr pod pod-projected-secrets-6415482f-6639-4f03-9048-12f037d4692e container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 20 06:28:54.594: INFO: Waiting for pod pod-projected-secrets-6415482f-6639-4f03-9048-12f037d4692e to disappear
Apr 20 06:28:54.596: INFO: Pod pod-projected-secrets-6415482f-6639-4f03-9048-12f037d4692e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:28:54.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-859" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":157,"skipped":3046,"failed":0}
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:28:54.603: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] deployment should support proportional scaling [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:28:54.638: INFO: Creating deployment "webserver-deployment"
Apr 20 06:28:54.642: INFO: Waiting for observed generation 1
Apr 20 06:28:56.650: INFO: Waiting for all required pods to come up
Apr 20 06:28:56.657: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Apr 20 06:28:58.672: INFO: Waiting for deployment "webserver-deployment" to complete
Apr 20 06:28:58.676: INFO: Updating deployment "webserver-deployment" with a non-existent image
Apr 20 06:28:58.683: INFO: Updating deployment webserver-deployment
Apr 20 06:28:58.683: INFO: Waiting for observed generation 2
Apr 20 06:29:00.700: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr 20 06:29:00.702: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr 20 06:29:00.704: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr 20 06:29:00.709: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr 20 06:29:00.709: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr 20 06:29:00.711: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr 20 06:29:00.714: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Apr 20 06:29:00.714: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Apr 20 06:29:00.720: INFO: Updating deployment webserver-deployment
Apr 20 06:29:00.720: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Apr 20 06:29:00.727: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr 20 06:29:00.732: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Apr 20 06:29:02.857: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-6136  a8cdb0c4-eb32-4551-866a-6d6410cb1c82 21042 3 2022-04-20 06:28:54 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-04-20 06:28:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-20 06:28:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0028b3518 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-04-20 06:29:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-795d758f88" is progressing.,LastUpdateTime:2022-04-20 06:29:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:54 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Apr 20 06:29:02.924: INFO: New ReplicaSet "webserver-deployment-795d758f88" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-795d758f88  deployment-6136  8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef 21035 3 2022-04-20 06:28:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment a8cdb0c4-eb32-4551-866a-6d6410cb1c82 0xc0028b3d47 0xc0028b3d48}] []  [{kube-controller-manager Update apps/v1 2022-04-20 06:28:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a8cdb0c4-eb32-4551-866a-6d6410cb1c82\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-20 06:28:58 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 795d758f88,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0028b3ec8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 20 06:29:02.925: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Apr 20 06:29:02.926: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-847dcfb7fb  deployment-6136  904e1653-a736-4bc0-8354-cc19952680a4 21022 3 2022-04-20 06:28:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment a8cdb0c4-eb32-4551-866a-6d6410cb1c82 0xc0028b3f27 0xc0028b3f28}] []  [{kube-controller-manager Update apps/v1 2022-04-20 06:28:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a8cdb0c4-eb32-4551-866a-6d6410cb1c82\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-20 06:28:55 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 847dcfb7fb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0028b3fb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Apr 20 06:29:02.945: INFO: Pod "webserver-deployment-795d758f88-27sp5" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-27sp5 webserver-deployment-795d758f88- deployment-6136  12e07951-129f-4c85-aa55-8eb9b4da057f 21071 0 2022-04-20 06:29:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[cni.projectcalico.org/podIP:10.233.2.116/32 cni.projectcalico.org/podIPs:10.233.2.116/32] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef 0xc00291aa17 0xc00291aa18}] []  [{kube-controller-manager Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-04-20 06:29:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vrb74,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vrb74,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-wriki,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.99.219,PodIP:,StartTime:2022-04-20 06:29:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:02.953: INFO: Pod "webserver-deployment-795d758f88-2pmpr" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-2pmpr webserver-deployment-795d758f88- deployment-6136  c153dcbc-d993-474f-b2d8-7c021e523be0 20930 0 2022-04-20 06:28:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[cni.projectcalico.org/podIP:10.233.1.54/32 cni.projectcalico.org/podIPs:10.233.1.54/32] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef 0xc00291ac57 0xc00291ac58}] []  [{kube-controller-manager Update v1 2022-04-20 06:28:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-04-20 06:28:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-04-20 06:28:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qhqns,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qhqns,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-07idr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.118.168,PodIP:,StartTime:2022-04-20 06:28:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:02.953: INFO: Pod "webserver-deployment-795d758f88-d6rd9" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-d6rd9 webserver-deployment-795d758f88- deployment-6136  0ecd01c0-fa07-44ba-8aad-f9d00b53dc23 20929 0 2022-04-20 06:28:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[cni.projectcalico.org/podIP:10.233.0.76/32 cni.projectcalico.org/podIPs:10.233.0.76/32] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef 0xc00291ae87 0xc00291ae88}] []  [{kube-controller-manager Update v1 2022-04-20 06:28:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-04-20 06:28:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-04-20 06:28:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2kgfv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2kgfv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-hwh1v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.125.144,PodIP:,StartTime:2022-04-20 06:28:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:02.954: INFO: Pod "webserver-deployment-795d758f88-ddsnh" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-ddsnh webserver-deployment-795d758f88- deployment-6136  2c110fd9-5775-41ad-9198-7289b05a3fc9 21090 0 2022-04-20 06:29:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[cni.projectcalico.org/podIP:10.233.0.81/32 cni.projectcalico.org/podIPs:10.233.0.81/32] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef 0xc00291b0b7 0xc00291b0b8}] []  [{kube-controller-manager Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-04-20 06:29:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l56hz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l56hz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-hwh1v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.125.144,PodIP:,StartTime:2022-04-20 06:29:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:02.954: INFO: Pod "webserver-deployment-795d758f88-fgfvk" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-fgfvk webserver-deployment-795d758f88- deployment-6136  87ffd111-1ce1-4233-ba24-0598f3fbdee2 20928 0 2022-04-20 06:28:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[cni.projectcalico.org/podIP:10.233.2.115/32 cni.projectcalico.org/podIPs:10.233.2.115/32] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef 0xc00291ba37 0xc00291ba38}] []  [{kube-controller-manager Update v1 2022-04-20 06:28:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-04-20 06:28:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-04-20 06:28:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8n66b,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8n66b,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-wriki,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.99.219,PodIP:,StartTime:2022-04-20 06:28:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:02.954: INFO: Pod "webserver-deployment-795d758f88-lbgqq" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-lbgqq webserver-deployment-795d758f88- deployment-6136  c1b30285-cdb1-4a72-ab22-357ac532cd46 21086 0 2022-04-20 06:29:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[cni.projectcalico.org/podIP:10.233.1.57/32 cni.projectcalico.org/podIPs:10.233.1.57/32] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef 0xc00291bcc7 0xc00291bcc8}] []  [{kube-controller-manager Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-04-20 06:29:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9j8tk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9j8tk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-07idr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.118.168,PodIP:,StartTime:2022-04-20 06:29:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:02.955: INFO: Pod "webserver-deployment-795d758f88-ndwf6" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-ndwf6 webserver-deployment-795d758f88- deployment-6136  c366ae39-1b78-426c-8146-1aa2a5e79f10 21118 0 2022-04-20 06:29:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[cni.projectcalico.org/podIP:10.233.1.61/32 cni.projectcalico.org/podIPs:10.233.1.61/32] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef 0xc0026ae187 0xc0026ae188}] []  [{kube-controller-manager Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-04-20 06:29:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9992w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9992w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-07idr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:02.955: INFO: Pod "webserver-deployment-795d758f88-qrdm6" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-qrdm6 webserver-deployment-795d758f88- deployment-6136  c0328dd8-1f34-4ec1-bf4d-f0779ae42a9f 20932 0 2022-04-20 06:28:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[cni.projectcalico.org/podIP:10.233.0.77/32 cni.projectcalico.org/podIPs:10.233.0.77/32] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef 0xc0026ae340 0xc0026ae341}] []  [{kube-controller-manager Update v1 2022-04-20 06:28:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-04-20 06:28:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-04-20 06:28:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7nxpf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7nxpf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-hwh1v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.125.144,PodIP:,StartTime:2022-04-20 06:28:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:02.955: INFO: Pod "webserver-deployment-795d758f88-qvdhk" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-qvdhk webserver-deployment-795d758f88- deployment-6136  ca3557cc-0530-45da-95a2-e3b8f16e8d1a 21088 0 2022-04-20 06:29:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[cni.projectcalico.org/podIP:10.233.2.119/32 cni.projectcalico.org/podIPs:10.233.2.119/32] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef 0xc0026ae567 0xc0026ae568}] []  [{kube-controller-manager Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-04-20 06:29:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-04-20 06:29:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qf6fv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qf6fv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-wriki,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.99.219,PodIP:,StartTime:2022-04-20 06:29:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:02.987: INFO: Pod "webserver-deployment-795d758f88-sdcbk" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-sdcbk webserver-deployment-795d758f88- deployment-6136  9e062980-4bfb-44e5-8aba-ece08b6297a2 21072 0 2022-04-20 06:29:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[cni.projectcalico.org/podIP:10.233.0.78/32 cni.projectcalico.org/podIPs:10.233.0.78/32] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef 0xc0026ae797 0xc0026ae798}] []  [{kube-controller-manager Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-04-20 06:29:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5z2dp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5z2dp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-hwh1v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.125.144,PodIP:,StartTime:2022-04-20 06:29:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:03.006: INFO: Pod "webserver-deployment-795d758f88-vc8kb" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-vc8kb webserver-deployment-795d758f88- deployment-6136  af7fe310-1e61-469e-8ec4-1720ae8f1199 21115 0 2022-04-20 06:29:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[cni.projectcalico.org/podIP:10.233.1.60/32 cni.projectcalico.org/podIPs:10.233.1.60/32] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef 0xc0026ae9c7 0xc0026ae9c8}] []  [{kube-controller-manager Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-04-20 06:29:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-whbg8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-whbg8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-07idr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.118.168,PodIP:,StartTime:2022-04-20 06:29:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:03.007: INFO: Pod "webserver-deployment-795d758f88-vfv8w" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-vfv8w webserver-deployment-795d758f88- deployment-6136  4917a2cc-0cc5-4787-b1a4-8c31d674759c 21116 0 2022-04-20 06:29:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[cni.projectcalico.org/podIP:10.233.2.120/32 cni.projectcalico.org/podIPs:10.233.2.120/32] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef 0xc0026aebf7 0xc0026aebf8}] []  [{kube-controller-manager Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-04-20 06:29:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-04-20 06:29:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jzhxn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jzhxn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-wriki,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.99.219,PodIP:,StartTime:2022-04-20 06:29:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:03.011: INFO: Pod "webserver-deployment-795d758f88-wgqvv" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-wgqvv webserver-deployment-795d758f88- deployment-6136  10f6150d-1324-452b-9e25-a76d02e82d0e 20931 0 2022-04-20 06:28:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[cni.projectcalico.org/podIP:10.233.1.55/32 cni.projectcalico.org/podIPs:10.233.1.55/32] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef 0xc0026aee27 0xc0026aee28}] []  [{kube-controller-manager Update v1 2022-04-20 06:28:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8d10cf2d-bfce-4705-a3f9-1d8ba8a984ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-04-20 06:28:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-04-20 06:28:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gg5md,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gg5md,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-07idr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.118.168,PodIP:,StartTime:2022-04-20 06:28:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:03.017: INFO: Pod "webserver-deployment-847dcfb7fb-2gk78" is not available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-2gk78 webserver-deployment-847dcfb7fb- deployment-6136  ccb2dd57-7f03-4f6a-8fce-45110af0aa90 21085 0 2022-04-20 06:29:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/podIP:10.233.0.80/32 cni.projectcalico.org/podIPs:10.233.0.80/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb 904e1653-a736-4bc0-8354-cc19952680a4 0xc0026af057 0xc0026af058}] []  [{kube-controller-manager Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"904e1653-a736-4bc0-8354-cc19952680a4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-04-20 06:29:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-55v2v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-55v2v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-hwh1v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.125.144,PodIP:,StartTime:2022-04-20 06:29:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:03.045: INFO: Pod "webserver-deployment-847dcfb7fb-5f7f5" is not available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-5f7f5 webserver-deployment-847dcfb7fb- deployment-6136  6d03d185-84ce-4988-8474-e50cf47631e8 21091 0 2022-04-20 06:29:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/podIP:10.233.0.82/32 cni.projectcalico.org/podIPs:10.233.0.82/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb 904e1653-a736-4bc0-8354-cc19952680a4 0xc0026af297 0xc0026af298}] []  [{kube-controller-manager Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"904e1653-a736-4bc0-8354-cc19952680a4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-04-20 06:29:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dqrzz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dqrzz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-hwh1v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.125.144,PodIP:,StartTime:2022-04-20 06:29:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:03.045: INFO: Pod "webserver-deployment-847dcfb7fb-76sbh" is available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-76sbh webserver-deployment-847dcfb7fb- deployment-6136  19660545-35b9-4040-8f60-a77447ac2900 20856 0 2022-04-20 06:28:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/podIP:10.233.1.53/32 cni.projectcalico.org/podIPs:10.233.1.53/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb 904e1653-a736-4bc0-8354-cc19952680a4 0xc0026af4a7 0xc0026af4a8}] []  [{kube-controller-manager Update v1 2022-04-20 06:28:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"904e1653-a736-4bc0-8354-cc19952680a4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-04-20 06:28:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-04-20 06:28:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.1.53\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-96mgp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-96mgp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-07idr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.118.168,PodIP:10.233.1.53,StartTime:2022-04-20 06:28:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-20 06:28:55 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:containerd://937caf52344c1118cd604c7dbe870c1326e86ae34e2ddee2b9cbc113fcbb93c2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.1.53,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:03.075: INFO: Pod "webserver-deployment-847dcfb7fb-968tq" is not available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-968tq webserver-deployment-847dcfb7fb- deployment-6136  37899c53-853d-40e2-a817-17de86756f33 21111 0 2022-04-20 06:29:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/podIP:10.233.2.122/32 cni.projectcalico.org/podIPs:10.233.2.122/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb 904e1653-a736-4bc0-8354-cc19952680a4 0xc0026af8f0 0xc0026af8f1}] []  [{kube-controller-manager Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"904e1653-a736-4bc0-8354-cc19952680a4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-04-20 06:29:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-d45lh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-d45lh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-wriki,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.99.219,PodIP:,StartTime:2022-04-20 06:29:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:03.078: INFO: Pod "webserver-deployment-847dcfb7fb-cjfwl" is not available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-cjfwl webserver-deployment-847dcfb7fb- deployment-6136  6771f0e2-3715-4197-8fc3-10d8b34409f4 21077 0 2022-04-20 06:29:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/podIP:10.233.2.117/32 cni.projectcalico.org/podIPs:10.233.2.117/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb 904e1653-a736-4bc0-8354-cc19952680a4 0xc0026afb97 0xc0026afb98}] []  [{kube-controller-manager Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"904e1653-a736-4bc0-8354-cc19952680a4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-04-20 06:29:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5nlfg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5nlfg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-wriki,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.99.219,PodIP:,StartTime:2022-04-20 06:29:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:03.080: INFO: Pod "webserver-deployment-847dcfb7fb-dkzbh" is available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-dkzbh webserver-deployment-847dcfb7fb- deployment-6136  b4aa9434-2cdc-4b60-8cf9-db668b3398bd 20850 0 2022-04-20 06:28:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/podIP:10.233.0.73/32 cni.projectcalico.org/podIPs:10.233.0.73/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb 904e1653-a736-4bc0-8354-cc19952680a4 0xc0027d60c7 0xc0027d60c8}] []  [{kube-controller-manager Update v1 2022-04-20 06:28:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"904e1653-a736-4bc0-8354-cc19952680a4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-04-20 06:28:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-04-20 06:28:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.0.73\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8sw8l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8sw8l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-hwh1v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.125.144,PodIP:10.233.0.73,StartTime:2022-04-20 06:28:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-20 06:28:55 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:containerd://9178e21849a5570445f80380913bd2615346cb06a1e7e13c85ce8857e0a69d26,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.0.73,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:03.082: INFO: Pod "webserver-deployment-847dcfb7fb-f8x2z" is available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-f8x2z webserver-deployment-847dcfb7fb- deployment-6136  d61bca47-e2cf-4536-aafd-ed37f301660e 20846 0 2022-04-20 06:28:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/podIP:10.233.0.74/32 cni.projectcalico.org/podIPs:10.233.0.74/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb 904e1653-a736-4bc0-8354-cc19952680a4 0xc0027d62f0 0xc0027d62f1}] []  [{kube-controller-manager Update v1 2022-04-20 06:28:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"904e1653-a736-4bc0-8354-cc19952680a4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-04-20 06:28:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-04-20 06:28:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.0.74\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rt5vv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rt5vv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-hwh1v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.125.144,PodIP:10.233.0.74,StartTime:2022-04-20 06:28:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-20 06:28:55 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:containerd://904d5b9e05f5692a5b7699bb2ca947688523a8d60525ef0db3b1ac74f54c8744,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.0.74,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:03.082: INFO: Pod "webserver-deployment-847dcfb7fb-gch9j" is not available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-gch9j webserver-deployment-847dcfb7fb- deployment-6136  2e13f760-506b-4fd5-a8f9-080db8f44b8d 21081 0 2022-04-20 06:29:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/podIP:10.233.0.79/32 cni.projectcalico.org/podIPs:10.233.0.79/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb 904e1653-a736-4bc0-8354-cc19952680a4 0xc0027d6510 0xc0027d6511}] []  [{kube-controller-manager Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"904e1653-a736-4bc0-8354-cc19952680a4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-04-20 06:29:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-04-20 06:29:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x5nxc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x5nxc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-hwh1v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.125.144,PodIP:,StartTime:2022-04-20 06:29:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:03.082: INFO: Pod "webserver-deployment-847dcfb7fb-gfbwf" is not available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-gfbwf webserver-deployment-847dcfb7fb- deployment-6136  9a19c58f-f987-44a0-8205-c9d2dae9ce58 21084 0 2022-04-20 06:29:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/podIP:10.233.1.56/32 cni.projectcalico.org/podIPs:10.233.1.56/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb 904e1653-a736-4bc0-8354-cc19952680a4 0xc0027d6717 0xc0027d6718}] []  [{kube-controller-manager Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"904e1653-a736-4bc0-8354-cc19952680a4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-04-20 06:29:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-04-20 06:29:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-984jt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-984jt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-07idr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.118.168,PodIP:,StartTime:2022-04-20 06:29:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:03.101: INFO: Pod "webserver-deployment-847dcfb7fb-gzk4l" is available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-gzk4l webserver-deployment-847dcfb7fb- deployment-6136  e0583e20-ec91-4f34-a9f6-8df6f9f90e9e 20838 0 2022-04-20 06:28:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/podIP:10.233.2.112/32 cni.projectcalico.org/podIPs:10.233.2.112/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb 904e1653-a736-4bc0-8354-cc19952680a4 0xc0027d6927 0xc0027d6928}] []  [{kube-controller-manager Update v1 2022-04-20 06:28:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"904e1653-a736-4bc0-8354-cc19952680a4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-04-20 06:28:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-04-20 06:28:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.2.112\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m2p6r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m2p6r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-wriki,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.99.219,PodIP:10.233.2.112,StartTime:2022-04-20 06:28:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-20 06:28:56 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:containerd://a04a408047633a06a856e58da8e2d4748047351360c84540f1ba4405ce149faf,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.2.112,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:03.103: INFO: Pod "webserver-deployment-847dcfb7fb-hq6g6" is available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-hq6g6 webserver-deployment-847dcfb7fb- deployment-6136  67a561f6-84a0-43f2-9511-e25aa156941b 20840 0 2022-04-20 06:28:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/podIP:10.233.0.75/32 cni.projectcalico.org/podIPs:10.233.0.75/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb 904e1653-a736-4bc0-8354-cc19952680a4 0xc0027d6b57 0xc0027d6b58}] []  [{kube-controller-manager Update v1 2022-04-20 06:28:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"904e1653-a736-4bc0-8354-cc19952680a4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-04-20 06:28:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-04-20 06:28:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.0.75\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xw4hg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xw4hg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-hwh1v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.125.144,PodIP:10.233.0.75,StartTime:2022-04-20 06:28:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-20 06:28:55 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:containerd://2ceada65a6f5df5ba173301daf52ad131ea07b5af14332a1e63396934a2e3126,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.0.75,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:03.104: INFO: Pod "webserver-deployment-847dcfb7fb-jhrm2" is available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-jhrm2 webserver-deployment-847dcfb7fb- deployment-6136  5f583c53-78dd-4322-939f-96ed4a40a627 20807 0 2022-04-20 06:28:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/podIP:10.233.1.51/32 cni.projectcalico.org/podIPs:10.233.1.51/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb 904e1653-a736-4bc0-8354-cc19952680a4 0xc0027d6d80 0xc0027d6d81}] []  [{kube-controller-manager Update v1 2022-04-20 06:28:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"904e1653-a736-4bc0-8354-cc19952680a4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-04-20 06:28:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-04-20 06:28:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.1.51\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-h8h7z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-h8h7z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-07idr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.118.168,PodIP:10.233.1.51,StartTime:2022-04-20 06:28:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-20 06:28:55 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:containerd://212819d5a8fc2afff9edf23c6a9a235940b9aaf0f4899acc86b2ffd2c5bdbdea,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.1.51,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:03.106: INFO: Pod "webserver-deployment-847dcfb7fb-ksfzw" is available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-ksfzw webserver-deployment-847dcfb7fb- deployment-6136  cfaa51ba-1329-4a5d-bd28-1030450ef260 20854 0 2022-04-20 06:28:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/podIP:10.233.1.52/32 cni.projectcalico.org/podIPs:10.233.1.52/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb 904e1653-a736-4bc0-8354-cc19952680a4 0xc0027d6fa0 0xc0027d6fa1}] []  [{kube-controller-manager Update v1 2022-04-20 06:28:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"904e1653-a736-4bc0-8354-cc19952680a4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-04-20 06:28:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-04-20 06:28:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.1.52\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-v99nw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-v99nw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-07idr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.118.168,PodIP:10.233.1.52,StartTime:2022-04-20 06:28:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-20 06:28:55 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:containerd://2f7db73073b90ea301a01815e966e7b50d6d6fc62a422a8e1374a35cce66ff7c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.1.52,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:03.106: INFO: Pod "webserver-deployment-847dcfb7fb-lfklj" is not available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-lfklj webserver-deployment-847dcfb7fb- deployment-6136  37f1092d-1194-400f-9c2a-5a20b6a7949d 21079 0 2022-04-20 06:29:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/podIP:10.233.2.118/32 cni.projectcalico.org/podIPs:10.233.2.118/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb 904e1653-a736-4bc0-8354-cc19952680a4 0xc0027d71c0 0xc0027d71c1}] []  [{kube-controller-manager Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"904e1653-a736-4bc0-8354-cc19952680a4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-04-20 06:29:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f5sh4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f5sh4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-wriki,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.99.219,PodIP:,StartTime:2022-04-20 06:29:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:03.109: INFO: Pod "webserver-deployment-847dcfb7fb-p9kgd" is available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-p9kgd webserver-deployment-847dcfb7fb- deployment-6136  26a8463e-c5be-469f-832d-c43e3eb197e6 20837 0 2022-04-20 06:28:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/podIP:10.233.2.114/32 cni.projectcalico.org/podIPs:10.233.2.114/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb 904e1653-a736-4bc0-8354-cc19952680a4 0xc0027d7807 0xc0027d7808}] []  [{kube-controller-manager Update v1 2022-04-20 06:28:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"904e1653-a736-4bc0-8354-cc19952680a4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-04-20 06:28:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-04-20 06:28:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.2.114\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-n85f4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-n85f4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-wriki,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:28:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.99.219,PodIP:10.233.2.114,StartTime:2022-04-20 06:28:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-20 06:28:56 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:containerd://15ab6a1a48b41e4e354a5c8ec663d36ac4488f50da30e68a72225db36733dc8e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.2.114,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:03.109: INFO: Pod "webserver-deployment-847dcfb7fb-q6kbv" is not available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-q6kbv webserver-deployment-847dcfb7fb- deployment-6136  ad8ef0de-beed-4d75-90d4-fb7561455f34 21112 0 2022-04-20 06:29:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/podIP:10.233.0.83/32 cni.projectcalico.org/podIPs:10.233.0.83/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb 904e1653-a736-4bc0-8354-cc19952680a4 0xc0027d7a37 0xc0027d7a38}] []  [{kube-controller-manager Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"904e1653-a736-4bc0-8354-cc19952680a4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-04-20 06:29:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-t9sx7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-t9sx7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-hwh1v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.125.144,PodIP:,StartTime:2022-04-20 06:29:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:03.110: INFO: Pod "webserver-deployment-847dcfb7fb-qmkjk" is not available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-qmkjk webserver-deployment-847dcfb7fb- deployment-6136  99d14f96-e601-4055-b8a2-87b7b5a6ee72 21087 0 2022-04-20 06:29:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/podIP:10.233.1.58/32 cni.projectcalico.org/podIPs:10.233.1.58/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb 904e1653-a736-4bc0-8354-cc19952680a4 0xc0027d7c47 0xc0027d7c48}] []  [{kube-controller-manager Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"904e1653-a736-4bc0-8354-cc19952680a4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-04-20 06:29:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bxs5t,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bxs5t,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-07idr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.118.168,PodIP:,StartTime:2022-04-20 06:29:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:03.110: INFO: Pod "webserver-deployment-847dcfb7fb-qvc5c" is not available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-qvc5c webserver-deployment-847dcfb7fb- deployment-6136  b3cbf246-48ff-4796-b5f1-8cba74088763 21094 0 2022-04-20 06:29:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/podIP:10.233.2.121/32 cni.projectcalico.org/podIPs:10.233.2.121/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb 904e1653-a736-4bc0-8354-cc19952680a4 0xc0027d7e57 0xc0027d7e58}] []  [{kube-controller-manager Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"904e1653-a736-4bc0-8354-cc19952680a4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-04-20 06:29:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5dphr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5dphr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-wriki,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:03.110: INFO: Pod "webserver-deployment-847dcfb7fb-tzrzm" is not available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-tzrzm webserver-deployment-847dcfb7fb- deployment-6136  7576b856-9b38-4851-8797-8eddaa49b163 21031 0 2022-04-20 06:29:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb 904e1653-a736-4bc0-8354-cc19952680a4 0xc003990020 0xc003990021}] []  [{kube-controller-manager Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"904e1653-a736-4bc0-8354-cc19952680a4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dhs7d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dhs7d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-07idr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.118.168,PodIP:,StartTime:2022-04-20 06:29:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:29:03.112: INFO: Pod "webserver-deployment-847dcfb7fb-xhvq4" is not available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-xhvq4 webserver-deployment-847dcfb7fb- deployment-6136  0bf963d4-e73f-4ff0-aecf-510a583b90f3 21092 0 2022-04-20 06:29:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/podIP:10.233.1.59/32 cni.projectcalico.org/podIPs:10.233.1.59/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb 904e1653-a736-4bc0-8354-cc19952680a4 0xc003990207 0xc003990208}] []  [{kube-controller-manager Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"904e1653-a736-4bc0-8354-cc19952680a4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-04-20 06:29:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-04-20 06:29:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7dvqs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7dvqs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-07idr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:29:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.118.168,PodIP:,StartTime:2022-04-20 06:29:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:29:03.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6136" for this suite.

• [SLOW TEST:8.524 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":346,"completed":158,"skipped":3053,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:29:03.128: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/security_context.go:46
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:29:03.201: INFO: Waiting up to 5m0s for pod "busybox-user-65534-eb524de6-669d-4037-bc4f-db2ca7e7b778" in namespace "security-context-test-9900" to be "Succeeded or Failed"
Apr 20 06:29:03.205: INFO: Pod "busybox-user-65534-eb524de6-669d-4037-bc4f-db2ca7e7b778": Phase="Pending", Reason="", readiness=false. Elapsed: 3.663998ms
Apr 20 06:29:05.212: INFO: Pod "busybox-user-65534-eb524de6-669d-4037-bc4f-db2ca7e7b778": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011055261s
Apr 20 06:29:07.217: INFO: Pod "busybox-user-65534-eb524de6-669d-4037-bc4f-db2ca7e7b778": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016308239s
Apr 20 06:29:07.217: INFO: Pod "busybox-user-65534-eb524de6-669d-4037-bc4f-db2ca7e7b778" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:29:07.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9900" for this suite.
•{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":159,"skipped":3087,"failed":0}
SSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:29:07.228: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:38
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:29:07.271: INFO: The status of Pod busybox-scheduling-f0b5b3af-6d3a-4eb0-a770-e44c39beb0b1 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:29:09.275: INFO: The status of Pod busybox-scheduling-f0b5b3af-6d3a-4eb0-a770-e44c39beb0b1 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:29:11.279: INFO: The status of Pod busybox-scheduling-f0b5b3af-6d3a-4eb0-a770-e44c39beb0b1 is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:29:11.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1486" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":346,"completed":160,"skipped":3093,"failed":0}
S
------------------------------
[sig-instrumentation] Events 
  should delete a collection of events [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-instrumentation] Events
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:29:11.298: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a collection of events [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create set of events
Apr 20 06:29:11.332: INFO: created test-event-1
Apr 20 06:29:11.335: INFO: created test-event-2
Apr 20 06:29:11.337: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace
STEP: delete collection of events
Apr 20 06:29:11.339: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity
Apr 20 06:29:11.350: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:29:11.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7232" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","total":346,"completed":161,"skipped":3094,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:29:11.361: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 20 06:29:11.391: INFO: Waiting up to 5m0s for pod "pod-aab2063b-3be4-4714-b556-e7ee0fee35cf" in namespace "emptydir-6522" to be "Succeeded or Failed"
Apr 20 06:29:11.395: INFO: Pod "pod-aab2063b-3be4-4714-b556-e7ee0fee35cf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.409677ms
Apr 20 06:29:13.401: INFO: Pod "pod-aab2063b-3be4-4714-b556-e7ee0fee35cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009862943s
STEP: Saw pod success
Apr 20 06:29:13.402: INFO: Pod "pod-aab2063b-3be4-4714-b556-e7ee0fee35cf" satisfied condition "Succeeded or Failed"
Apr 20 06:29:13.404: INFO: Trying to get logs from node node22-hwh1v pod pod-aab2063b-3be4-4714-b556-e7ee0fee35cf container test-container: <nil>
STEP: delete the pod
Apr 20 06:29:13.419: INFO: Waiting for pod pod-aab2063b-3be4-4714-b556-e7ee0fee35cf to disappear
Apr 20 06:29:13.421: INFO: Pod pod-aab2063b-3be4-4714-b556-e7ee0fee35cf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:29:13.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6522" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":162,"skipped":3116,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:29:13.431: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a service externalname-service with the type=ExternalName in namespace services-9742
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-9742
I0420 06:29:13.490840      20 runners.go:190] Created replication controller with name: externalname-service, namespace: services-9742, replica count: 2
Apr 20 06:29:16.541: INFO: Creating new exec pod
I0420 06:29:16.541747      20 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 20 06:29:19.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-9742 exec execpodnxznm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Apr 20 06:29:19.693: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 20 06:29:19.693: INFO: stdout: "externalname-service-sjfpd"
Apr 20 06:29:19.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-9742 exec execpodnxznm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.97.199.245 80'
Apr 20 06:29:19.808: INFO: stderr: "+ nc -v -t -w 2 10.97.199.245 80\n+ echo hostName\nConnection to 10.97.199.245 80 port [tcp/http] succeeded!\n"
Apr 20 06:29:19.808: INFO: stdout: "externalname-service-ddwd2"
Apr 20 06:29:19.808: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:29:19.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9742" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:6.408 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":346,"completed":163,"skipped":3141,"failed":0}
SSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:29:19.839: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a service externalname-service with the type=ExternalName in namespace services-8996
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-8996
I0420 06:29:19.895101      20 runners.go:190] Created replication controller with name: externalname-service, namespace: services-8996, replica count: 2
Apr 20 06:29:22.946: INFO: Creating new exec pod
I0420 06:29:22.946296      20 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 20 06:29:25.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-8996 exec execpod2bcmn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Apr 20 06:29:26.199: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 20 06:29:26.199: INFO: stdout: "externalname-service-fqr2j"
Apr 20 06:29:26.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-8996 exec execpod2bcmn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.103.96.176 80'
Apr 20 06:29:26.328: INFO: stderr: "+ nc -v -t -w 2 10.103.96.176 80\n+ echo hostName\nConnection to 10.103.96.176 80 port [tcp/http] succeeded!\n"
Apr 20 06:29:26.328: INFO: stdout: ""
Apr 20 06:29:27.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-8996 exec execpod2bcmn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.103.96.176 80'
Apr 20 06:29:27.454: INFO: stderr: "+ nc -v -t -w 2 10.103.96.176 80\n+ echo hostName\nConnection to 10.103.96.176 80 port [tcp/http] succeeded!\n"
Apr 20 06:29:27.454: INFO: stdout: ""
Apr 20 06:29:28.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-8996 exec execpod2bcmn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.103.96.176 80'
Apr 20 06:29:28.450: INFO: stderr: "+ nc -v -t -w 2 10.103.96.176 80\n+ echo hostName\nConnection to 10.103.96.176 80 port [tcp/http] succeeded!\n"
Apr 20 06:29:28.450: INFO: stdout: "externalname-service-fqr2j"
Apr 20 06:29:28.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-8996 exec execpod2bcmn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.118.168 31198'
Apr 20 06:29:28.566: INFO: stderr: "+ nc -v -t -w 2 10.100.118.168 31198\n+ echo hostName\nConnection to 10.100.118.168 31198 port [tcp/*] succeeded!\n"
Apr 20 06:29:28.566: INFO: stdout: "externalname-service-m5jhm"
Apr 20 06:29:28.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-8996 exec execpod2bcmn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.99.219 31198'
Apr 20 06:29:28.691: INFO: stderr: "+ nc -v -t -w 2 10.100.99.219 31198\n+ echo hostName\nConnection to 10.100.99.219 31198 port [tcp/*] succeeded!\n"
Apr 20 06:29:28.691: INFO: stdout: ""
Apr 20 06:29:29.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-8996 exec execpod2bcmn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.99.219 31198'
Apr 20 06:29:29.808: INFO: stderr: "+ nc -v -t -w 2 10.100.99.219 31198\nConnection to 10.100.99.219 31198 port [tcp/*] succeeded!\n+ echo hostName\n"
Apr 20 06:29:29.808: INFO: stdout: "externalname-service-m5jhm"
Apr 20 06:29:29.808: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:29:29.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8996" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:10.015 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":346,"completed":164,"skipped":3147,"failed":0}
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:29:29.854: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-6379268a-9e70-4d6d-9c35-e5be65e7920d
STEP: Creating a pod to test consume secrets
Apr 20 06:29:29.892: INFO: Waiting up to 5m0s for pod "pod-secrets-3be5094f-c05f-45d3-8fc2-38bda27412e3" in namespace "secrets-1152" to be "Succeeded or Failed"
Apr 20 06:29:29.894: INFO: Pod "pod-secrets-3be5094f-c05f-45d3-8fc2-38bda27412e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.102132ms
Apr 20 06:29:31.898: INFO: Pod "pod-secrets-3be5094f-c05f-45d3-8fc2-38bda27412e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006416782s
STEP: Saw pod success
Apr 20 06:29:31.898: INFO: Pod "pod-secrets-3be5094f-c05f-45d3-8fc2-38bda27412e3" satisfied condition "Succeeded or Failed"
Apr 20 06:29:31.901: INFO: Trying to get logs from node node22-wriki pod pod-secrets-3be5094f-c05f-45d3-8fc2-38bda27412e3 container secret-volume-test: <nil>
STEP: delete the pod
Apr 20 06:29:31.935: INFO: Waiting for pod pod-secrets-3be5094f-c05f-45d3-8fc2-38bda27412e3 to disappear
Apr 20 06:29:31.937: INFO: Pod pod-secrets-3be5094f-c05f-45d3-8fc2-38bda27412e3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:29:31.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1152" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":346,"completed":165,"skipped":3152,"failed":0}
SSSSSSSS
------------------------------
[sig-network] IngressClass API 
   should support creating IngressClass API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] IngressClass API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:29:31.947: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename ingressclass
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] IngressClass API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/ingressclass.go:148
[It]  should support creating IngressClass API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting /apis
STEP: getting /apis/networking.k8s.io
STEP: getting /apis/networking.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Apr 20 06:29:31.999: INFO: starting watch
STEP: patching
STEP: updating
Apr 20 06:29:32.006: INFO: waiting for watch events with expected annotations
Apr 20 06:29:32.006: INFO: saw patched and updated annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] IngressClass API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:29:32.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-5258" for this suite.
•{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","total":346,"completed":166,"skipped":3160,"failed":0}
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:29:32.032: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:29:48.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1355" for this suite.

• [SLOW TEST:16.155 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":346,"completed":167,"skipped":3164,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should not schedule jobs when suspended [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:29:48.187: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not schedule jobs when suspended [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a suspended cronjob
STEP: Ensuring no jobs are scheduled
STEP: Ensuring no job exists by listing jobs explicitly
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:34:48.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-1523" for this suite.

• [SLOW TEST:300.058 seconds]
[sig-apps] CronJob
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","total":346,"completed":168,"skipped":3179,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:34:48.246: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 20 06:34:48.508: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 20 06:34:51.531: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:34:51.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9004" for this suite.
STEP: Destroying namespace "webhook-9004-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":346,"completed":169,"skipped":3192,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:34:51.690: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 20 06:34:52.075: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 20 06:34:54.087: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63786033292, loc:(*time.Location)(0xa09bc80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786033292, loc:(*time.Location)(0xa09bc80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63786033292, loc:(*time.Location)(0xa09bc80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786033292, loc:(*time.Location)(0xa09bc80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 20 06:34:57.106: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:34:57.109: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:35:00.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4935" for this suite.
STEP: Destroying namespace "webhook-4935-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:8.986 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":346,"completed":170,"skipped":3226,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context 
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:35:00.679: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename security-context
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser
Apr 20 06:35:01.104: INFO: Waiting up to 5m0s for pod "security-context-1b202a81-aed3-40ad-b4ef-30c8c09f7723" in namespace "security-context-5212" to be "Succeeded or Failed"
Apr 20 06:35:01.107: INFO: Pod "security-context-1b202a81-aed3-40ad-b4ef-30c8c09f7723": Phase="Pending", Reason="", readiness=false. Elapsed: 2.606452ms
Apr 20 06:35:03.112: INFO: Pod "security-context-1b202a81-aed3-40ad-b4ef-30c8c09f7723": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007756923s
Apr 20 06:35:05.119: INFO: Pod "security-context-1b202a81-aed3-40ad-b4ef-30c8c09f7723": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014904334s
STEP: Saw pod success
Apr 20 06:35:05.119: INFO: Pod "security-context-1b202a81-aed3-40ad-b4ef-30c8c09f7723" satisfied condition "Succeeded or Failed"
Apr 20 06:35:05.122: INFO: Trying to get logs from node node22-wriki pod security-context-1b202a81-aed3-40ad-b4ef-30c8c09f7723 container test-container: <nil>
STEP: delete the pod
Apr 20 06:35:05.149: INFO: Waiting for pod security-context-1b202a81-aed3-40ad-b4ef-30c8c09f7723 to disappear
Apr 20 06:35:05.151: INFO: Pod security-context-1b202a81-aed3-40ad-b4ef-30c8c09f7723 no longer exists
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:35:05.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-5212" for this suite.
•{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","total":346,"completed":171,"skipped":3256,"failed":0}

------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:35:05.159: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:35:21.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9619" for this suite.

• [SLOW TEST:16.157 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":346,"completed":172,"skipped":3256,"failed":0}
SSSS
------------------------------
[sig-node] Pods 
  should delete a collection of pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:35:21.318: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:188
[It] should delete a collection of pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create set of pods
Apr 20 06:35:21.359: INFO: created test-pod-1
Apr 20 06:35:21.364: INFO: created test-pod-2
Apr 20 06:35:21.368: INFO: created test-pod-3
STEP: waiting for all 3 pods to be located
STEP: waiting for all pods to be deleted
Apr 20 06:35:21.388: INFO: Pod quantity 3 is different from expected quantity 0
Apr 20 06:35:22.394: INFO: Pod quantity 3 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:35:23.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3610" for this suite.
•{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","total":346,"completed":173,"skipped":3260,"failed":0}
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run 
  should check if kubectl can dry-run update Pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:35:23.401: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if kubectl can dry-run update Pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-1
Apr 20 06:35:23.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-7394 run e2e-test-httpd-pod --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Apr 20 06:35:23.566: INFO: stderr: ""
Apr 20 06:35:23.566: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run
Apr 20 06:35:23.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-7394 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "k8s.gcr.io/e2e-test-images/busybox:1.29-1"}]}} --dry-run=server'
Apr 20 06:35:23.737: INFO: stderr: ""
Apr 20 06:35:23.737: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image k8s.gcr.io/e2e-test-images/httpd:2.4.38-1
Apr 20 06:35:23.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-7394 delete pods e2e-test-httpd-pod'
Apr 20 06:35:26.361: INFO: stderr: ""
Apr 20 06:35:26.361: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:35:26.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7394" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","total":346,"completed":174,"skipped":3264,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:35:26.376: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr 20 06:35:27.423: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:35:27.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7227" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":346,"completed":175,"skipped":3283,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:35:27.445: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 20 06:35:27.480: INFO: Waiting up to 5m0s for pod "pod-bf2ce034-a163-4e17-9a65-2325b92ff267" in namespace "emptydir-21" to be "Succeeded or Failed"
Apr 20 06:35:27.482: INFO: Pod "pod-bf2ce034-a163-4e17-9a65-2325b92ff267": Phase="Pending", Reason="", readiness=false. Elapsed: 1.94511ms
Apr 20 06:35:29.487: INFO: Pod "pod-bf2ce034-a163-4e17-9a65-2325b92ff267": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007241106s
STEP: Saw pod success
Apr 20 06:35:29.487: INFO: Pod "pod-bf2ce034-a163-4e17-9a65-2325b92ff267" satisfied condition "Succeeded or Failed"
Apr 20 06:35:29.489: INFO: Trying to get logs from node node22-wriki pod pod-bf2ce034-a163-4e17-9a65-2325b92ff267 container test-container: <nil>
STEP: delete the pod
Apr 20 06:35:29.512: INFO: Waiting for pod pod-bf2ce034-a163-4e17-9a65-2325b92ff267 to disappear
Apr 20 06:35:29.517: INFO: Pod pod-bf2ce034-a163-4e17-9a65-2325b92ff267 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:35:29.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-21" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":176,"skipped":3293,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:35:29.536: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:52
STEP: create the container to handle the HTTPGet hook request.
Apr 20 06:35:29.587: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:35:31.591: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the pod with lifecycle hook
Apr 20 06:35:31.602: INFO: The status of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:35:33.608: INFO: The status of Pod pod-with-prestop-http-hook is Running (Ready = true)
STEP: delete the pod with lifecycle hook
Apr 20 06:35:33.616: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 20 06:35:33.619: INFO: Pod pod-with-prestop-http-hook still exists
Apr 20 06:35:35.620: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 20 06:35:35.627: INFO: Pod pod-with-prestop-http-hook still exists
Apr 20 06:35:37.619: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 20 06:35:37.623: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:35:37.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8199" for this suite.

• [SLOW TEST:8.103 seconds]
[sig-node] Container Lifecycle Hook
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:43
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":346,"completed":177,"skipped":3329,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:35:37.640: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with secret that has name projected-secret-test-map-e910bdb8-6746-4db2-88be-2949f0ef598f
STEP: Creating a pod to test consume secrets
Apr 20 06:35:37.684: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d39cdcf7-4097-4eba-b71e-bbc57de2ea36" in namespace "projected-3269" to be "Succeeded or Failed"
Apr 20 06:35:37.687: INFO: Pod "pod-projected-secrets-d39cdcf7-4097-4eba-b71e-bbc57de2ea36": Phase="Pending", Reason="", readiness=false. Elapsed: 3.420512ms
Apr 20 06:35:39.695: INFO: Pod "pod-projected-secrets-d39cdcf7-4097-4eba-b71e-bbc57de2ea36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011507041s
STEP: Saw pod success
Apr 20 06:35:39.696: INFO: Pod "pod-projected-secrets-d39cdcf7-4097-4eba-b71e-bbc57de2ea36" satisfied condition "Succeeded or Failed"
Apr 20 06:35:39.698: INFO: Trying to get logs from node node22-hwh1v pod pod-projected-secrets-d39cdcf7-4097-4eba-b71e-bbc57de2ea36 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 20 06:35:39.723: INFO: Waiting for pod pod-projected-secrets-d39cdcf7-4097-4eba-b71e-bbc57de2ea36 to disappear
Apr 20 06:35:39.725: INFO: Pod pod-projected-secrets-d39cdcf7-4097-4eba-b71e-bbc57de2ea36 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:35:39.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3269" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":178,"skipped":3355,"failed":0}
SSSS
------------------------------
[sig-node] Security Context 
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:35:39.733: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename security-context
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser
Apr 20 06:35:39.769: INFO: Waiting up to 5m0s for pod "security-context-9f1f7336-37e8-4afa-91cd-caf0ef6a6214" in namespace "security-context-4295" to be "Succeeded or Failed"
Apr 20 06:35:39.771: INFO: Pod "security-context-9f1f7336-37e8-4afa-91cd-caf0ef6a6214": Phase="Pending", Reason="", readiness=false. Elapsed: 2.531904ms
Apr 20 06:35:41.776: INFO: Pod "security-context-9f1f7336-37e8-4afa-91cd-caf0ef6a6214": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007162722s
STEP: Saw pod success
Apr 20 06:35:41.776: INFO: Pod "security-context-9f1f7336-37e8-4afa-91cd-caf0ef6a6214" satisfied condition "Succeeded or Failed"
Apr 20 06:35:41.778: INFO: Trying to get logs from node node22-hwh1v pod security-context-9f1f7336-37e8-4afa-91cd-caf0ef6a6214 container test-container: <nil>
STEP: delete the pod
Apr 20 06:35:41.793: INFO: Waiting for pod security-context-9f1f7336-37e8-4afa-91cd-caf0ef6a6214 to disappear
Apr 20 06:35:41.795: INFO: Pod security-context-9f1f7336-37e8-4afa-91cd-caf0ef6a6214 no longer exists
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:35:41.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-4295" for this suite.
•{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","total":346,"completed":179,"skipped":3359,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:35:41.803: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:35:41.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-2291 create -f -'
Apr 20 06:35:41.991: INFO: stderr: ""
Apr 20 06:35:41.991: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Apr 20 06:35:41.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-2291 create -f -'
Apr 20 06:35:42.132: INFO: stderr: ""
Apr 20 06:35:42.132: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Apr 20 06:35:43.138: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 20 06:35:43.138: INFO: Found 0 / 1
Apr 20 06:35:44.137: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 20 06:35:44.137: INFO: Found 1 / 1
Apr 20 06:35:44.137: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 20 06:35:44.142: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 20 06:35:44.142: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 20 06:35:44.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-2291 describe pod agnhost-primary-sv9pc'
Apr 20 06:35:44.211: INFO: stderr: ""
Apr 20 06:35:44.211: INFO: stdout: "Name:         agnhost-primary-sv9pc\nNamespace:    kubectl-2291\nPriority:     0\nNode:         node22-hwh1v/10.100.125.144\nStart Time:   Wed, 20 Apr 2022 06:35:42 +0000\nLabels:       app=agnhost\n              role=primary\nAnnotations:  cni.projectcalico.org/podIP: 10.233.0.91/32\n              cni.projectcalico.org/podIPs: 10.233.0.91/32\nStatus:       Running\nIP:           10.233.0.91\nIPs:\n  IP:           10.233.0.91\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://3b562c50558c1fc8e4b56061766a9af39b9a36b2304e52616c0cc73afda847ef\n    Image:          k8s.gcr.io/e2e-test-images/agnhost:2.32\n    Image ID:       k8s.gcr.io/e2e-test-images/agnhost@sha256:758db666ac7028534dba72e7e9bb1e57bb81b8196f976f7a5cc351ef8b3529e1\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 20 Apr 2022 06:35:42 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-5hgvn (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-5hgvn:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-2291/agnhost-primary-sv9pc to node22-hwh1v\n  Normal  Pulled     2s    kubelet            Container image \"k8s.gcr.io/e2e-test-images/agnhost:2.32\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    2s    kubelet            Started container agnhost-primary\n"
Apr 20 06:35:44.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-2291 describe rc agnhost-primary'
Apr 20 06:35:44.278: INFO: stderr: ""
Apr 20 06:35:44.278: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-2291\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        k8s.gcr.io/e2e-test-images/agnhost:2.32\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-sv9pc\n"
Apr 20 06:35:44.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-2291 describe service agnhost-primary'
Apr 20 06:35:44.335: INFO: stderr: ""
Apr 20 06:35:44.335: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-2291\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.96.84.202\nIPs:               10.96.84.202\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.233.0.91:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr 20 06:35:44.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-2291 describe node node22-07idr'
Apr 20 06:35:44.408: INFO: stderr: ""
Apr 20 06:35:44.408: INFO: stdout: "Name:               node22-07idr\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=medium\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=jp-east-1\n                    failure-domain.beta.kubernetes.io/zone=east-11\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=node22-07idr\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/instance-type=medium\n                    topology.kubernetes.io/region=jp-east-1\n                    topology.kubernetes.io/zone=east-11\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"36:9f:09:3a:d0:a6\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 111.171.205.217\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.100.118.168/15\n                    projectcalico.org/IPv4IPIPTunnelAddr: 10.233.1.1\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 20 Apr 2022 05:37:04 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  node22-07idr\n  AcquireTime:     <unset>\n  RenewTime:       Wed, 20 Apr 2022 06:35:38 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Wed, 20 Apr 2022 05:37:38 +0000   Wed, 20 Apr 2022 05:37:38 +0000   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Wed, 20 Apr 2022 06:35:06 +0000   Wed, 20 Apr 2022 05:37:04 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Wed, 20 Apr 2022 06:35:06 +0000   Wed, 20 Apr 2022 05:37:04 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Wed, 20 Apr 2022 06:35:06 +0000   Wed, 20 Apr 2022 05:37:04 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Wed, 20 Apr 2022 06:35:06 +0000   Wed, 20 Apr 2022 05:37:24 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  ExternalIP:  111.171.205.217\n  InternalIP:  10.100.118.168\n  Hostname:    node22-07idr\nCapacity:\n  cpu:                2\n  ephemeral-storage:  28196788Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             2006928Ki\n  pods:               100\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  25986159778\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             1597328Ki\n  pods:               100\nSystem Info:\n  Machine ID:                 4a524a04bf8e4e0399b261646a18743d\n  System UUID:                18363042-d53b-4cb8-2d71-3b42e86422a8\n  Boot ID:                    e1a91b1c-d6ea-48eb-8239-c53faeda1c20\n  Kernel Version:             5.4.0-33-generic\n  OS Image:                   Ubuntu 20.04 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.4.3\n  Kubelet Version:            v1.22.2\n  Kube-Proxy Version:         v1.22.2\nPodCIDR:                      10.233.1.0/24\nPodCIDRs:                     10.233.1.0/24\nProviderID:                   hatoba:///east-11/i-0v3awxn7\nNon-terminated Pods:          (4 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 canal-7z4s7                                                250m (12%)    0 (0%)      0 (0%)           0 (0%)         58m\n  kube-system                 konnectivity-agent-z8v6h                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         58m\n  sonobuoy                    sonobuoy-e2e-job-14e586816b6a497d                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         46m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-cdcdd281c10f40dc-vvhct    0 (0%)        0 (0%)      0 (0%)           0 (0%)         46m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                250m (12%)  0 (0%)\n  memory             0 (0%)      0 (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:\n  Type     Reason                   Age                From     Message\n  ----     ------                   ----               ----     -------\n  Normal   Starting                 58m                kubelet  Starting kubelet.\n  Warning  InvalidDiskCapacity      58m                kubelet  invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientMemory  58m (x2 over 58m)  kubelet  Node node22-07idr status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    58m (x2 over 58m)  kubelet  Node node22-07idr status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     58m (x2 over 58m)  kubelet  Node node22-07idr status is now: NodeHasSufficientPID\n  Normal   NodeAllocatableEnforced  58m                kubelet  Updated Node Allocatable limit across pods\n  Normal   NodeReady                58m                kubelet  Node node22-07idr status is now: NodeReady\n"
Apr 20 06:35:44.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-2291 describe namespace kubectl-2291'
Apr 20 06:35:44.467: INFO: stderr: ""
Apr 20 06:35:44.467: INFO: stdout: "Name:         kubectl-2291\nLabels:       e2e-framework=kubectl\n              e2e-run=6979b115-fb28-4782-b91c-53cfcb275f02\n              kubernetes.io/metadata.name=kubectl-2291\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:35:44.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2291" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":346,"completed":180,"skipped":3396,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:35:44.475: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr 20 06:35:44.515: INFO: Waiting up to 5m0s for pod "downwardapi-volume-510cdab5-7226-4808-ade0-07fa022ea17b" in namespace "projected-1015" to be "Succeeded or Failed"
Apr 20 06:35:44.517: INFO: Pod "downwardapi-volume-510cdab5-7226-4808-ade0-07fa022ea17b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.225118ms
Apr 20 06:35:46.520: INFO: Pod "downwardapi-volume-510cdab5-7226-4808-ade0-07fa022ea17b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005258459s
STEP: Saw pod success
Apr 20 06:35:46.520: INFO: Pod "downwardapi-volume-510cdab5-7226-4808-ade0-07fa022ea17b" satisfied condition "Succeeded or Failed"
Apr 20 06:35:46.523: INFO: Trying to get logs from node node22-wriki pod downwardapi-volume-510cdab5-7226-4808-ade0-07fa022ea17b container client-container: <nil>
STEP: delete the pod
Apr 20 06:35:46.546: INFO: Waiting for pod downwardapi-volume-510cdab5-7226-4808-ade0-07fa022ea17b to disappear
Apr 20 06:35:46.548: INFO: Pod downwardapi-volume-510cdab5-7226-4808-ade0-07fa022ea17b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:35:46.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1015" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":346,"completed":181,"skipped":3430,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:35:46.556: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Performing setup for networking test in namespace pod-network-test-9400
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 20 06:35:46.586: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 20 06:35:46.647: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:35:48.653: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 20 06:35:50.654: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 20 06:35:52.652: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 20 06:35:54.654: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 20 06:35:56.652: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 20 06:35:58.656: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 20 06:36:00.654: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 20 06:36:02.657: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 20 06:36:04.656: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 20 06:36:06.652: INFO: The status of Pod netserver-0 is Running (Ready = true)
Apr 20 06:36:06.656: INFO: The status of Pod netserver-1 is Running (Ready = true)
Apr 20 06:36:06.659: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Apr 20 06:36:08.682: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Apr 20 06:36:08.682: INFO: Going to poll 10.233.1.64 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Apr 20 06:36:08.684: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.1.64 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9400 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 06:36:08.684: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 06:36:09.765: INFO: Found all 1 expected endpoints: [netserver-0]
Apr 20 06:36:09.765: INFO: Going to poll 10.233.0.92 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Apr 20 06:36:09.769: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.0.92 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9400 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 06:36:09.769: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 06:36:10.827: INFO: Found all 1 expected endpoints: [netserver-1]
Apr 20 06:36:10.828: INFO: Going to poll 10.233.2.138 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Apr 20 06:36:10.834: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.2.138 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9400 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 06:36:10.834: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 06:36:11.921: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:36:11.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9400" for this suite.

• [SLOW TEST:25.378 seconds]
[sig-network] Networking
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/networking.go:30
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":182,"skipped":3449,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff 
  should check if kubectl diff finds a difference for Deployments [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:36:11.939: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create deployment with httpd image
Apr 20 06:36:11.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-6753 create -f -'
Apr 20 06:36:12.144: INFO: stderr: ""
Apr 20 06:36:12.144: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image
Apr 20 06:36:12.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-6753 diff -f -'
Apr 20 06:36:12.308: INFO: rc: 1
Apr 20 06:36:12.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-6753 delete -f -'
Apr 20 06:36:12.364: INFO: stderr: ""
Apr 20 06:36:12.364: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:36:12.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6753" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","total":346,"completed":183,"skipped":3478,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:36:12.375: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-83c30ddf-e996-4783-9c1a-3330f652fe19
STEP: Creating a pod to test consume secrets
Apr 20 06:36:12.409: INFO: Waiting up to 5m0s for pod "pod-secrets-663ddc3c-93b2-4211-aa53-3c1b2a7e52a4" in namespace "secrets-4328" to be "Succeeded or Failed"
Apr 20 06:36:12.411: INFO: Pod "pod-secrets-663ddc3c-93b2-4211-aa53-3c1b2a7e52a4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.495156ms
Apr 20 06:36:14.418: INFO: Pod "pod-secrets-663ddc3c-93b2-4211-aa53-3c1b2a7e52a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008919176s
STEP: Saw pod success
Apr 20 06:36:14.418: INFO: Pod "pod-secrets-663ddc3c-93b2-4211-aa53-3c1b2a7e52a4" satisfied condition "Succeeded or Failed"
Apr 20 06:36:14.424: INFO: Trying to get logs from node node22-wriki pod pod-secrets-663ddc3c-93b2-4211-aa53-3c1b2a7e52a4 container secret-env-test: <nil>
STEP: delete the pod
Apr 20 06:36:14.440: INFO: Waiting for pod pod-secrets-663ddc3c-93b2-4211-aa53-3c1b2a7e52a4 to disappear
Apr 20 06:36:14.442: INFO: Pod pod-secrets-663ddc3c-93b2-4211-aa53-3c1b2a7e52a4 no longer exists
[AfterEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:36:14.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4328" for this suite.
•{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":346,"completed":184,"skipped":3521,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:36:14.451: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-map-a85eae69-5141-4785-88eb-4c8f907b6a22
STEP: Creating a pod to test consume configMaps
Apr 20 06:36:14.494: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-45697b50-8ebc-4ddf-864b-edafa70a2e4b" in namespace "projected-1707" to be "Succeeded or Failed"
Apr 20 06:36:14.496: INFO: Pod "pod-projected-configmaps-45697b50-8ebc-4ddf-864b-edafa70a2e4b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.131225ms
Apr 20 06:36:16.499: INFO: Pod "pod-projected-configmaps-45697b50-8ebc-4ddf-864b-edafa70a2e4b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005241947s
STEP: Saw pod success
Apr 20 06:36:16.499: INFO: Pod "pod-projected-configmaps-45697b50-8ebc-4ddf-864b-edafa70a2e4b" satisfied condition "Succeeded or Failed"
Apr 20 06:36:16.501: INFO: Trying to get logs from node node22-07idr pod pod-projected-configmaps-45697b50-8ebc-4ddf-864b-edafa70a2e4b container agnhost-container: <nil>
STEP: delete the pod
Apr 20 06:36:16.545: INFO: Waiting for pod pod-projected-configmaps-45697b50-8ebc-4ddf-864b-edafa70a2e4b to disappear
Apr 20 06:36:16.547: INFO: Pod pod-projected-configmaps-45697b50-8ebc-4ddf-864b-edafa70a2e4b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:36:16.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1707" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":185,"skipped":3528,"failed":0}
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:36:16.558: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:90
Apr 20 06:36:16.585: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 20 06:36:16.590: INFO: Waiting for terminating namespaces to be deleted...
Apr 20 06:36:16.591: INFO: 
Logging pods the apiserver thinks is on node node22-07idr before test
Apr 20 06:36:16.595: INFO: canal-7z4s7 from kube-system started at 2022-04-20 05:37:05 +0000 UTC (2 container statuses recorded)
Apr 20 06:36:16.595: INFO: 	Container calico-node ready: true, restart count 0
Apr 20 06:36:16.595: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 20 06:36:16.595: INFO: konnectivity-agent-z8v6h from kube-system started at 2022-04-20 05:37:24 +0000 UTC (1 container statuses recorded)
Apr 20 06:36:16.595: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 20 06:36:16.595: INFO: netserver-0 from pod-network-test-9400 started at 2022-04-20 06:35:46 +0000 UTC (1 container statuses recorded)
Apr 20 06:36:16.595: INFO: 	Container webserver ready: true, restart count 0
Apr 20 06:36:16.595: INFO: test-container-pod from pod-network-test-9400 started at 2022-04-20 06:36:06 +0000 UTC (1 container statuses recorded)
Apr 20 06:36:16.595: INFO: 	Container webserver ready: true, restart count 0
Apr 20 06:36:16.595: INFO: sonobuoy-e2e-job-14e586816b6a497d from sonobuoy started at 2022-04-20 05:49:38 +0000 UTC (2 container statuses recorded)
Apr 20 06:36:16.595: INFO: 	Container e2e ready: true, restart count 0
Apr 20 06:36:16.595: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 20 06:36:16.595: INFO: sonobuoy-systemd-logs-daemon-set-cdcdd281c10f40dc-vvhct from sonobuoy started at 2022-04-20 05:49:38 +0000 UTC (2 container statuses recorded)
Apr 20 06:36:16.595: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 20 06:36:16.595: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 20 06:36:16.595: INFO: 
Logging pods the apiserver thinks is on node node22-hwh1v before test
Apr 20 06:36:16.600: INFO: calico-kube-controllers-5544f8d8d9-2pr5d from kube-system started at 2022-04-20 05:37:23 +0000 UTC (1 container statuses recorded)
Apr 20 06:36:16.600: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 20 06:36:16.600: INFO: canal-xrqg4 from kube-system started at 2022-04-20 05:37:04 +0000 UTC (2 container statuses recorded)
Apr 20 06:36:16.600: INFO: 	Container calico-node ready: true, restart count 0
Apr 20 06:36:16.600: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 20 06:36:16.600: INFO: coredns-748f75f5fb-2n9dt from kube-system started at 2022-04-20 05:37:23 +0000 UTC (1 container statuses recorded)
Apr 20 06:36:16.600: INFO: 	Container coredns ready: true, restart count 0
Apr 20 06:36:16.600: INFO: coredns-748f75f5fb-8sfr7 from kube-system started at 2022-04-20 05:37:23 +0000 UTC (1 container statuses recorded)
Apr 20 06:36:16.600: INFO: 	Container coredns ready: true, restart count 0
Apr 20 06:36:16.600: INFO: konnectivity-agent-9q5dq from kube-system started at 2022-04-20 05:37:23 +0000 UTC (1 container statuses recorded)
Apr 20 06:36:16.600: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 20 06:36:16.600: INFO: host-test-container-pod from pod-network-test-9400 started at 2022-04-20 06:36:06 +0000 UTC (1 container statuses recorded)
Apr 20 06:36:16.600: INFO: 	Container agnhost-container ready: true, restart count 0
Apr 20 06:36:16.601: INFO: netserver-1 from pod-network-test-9400 started at 2022-04-20 06:35:46 +0000 UTC (1 container statuses recorded)
Apr 20 06:36:16.601: INFO: 	Container webserver ready: true, restart count 0
Apr 20 06:36:16.601: INFO: sonobuoy-systemd-logs-daemon-set-cdcdd281c10f40dc-dc45f from sonobuoy started at 2022-04-20 05:49:38 +0000 UTC (2 container statuses recorded)
Apr 20 06:36:16.601: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 20 06:36:16.601: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 20 06:36:16.601: INFO: 
Logging pods the apiserver thinks is on node node22-wriki before test
Apr 20 06:36:16.605: INFO: canal-r5jz2 from kube-system started at 2022-04-20 05:37:06 +0000 UTC (2 container statuses recorded)
Apr 20 06:36:16.605: INFO: 	Container calico-node ready: true, restart count 0
Apr 20 06:36:16.605: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 20 06:36:16.605: INFO: konnectivity-agent-vgl4v from kube-system started at 2022-04-20 06:27:48 +0000 UTC (1 container statuses recorded)
Apr 20 06:36:16.605: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 20 06:36:16.605: INFO: httpd-deployment-8584777d8-ghqqh from kubectl-6753 started at 2022-04-20 06:36:12 +0000 UTC (1 container statuses recorded)
Apr 20 06:36:16.605: INFO: 	Container httpd ready: false, restart count 0
Apr 20 06:36:16.605: INFO: netserver-2 from pod-network-test-9400 started at 2022-04-20 06:35:46 +0000 UTC (1 container statuses recorded)
Apr 20 06:36:16.605: INFO: 	Container webserver ready: true, restart count 0
Apr 20 06:36:16.605: INFO: sonobuoy from sonobuoy started at 2022-04-20 05:49:32 +0000 UTC (1 container statuses recorded)
Apr 20 06:36:16.605: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 20 06:36:16.605: INFO: sonobuoy-systemd-logs-daemon-set-cdcdd281c10f40dc-48vdz from sonobuoy started at 2022-04-20 05:49:39 +0000 UTC (2 container statuses recorded)
Apr 20 06:36:16.605: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 20 06:36:16.605: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: verifying the node has the label node node22-07idr
STEP: verifying the node has the label node node22-hwh1v
STEP: verifying the node has the label node node22-wriki
Apr 20 06:36:16.662: INFO: Pod calico-kube-controllers-5544f8d8d9-2pr5d requesting resource cpu=0m on Node node22-hwh1v
Apr 20 06:36:16.662: INFO: Pod canal-7z4s7 requesting resource cpu=250m on Node node22-07idr
Apr 20 06:36:16.662: INFO: Pod canal-r5jz2 requesting resource cpu=250m on Node node22-wriki
Apr 20 06:36:16.662: INFO: Pod canal-xrqg4 requesting resource cpu=250m on Node node22-hwh1v
Apr 20 06:36:16.662: INFO: Pod coredns-748f75f5fb-2n9dt requesting resource cpu=100m on Node node22-hwh1v
Apr 20 06:36:16.662: INFO: Pod coredns-748f75f5fb-8sfr7 requesting resource cpu=100m on Node node22-hwh1v
Apr 20 06:36:16.662: INFO: Pod konnectivity-agent-9q5dq requesting resource cpu=0m on Node node22-hwh1v
Apr 20 06:36:16.662: INFO: Pod konnectivity-agent-vgl4v requesting resource cpu=0m on Node node22-wriki
Apr 20 06:36:16.662: INFO: Pod konnectivity-agent-z8v6h requesting resource cpu=0m on Node node22-07idr
Apr 20 06:36:16.662: INFO: Pod httpd-deployment-8584777d8-ghqqh requesting resource cpu=0m on Node node22-wriki
Apr 20 06:36:16.662: INFO: Pod host-test-container-pod requesting resource cpu=0m on Node node22-hwh1v
Apr 20 06:36:16.662: INFO: Pod netserver-0 requesting resource cpu=0m on Node node22-07idr
Apr 20 06:36:16.662: INFO: Pod netserver-1 requesting resource cpu=0m on Node node22-hwh1v
Apr 20 06:36:16.662: INFO: Pod netserver-2 requesting resource cpu=0m on Node node22-wriki
Apr 20 06:36:16.662: INFO: Pod test-container-pod requesting resource cpu=0m on Node node22-07idr
Apr 20 06:36:16.662: INFO: Pod sonobuoy requesting resource cpu=0m on Node node22-wriki
Apr 20 06:36:16.662: INFO: Pod sonobuoy-e2e-job-14e586816b6a497d requesting resource cpu=0m on Node node22-07idr
Apr 20 06:36:16.662: INFO: Pod sonobuoy-systemd-logs-daemon-set-cdcdd281c10f40dc-48vdz requesting resource cpu=0m on Node node22-wriki
Apr 20 06:36:16.662: INFO: Pod sonobuoy-systemd-logs-daemon-set-cdcdd281c10f40dc-dc45f requesting resource cpu=0m on Node node22-hwh1v
Apr 20 06:36:16.662: INFO: Pod sonobuoy-systemd-logs-daemon-set-cdcdd281c10f40dc-vvhct requesting resource cpu=0m on Node node22-07idr
STEP: Starting Pods to consume most of the cluster CPU.
Apr 20 06:36:16.662: INFO: Creating a pod which consumes cpu=1225m on Node node22-07idr
Apr 20 06:36:16.668: INFO: Creating a pod which consumes cpu=1085m on Node node22-hwh1v
Apr 20 06:36:16.672: INFO: Creating a pod which consumes cpu=1225m on Node node22-wriki
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-01afae8e-2f99-4d21-9255-431ef00485a1.16e7875277be463b], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3208/filler-pod-01afae8e-2f99-4d21-9255-431ef00485a1 to node22-07idr]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-01afae8e-2f99-4d21-9255-431ef00485a1.16e78752ab3e4954], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.5" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-01afae8e-2f99-4d21-9255-431ef00485a1.16e78752ac3fca11], Reason = [Created], Message = [Created container filler-pod-01afae8e-2f99-4d21-9255-431ef00485a1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-01afae8e-2f99-4d21-9255-431ef00485a1.16e78752b09833a8], Reason = [Started], Message = [Started container filler-pod-01afae8e-2f99-4d21-9255-431ef00485a1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-09edc68d-6de2-4e90-a535-504f24c7e670.16e7875278b54f26], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3208/filler-pod-09edc68d-6de2-4e90-a535-504f24c7e670 to node22-wriki]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-09edc68d-6de2-4e90-a535-504f24c7e670.16e78752a9a45c04], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.5" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-09edc68d-6de2-4e90-a535-504f24c7e670.16e78752aabb9f4f], Reason = [Created], Message = [Created container filler-pod-09edc68d-6de2-4e90-a535-504f24c7e670]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-09edc68d-6de2-4e90-a535-504f24c7e670.16e78752af39d17e], Reason = [Started], Message = [Started container filler-pod-09edc68d-6de2-4e90-a535-504f24c7e670]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b72b49e7-e07d-49f2-a41a-596bc34aafb0.16e78752786cd5e0], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3208/filler-pod-b72b49e7-e07d-49f2-a41a-596bc34aafb0 to node22-hwh1v]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b72b49e7-e07d-49f2-a41a-596bc34aafb0.16e78752a99453e4], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.5" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b72b49e7-e07d-49f2-a41a-596bc34aafb0.16e78752ab91c8de], Reason = [Created], Message = [Created container filler-pod-b72b49e7-e07d-49f2-a41a-596bc34aafb0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b72b49e7-e07d-49f2-a41a-596bc34aafb0.16e78752b06186ec], Reason = [Started], Message = [Started container filler-pod-b72b49e7-e07d-49f2-a41a-596bc34aafb0]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.16e78752f09fe977], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node node22-07idr
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node node22-hwh1v
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node node22-wriki
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:36:19.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3208" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":346,"completed":186,"skipped":3533,"failed":0}

------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:36:19.764: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:92
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:107
STEP: Creating service test in namespace statefulset-1256
[It] should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating statefulset ss in namespace statefulset-1256
Apr 20 06:36:19.843: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Apr 20 06:36:29.851: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
STEP: Patch a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:118
Apr 20 06:36:29.880: INFO: Deleting all statefulset in ns statefulset-1256
Apr 20 06:36:29.882: INFO: Scaling statefulset ss to 0
Apr 20 06:36:39.907: INFO: Waiting for statefulset status.replicas updated to 0
Apr 20 06:36:39.909: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:36:39.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1256" for this suite.

• [SLOW TEST:20.160 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:97
    should have a working scale subresource [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":346,"completed":187,"skipped":3533,"failed":0}
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:36:39.924: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 20 06:36:39.960: INFO: Waiting up to 5m0s for pod "pod-608903eb-412d-48a6-a0a6-284f01714554" in namespace "emptydir-1810" to be "Succeeded or Failed"
Apr 20 06:36:39.961: INFO: Pod "pod-608903eb-412d-48a6-a0a6-284f01714554": Phase="Pending", Reason="", readiness=false. Elapsed: 1.677257ms
Apr 20 06:36:41.965: INFO: Pod "pod-608903eb-412d-48a6-a0a6-284f01714554": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005214481s
STEP: Saw pod success
Apr 20 06:36:41.965: INFO: Pod "pod-608903eb-412d-48a6-a0a6-284f01714554" satisfied condition "Succeeded or Failed"
Apr 20 06:36:41.967: INFO: Trying to get logs from node node22-hwh1v pod pod-608903eb-412d-48a6-a0a6-284f01714554 container test-container: <nil>
STEP: delete the pod
Apr 20 06:36:41.982: INFO: Waiting for pod pod-608903eb-412d-48a6-a0a6-284f01714554 to disappear
Apr 20 06:36:41.995: INFO: Pod pod-608903eb-412d-48a6-a0a6-284f01714554 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:36:41.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1810" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":188,"skipped":3536,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:36:42.004: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0420 06:36:52.109382      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr 20 06:36:52.109: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Apr 20 06:36:52.109: INFO: Deleting pod "simpletest-rc-to-be-deleted-5jc7f" in namespace "gc-1133"
Apr 20 06:36:52.127: INFO: Deleting pod "simpletest-rc-to-be-deleted-6mw9m" in namespace "gc-1133"
Apr 20 06:36:52.155: INFO: Deleting pod "simpletest-rc-to-be-deleted-8bz22" in namespace "gc-1133"
Apr 20 06:36:52.172: INFO: Deleting pod "simpletest-rc-to-be-deleted-9rj88" in namespace "gc-1133"
Apr 20 06:36:52.181: INFO: Deleting pod "simpletest-rc-to-be-deleted-brkcg" in namespace "gc-1133"
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:36:52.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1133" for this suite.

• [SLOW TEST:10.197 seconds]
[sig-api-machinery] Garbage collector
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":346,"completed":189,"skipped":3594,"failed":0}
SSSS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:36:52.201: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test substitution in container's args
Apr 20 06:36:52.250: INFO: Waiting up to 5m0s for pod "var-expansion-87a1d87f-00ce-476f-82a3-19bff1dfe2af" in namespace "var-expansion-9509" to be "Succeeded or Failed"
Apr 20 06:36:52.252: INFO: Pod "var-expansion-87a1d87f-00ce-476f-82a3-19bff1dfe2af": Phase="Pending", Reason="", readiness=false. Elapsed: 1.883514ms
Apr 20 06:36:54.257: INFO: Pod "var-expansion-87a1d87f-00ce-476f-82a3-19bff1dfe2af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007431278s
STEP: Saw pod success
Apr 20 06:36:54.258: INFO: Pod "var-expansion-87a1d87f-00ce-476f-82a3-19bff1dfe2af" satisfied condition "Succeeded or Failed"
Apr 20 06:36:54.260: INFO: Trying to get logs from node node22-hwh1v pod var-expansion-87a1d87f-00ce-476f-82a3-19bff1dfe2af container dapi-container: <nil>
STEP: delete the pod
Apr 20 06:36:54.281: INFO: Waiting for pod var-expansion-87a1d87f-00ce-476f-82a3-19bff1dfe2af to disappear
Apr 20 06:36:54.283: INFO: Pod var-expansion-87a1d87f-00ce-476f-82a3-19bff1dfe2af no longer exists
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:36:54.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9509" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":346,"completed":190,"skipped":3598,"failed":0}
S
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:36:54.292: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/init_container.go:162
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
Apr 20 06:36:54.325: INFO: PodSpec: initContainers in spec.initContainers
Apr 20 06:37:42.704: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-3c7b6eeb-f1b4-4dfd-bf81-b7cc03006f83", GenerateName:"", Namespace:"init-container-6524", SelfLink:"", UID:"3faa1d59-2b75-43b7-a168-ee7a65035d8e", ResourceVersion:"24784", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63786033414, loc:(*time.Location)(0xa09bc80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"325571416"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.233.0.101/32", "cni.projectcalico.org/podIPs":"10.233.0.101/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc00224a840), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00224a858), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc00224a870), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00224a888), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc00224a8a0), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00224a8b8), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-q2f7r", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc003c14120), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-1", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-q2f7r", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-1", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-q2f7r", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.5", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-q2f7r", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003cc4398), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"node22-hwh1v", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc004054150), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003cc4420)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003cc4440)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc003cc4448), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc003cc444c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc003a0bb70), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786033414, loc:(*time.Location)(0xa09bc80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786033414, loc:(*time.Location)(0xa09bc80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786033414, loc:(*time.Location)(0xa09bc80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786033414, loc:(*time.Location)(0xa09bc80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.100.125.144", PodIP:"10.233.0.101", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.233.0.101"}}, StartTime:(*v1.Time)(0xc00224a8e8), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc004054230)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0040542a0)}, Ready:false, RestartCount:3, Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-1", ImageID:"k8s.gcr.io/e2e-test-images/busybox@sha256:39e1e963e5310e9c313bad51523be012ede7b35bb9316517d19089a010356592", ContainerID:"containerd://e01626bab0410cf76dcf64cd47f6100b39598f81464095255300755f65faf3a9", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003c14220), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-1", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003c14200), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.5", ImageID:"", ContainerID:"", Started:(*bool)(0xc003cc44ff)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:37:42.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6524" for this suite.

• [SLOW TEST:48.425 seconds]
[sig-node] InitContainer [NodeConformance]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":346,"completed":191,"skipped":3599,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring 
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] EndpointSliceMirroring
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:37:42.718: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename endpointslicemirroring
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSliceMirroring
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/endpointslicemirroring.go:39
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: mirroring a new custom Endpoint
Apr 20 06:37:42.778: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint
Apr 20 06:37:44.795: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
STEP: mirroring deletion of a custom Endpoint
Apr 20 06:37:46.811: INFO: Waiting for 0 EndpointSlices to exist, got 1
[AfterEach] [sig-network] EndpointSliceMirroring
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:37:48.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-2645" for this suite.

• [SLOW TEST:6.108 seconds]
[sig-network] EndpointSliceMirroring
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","total":346,"completed":192,"skipped":3625,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should patch a Namespace [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:37:48.826: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a Namespace [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a Namespace
STEP: patching the Namespace
STEP: get the Namespace and ensuring it has the label
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:37:48.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5573" for this suite.
STEP: Destroying namespace "nspatchtest-60a4487a-a548-448e-983d-9aec25dd203f-262" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","total":346,"completed":193,"skipped":3643,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:37:48.911: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 20 06:37:49.321: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 20 06:37:52.351: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:37:52.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3462" for this suite.
STEP: Destroying namespace "webhook-3462-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":346,"completed":194,"skipped":3650,"failed":0}
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:37:52.467: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 20 06:37:52.503: INFO: Waiting up to 5m0s for pod "pod-df037dda-0e0d-43cd-9e15-e613547e5087" in namespace "emptydir-9866" to be "Succeeded or Failed"
Apr 20 06:37:52.505: INFO: Pod "pod-df037dda-0e0d-43cd-9e15-e613547e5087": Phase="Pending", Reason="", readiness=false. Elapsed: 2.245608ms
Apr 20 06:37:54.512: INFO: Pod "pod-df037dda-0e0d-43cd-9e15-e613547e5087": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009056711s
STEP: Saw pod success
Apr 20 06:37:54.512: INFO: Pod "pod-df037dda-0e0d-43cd-9e15-e613547e5087" satisfied condition "Succeeded or Failed"
Apr 20 06:37:54.515: INFO: Trying to get logs from node node22-hwh1v pod pod-df037dda-0e0d-43cd-9e15-e613547e5087 container test-container: <nil>
STEP: delete the pod
Apr 20 06:37:54.529: INFO: Waiting for pod pod-df037dda-0e0d-43cd-9e15-e613547e5087 to disappear
Apr 20 06:37:54.531: INFO: Pod pod-df037dda-0e0d-43cd-9e15-e613547e5087 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:37:54.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9866" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":195,"skipped":3654,"failed":0}
SSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] 
  should support CSR API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:37:54.538: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename certificates
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support CSR API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting /apis
STEP: getting /apis/certificates.k8s.io
STEP: getting /apis/certificates.k8s.io/v1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Apr 20 06:37:55.104: INFO: starting watch
STEP: patching
STEP: updating
Apr 20 06:37:55.115: INFO: waiting for watch events with expected annotations
Apr 20 06:37:55.115: INFO: saw patched and updated annotations
STEP: getting /approval
STEP: patching /approval
STEP: updating /approval
STEP: getting /status
STEP: patching /status
STEP: updating /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:37:55.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-5416" for this suite.
•{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","total":346,"completed":196,"skipped":3657,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:37:55.173: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support proxy with --port 0  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: starting the proxy server
Apr 20 06:37:55.202: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-2327 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:37:55.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2327" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":346,"completed":197,"skipped":3673,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:37:55.260: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:90
Apr 20 06:37:55.287: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 20 06:37:55.291: INFO: Waiting for terminating namespaces to be deleted...
Apr 20 06:37:55.293: INFO: 
Logging pods the apiserver thinks is on node node22-07idr before test
Apr 20 06:37:55.296: INFO: canal-7z4s7 from kube-system started at 2022-04-20 05:37:05 +0000 UTC (2 container statuses recorded)
Apr 20 06:37:55.297: INFO: 	Container calico-node ready: true, restart count 0
Apr 20 06:37:55.297: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 20 06:37:55.297: INFO: konnectivity-agent-z8v6h from kube-system started at 2022-04-20 05:37:24 +0000 UTC (1 container statuses recorded)
Apr 20 06:37:55.297: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 20 06:37:55.297: INFO: sonobuoy-e2e-job-14e586816b6a497d from sonobuoy started at 2022-04-20 05:49:38 +0000 UTC (2 container statuses recorded)
Apr 20 06:37:55.297: INFO: 	Container e2e ready: true, restart count 0
Apr 20 06:37:55.297: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 20 06:37:55.297: INFO: sonobuoy-systemd-logs-daemon-set-cdcdd281c10f40dc-vvhct from sonobuoy started at 2022-04-20 05:49:38 +0000 UTC (2 container statuses recorded)
Apr 20 06:37:55.297: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 20 06:37:55.297: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 20 06:37:55.297: INFO: 
Logging pods the apiserver thinks is on node node22-hwh1v before test
Apr 20 06:37:55.301: INFO: calico-kube-controllers-5544f8d8d9-2pr5d from kube-system started at 2022-04-20 05:37:23 +0000 UTC (1 container statuses recorded)
Apr 20 06:37:55.301: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 20 06:37:55.301: INFO: canal-xrqg4 from kube-system started at 2022-04-20 05:37:04 +0000 UTC (2 container statuses recorded)
Apr 20 06:37:55.301: INFO: 	Container calico-node ready: true, restart count 0
Apr 20 06:37:55.301: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 20 06:37:55.301: INFO: coredns-748f75f5fb-2n9dt from kube-system started at 2022-04-20 05:37:23 +0000 UTC (1 container statuses recorded)
Apr 20 06:37:55.301: INFO: 	Container coredns ready: true, restart count 0
Apr 20 06:37:55.301: INFO: coredns-748f75f5fb-8sfr7 from kube-system started at 2022-04-20 05:37:23 +0000 UTC (1 container statuses recorded)
Apr 20 06:37:55.301: INFO: 	Container coredns ready: true, restart count 0
Apr 20 06:37:55.301: INFO: konnectivity-agent-9q5dq from kube-system started at 2022-04-20 05:37:23 +0000 UTC (1 container statuses recorded)
Apr 20 06:37:55.301: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 20 06:37:55.301: INFO: sonobuoy-systemd-logs-daemon-set-cdcdd281c10f40dc-dc45f from sonobuoy started at 2022-04-20 05:49:38 +0000 UTC (2 container statuses recorded)
Apr 20 06:37:55.301: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 20 06:37:55.301: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 20 06:37:55.301: INFO: 
Logging pods the apiserver thinks is on node node22-wriki before test
Apr 20 06:37:55.304: INFO: canal-r5jz2 from kube-system started at 2022-04-20 05:37:06 +0000 UTC (2 container statuses recorded)
Apr 20 06:37:55.304: INFO: 	Container calico-node ready: true, restart count 0
Apr 20 06:37:55.304: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 20 06:37:55.304: INFO: konnectivity-agent-vgl4v from kube-system started at 2022-04-20 06:27:48 +0000 UTC (1 container statuses recorded)
Apr 20 06:37:55.305: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 20 06:37:55.305: INFO: httpd-deployment-8584777d8-ghqqh from kubectl-6753 started at 2022-04-20 06:36:12 +0000 UTC (1 container statuses recorded)
Apr 20 06:37:55.305: INFO: 	Container httpd ready: false, restart count 0
Apr 20 06:37:55.305: INFO: sonobuoy from sonobuoy started at 2022-04-20 05:49:32 +0000 UTC (1 container statuses recorded)
Apr 20 06:37:55.305: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 20 06:37:55.305: INFO: sonobuoy-systemd-logs-daemon-set-cdcdd281c10f40dc-48vdz from sonobuoy started at 2022-04-20 05:49:39 +0000 UTC (2 container statuses recorded)
Apr 20 06:37:55.305: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 20 06:37:55.305: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.16e787696f9f6d25], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:37:56.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4256" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":346,"completed":198,"skipped":3684,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:37:56.337: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:188
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:37:56.367: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: creating the pod
STEP: submitting the pod to kubernetes
Apr 20 06:37:56.376: INFO: The status of Pod pod-logs-websocket-9f8b1642-7750-4d04-bb81-f55d4d61930d is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:37:58.381: INFO: The status of Pod pod-logs-websocket-9f8b1642-7750-4d04-bb81-f55d4d61930d is Running (Ready = true)
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:37:58.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2119" for this suite.
•{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":346,"completed":199,"skipped":3693,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:37:58.407: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Apr 20 06:37:58.866: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 20 06:38:01.889: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:38:01.894: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:38:05.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-3602" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:7.749 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":346,"completed":200,"skipped":3727,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:38:06.158: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod with failed condition
STEP: updating the pod
Apr 20 06:40:06.797: INFO: Successfully updated pod "var-expansion-92e4363e-341a-4fb0-acb4-7d22ce7d02f4"
STEP: waiting for pod running
STEP: deleting the pod gracefully
Apr 20 06:40:08.805: INFO: Deleting pod "var-expansion-92e4363e-341a-4fb0-acb4-7d22ce7d02f4" in namespace "var-expansion-6150"
Apr 20 06:40:08.813: INFO: Wait up to 5m0s for pod "var-expansion-92e4363e-341a-4fb0-acb4-7d22ce7d02f4" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:40:40.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6150" for this suite.

• [SLOW TEST:154.676 seconds]
[sig-node] Variable Expansion
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","total":346,"completed":201,"skipped":3740,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a volume subpath [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:40:40.835: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a volume subpath [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test substitution in volume subpath
Apr 20 06:40:40.888: INFO: Waiting up to 5m0s for pod "var-expansion-db21e519-9853-4444-8e85-5787ae18c654" in namespace "var-expansion-2340" to be "Succeeded or Failed"
Apr 20 06:40:40.892: INFO: Pod "var-expansion-db21e519-9853-4444-8e85-5787ae18c654": Phase="Pending", Reason="", readiness=false. Elapsed: 3.815461ms
Apr 20 06:40:42.898: INFO: Pod "var-expansion-db21e519-9853-4444-8e85-5787ae18c654": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010137644s
STEP: Saw pod success
Apr 20 06:40:42.898: INFO: Pod "var-expansion-db21e519-9853-4444-8e85-5787ae18c654" satisfied condition "Succeeded or Failed"
Apr 20 06:40:42.901: INFO: Trying to get logs from node node22-wriki pod var-expansion-db21e519-9853-4444-8e85-5787ae18c654 container dapi-container: <nil>
STEP: delete the pod
Apr 20 06:40:42.928: INFO: Waiting for pod var-expansion-db21e519-9853-4444-8e85-5787ae18c654 to disappear
Apr 20 06:40:42.930: INFO: Pod var-expansion-db21e519-9853-4444-8e85-5787ae18c654 no longer exists
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:40:42.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2340" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","total":346,"completed":202,"skipped":3752,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:40:42.942: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Kubectl logs
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1396
STEP: creating an pod
Apr 20 06:40:42.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-1061 run logs-generator --image=k8s.gcr.io/e2e-test-images/agnhost:2.32 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Apr 20 06:40:43.045: INFO: stderr: ""
Apr 20 06:40:43.045: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Waiting for log generator to start.
Apr 20 06:40:43.045: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Apr 20 06:40:43.045: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-1061" to be "running and ready, or succeeded"
Apr 20 06:40:43.048: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 3.065236ms
Apr 20 06:40:45.054: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.009061225s
Apr 20 06:40:45.054: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Apr 20 06:40:45.054: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Apr 20 06:40:45.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-1061 logs logs-generator logs-generator'
Apr 20 06:40:45.113: INFO: stderr: ""
Apr 20 06:40:45.114: INFO: stdout: "I0420 06:40:43.913316       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/qtzk 217\nI0420 06:40:44.113439       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/cp2 253\nI0420 06:40:44.313705       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/zb2 517\nI0420 06:40:44.513943       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/9xc 281\nI0420 06:40:44.714262       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/gs7 395\nI0420 06:40:44.913401       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/6hb 353\nI0420 06:40:45.113730       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/cjmx 302\n"
Apr 20 06:40:47.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-1061 logs logs-generator logs-generator'
Apr 20 06:40:47.169: INFO: stderr: ""
Apr 20 06:40:47.169: INFO: stdout: "I0420 06:40:43.913316       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/qtzk 217\nI0420 06:40:44.113439       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/cp2 253\nI0420 06:40:44.313705       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/zb2 517\nI0420 06:40:44.513943       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/9xc 281\nI0420 06:40:44.714262       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/gs7 395\nI0420 06:40:44.913401       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/6hb 353\nI0420 06:40:45.113730       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/cjmx 302\nI0420 06:40:45.314063       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/gpfq 324\nI0420 06:40:45.514173       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/vj4z 501\nI0420 06:40:45.713411       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/vmf 455\nI0420 06:40:45.913733       1 logs_generator.go:76] 10 POST /api/v1/namespaces/default/pods/w56 283\nI0420 06:40:46.113953       1 logs_generator.go:76] 11 GET /api/v1/namespaces/kube-system/pods/rbl 210\nI0420 06:40:46.314262       1 logs_generator.go:76] 12 GET /api/v1/namespaces/ns/pods/ckff 314\nI0420 06:40:46.513406       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/vcm 550\nI0420 06:40:46.713731       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/ns/pods/rj6j 297\nI0420 06:40:46.914029       1 logs_generator.go:76] 15 GET /api/v1/namespaces/default/pods/9hcx 597\nI0420 06:40:47.114347       1 logs_generator.go:76] 16 GET /api/v1/namespaces/default/pods/svg 575\n"
STEP: limiting log lines
Apr 20 06:40:47.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-1061 logs logs-generator logs-generator --tail=1'
Apr 20 06:40:47.230: INFO: stderr: ""
Apr 20 06:40:47.230: INFO: stdout: "I0420 06:40:47.114347       1 logs_generator.go:76] 16 GET /api/v1/namespaces/default/pods/svg 575\n"
Apr 20 06:40:47.230: INFO: got output "I0420 06:40:47.114347       1 logs_generator.go:76] 16 GET /api/v1/namespaces/default/pods/svg 575\n"
STEP: limiting log bytes
Apr 20 06:40:47.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-1061 logs logs-generator logs-generator --limit-bytes=1'
Apr 20 06:40:47.290: INFO: stderr: ""
Apr 20 06:40:47.290: INFO: stdout: "I"
Apr 20 06:40:47.290: INFO: got output "I"
STEP: exposing timestamps
Apr 20 06:40:47.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-1061 logs logs-generator logs-generator --tail=1 --timestamps'
Apr 20 06:40:47.361: INFO: stderr: ""
Apr 20 06:40:47.361: INFO: stdout: "2022-04-20T15:40:47.313743480+09:00 I0420 06:40:47.313651       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/j5c 265\n"
Apr 20 06:40:47.361: INFO: got output "2022-04-20T15:40:47.313743480+09:00 I0420 06:40:47.313651       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/j5c 265\n"
STEP: restricting to a time range
Apr 20 06:40:49.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-1061 logs logs-generator logs-generator --since=1s'
Apr 20 06:40:49.921: INFO: stderr: ""
Apr 20 06:40:49.921: INFO: stdout: "I0420 06:40:49.113965       1 logs_generator.go:76] 26 GET /api/v1/namespaces/kube-system/pods/ncl 328\nI0420 06:40:49.314395       1 logs_generator.go:76] 27 POST /api/v1/namespaces/default/pods/2wb 488\nI0420 06:40:49.513706       1 logs_generator.go:76] 28 POST /api/v1/namespaces/kube-system/pods/5st4 375\nI0420 06:40:49.714014       1 logs_generator.go:76] 29 PUT /api/v1/namespaces/ns/pods/7kr8 227\nI0420 06:40:49.914321       1 logs_generator.go:76] 30 POST /api/v1/namespaces/kube-system/pods/cc9w 415\n"
Apr 20 06:40:49.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-1061 logs logs-generator logs-generator --since=24h'
Apr 20 06:40:49.991: INFO: stderr: ""
Apr 20 06:40:49.991: INFO: stdout: "I0420 06:40:43.913316       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/qtzk 217\nI0420 06:40:44.113439       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/cp2 253\nI0420 06:40:44.313705       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/zb2 517\nI0420 06:40:44.513943       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/9xc 281\nI0420 06:40:44.714262       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/gs7 395\nI0420 06:40:44.913401       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/6hb 353\nI0420 06:40:45.113730       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/cjmx 302\nI0420 06:40:45.314063       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/gpfq 324\nI0420 06:40:45.514173       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/vj4z 501\nI0420 06:40:45.713411       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/vmf 455\nI0420 06:40:45.913733       1 logs_generator.go:76] 10 POST /api/v1/namespaces/default/pods/w56 283\nI0420 06:40:46.113953       1 logs_generator.go:76] 11 GET /api/v1/namespaces/kube-system/pods/rbl 210\nI0420 06:40:46.314262       1 logs_generator.go:76] 12 GET /api/v1/namespaces/ns/pods/ckff 314\nI0420 06:40:46.513406       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/vcm 550\nI0420 06:40:46.713731       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/ns/pods/rj6j 297\nI0420 06:40:46.914029       1 logs_generator.go:76] 15 GET /api/v1/namespaces/default/pods/9hcx 597\nI0420 06:40:47.114347       1 logs_generator.go:76] 16 GET /api/v1/namespaces/default/pods/svg 575\nI0420 06:40:47.313651       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/j5c 265\nI0420 06:40:47.513980       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/fmc 322\nI0420 06:40:47.714288       1 logs_generator.go:76] 19 POST /api/v1/namespaces/ns/pods/t5r 469\nI0420 06:40:47.913531       1 logs_generator.go:76] 20 POST /api/v1/namespaces/default/pods/pgp 442\nI0420 06:40:48.113663       1 logs_generator.go:76] 21 GET /api/v1/namespaces/ns/pods/p6f 535\nI0420 06:40:48.313982       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/kube-system/pods/blr 271\nI0420 06:40:48.514122       1 logs_generator.go:76] 23 GET /api/v1/namespaces/kube-system/pods/68k 502\nI0420 06:40:48.713389       1 logs_generator.go:76] 24 GET /api/v1/namespaces/default/pods/tsv 475\nI0420 06:40:48.913820       1 logs_generator.go:76] 25 GET /api/v1/namespaces/default/pods/mxk 419\nI0420 06:40:49.113965       1 logs_generator.go:76] 26 GET /api/v1/namespaces/kube-system/pods/ncl 328\nI0420 06:40:49.314395       1 logs_generator.go:76] 27 POST /api/v1/namespaces/default/pods/2wb 488\nI0420 06:40:49.513706       1 logs_generator.go:76] 28 POST /api/v1/namespaces/kube-system/pods/5st4 375\nI0420 06:40:49.714014       1 logs_generator.go:76] 29 PUT /api/v1/namespaces/ns/pods/7kr8 227\nI0420 06:40:49.914321       1 logs_generator.go:76] 30 POST /api/v1/namespaces/kube-system/pods/cc9w 415\n"
[AfterEach] Kubectl logs
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1401
Apr 20 06:40:49.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-1061 delete pod logs-generator'
Apr 20 06:40:50.968: INFO: stderr: ""
Apr 20 06:40:50.968: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:40:50.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1061" for this suite.

• [SLOW TEST:8.037 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1393
    should be able to retrieve and filter logs  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":346,"completed":203,"skipped":3788,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:40:50.980: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with configMap that has name projected-configmap-test-upd-ca6ed2a2-4820-4881-8dd7-24432c0b6d23
STEP: Creating the pod
Apr 20 06:40:51.023: INFO: The status of Pod pod-projected-configmaps-1282fc96-548c-4414-8e0c-0fde0f455675 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:40:53.030: INFO: The status of Pod pod-projected-configmaps-1282fc96-548c-4414-8e0c-0fde0f455675 is Running (Ready = true)
STEP: Updating configmap projected-configmap-test-upd-ca6ed2a2-4820-4881-8dd7-24432c0b6d23
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:42:19.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1089" for this suite.

• [SLOW TEST:88.400 seconds]
[sig-storage] Projected configMap
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":204,"skipped":3825,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:42:19.383: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-upd-044a2689-5bd9-43de-bac5-0127c3e42290
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:42:21.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4566" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":205,"skipped":3848,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:42:21.451: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr 20 06:42:21.493: INFO: Waiting up to 5m0s for pod "downwardapi-volume-204b54fa-7b1d-459a-952b-22ae4220a4d2" in namespace "downward-api-5552" to be "Succeeded or Failed"
Apr 20 06:42:21.496: INFO: Pod "downwardapi-volume-204b54fa-7b1d-459a-952b-22ae4220a4d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.889009ms
Apr 20 06:42:23.501: INFO: Pod "downwardapi-volume-204b54fa-7b1d-459a-952b-22ae4220a4d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008262921s
STEP: Saw pod success
Apr 20 06:42:23.502: INFO: Pod "downwardapi-volume-204b54fa-7b1d-459a-952b-22ae4220a4d2" satisfied condition "Succeeded or Failed"
Apr 20 06:42:23.503: INFO: Trying to get logs from node node22-hwh1v pod downwardapi-volume-204b54fa-7b1d-459a-952b-22ae4220a4d2 container client-container: <nil>
STEP: delete the pod
Apr 20 06:42:23.526: INFO: Waiting for pod downwardapi-volume-204b54fa-7b1d-459a-952b-22ae4220a4d2 to disappear
Apr 20 06:42:23.528: INFO: Pod downwardapi-volume-204b54fa-7b1d-459a-952b-22ae4220a4d2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:42:23.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5552" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":346,"completed":206,"skipped":3883,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:42:23.535: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir volume type on node default medium
Apr 20 06:42:23.573: INFO: Waiting up to 5m0s for pod "pod-ffdb5d21-b215-48f9-8bec-36e45017c926" in namespace "emptydir-9226" to be "Succeeded or Failed"
Apr 20 06:42:23.575: INFO: Pod "pod-ffdb5d21-b215-48f9-8bec-36e45017c926": Phase="Pending", Reason="", readiness=false. Elapsed: 1.989275ms
Apr 20 06:42:25.581: INFO: Pod "pod-ffdb5d21-b215-48f9-8bec-36e45017c926": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007986867s
STEP: Saw pod success
Apr 20 06:42:25.582: INFO: Pod "pod-ffdb5d21-b215-48f9-8bec-36e45017c926" satisfied condition "Succeeded or Failed"
Apr 20 06:42:25.584: INFO: Trying to get logs from node node22-hwh1v pod pod-ffdb5d21-b215-48f9-8bec-36e45017c926 container test-container: <nil>
STEP: delete the pod
Apr 20 06:42:25.597: INFO: Waiting for pod pod-ffdb5d21-b215-48f9-8bec-36e45017c926 to disappear
Apr 20 06:42:25.599: INFO: Pod pod-ffdb5d21-b215-48f9-8bec-36e45017c926 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:42:25.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9226" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":207,"skipped":3920,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:42:25.611: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 20 06:42:25.952: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 20 06:42:27.965: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63786033746, loc:(*time.Location)(0xa09bc80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786033746, loc:(*time.Location)(0xa09bc80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63786033746, loc:(*time.Location)(0xa09bc80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786033745, loc:(*time.Location)(0xa09bc80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 20 06:42:30.989: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:42:31.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-230" for this suite.
STEP: Destroying namespace "webhook-230-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.487 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":346,"completed":208,"skipped":3926,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:42:31.098: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:42:44.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7613" for this suite.
STEP: Destroying namespace "nsdeletetest-9733" for this suite.
Apr 20 06:42:44.247: INFO: Namespace nsdeletetest-9733 was already deleted
STEP: Destroying namespace "nsdeletetest-3798" for this suite.

• [SLOW TEST:13.154 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":346,"completed":209,"skipped":3933,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:42:44.253: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward api env vars
Apr 20 06:42:44.287: INFO: Waiting up to 5m0s for pod "downward-api-83a17712-ff1f-4633-b4a2-77501bd5779b" in namespace "downward-api-6858" to be "Succeeded or Failed"
Apr 20 06:42:44.290: INFO: Pod "downward-api-83a17712-ff1f-4633-b4a2-77501bd5779b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.863441ms
Apr 20 06:42:46.294: INFO: Pod "downward-api-83a17712-ff1f-4633-b4a2-77501bd5779b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00705913s
STEP: Saw pod success
Apr 20 06:42:46.295: INFO: Pod "downward-api-83a17712-ff1f-4633-b4a2-77501bd5779b" satisfied condition "Succeeded or Failed"
Apr 20 06:42:46.296: INFO: Trying to get logs from node node22-hwh1v pod downward-api-83a17712-ff1f-4633-b4a2-77501bd5779b container dapi-container: <nil>
STEP: delete the pod
Apr 20 06:42:46.312: INFO: Waiting for pod downward-api-83a17712-ff1f-4633-b4a2-77501bd5779b to disappear
Apr 20 06:42:46.315: INFO: Pod downward-api-83a17712-ff1f-4633-b4a2-77501bd5779b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:42:46.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6858" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":346,"completed":210,"skipped":3950,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:42:46.325: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:42:46.364: INFO: created pod
Apr 20 06:42:46.364: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-786" to be "Succeeded or Failed"
Apr 20 06:42:46.366: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 1.942684ms
Apr 20 06:42:48.370: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006167259s
STEP: Saw pod success
Apr 20 06:42:48.370: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Apr 20 06:43:18.371: INFO: polling logs
Apr 20 06:43:18.377: INFO: Pod logs: 
2022/04/20 06:42:47 OK: Got token
2022/04/20 06:42:47 validating with in-cluster discovery
2022/04/20 06:42:47 OK: got issuer https://kubernetes.default.svc.cluster.local
2022/04/20 06:42:47 Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-786:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1650437566, NotBefore:1650436966, IssuedAt:1650436966, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-786", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"71381fee-ec28-427a-8e70-3251d6af206c"}}}
2022/04/20 06:42:47 OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
2022/04/20 06:42:47 OK: Validated signature on JWT
2022/04/20 06:42:47 OK: Got valid claims from token!
2022/04/20 06:42:47 Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-786:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1650437566, NotBefore:1650436966, IssuedAt:1650436966, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-786", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"71381fee-ec28-427a-8e70-3251d6af206c"}}}

Apr 20 06:43:18.377: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:43:18.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-786" for this suite.

• [SLOW TEST:32.065 seconds]
[sig-auth] ServiceAccounts
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","total":346,"completed":211,"skipped":3977,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] 
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/sysctl.go:36
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:43:18.390: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename sysctl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/sysctl.go:65
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl
STEP: Watching for error events or started pod
STEP: Waiting for pod completion
STEP: Checking that the pod succeeded
STEP: Getting logs from the pod
STEP: Checking that the sysctl is actually updated
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:43:20.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-8540" for this suite.
•{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","total":346,"completed":212,"skipped":3989,"failed":0}
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:43:20.459: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 20 06:43:20.852: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 20 06:43:23.872: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:43:23.876: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9435-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:43:25.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3412" for this suite.
STEP: Destroying namespace "webhook-3412-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.576 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":346,"completed":213,"skipped":3991,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:43:26.036: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:142
[It] should run and stop complex daemon [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:43:26.083: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Apr 20 06:43:26.089: INFO: Number of nodes with available pods: 0
Apr 20 06:43:26.089: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Apr 20 06:43:26.104: INFO: Number of nodes with available pods: 0
Apr 20 06:43:26.104: INFO: Node node22-07idr is running more than one daemon pod
Apr 20 06:43:27.165: INFO: Number of nodes with available pods: 0
Apr 20 06:43:27.165: INFO: Node node22-07idr is running more than one daemon pod
Apr 20 06:43:28.110: INFO: Number of nodes with available pods: 0
Apr 20 06:43:28.110: INFO: Node node22-07idr is running more than one daemon pod
Apr 20 06:43:29.109: INFO: Number of nodes with available pods: 1
Apr 20 06:43:29.109: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Apr 20 06:43:29.136: INFO: Number of nodes with available pods: 0
Apr 20 06:43:29.136: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Apr 20 06:43:29.147: INFO: Number of nodes with available pods: 0
Apr 20 06:43:29.147: INFO: Node node22-07idr is running more than one daemon pod
Apr 20 06:43:30.152: INFO: Number of nodes with available pods: 0
Apr 20 06:43:30.152: INFO: Node node22-07idr is running more than one daemon pod
Apr 20 06:43:31.152: INFO: Number of nodes with available pods: 0
Apr 20 06:43:31.152: INFO: Node node22-07idr is running more than one daemon pod
Apr 20 06:43:32.151: INFO: Number of nodes with available pods: 0
Apr 20 06:43:32.151: INFO: Node node22-07idr is running more than one daemon pod
Apr 20 06:43:33.153: INFO: Number of nodes with available pods: 1
Apr 20 06:43:33.153: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:108
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5398, will wait for the garbage collector to delete the pods
Apr 20 06:43:33.216: INFO: Deleting DaemonSet.extensions daemon-set took: 6.695881ms
Apr 20 06:43:33.317: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.808706ms
Apr 20 06:43:35.325: INFO: Number of nodes with available pods: 0
Apr 20 06:43:35.325: INFO: Number of running nodes: 0, number of available pods: 0
Apr 20 06:43:35.327: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"26824"},"items":null}

Apr 20 06:43:35.333: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"26824"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:43:35.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5398" for this suite.

• [SLOW TEST:9.320 seconds]
[sig-apps] Daemon set [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":346,"completed":214,"skipped":4023,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should run through a ConfigMap lifecycle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:43:35.358: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run through a ConfigMap lifecycle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a ConfigMap
STEP: fetching the ConfigMap
STEP: patching the ConfigMap
STEP: listing all ConfigMaps in all namespaces with a label selector
STEP: deleting the ConfigMap by collection with a label selector
STEP: listing all ConfigMaps in test namespace
[AfterEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:43:35.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2877" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","total":346,"completed":215,"skipped":4047,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:43:35.416: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:52
STEP: create the container to handle the HTTPGet hook request.
Apr 20 06:43:35.451: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:43:37.456: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the pod with lifecycle hook
Apr 20 06:43:37.472: INFO: The status of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:43:39.476: INFO: The status of Pod pod-with-poststart-http-hook is Running (Ready = true)
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 20 06:43:39.491: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 20 06:43:39.493: INFO: Pod pod-with-poststart-http-hook still exists
Apr 20 06:43:41.494: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 20 06:43:41.502: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:43:41.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8643" for this suite.

• [SLOW TEST:6.096 seconds]
[sig-node] Container Lifecycle Hook
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:43
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":346,"completed":216,"skipped":4062,"failed":0}
SSSSSS
------------------------------
[sig-apps] Deployment 
  Deployment should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:43:41.515: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] Deployment should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:43:41.549: INFO: Creating simple deployment test-new-deployment
Apr 20 06:43:41.567: INFO: deployment "test-new-deployment" doesn't have the required revision set
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the deployment Spec.Replicas was modified
STEP: Patch a scale subresource
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Apr 20 06:43:43.636: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-2972  55330414-228e-4c96-a3a2-c92099e23617 26959 3 2022-04-20 06:43:41 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-04-20 06:43:41 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-20 06:43:43 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc000ba4758 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:3,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-847dcfb7fb" has successfully progressed.,LastUpdateTime:2022-04-20 06:43:43 +0000 UTC,LastTransitionTime:2022-04-20 06:43:41 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-04-20 06:43:43 +0000 UTC,LastTransitionTime:2022-04-20 06:43:43 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 20 06:43:43.640: INFO: New ReplicaSet "test-new-deployment-847dcfb7fb" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-847dcfb7fb  deployment-2972  db5d282f-23f3-4b77-9713-ef3e3607bd17 26960 3 2022-04-20 06:43:41 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 55330414-228e-4c96-a3a2-c92099e23617 0xc002854f37 0xc002854f38}] []  [{kube-controller-manager Update apps/v1 2022-04-20 06:43:41 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"55330414-228e-4c96-a3a2-c92099e23617\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-20 06:43:43 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 847dcfb7fb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002854fc8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 20 06:43:43.650: INFO: Pod "test-new-deployment-847dcfb7fb-gl597" is not available:
&Pod{ObjectMeta:{test-new-deployment-847dcfb7fb-gl597 test-new-deployment-847dcfb7fb- deployment-2972  9ab37f5e-8562-4deb-a6c0-1cc9cdc4d201 26956 0 2022-04-20 06:43:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[] [{apps/v1 ReplicaSet test-new-deployment-847dcfb7fb db5d282f-23f3-4b77-9713-ef3e3607bd17 0xc000ba4bc7 0xc000ba4bc8}] []  [{kube-controller-manager Update v1 2022-04-20 06:43:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db5d282f-23f3-4b77-9713-ef3e3607bd17\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-04-20 06:43:43 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lr4zl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lr4zl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-07idr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:43:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:43:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:43:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:43:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.118.168,PodIP:,StartTime:2022-04-20 06:43:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:43:43.651: INFO: Pod "test-new-deployment-847dcfb7fb-jztx4" is available:
&Pod{ObjectMeta:{test-new-deployment-847dcfb7fb-jztx4 test-new-deployment-847dcfb7fb- deployment-2972  b99e31d2-18b2-480f-8135-996e06370991 26940 0 2022-04-20 06:43:41 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/podIP:10.233.2.150/32 cni.projectcalico.org/podIPs:10.233.2.150/32] [{apps/v1 ReplicaSet test-new-deployment-847dcfb7fb db5d282f-23f3-4b77-9713-ef3e3607bd17 0xc000ba4de7 0xc000ba4de8}] []  [{kube-controller-manager Update v1 2022-04-20 06:43:41 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db5d282f-23f3-4b77-9713-ef3e3607bd17\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-04-20 06:43:42 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-04-20 06:43:43 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.2.150\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fsmsf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fsmsf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-wriki,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:43:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:43:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:43:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:43:41 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.99.219,PodIP:10.233.2.150,StartTime:2022-04-20 06:43:41 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-20 06:43:42 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:containerd://ba3b3f141f7474c8b85a09efcc5235bc18e8e9c20de545f24d25fc8ba2da1116,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.2.150,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:43:43.651: INFO: Pod "test-new-deployment-847dcfb7fb-vztrf" is not available:
&Pod{ObjectMeta:{test-new-deployment-847dcfb7fb-vztrf test-new-deployment-847dcfb7fb- deployment-2972  ade9e68d-df67-404a-92a8-da2b02ee8c53 26962 0 2022-04-20 06:43:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[] [{apps/v1 ReplicaSet test-new-deployment-847dcfb7fb db5d282f-23f3-4b77-9713-ef3e3607bd17 0xc000ba5017 0xc000ba5018}] []  [{kube-controller-manager Update v1 2022-04-20 06:43:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"db5d282f-23f3-4b77-9713-ef3e3607bd17\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lsb6w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lsb6w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:43:43.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2972" for this suite.
•{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","total":346,"completed":217,"skipped":4068,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:43:43.675: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/init_container.go:162
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
Apr 20 06:43:43.702: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:43:47.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9433" for this suite.
•{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":346,"completed":218,"skipped":4116,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:43:47.312: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:43:53.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3169" for this suite.

• [SLOW TEST:6.056 seconds]
[sig-apps] Job
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":346,"completed":219,"skipped":4125,"failed":0}
S
------------------------------
[sig-apps] DisruptionController 
  should create a PodDisruptionBudget [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:43:53.368: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:69
[It] should create a PodDisruptionBudget [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pdb
STEP: Waiting for the pdb to be processed
STEP: updating the pdb
STEP: Waiting for the pdb to be processed
STEP: patching the pdb
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be deleted
[AfterEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:43:57.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-4774" for this suite.
•{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","total":346,"completed":220,"skipped":4126,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API 
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:43:57.470: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/instrumentation/events.go:81
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a test event
STEP: listing events in all namespaces
STEP: listing events in test namespace
STEP: listing events with field selection filtering on source
STEP: listing events with field selection filtering on reportingController
STEP: getting the test event
STEP: patching the test event
STEP: getting the test event
STEP: updating the test event
STEP: getting the test event
STEP: deleting the test event
STEP: listing events in all namespaces
STEP: listing events in test namespace
[AfterEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:43:57.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-4511" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","total":346,"completed":221,"skipped":4143,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:43:57.541: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:43:57.566: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Apr 20 06:44:00.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-6168 --namespace=crd-publish-openapi-6168 create -f -'
Apr 20 06:44:00.618: INFO: stderr: ""
Apr 20 06:44:00.618: INFO: stdout: "e2e-test-crd-publish-openapi-1649-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr 20 06:44:00.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-6168 --namespace=crd-publish-openapi-6168 delete e2e-test-crd-publish-openapi-1649-crds test-cr'
Apr 20 06:44:00.674: INFO: stderr: ""
Apr 20 06:44:00.674: INFO: stdout: "e2e-test-crd-publish-openapi-1649-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Apr 20 06:44:00.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-6168 --namespace=crd-publish-openapi-6168 apply -f -'
Apr 20 06:44:00.854: INFO: stderr: ""
Apr 20 06:44:00.854: INFO: stdout: "e2e-test-crd-publish-openapi-1649-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr 20 06:44:00.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-6168 --namespace=crd-publish-openapi-6168 delete e2e-test-crd-publish-openapi-1649-crds test-cr'
Apr 20 06:44:00.917: INFO: stderr: ""
Apr 20 06:44:00.917: INFO: stdout: "e2e-test-crd-publish-openapi-1649-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Apr 20 06:44:00.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=crd-publish-openapi-6168 explain e2e-test-crd-publish-openapi-1649-crds'
Apr 20 06:44:01.042: INFO: stderr: ""
Apr 20 06:44:01.042: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1649-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:44:03.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6168" for this suite.

• [SLOW TEST:6.268 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":346,"completed":222,"skipped":4146,"failed":0}
[sig-network] Services 
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:44:03.810: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service in namespace services-8915
STEP: creating service affinity-nodeport-transition in namespace services-8915
STEP: creating replication controller affinity-nodeport-transition in namespace services-8915
I0420 06:44:03.860787      20 runners.go:190] Created replication controller with name: affinity-nodeport-transition, namespace: services-8915, replica count: 3
I0420 06:44:06.911849      20 runners.go:190] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 20 06:44:06.919: INFO: Creating new exec pod
Apr 20 06:44:09.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-8915 exec execpod-affinity7bmbt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Apr 20 06:44:10.076: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport-transition 80\n+ echo hostName\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Apr 20 06:44:10.076: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 20 06:44:10.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-8915 exec execpod-affinity7bmbt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.109.103.157 80'
Apr 20 06:44:10.187: INFO: stderr: "+ nc -v -t -w 2 10.109.103.157 80\n+ echo hostName\nConnection to 10.109.103.157 80 port [tcp/http] succeeded!\n"
Apr 20 06:44:10.187: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 20 06:44:10.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-8915 exec execpod-affinity7bmbt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.118.168 30581'
Apr 20 06:44:10.307: INFO: stderr: "+ nc -v -t -w 2 10.100.118.168 30581\n+ echo hostName\nConnection to 10.100.118.168 30581 port [tcp/*] succeeded!\n"
Apr 20 06:44:10.307: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 20 06:44:10.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-8915 exec execpod-affinity7bmbt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.99.219 30581'
Apr 20 06:44:10.437: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.100.99.219 30581\nConnection to 10.100.99.219 30581 port [tcp/*] succeeded!\n"
Apr 20 06:44:10.437: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 20 06:44:10.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-8915 exec execpod-affinity7bmbt -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.100.118.168:30581/ ; done'
Apr 20 06:44:10.683: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n"
Apr 20 06:44:10.683: INFO: stdout: "\naffinity-nodeport-transition-hf2hc\naffinity-nodeport-transition-hf2hc\naffinity-nodeport-transition-hf2hc\naffinity-nodeport-transition-hf2hc\naffinity-nodeport-transition-hf2hc\naffinity-nodeport-transition-5sjdx\naffinity-nodeport-transition-mchbh\naffinity-nodeport-transition-mchbh\naffinity-nodeport-transition-5sjdx\naffinity-nodeport-transition-hf2hc\naffinity-nodeport-transition-5sjdx\naffinity-nodeport-transition-hf2hc\naffinity-nodeport-transition-mchbh\naffinity-nodeport-transition-5sjdx\naffinity-nodeport-transition-mchbh\naffinity-nodeport-transition-5sjdx"
Apr 20 06:44:10.683: INFO: Received response from host: affinity-nodeport-transition-hf2hc
Apr 20 06:44:10.683: INFO: Received response from host: affinity-nodeport-transition-hf2hc
Apr 20 06:44:10.683: INFO: Received response from host: affinity-nodeport-transition-hf2hc
Apr 20 06:44:10.683: INFO: Received response from host: affinity-nodeport-transition-hf2hc
Apr 20 06:44:10.683: INFO: Received response from host: affinity-nodeport-transition-hf2hc
Apr 20 06:44:10.683: INFO: Received response from host: affinity-nodeport-transition-5sjdx
Apr 20 06:44:10.683: INFO: Received response from host: affinity-nodeport-transition-mchbh
Apr 20 06:44:10.683: INFO: Received response from host: affinity-nodeport-transition-mchbh
Apr 20 06:44:10.683: INFO: Received response from host: affinity-nodeport-transition-5sjdx
Apr 20 06:44:10.683: INFO: Received response from host: affinity-nodeport-transition-hf2hc
Apr 20 06:44:10.683: INFO: Received response from host: affinity-nodeport-transition-5sjdx
Apr 20 06:44:10.683: INFO: Received response from host: affinity-nodeport-transition-hf2hc
Apr 20 06:44:10.683: INFO: Received response from host: affinity-nodeport-transition-mchbh
Apr 20 06:44:10.683: INFO: Received response from host: affinity-nodeport-transition-5sjdx
Apr 20 06:44:10.683: INFO: Received response from host: affinity-nodeport-transition-mchbh
Apr 20 06:44:10.683: INFO: Received response from host: affinity-nodeport-transition-5sjdx
Apr 20 06:44:10.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-8915 exec execpod-affinity7bmbt -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.100.118.168:30581/ ; done'
Apr 20 06:44:10.916: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.118.168:30581/\n"
Apr 20 06:44:10.917: INFO: stdout: "\naffinity-nodeport-transition-hf2hc\naffinity-nodeport-transition-hf2hc\naffinity-nodeport-transition-hf2hc\naffinity-nodeport-transition-hf2hc\naffinity-nodeport-transition-hf2hc\naffinity-nodeport-transition-hf2hc\naffinity-nodeport-transition-hf2hc\naffinity-nodeport-transition-hf2hc\naffinity-nodeport-transition-hf2hc\naffinity-nodeport-transition-hf2hc\naffinity-nodeport-transition-hf2hc\naffinity-nodeport-transition-hf2hc\naffinity-nodeport-transition-hf2hc\naffinity-nodeport-transition-hf2hc\naffinity-nodeport-transition-hf2hc\naffinity-nodeport-transition-hf2hc"
Apr 20 06:44:10.917: INFO: Received response from host: affinity-nodeport-transition-hf2hc
Apr 20 06:44:10.917: INFO: Received response from host: affinity-nodeport-transition-hf2hc
Apr 20 06:44:10.917: INFO: Received response from host: affinity-nodeport-transition-hf2hc
Apr 20 06:44:10.917: INFO: Received response from host: affinity-nodeport-transition-hf2hc
Apr 20 06:44:10.917: INFO: Received response from host: affinity-nodeport-transition-hf2hc
Apr 20 06:44:10.917: INFO: Received response from host: affinity-nodeport-transition-hf2hc
Apr 20 06:44:10.917: INFO: Received response from host: affinity-nodeport-transition-hf2hc
Apr 20 06:44:10.917: INFO: Received response from host: affinity-nodeport-transition-hf2hc
Apr 20 06:44:10.917: INFO: Received response from host: affinity-nodeport-transition-hf2hc
Apr 20 06:44:10.917: INFO: Received response from host: affinity-nodeport-transition-hf2hc
Apr 20 06:44:10.917: INFO: Received response from host: affinity-nodeport-transition-hf2hc
Apr 20 06:44:10.917: INFO: Received response from host: affinity-nodeport-transition-hf2hc
Apr 20 06:44:10.917: INFO: Received response from host: affinity-nodeport-transition-hf2hc
Apr 20 06:44:10.917: INFO: Received response from host: affinity-nodeport-transition-hf2hc
Apr 20 06:44:10.917: INFO: Received response from host: affinity-nodeport-transition-hf2hc
Apr 20 06:44:10.917: INFO: Received response from host: affinity-nodeport-transition-hf2hc
Apr 20 06:44:10.917: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-8915, will wait for the garbage collector to delete the pods
Apr 20 06:44:10.991: INFO: Deleting ReplicationController affinity-nodeport-transition took: 6.701213ms
Apr 20 06:44:11.092: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.732194ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:44:12.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8915" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:8.744 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","total":346,"completed":223,"skipped":4146,"failed":0}
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:44:12.556: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:92
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:107
STEP: Creating service test in namespace statefulset-9451
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating stateful set ss in namespace statefulset-9451
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9451
Apr 20 06:44:12.608: INFO: Found 0 stateful pods, waiting for 1
Apr 20 06:44:22.615: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Apr 20 06:44:22.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=statefulset-9451 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 20 06:44:22.750: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 20 06:44:22.750: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 20 06:44:22.750: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 20 06:44:22.753: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 20 06:44:32.759: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 20 06:44:32.759: INFO: Waiting for statefulset status.replicas updated to 0
Apr 20 06:44:32.776: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Apr 20 06:44:32.776: INFO: ss-0  node22-hwh1v  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-04-20 06:44:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-04-20 06:44:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-04-20 06:44:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-04-20 06:44:12 +0000 UTC  }]
Apr 20 06:44:32.776: INFO: 
Apr 20 06:44:32.776: INFO: StatefulSet ss has not reached scale 3, at 1
Apr 20 06:44:33.781: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994074876s
Apr 20 06:44:34.787: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989060896s
Apr 20 06:44:35.791: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.983339649s
Apr 20 06:44:36.796: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.978884044s
Apr 20 06:44:37.800: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.973852149s
Apr 20 06:44:38.805: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.969916945s
Apr 20 06:44:39.811: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.964077926s
Apr 20 06:44:40.816: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.95961287s
Apr 20 06:44:41.820: INFO: Verifying statefulset ss doesn't scale past 3 for another 954.238803ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9451
Apr 20 06:44:42.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=statefulset-9451 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 20 06:44:42.960: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 20 06:44:42.960: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 20 06:44:42.960: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 20 06:44:42.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=statefulset-9451 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 20 06:44:43.086: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 20 06:44:43.086: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 20 06:44:43.086: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 20 06:44:43.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=statefulset-9451 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 20 06:44:43.221: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 20 06:44:43.221: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 20 06:44:43.221: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 20 06:44:43.229: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Apr 20 06:44:53.235: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 20 06:44:53.235: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 20 06:44:53.235: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Apr 20 06:44:53.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=statefulset-9451 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 20 06:44:53.359: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 20 06:44:53.359: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 20 06:44:53.359: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 20 06:44:53.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=statefulset-9451 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 20 06:44:53.490: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 20 06:44:53.490: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 20 06:44:53.490: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 20 06:44:53.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=statefulset-9451 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 20 06:44:53.617: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 20 06:44:53.617: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 20 06:44:53.617: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 20 06:44:53.617: INFO: Waiting for statefulset status.replicas updated to 0
Apr 20 06:44:53.620: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Apr 20 06:45:03.629: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 20 06:45:03.629: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 20 06:45:03.629: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 20 06:45:03.647: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Apr 20 06:45:03.647: INFO: ss-0  node22-hwh1v  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-04-20 06:44:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-04-20 06:44:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-04-20 06:44:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-04-20 06:44:12 +0000 UTC  }]
Apr 20 06:45:03.647: INFO: ss-1  node22-07idr  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-04-20 06:44:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-04-20 06:44:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-04-20 06:44:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-04-20 06:44:32 +0000 UTC  }]
Apr 20 06:45:03.647: INFO: ss-2  node22-wriki  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-04-20 06:44:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-04-20 06:44:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-04-20 06:44:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-04-20 06:44:32 +0000 UTC  }]
Apr 20 06:45:03.648: INFO: 
Apr 20 06:45:03.648: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 20 06:45:04.652: INFO: Verifying statefulset ss doesn't scale past 0 for another 8.996034161s
Apr 20 06:45:05.656: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.991712857s
Apr 20 06:45:06.659: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.987945613s
Apr 20 06:45:07.664: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.984700941s
Apr 20 06:45:08.668: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.97989846s
Apr 20 06:45:09.673: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.975293414s
Apr 20 06:45:10.678: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.970799008s
Apr 20 06:45:11.681: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.965804555s
Apr 20 06:45:12.686: INFO: Verifying statefulset ss doesn't scale past 0 for another 962.192562ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9451
Apr 20 06:45:13.690: INFO: Scaling statefulset ss to 0
Apr 20 06:45:13.698: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:118
Apr 20 06:45:13.700: INFO: Deleting all statefulset in ns statefulset-9451
Apr 20 06:45:13.702: INFO: Scaling statefulset ss to 0
Apr 20 06:45:13.708: INFO: Waiting for statefulset status.replicas updated to 0
Apr 20 06:45:13.710: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:45:13.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9451" for this suite.

• [SLOW TEST:61.169 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:97
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":346,"completed":224,"skipped":4147,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:45:13.725: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Apr 20 06:45:13.767: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 06:45:16.555: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:45:27.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5712" for this suite.

• [SLOW TEST:13.687 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":346,"completed":225,"skipped":4155,"failed":0}
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:45:27.412: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 20 06:45:27.910: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 20 06:45:30.931: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:45:30.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3096" for this suite.
STEP: Destroying namespace "webhook-3096-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":346,"completed":226,"skipped":4159,"failed":0}
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:45:31.017: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Performing setup for networking test in namespace pod-network-test-7046
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 20 06:45:31.049: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 20 06:45:31.108: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:45:33.112: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 20 06:45:35.115: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 20 06:45:37.113: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 20 06:45:39.115: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 20 06:45:41.114: INFO: The status of Pod netserver-0 is Running (Ready = true)
Apr 20 06:45:41.118: INFO: The status of Pod netserver-1 is Running (Ready = true)
Apr 20 06:45:41.121: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Apr 20 06:45:43.149: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Apr 20 06:45:43.149: INFO: Going to poll 10.233.1.78 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Apr 20 06:45:43.151: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.1.78:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7046 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 06:45:43.151: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 06:45:43.225: INFO: Found all 1 expected endpoints: [netserver-0]
Apr 20 06:45:43.225: INFO: Going to poll 10.233.0.119 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Apr 20 06:45:43.228: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.0.119:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7046 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 06:45:43.228: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 06:45:43.290: INFO: Found all 1 expected endpoints: [netserver-1]
Apr 20 06:45:43.290: INFO: Going to poll 10.233.2.156 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Apr 20 06:45:43.293: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.2.156:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7046 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 06:45:43.293: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 06:45:43.354: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:45:43.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7046" for this suite.

• [SLOW TEST:12.346 seconds]
[sig-network] Networking
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/networking.go:30
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":227,"skipped":4168,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should schedule multiple jobs concurrently [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:45:43.368: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
[It] should schedule multiple jobs concurrently [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a cronjob
STEP: Ensuring more than one job is running at a time
STEP: Ensuring at least two running jobs exists by listing jobs explicitly
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:47:01.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-1098" for this suite.

• [SLOW TEST:78.080 seconds]
[sig-apps] CronJob
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","total":346,"completed":228,"skipped":4229,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:47:01.449: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: set up a multi version CRD
Apr 20 06:47:01.545: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:47:15.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2792" for this suite.

• [SLOW TEST:13.992 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":346,"completed":229,"skipped":4238,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:47:15.442: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a service nodeport-service with the type=NodePort in namespace services-2183
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-2183
STEP: creating replication controller externalsvc in namespace services-2183
I0420 06:47:15.517875      20 runners.go:190] Created replication controller with name: externalsvc, namespace: services-2183, replica count: 2
I0420 06:47:18.568826      20 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Apr 20 06:47:18.601: INFO: Creating new exec pod
Apr 20 06:47:20.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=services-2183 exec execpodsl9c8 -- /bin/sh -x -c nslookup nodeport-service.services-2183.svc.cluster.local'
Apr 20 06:47:20.784: INFO: stderr: "+ nslookup nodeport-service.services-2183.svc.cluster.local\n"
Apr 20 06:47:20.784: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-2183.svc.cluster.local\tcanonical name = externalsvc.services-2183.svc.cluster.local.\nName:\texternalsvc.services-2183.svc.cluster.local\nAddress: 10.96.211.198\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-2183, will wait for the garbage collector to delete the pods
Apr 20 06:47:20.844: INFO: Deleting ReplicationController externalsvc took: 6.053306ms
Apr 20 06:47:20.945: INFO: Terminating ReplicationController externalsvc pods took: 100.972289ms
Apr 20 06:47:22.867: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:47:22.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2183" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

• [SLOW TEST:7.446 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":346,"completed":230,"skipped":4278,"failed":0}
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:47:22.889: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1799.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-1799.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1799.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1799.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1799.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-1799.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1799.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-1799.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1799.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1799.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-1799.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1799.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-1799.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1799.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-1799.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1799.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-1799.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1799.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 20 06:47:24.970: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1799.svc.cluster.local from pod dns-1799/dns-test-840a9e50-fb82-4730-a5ab-999ec4197f47: the server could not find the requested resource (get pods dns-test-840a9e50-fb82-4730-a5ab-999ec4197f47)
Apr 20 06:47:24.974: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1799.svc.cluster.local from pod dns-1799/dns-test-840a9e50-fb82-4730-a5ab-999ec4197f47: the server could not find the requested resource (get pods dns-test-840a9e50-fb82-4730-a5ab-999ec4197f47)
Apr 20 06:47:24.979: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1799.svc.cluster.local from pod dns-1799/dns-test-840a9e50-fb82-4730-a5ab-999ec4197f47: the server could not find the requested resource (get pods dns-test-840a9e50-fb82-4730-a5ab-999ec4197f47)
Apr 20 06:47:24.989: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1799.svc.cluster.local from pod dns-1799/dns-test-840a9e50-fb82-4730-a5ab-999ec4197f47: the server could not find the requested resource (get pods dns-test-840a9e50-fb82-4730-a5ab-999ec4197f47)
Apr 20 06:47:25.011: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1799.svc.cluster.local from pod dns-1799/dns-test-840a9e50-fb82-4730-a5ab-999ec4197f47: the server could not find the requested resource (get pods dns-test-840a9e50-fb82-4730-a5ab-999ec4197f47)
Apr 20 06:47:25.016: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1799.svc.cluster.local from pod dns-1799/dns-test-840a9e50-fb82-4730-a5ab-999ec4197f47: the server could not find the requested resource (get pods dns-test-840a9e50-fb82-4730-a5ab-999ec4197f47)
Apr 20 06:47:25.019: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1799.svc.cluster.local from pod dns-1799/dns-test-840a9e50-fb82-4730-a5ab-999ec4197f47: the server could not find the requested resource (get pods dns-test-840a9e50-fb82-4730-a5ab-999ec4197f47)
Apr 20 06:47:25.023: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1799.svc.cluster.local from pod dns-1799/dns-test-840a9e50-fb82-4730-a5ab-999ec4197f47: the server could not find the requested resource (get pods dns-test-840a9e50-fb82-4730-a5ab-999ec4197f47)
Apr 20 06:47:25.029: INFO: Lookups using dns-1799/dns-test-840a9e50-fb82-4730-a5ab-999ec4197f47 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1799.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1799.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1799.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1799.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1799.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1799.svc.cluster.local jessie_udp@dns-test-service-2.dns-1799.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1799.svc.cluster.local]

Apr 20 06:47:30.062: INFO: DNS probes using dns-1799/dns-test-840a9e50-fb82-4730-a5ab-999ec4197f47 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:47:30.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1799" for this suite.

• [SLOW TEST:7.219 seconds]
[sig-network] DNS
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":346,"completed":231,"skipped":4281,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:47:30.109: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with secret that has name projected-secret-test-ec8a0ad2-9136-431a-b68c-69286d22ace1
STEP: Creating a pod to test consume secrets
Apr 20 06:47:30.146: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3e4a279f-abe9-46b3-aa33-d6658386c4d0" in namespace "projected-6995" to be "Succeeded or Failed"
Apr 20 06:47:30.149: INFO: Pod "pod-projected-secrets-3e4a279f-abe9-46b3-aa33-d6658386c4d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.48086ms
Apr 20 06:47:32.158: INFO: Pod "pod-projected-secrets-3e4a279f-abe9-46b3-aa33-d6658386c4d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011649017s
STEP: Saw pod success
Apr 20 06:47:32.158: INFO: Pod "pod-projected-secrets-3e4a279f-abe9-46b3-aa33-d6658386c4d0" satisfied condition "Succeeded or Failed"
Apr 20 06:47:32.160: INFO: Trying to get logs from node node22-wriki pod pod-projected-secrets-3e4a279f-abe9-46b3-aa33-d6658386c4d0 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 20 06:47:32.185: INFO: Waiting for pod pod-projected-secrets-3e4a279f-abe9-46b3-aa33-d6658386c4d0 to disappear
Apr 20 06:47:32.187: INFO: Pod pod-projected-secrets-3e4a279f-abe9-46b3-aa33-d6658386c4d0 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:47:32.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6995" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":232,"skipped":4296,"failed":0}
SSSS
------------------------------
[sig-node] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:47:32.195: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test override all
Apr 20 06:47:32.228: INFO: Waiting up to 5m0s for pod "client-containers-cd45233b-33ed-4fe8-b5d1-19f63061b645" in namespace "containers-1798" to be "Succeeded or Failed"
Apr 20 06:47:32.230: INFO: Pod "client-containers-cd45233b-33ed-4fe8-b5d1-19f63061b645": Phase="Pending", Reason="", readiness=false. Elapsed: 1.847554ms
Apr 20 06:47:34.236: INFO: Pod "client-containers-cd45233b-33ed-4fe8-b5d1-19f63061b645": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007546346s
STEP: Saw pod success
Apr 20 06:47:34.236: INFO: Pod "client-containers-cd45233b-33ed-4fe8-b5d1-19f63061b645" satisfied condition "Succeeded or Failed"
Apr 20 06:47:34.238: INFO: Trying to get logs from node node22-wriki pod client-containers-cd45233b-33ed-4fe8-b5d1-19f63061b645 container agnhost-container: <nil>
STEP: delete the pod
Apr 20 06:47:34.253: INFO: Waiting for pod client-containers-cd45233b-33ed-4fe8-b5d1-19f63061b645 to disappear
Apr 20 06:47:34.255: INFO: Pod client-containers-cd45233b-33ed-4fe8-b5d1-19f63061b645 no longer exists
[AfterEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:47:34.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1798" for this suite.
•{"msg":"PASSED [sig-node] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":346,"completed":233,"skipped":4300,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:47:34.264: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:142
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:47:34.308: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Apr 20 06:47:34.323: INFO: Number of nodes with available pods: 0
Apr 20 06:47:34.323: INFO: Node node22-07idr is running more than one daemon pod
Apr 20 06:47:35.332: INFO: Number of nodes with available pods: 0
Apr 20 06:47:35.332: INFO: Node node22-07idr is running more than one daemon pod
Apr 20 06:47:36.330: INFO: Number of nodes with available pods: 3
Apr 20 06:47:36.330: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Apr 20 06:47:36.354: INFO: Wrong image for pod: daemon-set-swhfq. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.32, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-1.
Apr 20 06:47:36.354: INFO: Wrong image for pod: daemon-set-x7llb. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.32, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-1.
Apr 20 06:47:36.354: INFO: Wrong image for pod: daemon-set-zrb2j. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.32, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-1.
Apr 20 06:47:37.365: INFO: Wrong image for pod: daemon-set-swhfq. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.32, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-1.
Apr 20 06:47:37.365: INFO: Wrong image for pod: daemon-set-x7llb. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.32, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-1.
Apr 20 06:47:38.365: INFO: Wrong image for pod: daemon-set-swhfq. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.32, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-1.
Apr 20 06:47:38.365: INFO: Wrong image for pod: daemon-set-x7llb. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.32, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-1.
Apr 20 06:47:39.364: INFO: Pod daemon-set-blh2r is not available
Apr 20 06:47:39.364: INFO: Wrong image for pod: daemon-set-swhfq. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.32, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-1.
Apr 20 06:47:39.364: INFO: Wrong image for pod: daemon-set-x7llb. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.32, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-1.
Apr 20 06:47:40.365: INFO: Wrong image for pod: daemon-set-x7llb. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.32, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-1.
Apr 20 06:47:41.363: INFO: Pod daemon-set-rftgn is not available
Apr 20 06:47:41.363: INFO: Wrong image for pod: daemon-set-x7llb. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.32, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-1.
Apr 20 06:47:43.366: INFO: Pod daemon-set-gmx8x is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Apr 20 06:47:43.381: INFO: Number of nodes with available pods: 2
Apr 20 06:47:43.381: INFO: Node node22-07idr is running more than one daemon pod
Apr 20 06:47:44.389: INFO: Number of nodes with available pods: 3
Apr 20 06:47:44.389: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:108
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9607, will wait for the garbage collector to delete the pods
Apr 20 06:47:44.457: INFO: Deleting DaemonSet.extensions daemon-set took: 5.171093ms
Apr 20 06:47:44.557: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.278062ms
Apr 20 06:47:46.760: INFO: Number of nodes with available pods: 0
Apr 20 06:47:46.760: INFO: Number of running nodes: 0, number of available pods: 0
Apr 20 06:47:46.762: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"29034"},"items":null}

Apr 20 06:47:46.764: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"29034"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:47:46.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9607" for this suite.

• [SLOW TEST:12.519 seconds]
[sig-apps] Daemon set [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":346,"completed":234,"skipped":4323,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:47:46.787: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod pod-subpath-test-configmap-7m6b
STEP: Creating a pod to test atomic-volume-subpath
Apr 20 06:47:46.831: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-7m6b" in namespace "subpath-6035" to be "Succeeded or Failed"
Apr 20 06:47:46.833: INFO: Pod "pod-subpath-test-configmap-7m6b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.967243ms
Apr 20 06:47:48.839: INFO: Pod "pod-subpath-test-configmap-7m6b": Phase="Running", Reason="", readiness=true. Elapsed: 2.008711761s
Apr 20 06:47:50.846: INFO: Pod "pod-subpath-test-configmap-7m6b": Phase="Running", Reason="", readiness=true. Elapsed: 4.015049862s
Apr 20 06:47:52.855: INFO: Pod "pod-subpath-test-configmap-7m6b": Phase="Running", Reason="", readiness=true. Elapsed: 6.024410074s
Apr 20 06:47:54.860: INFO: Pod "pod-subpath-test-configmap-7m6b": Phase="Running", Reason="", readiness=true. Elapsed: 8.029292286s
Apr 20 06:47:56.865: INFO: Pod "pod-subpath-test-configmap-7m6b": Phase="Running", Reason="", readiness=true. Elapsed: 10.034019864s
Apr 20 06:47:58.870: INFO: Pod "pod-subpath-test-configmap-7m6b": Phase="Running", Reason="", readiness=true. Elapsed: 12.039674958s
Apr 20 06:48:00.876: INFO: Pod "pod-subpath-test-configmap-7m6b": Phase="Running", Reason="", readiness=true. Elapsed: 14.045724977s
Apr 20 06:48:02.883: INFO: Pod "pod-subpath-test-configmap-7m6b": Phase="Running", Reason="", readiness=true. Elapsed: 16.052606939s
Apr 20 06:48:04.890: INFO: Pod "pod-subpath-test-configmap-7m6b": Phase="Running", Reason="", readiness=true. Elapsed: 18.059226604s
Apr 20 06:48:06.895: INFO: Pod "pod-subpath-test-configmap-7m6b": Phase="Running", Reason="", readiness=true. Elapsed: 20.064362165s
Apr 20 06:48:08.901: INFO: Pod "pod-subpath-test-configmap-7m6b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.07001078s
STEP: Saw pod success
Apr 20 06:48:08.901: INFO: Pod "pod-subpath-test-configmap-7m6b" satisfied condition "Succeeded or Failed"
Apr 20 06:48:08.903: INFO: Trying to get logs from node node22-wriki pod pod-subpath-test-configmap-7m6b container test-container-subpath-configmap-7m6b: <nil>
STEP: delete the pod
Apr 20 06:48:08.924: INFO: Waiting for pod pod-subpath-test-configmap-7m6b to disappear
Apr 20 06:48:08.926: INFO: Pod pod-subpath-test-configmap-7m6b no longer exists
STEP: Deleting pod pod-subpath-test-configmap-7m6b
Apr 20 06:48:08.926: INFO: Deleting pod "pod-subpath-test-configmap-7m6b" in namespace "subpath-6035"
[AfterEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:48:08.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6035" for this suite.

• [SLOW TEST:22.150 seconds]
[sig-storage] Subpath
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [LinuxOnly] [Conformance]","total":346,"completed":235,"skipped":4339,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:48:08.937: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 20 06:48:09.458: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 20 06:48:12.479: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:48:12.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4720" for this suite.
STEP: Destroying namespace "webhook-4720-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":346,"completed":236,"skipped":4348,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:48:12.616: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/security_context.go:46
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:48:12.655: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-574069ca-e350-4113-aac9-2722254367d4" in namespace "security-context-test-1052" to be "Succeeded or Failed"
Apr 20 06:48:12.657: INFO: Pod "busybox-privileged-false-574069ca-e350-4113-aac9-2722254367d4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.877892ms
Apr 20 06:48:14.662: INFO: Pod "busybox-privileged-false-574069ca-e350-4113-aac9-2722254367d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007420418s
Apr 20 06:48:14.663: INFO: Pod "busybox-privileged-false-574069ca-e350-4113-aac9-2722254367d4" satisfied condition "Succeeded or Failed"
Apr 20 06:48:14.670: INFO: Got logs for pod "busybox-privileged-false-574069ca-e350-4113-aac9-2722254367d4": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:48:14.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1052" for this suite.
•{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":237,"skipped":4363,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:48:14.687: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Apr 20 06:48:14.724: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-8492  9f8c0d95-c250-487d-866d-8650d5d6325e 29287 0 2022-04-20 06:48:14 +0000 UTC <nil> <nil> map[] map[] [] []  [{e2e.test Update v1 2022-04-20 06:48:14 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nwffc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:k8s.gcr.io/e2e-test-images/agnhost:2.32,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nwffc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 20 06:48:14.728: INFO: The status of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:48:16.731: INFO: The status of Pod test-dns-nameservers is Running (Ready = true)
STEP: Verifying customized DNS suffix list is configured on pod...
Apr 20 06:48:16.731: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-8492 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 06:48:16.731: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Verifying customized DNS server is configured on pod...
Apr 20 06:48:16.812: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-8492 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 06:48:16.812: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 06:48:16.879: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:48:16.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8492" for this suite.
•{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":346,"completed":238,"skipped":4442,"failed":0}
S
------------------------------
[sig-node] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:48:16.898: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
Apr 20 06:48:16.936: INFO: The status of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:48:18.940: INFO: The status of Pod test-pod is Running (Ready = true)
STEP: Creating hostNetwork=true pod
Apr 20 06:48:18.949: INFO: The status of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:48:20.954: INFO: The status of Pod test-host-network-pod is Running (Ready = true)
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Apr 20 06:48:20.956: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2158 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 06:48:20.957: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 06:48:21.022: INFO: Exec stderr: ""
Apr 20 06:48:21.022: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2158 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 06:48:21.022: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 06:48:21.085: INFO: Exec stderr: ""
Apr 20 06:48:21.085: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2158 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 06:48:21.085: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 06:48:21.146: INFO: Exec stderr: ""
Apr 20 06:48:21.147: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2158 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 06:48:21.147: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 06:48:21.214: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Apr 20 06:48:21.214: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2158 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 06:48:21.214: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 06:48:21.296: INFO: Exec stderr: ""
Apr 20 06:48:21.296: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2158 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 06:48:21.296: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 06:48:21.360: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Apr 20 06:48:21.360: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2158 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 06:48:21.360: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 06:48:21.414: INFO: Exec stderr: ""
Apr 20 06:48:21.415: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2158 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 06:48:21.416: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 06:48:21.480: INFO: Exec stderr: ""
Apr 20 06:48:21.480: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2158 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 06:48:21.480: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 06:48:21.542: INFO: Exec stderr: ""
Apr 20 06:48:21.542: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2158 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 06:48:21.542: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 06:48:21.614: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:48:21.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-2158" for this suite.
•{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":239,"skipped":4443,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:48:21.627: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create services for rc  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating Agnhost RC
Apr 20 06:48:21.660: INFO: namespace kubectl-8004
Apr 20 06:48:21.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-8004 create -f -'
Apr 20 06:48:21.849: INFO: stderr: ""
Apr 20 06:48:21.850: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Apr 20 06:48:22.855: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 20 06:48:22.855: INFO: Found 0 / 1
Apr 20 06:48:23.854: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 20 06:48:23.854: INFO: Found 1 / 1
Apr 20 06:48:23.854: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 20 06:48:23.857: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 20 06:48:23.857: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 20 06:48:23.857: INFO: wait on agnhost-primary startup in kubectl-8004 
Apr 20 06:48:23.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-8004 logs agnhost-primary-bzgk9 agnhost-primary'
Apr 20 06:48:23.927: INFO: stderr: ""
Apr 20 06:48:23.927: INFO: stdout: "Paused\n"
STEP: exposing RC
Apr 20 06:48:23.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-8004 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Apr 20 06:48:24.004: INFO: stderr: ""
Apr 20 06:48:24.004: INFO: stdout: "service/rm2 exposed\n"
Apr 20 06:48:24.020: INFO: Service rm2 in namespace kubectl-8004 found.
STEP: exposing service
Apr 20 06:48:26.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-8004 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Apr 20 06:48:26.102: INFO: stderr: ""
Apr 20 06:48:26.102: INFO: stdout: "service/rm3 exposed\n"
Apr 20 06:48:26.104: INFO: Service rm3 in namespace kubectl-8004 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:48:28.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8004" for this suite.

• [SLOW TEST:6.493 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1233
    should create services for rc  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":346,"completed":240,"skipped":4458,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:48:28.119: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:188
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:48:28.148: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: creating the pod
STEP: submitting the pod to kubernetes
Apr 20 06:48:28.156: INFO: The status of Pod pod-exec-websocket-af71d355-e36f-4f94-a1e7-a756200013d7 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:48:30.161: INFO: The status of Pod pod-exec-websocket-af71d355-e36f-4f94-a1e7-a756200013d7 is Running (Ready = true)
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:48:30.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5821" for this suite.
•{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":346,"completed":241,"skipped":4470,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:48:30.236: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 20 06:48:30.531: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 20 06:48:33.553: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Apr 20 06:48:35.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=webhook-4465 attach --namespace=webhook-4465 to-be-attached-pod -i -c=container1'
Apr 20 06:48:35.666: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:48:35.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4465" for this suite.
STEP: Destroying namespace "webhook-4465-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.487 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":346,"completed":242,"skipped":4480,"failed":0}
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:48:35.724: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:48:48.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5954" for this suite.

• [SLOW TEST:13.134 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":346,"completed":243,"skipped":4484,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should list and delete a collection of DaemonSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:48:48.858: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:142
[It] should list and delete a collection of DaemonSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 20 06:48:48.922: INFO: Number of nodes with available pods: 0
Apr 20 06:48:48.922: INFO: Node node22-07idr is running more than one daemon pod
Apr 20 06:48:49.928: INFO: Number of nodes with available pods: 1
Apr 20 06:48:49.928: INFO: Node node22-hwh1v is running more than one daemon pod
Apr 20 06:48:50.931: INFO: Number of nodes with available pods: 3
Apr 20 06:48:50.931: INFO: Number of running nodes: 3, number of available pods: 3
STEP: listing all DeamonSets
STEP: DeleteCollection of the DaemonSets
STEP: Verify that ReplicaSets have been deleted
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:108
Apr 20 06:48:50.946: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"29746"},"items":null}

Apr 20 06:48:50.948: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"29746"},"items":[{"metadata":{"name":"daemon-set-6qtl8","generateName":"daemon-set-","namespace":"daemonsets-6018","uid":"52b15b13-1ab1-45a0-a56d-42fb9b992dd5","resourceVersion":"29737","creationTimestamp":"2022-04-20T06:48:48Z","labels":{"controller-revision-hash":"577749b6b","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/podIP":"10.233.0.125/32","cni.projectcalico.org/podIPs":"10.233.0.125/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"e057fa4b-8681-42cc-a3c0-683830e89ea4","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-04-20T06:48:48Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e057fa4b-8681-42cc-a3c0-683830e89ea4\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-04-20T06:48:49Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-04-20T06:48:50Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.0.125\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-l5r2t","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-1","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-l5r2t","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent"}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"node22-hwh1v","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["node22-hwh1v"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-04-20T06:48:48Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-04-20T06:48:49Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-04-20T06:48:49Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-04-20T06:48:48Z"}],"hostIP":"10.100.125.144","podIP":"10.233.0.125","podIPs":[{"ip":"10.233.0.125"}],"startTime":"2022-04-20T06:48:48Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-04-20T06:48:49Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-1","imageID":"k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50","containerID":"containerd://9032e87918884222be6e5417716171fc9ecb58834b140f6eeddc84f453ece365","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-fr478","generateName":"daemon-set-","namespace":"daemonsets-6018","uid":"433e15b7-6e14-400b-8a73-4afeeef2b6eb","resourceVersion":"29739","creationTimestamp":"2022-04-20T06:48:48Z","labels":{"controller-revision-hash":"577749b6b","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/podIP":"10.233.2.170/32","cni.projectcalico.org/podIPs":"10.233.2.170/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"e057fa4b-8681-42cc-a3c0-683830e89ea4","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-04-20T06:48:48Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e057fa4b-8681-42cc-a3c0-683830e89ea4\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-04-20T06:48:49Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-04-20T06:48:50Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.2.170\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-sxqdg","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-1","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-sxqdg","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent"}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"node22-wriki","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["node22-wriki"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-04-20T06:48:48Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-04-20T06:48:50Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-04-20T06:48:50Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-04-20T06:48:48Z"}],"hostIP":"10.100.99.219","podIP":"10.233.2.170","podIPs":[{"ip":"10.233.2.170"}],"startTime":"2022-04-20T06:48:48Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-04-20T06:48:49Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-1","imageID":"k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50","containerID":"containerd://c1acdbe229f6758499af3f27f153a6d51e27200e76f529345507e0b889ca8eed","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-n8wtg","generateName":"daemon-set-","namespace":"daemonsets-6018","uid":"ce9be566-ac7e-4720-b8e3-0335a49f0c39","resourceVersion":"29735","creationTimestamp":"2022-04-20T06:48:48Z","labels":{"controller-revision-hash":"577749b6b","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/podIP":"10.233.1.85/32","cni.projectcalico.org/podIPs":"10.233.1.85/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"e057fa4b-8681-42cc-a3c0-683830e89ea4","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-04-20T06:48:48Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e057fa4b-8681-42cc-a3c0-683830e89ea4\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-04-20T06:48:49Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-04-20T06:48:49Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.1.85\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-wqv5r","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-1","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-wqv5r","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent"}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"node22-07idr","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["node22-07idr"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-04-20T06:48:48Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-04-20T06:48:49Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-04-20T06:48:49Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-04-20T06:48:48Z"}],"hostIP":"10.100.118.168","podIP":"10.233.1.85","podIPs":[{"ip":"10.233.1.85"}],"startTime":"2022-04-20T06:48:48Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-04-20T06:48:49Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-1","imageID":"k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50","containerID":"containerd://188a4934f12441f5640a6d837294c1985c0f4d7de45ef13b2a6066c58873d096","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:48:50.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6018" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","total":346,"completed":244,"skipped":4572,"failed":0}
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:48:50.984: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Kubectl replace
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1558
[It] should update a single-container pod's image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-1
Apr 20 06:48:51.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-5981 run e2e-test-httpd-pod --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Apr 20 06:48:51.078: INFO: stderr: ""
Apr 20 06:48:51.078: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Apr 20 06:48:56.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-5981 get pod e2e-test-httpd-pod -o json'
Apr 20 06:48:56.180: INFO: stderr: ""
Apr 20 06:48:56.180: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.233.2.171/32\",\n            \"cni.projectcalico.org/podIPs\": \"10.233.2.171/32\"\n        },\n        \"creationTimestamp\": \"2022-04-20T06:48:51Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-5981\",\n        \"resourceVersion\": \"29765\",\n        \"uid\": \"d7470820-58ae-4c79-b216-1ca25e7c45f4\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"k8s.gcr.io/e2e-test-images/httpd:2.4.38-1\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-p9qnf\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"node22-wriki\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-p9qnf\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-04-20T06:48:51Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-04-20T06:48:52Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-04-20T06:48:52Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-04-20T06:48:51Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://a4da4e079aa5c8cc3b1b0ca82447ded4696e4ac10c43da71d79f31cbe0ad4833\",\n                \"image\": \"k8s.gcr.io/e2e-test-images/httpd:2.4.38-1\",\n                \"imageID\": \"k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-04-20T06:48:51Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.100.99.219\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.233.2.171\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.233.2.171\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-04-20T06:48:51Z\"\n    }\n}\n"
STEP: replace the image in the pod
Apr 20 06:48:56.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-5981 replace -f -'
Apr 20 06:48:56.330: INFO: stderr: ""
Apr 20 06:48:56.330: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image k8s.gcr.io/e2e-test-images/busybox:1.29-1
[AfterEach] Kubectl replace
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1562
Apr 20 06:48:56.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-5981 delete pods e2e-test-httpd-pod'
Apr 20 06:48:58.072: INFO: stderr: ""
Apr 20 06:48:58.072: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:48:58.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5981" for this suite.

• [SLOW TEST:7.099 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1555
    should update a single-container pod's image  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":346,"completed":245,"skipped":4578,"failed":0}
SSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] 
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/sysctl.go:36
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:48:58.083: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename sysctl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/sysctl.go:65
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod with one valid and two invalid sysctls
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:48:58.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-3189" for this suite.
•{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","total":346,"completed":246,"skipped":4583,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:48:58.123: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Apr 20 06:48:58.167: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8631  8b857240-175d-4ea9-bd0a-d0e5e8173315 29852 0 2022-04-20 06:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-04-20 06:48:58 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 20 06:48:58.167: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8631  8b857240-175d-4ea9-bd0a-d0e5e8173315 29853 0 2022-04-20 06:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-04-20 06:48:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Apr 20 06:48:58.175: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8631  8b857240-175d-4ea9-bd0a-d0e5e8173315 29854 0 2022-04-20 06:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-04-20 06:48:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 20 06:48:58.176: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8631  8b857240-175d-4ea9-bd0a-d0e5e8173315 29855 0 2022-04-20 06:48:58 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-04-20 06:48:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:48:58.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8631" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":346,"completed":247,"skipped":4593,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:48:58.186: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr 20 06:48:58.218: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5cba4a37-6433-4cb3-aa25-d490adcf4af7" in namespace "projected-6434" to be "Succeeded or Failed"
Apr 20 06:48:58.225: INFO: Pod "downwardapi-volume-5cba4a37-6433-4cb3-aa25-d490adcf4af7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.113516ms
Apr 20 06:49:00.229: INFO: Pod "downwardapi-volume-5cba4a37-6433-4cb3-aa25-d490adcf4af7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01075149s
STEP: Saw pod success
Apr 20 06:49:00.229: INFO: Pod "downwardapi-volume-5cba4a37-6433-4cb3-aa25-d490adcf4af7" satisfied condition "Succeeded or Failed"
Apr 20 06:49:00.231: INFO: Trying to get logs from node node22-wriki pod downwardapi-volume-5cba4a37-6433-4cb3-aa25-d490adcf4af7 container client-container: <nil>
STEP: delete the pod
Apr 20 06:49:00.245: INFO: Waiting for pod downwardapi-volume-5cba4a37-6433-4cb3-aa25-d490adcf4af7 to disappear
Apr 20 06:49:00.246: INFO: Pod downwardapi-volume-5cba4a37-6433-4cb3-aa25-d490adcf4af7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:49:00.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6434" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":346,"completed":248,"skipped":4614,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints 
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:49:00.255: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:90
Apr 20 06:49:00.292: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 20 06:50:00.319: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:50:00.321: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename sched-preemption-path
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] PriorityClass endpoints
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:679
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:50:00.369: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: Value: Forbidden: may not be changed in an update.
Apr 20 06:50:00.371: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: Value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:50:00.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-3301" for this suite.
[AfterEach] PriorityClass endpoints
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:693
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:50:00.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-3136" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:78

• [SLOW TEST:60.176 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:673
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","total":346,"completed":249,"skipped":4626,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:50:00.432: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-map-ce11783b-ac83-4bce-9c50-8f054cc61d4a
STEP: Creating a pod to test consume configMaps
Apr 20 06:50:00.468: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7f1f45ee-559b-46d3-a465-f9a18a8499a4" in namespace "projected-5556" to be "Succeeded or Failed"
Apr 20 06:50:00.470: INFO: Pod "pod-projected-configmaps-7f1f45ee-559b-46d3-a465-f9a18a8499a4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.520263ms
Apr 20 06:50:02.477: INFO: Pod "pod-projected-configmaps-7f1f45ee-559b-46d3-a465-f9a18a8499a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008103744s
STEP: Saw pod success
Apr 20 06:50:02.477: INFO: Pod "pod-projected-configmaps-7f1f45ee-559b-46d3-a465-f9a18a8499a4" satisfied condition "Succeeded or Failed"
Apr 20 06:50:02.479: INFO: Trying to get logs from node node22-wriki pod pod-projected-configmaps-7f1f45ee-559b-46d3-a465-f9a18a8499a4 container agnhost-container: <nil>
STEP: delete the pod
Apr 20 06:50:02.499: INFO: Waiting for pod pod-projected-configmaps-7f1f45ee-559b-46d3-a465-f9a18a8499a4 to disappear
Apr 20 06:50:02.505: INFO: Pod pod-projected-configmaps-7f1f45ee-559b-46d3-a465-f9a18a8499a4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:50:02.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5556" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":346,"completed":250,"skipped":4642,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:50:02.514: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:50:02.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7256" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":346,"completed":251,"skipped":4654,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:50:02.624: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/endpointslice.go:49
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:50:02.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-6434" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","total":346,"completed":252,"skipped":4743,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:50:02.682: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 20 06:50:03.050: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 20 06:50:06.074: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:50:18.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9730" for this suite.
STEP: Destroying namespace "webhook-9730-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:15.583 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":346,"completed":253,"skipped":4749,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:50:18.266: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5821.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-5821.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5821.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5821.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-5821.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5821.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 20 06:50:20.385: INFO: DNS probes using dns-5821/dns-test-38270c04-8f3c-4023-ae61-bbf45af7fa33 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:50:20.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5821" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]","total":346,"completed":254,"skipped":4772,"failed":0}
SSSS
------------------------------
[sig-network] Services 
  should find a service from listing all namespaces [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:50:20.412: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should find a service from listing all namespaces [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: fetching services
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:50:20.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5546" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753
•{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","total":346,"completed":255,"skipped":4776,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods Extended
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:50:20.469: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Pods Set QOS Class
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:149
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [sig-node] Pods Extended
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:50:20.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3815" for this suite.
•{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":346,"completed":256,"skipped":4827,"failed":0}
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:50:20.516: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr 20 06:50:22.560: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:50:22.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-229" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":346,"completed":257,"skipped":4828,"failed":0}
SSS
------------------------------
[sig-node] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:50:22.578: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:188
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:50:22.619: INFO: The status of Pod server-envvars-4d1575a5-6711-418e-ab7a-17d4998d4735 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:50:24.626: INFO: The status of Pod server-envvars-4d1575a5-6711-418e-ab7a-17d4998d4735 is Running (Ready = true)
Apr 20 06:50:24.671: INFO: Waiting up to 5m0s for pod "client-envvars-115f420a-07a9-4f62-b03f-7301102f0554" in namespace "pods-7862" to be "Succeeded or Failed"
Apr 20 06:50:24.676: INFO: Pod "client-envvars-115f420a-07a9-4f62-b03f-7301102f0554": Phase="Pending", Reason="", readiness=false. Elapsed: 4.648182ms
Apr 20 06:50:26.679: INFO: Pod "client-envvars-115f420a-07a9-4f62-b03f-7301102f0554": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007989175s
STEP: Saw pod success
Apr 20 06:50:26.679: INFO: Pod "client-envvars-115f420a-07a9-4f62-b03f-7301102f0554" satisfied condition "Succeeded or Failed"
Apr 20 06:50:26.681: INFO: Trying to get logs from node node22-hwh1v pod client-envvars-115f420a-07a9-4f62-b03f-7301102f0554 container env3cont: <nil>
STEP: delete the pod
Apr 20 06:50:26.702: INFO: Waiting for pod client-envvars-115f420a-07a9-4f62-b03f-7301102f0554 to disappear
Apr 20 06:50:26.704: INFO: Pod client-envvars-115f420a-07a9-4f62-b03f-7301102f0554 no longer exists
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:50:26.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7862" for this suite.
•{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":346,"completed":258,"skipped":4831,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:50:26.715: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with secret that has name projected-secret-test-map-36673499-134a-47cd-8ba6-c3a1792b6496
STEP: Creating a pod to test consume secrets
Apr 20 06:50:26.753: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1e62ab7f-37ca-441b-bc07-f5208b63c34b" in namespace "projected-7265" to be "Succeeded or Failed"
Apr 20 06:50:26.755: INFO: Pod "pod-projected-secrets-1e62ab7f-37ca-441b-bc07-f5208b63c34b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.283025ms
Apr 20 06:50:28.762: INFO: Pod "pod-projected-secrets-1e62ab7f-37ca-441b-bc07-f5208b63c34b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009338316s
STEP: Saw pod success
Apr 20 06:50:28.762: INFO: Pod "pod-projected-secrets-1e62ab7f-37ca-441b-bc07-f5208b63c34b" satisfied condition "Succeeded or Failed"
Apr 20 06:50:28.764: INFO: Trying to get logs from node node22-hwh1v pod pod-projected-secrets-1e62ab7f-37ca-441b-bc07-f5208b63c34b container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 20 06:50:28.779: INFO: Waiting for pod pod-projected-secrets-1e62ab7f-37ca-441b-bc07-f5208b63c34b to disappear
Apr 20 06:50:28.781: INFO: Pod pod-projected-secrets-1e62ab7f-37ca-441b-bc07-f5208b63c34b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:50:28.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7265" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":346,"completed":259,"skipped":4838,"failed":0}

------------------------------
[sig-node] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:50:28.788: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:188
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating pod
Apr 20 06:50:28.827: INFO: The status of Pod pod-hostip-d621aa74-295b-40f6-a469-75882e4c688b is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:50:30.830: INFO: The status of Pod pod-hostip-d621aa74-295b-40f6-a469-75882e4c688b is Running (Ready = true)
Apr 20 06:50:30.836: INFO: Pod pod-hostip-d621aa74-295b-40f6-a469-75882e4c688b has hostIP: 10.100.125.144
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:50:30.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7791" for this suite.
•{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","total":346,"completed":260,"skipped":4838,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:50:30.846: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting the auto-created API token
Apr 20 06:50:31.419: INFO: created pod pod-service-account-defaultsa
Apr 20 06:50:31.419: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr 20 06:50:31.428: INFO: created pod pod-service-account-mountsa
Apr 20 06:50:31.428: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr 20 06:50:31.431: INFO: created pod pod-service-account-nomountsa
Apr 20 06:50:31.431: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr 20 06:50:31.441: INFO: created pod pod-service-account-defaultsa-mountspec
Apr 20 06:50:31.441: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr 20 06:50:31.446: INFO: created pod pod-service-account-mountsa-mountspec
Apr 20 06:50:31.446: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr 20 06:50:31.455: INFO: created pod pod-service-account-nomountsa-mountspec
Apr 20 06:50:31.455: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr 20 06:50:31.513: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr 20 06:50:31.513: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr 20 06:50:31.534: INFO: created pod pod-service-account-mountsa-nomountspec
Apr 20 06:50:31.534: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr 20 06:50:31.539: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr 20 06:50:31.539: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:50:31.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6878" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":346,"completed":261,"skipped":4852,"failed":0}
S
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:50:31.558: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Apr 20 06:50:32.026: INFO: Pod name wrapped-volume-race-d3d1bc93-ef84-4c73-9627-7fc400d69db9: Found 2 pods out of 5
Apr 20 06:50:37.032: INFO: Pod name wrapped-volume-race-d3d1bc93-ef84-4c73-9627-7fc400d69db9: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d3d1bc93-ef84-4c73-9627-7fc400d69db9 in namespace emptydir-wrapper-515, will wait for the garbage collector to delete the pods
Apr 20 06:50:51.117: INFO: Deleting ReplicationController wrapped-volume-race-d3d1bc93-ef84-4c73-9627-7fc400d69db9 took: 10.897549ms
Apr 20 06:50:51.217: INFO: Terminating ReplicationController wrapped-volume-race-d3d1bc93-ef84-4c73-9627-7fc400d69db9 pods took: 100.628186ms
STEP: Creating RC which spawns configmap-volume pods
Apr 20 06:50:55.542: INFO: Pod name wrapped-volume-race-5fe9d2d6-6566-42ae-8096-4c39389d0b61: Found 0 pods out of 5
Apr 20 06:51:00.549: INFO: Pod name wrapped-volume-race-5fe9d2d6-6566-42ae-8096-4c39389d0b61: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-5fe9d2d6-6566-42ae-8096-4c39389d0b61 in namespace emptydir-wrapper-515, will wait for the garbage collector to delete the pods
Apr 20 06:51:12.633: INFO: Deleting ReplicationController wrapped-volume-race-5fe9d2d6-6566-42ae-8096-4c39389d0b61 took: 7.684447ms
Apr 20 06:51:12.734: INFO: Terminating ReplicationController wrapped-volume-race-5fe9d2d6-6566-42ae-8096-4c39389d0b61 pods took: 101.162483ms
STEP: Creating RC which spawns configmap-volume pods
Apr 20 06:51:15.254: INFO: Pod name wrapped-volume-race-e1d87678-3a9d-4b69-981f-8661573c07d2: Found 0 pods out of 5
Apr 20 06:51:20.263: INFO: Pod name wrapped-volume-race-e1d87678-3a9d-4b69-981f-8661573c07d2: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-e1d87678-3a9d-4b69-981f-8661573c07d2 in namespace emptydir-wrapper-515, will wait for the garbage collector to delete the pods
Apr 20 06:51:30.350: INFO: Deleting ReplicationController wrapped-volume-race-e1d87678-3a9d-4b69-981f-8661573c07d2 took: 13.983891ms
Apr 20 06:51:30.450: INFO: Terminating ReplicationController wrapped-volume-race-e1d87678-3a9d-4b69-981f-8661573c07d2 pods took: 100.833824ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:51:34.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-515" for this suite.

• [SLOW TEST:62.590 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":346,"completed":262,"skipped":4853,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:51:34.149: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:51:34.180: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:51:35.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-280" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":346,"completed":263,"skipped":4867,"failed":0}
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:51:35.243: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr 20 06:51:35.726: INFO: Waiting up to 5m0s for pod "downwardapi-volume-074d7797-f8f4-476e-b752-3f64627c1e4a" in namespace "projected-8402" to be "Succeeded or Failed"
Apr 20 06:51:35.728: INFO: Pod "downwardapi-volume-074d7797-f8f4-476e-b752-3f64627c1e4a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.696408ms
Apr 20 06:51:37.734: INFO: Pod "downwardapi-volume-074d7797-f8f4-476e-b752-3f64627c1e4a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007997601s
STEP: Saw pod success
Apr 20 06:51:37.734: INFO: Pod "downwardapi-volume-074d7797-f8f4-476e-b752-3f64627c1e4a" satisfied condition "Succeeded or Failed"
Apr 20 06:51:37.736: INFO: Trying to get logs from node node22-07idr pod downwardapi-volume-074d7797-f8f4-476e-b752-3f64627c1e4a container client-container: <nil>
STEP: delete the pod
Apr 20 06:51:37.759: INFO: Waiting for pod downwardapi-volume-074d7797-f8f4-476e-b752-3f64627c1e4a to disappear
Apr 20 06:51:37.761: INFO: Pod downwardapi-volume-074d7797-f8f4-476e-b752-3f64627c1e4a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:51:37.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8402" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":346,"completed":264,"skipped":4870,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:51:37.773: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward api env vars
Apr 20 06:51:37.880: INFO: Waiting up to 5m0s for pod "downward-api-c5199475-55f8-4f43-8c50-ff95ca410539" in namespace "downward-api-9880" to be "Succeeded or Failed"
Apr 20 06:51:37.888: INFO: Pod "downward-api-c5199475-55f8-4f43-8c50-ff95ca410539": Phase="Pending", Reason="", readiness=false. Elapsed: 8.402787ms
Apr 20 06:51:39.895: INFO: Pod "downward-api-c5199475-55f8-4f43-8c50-ff95ca410539": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015019466s
STEP: Saw pod success
Apr 20 06:51:39.895: INFO: Pod "downward-api-c5199475-55f8-4f43-8c50-ff95ca410539" satisfied condition "Succeeded or Failed"
Apr 20 06:51:39.898: INFO: Trying to get logs from node node22-07idr pod downward-api-c5199475-55f8-4f43-8c50-ff95ca410539 container dapi-container: <nil>
STEP: delete the pod
Apr 20 06:51:39.915: INFO: Waiting for pod downward-api-c5199475-55f8-4f43-8c50-ff95ca410539 to disappear
Apr 20 06:51:39.917: INFO: Pod downward-api-c5199475-55f8-4f43-8c50-ff95ca410539 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:51:39.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9880" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":346,"completed":265,"skipped":4885,"failed":0}
SSSSS
------------------------------
[sig-apps] Deployment 
  should run the lifecycle of a Deployment [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:51:39.927: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] should run the lifecycle of a Deployment [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a Deployment
STEP: waiting for Deployment to be created
STEP: waiting for all Replicas to be Ready
Apr 20 06:51:40.014: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 20 06:51:40.014: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 20 06:51:40.020: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 20 06:51:40.020: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 20 06:51:40.042: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 20 06:51:40.042: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 20 06:51:40.066: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 20 06:51:40.066: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 20 06:51:41.218: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Apr 20 06:51:41.218: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Apr 20 06:51:41.469: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment
Apr 20 06:51:41.484: INFO: observed event type ADDED
STEP: waiting for Replicas to scale
Apr 20 06:51:41.488: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 0
Apr 20 06:51:41.488: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 0
Apr 20 06:51:41.489: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 0
Apr 20 06:51:41.489: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 0
Apr 20 06:51:41.489: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 0
Apr 20 06:51:41.489: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 0
Apr 20 06:51:41.489: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 0
Apr 20 06:51:41.489: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 0
Apr 20 06:51:41.489: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 1
Apr 20 06:51:41.489: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 1
Apr 20 06:51:41.489: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 2
Apr 20 06:51:41.494: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 2
Apr 20 06:51:41.494: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 2
Apr 20 06:51:41.494: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 2
Apr 20 06:51:41.494: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 2
Apr 20 06:51:41.494: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 2
Apr 20 06:51:41.508: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 2
Apr 20 06:51:41.508: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 2
Apr 20 06:51:41.523: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 1
Apr 20 06:51:41.523: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 1
Apr 20 06:51:41.530: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 1
Apr 20 06:51:41.530: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 1
Apr 20 06:51:42.486: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 2
Apr 20 06:51:42.486: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 2
Apr 20 06:51:42.499: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 1
STEP: listing Deployments
Apr 20 06:51:42.504: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment
Apr 20 06:51:42.518: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 1
STEP: fetching the DeploymentStatus
Apr 20 06:51:42.528: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 20 06:51:42.554: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 20 06:51:42.582: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 20 06:51:42.597: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 20 06:51:44.229: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr 20 06:51:44.244: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
Apr 20 06:51:44.274: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr 20 06:51:44.282: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr 20 06:51:45.485: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus
STEP: fetching the DeploymentStatus
Apr 20 06:51:45.515: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 1
Apr 20 06:51:45.515: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 1
Apr 20 06:51:45.515: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 1
Apr 20 06:51:45.515: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 1
Apr 20 06:51:45.515: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 2
Apr 20 06:51:45.515: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 3
Apr 20 06:51:45.515: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 2
Apr 20 06:51:45.515: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 2
Apr 20 06:51:45.515: INFO: observed Deployment test-deployment in namespace deployment-8871 with ReadyReplicas 3
STEP: deleting the Deployment
Apr 20 06:51:45.521: INFO: observed event type MODIFIED
Apr 20 06:51:45.521: INFO: observed event type MODIFIED
Apr 20 06:51:45.521: INFO: observed event type MODIFIED
Apr 20 06:51:45.521: INFO: observed event type MODIFIED
Apr 20 06:51:45.521: INFO: observed event type MODIFIED
Apr 20 06:51:45.521: INFO: observed event type MODIFIED
Apr 20 06:51:45.522: INFO: observed event type MODIFIED
Apr 20 06:51:45.522: INFO: observed event type MODIFIED
Apr 20 06:51:45.522: INFO: observed event type MODIFIED
Apr 20 06:51:45.522: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Apr 20 06:51:45.525: INFO: Log out all the ReplicaSets if there is no deployment created
Apr 20 06:51:45.530: INFO: ReplicaSet "test-deployment-56c98d85f9":
&ReplicaSet{ObjectMeta:{test-deployment-56c98d85f9  deployment-8871  a700344a-0c68-4201-9dcb-266d43fdc6dc 32059 4 2022-04-20 06:51:41 +0000 UTC <nil> <nil> map[pod-template-hash:56c98d85f9 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment d102bd1c-ff98-4aa8-a2f7-fd09d0e442ee 0xc004c3ce67 0xc004c3ce68}] []  [{kube-controller-manager Update apps/v1 2022-04-20 06:51:41 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d102bd1c-ff98-4aa8-a2f7-fd09d0e442ee\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-20 06:51:45 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 56c98d85f9,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:56c98d85f9 test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/pause:3.5 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004c3cef0 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Apr 20 06:51:45.536: INFO: pod: "test-deployment-56c98d85f9-8v4zs":
&Pod{ObjectMeta:{test-deployment-56c98d85f9-8v4zs test-deployment-56c98d85f9- deployment-8871  cd213aa5-b71b-4a47-b30a-ceba9dd8a0c5 32055 0 2022-04-20 06:51:41 +0000 UTC 2022-04-20 06:51:46 +0000 UTC 0xc004c3d338 map[pod-template-hash:56c98d85f9 test-deployment-static:true] map[cni.projectcalico.org/podIP:10.233.2.184/32 cni.projectcalico.org/podIPs:10.233.2.184/32] [{apps/v1 ReplicaSet test-deployment-56c98d85f9 a700344a-0c68-4201-9dcb-266d43fdc6dc 0xc004c3d387 0xc004c3d388}] []  [{calico Update v1 2022-04-20 06:51:41 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-04-20 06:51:41 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a700344a-0c68-4201-9dcb-266d43fdc6dc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-04-20 06:51:42 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.2.184\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qs2cm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/pause:3.5,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qs2cm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-wriki,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:51:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:51:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:51:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:51:41 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.99.219,PodIP:10.233.2.184,StartTime:2022-04-20 06:51:41 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-20 06:51:42 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/pause:3.5,ImageID:k8s.gcr.io/pause@sha256:1ff6c18fbef2045af6b9c16bf034cc421a29027b800e4f9b68ae9b1cb3e9ae07,ContainerID:containerd://209c9de383375852aedbfae62f930f17bae8e0d0aa1edc24cb9c0f440fc29d9c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.2.184,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Apr 20 06:51:45.536: INFO: pod: "test-deployment-56c98d85f9-xm9m8":
&Pod{ObjectMeta:{test-deployment-56c98d85f9-xm9m8 test-deployment-56c98d85f9- deployment-8871  54fac2e2-2446-4be5-b1a6-bf6905b59214 32013 0 2022-04-20 06:51:42 +0000 UTC 2022-04-20 06:51:45 +0000 UTC 0xc004c3d570 map[pod-template-hash:56c98d85f9 test-deployment-static:true] map[cni.projectcalico.org/podIP:10.233.1.96/32 cni.projectcalico.org/podIPs:10.233.1.96/32] [{apps/v1 ReplicaSet test-deployment-56c98d85f9 a700344a-0c68-4201-9dcb-266d43fdc6dc 0xc004c3d5c7 0xc004c3d5c8}] []  [{kube-controller-manager Update v1 2022-04-20 06:51:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a700344a-0c68-4201-9dcb-266d43fdc6dc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-04-20 06:51:43 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-04-20 06:51:44 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.1.96\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-69wk7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/pause:3.5,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-69wk7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-07idr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:51:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:51:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:51:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:51:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.118.168,PodIP:10.233.1.96,StartTime:2022-04-20 06:51:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-20 06:51:43 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/pause:3.5,ImageID:k8s.gcr.io/pause@sha256:1ff6c18fbef2045af6b9c16bf034cc421a29027b800e4f9b68ae9b1cb3e9ae07,ContainerID:containerd://1bd910ba41dba3138dcd07c573df199ab865d157522438e755b218f25204087e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.1.96,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Apr 20 06:51:45.537: INFO: ReplicaSet "test-deployment-855f7994f9":
&ReplicaSet{ObjectMeta:{test-deployment-855f7994f9  deployment-8871  12370151-4c65-4933-9c59-fcdb5b34e81f 31952 3 2022-04-20 06:51:40 +0000 UTC <nil> <nil> map[pod-template-hash:855f7994f9 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment d102bd1c-ff98-4aa8-a2f7-fd09d0e442ee 0xc004c3cf57 0xc004c3cf58}] []  [{kube-controller-manager Update apps/v1 2022-04-20 06:51:40 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d102bd1c-ff98-4aa8-a2f7-fd09d0e442ee\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-20 06:51:42 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 855f7994f9,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:855f7994f9 test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/e2e-test-images/agnhost:2.32 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004c3cfe0 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Apr 20 06:51:45.544: INFO: ReplicaSet "test-deployment-d4dfddfbf":
&ReplicaSet{ObjectMeta:{test-deployment-d4dfddfbf  deployment-8871  cc0d9ac2-6f5a-4605-ba57-2be5adf10531 32051 2 2022-04-20 06:51:42 +0000 UTC <nil> <nil> map[pod-template-hash:d4dfddfbf test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment d102bd1c-ff98-4aa8-a2f7-fd09d0e442ee 0xc004c3d047 0xc004c3d048}] []  [{kube-controller-manager Update apps/v1 2022-04-20 06:51:42 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d102bd1c-ff98-4aa8-a2f7-fd09d0e442ee\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-20 06:51:44 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: d4dfddfbf,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:d4dfddfbf test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004c3d0d0 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

Apr 20 06:51:45.546: INFO: pod: "test-deployment-d4dfddfbf-52tff":
&Pod{ObjectMeta:{test-deployment-d4dfddfbf-52tff test-deployment-d4dfddfbf- deployment-8871  a70e58d1-14c2-47c0-8157-6add5c0f1231 32066 0 2022-04-20 06:51:42 +0000 UTC 2022-04-20 06:51:46 +0000 UTC 0xc001c40148 map[pod-template-hash:d4dfddfbf test-deployment-static:true] map[cni.projectcalico.org/podIP:10.233.1.97/32 cni.projectcalico.org/podIPs:10.233.1.97/32] [{apps/v1 ReplicaSet test-deployment-d4dfddfbf cc0d9ac2-6f5a-4605-ba57-2be5adf10531 0xc001c40277 0xc001c40278}] []  [{kube-controller-manager Update v1 2022-04-20 06:51:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc0d9ac2-6f5a-4605-ba57-2be5adf10531\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-04-20 06:51:43 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-04-20 06:51:44 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.1.97\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fv4wd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fv4wd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-07idr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:51:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:51:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:51:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:51:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.118.168,PodIP:10.233.1.97,StartTime:2022-04-20 06:51:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-20 06:51:43 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:containerd://ab4e4c3c0fcc57f8164683bf8dfdfda9f586d78522a6c6e6dc18624d09deeb34,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.1.97,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Apr 20 06:51:45.547: INFO: pod: "test-deployment-d4dfddfbf-n97qg":
&Pod{ObjectMeta:{test-deployment-d4dfddfbf-n97qg test-deployment-d4dfddfbf- deployment-8871  eb271591-8ee2-4135-a73d-ae6cc8380bf5 32065 0 2022-04-20 06:51:44 +0000 UTC 2022-04-20 06:51:46 +0000 UTC 0xc001c40470 map[pod-template-hash:d4dfddfbf test-deployment-static:true] map[cni.projectcalico.org/podIP:10.233.2.185/32 cni.projectcalico.org/podIPs:10.233.2.185/32] [{apps/v1 ReplicaSet test-deployment-d4dfddfbf cc0d9ac2-6f5a-4605-ba57-2be5adf10531 0xc001c404c7 0xc001c404c8}] []  [{calico Update v1 2022-04-20 06:51:44 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-04-20 06:51:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc0d9ac2-6f5a-4605-ba57-2be5adf10531\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-04-20 06:51:45 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.2.185\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2dncc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2dncc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-wriki,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:51:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:51:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:51:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:51:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.99.219,PodIP:10.233.2.185,StartTime:2022-04-20 06:51:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-20 06:51:45 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:containerd://4d651da5f11be294a70a3ab9ca9422f47d71f148aaa4d65e660e638c2497950b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.2.185,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:51:45.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8871" for this suite.

• [SLOW TEST:5.628 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","total":346,"completed":266,"skipped":4890,"failed":0}
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:51:45.556: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:51:56.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6608" for this suite.

• [SLOW TEST:11.082 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":346,"completed":267,"skipped":4893,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should validate Replicaset Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:51:56.639: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should validate Replicaset Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create a Replicaset
STEP: Verify that the required pods have come up.
Apr 20 06:51:56.694: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 20 06:52:01.701: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: Getting /status
Apr 20 06:52:01.705: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status
Apr 20 06:52:01.716: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated
Apr 20 06:52:01.719: INFO: Observed &ReplicaSet event: ADDED
Apr 20 06:52:01.720: INFO: Observed &ReplicaSet event: MODIFIED
Apr 20 06:52:01.720: INFO: Observed &ReplicaSet event: MODIFIED
Apr 20 06:52:01.720: INFO: Observed &ReplicaSet event: MODIFIED
Apr 20 06:52:01.720: INFO: Found replicaset test-rs in namespace replicaset-4937 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 20 06:52:01.720: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status
Apr 20 06:52:01.720: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Apr 20 06:52:01.737: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched
Apr 20 06:52:01.739: INFO: Observed &ReplicaSet event: ADDED
Apr 20 06:52:01.740: INFO: Observed &ReplicaSet event: MODIFIED
Apr 20 06:52:01.740: INFO: Observed &ReplicaSet event: MODIFIED
Apr 20 06:52:01.740: INFO: Observed &ReplicaSet event: MODIFIED
Apr 20 06:52:01.740: INFO: Observed replicaset test-rs in namespace replicaset-4937 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 20 06:52:01.740: INFO: Observed &ReplicaSet event: MODIFIED
Apr 20 06:52:01.740: INFO: Found replicaset test-rs in namespace replicaset-4937 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Apr 20 06:52:01.740: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:52:01.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4937" for this suite.

• [SLOW TEST:5.118 seconds]
[sig-apps] ReplicaSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","total":346,"completed":268,"skipped":4922,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should verify changes to a daemon set status [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:52:01.758: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:142
[It] should verify changes to a daemon set status [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 20 06:52:01.926: INFO: Number of nodes with available pods: 0
Apr 20 06:52:01.926: INFO: Node node22-07idr is running more than one daemon pod
Apr 20 06:52:02.933: INFO: Number of nodes with available pods: 0
Apr 20 06:52:02.933: INFO: Node node22-07idr is running more than one daemon pod
Apr 20 06:52:03.935: INFO: Number of nodes with available pods: 2
Apr 20 06:52:03.935: INFO: Node node22-07idr is running more than one daemon pod
Apr 20 06:52:04.936: INFO: Number of nodes with available pods: 3
Apr 20 06:52:04.936: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Getting /status
Apr 20 06:52:04.940: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status
Apr 20 06:52:04.959: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated
Apr 20 06:52:04.960: INFO: Observed &DaemonSet event: ADDED
Apr 20 06:52:04.960: INFO: Observed &DaemonSet event: MODIFIED
Apr 20 06:52:04.960: INFO: Observed &DaemonSet event: MODIFIED
Apr 20 06:52:04.961: INFO: Observed &DaemonSet event: MODIFIED
Apr 20 06:52:04.961: INFO: Observed &DaemonSet event: MODIFIED
Apr 20 06:52:04.961: INFO: Observed &DaemonSet event: MODIFIED
Apr 20 06:52:04.961: INFO: Found daemon set daemon-set in namespace daemonsets-6902 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 20 06:52:04.961: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status
STEP: watching for the daemon set status to be patched
Apr 20 06:52:04.968: INFO: Observed &DaemonSet event: ADDED
Apr 20 06:52:04.968: INFO: Observed &DaemonSet event: MODIFIED
Apr 20 06:52:04.968: INFO: Observed &DaemonSet event: MODIFIED
Apr 20 06:52:04.968: INFO: Observed &DaemonSet event: MODIFIED
Apr 20 06:52:04.969: INFO: Observed &DaemonSet event: MODIFIED
Apr 20 06:52:04.969: INFO: Observed &DaemonSet event: MODIFIED
Apr 20 06:52:04.969: INFO: Observed daemon set daemon-set in namespace daemonsets-6902 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 20 06:52:04.969: INFO: Observed &DaemonSet event: MODIFIED
Apr 20 06:52:04.969: INFO: Found daemon set daemon-set in namespace daemonsets-6902 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Apr 20 06:52:04.969: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:108
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6902, will wait for the garbage collector to delete the pods
Apr 20 06:52:05.034: INFO: Deleting DaemonSet.extensions daemon-set took: 7.192692ms
Apr 20 06:52:05.134: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.553769ms
Apr 20 06:52:07.338: INFO: Number of nodes with available pods: 0
Apr 20 06:52:07.338: INFO: Number of running nodes: 0, number of available pods: 0
Apr 20 06:52:07.341: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"32334"},"items":null}

Apr 20 06:52:07.343: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"32334"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:52:07.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6902" for this suite.

• [SLOW TEST:5.606 seconds]
[sig-apps] Daemon set [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","total":346,"completed":269,"skipped":4930,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:52:07.365: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:52:09.410: INFO: Deleting pod "var-expansion-398a4954-b60e-46c8-8382-2a4e3fb77fa9" in namespace "var-expansion-2887"
Apr 20 06:52:09.419: INFO: Wait up to 5m0s for pod "var-expansion-398a4954-b60e-46c8-8382-2a4e3fb77fa9" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:52:13.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2887" for this suite.

• [SLOW TEST:6.071 seconds]
[sig-node] Variable Expansion
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","total":346,"completed":270,"skipped":4941,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected combined
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:52:13.438: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-projected-all-test-volume-ced02fae-d1ab-42b5-b456-2c4c239005a7
STEP: Creating secret with name secret-projected-all-test-volume-5f281164-ef4e-4570-81c5-bb6b9c0ef4f7
STEP: Creating a pod to test Check all projections for projected volume plugin
Apr 20 06:52:13.483: INFO: Waiting up to 5m0s for pod "projected-volume-51ace89e-8db2-4a61-b85c-6342dd03166e" in namespace "projected-9429" to be "Succeeded or Failed"
Apr 20 06:52:13.484: INFO: Pod "projected-volume-51ace89e-8db2-4a61-b85c-6342dd03166e": Phase="Pending", Reason="", readiness=false. Elapsed: 1.842601ms
Apr 20 06:52:15.490: INFO: Pod "projected-volume-51ace89e-8db2-4a61-b85c-6342dd03166e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007816404s
STEP: Saw pod success
Apr 20 06:52:15.490: INFO: Pod "projected-volume-51ace89e-8db2-4a61-b85c-6342dd03166e" satisfied condition "Succeeded or Failed"
Apr 20 06:52:15.493: INFO: Trying to get logs from node node22-wriki pod projected-volume-51ace89e-8db2-4a61-b85c-6342dd03166e container projected-all-volume-test: <nil>
STEP: delete the pod
Apr 20 06:52:15.518: INFO: Waiting for pod projected-volume-51ace89e-8db2-4a61-b85c-6342dd03166e to disappear
Apr 20 06:52:15.520: INFO: Pod projected-volume-51ace89e-8db2-4a61-b85c-6342dd03166e no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:52:15.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9429" for this suite.
•{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":346,"completed":271,"skipped":4953,"failed":0}
S
------------------------------
[sig-node] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:52:15.532: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:54
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod liveness-ddc12830-7d18-4404-9a7a-8dd901a20758 in namespace container-probe-1005
Apr 20 06:52:17.588: INFO: Started pod liveness-ddc12830-7d18-4404-9a7a-8dd901a20758 in namespace container-probe-1005
STEP: checking the pod's current state and verifying that restartCount is present
Apr 20 06:52:17.590: INFO: Initial restart count of pod liveness-ddc12830-7d18-4404-9a7a-8dd901a20758 is 0
Apr 20 06:52:37.644: INFO: Restart count of pod container-probe-1005/liveness-ddc12830-7d18-4404-9a7a-8dd901a20758 is now 1 (20.053833982s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:52:37.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1005" for this suite.

• [SLOW TEST:22.134 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":346,"completed":272,"skipped":4954,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:52:37.671: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Apr 20 06:52:37.719: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9610  84500eea-611a-442f-82d9-e5cc1a4ef38b 32566 0 2022-04-20 06:52:37 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-04-20 06:52:37 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 20 06:52:37.719: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9610  84500eea-611a-442f-82d9-e5cc1a4ef38b 32566 0 2022-04-20 06:52:37 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-04-20 06:52:37 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Apr 20 06:52:47.728: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9610  84500eea-611a-442f-82d9-e5cc1a4ef38b 32610 0 2022-04-20 06:52:37 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-04-20 06:52:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 20 06:52:47.728: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9610  84500eea-611a-442f-82d9-e5cc1a4ef38b 32610 0 2022-04-20 06:52:37 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-04-20 06:52:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Apr 20 06:52:57.740: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9610  84500eea-611a-442f-82d9-e5cc1a4ef38b 32641 0 2022-04-20 06:52:37 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-04-20 06:52:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 20 06:52:57.741: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9610  84500eea-611a-442f-82d9-e5cc1a4ef38b 32641 0 2022-04-20 06:52:37 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-04-20 06:52:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Apr 20 06:53:07.750: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9610  84500eea-611a-442f-82d9-e5cc1a4ef38b 32673 0 2022-04-20 06:52:37 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-04-20 06:52:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 20 06:53:07.750: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9610  84500eea-611a-442f-82d9-e5cc1a4ef38b 32673 0 2022-04-20 06:52:37 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-04-20 06:52:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Apr 20 06:53:17.758: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9610  537c9715-0968-40e8-8d46-5b464507e5ef 32706 0 2022-04-20 06:53:17 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-04-20 06:53:17 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 20 06:53:17.759: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9610  537c9715-0968-40e8-8d46-5b464507e5ef 32706 0 2022-04-20 06:53:17 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-04-20 06:53:17 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Apr 20 06:53:27.771: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9610  537c9715-0968-40e8-8d46-5b464507e5ef 32744 0 2022-04-20 06:53:17 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-04-20 06:53:17 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 20 06:53:27.771: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9610  537c9715-0968-40e8-8d46-5b464507e5ef 32744 0 2022-04-20 06:53:17 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-04-20 06:53:17 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:53:37.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9610" for this suite.

• [SLOW TEST:60.116 seconds]
[sig-api-machinery] Watchers
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":346,"completed":273,"skipped":4959,"failed":0}
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:53:37.788: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr 20 06:53:37.829: INFO: Waiting up to 5m0s for pod "downwardapi-volume-686f3199-c418-42d5-b10a-96619dc8b9be" in namespace "downward-api-1695" to be "Succeeded or Failed"
Apr 20 06:53:37.832: INFO: Pod "downwardapi-volume-686f3199-c418-42d5-b10a-96619dc8b9be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.921284ms
Apr 20 06:53:39.843: INFO: Pod "downwardapi-volume-686f3199-c418-42d5-b10a-96619dc8b9be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014476813s
STEP: Saw pod success
Apr 20 06:53:39.843: INFO: Pod "downwardapi-volume-686f3199-c418-42d5-b10a-96619dc8b9be" satisfied condition "Succeeded or Failed"
Apr 20 06:53:39.846: INFO: Trying to get logs from node node22-wriki pod downwardapi-volume-686f3199-c418-42d5-b10a-96619dc8b9be container client-container: <nil>
STEP: delete the pod
Apr 20 06:53:39.865: INFO: Waiting for pod downwardapi-volume-686f3199-c418-42d5-b10a-96619dc8b9be to disappear
Apr 20 06:53:39.869: INFO: Pod downwardapi-volume-686f3199-c418-42d5-b10a-96619dc8b9be no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:53:39.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1695" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":346,"completed":274,"skipped":4959,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should support CronJob API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:53:39.876: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support CronJob API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a cronjob
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Apr 20 06:53:39.919: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Apr 20 06:53:39.922: INFO: starting watch
STEP: patching
STEP: updating
Apr 20 06:53:39.944: INFO: waiting for watch events with expected annotations
Apr 20 06:53:39.944: INFO: saw patched and updated annotations
STEP: patching /status
STEP: updating /status
STEP: get /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:53:39.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-262" for this suite.
•{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","total":346,"completed":275,"skipped":4979,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:53:39.986: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-aab6f615-fe85-42bf-9bbe-06609171ce2a
STEP: Creating a pod to test consume secrets
Apr 20 06:53:40.019: INFO: Waiting up to 5m0s for pod "pod-secrets-dfcd2607-a265-4592-ad1d-4d1cbf5aa66c" in namespace "secrets-5392" to be "Succeeded or Failed"
Apr 20 06:53:40.022: INFO: Pod "pod-secrets-dfcd2607-a265-4592-ad1d-4d1cbf5aa66c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.674097ms
Apr 20 06:53:42.027: INFO: Pod "pod-secrets-dfcd2607-a265-4592-ad1d-4d1cbf5aa66c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007498992s
STEP: Saw pod success
Apr 20 06:53:42.027: INFO: Pod "pod-secrets-dfcd2607-a265-4592-ad1d-4d1cbf5aa66c" satisfied condition "Succeeded or Failed"
Apr 20 06:53:42.029: INFO: Trying to get logs from node node22-wriki pod pod-secrets-dfcd2607-a265-4592-ad1d-4d1cbf5aa66c container secret-volume-test: <nil>
STEP: delete the pod
Apr 20 06:53:42.043: INFO: Waiting for pod pod-secrets-dfcd2607-a265-4592-ad1d-4d1cbf5aa66c to disappear
Apr 20 06:53:42.045: INFO: Pod pod-secrets-dfcd2607-a265-4592-ad1d-4d1cbf5aa66c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:53:42.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5392" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":276,"skipped":4995,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:53:42.052: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:54
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod liveness-10aafa2d-57d9-40a0-b103-0261bdbc50dd in namespace container-probe-4353
Apr 20 06:53:44.106: INFO: Started pod liveness-10aafa2d-57d9-40a0-b103-0261bdbc50dd in namespace container-probe-4353
STEP: checking the pod's current state and verifying that restartCount is present
Apr 20 06:53:44.109: INFO: Initial restart count of pod liveness-10aafa2d-57d9-40a0-b103-0261bdbc50dd is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:57:44.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4353" for this suite.

• [SLOW TEST:242.840 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","total":346,"completed":277,"skipped":5013,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] DisruptionController 
  should observe PodDisruptionBudget status updated [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:57:44.894: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:69
[It] should observe PodDisruptionBudget status updated [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Waiting for the pdb to be processed
STEP: Waiting for all pods to be running
Apr 20 06:57:46.987: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:57:48.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-4736" for this suite.
•{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","total":346,"completed":278,"skipped":5023,"failed":0}
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:57:49.011: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating Pod
STEP: Reading file content from the nginx-container
Apr 20 06:57:51.059: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-7855 PodName:pod-sharedvolume-687d26d8-a342-456d-9a4d-f1f682d6df7c ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 06:57:51.059: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 06:57:51.122: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:57:51.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7855" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":346,"completed":279,"skipped":5026,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:57:51.134: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:142
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:57:51.181: INFO: Create a RollingUpdate DaemonSet
Apr 20 06:57:51.185: INFO: Check that daemon pods launch on every node of the cluster
Apr 20 06:57:51.192: INFO: Number of nodes with available pods: 0
Apr 20 06:57:51.192: INFO: Node node22-07idr is running more than one daemon pod
Apr 20 06:57:52.200: INFO: Number of nodes with available pods: 2
Apr 20 06:57:52.200: INFO: Node node22-07idr is running more than one daemon pod
Apr 20 06:57:53.199: INFO: Number of nodes with available pods: 3
Apr 20 06:57:53.200: INFO: Number of running nodes: 3, number of available pods: 3
Apr 20 06:57:53.200: INFO: Update the DaemonSet to trigger a rollout
Apr 20 06:57:53.207: INFO: Updating DaemonSet daemon-set
Apr 20 06:57:55.220: INFO: Roll back the DaemonSet before rollout is complete
Apr 20 06:57:55.228: INFO: Updating DaemonSet daemon-set
Apr 20 06:57:55.228: INFO: Make sure DaemonSet rollback is complete
Apr 20 06:57:55.231: INFO: Wrong image for pod: daemon-set-z2549. Expected: k8s.gcr.io/e2e-test-images/httpd:2.4.38-1, got: foo:non-existent.
Apr 20 06:57:55.231: INFO: Pod daemon-set-z2549 is not available
Apr 20 06:58:01.241: INFO: Pod daemon-set-pg97t is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:108
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7005, will wait for the garbage collector to delete the pods
Apr 20 06:58:01.314: INFO: Deleting DaemonSet.extensions daemon-set took: 7.462112ms
Apr 20 06:58:01.414: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.51172ms
Apr 20 06:58:03.118: INFO: Number of nodes with available pods: 0
Apr 20 06:58:03.118: INFO: Number of running nodes: 0, number of available pods: 0
Apr 20 06:58:03.120: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"33947"},"items":null}

Apr 20 06:58:03.123: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"33947"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:58:03.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7005" for this suite.

• [SLOW TEST:12.012 seconds]
[sig-apps] Daemon set [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":346,"completed":280,"skipped":5039,"failed":0}
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:58:03.146: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-map-f73a0b04-87c7-43dc-93fe-af77c7c2bcb4
STEP: Creating a pod to test consume secrets
Apr 20 06:58:03.207: INFO: Waiting up to 5m0s for pod "pod-secrets-d666d130-521b-476a-b06b-d0d16f6bf48e" in namespace "secrets-634" to be "Succeeded or Failed"
Apr 20 06:58:03.209: INFO: Pod "pod-secrets-d666d130-521b-476a-b06b-d0d16f6bf48e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.142236ms
Apr 20 06:58:05.216: INFO: Pod "pod-secrets-d666d130-521b-476a-b06b-d0d16f6bf48e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009245507s
STEP: Saw pod success
Apr 20 06:58:05.216: INFO: Pod "pod-secrets-d666d130-521b-476a-b06b-d0d16f6bf48e" satisfied condition "Succeeded or Failed"
Apr 20 06:58:05.218: INFO: Trying to get logs from node node22-wriki pod pod-secrets-d666d130-521b-476a-b06b-d0d16f6bf48e container secret-volume-test: <nil>
STEP: delete the pod
Apr 20 06:58:05.254: INFO: Waiting for pod pod-secrets-d666d130-521b-476a-b06b-d0d16f6bf48e to disappear
Apr 20 06:58:05.256: INFO: Pod pod-secrets-d666d130-521b-476a-b06b-d0d16f6bf48e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:58:05.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-634" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":281,"skipped":5045,"failed":0}
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:58:05.264: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating the pod
Apr 20 06:58:05.306: INFO: The status of Pod annotationupdateb48ba688-f754-4327-9e23-2eeb17d8905d is Pending, waiting for it to be Running (with Ready = true)
Apr 20 06:58:07.311: INFO: The status of Pod annotationupdateb48ba688-f754-4327-9e23-2eeb17d8905d is Running (Ready = true)
Apr 20 06:58:07.830: INFO: Successfully updated pod "annotationupdateb48ba688-f754-4327-9e23-2eeb17d8905d"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:58:11.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-131" for this suite.

• [SLOW TEST:6.596 seconds]
[sig-storage] Projected downwardAPI
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":346,"completed":282,"skipped":5047,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:58:11.860: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Apr 20 06:58:11.893: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering the sample API server.
Apr 20 06:58:12.495: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Apr 20 06:58:14.537: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034692, loc:(*time.Location)(0xa09bc80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034692, loc:(*time.Location)(0xa09bc80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034692, loc:(*time.Location)(0xa09bc80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034692, loc:(*time.Location)(0xa09bc80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-64f6b9dc99\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 20 06:58:16.541: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034692, loc:(*time.Location)(0xa09bc80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034692, loc:(*time.Location)(0xa09bc80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034692, loc:(*time.Location)(0xa09bc80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034692, loc:(*time.Location)(0xa09bc80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-64f6b9dc99\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 20 06:58:18.544: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034692, loc:(*time.Location)(0xa09bc80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034692, loc:(*time.Location)(0xa09bc80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034692, loc:(*time.Location)(0xa09bc80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034692, loc:(*time.Location)(0xa09bc80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-64f6b9dc99\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 20 06:58:20.545: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034692, loc:(*time.Location)(0xa09bc80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034692, loc:(*time.Location)(0xa09bc80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034692, loc:(*time.Location)(0xa09bc80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034692, loc:(*time.Location)(0xa09bc80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-64f6b9dc99\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 20 06:58:24.977: INFO: Waited 2.428036195s for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}'
STEP: List APIServices
Apr 20 06:58:25.055: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:58:25.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-4661" for this suite.

• [SLOW TEST:14.106 seconds]
[sig-api-machinery] Aggregator
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","total":346,"completed":283,"skipped":5091,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:58:25.967: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0420 06:58:27.033763      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr 20 06:58:27.033: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:58:27.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9335" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":346,"completed":284,"skipped":5115,"failed":0}
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:58:27.042: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:90
Apr 20 06:58:27.073: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 20 06:58:27.077: INFO: Waiting for terminating namespaces to be deleted...
Apr 20 06:58:27.079: INFO: 
Logging pods the apiserver thinks is on node node22-07idr before test
Apr 20 06:58:27.083: INFO: canal-7z4s7 from kube-system started at 2022-04-20 05:37:05 +0000 UTC (2 container statuses recorded)
Apr 20 06:58:27.083: INFO: 	Container calico-node ready: true, restart count 0
Apr 20 06:58:27.083: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 20 06:58:27.083: INFO: konnectivity-agent-z8v6h from kube-system started at 2022-04-20 05:37:24 +0000 UTC (1 container statuses recorded)
Apr 20 06:58:27.083: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 20 06:58:27.083: INFO: sonobuoy-e2e-job-14e586816b6a497d from sonobuoy started at 2022-04-20 05:49:38 +0000 UTC (2 container statuses recorded)
Apr 20 06:58:27.083: INFO: 	Container e2e ready: true, restart count 0
Apr 20 06:58:27.083: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 20 06:58:27.083: INFO: sonobuoy-systemd-logs-daemon-set-cdcdd281c10f40dc-vvhct from sonobuoy started at 2022-04-20 05:49:38 +0000 UTC (2 container statuses recorded)
Apr 20 06:58:27.083: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 20 06:58:27.083: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 20 06:58:27.083: INFO: 
Logging pods the apiserver thinks is on node node22-hwh1v before test
Apr 20 06:58:27.086: INFO: calico-kube-controllers-5544f8d8d9-2pr5d from kube-system started at 2022-04-20 05:37:23 +0000 UTC (1 container statuses recorded)
Apr 20 06:58:27.086: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 20 06:58:27.086: INFO: canal-xrqg4 from kube-system started at 2022-04-20 05:37:04 +0000 UTC (2 container statuses recorded)
Apr 20 06:58:27.086: INFO: 	Container calico-node ready: true, restart count 0
Apr 20 06:58:27.086: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 20 06:58:27.086: INFO: coredns-748f75f5fb-2n9dt from kube-system started at 2022-04-20 05:37:23 +0000 UTC (1 container statuses recorded)
Apr 20 06:58:27.086: INFO: 	Container coredns ready: true, restart count 0
Apr 20 06:58:27.086: INFO: coredns-748f75f5fb-8sfr7 from kube-system started at 2022-04-20 05:37:23 +0000 UTC (1 container statuses recorded)
Apr 20 06:58:27.086: INFO: 	Container coredns ready: true, restart count 0
Apr 20 06:58:27.086: INFO: konnectivity-agent-9q5dq from kube-system started at 2022-04-20 05:37:23 +0000 UTC (1 container statuses recorded)
Apr 20 06:58:27.086: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 20 06:58:27.086: INFO: sonobuoy-systemd-logs-daemon-set-cdcdd281c10f40dc-dc45f from sonobuoy started at 2022-04-20 05:49:38 +0000 UTC (2 container statuses recorded)
Apr 20 06:58:27.087: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 20 06:58:27.087: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 20 06:58:27.087: INFO: 
Logging pods the apiserver thinks is on node node22-wriki before test
Apr 20 06:58:27.090: INFO: canal-r5jz2 from kube-system started at 2022-04-20 05:37:06 +0000 UTC (2 container statuses recorded)
Apr 20 06:58:27.090: INFO: 	Container calico-node ready: true, restart count 0
Apr 20 06:58:27.090: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 20 06:58:27.090: INFO: konnectivity-agent-vgl4v from kube-system started at 2022-04-20 06:27:48 +0000 UTC (1 container statuses recorded)
Apr 20 06:58:27.090: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 20 06:58:27.090: INFO: sonobuoy from sonobuoy started at 2022-04-20 05:49:32 +0000 UTC (1 container statuses recorded)
Apr 20 06:58:27.090: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 20 06:58:27.090: INFO: sonobuoy-systemd-logs-daemon-set-cdcdd281c10f40dc-48vdz from sonobuoy started at 2022-04-20 05:49:39 +0000 UTC (2 container statuses recorded)
Apr 20 06:58:27.090: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 20 06:58:27.090: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-fc7fe12f-8b03-4d61-8053-e11fdef259cf 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-fc7fe12f-8b03-4d61-8053-e11fdef259cf off the node node22-wriki
STEP: verifying the node doesn't have the label kubernetes.io/e2e-fc7fe12f-8b03-4d61-8053-e11fdef259cf
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:58:31.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3953" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":346,"completed":285,"skipped":5116,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:58:31.184: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: validating cluster-info
Apr 20 06:58:31.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-9455 cluster-info'
Apr 20 06:58:31.329: INFO: stderr: ""
Apr 20 06:58:31.329: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:58:31.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9455" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","total":346,"completed":286,"skipped":5221,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:58:31.338: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr 20 06:58:31.372: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e0d53aef-8fe0-4812-91be-6a7635fb08cf" in namespace "downward-api-6480" to be "Succeeded or Failed"
Apr 20 06:58:31.375: INFO: Pod "downwardapi-volume-e0d53aef-8fe0-4812-91be-6a7635fb08cf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.421295ms
Apr 20 06:58:33.380: INFO: Pod "downwardapi-volume-e0d53aef-8fe0-4812-91be-6a7635fb08cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007517506s
STEP: Saw pod success
Apr 20 06:58:33.380: INFO: Pod "downwardapi-volume-e0d53aef-8fe0-4812-91be-6a7635fb08cf" satisfied condition "Succeeded or Failed"
Apr 20 06:58:33.382: INFO: Trying to get logs from node node22-hwh1v pod downwardapi-volume-e0d53aef-8fe0-4812-91be-6a7635fb08cf container client-container: <nil>
STEP: delete the pod
Apr 20 06:58:33.407: INFO: Waiting for pod downwardapi-volume-e0d53aef-8fe0-4812-91be-6a7635fb08cf to disappear
Apr 20 06:58:33.409: INFO: Pod downwardapi-volume-e0d53aef-8fe0-4812-91be-6a7635fb08cf no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:58:33.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6480" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":287,"skipped":5236,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:58:33.416: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9801.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9801.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9801.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9801.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 20 06:58:35.480: INFO: DNS probes using dns-test-9c328c73-0ae6-4a6f-8c5f-3770aeefa19c succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9801.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9801.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9801.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9801.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 20 06:58:37.526: INFO: File wheezy_udp@dns-test-service-3.dns-9801.svc.cluster.local from pod  dns-9801/dns-test-6b7d153a-1fe7-484f-95da-f7372e49396b contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 20 06:58:37.531: INFO: File jessie_udp@dns-test-service-3.dns-9801.svc.cluster.local from pod  dns-9801/dns-test-6b7d153a-1fe7-484f-95da-f7372e49396b contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 20 06:58:37.531: INFO: Lookups using dns-9801/dns-test-6b7d153a-1fe7-484f-95da-f7372e49396b failed for: [wheezy_udp@dns-test-service-3.dns-9801.svc.cluster.local jessie_udp@dns-test-service-3.dns-9801.svc.cluster.local]

Apr 20 06:58:42.538: INFO: DNS probes using dns-test-6b7d153a-1fe7-484f-95da-f7372e49396b succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9801.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-9801.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9801.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-9801.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 20 06:58:44.630: INFO: DNS probes using dns-test-2acd3650-0a78-455a-b855-af9015d012aa succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:58:44.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9801" for this suite.

• [SLOW TEST:11.254 seconds]
[sig-network] DNS
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":346,"completed":288,"skipped":5312,"failed":0}
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be immutable if `immutable` field is set [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:58:44.670: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be immutable if `immutable` field is set [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:58:44.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7375" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","total":346,"completed":289,"skipped":5318,"failed":0}
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:58:44.732: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] deployment should support rollover [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 06:58:44.767: INFO: Pod name rollover-pod: Found 0 pods out of 1
Apr 20 06:58:49.777: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 20 06:58:49.777: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr 20 06:58:51.781: INFO: Creating deployment "test-rollover-deployment"
Apr 20 06:58:51.794: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr 20 06:58:53.801: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr 20 06:58:53.805: INFO: Ensure that both replica sets have 1 created replica
Apr 20 06:58:53.809: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr 20 06:58:53.815: INFO: Updating deployment test-rollover-deployment
Apr 20 06:58:53.815: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr 20 06:58:55.827: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr 20 06:58:55.832: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr 20 06:58:55.836: INFO: all replica sets need to contain the pod-template-hash label
Apr 20 06:58:55.836: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034731, loc:(*time.Location)(0xa09bc80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034731, loc:(*time.Location)(0xa09bc80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034735, loc:(*time.Location)(0xa09bc80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034731, loc:(*time.Location)(0xa09bc80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-98c5f4599\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 20 06:58:57.844: INFO: all replica sets need to contain the pod-template-hash label
Apr 20 06:58:57.844: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034731, loc:(*time.Location)(0xa09bc80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034731, loc:(*time.Location)(0xa09bc80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034735, loc:(*time.Location)(0xa09bc80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034731, loc:(*time.Location)(0xa09bc80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-98c5f4599\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 20 06:58:59.844: INFO: all replica sets need to contain the pod-template-hash label
Apr 20 06:58:59.844: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034731, loc:(*time.Location)(0xa09bc80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034731, loc:(*time.Location)(0xa09bc80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034735, loc:(*time.Location)(0xa09bc80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034731, loc:(*time.Location)(0xa09bc80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-98c5f4599\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 20 06:59:01.844: INFO: all replica sets need to contain the pod-template-hash label
Apr 20 06:59:01.845: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034731, loc:(*time.Location)(0xa09bc80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034731, loc:(*time.Location)(0xa09bc80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034735, loc:(*time.Location)(0xa09bc80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034731, loc:(*time.Location)(0xa09bc80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-98c5f4599\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 20 06:59:03.847: INFO: all replica sets need to contain the pod-template-hash label
Apr 20 06:59:03.847: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034731, loc:(*time.Location)(0xa09bc80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034731, loc:(*time.Location)(0xa09bc80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034735, loc:(*time.Location)(0xa09bc80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63786034731, loc:(*time.Location)(0xa09bc80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-98c5f4599\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 20 06:59:05.846: INFO: 
Apr 20 06:59:05.846: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Apr 20 06:59:05.852: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-2095  a31b81b2-5e08-4a7f-839f-ddc094fa7ee3 34696 2 2022-04-20 06:58:51 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-04-20 06:58:53 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-20 06:59:05 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.32 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004c424d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-04-20 06:58:51 +0000 UTC,LastTransitionTime:2022-04-20 06:58:51 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-98c5f4599" has successfully progressed.,LastUpdateTime:2022-04-20 06:59:05 +0000 UTC,LastTransitionTime:2022-04-20 06:58:51 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 20 06:59:05.854: INFO: New ReplicaSet "test-rollover-deployment-98c5f4599" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-98c5f4599  deployment-2095  925081b7-3a31-478b-b0ab-f8433be27bf6 34687 2 2022-04-20 06:58:53 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:98c5f4599] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment a31b81b2-5e08-4a7f-839f-ddc094fa7ee3 0xc004c42aa0 0xc004c42aa1}] []  [{kube-controller-manager Update apps/v1 2022-04-20 06:58:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a31b81b2-5e08-4a7f-839f-ddc094fa7ee3\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-20 06:59:05 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 98c5f4599,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:98c5f4599] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.32 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004c42b38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 20 06:59:05.854: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr 20 06:59:05.855: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-2095  8c65befa-fa43-49bd-853b-072ba6a23b48 34695 2 2022-04-20 06:58:44 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment a31b81b2-5e08-4a7f-839f-ddc094fa7ee3 0xc004c42857 0xc004c42858}] []  [{e2e.test Update apps/v1 2022-04-20 06:58:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-20 06:59:05 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a31b81b2-5e08-4a7f-839f-ddc094fa7ee3\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-04-20 06:59:05 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004c42918 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 20 06:59:05.855: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-78bc8b888c  deployment-2095  abd10c3c-4a47-48d2-be83-6da96c5328a4 34637 2 2022-04-20 06:58:51 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:78bc8b888c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment a31b81b2-5e08-4a7f-839f-ddc094fa7ee3 0xc004c42987 0xc004c42988}] []  [{kube-controller-manager Update apps/v1 2022-04-20 06:58:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a31b81b2-5e08-4a7f-839f-ddc094fa7ee3\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-20 06:58:53 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 78bc8b888c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:78bc8b888c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004c42a38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 20 06:59:05.857: INFO: Pod "test-rollover-deployment-98c5f4599-bxz5z" is available:
&Pod{ObjectMeta:{test-rollover-deployment-98c5f4599-bxz5z test-rollover-deployment-98c5f4599- deployment-2095  da024101-b9b9-4e08-9820-32c12c24ed44 34654 0 2022-04-20 06:58:53 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:98c5f4599] map[cni.projectcalico.org/podIP:10.233.0.145/32 cni.projectcalico.org/podIPs:10.233.0.145/32] [{apps/v1 ReplicaSet test-rollover-deployment-98c5f4599 925081b7-3a31-478b-b0ab-f8433be27bf6 0xc004c43080 0xc004c43081}] []  [{kube-controller-manager Update v1 2022-04-20 06:58:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"925081b7-3a31-478b-b0ab-f8433be27bf6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-04-20 06:58:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-04-20 06:58:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.0.145\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ck9kg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.32,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ck9kg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-hwh1v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:58:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:58:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:58:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 06:58:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.125.144,PodIP:10.233.0.145,StartTime:2022-04-20 06:58:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-20 06:58:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.32,ImageID:k8s.gcr.io/e2e-test-images/agnhost@sha256:758db666ac7028534dba72e7e9bb1e57bb81b8196f976f7a5cc351ef8b3529e1,ContainerID:containerd://c32a583a5f7b076e9dccfe83b17fb4b987ea87ff7367de784c6149c87f7b7c1d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.0.145,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:59:05.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2095" for this suite.

• [SLOW TEST:21.133 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":346,"completed":290,"skipped":5323,"failed":0}
SS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:59:05.868: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should release no longer matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Apr 20 06:59:05.931: INFO: Pod name pod-release: Found 0 pods out of 1
Apr 20 06:59:10.939: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:59:10.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1433" for this suite.

• [SLOW TEST:5.130 seconds]
[sig-apps] ReplicationController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":346,"completed":291,"skipped":5325,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:59:11.004: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 20 06:59:11.103: INFO: Waiting up to 5m0s for pod "pod-2edc4e8f-001d-47e5-a593-f79259f12853" in namespace "emptydir-9000" to be "Succeeded or Failed"
Apr 20 06:59:11.110: INFO: Pod "pod-2edc4e8f-001d-47e5-a593-f79259f12853": Phase="Pending", Reason="", readiness=false. Elapsed: 6.118131ms
Apr 20 06:59:13.113: INFO: Pod "pod-2edc4e8f-001d-47e5-a593-f79259f12853": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009436424s
STEP: Saw pod success
Apr 20 06:59:13.113: INFO: Pod "pod-2edc4e8f-001d-47e5-a593-f79259f12853" satisfied condition "Succeeded or Failed"
Apr 20 06:59:13.115: INFO: Trying to get logs from node node22-wriki pod pod-2edc4e8f-001d-47e5-a593-f79259f12853 container test-container: <nil>
STEP: delete the pod
Apr 20 06:59:13.134: INFO: Waiting for pod pod-2edc4e8f-001d-47e5-a593-f79259f12853 to disappear
Apr 20 06:59:13.136: INFO: Pod pod-2edc4e8f-001d-47e5-a593-f79259f12853 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:59:13.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9000" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":292,"skipped":5402,"failed":0}
SS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:59:13.145: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr 20 06:59:15.197: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:59:15.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1806" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":346,"completed":293,"skipped":5404,"failed":0}
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:59:15.217: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:59:15.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5137" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":346,"completed":294,"skipped":5408,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:59:15.263: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-b4a9fea8-c7b2-43fa-90ce-2264be43f7a1
STEP: Creating a pod to test consume configMaps
Apr 20 06:59:15.296: INFO: Waiting up to 5m0s for pod "pod-configmaps-8748a27e-1909-4072-874b-e49a3913b0be" in namespace "configmap-6316" to be "Succeeded or Failed"
Apr 20 06:59:15.298: INFO: Pod "pod-configmaps-8748a27e-1909-4072-874b-e49a3913b0be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.214228ms
Apr 20 06:59:17.303: INFO: Pod "pod-configmaps-8748a27e-1909-4072-874b-e49a3913b0be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007083657s
STEP: Saw pod success
Apr 20 06:59:17.303: INFO: Pod "pod-configmaps-8748a27e-1909-4072-874b-e49a3913b0be" satisfied condition "Succeeded or Failed"
Apr 20 06:59:17.305: INFO: Trying to get logs from node node22-hwh1v pod pod-configmaps-8748a27e-1909-4072-874b-e49a3913b0be container agnhost-container: <nil>
STEP: delete the pod
Apr 20 06:59:17.323: INFO: Waiting for pod pod-configmaps-8748a27e-1909-4072-874b-e49a3913b0be to disappear
Apr 20 06:59:17.325: INFO: Pod pod-configmaps-8748a27e-1909-4072-874b-e49a3913b0be no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:59:17.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6316" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":295,"skipped":5465,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:59:17.335: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:59:23.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-134" for this suite.
STEP: Destroying namespace "nsdeletetest-408" for this suite.
Apr 20 06:59:23.449: INFO: Namespace nsdeletetest-408 was already deleted
STEP: Destroying namespace "nsdeletetest-7365" for this suite.

• [SLOW TEST:6.118 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":346,"completed":296,"skipped":5475,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] PreStop
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:59:23.454: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] PreStop
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:157
[It] should call prestop when killing a pod  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating server pod server in namespace prestop-8686
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-8686
STEP: Deleting pre-stop pod
Apr 20 06:59:32.528: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [sig-node] PreStop
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:59:32.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-8686" for this suite.

• [SLOW TEST:9.100 seconds]
[sig-node] PreStop
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":346,"completed":297,"skipped":5494,"failed":0}
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:59:32.556: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Apr 20 06:59:32.586: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Apr 20 06:59:43.046: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 06:59:45.777: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:59:55.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4390" for this suite.

• [SLOW TEST:22.890 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":346,"completed":298,"skipped":5498,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should test the lifecycle of an Endpoint [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:59:55.448: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should test the lifecycle of an Endpoint [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating an Endpoint
STEP: waiting for available Endpoint
STEP: listing all Endpoints
STEP: updating the Endpoint
STEP: fetching the Endpoint
STEP: patching the Endpoint
STEP: fetching the Endpoint
STEP: deleting the Endpoint by Collection
STEP: waiting for Endpoint deletion
STEP: fetching the Endpoint
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 06:59:55.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3138" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753
•{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","total":346,"completed":299,"skipped":5510,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 06:59:55.516: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:00:06.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6510" for this suite.

• [SLOW TEST:11.094 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":346,"completed":300,"skipped":5517,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  Replicaset should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:00:06.612: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] Replicaset should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota
Apr 20 07:00:06.663: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 20 07:00:11.667: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the replicaset Spec.Replicas was modified
STEP: Patch a scale subresource
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:00:11.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6948" for this suite.

• [SLOW TEST:5.129 seconds]
[sig-apps] ReplicaSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","total":346,"completed":301,"skipped":5525,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:00:11.741: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Apr 20 07:00:11.785: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 07:00:14.536: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:00:25.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9149" for this suite.

• [SLOW TEST:13.484 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":346,"completed":302,"skipped":5534,"failed":0}
SSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:00:25.226: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should provide secure master service  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:00:25.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8990" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":346,"completed":303,"skipped":5537,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:00:25.272: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Update Demo
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:296
[It] should scale a replication controller  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a replication controller
Apr 20 07:00:25.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 create -f -'
Apr 20 07:00:25.438: INFO: stderr: ""
Apr 20 07:00:25.438: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 20 07:00:25.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 20 07:00:25.494: INFO: stderr: ""
Apr 20 07:00:25.494: INFO: stdout: "update-demo-nautilus-5ssnj update-demo-nautilus-prdbp "
Apr 20 07:00:25.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 get pods update-demo-nautilus-5ssnj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 20 07:00:25.551: INFO: stderr: ""
Apr 20 07:00:25.551: INFO: stdout: ""
Apr 20 07:00:25.551: INFO: update-demo-nautilus-5ssnj is created but not running
Apr 20 07:00:30.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 20 07:00:30.609: INFO: stderr: ""
Apr 20 07:00:30.609: INFO: stdout: "update-demo-nautilus-5ssnj update-demo-nautilus-prdbp "
Apr 20 07:00:30.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 get pods update-demo-nautilus-5ssnj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 20 07:00:30.659: INFO: stderr: ""
Apr 20 07:00:30.659: INFO: stdout: "true"
Apr 20 07:00:30.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 get pods update-demo-nautilus-5ssnj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 20 07:00:30.709: INFO: stderr: ""
Apr 20 07:00:30.709: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.4"
Apr 20 07:00:30.709: INFO: validating pod update-demo-nautilus-5ssnj
Apr 20 07:00:30.715: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 20 07:00:30.715: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 20 07:00:30.715: INFO: update-demo-nautilus-5ssnj is verified up and running
Apr 20 07:00:30.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 get pods update-demo-nautilus-prdbp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 20 07:00:30.767: INFO: stderr: ""
Apr 20 07:00:30.767: INFO: stdout: "true"
Apr 20 07:00:30.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 get pods update-demo-nautilus-prdbp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 20 07:00:30.815: INFO: stderr: ""
Apr 20 07:00:30.815: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.4"
Apr 20 07:00:30.815: INFO: validating pod update-demo-nautilus-prdbp
Apr 20 07:00:30.820: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 20 07:00:30.820: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 20 07:00:30.820: INFO: update-demo-nautilus-prdbp is verified up and running
STEP: scaling down the replication controller
Apr 20 07:00:30.822: INFO: scanned /root for discovery docs: <nil>
Apr 20 07:00:30.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Apr 20 07:00:31.900: INFO: stderr: ""
Apr 20 07:00:31.900: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 20 07:00:31.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 20 07:00:31.953: INFO: stderr: ""
Apr 20 07:00:31.953: INFO: stdout: "update-demo-nautilus-5ssnj update-demo-nautilus-prdbp "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr 20 07:00:36.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 20 07:00:37.004: INFO: stderr: ""
Apr 20 07:00:37.004: INFO: stdout: "update-demo-nautilus-5ssnj "
Apr 20 07:00:37.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 get pods update-demo-nautilus-5ssnj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 20 07:00:37.062: INFO: stderr: ""
Apr 20 07:00:37.063: INFO: stdout: "true"
Apr 20 07:00:37.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 get pods update-demo-nautilus-5ssnj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 20 07:00:37.116: INFO: stderr: ""
Apr 20 07:00:37.116: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.4"
Apr 20 07:00:37.116: INFO: validating pod update-demo-nautilus-5ssnj
Apr 20 07:00:37.121: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 20 07:00:37.121: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 20 07:00:37.121: INFO: update-demo-nautilus-5ssnj is verified up and running
STEP: scaling up the replication controller
Apr 20 07:00:37.122: INFO: scanned /root for discovery docs: <nil>
Apr 20 07:00:37.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Apr 20 07:00:38.192: INFO: stderr: ""
Apr 20 07:00:38.192: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 20 07:00:38.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 20 07:00:38.251: INFO: stderr: ""
Apr 20 07:00:38.251: INFO: stdout: "update-demo-nautilus-5ssnj update-demo-nautilus-zfbvk "
Apr 20 07:00:38.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 get pods update-demo-nautilus-5ssnj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 20 07:00:38.300: INFO: stderr: ""
Apr 20 07:00:38.300: INFO: stdout: "true"
Apr 20 07:00:38.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 get pods update-demo-nautilus-5ssnj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 20 07:00:38.348: INFO: stderr: ""
Apr 20 07:00:38.348: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.4"
Apr 20 07:00:38.348: INFO: validating pod update-demo-nautilus-5ssnj
Apr 20 07:00:38.352: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 20 07:00:38.352: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 20 07:00:38.352: INFO: update-demo-nautilus-5ssnj is verified up and running
Apr 20 07:00:38.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 get pods update-demo-nautilus-zfbvk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 20 07:00:38.402: INFO: stderr: ""
Apr 20 07:00:38.402: INFO: stdout: ""
Apr 20 07:00:38.402: INFO: update-demo-nautilus-zfbvk is created but not running
Apr 20 07:00:43.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 20 07:00:43.459: INFO: stderr: ""
Apr 20 07:00:43.459: INFO: stdout: "update-demo-nautilus-5ssnj update-demo-nautilus-zfbvk "
Apr 20 07:00:43.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 get pods update-demo-nautilus-5ssnj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 20 07:00:43.506: INFO: stderr: ""
Apr 20 07:00:43.506: INFO: stdout: "true"
Apr 20 07:00:43.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 get pods update-demo-nautilus-5ssnj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 20 07:00:43.551: INFO: stderr: ""
Apr 20 07:00:43.551: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.4"
Apr 20 07:00:43.551: INFO: validating pod update-demo-nautilus-5ssnj
Apr 20 07:00:43.555: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 20 07:00:43.555: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 20 07:00:43.555: INFO: update-demo-nautilus-5ssnj is verified up and running
Apr 20 07:00:43.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 get pods update-demo-nautilus-zfbvk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 20 07:00:43.604: INFO: stderr: ""
Apr 20 07:00:43.604: INFO: stdout: "true"
Apr 20 07:00:43.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 get pods update-demo-nautilus-zfbvk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 20 07:00:43.659: INFO: stderr: ""
Apr 20 07:00:43.659: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.4"
Apr 20 07:00:43.659: INFO: validating pod update-demo-nautilus-zfbvk
Apr 20 07:00:43.666: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 20 07:00:43.666: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 20 07:00:43.666: INFO: update-demo-nautilus-zfbvk is verified up and running
STEP: using delete to clean up resources
Apr 20 07:00:43.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 delete --grace-period=0 --force -f -'
Apr 20 07:00:43.721: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 20 07:00:43.721: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 20 07:00:43.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 get rc,svc -l name=update-demo --no-headers'
Apr 20 07:00:43.783: INFO: stderr: "No resources found in kubectl-3124 namespace.\n"
Apr 20 07:00:43.783: INFO: stdout: ""
Apr 20 07:00:43.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=kubectl-3124 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 20 07:00:43.837: INFO: stderr: ""
Apr 20 07:00:43.837: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:00:43.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3124" for this suite.

• [SLOW TEST:18.573 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:294
    should scale a replication controller  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":346,"completed":304,"skipped":5549,"failed":0}
SS
------------------------------
[sig-network] EndpointSlice 
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:00:43.845: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/endpointslice.go:49
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:00:43.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-2116" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","total":346,"completed":305,"skipped":5551,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] 
  validates basic preemption works [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:00:43.947: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:90
Apr 20 07:00:43.994: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 20 07:01:44.022: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create pods that use 4/5 of node resources.
Apr 20 07:01:44.039: INFO: Created pod: pod0-0-sched-preemption-low-priority
Apr 20 07:01:44.044: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Apr 20 07:01:44.059: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Apr 20 07:01:44.065: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Apr 20 07:01:44.080: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Apr 20 07:01:44.086: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled.
STEP: Run a high priority pod that has same requirements as that of lower priority pod
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:02:00.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-3590" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:78

• [SLOW TEST:76.220 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","total":346,"completed":306,"skipped":5569,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should support creating EndpointSlice API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:02:00.171: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/endpointslice.go:49
[It] should support creating EndpointSlice API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting /apis
STEP: getting /apis/discovery.k8s.io
STEP: getting /apis/discovery.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Apr 20 07:02:00.226: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Apr 20 07:02:00.229: INFO: starting watch
STEP: patching
STEP: updating
Apr 20 07:02:00.240: INFO: waiting for watch events with expected annotations
Apr 20 07:02:00.240: INFO: saw patched and updated annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:02:00.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-5203" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","total":346,"completed":307,"skipped":5591,"failed":0}
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:02:00.266: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 20 07:02:00.728: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 20 07:02:03.803: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 07:02:03.809: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7828-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:02:07.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6954" for this suite.
STEP: Destroying namespace "webhook-6954-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.092 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":346,"completed":308,"skipped":5594,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:02:07.359: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr 20 07:02:07.458: INFO: Waiting up to 5m0s for pod "downwardapi-volume-67779955-82c2-4114-a61e-b10014237cb5" in namespace "downward-api-293" to be "Succeeded or Failed"
Apr 20 07:02:07.461: INFO: Pod "downwardapi-volume-67779955-82c2-4114-a61e-b10014237cb5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209224ms
Apr 20 07:02:09.467: INFO: Pod "downwardapi-volume-67779955-82c2-4114-a61e-b10014237cb5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00811363s
Apr 20 07:02:11.471: INFO: Pod "downwardapi-volume-67779955-82c2-4114-a61e-b10014237cb5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01183684s
STEP: Saw pod success
Apr 20 07:02:11.471: INFO: Pod "downwardapi-volume-67779955-82c2-4114-a61e-b10014237cb5" satisfied condition "Succeeded or Failed"
Apr 20 07:02:11.473: INFO: Trying to get logs from node node22-wriki pod downwardapi-volume-67779955-82c2-4114-a61e-b10014237cb5 container client-container: <nil>
STEP: delete the pod
Apr 20 07:02:11.505: INFO: Waiting for pod downwardapi-volume-67779955-82c2-4114-a61e-b10014237cb5 to disappear
Apr 20 07:02:11.507: INFO: Pod downwardapi-volume-67779955-82c2-4114-a61e-b10014237cb5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:02:11.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-293" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":346,"completed":309,"skipped":5636,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:02:11.515: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-462c321a-6ea4-4957-b656-059085dcd1e4
STEP: Creating a pod to test consume secrets
Apr 20 07:02:11.596: INFO: Waiting up to 5m0s for pod "pod-secrets-cad115e0-1a7e-408c-a5fe-3930f24d8995" in namespace "secrets-3879" to be "Succeeded or Failed"
Apr 20 07:02:11.598: INFO: Pod "pod-secrets-cad115e0-1a7e-408c-a5fe-3930f24d8995": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010255ms
Apr 20 07:02:13.602: INFO: Pod "pod-secrets-cad115e0-1a7e-408c-a5fe-3930f24d8995": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006522347s
STEP: Saw pod success
Apr 20 07:02:13.602: INFO: Pod "pod-secrets-cad115e0-1a7e-408c-a5fe-3930f24d8995" satisfied condition "Succeeded or Failed"
Apr 20 07:02:13.605: INFO: Trying to get logs from node node22-wriki pod pod-secrets-cad115e0-1a7e-408c-a5fe-3930f24d8995 container secret-volume-test: <nil>
STEP: delete the pod
Apr 20 07:02:13.618: INFO: Waiting for pod pod-secrets-cad115e0-1a7e-408c-a5fe-3930f24d8995 to disappear
Apr 20 07:02:13.621: INFO: Pod pod-secrets-cad115e0-1a7e-408c-a5fe-3930f24d8995 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:02:13.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3879" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":310,"skipped":5671,"failed":0}
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:02:13.629: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] deployment should delete old replica sets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 07:02:13.667: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Apr 20 07:02:18.673: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 20 07:02:18.673: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Apr 20 07:02:18.694: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-8930  5c5a8c44-128a-40ef-8d4b-cce1efb35b99 36247 1 2022-04-20 07:02:18 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  [{e2e.test Update apps/v1 2022-04-20 07:02:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.32 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00323f018 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Apr 20 07:02:18.698: INFO: New ReplicaSet "test-cleanup-deployment-5b4d99b59b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-5b4d99b59b  deployment-8930  0a96c3aa-85a1-471b-a4cb-93ab605f1ec7 36251 1 2022-04-20 07:02:18 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:5b4d99b59b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 5c5a8c44-128a-40ef-8d4b-cce1efb35b99 0xc00323f657 0xc00323f658}] []  [{kube-controller-manager Update apps/v1 2022-04-20 07:02:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5c5a8c44-128a-40ef-8d4b-cce1efb35b99\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 5b4d99b59b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:5b4d99b59b] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.32 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00323f6f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 20 07:02:18.698: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Apr 20 07:02:18.698: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-8930  28693332-c1b9-4a0d-8b2c-e0e7f42c8830 36249 1 2022-04-20 07:02:13 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 5c5a8c44-128a-40ef-8d4b-cce1efb35b99 0xc00323f4f7 0xc00323f4f8}] []  [{e2e.test Update apps/v1 2022-04-20 07:02:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-20 07:02:14 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-04-20 07:02:18 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"5c5a8c44-128a-40ef-8d4b-cce1efb35b99\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00323f5e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 20 07:02:18.702: INFO: Pod "test-cleanup-controller-5rszr" is available:
&Pod{ObjectMeta:{test-cleanup-controller-5rszr test-cleanup-controller- deployment-8930  ca391dae-4f7a-47d9-bf57-bf38795bbba1 36216 0 2022-04-20 07:02:13 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/podIP:10.233.2.211/32 cni.projectcalico.org/podIPs:10.233.2.211/32] [{apps/v1 ReplicaSet test-cleanup-controller 28693332-c1b9-4a0d-8b2c-e0e7f42c8830 0xc00323fbd7 0xc00323fbd8}] []  [{kube-controller-manager Update v1 2022-04-20 07:02:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"28693332-c1b9-4a0d-8b2c-e0e7f42c8830\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-04-20 07:02:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-04-20 07:02:14 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.2.211\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nmzd5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nmzd5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-wriki,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 07:02:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 07:02:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 07:02:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 07:02:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.99.219,PodIP:10.233.2.211,StartTime:2022-04-20 07:02:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-04-20 07:02:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:containerd://2661b90c60e4c2c39f1ce1a4ff42e230001af3764f6f044ce8729cbcd9e03ca2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.2.211,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:02:18.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8930" for this suite.

• [SLOW TEST:5.097 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":346,"completed":311,"skipped":5676,"failed":0}
SSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:02:18.726: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should adopt matching pods on creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Given a Pod with a 'name' label pod-adoption is created
Apr 20 07:02:18.777: INFO: The status of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Apr 20 07:02:20.785: INFO: The status of Pod pod-adoption is Running (Ready = true)
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:02:21.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6678" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":346,"completed":312,"skipped":5679,"failed":0}
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:02:21.813: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 20 07:02:22.204: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 20 07:02:25.226: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Apr 20 07:02:25.248: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:02:25.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1735" for this suite.
STEP: Destroying namespace "webhook-1735-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":346,"completed":313,"skipped":5683,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:02:25.348: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:38
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 07:02:25.387: INFO: The status of Pod busybox-readonly-fs830a8add-26d6-4d26-b9e6-a429025d6a02 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 07:02:27.391: INFO: The status of Pod busybox-readonly-fs830a8add-26d6-4d26-b9e6-a429025d6a02 is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:02:27.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4971" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":314,"skipped":5705,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:02:27.407: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:54
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod test-webserver-6c8890e1-121f-4abc-b86d-5c4f793a02de in namespace container-probe-772
Apr 20 07:02:29.460: INFO: Started pod test-webserver-6c8890e1-121f-4abc-b86d-5c4f793a02de in namespace container-probe-772
STEP: checking the pod's current state and verifying that restartCount is present
Apr 20 07:02:29.464: INFO: Initial restart count of pod test-webserver-6c8890e1-121f-4abc-b86d-5c4f793a02de is 0
Apr 20 07:06:35.549: FAIL: getting pod 
Unexpected error:
    <*errors.StatusError | 0xc002a10b40>: {
        ErrStatus: {
            TypeMeta: {Kind: "", APIVersion: ""},
            ListMeta: {
                SelfLink: "",
                ResourceVersion: "",
                Continue: "",
                RemainingItemCount: nil,
            },
            Status: "Failure",
            Message: "etcdserver: request timed out",
            Reason: "",
            Details: nil,
            Code: 500,
        },
    }
    etcdserver: request timed out
occurred

Full Stack Trace
k8s.io/kubernetes/test/e2e/common/node.RunLivenessTest(0xc00060ba20, 0xc002d46800, 0x0, 0x37e11d6000)
	/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:701 +0xbaa
k8s.io/kubernetes/test/e2e/common/node.glob..func2.9()
	/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:209 +0x165
k8s.io/kubernetes/test/e2e.RunE2ETests(0xc000105800)
	_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e.go:130 +0x36c
k8s.io/kubernetes/test/e2e.TestE2E(0xc000105800)
	_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/e2e_test.go:136 +0x2b
testing.tRunner(0xc000105800, 0x72d3060)
	/usr/local/go/src/testing/testing.go:1193 +0xef
created by testing.(*T).Run
	/usr/local/go/src/testing/testing.go:1238 +0x2b3
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
STEP: Collecting events from namespace "container-probe-772".
STEP: Found 4 events.
Apr 20 07:06:35.562: INFO: At 0001-01-01 00:00:00 +0000 UTC - event for test-webserver-6c8890e1-121f-4abc-b86d-5c4f793a02de: { } Scheduled: Successfully assigned container-probe-772/test-webserver-6c8890e1-121f-4abc-b86d-5c4f793a02de to node22-wriki
Apr 20 07:06:35.562: INFO: At 2022-04-20 07:02:28 +0000 UTC - event for test-webserver-6c8890e1-121f-4abc-b86d-5c4f793a02de: {kubelet node22-wriki} Pulled: Container image "k8s.gcr.io/e2e-test-images/agnhost:2.32" already present on machine
Apr 20 07:06:35.562: INFO: At 2022-04-20 07:02:28 +0000 UTC - event for test-webserver-6c8890e1-121f-4abc-b86d-5c4f793a02de: {kubelet node22-wriki} Created: Created container test-webserver
Apr 20 07:06:35.563: INFO: At 2022-04-20 07:02:28 +0000 UTC - event for test-webserver-6c8890e1-121f-4abc-b86d-5c4f793a02de: {kubelet node22-wriki} Started: Started container test-webserver
Apr 20 07:06:35.589: INFO: POD                                                  NODE          PHASE    GRACE  CONDITIONS
Apr 20 07:06:35.589: INFO: test-webserver-6c8890e1-121f-4abc-b86d-5c4f793a02de  node22-wriki  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-04-20 07:02:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-04-20 07:02:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-04-20 07:02:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-04-20 07:02:27 +0000 UTC  }]
Apr 20 07:06:35.589: INFO: 
Apr 20 07:06:35.610: INFO: 
Logging node info for node node22-07idr
Apr 20 07:06:35.613: INFO: Node Info: &Node{ObjectMeta:{node22-07idr    730acef7-68e7-476f-a9bc-2d75024e5b90 37116 0 2022-04-20 05:37:04 +0000 UTC <nil> <nil> map[beta.kubernetes.io/arch:amd64 beta.kubernetes.io/instance-type:medium beta.kubernetes.io/os:linux failure-domain.beta.kubernetes.io/region:jp-east-1 failure-domain.beta.kubernetes.io/zone:east-11 kubernetes.io/arch:amd64 kubernetes.io/hostname:node22-07idr kubernetes.io/os:linux node.kubernetes.io/instance-type:medium topology.kubernetes.io/region:jp-east-1 topology.kubernetes.io/zone:east-11] map[flannel.alpha.coreos.com/backend-data:{"VtepMAC":"36:9f:09:3a:d0:a6"} flannel.alpha.coreos.com/backend-type:vxlan flannel.alpha.coreos.com/kube-subnet-manager:true flannel.alpha.coreos.com/public-ip:111.171.205.217 node.alpha.kubernetes.io/ttl:0 projectcalico.org/IPv4Address:10.100.118.168/15 projectcalico.org/IPv4IPIPTunnelAddr:10.233.1.1 volumes.kubernetes.io/controller-managed-attach-detach:true] [] []  [{hatoba-cloud-controller-manager Update v1 2022-04-20 05:37:04 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{"f:beta.kubernetes.io/instance-type":{},"f:failure-domain.beta.kubernetes.io/region":{},"f:failure-domain.beta.kubernetes.io/zone":{},"f:node.kubernetes.io/instance-type":{},"f:topology.kubernetes.io/region":{},"f:topology.kubernetes.io/zone":{}}},"f:spec":{"f:providerID":{}}} } {hatoba-cloud-controller-manager Update v1 2022-04-20 05:37:04 +0000 UTC FieldsV1 {"f:status":{"f:addresses":{"k:{\"type\":\"ExternalIP\"}":{".":{},"f:address":{},"f:type":{}},"k:{\"type\":\"InternalIP\"}":{"f:address":{}}}}} status} {kube-controller-manager Update v1 2022-04-20 05:37:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:node.alpha.kubernetes.io/ttl":{}}},"f:spec":{"f:podCIDR":{},"f:podCIDRs":{".":{},"v:\"10.233.1.0/24\"":{}}}} } {kubelet Update v1 2022-04-20 05:37:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:volumes.kubernetes.io/controller-managed-attach-detach":{}},"f:labels":{".":{},"f:beta.kubernetes.io/arch":{},"f:beta.kubernetes.io/os":{},"f:kubernetes.io/arch":{},"f:kubernetes.io/hostname":{},"f:kubernetes.io/os":{}}}} } {calico-node Update v1 2022-04-20 05:37:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:projectcalico.org/IPv4Address":{},"f:projectcalico.org/IPv4IPIPTunnelAddr":{}}}} status} {flanneld Update v1 2022-04-20 05:37:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:flannel.alpha.coreos.com/backend-data":{},"f:flannel.alpha.coreos.com/backend-type":{},"f:flannel.alpha.coreos.com/kube-subnet-manager":{},"f:flannel.alpha.coreos.com/public-ip":{}}},"f:status":{"f:conditions":{"k:{\"type\":\"NetworkUnavailable\"}":{".":{},"f:lastHeartbeatTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}}}} status} {e2e.test Update v1 2022-04-20 07:01:44 +0000 UTC FieldsV1 {"f:status":{"f:capacity":{"f:scheduling.k8s.io/foo":{}}}} status} {kubelet Update v1 2022-04-20 07:01:52 +0000 UTC FieldsV1 {"f:status":{"f:allocatable":{"f:scheduling.k8s.io/foo":{}},"f:conditions":{"k:{\"type\":\"DiskPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"MemoryPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"PIDPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"Ready\"}":{"f:lastHeartbeatTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{}}},"f:images":{}}} status}]},Spec:NodeSpec{PodCIDR:10.233.1.0/24,DoNotUseExternalID:,ProviderID:hatoba:///east-11/i-0v3awxn7,Unschedulable:false,Taints:[]Taint{},ConfigSource:nil,PodCIDRs:[10.233.1.0/24],},Status:NodeStatus{Capacity:ResourceList{cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{28873510912 0} {<nil>} 28196788Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{2055094272 0} {<nil>}  BinarySI},pods: {{100 0} {<nil>} 100 DecimalSI},scheduling.k8s.io/foo: {{5 0} {<nil>} 5 DecimalSI},},Allocatable:ResourceList{cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{25986159778 0} {<nil>} 25986159778 DecimalSI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{1635663872 0} {<nil>}  BinarySI},pods: {{100 0} {<nil>} 100 DecimalSI},scheduling.k8s.io/foo: {{5 0} {<nil>} 5 DecimalSI},},Phase:,Conditions:[]NodeCondition{NodeCondition{Type:NetworkUnavailable,Status:False,LastHeartbeatTime:2022-04-20 05:37:38 +0000 UTC,LastTransitionTime:2022-04-20 05:37:38 +0000 UTC,Reason:FlannelIsUp,Message:Flannel is running on this node,},NodeCondition{Type:MemoryPressure,Status:False,LastHeartbeatTime:2022-04-20 07:05:53 +0000 UTC,LastTransitionTime:2022-04-20 05:37:04 +0000 UTC,Reason:KubeletHasSufficientMemory,Message:kubelet has sufficient memory available,},NodeCondition{Type:DiskPressure,Status:False,LastHeartbeatTime:2022-04-20 07:05:53 +0000 UTC,LastTransitionTime:2022-04-20 05:37:04 +0000 UTC,Reason:KubeletHasNoDiskPressure,Message:kubelet has no disk pressure,},NodeCondition{Type:PIDPressure,Status:False,LastHeartbeatTime:2022-04-20 07:05:53 +0000 UTC,LastTransitionTime:2022-04-20 05:37:04 +0000 UTC,Reason:KubeletHasSufficientPID,Message:kubelet has sufficient PID available,},NodeCondition{Type:Ready,Status:True,LastHeartbeatTime:2022-04-20 07:05:53 +0000 UTC,LastTransitionTime:2022-04-20 05:37:24 +0000 UTC,Reason:KubeletReady,Message:kubelet is posting ready status. AppArmor enabled,},},Addresses:[]NodeAddress{NodeAddress{Type:ExternalIP,Address:111.171.205.217,},NodeAddress{Type:InternalIP,Address:10.100.118.168,},NodeAddress{Type:Hostname,Address:node22-07idr,},},DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:4a524a04bf8e4e0399b261646a18743d,SystemUUID:18363042-d53b-4cb8-2d71-3b42e86422a8,BootID:e1a91b1c-d6ea-48eb-8239-c53faeda1c20,KernelVersion:5.4.0-33-generic,OSImage:Ubuntu 20.04 LTS,ContainerRuntimeVersion:containerd://1.4.3,KubeletVersion:v1.22.2,KubeProxyVersion:v1.22.2,OperatingSystem:linux,Architecture:amd64,},Images:[]ContainerImage{ContainerImage{Names:[docker.io/sonobuoy/systemd-logs@sha256:0b8b2b7b43b03f7db26e7e4b99be402495b77b496f5a5b0425b3c226bc1e9cbd docker.io/sonobuoy/systemd-logs:v0.4],SizeBytes:127795048,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/jessie-dnsutils@sha256:702a992280fb7c3303e84a5801acbb4c9c7fcf48cffe0e9c8be3f0c60f74cf89 k8s.gcr.io/e2e-test-images/jessie-dnsutils:1.4],SizeBytes:112029652,},ContainerImage{Names:[k8s.gcr.io/conformance@sha256:ad3fddc826dd6d0624b53d43f01871a700209afec294c834021477d73d5e0f3c k8s.gcr.io/conformance:v1.22.2],SizeBytes:72154357,},ContainerImage{Names:[docker.io/calico/node@sha256:c9fff18476540e191fcc151494e40e2431453a80605ec72407449b59a33f4b95 docker.io/calico/node:v3.16.3],SizeBytes:57793514,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/agnhost@sha256:758db666ac7028534dba72e7e9bb1e57bb81b8196f976f7a5cc351ef8b3529e1 k8s.gcr.io/e2e-test-images/agnhost:2.32],SizeBytes:50002177,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/nautilus@sha256:1f36a24cfb5e0c3f725d7565a867c2384282fcbeccc77b07b423c9da95763a9a k8s.gcr.io/e2e-test-images/nautilus:1.4],SizeBytes:49230179,},ContainerImage{Names:[docker.io/calico/cni@sha256:41882c4dc53403173009a1fb2009ea766fb41fb2eec85e000c81a017bde4a069 docker.io/calico/cni:v3.16.3],SizeBytes:46311962,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/httpd@sha256:716d2f68314c5c4ddd5ecdb45183fcb4ed8019015982c1321571f863989b70b0 k8s.gcr.io/e2e-test-images/httpd:2.4.39-1],SizeBytes:41902332,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50 k8s.gcr.io/e2e-test-images/httpd:2.4.38-1],SizeBytes:40765006,},ContainerImage{Names:[docker.io/sonobuoy/sonobuoy@sha256:be5e6a32469df1409c647c2a45b6bb1da40d67af1a49175c10928f0b62f161b3 docker.io/sonobuoy/sonobuoy:v0.56.4],SizeBytes:19498697,},ContainerImage{Names:[quay.io/coreos/flannel@sha256:6d451d92c921f14bfb38196aacb6e506d4593c5b3c9d40a8b8a2506010dc3e10 quay.io/coreos/flannel:v0.12.0],SizeBytes:17124093,},ContainerImage{Names:[docker.io/calico/pod2daemon-flexvol@sha256:79fcc69371ae1c44d9e14bd6fea0effb5a9b025e23d2b2aed1483d325657a8ce docker.io/calico/pod2daemon-flexvol:v3.16.3],SizeBytes:9435888,},ContainerImage{Names:[us.gcr.io/k8s-artifacts-prod/kas-network-proxy/proxy-agent@sha256:3b491febf922e2d54df7e775fe111d48e04a98dba606b958426d9dab6255c66c us.gcr.io/k8s-artifacts-prod/kas-network-proxy/proxy-agent:v0.0.15],SizeBytes:8368867,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/nginx@sha256:503b7abb89e57383eba61cc8a9cb0b495ea575c516108f7d972a6ff6e1ab3c9b k8s.gcr.io/e2e-test-images/nginx:1.14-1],SizeBytes:6979365,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/busybox@sha256:39e1e963e5310e9c313bad51523be012ede7b35bb9316517d19089a010356592 k8s.gcr.io/e2e-test-images/busybox:1.29-1],SizeBytes:732746,},ContainerImage{Names:[k8s.gcr.io/pause@sha256:1ff6c18fbef2045af6b9c16bf034cc421a29027b800e4f9b68ae9b1cb3e9ae07 k8s.gcr.io/pause:3.5],SizeBytes:301416,},ContainerImage{Names:[k8s.gcr.io/pause@sha256:927d98197ec1141a368550822d18fa1c60bdae27b78b0c004f705f548c07814f k8s.gcr.io/pause:3.2],SizeBytes:299513,},},VolumesInUse:[],VolumesAttached:[]AttachedVolume{},Config:nil,},}
Apr 20 07:06:35.613: INFO: 
Logging kubelet events for node node22-07idr
Apr 20 07:06:35.618: INFO: 
Logging pods the kubelet thinks is on node node22-07idr
Apr 20 07:06:35.640: INFO: canal-7z4s7 started at 2022-04-20 05:37:05 +0000 UTC (2+2 container statuses recorded)
Apr 20 07:06:35.640: INFO: 	Init container install-cni ready: true, restart count 0
Apr 20 07:06:35.641: INFO: 	Init container flexvol-driver ready: true, restart count 0
Apr 20 07:06:35.641: INFO: 	Container calico-node ready: true, restart count 0
Apr 20 07:06:35.641: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 20 07:06:35.641: INFO: sonobuoy-e2e-job-14e586816b6a497d started at 2022-04-20 05:49:38 +0000 UTC (0+2 container statuses recorded)
Apr 20 07:06:35.641: INFO: 	Container e2e ready: true, restart count 0
Apr 20 07:06:35.641: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 20 07:06:35.641: INFO: konnectivity-agent-z8v6h started at 2022-04-20 05:37:24 +0000 UTC (0+1 container statuses recorded)
Apr 20 07:06:35.641: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 20 07:06:35.641: INFO: sonobuoy-systemd-logs-daemon-set-cdcdd281c10f40dc-vvhct started at 2022-04-20 05:49:38 +0000 UTC (0+2 container statuses recorded)
Apr 20 07:06:35.641: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 20 07:06:35.641: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 20 07:06:35.698: INFO: 
Latency metrics for node node22-07idr
Apr 20 07:06:35.698: INFO: 
Logging node info for node node22-hwh1v
Apr 20 07:06:35.701: INFO: Node Info: &Node{ObjectMeta:{node22-hwh1v    116b9a62-bf78-4dcf-8a93-bc3799500415 37103 0 2022-04-20 05:37:03 +0000 UTC <nil> <nil> map[beta.kubernetes.io/arch:amd64 beta.kubernetes.io/instance-type:medium beta.kubernetes.io/os:linux failure-domain.beta.kubernetes.io/region:jp-east-1 failure-domain.beta.kubernetes.io/zone:east-11 kubernetes.io/arch:amd64 kubernetes.io/hostname:node22-hwh1v kubernetes.io/os:linux node.kubernetes.io/instance-type:medium topology.kubernetes.io/region:jp-east-1 topology.kubernetes.io/zone:east-11] map[flannel.alpha.coreos.com/backend-data:{"VtepMAC":"2e:e8:4f:f7:da:c2"} flannel.alpha.coreos.com/backend-type:vxlan flannel.alpha.coreos.com/kube-subnet-manager:true flannel.alpha.coreos.com/public-ip:111.171.215.173 node.alpha.kubernetes.io/ttl:0 projectcalico.org/IPv4Address:10.100.125.144/15 projectcalico.org/IPv4IPIPTunnelAddr:10.233.0.1 volumes.kubernetes.io/controller-managed-attach-detach:true] [] []  [{hatoba-cloud-controller-manager Update v1 2022-04-20 05:37:03 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{"f:beta.kubernetes.io/instance-type":{},"f:failure-domain.beta.kubernetes.io/region":{},"f:failure-domain.beta.kubernetes.io/zone":{},"f:node.kubernetes.io/instance-type":{},"f:topology.kubernetes.io/region":{},"f:topology.kubernetes.io/zone":{}}},"f:spec":{"f:providerID":{}}} } {hatoba-cloud-controller-manager Update v1 2022-04-20 05:37:03 +0000 UTC FieldsV1 {"f:status":{"f:addresses":{"k:{\"type\":\"ExternalIP\"}":{".":{},"f:address":{},"f:type":{}},"k:{\"type\":\"InternalIP\"}":{"f:address":{}}}}} status} {kube-controller-manager Update v1 2022-04-20 05:37:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:node.alpha.kubernetes.io/ttl":{}}},"f:spec":{"f:podCIDR":{},"f:podCIDRs":{".":{},"v:\"10.233.0.0/24\"":{}}}} } {kubelet Update v1 2022-04-20 05:37:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:volumes.kubernetes.io/controller-managed-attach-detach":{}},"f:labels":{".":{},"f:beta.kubernetes.io/arch":{},"f:beta.kubernetes.io/os":{},"f:kubernetes.io/arch":{},"f:kubernetes.io/hostname":{},"f:kubernetes.io/os":{}}}} } {calico-node Update v1 2022-04-20 05:37:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:projectcalico.org/IPv4Address":{},"f:projectcalico.org/IPv4IPIPTunnelAddr":{}}}} status} {flanneld Update v1 2022-04-20 05:37:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:flannel.alpha.coreos.com/backend-data":{},"f:flannel.alpha.coreos.com/backend-type":{},"f:flannel.alpha.coreos.com/kube-subnet-manager":{},"f:flannel.alpha.coreos.com/public-ip":{}}},"f:status":{"f:conditions":{"k:{\"type\":\"NetworkUnavailable\"}":{".":{},"f:lastHeartbeatTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}}}} status} {e2e.test Update v1 2022-04-20 07:01:44 +0000 UTC FieldsV1 {"f:status":{"f:capacity":{"f:scheduling.k8s.io/foo":{}}}} status} {kubelet Update v1 2022-04-20 07:01:48 +0000 UTC FieldsV1 {"f:status":{"f:allocatable":{"f:ephemeral-storage":{},"f:scheduling.k8s.io/foo":{}},"f:capacity":{"f:ephemeral-storage":{}},"f:conditions":{"k:{\"type\":\"DiskPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"MemoryPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"PIDPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"Ready\"}":{"f:lastHeartbeatTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{}}},"f:images":{}}} status}]},Spec:NodeSpec{PodCIDR:10.233.0.0/24,DoNotUseExternalID:,ProviderID:hatoba:///east-11/i-0xeyxl2h,Unschedulable:false,Taints:[]Taint{},ConfigSource:nil,PodCIDRs:[10.233.0.0/24],},Status:NodeStatus{Capacity:ResourceList{cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{28873510912 0} {<nil>} 28196788Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{2055094272 0} {<nil>}  BinarySI},pods: {{100 0} {<nil>} 100 DecimalSI},scheduling.k8s.io/foo: {{5 0} {<nil>} 5 DecimalSI},},Allocatable:ResourceList{cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{25986159778 0} {<nil>} 25986159778 DecimalSI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{1635663872 0} {<nil>}  BinarySI},pods: {{100 0} {<nil>} 100 DecimalSI},scheduling.k8s.io/foo: {{5 0} {<nil>} 5 DecimalSI},},Phase:,Conditions:[]NodeCondition{NodeCondition{Type:NetworkUnavailable,Status:False,LastHeartbeatTime:2022-04-20 05:37:38 +0000 UTC,LastTransitionTime:2022-04-20 05:37:38 +0000 UTC,Reason:FlannelIsUp,Message:Flannel is running on this node,},NodeCondition{Type:MemoryPressure,Status:False,LastHeartbeatTime:2022-04-20 07:05:50 +0000 UTC,LastTransitionTime:2022-04-20 05:37:03 +0000 UTC,Reason:KubeletHasSufficientMemory,Message:kubelet has sufficient memory available,},NodeCondition{Type:DiskPressure,Status:False,LastHeartbeatTime:2022-04-20 07:05:50 +0000 UTC,LastTransitionTime:2022-04-20 05:37:03 +0000 UTC,Reason:KubeletHasNoDiskPressure,Message:kubelet has no disk pressure,},NodeCondition{Type:PIDPressure,Status:False,LastHeartbeatTime:2022-04-20 07:05:50 +0000 UTC,LastTransitionTime:2022-04-20 05:37:03 +0000 UTC,Reason:KubeletHasSufficientPID,Message:kubelet has sufficient PID available,},NodeCondition{Type:Ready,Status:True,LastHeartbeatTime:2022-04-20 07:05:50 +0000 UTC,LastTransitionTime:2022-04-20 05:37:23 +0000 UTC,Reason:KubeletReady,Message:kubelet is posting ready status. AppArmor enabled,},},Addresses:[]NodeAddress{NodeAddress{Type:ExternalIP,Address:111.171.215.173,},NodeAddress{Type:InternalIP,Address:10.100.125.144,},NodeAddress{Type:Hostname,Address:node22-hwh1v,},},DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:1f563cfdf6374699ba0094d94fc5542a,SystemUUID:8fb13042-659f-9be6-311e-89125cec206e,BootID:b5d47d79-7126-455b-ab32-06154caa4124,KernelVersion:5.4.0-33-generic,OSImage:Ubuntu 20.04 LTS,ContainerRuntimeVersion:containerd://1.4.3,KubeletVersion:v1.22.2,KubeProxyVersion:v1.22.2,OperatingSystem:linux,Architecture:amd64,},Images:[]ContainerImage{ContainerImage{Names:[docker.io/sonobuoy/systemd-logs@sha256:0b8b2b7b43b03f7db26e7e4b99be402495b77b496f5a5b0425b3c226bc1e9cbd docker.io/sonobuoy/systemd-logs:v0.4],SizeBytes:127795048,},ContainerImage{Names:[docker.io/calico/node@sha256:c9fff18476540e191fcc151494e40e2431453a80605ec72407449b59a33f4b95 docker.io/calico/node:v3.16.3],SizeBytes:57793514,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/agnhost@sha256:758db666ac7028534dba72e7e9bb1e57bb81b8196f976f7a5cc351ef8b3529e1 k8s.gcr.io/e2e-test-images/agnhost:2.32],SizeBytes:50002177,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/nautilus@sha256:1f36a24cfb5e0c3f725d7565a867c2384282fcbeccc77b07b423c9da95763a9a k8s.gcr.io/e2e-test-images/nautilus:1.4],SizeBytes:49230179,},ContainerImage{Names:[docker.io/calico/cni@sha256:41882c4dc53403173009a1fb2009ea766fb41fb2eec85e000c81a017bde4a069 docker.io/calico/cni:v3.16.3],SizeBytes:46311962,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/httpd@sha256:716d2f68314c5c4ddd5ecdb45183fcb4ed8019015982c1321571f863989b70b0 k8s.gcr.io/e2e-test-images/httpd:2.4.39-1],SizeBytes:41902332,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50 k8s.gcr.io/e2e-test-images/httpd:2.4.38-1],SizeBytes:40765006,},ContainerImage{Names:[docker.io/calico/kube-controllers@sha256:61b78782f250a07722d003f34c3a55fc66e72017b43f6233b9108dd754b8a364 docker.io/calico/kube-controllers:v3.16.3],SizeBytes:22381765,},ContainerImage{Names:[docker.io/sonobuoy/sonobuoy@sha256:be5e6a32469df1409c647c2a45b6bb1da40d67af1a49175c10928f0b62f161b3 docker.io/sonobuoy/sonobuoy:v0.56.4],SizeBytes:19498697,},ContainerImage{Names:[quay.io/coreos/flannel@sha256:6d451d92c921f14bfb38196aacb6e506d4593c5b3c9d40a8b8a2506010dc3e10 quay.io/coreos/flannel:v0.12.0],SizeBytes:17124093,},ContainerImage{Names:[docker.io/coredns/coredns@sha256:73ca82b4ce829766d4f1f10947c3a338888f876fbed0540dc849c89ff256e90c docker.io/coredns/coredns:1.7.0],SizeBytes:13982350,},ContainerImage{Names:[docker.io/calico/pod2daemon-flexvol@sha256:79fcc69371ae1c44d9e14bd6fea0effb5a9b025e23d2b2aed1483d325657a8ce docker.io/calico/pod2daemon-flexvol:v3.16.3],SizeBytes:9435888,},ContainerImage{Names:[us.gcr.io/k8s-artifacts-prod/kas-network-proxy/proxy-agent@sha256:3b491febf922e2d54df7e775fe111d48e04a98dba606b958426d9dab6255c66c us.gcr.io/k8s-artifacts-prod/kas-network-proxy/proxy-agent:v0.0.15],SizeBytes:8368867,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/nginx@sha256:503b7abb89e57383eba61cc8a9cb0b495ea575c516108f7d972a6ff6e1ab3c9b k8s.gcr.io/e2e-test-images/nginx:1.14-1],SizeBytes:6979365,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/busybox@sha256:39e1e963e5310e9c313bad51523be012ede7b35bb9316517d19089a010356592 k8s.gcr.io/e2e-test-images/busybox:1.29-1],SizeBytes:732746,},ContainerImage{Names:[k8s.gcr.io/pause@sha256:1ff6c18fbef2045af6b9c16bf034cc421a29027b800e4f9b68ae9b1cb3e9ae07 k8s.gcr.io/pause:3.5],SizeBytes:301416,},ContainerImage{Names:[k8s.gcr.io/pause@sha256:927d98197ec1141a368550822d18fa1c60bdae27b78b0c004f705f548c07814f k8s.gcr.io/pause:3.2],SizeBytes:299513,},},VolumesInUse:[],VolumesAttached:[]AttachedVolume{},Config:nil,},}
Apr 20 07:06:35.701: INFO: 
Logging kubelet events for node node22-hwh1v
Apr 20 07:06:35.704: INFO: 
Logging pods the kubelet thinks is on node node22-hwh1v
Apr 20 07:06:35.726: INFO: coredns-748f75f5fb-8sfr7 started at 2022-04-20 05:37:23 +0000 UTC (0+1 container statuses recorded)
Apr 20 07:06:35.726: INFO: 	Container coredns ready: true, restart count 0
Apr 20 07:06:35.726: INFO: canal-xrqg4 started at 2022-04-20 05:37:04 +0000 UTC (2+2 container statuses recorded)
Apr 20 07:06:35.726: INFO: 	Init container install-cni ready: true, restart count 0
Apr 20 07:06:35.726: INFO: 	Init container flexvol-driver ready: true, restart count 0
Apr 20 07:06:35.726: INFO: 	Container calico-node ready: true, restart count 0
Apr 20 07:06:35.726: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 20 07:06:35.726: INFO: konnectivity-agent-9q5dq started at 2022-04-20 05:37:23 +0000 UTC (0+1 container statuses recorded)
Apr 20 07:06:35.726: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 20 07:06:35.726: INFO: coredns-748f75f5fb-2n9dt started at 2022-04-20 05:37:23 +0000 UTC (0+1 container statuses recorded)
Apr 20 07:06:35.726: INFO: 	Container coredns ready: true, restart count 0
Apr 20 07:06:35.726: INFO: sonobuoy-systemd-logs-daemon-set-cdcdd281c10f40dc-dc45f started at 2022-04-20 05:49:38 +0000 UTC (0+2 container statuses recorded)
Apr 20 07:06:35.726: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 20 07:06:35.726: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 20 07:06:35.726: INFO: calico-kube-controllers-5544f8d8d9-2pr5d started at 2022-04-20 05:37:23 +0000 UTC (0+1 container statuses recorded)
Apr 20 07:06:35.726: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 20 07:06:35.773: INFO: 
Latency metrics for node node22-hwh1v
Apr 20 07:06:35.773: INFO: 
Logging node info for node node22-wriki
Apr 20 07:06:35.776: INFO: Node Info: &Node{ObjectMeta:{node22-wriki    999856ca-c55e-4673-b930-e820e594c176 37104 0 2022-04-20 05:37:05 +0000 UTC <nil> <nil> map[beta.kubernetes.io/arch:amd64 beta.kubernetes.io/instance-type:medium beta.kubernetes.io/os:linux failure-domain.beta.kubernetes.io/region:jp-east-1 failure-domain.beta.kubernetes.io/zone:east-11 kubernetes.io/arch:amd64 kubernetes.io/hostname:node22-wriki kubernetes.io/os:linux node.kubernetes.io/instance-type:medium topology.kubernetes.io/region:jp-east-1 topology.kubernetes.io/zone:east-11] map[flannel.alpha.coreos.com/backend-data:{"VtepMAC":"46:bf:4c:31:8f:71"} flannel.alpha.coreos.com/backend-type:vxlan flannel.alpha.coreos.com/kube-subnet-manager:true flannel.alpha.coreos.com/public-ip:111.171.192.229 node.alpha.kubernetes.io/ttl:0 projectcalico.org/IPv4Address:10.100.99.219/15 projectcalico.org/IPv4IPIPTunnelAddr:10.233.2.1 volumes.kubernetes.io/controller-managed-attach-detach:true] [] []  [{hatoba-cloud-controller-manager Update v1 2022-04-20 05:37:05 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{"f:beta.kubernetes.io/instance-type":{},"f:failure-domain.beta.kubernetes.io/region":{},"f:failure-domain.beta.kubernetes.io/zone":{},"f:node.kubernetes.io/instance-type":{},"f:topology.kubernetes.io/region":{},"f:topology.kubernetes.io/zone":{}}},"f:spec":{"f:providerID":{}}} } {hatoba-cloud-controller-manager Update v1 2022-04-20 05:37:05 +0000 UTC FieldsV1 {"f:status":{"f:addresses":{"k:{\"type\":\"ExternalIP\"}":{".":{},"f:address":{},"f:type":{}},"k:{\"type\":\"InternalIP\"}":{"f:address":{}}}}} status} {kube-controller-manager Update v1 2022-04-20 05:37:05 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:node.alpha.kubernetes.io/ttl":{}}},"f:spec":{"f:podCIDR":{},"f:podCIDRs":{".":{},"v:\"10.233.2.0/24\"":{}}}} } {kubelet Update v1 2022-04-20 05:37:05 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:volumes.kubernetes.io/controller-managed-attach-detach":{}},"f:labels":{".":{},"f:beta.kubernetes.io/arch":{},"f:beta.kubernetes.io/os":{},"f:kubernetes.io/arch":{},"f:kubernetes.io/hostname":{},"f:kubernetes.io/os":{}}}} } {calico-node Update v1 2022-04-20 05:37:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:projectcalico.org/IPv4Address":{},"f:projectcalico.org/IPv4IPIPTunnelAddr":{}}}} status} {flanneld Update v1 2022-04-20 05:37:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:flannel.alpha.coreos.com/backend-data":{},"f:flannel.alpha.coreos.com/backend-type":{},"f:flannel.alpha.coreos.com/kube-subnet-manager":{},"f:flannel.alpha.coreos.com/public-ip":{}}},"f:status":{"f:conditions":{"k:{\"type\":\"NetworkUnavailable\"}":{".":{},"f:lastHeartbeatTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}}}} status} {e2e.test Update v1 2022-04-20 07:01:44 +0000 UTC FieldsV1 {"f:status":{"f:capacity":{"f:example.com/fakecpu":{},"f:scheduling.k8s.io/foo":{}}}} status} {kubelet Update v1 2022-04-20 07:01:48 +0000 UTC FieldsV1 {"f:status":{"f:allocatable":{"f:example.com/fakecpu":{},"f:scheduling.k8s.io/foo":{}},"f:conditions":{"k:{\"type\":\"DiskPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"MemoryPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"PIDPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"Ready\"}":{"f:lastHeartbeatTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{}}},"f:images":{}}} status}]},Spec:NodeSpec{PodCIDR:10.233.2.0/24,DoNotUseExternalID:,ProviderID:hatoba:///east-11/i-0wrjevj0,Unschedulable:false,Taints:[]Taint{},ConfigSource:nil,PodCIDRs:[10.233.2.0/24],},Status:NodeStatus{Capacity:ResourceList{cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{28873510912 0} {<nil>} 28196788Ki BinarySI},example.com/fakecpu: {{1 3} {<nil>} 1k DecimalSI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{2055094272 0} {<nil>}  BinarySI},pods: {{100 0} {<nil>} 100 DecimalSI},scheduling.k8s.io/foo: {{5 0} {<nil>} 5 DecimalSI},},Allocatable:ResourceList{cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{25986159778 0} {<nil>} 25986159778 DecimalSI},example.com/fakecpu: {{1 3} {<nil>} 1k DecimalSI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{1635663872 0} {<nil>}  BinarySI},pods: {{100 0} {<nil>} 100 DecimalSI},scheduling.k8s.io/foo: {{5 0} {<nil>} 5 DecimalSI},},Phase:,Conditions:[]NodeCondition{NodeCondition{Type:NetworkUnavailable,Status:False,LastHeartbeatTime:2022-04-20 05:37:34 +0000 UTC,LastTransitionTime:2022-04-20 05:37:34 +0000 UTC,Reason:FlannelIsUp,Message:Flannel is running on this node,},NodeCondition{Type:MemoryPressure,Status:False,LastHeartbeatTime:2022-04-20 07:05:50 +0000 UTC,LastTransitionTime:2022-04-20 05:37:05 +0000 UTC,Reason:KubeletHasSufficientMemory,Message:kubelet has sufficient memory available,},NodeCondition{Type:DiskPressure,Status:False,LastHeartbeatTime:2022-04-20 07:05:50 +0000 UTC,LastTransitionTime:2022-04-20 05:37:05 +0000 UTC,Reason:KubeletHasNoDiskPressure,Message:kubelet has no disk pressure,},NodeCondition{Type:PIDPressure,Status:False,LastHeartbeatTime:2022-04-20 07:05:50 +0000 UTC,LastTransitionTime:2022-04-20 05:37:05 +0000 UTC,Reason:KubeletHasSufficientPID,Message:kubelet has sufficient PID available,},NodeCondition{Type:Ready,Status:True,LastHeartbeatTime:2022-04-20 07:05:50 +0000 UTC,LastTransitionTime:2022-04-20 05:37:25 +0000 UTC,Reason:KubeletReady,Message:kubelet is posting ready status. AppArmor enabled,},},Addresses:[]NodeAddress{NodeAddress{Type:ExternalIP,Address:111.171.192.229,},NodeAddress{Type:InternalIP,Address:10.100.99.219,},NodeAddress{Type:Hostname,Address:node22-wriki,},},DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:b0514ab7455b412ca797a482f71324f1,SystemUUID:e7a73042-28cd-3c4a-b7c2-c1692a609ac4,BootID:9821a45e-1fd2-4c7c-9ff0-33d017c156f2,KernelVersion:5.4.0-33-generic,OSImage:Ubuntu 20.04 LTS,ContainerRuntimeVersion:containerd://1.4.3,KubeletVersion:v1.22.2,KubeProxyVersion:v1.22.2,OperatingSystem:linux,Architecture:amd64,},Images:[]ContainerImage{ContainerImage{Names:[docker.io/sonobuoy/systemd-logs@sha256:0b8b2b7b43b03f7db26e7e4b99be402495b77b496f5a5b0425b3c226bc1e9cbd docker.io/sonobuoy/systemd-logs:v0.4],SizeBytes:127795048,},ContainerImage{Names:[k8s.gcr.io/etcd@sha256:4ad90a11b55313b182afc186b9876c8e891531b8db4c9bf1541953021618d0e2 k8s.gcr.io/etcd:3.4.13-0],SizeBytes:86742272,},ContainerImage{Names:[docker.io/calico/node@sha256:c9fff18476540e191fcc151494e40e2431453a80605ec72407449b59a33f4b95 docker.io/calico/node:v3.16.3],SizeBytes:57793514,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/agnhost@sha256:758db666ac7028534dba72e7e9bb1e57bb81b8196f976f7a5cc351ef8b3529e1 k8s.gcr.io/e2e-test-images/agnhost:2.32],SizeBytes:50002177,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/nautilus@sha256:1f36a24cfb5e0c3f725d7565a867c2384282fcbeccc77b07b423c9da95763a9a k8s.gcr.io/e2e-test-images/nautilus:1.4],SizeBytes:49230179,},ContainerImage{Names:[docker.io/calico/cni@sha256:41882c4dc53403173009a1fb2009ea766fb41fb2eec85e000c81a017bde4a069 docker.io/calico/cni:v3.16.3],SizeBytes:46311962,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/httpd@sha256:716d2f68314c5c4ddd5ecdb45183fcb4ed8019015982c1321571f863989b70b0 k8s.gcr.io/e2e-test-images/httpd:2.4.39-1],SizeBytes:41902332,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50 k8s.gcr.io/e2e-test-images/httpd:2.4.38-1],SizeBytes:40765006,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/sample-apiserver@sha256:e7fddbaac4c3451da2365ab90bad149d32f11409738034e41e0f460927f7c276 k8s.gcr.io/e2e-test-images/sample-apiserver:1.17.4],SizeBytes:24757245,},ContainerImage{Names:[docker.io/sonobuoy/sonobuoy@sha256:be5e6a32469df1409c647c2a45b6bb1da40d67af1a49175c10928f0b62f161b3 docker.io/sonobuoy/sonobuoy:v0.56.4],SizeBytes:19498697,},ContainerImage{Names:[quay.io/coreos/flannel@sha256:6d451d92c921f14bfb38196aacb6e506d4593c5b3c9d40a8b8a2506010dc3e10 quay.io/coreos/flannel:v0.12.0],SizeBytes:17124093,},ContainerImage{Names:[docker.io/calico/pod2daemon-flexvol@sha256:79fcc69371ae1c44d9e14bd6fea0effb5a9b025e23d2b2aed1483d325657a8ce docker.io/calico/pod2daemon-flexvol:v3.16.3],SizeBytes:9435888,},ContainerImage{Names:[us.gcr.io/k8s-artifacts-prod/kas-network-proxy/proxy-agent@sha256:3b491febf922e2d54df7e775fe111d48e04a98dba606b958426d9dab6255c66c us.gcr.io/k8s-artifacts-prod/kas-network-proxy/proxy-agent:v0.0.15],SizeBytes:8368867,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/nginx@sha256:503b7abb89e57383eba61cc8a9cb0b495ea575c516108f7d972a6ff6e1ab3c9b k8s.gcr.io/e2e-test-images/nginx:1.14-1],SizeBytes:6979365,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/nonewprivs@sha256:8ac1264691820febacf3aea5d152cbde6d10685731ec14966a9401c6f47a68ac k8s.gcr.io/e2e-test-images/nonewprivs:1.3],SizeBytes:3263463,},ContainerImage{Names:[k8s.gcr.io/e2e-test-images/busybox@sha256:39e1e963e5310e9c313bad51523be012ede7b35bb9316517d19089a010356592 k8s.gcr.io/e2e-test-images/busybox:1.29-1],SizeBytes:732746,},ContainerImage{Names:[k8s.gcr.io/pause@sha256:1ff6c18fbef2045af6b9c16bf034cc421a29027b800e4f9b68ae9b1cb3e9ae07 k8s.gcr.io/pause:3.5],SizeBytes:301416,},ContainerImage{Names:[k8s.gcr.io/pause@sha256:927d98197ec1141a368550822d18fa1c60bdae27b78b0c004f705f548c07814f k8s.gcr.io/pause:3.2],SizeBytes:299513,},},VolumesInUse:[],VolumesAttached:[]AttachedVolume{},Config:nil,},}
Apr 20 07:06:35.776: INFO: 
Logging kubelet events for node node22-wriki
Apr 20 07:06:35.778: INFO: 
Logging pods the kubelet thinks is on node node22-wriki
Apr 20 07:06:35.792: INFO: canal-r5jz2 started at 2022-04-20 05:37:06 +0000 UTC (2+2 container statuses recorded)
Apr 20 07:06:35.792: INFO: 	Init container install-cni ready: true, restart count 0
Apr 20 07:06:35.792: INFO: 	Init container flexvol-driver ready: true, restart count 0
Apr 20 07:06:35.792: INFO: 	Container calico-node ready: true, restart count 0
Apr 20 07:06:35.792: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 20 07:06:35.792: INFO: sonobuoy started at 2022-04-20 05:49:32 +0000 UTC (0+1 container statuses recorded)
Apr 20 07:06:35.792: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 20 07:06:35.792: INFO: konnectivity-agent-vgl4v started at 2022-04-20 06:27:48 +0000 UTC (0+1 container statuses recorded)
Apr 20 07:06:35.792: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 20 07:06:35.792: INFO: test-webserver-6c8890e1-121f-4abc-b86d-5c4f793a02de started at 2022-04-20 07:02:27 +0000 UTC (0+1 container statuses recorded)
Apr 20 07:06:35.792: INFO: 	Container test-webserver ready: true, restart count 0
Apr 20 07:06:35.792: INFO: sonobuoy-systemd-logs-daemon-set-cdcdd281c10f40dc-48vdz started at 2022-04-20 05:49:39 +0000 UTC (0+2 container statuses recorded)
Apr 20 07:06:35.792: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 20 07:06:35.792: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 20 07:06:35.844: INFO: 
Latency metrics for node node22-wriki
Apr 20 07:06:35.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-772" for this suite.

• Failure [248.448 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [It]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630

  Apr 20 07:06:35.549: getting pod 
  Unexpected error:
      <*errors.StatusError | 0xc002a10b40>: {
          ErrStatus: {
              TypeMeta: {Kind: "", APIVersion: ""},
              ListMeta: {
                  SelfLink: "",
                  ResourceVersion: "",
                  Continue: "",
                  RemainingItemCount: nil,
              },
              Status: "Failure",
              Message: "etcdserver: request timed out",
              Reason: "",
              Details: nil,
              Code: 500,
          },
      }
      etcdserver: request timed out
  occurred

  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:701
------------------------------
{"msg":"FAILED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":346,"completed":314,"skipped":5741,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces 
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:06:35.858: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:69
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:06:35.895: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename disruption-2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be processed
STEP: listing a collection of PDBs across all namespaces
STEP: listing a collection of PDBs in namespace disruption-8586
STEP: deleting a collection of PDBs
STEP: Waiting for the PDB collection to be deleted
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:06:42.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-1181" for this suite.
[AfterEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:06:42.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-8586" for this suite.

• [SLOW TEST:6.175 seconds]
[sig-apps] DisruptionController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:75
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","total":346,"completed":315,"skipped":5756,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:06:42.036: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Performing setup for networking test in namespace pod-network-test-3870
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 20 07:06:42.069: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 20 07:06:42.108: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 07:06:44.111: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 20 07:06:46.113: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 20 07:06:48.114: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 20 07:06:50.114: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 20 07:06:52.126: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 20 07:06:54.110: INFO: The status of Pod netserver-0 is Running (Ready = true)
Apr 20 07:06:54.114: INFO: The status of Pod netserver-1 is Running (Ready = true)
Apr 20 07:06:54.117: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Apr 20 07:06:56.135: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Apr 20 07:06:56.135: INFO: Breadth first check of 10.233.1.110 on host 10.100.118.168...
Apr 20 07:06:56.138: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.1.111:9080/dial?request=hostname&protocol=udp&host=10.233.1.110&port=8081&tries=1'] Namespace:pod-network-test-3870 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 07:06:56.138: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 07:06:56.223: INFO: Waiting for responses: map[]
Apr 20 07:06:56.223: INFO: reached 10.233.1.110 after 0/1 tries
Apr 20 07:06:56.223: INFO: Breadth first check of 10.233.0.153 on host 10.100.125.144...
Apr 20 07:06:56.227: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.1.111:9080/dial?request=hostname&protocol=udp&host=10.233.0.153&port=8081&tries=1'] Namespace:pod-network-test-3870 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 07:06:56.227: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 07:06:56.294: INFO: Waiting for responses: map[]
Apr 20 07:06:56.294: INFO: reached 10.233.0.153 after 0/1 tries
Apr 20 07:06:56.294: INFO: Breadth first check of 10.233.2.215 on host 10.100.99.219...
Apr 20 07:06:56.296: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.1.111:9080/dial?request=hostname&protocol=udp&host=10.233.2.215&port=8081&tries=1'] Namespace:pod-network-test-3870 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 20 07:06:56.296: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
Apr 20 07:06:56.361: INFO: Waiting for responses: map[]
Apr 20 07:06:56.362: INFO: reached 10.233.2.215 after 0/1 tries
Apr 20 07:06:56.362: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:06:56.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3870" for this suite.

• [SLOW TEST:14.335 seconds]
[sig-network] Networking
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/networking.go:30
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","total":346,"completed":316,"skipped":5773,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:06:56.370: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 07:06:56.403: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:06:59.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-584" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":346,"completed":317,"skipped":5786,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:06:59.658: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:07:24.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2497" for this suite.

• [SLOW TEST:25.257 seconds]
[sig-node] Container Runtime
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  blackbox test
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/runtime.go:41
    when starting a container that exits
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/runtime.go:42
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":346,"completed":318,"skipped":5788,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:07:24.916: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:92
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:107
STEP: Creating service test in namespace statefulset-4609
[It] Should recreate evicted statefulset [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-4609
STEP: Waiting until pod test-pod will start running in namespace statefulset-4609
STEP: Creating statefulset with conflicting port in namespace statefulset-4609
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-4609
Apr 20 07:07:27.022: INFO: Observed stateful pod in namespace: statefulset-4609, name: ss-0, uid: 05cfdb61-44f2-41fe-b052-f723a70ca7e8, status phase: Pending. Waiting for statefulset controller to delete.
Apr 20 07:07:27.036: INFO: Observed stateful pod in namespace: statefulset-4609, name: ss-0, uid: 05cfdb61-44f2-41fe-b052-f723a70ca7e8, status phase: Failed. Waiting for statefulset controller to delete.
Apr 20 07:07:27.043: INFO: Observed stateful pod in namespace: statefulset-4609, name: ss-0, uid: 05cfdb61-44f2-41fe-b052-f723a70ca7e8, status phase: Failed. Waiting for statefulset controller to delete.
Apr 20 07:07:27.046: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-4609
STEP: Removing pod with conflicting port in namespace statefulset-4609
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-4609 and will be in running state
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:118
Apr 20 07:07:29.075: INFO: Deleting all statefulset in ns statefulset-4609
Apr 20 07:07:29.078: INFO: Scaling statefulset ss to 0
Apr 20 07:07:39.097: INFO: Waiting for statefulset status.replicas updated to 0
Apr 20 07:07:39.099: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:07:39.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4609" for this suite.

• [SLOW TEST:14.204 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:97
    Should recreate evicted statefulset [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":346,"completed":319,"skipped":5795,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:07:39.120: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap configmap-5441/configmap-test-403f286f-850d-4f44-b4f4-072eb515212e
STEP: Creating a pod to test consume configMaps
Apr 20 07:07:39.159: INFO: Waiting up to 5m0s for pod "pod-configmaps-7869e01c-6e8f-42b5-9901-6e68f5716248" in namespace "configmap-5441" to be "Succeeded or Failed"
Apr 20 07:07:39.161: INFO: Pod "pod-configmaps-7869e01c-6e8f-42b5-9901-6e68f5716248": Phase="Pending", Reason="", readiness=false. Elapsed: 1.651079ms
Apr 20 07:07:41.165: INFO: Pod "pod-configmaps-7869e01c-6e8f-42b5-9901-6e68f5716248": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005601768s
STEP: Saw pod success
Apr 20 07:07:41.165: INFO: Pod "pod-configmaps-7869e01c-6e8f-42b5-9901-6e68f5716248" satisfied condition "Succeeded or Failed"
Apr 20 07:07:41.172: INFO: Trying to get logs from node node22-wriki pod pod-configmaps-7869e01c-6e8f-42b5-9901-6e68f5716248 container env-test: <nil>
STEP: delete the pod
Apr 20 07:07:41.188: INFO: Waiting for pod pod-configmaps-7869e01c-6e8f-42b5-9901-6e68f5716248 to disappear
Apr 20 07:07:41.190: INFO: Pod pod-configmaps-7869e01c-6e8f-42b5-9901-6e68f5716248 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:07:41.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5441" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":346,"completed":320,"skipped":5797,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:07:41.202: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 07:07:41.284: INFO: Creating ReplicaSet my-hostname-basic-c0ab2f7c-2b66-45b3-87b7-3a15cf1f582f
Apr 20 07:07:41.292: INFO: Pod name my-hostname-basic-c0ab2f7c-2b66-45b3-87b7-3a15cf1f582f: Found 0 pods out of 1
Apr 20 07:07:46.298: INFO: Pod name my-hostname-basic-c0ab2f7c-2b66-45b3-87b7-3a15cf1f582f: Found 1 pods out of 1
Apr 20 07:07:46.298: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-c0ab2f7c-2b66-45b3-87b7-3a15cf1f582f" is running
Apr 20 07:07:46.301: INFO: Pod "my-hostname-basic-c0ab2f7c-2b66-45b3-87b7-3a15cf1f582f-7cqjf" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-04-20 07:07:41 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-04-20 07:07:42 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-04-20 07:07:42 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-04-20 07:07:41 +0000 UTC Reason: Message:}])
Apr 20 07:07:46.302: INFO: Trying to dial the pod
Apr 20 07:07:51.319: INFO: Controller my-hostname-basic-c0ab2f7c-2b66-45b3-87b7-3a15cf1f582f: Got expected result from replica 1 [my-hostname-basic-c0ab2f7c-2b66-45b3-87b7-3a15cf1f582f-7cqjf]: "my-hostname-basic-c0ab2f7c-2b66-45b3-87b7-3a15cf1f582f-7cqjf", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:07:51.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5025" for this suite.

• [SLOW TEST:10.126 seconds]
[sig-apps] ReplicaSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":346,"completed":321,"skipped":5829,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:07:51.328: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr 20 07:07:51.421: INFO: Waiting up to 5m0s for pod "downwardapi-volume-febc5a93-cb68-4d31-97b7-6a5ce012f731" in namespace "downward-api-9815" to be "Succeeded or Failed"
Apr 20 07:07:51.423: INFO: Pod "downwardapi-volume-febc5a93-cb68-4d31-97b7-6a5ce012f731": Phase="Pending", Reason="", readiness=false. Elapsed: 1.731859ms
Apr 20 07:07:53.430: INFO: Pod "downwardapi-volume-febc5a93-cb68-4d31-97b7-6a5ce012f731": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00900702s
STEP: Saw pod success
Apr 20 07:07:53.430: INFO: Pod "downwardapi-volume-febc5a93-cb68-4d31-97b7-6a5ce012f731" satisfied condition "Succeeded or Failed"
Apr 20 07:07:53.432: INFO: Trying to get logs from node node22-hwh1v pod downwardapi-volume-febc5a93-cb68-4d31-97b7-6a5ce012f731 container client-container: <nil>
STEP: delete the pod
Apr 20 07:07:53.447: INFO: Waiting for pod downwardapi-volume-febc5a93-cb68-4d31-97b7-6a5ce012f731 to disappear
Apr 20 07:07:53.448: INFO: Pod downwardapi-volume-febc5a93-cb68-4d31-97b7-6a5ce012f731 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:07:53.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9815" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":346,"completed":322,"skipped":5833,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:07:53.456: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr 20 07:07:55.506: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:07:55.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9788" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":346,"completed":323,"skipped":5873,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:07:55.525: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 07:07:55.622: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"c825593f-1691-4911-952f-749d26b45a45", Controller:(*bool)(0xc0047fd676), BlockOwnerDeletion:(*bool)(0xc0047fd677)}}
Apr 20 07:07:55.652: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"6fc0cec6-e756-4a71-9437-e8462ae5abac", Controller:(*bool)(0xc000ba474e), BlockOwnerDeletion:(*bool)(0xc000ba474f)}}
Apr 20 07:07:55.658: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"7d7fa6f1-eb99-4400-8b12-d648501dc339", Controller:(*bool)(0xc0047fdabe), BlockOwnerDeletion:(*bool)(0xc0047fdabf)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:08:00.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-186" for this suite.

• [SLOW TEST:5.175 seconds]
[sig-api-machinery] Garbage collector
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":346,"completed":324,"skipped":5877,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
S
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:08:00.703: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-7758, will wait for the garbage collector to delete the pods
Apr 20 07:08:02.853: INFO: Deleting Job.batch foo took: 10.80602ms
Apr 20 07:08:02.954: INFO: Terminating Job.batch foo pods took: 101.167868ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:08:35.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7758" for this suite.

• [SLOW TEST:34.867 seconds]
[sig-apps] Job
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":346,"completed":325,"skipped":5878,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:08:35.573: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name cm-test-opt-del-af4ad2d1-3c9c-4804-ac6a-8b0dda4c8480
STEP: Creating configMap with name cm-test-opt-upd-ed09e356-6ddb-4385-9eb5-f2d2b61de464
STEP: Creating the pod
Apr 20 07:08:35.672: INFO: The status of Pod pod-configmaps-58fe3fb6-8c91-48b6-8d89-1f6c7dfd2470 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 07:08:37.679: INFO: The status of Pod pod-configmaps-58fe3fb6-8c91-48b6-8d89-1f6c7dfd2470 is Running (Ready = true)
STEP: Deleting configmap cm-test-opt-del-af4ad2d1-3c9c-4804-ac6a-8b0dda4c8480
STEP: Updating configmap cm-test-opt-upd-ed09e356-6ddb-4385-9eb5-f2d2b61de464
STEP: Creating configMap with name cm-test-opt-create-b1df54df-e675-423d-9212-19be6bbd1cfc
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:08:41.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3202" for this suite.

• [SLOW TEST:6.171 seconds]
[sig-storage] ConfigMap
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":326,"skipped":5882,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:08:41.744: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod pod-subpath-test-secret-rn6s
STEP: Creating a pod to test atomic-volume-subpath
Apr 20 07:08:41.837: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-rn6s" in namespace "subpath-5547" to be "Succeeded or Failed"
Apr 20 07:08:41.839: INFO: Pod "pod-subpath-test-secret-rn6s": Phase="Pending", Reason="", readiness=false. Elapsed: 1.868555ms
Apr 20 07:08:43.844: INFO: Pod "pod-subpath-test-secret-rn6s": Phase="Running", Reason="", readiness=true. Elapsed: 2.007203002s
Apr 20 07:08:45.850: INFO: Pod "pod-subpath-test-secret-rn6s": Phase="Running", Reason="", readiness=true. Elapsed: 4.013639887s
Apr 20 07:08:47.856: INFO: Pod "pod-subpath-test-secret-rn6s": Phase="Running", Reason="", readiness=true. Elapsed: 6.018849709s
Apr 20 07:08:49.861: INFO: Pod "pod-subpath-test-secret-rn6s": Phase="Running", Reason="", readiness=true. Elapsed: 8.024149564s
Apr 20 07:08:51.865: INFO: Pod "pod-subpath-test-secret-rn6s": Phase="Running", Reason="", readiness=true. Elapsed: 10.028362523s
Apr 20 07:08:53.871: INFO: Pod "pod-subpath-test-secret-rn6s": Phase="Running", Reason="", readiness=true. Elapsed: 12.033808649s
Apr 20 07:08:55.877: INFO: Pod "pod-subpath-test-secret-rn6s": Phase="Running", Reason="", readiness=true. Elapsed: 14.040557439s
Apr 20 07:08:57.882: INFO: Pod "pod-subpath-test-secret-rn6s": Phase="Running", Reason="", readiness=true. Elapsed: 16.045618426s
Apr 20 07:08:59.890: INFO: Pod "pod-subpath-test-secret-rn6s": Phase="Running", Reason="", readiness=true. Elapsed: 18.053502504s
Apr 20 07:09:01.898: INFO: Pod "pod-subpath-test-secret-rn6s": Phase="Running", Reason="", readiness=true. Elapsed: 20.060758164s
Apr 20 07:09:03.902: INFO: Pod "pod-subpath-test-secret-rn6s": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.065637381s
STEP: Saw pod success
Apr 20 07:09:03.903: INFO: Pod "pod-subpath-test-secret-rn6s" satisfied condition "Succeeded or Failed"
Apr 20 07:09:03.905: INFO: Trying to get logs from node node22-hwh1v pod pod-subpath-test-secret-rn6s container test-container-subpath-secret-rn6s: <nil>
STEP: delete the pod
Apr 20 07:09:03.918: INFO: Waiting for pod pod-subpath-test-secret-rn6s to disappear
Apr 20 07:09:03.920: INFO: Pod pod-subpath-test-secret-rn6s no longer exists
STEP: Deleting pod pod-subpath-test-secret-rn6s
Apr 20 07:09:03.920: INFO: Deleting pod "pod-subpath-test-secret-rn6s" in namespace "subpath-5547"
[AfterEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:09:03.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5547" for this suite.

• [SLOW TEST:22.185 seconds]
[sig-storage] Subpath
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [LinuxOnly] [Conformance]","total":346,"completed":327,"skipped":5885,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:09:03.930: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:09:10.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2250" for this suite.

• [SLOW TEST:7.074 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":346,"completed":328,"skipped":5889,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:09:11.005: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating replication controller my-hostname-basic-80d40393-daef-4436-aae1-16207b4a0fa5
Apr 20 07:09:11.101: INFO: Pod name my-hostname-basic-80d40393-daef-4436-aae1-16207b4a0fa5: Found 0 pods out of 1
Apr 20 07:09:16.107: INFO: Pod name my-hostname-basic-80d40393-daef-4436-aae1-16207b4a0fa5: Found 1 pods out of 1
Apr 20 07:09:16.107: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-80d40393-daef-4436-aae1-16207b4a0fa5" are running
Apr 20 07:09:16.110: INFO: Pod "my-hostname-basic-80d40393-daef-4436-aae1-16207b4a0fa5-2bg2x" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-04-20 07:09:11 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-04-20 07:09:12 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-04-20 07:09:12 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-04-20 07:09:11 +0000 UTC Reason: Message:}])
Apr 20 07:09:16.110: INFO: Trying to dial the pod
Apr 20 07:09:21.122: INFO: Controller my-hostname-basic-80d40393-daef-4436-aae1-16207b4a0fa5: Got expected result from replica 1 [my-hostname-basic-80d40393-daef-4436-aae1-16207b4a0fa5-2bg2x]: "my-hostname-basic-80d40393-daef-4436-aae1-16207b4a0fa5-2bg2x", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:09:21.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8984" for this suite.

• [SLOW TEST:10.126 seconds]
[sig-apps] ReplicationController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":346,"completed":329,"skipped":5917,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:09:21.132: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-20f8153e-76aa-47cc-94d4-8aab42a0a66b
STEP: Creating a pod to test consume configMaps
Apr 20 07:09:21.186: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-30f71a06-624b-4fcf-a904-3747b2ae3c46" in namespace "projected-6743" to be "Succeeded or Failed"
Apr 20 07:09:21.188: INFO: Pod "pod-projected-configmaps-30f71a06-624b-4fcf-a904-3747b2ae3c46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.643385ms
Apr 20 07:09:23.193: INFO: Pod "pod-projected-configmaps-30f71a06-624b-4fcf-a904-3747b2ae3c46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00675157s
STEP: Saw pod success
Apr 20 07:09:23.193: INFO: Pod "pod-projected-configmaps-30f71a06-624b-4fcf-a904-3747b2ae3c46" satisfied condition "Succeeded or Failed"
Apr 20 07:09:23.195: INFO: Trying to get logs from node node22-hwh1v pod pod-projected-configmaps-30f71a06-624b-4fcf-a904-3747b2ae3c46 container agnhost-container: <nil>
STEP: delete the pod
Apr 20 07:09:23.211: INFO: Waiting for pod pod-projected-configmaps-30f71a06-624b-4fcf-a904-3747b2ae3c46 to disappear
Apr 20 07:09:23.213: INFO: Pod pod-projected-configmaps-30f71a06-624b-4fcf-a904-3747b2ae3c46 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:09:23.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6743" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":330,"skipped":5918,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:09:23.224: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-map-83c85d8e-4444-4cb0-a1ec-d4dd772f528d
STEP: Creating a pod to test consume configMaps
Apr 20 07:09:23.271: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d9d53327-8887-4983-b20e-ef95d646d596" in namespace "projected-9473" to be "Succeeded or Failed"
Apr 20 07:09:23.273: INFO: Pod "pod-projected-configmaps-d9d53327-8887-4983-b20e-ef95d646d596": Phase="Pending", Reason="", readiness=false. Elapsed: 1.912067ms
Apr 20 07:09:25.278: INFO: Pod "pod-projected-configmaps-d9d53327-8887-4983-b20e-ef95d646d596": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006533678s
STEP: Saw pod success
Apr 20 07:09:25.278: INFO: Pod "pod-projected-configmaps-d9d53327-8887-4983-b20e-ef95d646d596" satisfied condition "Succeeded or Failed"
Apr 20 07:09:25.280: INFO: Trying to get logs from node node22-hwh1v pod pod-projected-configmaps-d9d53327-8887-4983-b20e-ef95d646d596 container agnhost-container: <nil>
STEP: delete the pod
Apr 20 07:09:25.297: INFO: Waiting for pod pod-projected-configmaps-d9d53327-8887-4983-b20e-ef95d646d596 to disappear
Apr 20 07:09:25.298: INFO: Pod pod-projected-configmaps-d9d53327-8887-4983-b20e-ef95d646d596 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:09:25.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9473" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":346,"completed":331,"skipped":5933,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:09:25.308: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Apr 20 07:09:25.993: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
W0420 07:09:25.993033      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr 20 07:09:25.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4299" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":346,"completed":332,"skipped":5943,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:09:26.002: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with secret that has name projected-secret-test-3731aa35-4d39-49fc-9054-6d75e0ea6f4d
STEP: Creating a pod to test consume secrets
Apr 20 07:09:26.038: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5dd622ba-b543-4f87-9447-ebf6a3c0c99a" in namespace "projected-9971" to be "Succeeded or Failed"
Apr 20 07:09:26.040: INFO: Pod "pod-projected-secrets-5dd622ba-b543-4f87-9447-ebf6a3c0c99a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.54542ms
Apr 20 07:09:28.046: INFO: Pod "pod-projected-secrets-5dd622ba-b543-4f87-9447-ebf6a3c0c99a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007731022s
STEP: Saw pod success
Apr 20 07:09:28.046: INFO: Pod "pod-projected-secrets-5dd622ba-b543-4f87-9447-ebf6a3c0c99a" satisfied condition "Succeeded or Failed"
Apr 20 07:09:28.048: INFO: Trying to get logs from node node22-hwh1v pod pod-projected-secrets-5dd622ba-b543-4f87-9447-ebf6a3c0c99a container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 20 07:09:28.063: INFO: Waiting for pod pod-projected-secrets-5dd622ba-b543-4f87-9447-ebf6a3c0c99a to disappear
Apr 20 07:09:28.065: INFO: Pod pod-projected-secrets-5dd622ba-b543-4f87-9447-ebf6a3c0c99a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:09:28.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9971" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":346,"completed":333,"skipped":5944,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:09:28.073: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
Apr 20 07:09:28.158: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4845284f-0bcd-404c-a950-ead33b86b5d9" in namespace "projected-6246" to be "Succeeded or Failed"
Apr 20 07:09:28.160: INFO: Pod "downwardapi-volume-4845284f-0bcd-404c-a950-ead33b86b5d9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.081894ms
Apr 20 07:09:30.166: INFO: Pod "downwardapi-volume-4845284f-0bcd-404c-a950-ead33b86b5d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007363264s
STEP: Saw pod success
Apr 20 07:09:30.166: INFO: Pod "downwardapi-volume-4845284f-0bcd-404c-a950-ead33b86b5d9" satisfied condition "Succeeded or Failed"
Apr 20 07:09:30.168: INFO: Trying to get logs from node node22-wriki pod downwardapi-volume-4845284f-0bcd-404c-a950-ead33b86b5d9 container client-container: <nil>
STEP: delete the pod
Apr 20 07:09:30.182: INFO: Waiting for pod downwardapi-volume-4845284f-0bcd-404c-a950-ead33b86b5d9 to disappear
Apr 20 07:09:30.184: INFO: Pod downwardapi-volume-4845284f-0bcd-404c-a950-ead33b86b5d9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:09:30.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6246" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":346,"completed":334,"skipped":5964,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:09:30.192: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name s-test-opt-del-4d9ef906-ce9c-43b2-a791-8630397814ef
STEP: Creating secret with name s-test-opt-upd-8542c7a3-642e-4887-9d64-289fa6ef4050
STEP: Creating the pod
Apr 20 07:09:30.240: INFO: The status of Pod pod-secrets-5d4584e3-5b33-40bf-ae6e-80054dce7c89 is Pending, waiting for it to be Running (with Ready = true)
Apr 20 07:09:32.246: INFO: The status of Pod pod-secrets-5d4584e3-5b33-40bf-ae6e-80054dce7c89 is Running (Ready = true)
STEP: Deleting secret s-test-opt-del-4d9ef906-ce9c-43b2-a791-8630397814ef
STEP: Updating secret s-test-opt-upd-8542c7a3-642e-4887-9d64-289fa6ef4050
STEP: Creating secret with name s-test-opt-create-c71ac4dc-9827-4f05-9553-8e8c404b1b65
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:09:34.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8209" for this suite.
•{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":335,"skipped":5966,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:09:34.310: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 20 07:09:34.399: INFO: Waiting up to 5m0s for pod "pod-2d69d03c-5cea-4877-ac06-18599e56a50d" in namespace "emptydir-3337" to be "Succeeded or Failed"
Apr 20 07:09:34.402: INFO: Pod "pod-2d69d03c-5cea-4877-ac06-18599e56a50d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.291407ms
Apr 20 07:09:36.406: INFO: Pod "pod-2d69d03c-5cea-4877-ac06-18599e56a50d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006863424s
STEP: Saw pod success
Apr 20 07:09:36.406: INFO: Pod "pod-2d69d03c-5cea-4877-ac06-18599e56a50d" satisfied condition "Succeeded or Failed"
Apr 20 07:09:36.408: INFO: Trying to get logs from node node22-wriki pod pod-2d69d03c-5cea-4877-ac06-18599e56a50d container test-container: <nil>
STEP: delete the pod
Apr 20 07:09:36.423: INFO: Waiting for pod pod-2d69d03c-5cea-4877-ac06-18599e56a50d to disappear
Apr 20 07:09:36.425: INFO: Pod pod-2d69d03c-5cea-4877-ac06-18599e56a50d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:09:36.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3337" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":336,"skipped":5967,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:09:36.438: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:09:36.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-9192" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":346,"completed":337,"skipped":5991,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:09:36.480: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 20 07:09:36.762: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 20 07:09:39.790: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:09:49.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1612" for this suite.
STEP: Destroying namespace "webhook-1612-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:13.528 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":346,"completed":338,"skipped":6002,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:09:50.007: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:92
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:107
STEP: Creating service test in namespace statefulset-3463
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-3463
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3463
Apr 20 07:09:50.061: INFO: Found 0 stateful pods, waiting for 1
Apr 20 07:10:00.069: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Apr 20 07:10:00.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=statefulset-3463 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 20 07:10:00.281: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 20 07:10:00.281: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 20 07:10:00.281: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 20 07:10:00.284: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 20 07:10:10.289: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 20 07:10:10.289: INFO: Waiting for statefulset status.replicas updated to 0
Apr 20 07:10:10.307: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999685s
Apr 20 07:10:11.313: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995393522s
Apr 20 07:10:12.319: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.989658787s
Apr 20 07:10:13.324: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.983810848s
Apr 20 07:10:14.331: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.978477686s
Apr 20 07:10:15.335: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.971730942s
Apr 20 07:10:16.338: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.966941202s
Apr 20 07:10:17.343: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.964477556s
Apr 20 07:10:18.347: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.959819172s
Apr 20 07:10:19.352: INFO: Verifying statefulset ss doesn't scale past 1 for another 955.684708ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3463
Apr 20 07:10:20.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=statefulset-3463 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 20 07:10:20.473: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 20 07:10:20.473: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 20 07:10:20.473: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 20 07:10:20.476: INFO: Found 1 stateful pods, waiting for 3
Apr 20 07:10:30.486: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 20 07:10:30.486: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 20 07:10:30.486: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Apr 20 07:10:30.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=statefulset-3463 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 20 07:10:30.620: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 20 07:10:30.620: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 20 07:10:30.620: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 20 07:10:30.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=statefulset-3463 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 20 07:10:30.753: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 20 07:10:30.753: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 20 07:10:30.753: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 20 07:10:30.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=statefulset-3463 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 20 07:10:30.877: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 20 07:10:30.877: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 20 07:10:30.877: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 20 07:10:30.877: INFO: Waiting for statefulset status.replicas updated to 0
Apr 20 07:10:30.880: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Apr 20 07:10:40.893: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 20 07:10:40.893: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 20 07:10:40.893: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 20 07:10:40.909: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999787s
Apr 20 07:10:41.912: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995866398s
Apr 20 07:10:42.917: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992915541s
Apr 20 07:10:43.922: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.98759078s
Apr 20 07:10:44.926: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.982508041s
Apr 20 07:10:45.931: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.978631231s
Apr 20 07:10:46.936: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.973796298s
Apr 20 07:10:47.942: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.968639359s
Apr 20 07:10:48.949: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.962747022s
Apr 20 07:10:49.954: INFO: Verifying statefulset ss doesn't scale past 3 for another 955.364653ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3463
Apr 20 07:10:50.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=statefulset-3463 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 20 07:10:51.086: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 20 07:10:51.086: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 20 07:10:51.086: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 20 07:10:51.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=statefulset-3463 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 20 07:10:51.192: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 20 07:10:51.192: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 20 07:10:51.192: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 20 07:10:51.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=statefulset-3463 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 20 07:10:51.311: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 20 07:10:51.311: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 20 07:10:51.311: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 20 07:10:51.311: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:118
Apr 20 07:11:01.325: INFO: Deleting all statefulset in ns statefulset-3463
Apr 20 07:11:01.328: INFO: Scaling statefulset ss to 0
Apr 20 07:11:01.338: INFO: Waiting for statefulset status.replicas updated to 0
Apr 20 07:11:01.340: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:11:01.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3463" for this suite.

• [SLOW TEST:71.353 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:97
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":346,"completed":339,"skipped":6005,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:11:01.362: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/security_context.go:46
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 07:11:01.413: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-c723c7b5-6362-4e1d-8f90-b561e8e4daa5" in namespace "security-context-test-9018" to be "Succeeded or Failed"
Apr 20 07:11:01.415: INFO: Pod "busybox-readonly-false-c723c7b5-6362-4e1d-8f90-b561e8e4daa5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.586544ms
Apr 20 07:11:03.422: INFO: Pod "busybox-readonly-false-c723c7b5-6362-4e1d-8f90-b561e8e4daa5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009671578s
Apr 20 07:11:03.423: INFO: Pod "busybox-readonly-false-c723c7b5-6362-4e1d-8f90-b561e8e4daa5" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:11:03.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9018" for this suite.
•{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":346,"completed":340,"skipped":6008,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:11:03.433: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 20 07:11:03.485: INFO: Waiting up to 5m0s for pod "pod-7a55fcd7-e2dd-4073-b919-2d7d24c45756" in namespace "emptydir-6070" to be "Succeeded or Failed"
Apr 20 07:11:03.487: INFO: Pod "pod-7a55fcd7-e2dd-4073-b919-2d7d24c45756": Phase="Pending", Reason="", readiness=false. Elapsed: 2.420685ms
Apr 20 07:11:05.491: INFO: Pod "pod-7a55fcd7-e2dd-4073-b919-2d7d24c45756": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006642701s
STEP: Saw pod success
Apr 20 07:11:05.491: INFO: Pod "pod-7a55fcd7-e2dd-4073-b919-2d7d24c45756" satisfied condition "Succeeded or Failed"
Apr 20 07:11:05.493: INFO: Trying to get logs from node node22-wriki pod pod-7a55fcd7-e2dd-4073-b919-2d7d24c45756 container test-container: <nil>
STEP: delete the pod
Apr 20 07:11:05.506: INFO: Waiting for pod pod-7a55fcd7-e2dd-4073-b919-2d7d24c45756 to disappear
Apr 20 07:11:05.508: INFO: Pod pod-7a55fcd7-e2dd-4073-b919-2d7d24c45756 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:11:05.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6070" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":341,"skipped":6014,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:11:05.518: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:92
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:107
STEP: Creating service test in namespace statefulset-6197
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a new StatefulSet
Apr 20 07:11:05.562: INFO: Found 0 stateful pods, waiting for 3
Apr 20 07:11:15.568: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 20 07:11:15.568: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 20 07:11:15.568: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr 20 07:11:15.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=statefulset-6197 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 20 07:11:15.698: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 20 07:11:15.698: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 20 07:11:15.698: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 to k8s.gcr.io/e2e-test-images/httpd:2.4.39-1
Apr 20 07:11:25.728: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Apr 20 07:11:35.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=statefulset-6197 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 20 07:11:35.869: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 20 07:11:35.869: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 20 07:11:35.869: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

STEP: Rolling back to a previous revision
Apr 20 07:11:45.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=statefulset-6197 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 20 07:11:46.010: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 20 07:11:46.010: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 20 07:11:46.010: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 20 07:11:56.043: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Apr 20 07:12:06.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-500455158 --namespace=statefulset-6197 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 20 07:12:06.181: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 20 07:12:06.181: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 20 07:12:06.181: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:118
Apr 20 07:12:16.198: INFO: Deleting all statefulset in ns statefulset-6197
Apr 20 07:12:16.200: INFO: Scaling statefulset ss2 to 0
Apr 20 07:12:26.214: INFO: Waiting for statefulset status.replicas updated to 0
Apr 20 07:12:26.217: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:12:26.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6197" for this suite.

• [SLOW TEST:80.718 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:97
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":346,"completed":342,"skipped":6021,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:12:26.238: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:90
Apr 20 07:12:26.271: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 20 07:12:26.276: INFO: Waiting for terminating namespaces to be deleted...
Apr 20 07:12:26.278: INFO: 
Logging pods the apiserver thinks is on node node22-07idr before test
Apr 20 07:12:26.281: INFO: canal-7z4s7 from kube-system started at 2022-04-20 05:37:05 +0000 UTC (2 container statuses recorded)
Apr 20 07:12:26.281: INFO: 	Container calico-node ready: true, restart count 0
Apr 20 07:12:26.282: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 20 07:12:26.282: INFO: konnectivity-agent-z8v6h from kube-system started at 2022-04-20 05:37:24 +0000 UTC (1 container statuses recorded)
Apr 20 07:12:26.282: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 20 07:12:26.282: INFO: sonobuoy-e2e-job-14e586816b6a497d from sonobuoy started at 2022-04-20 05:49:38 +0000 UTC (2 container statuses recorded)
Apr 20 07:12:26.282: INFO: 	Container e2e ready: true, restart count 0
Apr 20 07:12:26.282: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 20 07:12:26.282: INFO: sonobuoy-systemd-logs-daemon-set-cdcdd281c10f40dc-vvhct from sonobuoy started at 2022-04-20 05:49:38 +0000 UTC (2 container statuses recorded)
Apr 20 07:12:26.282: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 20 07:12:26.282: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 20 07:12:26.282: INFO: 
Logging pods the apiserver thinks is on node node22-hwh1v before test
Apr 20 07:12:26.286: INFO: calico-kube-controllers-5544f8d8d9-2pr5d from kube-system started at 2022-04-20 05:37:23 +0000 UTC (1 container statuses recorded)
Apr 20 07:12:26.286: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 20 07:12:26.286: INFO: canal-xrqg4 from kube-system started at 2022-04-20 05:37:04 +0000 UTC (2 container statuses recorded)
Apr 20 07:12:26.286: INFO: 	Container calico-node ready: true, restart count 0
Apr 20 07:12:26.286: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 20 07:12:26.286: INFO: coredns-748f75f5fb-2n9dt from kube-system started at 2022-04-20 05:37:23 +0000 UTC (1 container statuses recorded)
Apr 20 07:12:26.286: INFO: 	Container coredns ready: true, restart count 0
Apr 20 07:12:26.287: INFO: coredns-748f75f5fb-8sfr7 from kube-system started at 2022-04-20 05:37:23 +0000 UTC (1 container statuses recorded)
Apr 20 07:12:26.287: INFO: 	Container coredns ready: true, restart count 0
Apr 20 07:12:26.287: INFO: konnectivity-agent-9q5dq from kube-system started at 2022-04-20 05:37:23 +0000 UTC (1 container statuses recorded)
Apr 20 07:12:26.287: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 20 07:12:26.287: INFO: sonobuoy-systemd-logs-daemon-set-cdcdd281c10f40dc-dc45f from sonobuoy started at 2022-04-20 05:49:38 +0000 UTC (2 container statuses recorded)
Apr 20 07:12:26.287: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 20 07:12:26.287: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 20 07:12:26.287: INFO: 
Logging pods the apiserver thinks is on node node22-wriki before test
Apr 20 07:12:26.290: INFO: canal-r5jz2 from kube-system started at 2022-04-20 05:37:06 +0000 UTC (2 container statuses recorded)
Apr 20 07:12:26.290: INFO: 	Container calico-node ready: true, restart count 0
Apr 20 07:12:26.290: INFO: 	Container kube-flannel ready: true, restart count 0
Apr 20 07:12:26.290: INFO: konnectivity-agent-vgl4v from kube-system started at 2022-04-20 06:27:48 +0000 UTC (1 container statuses recorded)
Apr 20 07:12:26.290: INFO: 	Container konnectivity-agent ready: true, restart count 0
Apr 20 07:12:26.290: INFO: sonobuoy from sonobuoy started at 2022-04-20 05:49:32 +0000 UTC (1 container statuses recorded)
Apr 20 07:12:26.290: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 20 07:12:26.290: INFO: sonobuoy-systemd-logs-daemon-set-cdcdd281c10f40dc-48vdz from sonobuoy started at 2022-04-20 05:49:39 +0000 UTC (2 container statuses recorded)
Apr 20 07:12:26.290: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 20 07:12:26.290: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-fac5a774-4785-458b-b56a-de61df67758d 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.100.99.219 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-fac5a774-4785-458b-b56a-de61df67758d off the node node22-wriki
STEP: verifying the node doesn't have the label kubernetes.io/e2e-fac5a774-4785-458b-b56a-de61df67758d
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:17:30.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4810" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81

• [SLOW TEST:304.149 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":346,"completed":343,"skipped":6055,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:17:30.389: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
Apr 20 07:17:30.433: INFO: Creating deployment "test-recreate-deployment"
Apr 20 07:17:30.437: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr 20 07:17:30.441: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Apr 20 07:17:32.447: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr 20 07:17:32.449: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr 20 07:17:32.455: INFO: Updating deployment test-recreate-deployment
Apr 20 07:17:32.455: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Apr 20 07:17:32.526: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-9439  b3321a95-0c60-4de9-b9fb-6c3f162cf757 41211 2 2022-04-20 07:17:30 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-04-20 07:17:32 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-20 07:17:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00545b018 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-04-20 07:17:32 +0000 UTC,LastTransitionTime:2022-04-20 07:17:32 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-85d47dcb4" is progressing.,LastUpdateTime:2022-04-20 07:17:32 +0000 UTC,LastTransitionTime:2022-04-20 07:17:30 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Apr 20 07:17:32.528: INFO: New ReplicaSet "test-recreate-deployment-85d47dcb4" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-85d47dcb4  deployment-9439  952ff2cd-3638-4ff5-a025-31d64cff53c7 41206 1 2022-04-20 07:17:32 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:85d47dcb4] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment b3321a95-0c60-4de9-b9fb-6c3f162cf757 0xc00545b510 0xc00545b511}] []  [{kube-controller-manager Update apps/v1 2022-04-20 07:17:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b3321a95-0c60-4de9-b9fb-6c3f162cf757\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-20 07:17:32 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 85d47dcb4,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:85d47dcb4] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00545b5a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 20 07:17:32.528: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr 20 07:17:32.528: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-6cb8b65c46  deployment-9439  c2def634-222b-4b7b-838a-f1b28a59165a 41199 2 2022-04-20 07:17:30 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:6cb8b65c46] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment b3321a95-0c60-4de9-b9fb-6c3f162cf757 0xc00545b3f7 0xc00545b3f8}] []  [{kube-controller-manager Update apps/v1 2022-04-20 07:17:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b3321a95-0c60-4de9-b9fb-6c3f162cf757\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-04-20 07:17:32 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6cb8b65c46,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:6cb8b65c46] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.32 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00545b4a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 20 07:17:32.530: INFO: Pod "test-recreate-deployment-85d47dcb4-fcznc" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-85d47dcb4-fcznc test-recreate-deployment-85d47dcb4- deployment-9439  6ae6b216-7842-400b-87fc-ddc059e9c8e7 41210 0 2022-04-20 07:17:32 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:85d47dcb4] map[] [{apps/v1 ReplicaSet test-recreate-deployment-85d47dcb4 952ff2cd-3638-4ff5-a025-31d64cff53c7 0xc00545ba60 0xc00545ba61}] []  [{kube-controller-manager Update v1 2022-04-20 07:17:32 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"952ff2cd-3638-4ff5-a025-31d64cff53c7\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-04-20 07:17:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pc8qt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pc8qt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node22-hwh1v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 07:17:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 07:17:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 07:17:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-04-20 07:17:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.125.144,PodIP:,StartTime:2022-04-20 07:17:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:17:32.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9439" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":346,"completed":344,"skipped":6081,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
SSSSS
------------------------------
[sig-node] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[BeforeEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Apr 20 07:17:32.539: INFO: >>> kubeConfig: /tmp/kubeconfig-500455158
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test override arguments
Apr 20 07:17:32.633: INFO: Waiting up to 5m0s for pod "client-containers-8968a85d-8e10-4233-b79f-4e1da7a5471e" in namespace "containers-3990" to be "Succeeded or Failed"
Apr 20 07:17:32.635: INFO: Pod "client-containers-8968a85d-8e10-4233-b79f-4e1da7a5471e": Phase="Pending", Reason="", readiness=false. Elapsed: 1.899681ms
Apr 20 07:17:34.640: INFO: Pod "client-containers-8968a85d-8e10-4233-b79f-4e1da7a5471e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007092144s
STEP: Saw pod success
Apr 20 07:17:34.640: INFO: Pod "client-containers-8968a85d-8e10-4233-b79f-4e1da7a5471e" satisfied condition "Succeeded or Failed"
Apr 20 07:17:34.642: INFO: Trying to get logs from node node22-hwh1v pod client-containers-8968a85d-8e10-4233-b79f-4e1da7a5471e container agnhost-container: <nil>
STEP: delete the pod
Apr 20 07:17:34.664: INFO: Waiting for pod client-containers-8968a85d-8e10-4233-b79f-4e1da7a5471e to disappear
Apr 20 07:17:34.665: INFO: Pod client-containers-8968a85d-8e10-4233-b79f-4e1da7a5471e no longer exists
[AfterEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Apr 20 07:17:34.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3990" for this suite.
•{"msg":"PASSED [sig-node] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]","total":346,"completed":345,"skipped":6086,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}
Apr 20 07:17:34.674: INFO: Running AfterSuite actions on all nodes
Apr 20 07:17:34.674: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func17.2
Apr 20 07:17:34.674: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func8.2
Apr 20 07:17:34.674: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func7.2
Apr 20 07:17:34.675: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Apr 20 07:17:34.676: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Apr 20 07:17:34.676: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Apr 20 07:17:34.676: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
Apr 20 07:17:34.676: INFO: Running AfterSuite actions on node 1
Apr 20 07:17:34.676: INFO: Skipping dumping logs from cluster

JUnit report was created: /tmp/sonobuoy/results/junit_01.xml
{"msg":"Test Suite completed","total":346,"completed":345,"skipped":6086,"failed":1,"failures":["[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]"]}


Summarizing 1 Failure:

[Fail] [sig-node] Probing container [It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] 
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:701

Ran 346 of 6432 Specs in 5258.362 seconds
FAIL! -- 345 Passed | 1 Failed | 0 Pending | 6086 Skipped
--- FAIL: TestE2E (5259.95s)
FAIL

Ginkgo ran 1 suite in 1h27m40.047074371s
Test Suite Failed

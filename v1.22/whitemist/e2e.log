Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1651521283 - Will randomize all specs
Will run 6433 specs

Running in parallel across 2 nodes

May  2 19:54:48.580: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
May  2 19:54:48.585: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
May  2 19:54:48.628: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May  2 19:54:48.749: INFO: 29 / 29 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May  2 19:54:48.749: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
May  2 19:54:48.749: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
May  2 19:54:48.787: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
May  2 19:54:48.787: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
May  2 19:54:48.787: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-vip-ds' (0 seconds elapsed)
May  2 19:54:48.787: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'nodelocaldns' (0 seconds elapsed)
May  2 19:54:48.787: INFO: e2e test version: v1.22.5
May  2 19:54:48.789: INFO: kube-apiserver version: v1.22.5
May  2 19:54:48.799: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
May  2 19:54:49.038: INFO: Cluster IP family: ipv4

SSSSSSSSSSSSSSS
------------------------------
May  2 19:54:48.999: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
May  2 19:54:49.088: INFO: Cluster IP family: ipv4

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:54:49.217: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename emptydir
W0502 19:54:49.364632      19 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+
May  2 19:54:49.364: INFO: Found PodSecurityPolicies; testing pod creation to see if PodSecurityPolicy is enabled
May  2 19:54:49.401: INFO: No PSP annotation exists on dry run pod; assuming PodSecurityPolicy is disabled
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0644 on node default medium
May  2 19:54:49.422: INFO: Waiting up to 5m0s for pod "pod-e12aa6db-ff2c-4d2a-bccf-396575b06700" in namespace "emptydir-1565" to be "Succeeded or Failed"
May  2 19:54:49.434: INFO: Pod "pod-e12aa6db-ff2c-4d2a-bccf-396575b06700": Phase="Pending", Reason="", readiness=false. Elapsed: 11.984508ms
May  2 19:54:51.459: INFO: Pod "pod-e12aa6db-ff2c-4d2a-bccf-396575b06700": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036609196s
May  2 19:54:53.521: INFO: Pod "pod-e12aa6db-ff2c-4d2a-bccf-396575b06700": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.098684204s
STEP: Saw pod success
May  2 19:54:53.521: INFO: Pod "pod-e12aa6db-ff2c-4d2a-bccf-396575b06700" satisfied condition "Succeeded or Failed"
May  2 19:54:53.547: INFO: Trying to get logs from node node-2 pod pod-e12aa6db-ff2c-4d2a-bccf-396575b06700 container test-container: <nil>
STEP: delete the pod
May  2 19:54:53.673: INFO: Waiting for pod pod-e12aa6db-ff2c-4d2a-bccf-396575b06700 to disappear
May  2 19:54:53.683: INFO: Pod pod-e12aa6db-ff2c-4d2a-bccf-396575b06700 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:54:53.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1565" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":1,"skipped":37,"failed":0}

SSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:54:49.205: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename disruption
W0502 19:54:49.350496      18 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+
May  2 19:54:49.351: INFO: Found PodSecurityPolicies; testing pod creation to see if PodSecurityPolicy is enabled
May  2 19:54:49.398: INFO: No PSP annotation exists on dry run pod; assuming PodSecurityPolicy is disabled
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:69
[It] should update/patch PodDisruptionBudget status [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Waiting for the pdb to be processed
STEP: Updating PodDisruptionBudget status
STEP: Waiting for all pods to be running
May  2 19:54:51.492: INFO: running pods: 0 < 1
May  2 19:54:53.505: INFO: running pods: 0 < 1
STEP: locating a running pod
STEP: Waiting for the pdb to be processed
STEP: Patching PodDisruptionBudget status
STEP: Waiting for the pdb to be processed
[AfterEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:54:55.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-9875" for this suite.


• [SLOW TEST:6.473 seconds]
[sig-apps] DisruptionController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","total":-1,"completed":1,"skipped":43,"failed":0}

SSS
------------------------------
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:54:55.686: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a volume subpath [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test substitution in volume subpath
May  2 19:54:55.803: INFO: Waiting up to 5m0s for pod "var-expansion-802a3f03-9447-4e7a-b1ae-c1fd7ef516a0" in namespace "var-expansion-9056" to be "Succeeded or Failed"
May  2 19:54:55.826: INFO: Pod "var-expansion-802a3f03-9447-4e7a-b1ae-c1fd7ef516a0": Phase="Pending", Reason="", readiness=false. Elapsed: 23.112127ms
May  2 19:54:57.837: INFO: Pod "var-expansion-802a3f03-9447-4e7a-b1ae-c1fd7ef516a0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033443348s
May  2 19:54:59.852: INFO: Pod "var-expansion-802a3f03-9447-4e7a-b1ae-c1fd7ef516a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048999781s
STEP: Saw pod success
May  2 19:54:59.852: INFO: Pod "var-expansion-802a3f03-9447-4e7a-b1ae-c1fd7ef516a0" satisfied condition "Succeeded or Failed"
May  2 19:54:59.865: INFO: Trying to get logs from node node-2 pod var-expansion-802a3f03-9447-4e7a-b1ae-c1fd7ef516a0 container dapi-container: <nil>
STEP: delete the pod
May  2 19:54:59.971: INFO: Waiting for pod var-expansion-802a3f03-9447-4e7a-b1ae-c1fd7ef516a0 to disappear
May  2 19:54:59.982: INFO: Pod var-expansion-802a3f03-9447-4e7a-b1ae-c1fd7ef516a0 no longer exists
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:54:59.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9056" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","total":-1,"completed":2,"skipped":46,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:54:53.791: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:188
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
STEP: submitting the pod to kubernetes
May  2 19:54:53.918: INFO: The status of Pod pod-update-activedeadlineseconds-b7fd9f72-dc68-4f43-9275-a5d8b39389d7 is Pending, waiting for it to be Running (with Ready = true)
May  2 19:54:55.931: INFO: The status of Pod pod-update-activedeadlineseconds-b7fd9f72-dc68-4f43-9275-a5d8b39389d7 is Pending, waiting for it to be Running (with Ready = true)
May  2 19:54:57.936: INFO: The status of Pod pod-update-activedeadlineseconds-b7fd9f72-dc68-4f43-9275-a5d8b39389d7 is Running (Ready = true)
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May  2 19:54:58.495: INFO: Successfully updated pod "pod-update-activedeadlineseconds-b7fd9f72-dc68-4f43-9275-a5d8b39389d7"
May  2 19:54:58.495: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-b7fd9f72-dc68-4f43-9275-a5d8b39389d7" in namespace "pods-9892" to be "terminated due to deadline exceeded"
May  2 19:54:58.518: INFO: Pod "pod-update-activedeadlineseconds-b7fd9f72-dc68-4f43-9275-a5d8b39389d7": Phase="Running", Reason="", readiness=true. Elapsed: 23.240817ms
May  2 19:55:00.538: INFO: Pod "pod-update-activedeadlineseconds-b7fd9f72-dc68-4f43-9275-a5d8b39389d7": Phase="Failed", Reason="DeadlineExceeded", readiness=true. Elapsed: 2.043066558s
May  2 19:55:00.538: INFO: Pod "pod-update-activedeadlineseconds-b7fd9f72-dc68-4f43-9275-a5d8b39389d7" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:55:00.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9892" for this suite.


• [SLOW TEST:6.782 seconds]
[sig-node] Pods
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":-1,"completed":2,"skipped":54,"failed":0}

SSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:55:00.101: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
May  2 19:55:00.368: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9bd2d9cb-4e80-4501-8184-428b5f0bfcaa" in namespace "downward-api-1418" to be "Succeeded or Failed"
May  2 19:55:00.433: INFO: Pod "downwardapi-volume-9bd2d9cb-4e80-4501-8184-428b5f0bfcaa": Phase="Pending", Reason="", readiness=false. Elapsed: 64.933804ms
May  2 19:55:02.455: INFO: Pod "downwardapi-volume-9bd2d9cb-4e80-4501-8184-428b5f0bfcaa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.086085972s
May  2 19:55:04.467: INFO: Pod "downwardapi-volume-9bd2d9cb-4e80-4501-8184-428b5f0bfcaa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.09799021s
STEP: Saw pod success
May  2 19:55:04.467: INFO: Pod "downwardapi-volume-9bd2d9cb-4e80-4501-8184-428b5f0bfcaa" satisfied condition "Succeeded or Failed"
May  2 19:55:04.476: INFO: Trying to get logs from node node-2 pod downwardapi-volume-9bd2d9cb-4e80-4501-8184-428b5f0bfcaa container client-container: <nil>
STEP: delete the pod
May  2 19:55:04.535: INFO: Waiting for pod downwardapi-volume-9bd2d9cb-4e80-4501-8184-428b5f0bfcaa to disappear
May  2 19:55:04.541: INFO: Pod downwardapi-volume-9bd2d9cb-4e80-4501-8184-428b5f0bfcaa no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:55:04.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1418" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":-1,"completed":3,"skipped":77,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:55:04.650: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward api env vars
May  2 19:55:04.820: INFO: Waiting up to 5m0s for pod "downward-api-5827c81e-f736-428c-af9a-5fbe25dfa808" in namespace "downward-api-2025" to be "Succeeded or Failed"
May  2 19:55:04.849: INFO: Pod "downward-api-5827c81e-f736-428c-af9a-5fbe25dfa808": Phase="Pending", Reason="", readiness=false. Elapsed: 28.59502ms
May  2 19:55:06.908: INFO: Pod "downward-api-5827c81e-f736-428c-af9a-5fbe25dfa808": Phase="Pending", Reason="", readiness=false. Elapsed: 2.087543339s
May  2 19:55:08.951: INFO: Pod "downward-api-5827c81e-f736-428c-af9a-5fbe25dfa808": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.131050078s
STEP: Saw pod success
May  2 19:55:08.952: INFO: Pod "downward-api-5827c81e-f736-428c-af9a-5fbe25dfa808" satisfied condition "Succeeded or Failed"
May  2 19:55:08.968: INFO: Trying to get logs from node node-2 pod downward-api-5827c81e-f736-428c-af9a-5fbe25dfa808 container dapi-container: <nil>
STEP: delete the pod
May  2 19:55:09.060: INFO: Waiting for pod downward-api-5827c81e-f736-428c-af9a-5fbe25dfa808 to disappear
May  2 19:55:09.079: INFO: Pod downward-api-5827c81e-f736-428c-af9a-5fbe25dfa808 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:55:09.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2025" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":-1,"completed":4,"skipped":107,"failed":0}

SSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-instrumentation] Events
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:55:09.200: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a collection of events [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create set of events
May  2 19:55:09.356: INFO: created test-event-1
May  2 19:55:09.375: INFO: created test-event-2
May  2 19:55:09.392: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace
STEP: delete collection of events
May  2 19:55:09.429: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity
May  2 19:55:09.511: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:55:09.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-2284" for this suite.

•
------------------------------
{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","total":-1,"completed":5,"skipped":124,"failed":0}

SSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:55:09.596: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:52
STEP: create the container to handle the HTTPGet hook request.
May  2 19:55:09.763: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
May  2 19:55:11.771: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
May  2 19:55:13.775: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the pod with lifecycle hook
May  2 19:55:13.817: INFO: The status of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
May  2 19:55:15.829: INFO: The status of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
May  2 19:55:17.833: INFO: The status of Pod pod-with-poststart-exec-hook is Running (Ready = true)
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May  2 19:55:17.895: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May  2 19:55:17.909: INFO: Pod pod-with-poststart-exec-hook still exists
May  2 19:55:19.909: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May  2 19:55:19.929: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:55:19.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7564" for this suite.


• [SLOW TEST:10.372 seconds]
[sig-node] Container Lifecycle Hook
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:43
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":-1,"completed":6,"skipped":133,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:55:00.626: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service endpoint-test2 in namespace services-8974
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8974 to expose endpoints map[]
May  2 19:55:00.920: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
May  2 19:55:01.969: INFO: successfully validated that service endpoint-test2 in namespace services-8974 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-8974
May  2 19:55:02.001: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
May  2 19:55:04.015: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
May  2 19:55:06.022: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8974 to expose endpoints map[pod1:[80]]
May  2 19:55:06.068: INFO: successfully validated that service endpoint-test2 in namespace services-8974 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1
May  2 19:55:06.068: INFO: Creating new exec pod
May  2 19:55:11.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-8974 exec execpod4s6zx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
May  2 19:55:12.097: INFO: stderr: "+ + echo hostName\nnc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
May  2 19:55:12.097: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 19:55:12.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-8974 exec execpod4s6zx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.12.2 80'
May  2 19:55:12.531: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.12.2 80\nConnection to 10.233.12.2 80 port [tcp/http] succeeded!\n"
May  2 19:55:12.531: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-8974
May  2 19:55:12.574: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
May  2 19:55:14.586: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
May  2 19:55:16.591: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8974 to expose endpoints map[pod1:[80] pod2:[80]]
May  2 19:55:16.647: INFO: successfully validated that service endpoint-test2 in namespace services-8974 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2
May  2 19:55:17.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-8974 exec execpod4s6zx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
May  2 19:55:17.955: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
May  2 19:55:17.955: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 19:55:17.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-8974 exec execpod4s6zx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.12.2 80'
May  2 19:55:18.266: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.12.2 80\nConnection to 10.233.12.2 80 port [tcp/http] succeeded!\n"
May  2 19:55:18.266: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-8974
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8974 to expose endpoints map[pod2:[80]]
May  2 19:55:19.387: INFO: successfully validated that service endpoint-test2 in namespace services-8974 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2
May  2 19:55:20.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-8974 exec execpod4s6zx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
May  2 19:55:20.742: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
May  2 19:55:20.743: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 19:55:20.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-8974 exec execpod4s6zx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.12.2 80'
May  2 19:55:21.267: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.12.2 80\nConnection to 10.233.12.2 80 port [tcp/http] succeeded!\n"
May  2 19:55:21.267: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-8974
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8974 to expose endpoints map[]
May  2 19:55:21.361: INFO: successfully validated that service endpoint-test2 in namespace services-8974 exposes endpoints map[]
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:55:21.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8974" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753


• [SLOW TEST:20.881 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":-1,"completed":3,"skipped":63,"failed":0}

SSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:55:21.636: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:55:28.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5369" for this suite.


• [SLOW TEST:7.198 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":-1,"completed":4,"skipped":74,"failed":0}

SSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:55:20.028: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod pod-subpath-test-configmap-zkpk
STEP: Creating a pod to test atomic-volume-subpath
May  2 19:55:20.270: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-zkpk" in namespace "subpath-1305" to be "Succeeded or Failed"
May  2 19:55:20.286: INFO: Pod "pod-subpath-test-configmap-zkpk": Phase="Pending", Reason="", readiness=false. Elapsed: 16.270758ms
May  2 19:55:22.318: INFO: Pod "pod-subpath-test-configmap-zkpk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048149597s
May  2 19:55:24.328: INFO: Pod "pod-subpath-test-configmap-zkpk": Phase="Running", Reason="", readiness=true. Elapsed: 4.05832128s
May  2 19:55:26.338: INFO: Pod "pod-subpath-test-configmap-zkpk": Phase="Running", Reason="", readiness=true. Elapsed: 6.067945389s
May  2 19:55:28.345: INFO: Pod "pod-subpath-test-configmap-zkpk": Phase="Running", Reason="", readiness=true. Elapsed: 8.075330602s
May  2 19:55:30.382: INFO: Pod "pod-subpath-test-configmap-zkpk": Phase="Running", Reason="", readiness=true. Elapsed: 10.111909279s
May  2 19:55:32.397: INFO: Pod "pod-subpath-test-configmap-zkpk": Phase="Running", Reason="", readiness=true. Elapsed: 12.126974813s
May  2 19:55:34.410: INFO: Pod "pod-subpath-test-configmap-zkpk": Phase="Running", Reason="", readiness=true. Elapsed: 14.139874315s
May  2 19:55:36.419: INFO: Pod "pod-subpath-test-configmap-zkpk": Phase="Running", Reason="", readiness=true. Elapsed: 16.149218768s
May  2 19:55:38.427: INFO: Pod "pod-subpath-test-configmap-zkpk": Phase="Running", Reason="", readiness=true. Elapsed: 18.157279699s
May  2 19:55:40.440: INFO: Pod "pod-subpath-test-configmap-zkpk": Phase="Running", Reason="", readiness=true. Elapsed: 20.169982337s
May  2 19:55:42.449: INFO: Pod "pod-subpath-test-configmap-zkpk": Phase="Running", Reason="", readiness=true. Elapsed: 22.179287169s
May  2 19:55:44.467: INFO: Pod "pod-subpath-test-configmap-zkpk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.196844776s
STEP: Saw pod success
May  2 19:55:44.467: INFO: Pod "pod-subpath-test-configmap-zkpk" satisfied condition "Succeeded or Failed"
May  2 19:55:44.486: INFO: Trying to get logs from node node-2 pod pod-subpath-test-configmap-zkpk container test-container-subpath-configmap-zkpk: <nil>
STEP: delete the pod
May  2 19:55:44.547: INFO: Waiting for pod pod-subpath-test-configmap-zkpk to disappear
May  2 19:55:44.553: INFO: Pod pod-subpath-test-configmap-zkpk no longer exists
STEP: Deleting pod pod-subpath-test-configmap-zkpk
May  2 19:55:44.554: INFO: Deleting pod "pod-subpath-test-configmap-zkpk" in namespace "subpath-1305"
[AfterEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:55:44.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1305" for this suite.


• [SLOW TEST:24.575 seconds]
[sig-storage] Subpath
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]","total":-1,"completed":7,"skipped":157,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:55:28.866: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
STEP: waiting for pod running
STEP: creating a file in subpath
May  2 19:55:33.047: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-7670 PodName:var-expansion-b1173925-b580-4254-9d21-5fef4efae1bd ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 19:55:33.048: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: test for file in mounted path
May  2 19:55:33.312: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-7670 PodName:var-expansion-b1173925-b580-4254-9d21-5fef4efae1bd ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 19:55:33.312: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: updating the annotation value
May  2 19:55:34.071: INFO: Successfully updated pod "var-expansion-b1173925-b580-4254-9d21-5fef4efae1bd"
STEP: waiting for annotated pod running
STEP: deleting the pod gracefully
May  2 19:55:34.098: INFO: Deleting pod "var-expansion-b1173925-b580-4254-9d21-5fef4efae1bd" in namespace "var-expansion-7670"
May  2 19:55:34.119: INFO: Wait up to 5m0s for pod "var-expansion-b1173925-b580-4254-9d21-5fef4efae1bd" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:56:08.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7670" for this suite.


• [SLOW TEST:39.336 seconds]
[sig-node] Variable Expansion
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","total":-1,"completed":5,"skipped":88,"failed":0}

SSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:56:08.224: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-upd-32feaea1-70c6-4759-812e-dcaeffd10a00
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:56:12.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6395" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":-1,"completed":6,"skipped":105,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:56:12.680: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support --unix-socket=/path  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Starting the proxy
May  2 19:56:12.781: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6506 proxy --unix-socket=/tmp/kubectl-proxy-unix109066267/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:56:12.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6506" for this suite.

•
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":-1,"completed":7,"skipped":152,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:56:13.018: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  2 19:56:14.265: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
May  2 19:56:16.339: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118174, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118174, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118174, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118174, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  2 19:56:19.391: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 19:56:19.400: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:56:27.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6911" for this suite.
STEP: Destroying namespace "webhook-6911-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102


• [SLOW TEST:14.463 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":-1,"completed":8,"skipped":188,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:55:44.812: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/init_container.go:162
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
May  2 19:55:44.915: INFO: PodSpec: initContainers in spec.initContainers
May  2 19:56:29.864: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-19260518-3dd5-4092-a783-38de9b8789f1", GenerateName:"", Namespace:"init-container-3146", SelfLink:"", UID:"272a09e0-5929-4e59-8b2b-a408144f03e6", ResourceVersion:"2861454", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63787118144, loc:(*time.Location)(0xa0a4dc0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"915907730"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"2e8be56d7d9b49345ba83e5b653e6f88b4aae0287b1efa0acc83b38b33af9fc4", "cni.projectcalico.org/podIP":"10.233.69.51/32", "cni.projectcalico.org/podIPs":"10.233.69.51/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc0047a4678), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0047a4690), Subresource:""}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc0047a46a8), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0047a46c0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc0047a46d8), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0047a46f0), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-5ffhl", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0047c2180), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-1", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-5ffhl", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-1", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-5ffhl", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.5", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-5ffhl", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00467b6d8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"node-2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0037e6000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00467b760)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00467b780)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00467b788), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00467b78c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc0047ae3c0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118144, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118144, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118144, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118144, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.100.20.46", PodIP:"10.233.69.51", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.233.69.51"}}, StartTime:(*v1.Time)(0xc0047a4720), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0037e60e0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0037e6150)}, Ready:false, RestartCount:3, Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-1", ImageID:"docker-pullable://k8s.gcr.io/e2e-test-images/busybox@sha256:39e1e963e5310e9c313bad51523be012ede7b35bb9316517d19089a010356592", ContainerID:"docker://8147970108b778a70965e8994cd809017d842dfc51deed23d875f8845c728f9f", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0047c2200), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-1", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0047c21e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.5", ImageID:"", ContainerID:"", Started:(*bool)(0xc00467b80f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:56:29.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3146" for this suite.


• [SLOW TEST:45.122 seconds]
[sig-node] InitContainer [NodeConformance]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":-1,"completed":8,"skipped":214,"failed":0}

SSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:56:30.015: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
May  2 19:56:30.189: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ddfdf90d-9375-489f-aad2-8a08d5d5140c" in namespace "projected-1528" to be "Succeeded or Failed"
May  2 19:56:30.207: INFO: Pod "downwardapi-volume-ddfdf90d-9375-489f-aad2-8a08d5d5140c": Phase="Pending", Reason="", readiness=false. Elapsed: 17.499412ms
May  2 19:56:32.229: INFO: Pod "downwardapi-volume-ddfdf90d-9375-489f-aad2-8a08d5d5140c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039350453s
May  2 19:56:34.248: INFO: Pod "downwardapi-volume-ddfdf90d-9375-489f-aad2-8a08d5d5140c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059089735s
STEP: Saw pod success
May  2 19:56:34.249: INFO: Pod "downwardapi-volume-ddfdf90d-9375-489f-aad2-8a08d5d5140c" satisfied condition "Succeeded or Failed"
May  2 19:56:34.255: INFO: Trying to get logs from node node-0 pod downwardapi-volume-ddfdf90d-9375-489f-aad2-8a08d5d5140c container client-container: <nil>
STEP: delete the pod
May  2 19:56:34.393: INFO: Waiting for pod downwardapi-volume-ddfdf90d-9375-489f-aad2-8a08d5d5140c to disappear
May  2 19:56:34.402: INFO: Pod downwardapi-volume-ddfdf90d-9375-489f-aad2-8a08d5d5140c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:56:34.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1528" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":-1,"completed":9,"skipped":227,"failed":0}

SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:56:34.524: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 19:56:34.693: INFO: Got root ca configmap in namespace "svcaccounts-4734"
May  2 19:56:34.717: INFO: Deleted root ca configmap in namespace "svcaccounts-4734"
STEP: waiting for a new root ca configmap created
May  2 19:56:35.226: INFO: Recreated root ca configmap in namespace "svcaccounts-4734"
May  2 19:56:35.237: INFO: Updated root ca configmap in namespace "svcaccounts-4734"
STEP: waiting for the root ca configmap reconciled
May  2 19:56:35.757: INFO: Reconciled root ca configmap in namespace "svcaccounts-4734"
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:56:35.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4734" for this suite.

•
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","total":-1,"completed":10,"skipped":249,"failed":0}
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:56:35.822: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount projected service account token [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test service account token: 
May  2 19:56:36.027: INFO: Waiting up to 5m0s for pod "test-pod-9a9bb293-5b64-4dd7-a640-c29311839863" in namespace "svcaccounts-8254" to be "Succeeded or Failed"
May  2 19:56:36.043: INFO: Pod "test-pod-9a9bb293-5b64-4dd7-a640-c29311839863": Phase="Pending", Reason="", readiness=false. Elapsed: 15.289086ms
May  2 19:56:38.078: INFO: Pod "test-pod-9a9bb293-5b64-4dd7-a640-c29311839863": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050223055s
May  2 19:56:40.090: INFO: Pod "test-pod-9a9bb293-5b64-4dd7-a640-c29311839863": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.062949999s
STEP: Saw pod success
May  2 19:56:40.090: INFO: Pod "test-pod-9a9bb293-5b64-4dd7-a640-c29311839863" satisfied condition "Succeeded or Failed"
May  2 19:56:40.113: INFO: Trying to get logs from node node-0 pod test-pod-9a9bb293-5b64-4dd7-a640-c29311839863 container agnhost-container: <nil>
STEP: delete the pod
May  2 19:56:40.165: INFO: Waiting for pod test-pod-9a9bb293-5b64-4dd7-a640-c29311839863 to disappear
May  2 19:56:40.174: INFO: Pod test-pod-9a9bb293-5b64-4dd7-a640-c29311839863 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:56:40.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8254" for this suite.

•
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","total":-1,"completed":11,"skipped":249,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:56:40.313: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
May  2 19:56:40.487: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering the sample API server.
May  2 19:56:41.055: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
May  2 19:56:43.276: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118201, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118201, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118201, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118201, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-64f6b9dc99\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  2 19:56:45.970: INFO: Waited 631.110395ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}'
STEP: List APIServices
May  2 19:56:46.292: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:56:47.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-3456" for this suite.


• [SLOW TEST:6.762 seconds]
[sig-api-machinery] Aggregator
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","total":-1,"completed":12,"skipped":275,"failed":0}

SSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:56:47.094: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-map-a250a379-589f-4ece-92f2-c06697322051
STEP: Creating a pod to test consume secrets
May  2 19:56:47.251: INFO: Waiting up to 5m0s for pod "pod-secrets-51b0c82a-2a55-4358-b20b-7357ba67d47b" in namespace "secrets-2055" to be "Succeeded or Failed"
May  2 19:56:47.269: INFO: Pod "pod-secrets-51b0c82a-2a55-4358-b20b-7357ba67d47b": Phase="Pending", Reason="", readiness=false. Elapsed: 17.077334ms
May  2 19:56:49.290: INFO: Pod "pod-secrets-51b0c82a-2a55-4358-b20b-7357ba67d47b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038010192s
May  2 19:56:51.301: INFO: Pod "pod-secrets-51b0c82a-2a55-4358-b20b-7357ba67d47b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049650047s
STEP: Saw pod success
May  2 19:56:51.301: INFO: Pod "pod-secrets-51b0c82a-2a55-4358-b20b-7357ba67d47b" satisfied condition "Succeeded or Failed"
May  2 19:56:51.335: INFO: Trying to get logs from node node-2 pod pod-secrets-51b0c82a-2a55-4358-b20b-7357ba67d47b container secret-volume-test: <nil>
STEP: delete the pod
May  2 19:56:51.532: INFO: Waiting for pod pod-secrets-51b0c82a-2a55-4358-b20b-7357ba67d47b to disappear
May  2 19:56:51.557: INFO: Pod pod-secrets-51b0c82a-2a55-4358-b20b-7357ba67d47b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:56:51.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2055" for this suite.

•
------------------------------
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:56:27.838: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Update Demo
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:296
[It] should scale a replication controller  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a replication controller
May  2 19:56:27.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6935 create -f -'
May  2 19:56:30.268: INFO: stderr: ""
May  2 19:56:30.268: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May  2 19:56:30.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6935 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
May  2 19:56:30.452: INFO: stderr: ""
May  2 19:56:30.452: INFO: stdout: "update-demo-nautilus-nr2vx update-demo-nautilus-sgfng "
May  2 19:56:30.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6935 get pods update-demo-nautilus-nr2vx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May  2 19:56:30.598: INFO: stderr: ""
May  2 19:56:30.598: INFO: stdout: ""
May  2 19:56:30.598: INFO: update-demo-nautilus-nr2vx is created but not running
May  2 19:56:35.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6935 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
May  2 19:56:35.767: INFO: stderr: ""
May  2 19:56:35.767: INFO: stdout: "update-demo-nautilus-nr2vx update-demo-nautilus-sgfng "
May  2 19:56:35.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6935 get pods update-demo-nautilus-nr2vx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May  2 19:56:35.909: INFO: stderr: ""
May  2 19:56:35.909: INFO: stdout: "true"
May  2 19:56:35.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6935 get pods update-demo-nautilus-nr2vx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
May  2 19:56:36.080: INFO: stderr: ""
May  2 19:56:36.080: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.4"
May  2 19:56:36.080: INFO: validating pod update-demo-nautilus-nr2vx
May  2 19:56:36.094: INFO: got data: {
  "image": "nautilus.jpg"
}

May  2 19:56:36.094: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  2 19:56:36.094: INFO: update-demo-nautilus-nr2vx is verified up and running
May  2 19:56:36.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6935 get pods update-demo-nautilus-sgfng -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May  2 19:56:36.212: INFO: stderr: ""
May  2 19:56:36.212: INFO: stdout: "true"
May  2 19:56:36.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6935 get pods update-demo-nautilus-sgfng -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
May  2 19:56:36.365: INFO: stderr: ""
May  2 19:56:36.365: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.4"
May  2 19:56:36.365: INFO: validating pod update-demo-nautilus-sgfng
May  2 19:56:36.387: INFO: got data: {
  "image": "nautilus.jpg"
}

May  2 19:56:36.388: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  2 19:56:36.388: INFO: update-demo-nautilus-sgfng is verified up and running
STEP: scaling down the replication controller
May  2 19:56:36.392: INFO: scanned /root for discovery docs: <nil>
May  2 19:56:36.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6935 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
May  2 19:56:37.642: INFO: stderr: ""
May  2 19:56:37.642: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May  2 19:56:37.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6935 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
May  2 19:56:37.802: INFO: stderr: ""
May  2 19:56:37.803: INFO: stdout: "update-demo-nautilus-nr2vx update-demo-nautilus-sgfng "
STEP: Replicas for name=update-demo: expected=1 actual=2
May  2 19:56:42.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6935 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
May  2 19:56:43.137: INFO: stderr: ""
May  2 19:56:43.137: INFO: stdout: "update-demo-nautilus-nr2vx "
May  2 19:56:43.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6935 get pods update-demo-nautilus-nr2vx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May  2 19:56:43.566: INFO: stderr: ""
May  2 19:56:43.566: INFO: stdout: "true"
May  2 19:56:43.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6935 get pods update-demo-nautilus-nr2vx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
May  2 19:56:43.888: INFO: stderr: ""
May  2 19:56:43.888: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.4"
May  2 19:56:43.888: INFO: validating pod update-demo-nautilus-nr2vx
May  2 19:56:43.900: INFO: got data: {
  "image": "nautilus.jpg"
}

May  2 19:56:43.900: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  2 19:56:43.900: INFO: update-demo-nautilus-nr2vx is verified up and running
STEP: scaling up the replication controller
May  2 19:56:43.903: INFO: scanned /root for discovery docs: <nil>
May  2 19:56:43.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6935 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
May  2 19:56:45.212: INFO: stderr: ""
May  2 19:56:45.212: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May  2 19:56:45.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6935 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
May  2 19:56:46.101: INFO: stderr: ""
May  2 19:56:46.101: INFO: stdout: "update-demo-nautilus-5ghqq update-demo-nautilus-nr2vx "
May  2 19:56:46.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6935 get pods update-demo-nautilus-5ghqq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May  2 19:56:46.447: INFO: stderr: ""
May  2 19:56:46.447: INFO: stdout: ""
May  2 19:56:46.447: INFO: update-demo-nautilus-5ghqq is created but not running
May  2 19:56:51.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6935 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
May  2 19:56:51.661: INFO: stderr: ""
May  2 19:56:51.662: INFO: stdout: "update-demo-nautilus-5ghqq update-demo-nautilus-nr2vx "
May  2 19:56:51.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6935 get pods update-demo-nautilus-5ghqq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May  2 19:56:51.978: INFO: stderr: ""
May  2 19:56:51.978: INFO: stdout: "true"
May  2 19:56:51.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6935 get pods update-demo-nautilus-5ghqq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
May  2 19:56:52.240: INFO: stderr: ""
May  2 19:56:52.240: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.4"
May  2 19:56:52.240: INFO: validating pod update-demo-nautilus-5ghqq
May  2 19:56:52.261: INFO: got data: {
  "image": "nautilus.jpg"
}

May  2 19:56:52.262: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  2 19:56:52.262: INFO: update-demo-nautilus-5ghqq is verified up and running
May  2 19:56:52.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6935 get pods update-demo-nautilus-nr2vx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May  2 19:56:52.579: INFO: stderr: ""
May  2 19:56:52.579: INFO: stdout: "true"
May  2 19:56:52.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6935 get pods update-demo-nautilus-nr2vx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
May  2 19:56:52.807: INFO: stderr: ""
May  2 19:56:52.807: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.4"
May  2 19:56:52.807: INFO: validating pod update-demo-nautilus-nr2vx
May  2 19:56:52.819: INFO: got data: {
  "image": "nautilus.jpg"
}

May  2 19:56:52.819: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  2 19:56:52.819: INFO: update-demo-nautilus-nr2vx is verified up and running
STEP: using delete to clean up resources
May  2 19:56:52.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6935 delete --grace-period=0 --force -f -'
May  2 19:56:52.981: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  2 19:56:52.981: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May  2 19:56:52.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6935 get rc,svc -l name=update-demo --no-headers'
May  2 19:56:53.328: INFO: stderr: "No resources found in kubectl-6935 namespace.\n"
May  2 19:56:53.329: INFO: stdout: ""
May  2 19:56:53.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6935 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May  2 19:56:53.610: INFO: stderr: ""
May  2 19:56:53.610: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:56:53.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6935" for this suite.


• [SLOW TEST:25.848 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:294
    should scale a replication controller  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":13,"skipped":284,"failed":0}
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:56:51.615: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/security_context.go:46
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 19:56:51.748: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-65013870-fb8d-4ac0-885f-bd4125704969" in namespace "security-context-test-881" to be "Succeeded or Failed"
May  2 19:56:51.755: INFO: Pod "alpine-nnp-false-65013870-fb8d-4ac0-885f-bd4125704969": Phase="Pending", Reason="", readiness=false. Elapsed: 6.672092ms
May  2 19:56:53.770: INFO: Pod "alpine-nnp-false-65013870-fb8d-4ac0-885f-bd4125704969": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021739002s
May  2 19:56:55.783: INFO: Pod "alpine-nnp-false-65013870-fb8d-4ac0-885f-bd4125704969": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034981407s
May  2 19:56:55.783: INFO: Pod "alpine-nnp-false-65013870-fb8d-4ac0-885f-bd4125704969" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:56:55.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-881" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":14,"skipped":284,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:56:55.989: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with secret that has name projected-secret-test-eded31be-7c70-46c3-80c4-e6732647a035
STEP: Creating a pod to test consume secrets
May  2 19:56:56.295: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2eab36ad-703e-41d3-927d-e8070b068537" in namespace "projected-4465" to be "Succeeded or Failed"
May  2 19:56:56.324: INFO: Pod "pod-projected-secrets-2eab36ad-703e-41d3-927d-e8070b068537": Phase="Pending", Reason="", readiness=false. Elapsed: 29.271253ms
May  2 19:56:58.348: INFO: Pod "pod-projected-secrets-2eab36ad-703e-41d3-927d-e8070b068537": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052928005s
May  2 19:57:00.358: INFO: Pod "pod-projected-secrets-2eab36ad-703e-41d3-927d-e8070b068537": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063292999s
STEP: Saw pod success
May  2 19:57:00.358: INFO: Pod "pod-projected-secrets-2eab36ad-703e-41d3-927d-e8070b068537" satisfied condition "Succeeded or Failed"
May  2 19:57:00.370: INFO: Trying to get logs from node node-2 pod pod-projected-secrets-2eab36ad-703e-41d3-927d-e8070b068537 container projected-secret-volume-test: <nil>
STEP: delete the pod
May  2 19:57:00.422: INFO: Waiting for pod pod-projected-secrets-2eab36ad-703e-41d3-927d-e8070b068537 to disappear
May  2 19:57:00.434: INFO: Pod pod-projected-secrets-2eab36ad-703e-41d3-927d-e8070b068537 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:57:00.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4465" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":15,"skipped":315,"failed":0}

SSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:57:00.525: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating the pod
May  2 19:57:00.710: INFO: The status of Pod labelsupdatefa3b0d73-6f99-4eee-bd98-d8d1652ea844 is Pending, waiting for it to be Running (with Ready = true)
May  2 19:57:02.749: INFO: The status of Pod labelsupdatefa3b0d73-6f99-4eee-bd98-d8d1652ea844 is Pending, waiting for it to be Running (with Ready = true)
May  2 19:57:04.719: INFO: The status of Pod labelsupdatefa3b0d73-6f99-4eee-bd98-d8d1652ea844 is Running (Ready = true)
May  2 19:57:05.278: INFO: Successfully updated pod "labelsupdatefa3b0d73-6f99-4eee-bd98-d8d1652ea844"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:57:07.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9151" for this suite.


• [SLOW TEST:6.894 seconds]
[sig-storage] Projected downwardAPI
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":-1,"completed":16,"skipped":326,"failed":0}

SSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:57:07.460: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
May  2 19:57:10.643: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:57:10.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5157" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":-1,"completed":17,"skipped":346,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":-1,"completed":9,"skipped":216,"failed":0}
[BeforeEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:56:53.707: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Performing setup for networking test in namespace pod-network-test-6626
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May  2 19:56:53.852: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
May  2 19:56:54.171: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May  2 19:56:56.222: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 19:56:58.184: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 19:57:00.185: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 19:57:02.189: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 19:57:04.194: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 19:57:06.190: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 19:57:08.184: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 19:57:10.192: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 19:57:12.183: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 19:57:14.190: INFO: The status of Pod netserver-0 is Running (Ready = true)
May  2 19:57:14.258: INFO: The status of Pod netserver-1 is Running (Ready = true)
May  2 19:57:14.300: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
May  2 19:57:18.398: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
May  2 19:57:18.398: INFO: Breadth first check of 10.233.95.201 on host 10.100.18.197...
May  2 19:57:18.405: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.69.195:9080/dial?request=hostname&protocol=udp&host=10.233.95.201&port=8081&tries=1'] Namespace:pod-network-test-6626 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 19:57:18.405: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
May  2 19:57:18.650: INFO: Waiting for responses: map[]
May  2 19:57:18.650: INFO: reached 10.233.95.201 after 0/1 tries
May  2 19:57:18.650: INFO: Breadth first check of 10.233.112.206 on host 10.100.20.186...
May  2 19:57:18.667: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.69.195:9080/dial?request=hostname&protocol=udp&host=10.233.112.206&port=8081&tries=1'] Namespace:pod-network-test-6626 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 19:57:18.667: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
May  2 19:57:18.801: INFO: Waiting for responses: map[]
May  2 19:57:18.801: INFO: reached 10.233.112.206 after 0/1 tries
May  2 19:57:18.801: INFO: Breadth first check of 10.233.69.14 on host 10.100.20.46...
May  2 19:57:18.815: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.69.195:9080/dial?request=hostname&protocol=udp&host=10.233.69.14&port=8081&tries=1'] Namespace:pod-network-test-6626 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 19:57:18.815: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
May  2 19:57:19.014: INFO: Waiting for responses: map[]
May  2 19:57:19.014: INFO: reached 10.233.69.14 after 0/1 tries
May  2 19:57:19.014: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:57:19.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6626" for this suite.


• [SLOW TEST:25.367 seconds]
[sig-network] Networking
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/networking.go:30
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","total":-1,"completed":10,"skipped":216,"failed":0}

SSSSS
------------------------------
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:57:10.888: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Update Demo
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:296
[It] should create and stop a replication controller  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a replication controller
May  2 19:57:11.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-1787 create -f -'
May  2 19:57:13.939: INFO: stderr: ""
May  2 19:57:13.939: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May  2 19:57:13.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-1787 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
May  2 19:57:14.221: INFO: stderr: ""
May  2 19:57:14.221: INFO: stdout: "update-demo-nautilus-462cg update-demo-nautilus-882pt "
May  2 19:57:14.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-1787 get pods update-demo-nautilus-462cg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May  2 19:57:14.506: INFO: stderr: ""
May  2 19:57:14.506: INFO: stdout: ""
May  2 19:57:14.506: INFO: update-demo-nautilus-462cg is created but not running
May  2 19:57:19.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-1787 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
May  2 19:57:19.710: INFO: stderr: ""
May  2 19:57:19.710: INFO: stdout: "update-demo-nautilus-462cg update-demo-nautilus-882pt "
May  2 19:57:19.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-1787 get pods update-demo-nautilus-462cg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May  2 19:57:19.886: INFO: stderr: ""
May  2 19:57:19.886: INFO: stdout: "true"
May  2 19:57:19.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-1787 get pods update-demo-nautilus-462cg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
May  2 19:57:20.137: INFO: stderr: ""
May  2 19:57:20.137: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.4"
May  2 19:57:20.137: INFO: validating pod update-demo-nautilus-462cg
May  2 19:57:20.150: INFO: got data: {
  "image": "nautilus.jpg"
}

May  2 19:57:20.150: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  2 19:57:20.150: INFO: update-demo-nautilus-462cg is verified up and running
May  2 19:57:20.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-1787 get pods update-demo-nautilus-882pt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May  2 19:57:20.323: INFO: stderr: ""
May  2 19:57:20.323: INFO: stdout: "true"
May  2 19:57:20.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-1787 get pods update-demo-nautilus-882pt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
May  2 19:57:20.529: INFO: stderr: ""
May  2 19:57:20.529: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.4"
May  2 19:57:20.529: INFO: validating pod update-demo-nautilus-882pt
May  2 19:57:20.541: INFO: got data: {
  "image": "nautilus.jpg"
}

May  2 19:57:20.542: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  2 19:57:20.542: INFO: update-demo-nautilus-882pt is verified up and running
STEP: using delete to clean up resources
May  2 19:57:20.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-1787 delete --grace-period=0 --force -f -'
May  2 19:57:20.777: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  2 19:57:20.777: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May  2 19:57:20.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-1787 get rc,svc -l name=update-demo --no-headers'
May  2 19:57:21.190: INFO: stderr: "No resources found in kubectl-1787 namespace.\n"
May  2 19:57:21.190: INFO: stdout: ""
May  2 19:57:21.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-1787 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May  2 19:57:21.510: INFO: stderr: ""
May  2 19:57:21.510: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:57:21.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1787" for this suite.


• [SLOW TEST:10.676 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:294
    should create and stop a replication controller  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":-1,"completed":18,"skipped":389,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:57:19.084: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/security_context.go:46
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 19:57:19.220: INFO: Waiting up to 5m0s for pod "busybox-user-65534-cd635e5a-e2a1-4a3d-b3f0-86cd942c332d" in namespace "security-context-test-8880" to be "Succeeded or Failed"
May  2 19:57:19.228: INFO: Pod "busybox-user-65534-cd635e5a-e2a1-4a3d-b3f0-86cd942c332d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.173716ms
May  2 19:57:21.257: INFO: Pod "busybox-user-65534-cd635e5a-e2a1-4a3d-b3f0-86cd942c332d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036853895s
May  2 19:57:23.505: INFO: Pod "busybox-user-65534-cd635e5a-e2a1-4a3d-b3f0-86cd942c332d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.28441712s
May  2 19:57:23.505: INFO: Pod "busybox-user-65534-cd635e5a-e2a1-4a3d-b3f0-86cd942c332d" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:57:23.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8880" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":11,"skipped":221,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:57:21.684: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if kubectl can dry-run update Pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-1
May  2 19:57:21.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-2298 run e2e-test-httpd-pod --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
May  2 19:57:22.166: INFO: stderr: ""
May  2 19:57:22.166: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run
May  2 19:57:22.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-2298 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "k8s.gcr.io/e2e-test-images/busybox:1.29-1"}]}} --dry-run=server'
May  2 19:57:25.257: INFO: stderr: ""
May  2 19:57:25.257: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image k8s.gcr.io/e2e-test-images/httpd:2.4.38-1
May  2 19:57:25.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-2298 delete pods e2e-test-httpd-pod'
May  2 19:57:29.267: INFO: stderr: ""
May  2 19:57:29.267: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:57:29.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2298" for this suite.


• [SLOW TEST:7.628 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:913
    should check if kubectl can dry-run update Pods [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","total":-1,"completed":19,"skipped":424,"failed":0}

SSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:57:24.195: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:188
[It] should be updated [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
STEP: submitting the pod to kubernetes
May  2 19:57:24.483: INFO: The status of Pod pod-update-1fea04ed-381f-40df-b3dd-081a5172456c is Pending, waiting for it to be Running (with Ready = true)
May  2 19:57:26.493: INFO: The status of Pod pod-update-1fea04ed-381f-40df-b3dd-081a5172456c is Pending, waiting for it to be Running (with Ready = true)
May  2 19:57:28.497: INFO: The status of Pod pod-update-1fea04ed-381f-40df-b3dd-081a5172456c is Pending, waiting for it to be Running (with Ready = true)
May  2 19:57:30.504: INFO: The status of Pod pod-update-1fea04ed-381f-40df-b3dd-081a5172456c is Running (Ready = true)
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May  2 19:57:31.064: INFO: Successfully updated pod "pod-update-1fea04ed-381f-40df-b3dd-081a5172456c"
STEP: verifying the updated pod is in kubernetes
May  2 19:57:31.103: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:57:31.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4773" for this suite.


• [SLOW TEST:6.953 seconds]
[sig-node] Pods
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","total":-1,"completed":12,"skipped":252,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:57:29.383: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  2 19:57:30.284: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
May  2 19:57:32.346: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118250, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118250, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118250, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118250, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  2 19:57:35.402: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:57:35.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5041" for this suite.
STEP: Destroying namespace "webhook-5041-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102


• [SLOW TEST:6.438 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":-1,"completed":20,"skipped":441,"failed":0}

SSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:57:35.914: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run through a ConfigMap lifecycle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a ConfigMap
STEP: fetching the ConfigMap
STEP: patching the ConfigMap
STEP: listing all ConfigMaps in all namespaces with a label selector
STEP: deleting the ConfigMap by collection with a label selector
STEP: listing all ConfigMaps in test namespace
[AfterEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:57:36.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6196" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","total":-1,"completed":21,"skipped":456,"failed":0}

SSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:57:31.407: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:57:59.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4050" for this suite.


• [SLOW TEST:28.362 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":-1,"completed":13,"skipped":328,"failed":0}

SSSSSS
------------------------------
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:57:59.781: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should adopt matching pods on creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Given a Pod with a 'name' label pod-adoption is created
May  2 19:57:59.938: INFO: The status of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
May  2 19:58:01.952: INFO: The status of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
May  2 19:58:03.953: INFO: The status of Pod pod-adoption is Running (Ready = true)
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:58:05.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1783" for this suite.


• [SLOW TEST:5.336 seconds]
[sig-apps] ReplicationController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":-1,"completed":14,"skipped":334,"failed":0}

SSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:58:05.160: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8123.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8123.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8123.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8123.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May  2 19:58:09.346: INFO: DNS probes using dns-test-d1dfc7d4-b4ed-45be-9fce-3c78b91c7200 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8123.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8123.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8123.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8123.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May  2 19:58:15.560: INFO: DNS probes using dns-test-cdba0eae-2a97-48ba-8500-c761fd17519a succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8123.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-8123.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8123.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-8123.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May  2 19:58:21.769: INFO: File wheezy_udp@dns-test-service-3.dns-8123.svc.cluster.local from pod  dns-8123/dns-test-69b73826-985c-43e9-82d7-fcc169b63253 contains '' instead of '10.233.51.180'
May  2 19:58:21.800: INFO: Lookups using dns-8123/dns-test-69b73826-985c-43e9-82d7-fcc169b63253 failed for: [wheezy_udp@dns-test-service-3.dns-8123.svc.cluster.local]

May  2 19:58:26.821: INFO: DNS probes using dns-test-69b73826-985c-43e9-82d7-fcc169b63253 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:58:26.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8123" for this suite.


• [SLOW TEST:21.794 seconds]
[sig-network] DNS
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":-1,"completed":15,"skipped":348,"failed":0}

SSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:57:36.429: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with configMap that has name projected-configmap-test-upd-b7c1e57a-317f-4cd0-8f57-376da2ae2c45
STEP: Creating the pod
May  2 19:57:36.631: INFO: The status of Pod pod-projected-configmaps-6dd6e1af-d535-4612-8bb4-55ac7ac1a924 is Pending, waiting for it to be Running (with Ready = true)
May  2 19:57:38.647: INFO: The status of Pod pod-projected-configmaps-6dd6e1af-d535-4612-8bb4-55ac7ac1a924 is Pending, waiting for it to be Running (with Ready = true)
May  2 19:57:40.649: INFO: The status of Pod pod-projected-configmaps-6dd6e1af-d535-4612-8bb4-55ac7ac1a924 is Running (Ready = true)
STEP: Updating configmap projected-configmap-test-upd-b7c1e57a-317f-4cd0-8f57-376da2ae2c45
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:58:49.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8017" for this suite.


• [SLOW TEST:73.460 seconds]
[sig-storage] Projected configMap
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":-1,"completed":22,"skipped":469,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:58:49.950: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 19:58:54.093: INFO: Deleting pod "var-expansion-0b77646c-0bea-40ad-9b64-8871ee4aa66b" in namespace "var-expansion-6898"
May  2 19:58:54.123: INFO: Wait up to 5m0s for pod "var-expansion-0b77646c-0bea-40ad-9b64-8871ee4aa66b" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:58:56.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6898" for this suite.


• [SLOW TEST:6.284 seconds]
[sig-node] Variable Expansion
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","total":-1,"completed":23,"skipped":510,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:58:56.355: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test substitution in container's command
May  2 19:58:56.493: INFO: Waiting up to 5m0s for pod "var-expansion-0d59a5c2-93b1-450e-91ff-338747056502" in namespace "var-expansion-4701" to be "Succeeded or Failed"
May  2 19:58:56.503: INFO: Pod "var-expansion-0d59a5c2-93b1-450e-91ff-338747056502": Phase="Pending", Reason="", readiness=false. Elapsed: 9.315035ms
May  2 19:58:58.526: INFO: Pod "var-expansion-0d59a5c2-93b1-450e-91ff-338747056502": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032382958s
May  2 19:59:00.554: INFO: Pod "var-expansion-0d59a5c2-93b1-450e-91ff-338747056502": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.060430634s
STEP: Saw pod success
May  2 19:59:00.554: INFO: Pod "var-expansion-0d59a5c2-93b1-450e-91ff-338747056502" satisfied condition "Succeeded or Failed"
May  2 19:59:00.563: INFO: Trying to get logs from node node-2 pod var-expansion-0d59a5c2-93b1-450e-91ff-338747056502 container dapi-container: <nil>
STEP: delete the pod
May  2 19:59:00.629: INFO: Waiting for pod var-expansion-0d59a5c2-93b1-450e-91ff-338747056502 to disappear
May  2 19:59:00.639: INFO: Pod var-expansion-0d59a5c2-93b1-450e-91ff-338747056502 no longer exists
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:59:00.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4701" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":-1,"completed":24,"skipped":544,"failed":0}

SSSSSS
------------------------------
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:59:00.685: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should add annotations for pods in rc  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating Agnhost RC
May  2 19:59:00.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-1379 create -f -'
May  2 19:59:01.372: INFO: stderr: ""
May  2 19:59:01.372: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
May  2 19:59:02.388: INFO: Selector matched 1 pods for map[app:agnhost]
May  2 19:59:02.388: INFO: Found 0 / 1
May  2 19:59:03.392: INFO: Selector matched 1 pods for map[app:agnhost]
May  2 19:59:03.392: INFO: Found 0 / 1
May  2 19:59:04.395: INFO: Selector matched 1 pods for map[app:agnhost]
May  2 19:59:04.395: INFO: Found 1 / 1
May  2 19:59:04.395: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
May  2 19:59:04.402: INFO: Selector matched 1 pods for map[app:agnhost]
May  2 19:59:04.402: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May  2 19:59:04.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-1379 patch pod agnhost-primary-gwr6z -p {"metadata":{"annotations":{"x":"y"}}}'
May  2 19:59:04.566: INFO: stderr: ""
May  2 19:59:04.566: INFO: stdout: "pod/agnhost-primary-gwr6z patched\n"
STEP: checking annotations
May  2 19:59:04.582: INFO: Selector matched 1 pods for map[app:agnhost]
May  2 19:59:04.582: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:59:04.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1379" for this suite.

•
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":-1,"completed":25,"skipped":550,"failed":0}

SS
------------------------------
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:59:04.611: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/endpointslice.go:49
[It] should support creating EndpointSlice API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting /apis
STEP: getting /apis/discovery.k8s.io
STEP: getting /apis/discovery.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
May  2 19:59:04.819: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
May  2 19:59:04.828: INFO: starting watch
STEP: patching
STEP: updating
May  2 19:59:04.901: INFO: waiting for watch events with expected annotations
May  2 19:59:04.901: INFO: saw patched and updated annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:59:04.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-5361" for this suite.

•
------------------------------
{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","total":-1,"completed":26,"skipped":552,"failed":0}
[BeforeEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:59:05.021: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward api env vars
May  2 19:59:05.191: INFO: Waiting up to 5m0s for pod "downward-api-1abbe748-970b-46cd-a272-eb9d63fca1b4" in namespace "downward-api-7228" to be "Succeeded or Failed"
May  2 19:59:05.206: INFO: Pod "downward-api-1abbe748-970b-46cd-a272-eb9d63fca1b4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.670021ms
May  2 19:59:07.256: INFO: Pod "downward-api-1abbe748-970b-46cd-a272-eb9d63fca1b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065172468s
May  2 19:59:09.269: INFO: Pod "downward-api-1abbe748-970b-46cd-a272-eb9d63fca1b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.078137606s
STEP: Saw pod success
May  2 19:59:09.270: INFO: Pod "downward-api-1abbe748-970b-46cd-a272-eb9d63fca1b4" satisfied condition "Succeeded or Failed"
May  2 19:59:09.276: INFO: Trying to get logs from node node-2 pod downward-api-1abbe748-970b-46cd-a272-eb9d63fca1b4 container dapi-container: <nil>
STEP: delete the pod
May  2 19:59:09.358: INFO: Waiting for pod downward-api-1abbe748-970b-46cd-a272-eb9d63fca1b4 to disappear
May  2 19:59:09.370: INFO: Pod downward-api-1abbe748-970b-46cd-a272-eb9d63fca1b4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:59:09.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7228" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":-1,"completed":27,"skipped":552,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:59:09.462: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] Replicaset should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota
May  2 19:59:09.637: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the replicaset Spec.Replicas was modified
STEP: Patch a scale subresource
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:59:13.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1338" for this suite.

•
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","total":-1,"completed":28,"skipped":581,"failed":0}
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:59:13.794: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0666 on tmpfs
May  2 19:59:13.951: INFO: Waiting up to 5m0s for pod "pod-9463f67f-d458-4329-a646-515e185cfb58" in namespace "emptydir-5144" to be "Succeeded or Failed"
May  2 19:59:13.968: INFO: Pod "pod-9463f67f-d458-4329-a646-515e185cfb58": Phase="Pending", Reason="", readiness=false. Elapsed: 17.101808ms
May  2 19:59:15.976: INFO: Pod "pod-9463f67f-d458-4329-a646-515e185cfb58": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025050533s
May  2 19:59:17.986: INFO: Pod "pod-9463f67f-d458-4329-a646-515e185cfb58": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035276466s
STEP: Saw pod success
May  2 19:59:17.986: INFO: Pod "pod-9463f67f-d458-4329-a646-515e185cfb58" satisfied condition "Succeeded or Failed"
May  2 19:59:17.996: INFO: Trying to get logs from node node-2 pod pod-9463f67f-d458-4329-a646-515e185cfb58 container test-container: <nil>
STEP: delete the pod
May  2 19:59:18.063: INFO: Waiting for pod pod-9463f67f-d458-4329-a646-515e185cfb58 to disappear
May  2 19:59:18.074: INFO: Pod pod-9463f67f-d458-4329-a646-515e185cfb58 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:59:18.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5144" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":29,"skipped":581,"failed":0}

SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:59:18.147: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  2 19:59:19.000: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May  2 19:59:21.100: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118359, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118359, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118359, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118358, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  2 19:59:24.183: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:59:24.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8486" for this suite.
STEP: Destroying namespace "webhook-8486-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102


• [SLOW TEST:6.239 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":-1,"completed":30,"skipped":603,"failed":0}

SSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:58:27.002: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:54
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:59:27.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2786" for this suite.


• [SLOW TEST:60.230 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":-1,"completed":16,"skipped":359,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:59:27.356: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:59:27.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2462" for this suite.

•
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":-1,"completed":17,"skipped":418,"failed":0}

SSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:59:24.464: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
May  2 19:59:27.809: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:59:27.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-39" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":-1,"completed":31,"skipped":614,"failed":0}

SSS
------------------------------
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:59:27.629: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 19:59:27.733: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
May  2 19:59:29.863: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:59:30.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8494" for this suite.

•
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":-1,"completed":18,"skipped":430,"failed":0}

SSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:59:27.931: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  2 19:59:28.440: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May  2 19:59:30.539: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118368, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118368, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118368, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118368, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  2 19:59:33.591: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:59:34.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5444" for this suite.
STEP: Destroying namespace "webhook-5444-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102


• [SLOW TEST:6.390 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":-1,"completed":32,"skipped":617,"failed":0}

S
------------------------------
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:59:34.330: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service in namespace services-3867
STEP: creating service affinity-clusterip in namespace services-3867
STEP: creating replication controller affinity-clusterip in namespace services-3867
I0502 19:59:34.597017      18 runners.go:190] Created replication controller with name: affinity-clusterip, namespace: services-3867, replica count: 3
I0502 19:59:37.653427      18 runners.go:190] affinity-clusterip Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0502 19:59:40.654169      18 runners.go:190] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  2 19:59:40.714: INFO: Creating new exec pod
May  2 19:59:45.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=services-3867 exec execpod-affinitywlhnv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
May  2 19:59:46.229: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip 80\n+ echo hostName\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
May  2 19:59:46.229: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 19:59:46.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=services-3867 exec execpod-affinitywlhnv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.24.26 80'
May  2 19:59:46.642: INFO: stderr: "+ nc -v -t -w 2 10.233.24.26 80\n+ echo hostName\nConnection to 10.233.24.26 80 port [tcp/http] succeeded!\n"
May  2 19:59:46.642: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 19:59:46.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=services-3867 exec execpod-affinitywlhnv -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.24.26:80/ ; done'
May  2 19:59:47.303: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.24.26:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.24.26:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.24.26:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.24.26:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.24.26:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.24.26:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.24.26:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.24.26:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.24.26:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.24.26:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.24.26:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.24.26:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.24.26:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.24.26:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.24.26:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.24.26:80/\n"
May  2 19:59:47.303: INFO: stdout: "\naffinity-clusterip-522lj\naffinity-clusterip-522lj\naffinity-clusterip-522lj\naffinity-clusterip-522lj\naffinity-clusterip-522lj\naffinity-clusterip-522lj\naffinity-clusterip-522lj\naffinity-clusterip-522lj\naffinity-clusterip-522lj\naffinity-clusterip-522lj\naffinity-clusterip-522lj\naffinity-clusterip-522lj\naffinity-clusterip-522lj\naffinity-clusterip-522lj\naffinity-clusterip-522lj\naffinity-clusterip-522lj"
May  2 19:59:47.303: INFO: Received response from host: affinity-clusterip-522lj
May  2 19:59:47.303: INFO: Received response from host: affinity-clusterip-522lj
May  2 19:59:47.303: INFO: Received response from host: affinity-clusterip-522lj
May  2 19:59:47.303: INFO: Received response from host: affinity-clusterip-522lj
May  2 19:59:47.303: INFO: Received response from host: affinity-clusterip-522lj
May  2 19:59:47.303: INFO: Received response from host: affinity-clusterip-522lj
May  2 19:59:47.303: INFO: Received response from host: affinity-clusterip-522lj
May  2 19:59:47.303: INFO: Received response from host: affinity-clusterip-522lj
May  2 19:59:47.303: INFO: Received response from host: affinity-clusterip-522lj
May  2 19:59:47.303: INFO: Received response from host: affinity-clusterip-522lj
May  2 19:59:47.303: INFO: Received response from host: affinity-clusterip-522lj
May  2 19:59:47.303: INFO: Received response from host: affinity-clusterip-522lj
May  2 19:59:47.303: INFO: Received response from host: affinity-clusterip-522lj
May  2 19:59:47.303: INFO: Received response from host: affinity-clusterip-522lj
May  2 19:59:47.303: INFO: Received response from host: affinity-clusterip-522lj
May  2 19:59:47.303: INFO: Received response from host: affinity-clusterip-522lj
May  2 19:59:47.303: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-3867, will wait for the garbage collector to delete the pods
May  2 19:59:47.504: INFO: Deleting ReplicationController affinity-clusterip took: 83.477635ms
May  2 19:59:47.704: INFO: Terminating ReplicationController affinity-clusterip pods took: 200.244519ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:59:51.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3867" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753


• [SLOW TEST:17.436 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","total":-1,"completed":33,"skipped":618,"failed":0}

SSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:59:51.871: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  2 19:59:52.947: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
May  2 19:59:55.021: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118393, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118393, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118393, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118392, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  2 19:59:58.132: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 19:59:58.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8736" for this suite.
STEP: Destroying namespace "webhook-8736-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102


• [SLOW TEST:6.642 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":-1,"completed":34,"skipped":630,"failed":0}

SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:59:31.192: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:92
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:107
STEP: Creating service test in namespace statefulset-1674
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 19:59:31.422: INFO: Found 0 stateful pods, waiting for 1
May  2 19:59:41.447: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet
May  2 19:59:41.619: INFO: Found 1 stateful pods, waiting for 2
May  2 19:59:51.665: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=false
May  2 20:00:01.641: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
May  2 20:00:01.641: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets
STEP: Delete all of the StatefulSets
STEP: Verify that StatefulSets have been deleted
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:118
May  2 20:00:01.710: INFO: Deleting all statefulset in ns statefulset-1674
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:00:01.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1674" for this suite.


• [SLOW TEST:30.733 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:97
    should list, patch and delete a collection of StatefulSets [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","total":-1,"completed":19,"skipped":443,"failed":0}

SSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:00:01.973: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with secret that has name projected-secret-test-71ae19d4-65b9-43e0-aa0c-ed7d2a95b8a2
STEP: Creating a pod to test consume secrets
May  2 20:00:02.218: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-924d4bbe-65d8-48f7-8760-5ed016217bec" in namespace "projected-5296" to be "Succeeded or Failed"
May  2 20:00:02.248: INFO: Pod "pod-projected-secrets-924d4bbe-65d8-48f7-8760-5ed016217bec": Phase="Pending", Reason="", readiness=false. Elapsed: 30.20764ms
May  2 20:00:04.283: INFO: Pod "pod-projected-secrets-924d4bbe-65d8-48f7-8760-5ed016217bec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0646535s
May  2 20:00:06.303: INFO: Pod "pod-projected-secrets-924d4bbe-65d8-48f7-8760-5ed016217bec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.085264107s
STEP: Saw pod success
May  2 20:00:06.304: INFO: Pod "pod-projected-secrets-924d4bbe-65d8-48f7-8760-5ed016217bec" satisfied condition "Succeeded or Failed"
May  2 20:00:06.312: INFO: Trying to get logs from node node-2 pod pod-projected-secrets-924d4bbe-65d8-48f7-8760-5ed016217bec container projected-secret-volume-test: <nil>
STEP: delete the pod
May  2 20:00:06.421: INFO: Waiting for pod pod-projected-secrets-924d4bbe-65d8-48f7-8760-5ed016217bec to disappear
May  2 20:00:06.444: INFO: Pod pod-projected-secrets-924d4bbe-65d8-48f7-8760-5ed016217bec no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:00:06.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5296" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":-1,"completed":20,"skipped":454,"failed":0}

SSSSSSS
------------------------------
[BeforeEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 19:59:58.741: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:52
STEP: create the container to handle the HTTPGet hook request.
May  2 19:59:58.916: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
May  2 20:00:00.943: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
May  2 20:00:02.947: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the pod with lifecycle hook
May  2 20:00:03.138: INFO: The status of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
May  2 20:00:05.162: INFO: The status of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
May  2 20:00:07.152: INFO: The status of Pod pod-with-prestop-http-hook is Running (Ready = true)
STEP: delete the pod with lifecycle hook
May  2 20:00:07.186: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May  2 20:00:07.200: INFO: Pod pod-with-prestop-http-hook still exists
May  2 20:00:09.200: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May  2 20:00:09.222: INFO: Pod pod-with-prestop-http-hook still exists
May  2 20:00:11.202: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May  2 20:00:11.217: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:00:11.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2646" for this suite.


• [SLOW TEST:12.556 seconds]
[sig-node] Container Lifecycle Hook
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:43
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":-1,"completed":35,"skipped":652,"failed":0}

SSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:00:11.376: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:00:11.578: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
May  2 20:00:11.614: INFO: Pod name sample-pod: Found 0 pods out of 1
May  2 20:00:16.625: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May  2 20:00:16.625: INFO: Creating deployment "test-rolling-update-deployment"
May  2 20:00:16.640: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
May  2 20:00:16.670: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
May  2 20:00:18.713: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
May  2 20:00:18.733: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118416, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118416, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118416, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118416, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-585b757574\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  2 20:00:20.792: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118416, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118416, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118420, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118416, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-585b757574\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  2 20:00:22.760: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
May  2 20:00:22.813: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-3830  dd5d3905-009c-48ac-841a-1455f4401296 2864933 1 2022-05-02 20:00:16 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  [{e2e.test Update apps/v1 2022-05-02 20:00:16 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-02 20:00:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.32 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0045933a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-05-02 20:00:16 +0000 UTC,LastTransitionTime:2022-05-02 20:00:16 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-585b757574" has successfully progressed.,LastUpdateTime:2022-05-02 20:00:20 +0000 UTC,LastTransitionTime:2022-05-02 20:00:16 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

May  2 20:00:22.824: INFO: New ReplicaSet "test-rolling-update-deployment-585b757574" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-585b757574  deployment-3830  debc08b9-4869-4f9d-a5a5-7dd42a9ec298 2864921 1 2022-05-02 20:00:16 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:585b757574] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment dd5d3905-009c-48ac-841a-1455f4401296 0xc004593867 0xc004593868}] []  [{kube-controller-manager Update apps/v1 2022-05-02 20:00:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dd5d3905-009c-48ac-841a-1455f4401296\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-02 20:00:20 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 585b757574,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:585b757574] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.32 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004593918 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
May  2 20:00:22.824: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
May  2 20:00:22.824: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-3830  43e1880e-dd9d-451f-b31d-2b1647a090ba 2864932 2 2022-05-02 20:00:11 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment dd5d3905-009c-48ac-841a-1455f4401296 0xc00459372f 0xc004593740}] []  [{e2e.test Update apps/v1 2022-05-02 20:00:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-02 20:00:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dd5d3905-009c-48ac-841a-1455f4401296\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-05-02 20:00:20 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0045937f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May  2 20:00:22.835: INFO: Pod "test-rolling-update-deployment-585b757574-n6bnq" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-585b757574-n6bnq test-rolling-update-deployment-585b757574- deployment-3830  daa152ea-7793-4e3d-9dca-8d5658f0049a 2864920 0 2022-05-02 20:00:16 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:585b757574] map[cni.projectcalico.org/containerID:c85febc295fe78d0c87fb89cb7d6f2d00584539da7004879bbbf8ff044d399f1 cni.projectcalico.org/podIP:10.233.69.226/32 cni.projectcalico.org/podIPs:10.233.69.226/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-585b757574 debc08b9-4869-4f9d-a5a5-7dd42a9ec298 0xc004593f67 0xc004593f68}] []  [{kube-controller-manager Update v1 2022-05-02 20:00:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"debc08b9-4869-4f9d-a5a5-7dd42a9ec298\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-05-02 20:00:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-05-02 20:00:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.69.226\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-85gcz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.32,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-85gcz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:00:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:00:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:00:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:00:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.20.46,PodIP:10.233.69.226,StartTime:2022-05-02 20:00:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-02 20:00:19 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.32,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/agnhost@sha256:758db666ac7028534dba72e7e9bb1e57bb81b8196f976f7a5cc351ef8b3529e1,ContainerID:docker://da8a454c44fde74d0dab6303b4b15fc17bcd07c83a2f6d512e4d66a08b30db08,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.69.226,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:00:22.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3830" for this suite.


• [SLOW TEST:11.526 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":-1,"completed":36,"skipped":671,"failed":0}

SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:00:22.962: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir volume type on node default medium
May  2 20:00:23.117: INFO: Waiting up to 5m0s for pod "pod-74d1f03f-5ed1-4abc-83d0-23b80b786f4b" in namespace "emptydir-3477" to be "Succeeded or Failed"
May  2 20:00:23.143: INFO: Pod "pod-74d1f03f-5ed1-4abc-83d0-23b80b786f4b": Phase="Pending", Reason="", readiness=false. Elapsed: 26.521319ms
May  2 20:00:25.163: INFO: Pod "pod-74d1f03f-5ed1-4abc-83d0-23b80b786f4b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04622314s
May  2 20:00:27.176: INFO: Pod "pod-74d1f03f-5ed1-4abc-83d0-23b80b786f4b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059068301s
STEP: Saw pod success
May  2 20:00:27.176: INFO: Pod "pod-74d1f03f-5ed1-4abc-83d0-23b80b786f4b" satisfied condition "Succeeded or Failed"
May  2 20:00:27.186: INFO: Trying to get logs from node node-2 pod pod-74d1f03f-5ed1-4abc-83d0-23b80b786f4b container test-container: <nil>
STEP: delete the pod
May  2 20:00:27.245: INFO: Waiting for pod pod-74d1f03f-5ed1-4abc-83d0-23b80b786f4b to disappear
May  2 20:00:27.260: INFO: Pod pod-74d1f03f-5ed1-4abc-83d0-23b80b786f4b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:00:27.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3477" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":37,"skipped":693,"failed":0}

SSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:00:27.346: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name projected-secret-test-3f0e411b-5b71-4549-bbf8-074626fca3f3
STEP: Creating a pod to test consume secrets
May  2 20:00:27.542: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c3c734cc-1f4f-4d64-8d7e-9cc3fc7df0c7" in namespace "projected-3663" to be "Succeeded or Failed"
May  2 20:00:27.586: INFO: Pod "pod-projected-secrets-c3c734cc-1f4f-4d64-8d7e-9cc3fc7df0c7": Phase="Pending", Reason="", readiness=false. Elapsed: 35.742471ms
May  2 20:00:29.597: INFO: Pod "pod-projected-secrets-c3c734cc-1f4f-4d64-8d7e-9cc3fc7df0c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046531877s
May  2 20:00:31.638: INFO: Pod "pod-projected-secrets-c3c734cc-1f4f-4d64-8d7e-9cc3fc7df0c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.087741599s
STEP: Saw pod success
May  2 20:00:31.639: INFO: Pod "pod-projected-secrets-c3c734cc-1f4f-4d64-8d7e-9cc3fc7df0c7" satisfied condition "Succeeded or Failed"
May  2 20:00:31.655: INFO: Trying to get logs from node node-2 pod pod-projected-secrets-c3c734cc-1f4f-4d64-8d7e-9cc3fc7df0c7 container secret-volume-test: <nil>
STEP: delete the pod
May  2 20:00:31.760: INFO: Waiting for pod pod-projected-secrets-c3c734cc-1f4f-4d64-8d7e-9cc3fc7df0c7 to disappear
May  2 20:00:31.775: INFO: Pod pod-projected-secrets-c3c734cc-1f4f-4d64-8d7e-9cc3fc7df0c7 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:00:31.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3663" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":-1,"completed":38,"skipped":706,"failed":0}

SSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:00:31.896: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
May  2 20:00:32.116: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2f2ba586-dee2-49a8-af7f-5c31932d5d5f" in namespace "downward-api-8030" to be "Succeeded or Failed"
May  2 20:00:32.154: INFO: Pod "downwardapi-volume-2f2ba586-dee2-49a8-af7f-5c31932d5d5f": Phase="Pending", Reason="", readiness=false. Elapsed: 37.667002ms
May  2 20:00:34.179: INFO: Pod "downwardapi-volume-2f2ba586-dee2-49a8-af7f-5c31932d5d5f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.06293355s
May  2 20:00:36.226: INFO: Pod "downwardapi-volume-2f2ba586-dee2-49a8-af7f-5c31932d5d5f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.110032044s
STEP: Saw pod success
May  2 20:00:36.226: INFO: Pod "downwardapi-volume-2f2ba586-dee2-49a8-af7f-5c31932d5d5f" satisfied condition "Succeeded or Failed"
May  2 20:00:36.346: INFO: Trying to get logs from node node-2 pod downwardapi-volume-2f2ba586-dee2-49a8-af7f-5c31932d5d5f container client-container: <nil>
STEP: delete the pod
May  2 20:00:36.409: INFO: Waiting for pod downwardapi-volume-2f2ba586-dee2-49a8-af7f-5c31932d5d5f to disappear
May  2 20:00:36.416: INFO: Pod downwardapi-volume-2f2ba586-dee2-49a8-af7f-5c31932d5d5f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:00:36.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8030" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":-1,"completed":39,"skipped":718,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:00:36.529: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
May  2 20:00:36.653: INFO: Waiting up to 5m0s for pod "downwardapi-volume-079c608a-293a-4ab2-81d5-bcffc01d8c52" in namespace "projected-218" to be "Succeeded or Failed"
May  2 20:00:36.667: INFO: Pod "downwardapi-volume-079c608a-293a-4ab2-81d5-bcffc01d8c52": Phase="Pending", Reason="", readiness=false. Elapsed: 14.197137ms
May  2 20:00:38.679: INFO: Pod "downwardapi-volume-079c608a-293a-4ab2-81d5-bcffc01d8c52": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025817604s
May  2 20:00:40.763: INFO: Pod "downwardapi-volume-079c608a-293a-4ab2-81d5-bcffc01d8c52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.110748679s
STEP: Saw pod success
May  2 20:00:40.764: INFO: Pod "downwardapi-volume-079c608a-293a-4ab2-81d5-bcffc01d8c52" satisfied condition "Succeeded or Failed"
May  2 20:00:40.772: INFO: Trying to get logs from node node-2 pod downwardapi-volume-079c608a-293a-4ab2-81d5-bcffc01d8c52 container client-container: <nil>
STEP: delete the pod
May  2 20:00:40.843: INFO: Waiting for pod downwardapi-volume-079c608a-293a-4ab2-81d5-bcffc01d8c52 to disappear
May  2 20:00:40.854: INFO: Pod downwardapi-volume-079c608a-293a-4ab2-81d5-bcffc01d8c52 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:00:40.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-218" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":-1,"completed":40,"skipped":744,"failed":0}

SSSSSS
------------------------------
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:00:40.919: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0777 on node default medium
May  2 20:00:41.176: INFO: Waiting up to 5m0s for pod "pod-4ff79f82-bffd-4708-9660-56c846b2e8ea" in namespace "emptydir-4628" to be "Succeeded or Failed"
May  2 20:00:41.186: INFO: Pod "pod-4ff79f82-bffd-4708-9660-56c846b2e8ea": Phase="Pending", Reason="", readiness=false. Elapsed: 9.422056ms
May  2 20:00:43.214: INFO: Pod "pod-4ff79f82-bffd-4708-9660-56c846b2e8ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038149992s
May  2 20:00:45.226: INFO: Pod "pod-4ff79f82-bffd-4708-9660-56c846b2e8ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049749792s
STEP: Saw pod success
May  2 20:00:45.226: INFO: Pod "pod-4ff79f82-bffd-4708-9660-56c846b2e8ea" satisfied condition "Succeeded or Failed"
May  2 20:00:45.249: INFO: Trying to get logs from node node-2 pod pod-4ff79f82-bffd-4708-9660-56c846b2e8ea container test-container: <nil>
STEP: delete the pod
May  2 20:00:45.330: INFO: Waiting for pod pod-4ff79f82-bffd-4708-9660-56c846b2e8ea to disappear
May  2 20:00:45.345: INFO: Pod pod-4ff79f82-bffd-4708-9660-56c846b2e8ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:00:45.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4628" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":41,"skipped":750,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:00:45.512: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] should validate Deployment Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a Deployment
May  2 20:00:46.191: INFO: Creating simple deployment test-deployment-srnt7
May  2 20:00:46.231: INFO: deployment "test-deployment-srnt7" doesn't have the required revision set
May  2 20:00:48.287: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118446, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118446, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118446, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118446, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-srnt7-794dd694d8\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Getting /status
May  2 20:00:50.345: INFO: Deployment test-deployment-srnt7 has Conditions: [{Available True 2022-05-02 20:00:48 +0000 UTC 2022-05-02 20:00:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-05-02 20:00:48 +0000 UTC 2022-05-02 20:00:46 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-srnt7-794dd694d8" has successfully progressed.}]
STEP: updating Deployment Status
May  2 20:00:50.387: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118448, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118448, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118448, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118446, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-srnt7-794dd694d8\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated
May  2 20:00:50.392: INFO: Observed &Deployment event: ADDED
May  2 20:00:50.392: INFO: Observed Deployment test-deployment-srnt7 in namespace deployment-3529 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-05-02 20:00:46 +0000 UTC 2022-05-02 20:00:46 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-srnt7-794dd694d8"}
May  2 20:00:50.392: INFO: Observed &Deployment event: MODIFIED
May  2 20:00:50.392: INFO: Observed Deployment test-deployment-srnt7 in namespace deployment-3529 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-05-02 20:00:46 +0000 UTC 2022-05-02 20:00:46 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-srnt7-794dd694d8"}
May  2 20:00:50.392: INFO: Observed Deployment test-deployment-srnt7 in namespace deployment-3529 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-05-02 20:00:46 +0000 UTC 2022-05-02 20:00:46 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
May  2 20:00:50.392: INFO: Observed &Deployment event: MODIFIED
May  2 20:00:50.392: INFO: Observed Deployment test-deployment-srnt7 in namespace deployment-3529 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-05-02 20:00:46 +0000 UTC 2022-05-02 20:00:46 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
May  2 20:00:50.392: INFO: Observed Deployment test-deployment-srnt7 in namespace deployment-3529 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-05-02 20:00:46 +0000 UTC 2022-05-02 20:00:46 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-srnt7-794dd694d8" is progressing.}
May  2 20:00:50.393: INFO: Observed &Deployment event: MODIFIED
May  2 20:00:50.394: INFO: Observed Deployment test-deployment-srnt7 in namespace deployment-3529 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-05-02 20:00:48 +0000 UTC 2022-05-02 20:00:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
May  2 20:00:50.394: INFO: Observed Deployment test-deployment-srnt7 in namespace deployment-3529 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-05-02 20:00:48 +0000 UTC 2022-05-02 20:00:46 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-srnt7-794dd694d8" has successfully progressed.}
May  2 20:00:50.395: INFO: Observed &Deployment event: MODIFIED
May  2 20:00:50.395: INFO: Observed Deployment test-deployment-srnt7 in namespace deployment-3529 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-05-02 20:00:48 +0000 UTC 2022-05-02 20:00:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
May  2 20:00:50.395: INFO: Observed Deployment test-deployment-srnt7 in namespace deployment-3529 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-05-02 20:00:48 +0000 UTC 2022-05-02 20:00:46 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-srnt7-794dd694d8" has successfully progressed.}
May  2 20:00:50.395: INFO: Found Deployment test-deployment-srnt7 in namespace deployment-3529 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
May  2 20:00:50.395: INFO: Deployment test-deployment-srnt7 has an updated status
STEP: patching the Statefulset Status
May  2 20:00:50.395: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
May  2 20:00:50.416: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched
May  2 20:00:50.422: INFO: Observed &Deployment event: ADDED
May  2 20:00:50.422: INFO: Observed deployment test-deployment-srnt7 in namespace deployment-3529 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-05-02 20:00:46 +0000 UTC 2022-05-02 20:00:46 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-srnt7-794dd694d8"}
May  2 20:00:50.422: INFO: Observed &Deployment event: MODIFIED
May  2 20:00:50.422: INFO: Observed deployment test-deployment-srnt7 in namespace deployment-3529 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-05-02 20:00:46 +0000 UTC 2022-05-02 20:00:46 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-srnt7-794dd694d8"}
May  2 20:00:50.423: INFO: Observed deployment test-deployment-srnt7 in namespace deployment-3529 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-05-02 20:00:46 +0000 UTC 2022-05-02 20:00:46 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
May  2 20:00:50.423: INFO: Observed &Deployment event: MODIFIED
May  2 20:00:50.423: INFO: Observed deployment test-deployment-srnt7 in namespace deployment-3529 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-05-02 20:00:46 +0000 UTC 2022-05-02 20:00:46 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
May  2 20:00:50.423: INFO: Observed deployment test-deployment-srnt7 in namespace deployment-3529 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-05-02 20:00:46 +0000 UTC 2022-05-02 20:00:46 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-srnt7-794dd694d8" is progressing.}
May  2 20:00:50.424: INFO: Observed &Deployment event: MODIFIED
May  2 20:00:50.424: INFO: Observed deployment test-deployment-srnt7 in namespace deployment-3529 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-05-02 20:00:48 +0000 UTC 2022-05-02 20:00:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
May  2 20:00:50.424: INFO: Observed deployment test-deployment-srnt7 in namespace deployment-3529 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-05-02 20:00:48 +0000 UTC 2022-05-02 20:00:46 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-srnt7-794dd694d8" has successfully progressed.}
May  2 20:00:50.424: INFO: Observed &Deployment event: MODIFIED
May  2 20:00:50.424: INFO: Observed deployment test-deployment-srnt7 in namespace deployment-3529 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-05-02 20:00:48 +0000 UTC 2022-05-02 20:00:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
May  2 20:00:50.424: INFO: Observed deployment test-deployment-srnt7 in namespace deployment-3529 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-05-02 20:00:48 +0000 UTC 2022-05-02 20:00:46 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-srnt7-794dd694d8" has successfully progressed.}
May  2 20:00:50.424: INFO: Observed deployment test-deployment-srnt7 in namespace deployment-3529 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
May  2 20:00:50.425: INFO: Observed &Deployment event: MODIFIED
May  2 20:00:50.425: INFO: Found deployment test-deployment-srnt7 in namespace deployment-3529 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
May  2 20:00:50.425: INFO: Deployment test-deployment-srnt7 has a patched status
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
May  2 20:00:50.437: INFO: Deployment "test-deployment-srnt7":
&Deployment{ObjectMeta:{test-deployment-srnt7  deployment-3529  5ff831f1-5197-476a-ad3c-292e6cba60f3 2865337 1 2022-05-02 20:00:46 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 2022-05-02 20:00:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-02 20:00:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status} {e2e.test Update apps/v1 2022-05-02 20:00:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002fe4c38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

May  2 20:00:50.454: INFO: New ReplicaSet "test-deployment-srnt7-794dd694d8" of Deployment "test-deployment-srnt7":
&ReplicaSet{ObjectMeta:{test-deployment-srnt7-794dd694d8  deployment-3529  8c65a3bc-f035-4f5c-9c9c-28e2f696861a 2865327 1 2022-05-02 20:00:46 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:794dd694d8] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-srnt7 5ff831f1-5197-476a-ad3c-292e6cba60f3 0xc002fe4ff7 0xc002fe4ff8}] []  [{kube-controller-manager Update apps/v1 2022-05-02 20:00:46 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5ff831f1-5197-476a-ad3c-292e6cba60f3\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-02 20:00:48 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 794dd694d8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:794dd694d8] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002fe50a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
May  2 20:00:50.471: INFO: Pod "test-deployment-srnt7-794dd694d8-mlgb8" is available:
&Pod{ObjectMeta:{test-deployment-srnt7-794dd694d8-mlgb8 test-deployment-srnt7-794dd694d8- deployment-3529  1be97db6-8cff-4208-80f5-fb9008c2d651 2865326 0 2022-05-02 20:00:46 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:794dd694d8] map[cni.projectcalico.org/containerID:7acc286329d845a08d9df85b4540be5c23b14cbbad218e2ccb9ccfa3f7f02ac3 cni.projectcalico.org/podIP:10.233.69.209/32 cni.projectcalico.org/podIPs:10.233.69.209/32] [{apps/v1 ReplicaSet test-deployment-srnt7-794dd694d8 8c65a3bc-f035-4f5c-9c9c-28e2f696861a 0xc002fe5477 0xc002fe5478}] []  [{kube-controller-manager Update v1 2022-05-02 20:00:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8c65a3bc-f035-4f5c-9c9c-28e2f696861a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-05-02 20:00:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-05-02 20:00:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.69.209\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bvt6x,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bvt6x,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:00:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:00:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:00:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:00:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.20.46,PodIP:10.233.69.209,StartTime:2022-05-02 20:00:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-02 20:00:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:docker://a1c0e4d1427d6d9d29c674cc258084e69f97aa5ca6f018a5cfecec484cebeb02,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.69.209,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:00:50.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3529" for this suite.


• [SLOW TEST:5.009 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","total":-1,"completed":42,"skipped":799,"failed":0}

SSSS
------------------------------
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:00:50.539: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:188
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:00:50.658: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: creating the pod
STEP: submitting the pod to kubernetes
May  2 20:00:50.739: INFO: The status of Pod pod-logs-websocket-21f21dc1-521f-4aef-a34f-653d94194eed is Pending, waiting for it to be Running (with Ready = true)
May  2 20:00:52.882: INFO: The status of Pod pod-logs-websocket-21f21dc1-521f-4aef-a34f-653d94194eed is Pending, waiting for it to be Running (with Ready = true)
May  2 20:00:54.753: INFO: The status of Pod pod-logs-websocket-21f21dc1-521f-4aef-a34f-653d94194eed is Running (Ready = true)
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:00:54.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8270" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":-1,"completed":43,"skipped":803,"failed":0}

SS
------------------------------
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:00:06.531: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:00:06.648: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:01:08.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4217" for this suite.


• [SLOW TEST:61.894 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:48
    listing custom resource definition objects works  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":-1,"completed":21,"skipped":461,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:01:08.476: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Kubectl run pod
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1524
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-1
May  2 20:01:08.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-1513 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-1'
May  2 20:01:08.924: INFO: stderr: ""
May  2 20:01:08.924: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1528
May  2 20:01:08.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-1513 delete pods e2e-test-httpd-pod'
May  2 20:01:14.053: INFO: stderr: ""
May  2 20:01:14.054: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:01:14.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1513" for this suite.


• [SLOW TEST:5.622 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1521
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":-1,"completed":22,"skipped":492,"failed":0}

S
------------------------------
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:01:14.114: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-upd-084e37b1-2d8a-4797-a4b3-93145d502c23
STEP: Creating the pod
May  2 20:01:14.266: INFO: The status of Pod pod-configmaps-945d481a-554d-4ffb-8b05-b531c55bd37e is Pending, waiting for it to be Running (with Ready = true)
May  2 20:01:16.280: INFO: The status of Pod pod-configmaps-945d481a-554d-4ffb-8b05-b531c55bd37e is Running (Ready = true)
STEP: Updating configmap configmap-test-upd-084e37b1-2d8a-4797-a4b3-93145d502c23
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:01:18.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9168" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":-1,"completed":23,"skipped":493,"failed":0}

SSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:00:54.864: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod pod-subpath-test-secret-xq45
STEP: Creating a pod to test atomic-volume-subpath
May  2 20:00:55.081: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-xq45" in namespace "subpath-8478" to be "Succeeded or Failed"
May  2 20:00:55.104: INFO: Pod "pod-subpath-test-secret-xq45": Phase="Pending", Reason="", readiness=false. Elapsed: 22.683537ms
May  2 20:00:57.161: INFO: Pod "pod-subpath-test-secret-xq45": Phase="Pending", Reason="", readiness=false. Elapsed: 2.079569297s
May  2 20:00:59.173: INFO: Pod "pod-subpath-test-secret-xq45": Phase="Running", Reason="", readiness=true. Elapsed: 4.091329716s
May  2 20:01:01.194: INFO: Pod "pod-subpath-test-secret-xq45": Phase="Running", Reason="", readiness=true. Elapsed: 6.112800817s
May  2 20:01:03.229: INFO: Pod "pod-subpath-test-secret-xq45": Phase="Running", Reason="", readiness=true. Elapsed: 8.147600557s
May  2 20:01:05.243: INFO: Pod "pod-subpath-test-secret-xq45": Phase="Running", Reason="", readiness=true. Elapsed: 10.162073807s
May  2 20:01:07.266: INFO: Pod "pod-subpath-test-secret-xq45": Phase="Running", Reason="", readiness=true. Elapsed: 12.184364549s
May  2 20:01:09.272: INFO: Pod "pod-subpath-test-secret-xq45": Phase="Running", Reason="", readiness=true. Elapsed: 14.190900456s
May  2 20:01:11.419: INFO: Pod "pod-subpath-test-secret-xq45": Phase="Running", Reason="", readiness=true. Elapsed: 16.337743275s
May  2 20:01:13.437: INFO: Pod "pod-subpath-test-secret-xq45": Phase="Running", Reason="", readiness=true. Elapsed: 18.355756614s
May  2 20:01:15.453: INFO: Pod "pod-subpath-test-secret-xq45": Phase="Running", Reason="", readiness=true. Elapsed: 20.371658252s
May  2 20:01:17.489: INFO: Pod "pod-subpath-test-secret-xq45": Phase="Running", Reason="", readiness=true. Elapsed: 22.408110244s
May  2 20:01:19.501: INFO: Pod "pod-subpath-test-secret-xq45": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.419906887s
STEP: Saw pod success
May  2 20:01:19.501: INFO: Pod "pod-subpath-test-secret-xq45" satisfied condition "Succeeded or Failed"
May  2 20:01:19.524: INFO: Trying to get logs from node node-2 pod pod-subpath-test-secret-xq45 container test-container-subpath-secret-xq45: <nil>
STEP: delete the pod
May  2 20:01:19.636: INFO: Waiting for pod pod-subpath-test-secret-xq45 to disappear
May  2 20:01:19.648: INFO: Pod pod-subpath-test-secret-xq45 no longer exists
STEP: Deleting pod pod-subpath-test-secret-xq45
May  2 20:01:19.648: INFO: Deleting pod "pod-subpath-test-secret-xq45" in namespace "subpath-8478"
[AfterEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:01:19.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8478" for this suite.


• [SLOW TEST:24.847 seconds]
[sig-storage] Subpath
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [LinuxOnly] [Conformance]","total":-1,"completed":44,"skipped":805,"failed":0}
[BeforeEach] [sig-node] Lease
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:01:19.731: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename lease-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] lease API should be available [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-node] Lease
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:01:20.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-5878" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","total":-1,"completed":45,"skipped":805,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:01:20.336: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
May  2 20:01:20.633: INFO: Waiting up to 5m0s for pod "downwardapi-volume-949058ec-bcb6-45ff-b49b-00c89607a389" in namespace "downward-api-8078" to be "Succeeded or Failed"
May  2 20:01:20.683: INFO: Pod "downwardapi-volume-949058ec-bcb6-45ff-b49b-00c89607a389": Phase="Pending", Reason="", readiness=false. Elapsed: 50.493491ms
May  2 20:01:22.726: INFO: Pod "downwardapi-volume-949058ec-bcb6-45ff-b49b-00c89607a389": Phase="Pending", Reason="", readiness=false. Elapsed: 2.093498816s
May  2 20:01:24.739: INFO: Pod "downwardapi-volume-949058ec-bcb6-45ff-b49b-00c89607a389": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.106432535s
STEP: Saw pod success
May  2 20:01:24.739: INFO: Pod "downwardapi-volume-949058ec-bcb6-45ff-b49b-00c89607a389" satisfied condition "Succeeded or Failed"
May  2 20:01:24.751: INFO: Trying to get logs from node node-2 pod downwardapi-volume-949058ec-bcb6-45ff-b49b-00c89607a389 container client-container: <nil>
STEP: delete the pod
May  2 20:01:24.871: INFO: Waiting for pod downwardapi-volume-949058ec-bcb6-45ff-b49b-00c89607a389 to disappear
May  2 20:01:24.901: INFO: Pod downwardapi-volume-949058ec-bcb6-45ff-b49b-00c89607a389 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:01:24.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8078" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":-1,"completed":46,"skipped":850,"failed":0}

SSSS
------------------------------
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:01:24.978: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:01:42.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3532" for this suite.


• [SLOW TEST:17.344 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":-1,"completed":47,"skipped":854,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:01:42.486: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  2 20:01:43.119: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May  2 20:01:45.174: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118503, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118503, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118503, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118503, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  2 20:01:48.219: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:01:48.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-514" for this suite.
STEP: Destroying namespace "webhook-514-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102


• [SLOW TEST:6.138 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":-1,"completed":48,"skipped":901,"failed":0}

SSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:01:48.827: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-416cf736-486f-4ce3-84c8-2f529b22d37a
STEP: Creating a pod to test consume secrets
May  2 20:01:49.142: INFO: Waiting up to 5m0s for pod "pod-secrets-aaf93612-c1e7-4380-811a-1c9a87ad1226" in namespace "secrets-9560" to be "Succeeded or Failed"
May  2 20:01:49.161: INFO: Pod "pod-secrets-aaf93612-c1e7-4380-811a-1c9a87ad1226": Phase="Pending", Reason="", readiness=false. Elapsed: 19.86714ms
May  2 20:01:51.169: INFO: Pod "pod-secrets-aaf93612-c1e7-4380-811a-1c9a87ad1226": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027144761s
May  2 20:01:53.200: INFO: Pod "pod-secrets-aaf93612-c1e7-4380-811a-1c9a87ad1226": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058048509s
STEP: Saw pod success
May  2 20:01:53.200: INFO: Pod "pod-secrets-aaf93612-c1e7-4380-811a-1c9a87ad1226" satisfied condition "Succeeded or Failed"
May  2 20:01:53.208: INFO: Trying to get logs from node node-2 pod pod-secrets-aaf93612-c1e7-4380-811a-1c9a87ad1226 container secret-volume-test: <nil>
STEP: delete the pod
May  2 20:01:53.298: INFO: Waiting for pod pod-secrets-aaf93612-c1e7-4380-811a-1c9a87ad1226 to disappear
May  2 20:01:53.306: INFO: Pod pod-secrets-aaf93612-c1e7-4380-811a-1c9a87ad1226 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:01:53.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9560" for this suite.
STEP: Destroying namespace "secret-namespace-6914" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":-1,"completed":49,"skipped":918,"failed":0}

SSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:01:53.409: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-975951a2-de9c-47a4-bfe4-0d633d36d283
STEP: Creating a pod to test consume configMaps
May  2 20:01:53.772: INFO: Waiting up to 5m0s for pod "pod-configmaps-96c5d727-0973-43ab-980a-cf52d57720d5" in namespace "configmap-646" to be "Succeeded or Failed"
May  2 20:01:53.794: INFO: Pod "pod-configmaps-96c5d727-0973-43ab-980a-cf52d57720d5": Phase="Pending", Reason="", readiness=false. Elapsed: 21.723555ms
May  2 20:01:55.808: INFO: Pod "pod-configmaps-96c5d727-0973-43ab-980a-cf52d57720d5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0357818s
May  2 20:01:57.835: INFO: Pod "pod-configmaps-96c5d727-0973-43ab-980a-cf52d57720d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.062424735s
STEP: Saw pod success
May  2 20:01:57.835: INFO: Pod "pod-configmaps-96c5d727-0973-43ab-980a-cf52d57720d5" satisfied condition "Succeeded or Failed"
May  2 20:01:57.842: INFO: Trying to get logs from node node-2 pod pod-configmaps-96c5d727-0973-43ab-980a-cf52d57720d5 container configmap-volume-test: <nil>
STEP: delete the pod
May  2 20:01:57.914: INFO: Waiting for pod pod-configmaps-96c5d727-0973-43ab-980a-cf52d57720d5 to disappear
May  2 20:01:57.921: INFO: Pod pod-configmaps-96c5d727-0973-43ab-980a-cf52d57720d5 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:01:57.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-646" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":-1,"completed":50,"skipped":928,"failed":0}

SSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:01:57.997: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0644 on tmpfs
May  2 20:01:58.177: INFO: Waiting up to 5m0s for pod "pod-66e018c2-ac76-4b4f-b02d-891f780af585" in namespace "emptydir-383" to be "Succeeded or Failed"
May  2 20:01:58.204: INFO: Pod "pod-66e018c2-ac76-4b4f-b02d-891f780af585": Phase="Pending", Reason="", readiness=false. Elapsed: 27.495448ms
May  2 20:02:00.224: INFO: Pod "pod-66e018c2-ac76-4b4f-b02d-891f780af585": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046967601s
May  2 20:02:02.238: INFO: Pod "pod-66e018c2-ac76-4b4f-b02d-891f780af585": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.061744658s
STEP: Saw pod success
May  2 20:02:02.239: INFO: Pod "pod-66e018c2-ac76-4b4f-b02d-891f780af585" satisfied condition "Succeeded or Failed"
May  2 20:02:02.246: INFO: Trying to get logs from node node-2 pod pod-66e018c2-ac76-4b4f-b02d-891f780af585 container test-container: <nil>
STEP: delete the pod
May  2 20:02:02.321: INFO: Waiting for pod pod-66e018c2-ac76-4b4f-b02d-891f780af585 to disappear
May  2 20:02:02.330: INFO: Pod pod-66e018c2-ac76-4b4f-b02d-891f780af585 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:02:02.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-383" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":51,"skipped":949,"failed":0}

SSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:02:02.465: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] deployment should delete old replica sets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:02:02.667: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May  2 20:02:06.723: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
May  2 20:02:06.789: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-4438  f72f25c1-7694-4b31-9471-7e705ea18dd9 2866394 1 2022-05-02 20:02:06 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  [{e2e.test Update apps/v1 2022-05-02 20:02:06 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.32 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0044bf598 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

May  2 20:02:06.803: INFO: New ReplicaSet "test-cleanup-deployment-5b4d99b59b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-5b4d99b59b  deployment-4438  840f4c3e-1723-4a81-80f7-dcf99d6180f5 2866396 1 2022-05-02 20:02:06 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:5b4d99b59b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment f72f25c1-7694-4b31-9471-7e705ea18dd9 0xc0044bf9f7 0xc0044bf9f8}] []  [{kube-controller-manager Update apps/v1 2022-05-02 20:02:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f72f25c1-7694-4b31-9471-7e705ea18dd9\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 5b4d99b59b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:5b4d99b59b] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.32 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0044bfa88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May  2 20:02:06.803: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
May  2 20:02:06.803: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-4438  457eb76d-560c-4ba2-acff-a1762d6dec71 2866395 1 2022-05-02 20:02:02 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment f72f25c1-7694-4b31-9471-7e705ea18dd9 0xc0044bf8c7 0xc0044bf8c8}] []  [{e2e.test Update apps/v1 2022-05-02 20:02:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-02 20:02:05 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-05-02 20:02:06 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"f72f25c1-7694-4b31-9471-7e705ea18dd9\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0044bf988 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
May  2 20:02:06.829: INFO: Pod "test-cleanup-controller-qrk7f" is available:
&Pod{ObjectMeta:{test-cleanup-controller-qrk7f test-cleanup-controller- deployment-4438  e9399273-36fe-4c8e-8a93-d5bc78824633 2866373 0 2022-05-02 20:02:02 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/containerID:d8d67bf9c5570292d6cf7db49820ed8d75e54992bd2e35054e1cd84092b486d4 cni.projectcalico.org/podIP:10.233.69.132/32 cni.projectcalico.org/podIPs:10.233.69.132/32] [{apps/v1 ReplicaSet test-cleanup-controller 457eb76d-560c-4ba2-acff-a1762d6dec71 0xc004590007 0xc004590008}] []  [{kube-controller-manager Update v1 2022-05-02 20:02:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"457eb76d-560c-4ba2-acff-a1762d6dec71\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-05-02 20:02:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-05-02 20:02:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.69.132\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4hdf4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4hdf4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:02:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:02:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:02:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:02:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.20.46,PodIP:10.233.69.132,StartTime:2022-05-02 20:02:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-02 20:02:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:docker://3839eb4db87c230e33e5fca93f4926823f41867576e9657833832558a2067bdf,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.69.132,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:02:06.829: INFO: Pod "test-cleanup-deployment-5b4d99b59b-hxcnr" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-5b4d99b59b-hxcnr test-cleanup-deployment-5b4d99b59b- deployment-4438  e7c398df-d1a3-4b4b-9971-6807a9cec6d7 2866399 0 2022-05-02 20:02:06 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:5b4d99b59b] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-5b4d99b59b 840f4c3e-1723-4a81-80f7-dcf99d6180f5 0xc004590227 0xc004590228}] []  [{kube-controller-manager Update v1 2022-05-02 20:02:06 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"840f4c3e-1723-4a81-80f7-dcf99d6180f5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pw4rq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.32,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pw4rq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:02:06.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4438" for this suite.

•
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":-1,"completed":52,"skipped":967,"failed":0}

SSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/sysctl.go:36
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:02:06.937: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename sysctl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/sysctl.go:65
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl
STEP: Watching for error events or started pod
STEP: Waiting for pod completion
STEP: Checking that the pod succeeded
STEP: Getting logs from the pod
STEP: Checking that the sysctl is actually updated
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:02:11.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-4466" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","total":-1,"completed":53,"skipped":977,"failed":0}

SSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:02:11.254: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: validating api versions
May  2 20:02:11.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-5735 api-versions'
May  2 20:02:11.642: INFO: stderr: ""
May  2 20:02:11.642: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ncstor.openebs.io/v1\ndiscovery.k8s.io/v1\ndiscovery.k8s.io/v1beta1\nevents.k8s.io/v1\nevents.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta1\nlocal.openebs.io/v1alpha1\nlonghorn.io/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\nnode.k8s.io/v1beta1\nopenebs.io/v1alpha1\npolicy/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nsnapshot.storage.k8s.io/v1\nsnapshot.storage.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\nzfs.openebs.io/v1\nzfs.openebs.io/v1alpha1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:02:11.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5735" for this suite.

•
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":-1,"completed":54,"skipped":989,"failed":0}

SSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:02:11.729: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename security-context
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser
May  2 20:02:11.874: INFO: Waiting up to 5m0s for pod "security-context-70cf060e-e1ee-4724-b4e3-fd6d5884a93f" in namespace "security-context-5199" to be "Succeeded or Failed"
May  2 20:02:11.885: INFO: Pod "security-context-70cf060e-e1ee-4724-b4e3-fd6d5884a93f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.068769ms
May  2 20:02:13.898: INFO: Pod "security-context-70cf060e-e1ee-4724-b4e3-fd6d5884a93f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024211047s
May  2 20:02:15.906: INFO: Pod "security-context-70cf060e-e1ee-4724-b4e3-fd6d5884a93f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032656157s
STEP: Saw pod success
May  2 20:02:15.906: INFO: Pod "security-context-70cf060e-e1ee-4724-b4e3-fd6d5884a93f" satisfied condition "Succeeded or Failed"
May  2 20:02:15.911: INFO: Trying to get logs from node node-2 pod security-context-70cf060e-e1ee-4724-b4e3-fd6d5884a93f container test-container: <nil>
STEP: delete the pod
May  2 20:02:15.977: INFO: Waiting for pod security-context-70cf060e-e1ee-4724-b4e3-fd6d5884a93f to disappear
May  2 20:02:15.985: INFO: Pod security-context-70cf060e-e1ee-4724-b4e3-fd6d5884a93f no longer exists
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:02:15.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-5199" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","total":-1,"completed":55,"skipped":998,"failed":0}

SSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:02:16.086: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
May  2 20:02:16.273: INFO: Waiting up to 5m0s for pod "downwardapi-volume-82348021-2f0f-4555-939a-b40ab85d23c0" in namespace "downward-api-2291" to be "Succeeded or Failed"
May  2 20:02:16.297: INFO: Pod "downwardapi-volume-82348021-2f0f-4555-939a-b40ab85d23c0": Phase="Pending", Reason="", readiness=false. Elapsed: 23.627929ms
May  2 20:02:18.313: INFO: Pod "downwardapi-volume-82348021-2f0f-4555-939a-b40ab85d23c0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03991187s
May  2 20:02:20.325: INFO: Pod "downwardapi-volume-82348021-2f0f-4555-939a-b40ab85d23c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051412473s
STEP: Saw pod success
May  2 20:02:20.325: INFO: Pod "downwardapi-volume-82348021-2f0f-4555-939a-b40ab85d23c0" satisfied condition "Succeeded or Failed"
May  2 20:02:20.335: INFO: Trying to get logs from node node-2 pod downwardapi-volume-82348021-2f0f-4555-939a-b40ab85d23c0 container client-container: <nil>
STEP: delete the pod
May  2 20:02:20.400: INFO: Waiting for pod downwardapi-volume-82348021-2f0f-4555-939a-b40ab85d23c0 to disappear
May  2 20:02:20.414: INFO: Pod downwardapi-volume-82348021-2f0f-4555-939a-b40ab85d23c0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:02:20.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2291" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":56,"skipped":1007,"failed":0}

SS
------------------------------
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:02:20.461: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] deployment should support rollover [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:02:20.622: INFO: Pod name rollover-pod: Found 0 pods out of 1
May  2 20:02:25.634: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May  2 20:02:25.634: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
May  2 20:02:27.643: INFO: Creating deployment "test-rollover-deployment"
May  2 20:02:27.666: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
May  2 20:02:29.690: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
May  2 20:02:29.710: INFO: Ensure that both replica sets have 1 created replica
May  2 20:02:29.727: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
May  2 20:02:29.762: INFO: Updating deployment test-rollover-deployment
May  2 20:02:29.762: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
May  2 20:02:31.840: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
May  2 20:02:31.905: INFO: Make sure deployment "test-rollover-deployment" is complete
May  2 20:02:31.929: INFO: all replica sets need to contain the pod-template-hash label
May  2 20:02:31.932: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118547, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118547, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118550, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118547, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-98c5f4599\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  2 20:02:33.950: INFO: all replica sets need to contain the pod-template-hash label
May  2 20:02:33.950: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118547, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118547, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118553, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118547, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-98c5f4599\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  2 20:02:35.969: INFO: all replica sets need to contain the pod-template-hash label
May  2 20:02:35.969: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118547, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118547, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118553, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118547, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-98c5f4599\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  2 20:02:37.951: INFO: all replica sets need to contain the pod-template-hash label
May  2 20:02:37.951: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118547, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118547, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118553, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118547, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-98c5f4599\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  2 20:02:39.970: INFO: all replica sets need to contain the pod-template-hash label
May  2 20:02:39.970: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118547, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118547, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118553, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118547, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-98c5f4599\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  2 20:02:41.975: INFO: all replica sets need to contain the pod-template-hash label
May  2 20:02:41.975: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118547, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118547, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118553, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118547, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-98c5f4599\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  2 20:02:43.950: INFO: 
May  2 20:02:43.950: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
May  2 20:02:43.982: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-9420  592d2f0e-7576-4460-a9ee-6f7659f7f817 2866947 2 2022-05-02 20:02:27 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-05-02 20:02:29 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-02 20:02:43 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.32 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0039a3658 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-05-02 20:02:27 +0000 UTC,LastTransitionTime:2022-05-02 20:02:27 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-98c5f4599" has successfully progressed.,LastUpdateTime:2022-05-02 20:02:43 +0000 UTC,LastTransitionTime:2022-05-02 20:02:27 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

May  2 20:02:43.990: INFO: New ReplicaSet "test-rollover-deployment-98c5f4599" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-98c5f4599  deployment-9420  55a51f0e-2d3b-4abd-9d82-428783f53fe8 2866931 2 2022-05-02 20:02:29 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:98c5f4599] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 592d2f0e-7576-4460-a9ee-6f7659f7f817 0xc0039a3c20 0xc0039a3c21}] []  [{kube-controller-manager Update apps/v1 2022-05-02 20:02:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"592d2f0e-7576-4460-a9ee-6f7659f7f817\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-02 20:02:43 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 98c5f4599,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:98c5f4599] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.32 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0039a3cb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
May  2 20:02:43.990: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
May  2 20:02:43.990: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-9420  7b8c10ab-b5cf-494f-8881-711f854194aa 2866944 2 2022-05-02 20:02:20 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 592d2f0e-7576-4460-a9ee-6f7659f7f817 0xc0039a39cf 0xc0039a39e0}] []  [{e2e.test Update apps/v1 2022-05-02 20:02:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-02 20:02:43 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"592d2f0e-7576-4460-a9ee-6f7659f7f817\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-05-02 20:02:43 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0039a3a98 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May  2 20:02:43.991: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-78bc8b888c  deployment-9420  cc80dbff-5b2d-4172-977c-22b4749047e8 2866814 2 2022-05-02 20:02:27 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:78bc8b888c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 592d2f0e-7576-4460-a9ee-6f7659f7f817 0xc0039a3b07 0xc0039a3b08}] []  [{kube-controller-manager Update apps/v1 2022-05-02 20:02:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"592d2f0e-7576-4460-a9ee-6f7659f7f817\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-02 20:02:30 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 78bc8b888c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:78bc8b888c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0039a3bb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May  2 20:02:43.998: INFO: Pod "test-rollover-deployment-98c5f4599-8kgd4" is available:
&Pod{ObjectMeta:{test-rollover-deployment-98c5f4599-8kgd4 test-rollover-deployment-98c5f4599- deployment-9420  003bcf6b-ee40-4c63-9c37-f592c3a8f514 2866855 0 2022-05-02 20:02:29 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:98c5f4599] map[cni.projectcalico.org/containerID:fb7a6031f856a85a5aedd25b7066f31d619513f6cdd7157efbb73ab274318815 cni.projectcalico.org/podIP:10.233.69.246/32 cni.projectcalico.org/podIPs:10.233.69.246/32] [{apps/v1 ReplicaSet test-rollover-deployment-98c5f4599 55a51f0e-2d3b-4abd-9d82-428783f53fe8 0xc00379c4b0 0xc00379c4b1}] []  [{kube-controller-manager Update v1 2022-05-02 20:02:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"55a51f0e-2d3b-4abd-9d82-428783f53fe8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-05-02 20:02:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-05-02 20:02:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.69.246\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qm874,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.32,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qm874,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:02:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:02:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:02:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:02:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.20.46,PodIP:10.233.69.246,StartTime:2022-05-02 20:02:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-02 20:02:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.32,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/agnhost@sha256:758db666ac7028534dba72e7e9bb1e57bb81b8196f976f7a5cc351ef8b3529e1,ContainerID:docker://08c6540d1b6c4ec1cae6f0d5048764b777e94a9d40cdb6d698e575ad898993d6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.69.246,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:02:43.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9420" for this suite.


• [SLOW TEST:23.572 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":-1,"completed":57,"skipped":1009,"failed":0}

SS
------------------------------
[BeforeEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:02:44.050: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support CronJob API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a cronjob
STEP: creating
STEP: getting
STEP: listing
STEP: watching
May  2 20:02:44.247: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
May  2 20:02:44.256: INFO: starting watch
STEP: patching
STEP: updating
May  2 20:02:44.296: INFO: waiting for watch events with expected annotations
May  2 20:02:44.296: INFO: saw patched and updated annotations
STEP: patching /status
STEP: updating /status
STEP: get /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:02:44.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-2202" for this suite.

•
------------------------------
{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","total":-1,"completed":58,"skipped":1011,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:01:18.552: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:92
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:107
STEP: Creating service test in namespace statefulset-8139
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a new StatefulSet
May  2 20:01:18.817: INFO: Found 0 stateful pods, waiting for 3
May  2 20:01:28.833: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May  2 20:01:28.833: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May  2 20:01:28.833: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
May  2 20:01:38.837: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May  2 20:01:38.837: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May  2 20:01:38.837: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
May  2 20:01:38.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=statefulset-8139 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  2 20:01:39.294: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  2 20:01:39.294: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  2 20:01:39.294: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 to k8s.gcr.io/e2e-test-images/httpd:2.4.39-1
May  2 20:01:49.371: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
May  2 20:01:59.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=statefulset-8139 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  2 20:01:59.789: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May  2 20:01:59.789: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  2 20:01:59.789: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

STEP: Rolling back to a previous revision
May  2 20:02:19.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=statefulset-8139 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  2 20:02:20.241: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  2 20:02:20.241: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  2 20:02:20.241: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  2 20:02:30.344: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
May  2 20:02:40.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=statefulset-8139 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  2 20:02:40.713: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May  2 20:02:40.713: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  2 20:02:40.713: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:118
May  2 20:03:00.771: INFO: Deleting all statefulset in ns statefulset-8139
May  2 20:03:00.779: INFO: Scaling statefulset ss2 to 0
May  2 20:03:10.832: INFO: Waiting for statefulset status.replicas updated to 0
May  2 20:03:10.841: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:03:10.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8139" for this suite.


• [SLOW TEST:112.351 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:97
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":-1,"completed":24,"skipped":514,"failed":0}

SSSS
------------------------------
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:03:10.941: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/endpointslice.go:49
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:03:13.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-5151" for this suite.

•
------------------------------
{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","total":-1,"completed":25,"skipped":518,"failed":0}

SSSSSSSS
------------------------------
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:03:13.337: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:38
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:03:13.480: INFO: The status of Pod busybox-readonly-fsa71998d0-3795-46c8-b70d-b27bac8be793 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:03:15.491: INFO: The status of Pod busybox-readonly-fsa71998d0-3795-46c8-b70d-b27bac8be793 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:03:17.490: INFO: The status of Pod busybox-readonly-fsa71998d0-3795-46c8-b70d-b27bac8be793 is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:03:17.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5531" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":26,"skipped":526,"failed":0}

SSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:03:17.583: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name cm-test-opt-del-afc989a3-370c-45d5-8405-902b29dc9e10
STEP: Creating configMap with name cm-test-opt-upd-0d2fe1d6-a913-4dbe-94ee-aaf3113d0ca2
STEP: Creating the pod
May  2 20:03:17.807: INFO: The status of Pod pod-projected-configmaps-7a1c3d7c-fd03-49f8-a94b-423bdd18f721 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:03:19.829: INFO: The status of Pod pod-projected-configmaps-7a1c3d7c-fd03-49f8-a94b-423bdd18f721 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:03:21.833: INFO: The status of Pod pod-projected-configmaps-7a1c3d7c-fd03-49f8-a94b-423bdd18f721 is Running (Ready = true)
STEP: Deleting configmap cm-test-opt-del-afc989a3-370c-45d5-8405-902b29dc9e10
STEP: Updating configmap cm-test-opt-upd-0d2fe1d6-a913-4dbe-94ee-aaf3113d0ca2
STEP: Creating configMap with name cm-test-opt-create-9adff93d-24d9-4924-bd5b-94e791ad3332
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:03:26.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5228" for this suite.


• [SLOW TEST:8.650 seconds]
[sig-storage] Projected configMap
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":-1,"completed":27,"skipped":537,"failed":0}

SSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] server version
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:03:26.247: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename server-version
STEP: Waiting for a default service account to be provisioned in namespace
[It] should find the server version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Request ServerVersion
STEP: Confirm major version
May  2 20:03:26.370: INFO: Major version: 1
STEP: Confirm minor version
May  2 20:03:26.370: INFO: cleanMinorVersion: 22
May  2 20:03:26.370: INFO: Minor version: 22
[AfterEach] [sig-api-machinery] server version
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:03:26.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-8051" for this suite.

•
------------------------------
{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","total":-1,"completed":28,"skipped":543,"failed":0}

SSSSSSSSS
------------------------------
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:03:26.415: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] should run the lifecycle of a Deployment [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a Deployment
STEP: waiting for Deployment to be created
STEP: waiting for all Replicas to be Ready
May  2 20:03:26.519: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 0 and labels map[test-deployment-static:true]
May  2 20:03:26.520: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 0 and labels map[test-deployment-static:true]
May  2 20:03:26.552: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 0 and labels map[test-deployment-static:true]
May  2 20:03:26.553: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 0 and labels map[test-deployment-static:true]
May  2 20:03:26.630: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 0 and labels map[test-deployment-static:true]
May  2 20:03:26.630: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 0 and labels map[test-deployment-static:true]
May  2 20:03:26.698: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 0 and labels map[test-deployment-static:true]
May  2 20:03:26.699: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 0 and labels map[test-deployment-static:true]
May  2 20:03:28.983: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 1 and labels map[test-deployment-static:true]
May  2 20:03:28.994: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 1 and labels map[test-deployment-static:true]
May  2 20:03:30.014: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment
May  2 20:03:30.048: INFO: observed event type ADDED
STEP: waiting for Replicas to scale
May  2 20:03:30.052: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 0
May  2 20:03:30.052: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 0
May  2 20:03:30.052: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 0
May  2 20:03:30.052: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 0
May  2 20:03:30.052: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 0
May  2 20:03:30.052: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 0
May  2 20:03:30.052: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 0
May  2 20:03:30.052: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 0
May  2 20:03:30.052: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 1
May  2 20:03:30.052: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 1
May  2 20:03:30.052: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 2
May  2 20:03:30.052: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 2
May  2 20:03:30.052: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 2
May  2 20:03:30.053: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 2
May  2 20:03:30.119: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 2
May  2 20:03:30.119: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 2
May  2 20:03:30.233: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 2
May  2 20:03:30.233: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 2
May  2 20:03:30.300: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 1
May  2 20:03:30.300: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 1
May  2 20:03:30.313: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 1
May  2 20:03:30.313: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 1
May  2 20:03:33.975: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 2
May  2 20:03:33.975: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 2
May  2 20:03:34.083: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 1
STEP: listing Deployments
May  2 20:03:34.099: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment
May  2 20:03:34.144: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 1
STEP: fetching the DeploymentStatus
May  2 20:03:34.159: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
May  2 20:03:34.205: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
May  2 20:03:34.337: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
May  2 20:03:34.426: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
May  2 20:03:34.448: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
May  2 20:03:36.719: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
May  2 20:03:37.955: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
May  2 20:03:38.161: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
May  2 20:03:38.206: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
May  2 20:03:41.659: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus
STEP: fetching the DeploymentStatus
May  2 20:03:41.799: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 1
May  2 20:03:41.799: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 1
May  2 20:03:41.799: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 1
May  2 20:03:41.799: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 1
May  2 20:03:41.799: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 1
May  2 20:03:41.799: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 2
May  2 20:03:41.800: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 3
May  2 20:03:41.800: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 3
May  2 20:03:41.800: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 2
May  2 20:03:41.800: INFO: observed Deployment test-deployment in namespace deployment-8910 with ReadyReplicas 3
STEP: deleting the Deployment
May  2 20:03:41.841: INFO: observed event type MODIFIED
May  2 20:03:41.842: INFO: observed event type MODIFIED
May  2 20:03:41.842: INFO: observed event type MODIFIED
May  2 20:03:41.842: INFO: observed event type MODIFIED
May  2 20:03:41.842: INFO: observed event type MODIFIED
May  2 20:03:41.842: INFO: observed event type MODIFIED
May  2 20:03:41.842: INFO: observed event type MODIFIED
May  2 20:03:41.843: INFO: observed event type MODIFIED
May  2 20:03:41.843: INFO: observed event type MODIFIED
May  2 20:03:41.843: INFO: observed event type MODIFIED
May  2 20:03:41.843: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
May  2 20:03:41.856: INFO: Log out all the ReplicaSets if there is no deployment created
May  2 20:03:41.864: INFO: ReplicaSet "test-deployment-56c98d85f9":
&ReplicaSet{ObjectMeta:{test-deployment-56c98d85f9  deployment-8910  6b0345cc-cd00-4516-a17a-570661fd501b 2867834 4 2022-05-02 20:03:30 +0000 UTC <nil> <nil> map[pod-template-hash:56c98d85f9 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 8d36f300-b53e-4ec5-aacf-d16a0a1f5421 0xc0034d0db7 0xc0034d0db8}] []  [{kube-controller-manager Update apps/v1 2022-05-02 20:03:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8d36f300-b53e-4ec5-aacf-d16a0a1f5421\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-02 20:03:41 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 56c98d85f9,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:56c98d85f9 test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/pause:3.5 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0034d0e40 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

May  2 20:03:41.874: INFO: pod: "test-deployment-56c98d85f9-7d49b":
&Pod{ObjectMeta:{test-deployment-56c98d85f9-7d49b test-deployment-56c98d85f9- deployment-8910  7efb852c-10ed-4679-b84c-e5487440b572 2867830 0 2022-05-02 20:03:34 +0000 UTC 2022-05-02 20:03:42 +0000 UTC 0xc0032b8e38 map[pod-template-hash:56c98d85f9 test-deployment-static:true] map[cni.projectcalico.org/containerID:37c8d740dbfd4fbc44a7a363faded630093be1d502447538ff21bc1c04fd2b50 cni.projectcalico.org/podIP:10.233.112.231/32 cni.projectcalico.org/podIPs:10.233.112.231/32] [{apps/v1 ReplicaSet test-deployment-56c98d85f9 6b0345cc-cd00-4516-a17a-570661fd501b 0xc0032b8e67 0xc0032b8e68}] []  [{kube-controller-manager Update v1 2022-05-02 20:03:34 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6b0345cc-cd00-4516-a17a-570661fd501b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-05-02 20:03:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-05-02 20:03:36 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.112.231\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-st7h5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/pause:3.5,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-st7h5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:03:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:03:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:03:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:03:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.20.186,PodIP:10.233.112.231,StartTime:2022-05-02 20:03:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-02 20:03:36 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/pause:3.5,ImageID:docker-pullable://k8s.gcr.io/pause@sha256:1ff6c18fbef2045af6b9c16bf034cc421a29027b800e4f9b68ae9b1cb3e9ae07,ContainerID:docker://9c2e86ecc1ba7a10bcbfdd2553aab201b85f23cbddf813e5bfacc64586c7fe1d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.112.231,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

May  2 20:03:41.874: INFO: ReplicaSet "test-deployment-855f7994f9":
&ReplicaSet{ObjectMeta:{test-deployment-855f7994f9  deployment-8910  5dc9d3fe-32cb-45e3-b626-dfca8a06bc0a 2867696 3 2022-05-02 20:03:26 +0000 UTC <nil> <nil> map[pod-template-hash:855f7994f9 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 8d36f300-b53e-4ec5-aacf-d16a0a1f5421 0xc0034d0ea7 0xc0034d0ea8}] []  [{kube-controller-manager Update apps/v1 2022-05-02 20:03:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8d36f300-b53e-4ec5-aacf-d16a0a1f5421\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-02 20:03:34 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 855f7994f9,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:855f7994f9 test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/e2e-test-images/agnhost:2.32 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0034d0f50 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

May  2 20:03:41.890: INFO: ReplicaSet "test-deployment-d4dfddfbf":
&ReplicaSet{ObjectMeta:{test-deployment-d4dfddfbf  deployment-8910  76b9b579-38bb-45a8-91b7-282d094495bb 2867826 2 2022-05-02 20:03:34 +0000 UTC <nil> <nil> map[pod-template-hash:d4dfddfbf test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 8d36f300-b53e-4ec5-aacf-d16a0a1f5421 0xc0034d0fb7 0xc0034d0fb8}] []  [{kube-controller-manager Update apps/v1 2022-05-02 20:03:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8d36f300-b53e-4ec5-aacf-d16a0a1f5421\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-02 20:03:37 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: d4dfddfbf,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:d4dfddfbf test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0034d1040 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

May  2 20:03:41.950: INFO: pod: "test-deployment-d4dfddfbf-wm7pv":
&Pod{ObjectMeta:{test-deployment-d4dfddfbf-wm7pv test-deployment-d4dfddfbf- deployment-8910  515c1399-1e71-4ed6-99f8-e25f63f45f4c 2867825 0 2022-05-02 20:03:37 +0000 UTC <nil> <nil> map[pod-template-hash:d4dfddfbf test-deployment-static:true] map[cni.projectcalico.org/containerID:0cbd523fd81e60d810824625eca7d792253de94c1d2ebed68d3126dd82a34be7 cni.projectcalico.org/podIP:10.233.95.225/32 cni.projectcalico.org/podIPs:10.233.95.225/32] [{apps/v1 ReplicaSet test-deployment-d4dfddfbf 76b9b579-38bb-45a8-91b7-282d094495bb 0xc0032b9c57 0xc0032b9c58}] []  [{kube-controller-manager Update v1 2022-05-02 20:03:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"76b9b579-38bb-45a8-91b7-282d094495bb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-05-02 20:03:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-05-02 20:03:41 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.95.225\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6b9ns,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6b9ns,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:03:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:03:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:03:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:03:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.18.197,PodIP:10.233.95.225,StartTime:2022-05-02 20:03:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-02 20:03:40 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:docker://e8035633c60910368cc47e1d4fd1725ed9980400488d36b1e66789850af86884,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.95.225,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

May  2 20:03:41.951: INFO: pod: "test-deployment-d4dfddfbf-xbvxf":
&Pod{ObjectMeta:{test-deployment-d4dfddfbf-xbvxf test-deployment-d4dfddfbf- deployment-8910  6aa71bc3-c738-44dd-8756-4664e24d97d5 2867769 0 2022-05-02 20:03:34 +0000 UTC <nil> <nil> map[pod-template-hash:d4dfddfbf test-deployment-static:true] map[cni.projectcalico.org/containerID:7a1547730bd43e76b360ec858e2ffbc7ce7d8c290720b4c751a6259479e8ee67 cni.projectcalico.org/podIP:10.233.69.18/32 cni.projectcalico.org/podIPs:10.233.69.18/32] [{apps/v1 ReplicaSet test-deployment-d4dfddfbf 76b9b579-38bb-45a8-91b7-282d094495bb 0xc0032b9f17 0xc0032b9f18}] []  [{kube-controller-manager Update v1 2022-05-02 20:03:34 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"76b9b579-38bb-45a8-91b7-282d094495bb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-05-02 20:03:36 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-05-02 20:03:37 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.69.18\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-j7pfv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-j7pfv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:03:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:03:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:03:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:03:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.20.46,PodIP:10.233.69.18,StartTime:2022-05-02 20:03:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-02 20:03:36 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:docker://ab2016472f02973f3bda64d4ea3968dd0c6b4937f958731c41afbcb77a1dc240,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.69.18,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:03:41.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8910" for this suite.


• [SLOW TEST:15.580 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","total":-1,"completed":29,"skipped":552,"failed":0}

SSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:03:42.072: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:03:48.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7117" for this suite.


• [SLOW TEST:6.278 seconds]
[sig-node] Docker Containers
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":-1,"completed":30,"skipped":564,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:03:48.414: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
[It] should schedule multiple jobs concurrently [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a cronjob
STEP: Ensuring more than one job is running at a time
STEP: Ensuring at least two running jobs exists by listing jobs explicitly
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:05:00.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-7622" for this suite.


• [SLOW TEST:72.209 seconds]
[sig-apps] CronJob
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","total":-1,"completed":31,"skipped":598,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:05:01.037: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with secret that has name secret-emptykey-test-3d8a87aa-0d3c-4352-843a-61cdb54e7f1f
[AfterEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:05:01.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9831" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","total":-1,"completed":32,"skipped":678,"failed":0}

SSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:05:01.258: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod pod-subpath-test-configmap-7lc8
STEP: Creating a pod to test atomic-volume-subpath
May  2 20:05:01.508: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-7lc8" in namespace "subpath-4893" to be "Succeeded or Failed"
May  2 20:05:01.523: INFO: Pod "pod-subpath-test-configmap-7lc8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.317977ms
May  2 20:05:03.568: INFO: Pod "pod-subpath-test-configmap-7lc8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059970499s
May  2 20:05:05.583: INFO: Pod "pod-subpath-test-configmap-7lc8": Phase="Running", Reason="", readiness=true. Elapsed: 4.074550046s
May  2 20:05:07.607: INFO: Pod "pod-subpath-test-configmap-7lc8": Phase="Running", Reason="", readiness=true. Elapsed: 6.098958001s
May  2 20:05:09.623: INFO: Pod "pod-subpath-test-configmap-7lc8": Phase="Running", Reason="", readiness=true. Elapsed: 8.11463683s
May  2 20:05:11.632: INFO: Pod "pod-subpath-test-configmap-7lc8": Phase="Running", Reason="", readiness=true. Elapsed: 10.123454431s
May  2 20:05:13.672: INFO: Pod "pod-subpath-test-configmap-7lc8": Phase="Running", Reason="", readiness=true. Elapsed: 12.163526505s
May  2 20:05:15.684: INFO: Pod "pod-subpath-test-configmap-7lc8": Phase="Running", Reason="", readiness=true. Elapsed: 14.175147951s
May  2 20:05:17.698: INFO: Pod "pod-subpath-test-configmap-7lc8": Phase="Running", Reason="", readiness=true. Elapsed: 16.189391321s
May  2 20:05:19.713: INFO: Pod "pod-subpath-test-configmap-7lc8": Phase="Running", Reason="", readiness=true. Elapsed: 18.204526276s
May  2 20:05:21.720: INFO: Pod "pod-subpath-test-configmap-7lc8": Phase="Running", Reason="", readiness=true. Elapsed: 20.211164328s
May  2 20:05:23.736: INFO: Pod "pod-subpath-test-configmap-7lc8": Phase="Running", Reason="", readiness=true. Elapsed: 22.227879602s
May  2 20:05:25.770: INFO: Pod "pod-subpath-test-configmap-7lc8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.261578119s
STEP: Saw pod success
May  2 20:05:25.770: INFO: Pod "pod-subpath-test-configmap-7lc8" satisfied condition "Succeeded or Failed"
May  2 20:05:25.778: INFO: Trying to get logs from node node-2 pod pod-subpath-test-configmap-7lc8 container test-container-subpath-configmap-7lc8: <nil>
STEP: delete the pod
May  2 20:05:25.883: INFO: Waiting for pod pod-subpath-test-configmap-7lc8 to disappear
May  2 20:05:25.898: INFO: Pod pod-subpath-test-configmap-7lc8 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-7lc8
May  2 20:05:25.898: INFO: Deleting pod "pod-subpath-test-configmap-7lc8" in namespace "subpath-4893"
[AfterEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:05:25.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4893" for this suite.


• [SLOW TEST:24.706 seconds]
[sig-storage] Subpath
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [LinuxOnly] [Conformance]","total":-1,"completed":33,"skipped":688,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:02:44.634: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: set up a multi version CRD
May  2 20:02:44.773: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:05:30.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2672" for this suite.


• [SLOW TEST:166.203 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":-1,"completed":59,"skipped":1097,"failed":0}

SSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:05:30.922: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:05:31.124: INFO: Creating deployment "test-recreate-deployment"
May  2 20:05:31.156: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
May  2 20:05:31.226: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
May  2 20:05:33.255: INFO: Waiting deployment "test-recreate-deployment" to complete
May  2 20:05:33.274: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118731, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118731, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118731, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118731, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6cb8b65c46\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  2 20:05:35.290: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
May  2 20:05:35.321: INFO: Updating deployment test-recreate-deployment
May  2 20:05:35.321: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
May  2 20:05:35.570: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-9245  1cda108d-d8e2-4a32-8e54-adb5cd7ce0ae 2868780 2 2022-05-02 20:05:31 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-05-02 20:05:35 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-02 20:05:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc007c89b08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-05-02 20:05:35 +0000 UTC,LastTransitionTime:2022-05-02 20:05:35 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-85d47dcb4" is progressing.,LastUpdateTime:2022-05-02 20:05:35 +0000 UTC,LastTransitionTime:2022-05-02 20:05:31 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

May  2 20:05:35.592: INFO: New ReplicaSet "test-recreate-deployment-85d47dcb4" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-85d47dcb4  deployment-9245  0e2686e8-f111-4439-9e14-a0d3fbb43d58 2868779 1 2022-05-02 20:05:35 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:85d47dcb4] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 1cda108d-d8e2-4a32-8e54-adb5cd7ce0ae 0xc007ccc1b0 0xc007ccc1b1}] []  [{kube-controller-manager Update apps/v1 2022-05-02 20:05:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1cda108d-d8e2-4a32-8e54-adb5cd7ce0ae\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-02 20:05:35 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 85d47dcb4,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:85d47dcb4] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc007ccc288 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May  2 20:05:35.592: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
May  2 20:05:35.592: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-6cb8b65c46  deployment-9245  b17718f5-431e-4aae-b0a9-d30fd986bb6b 2868769 2 2022-05-02 20:05:31 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:6cb8b65c46] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 1cda108d-d8e2-4a32-8e54-adb5cd7ce0ae 0xc007ccc027 0xc007ccc028}] []  [{kube-controller-manager Update apps/v1 2022-05-02 20:05:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1cda108d-d8e2-4a32-8e54-adb5cd7ce0ae\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-02 20:05:35 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6cb8b65c46,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:6cb8b65c46] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.32 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc007ccc118 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May  2 20:05:35.614: INFO: Pod "test-recreate-deployment-85d47dcb4-w2s57" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-85d47dcb4-w2s57 test-recreate-deployment-85d47dcb4- deployment-9245  6e545fd5-e180-416d-95f9-841c457e5c0e 2868778 0 2022-05-02 20:05:35 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:85d47dcb4] map[] [{apps/v1 ReplicaSet test-recreate-deployment-85d47dcb4 0e2686e8-f111-4439-9e14-a0d3fbb43d58 0xc00788ca40 0xc00788ca41}] []  [{kube-controller-manager Update v1 2022-05-02 20:05:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0e2686e8-f111-4439-9e14-a0d3fbb43d58\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-twx87,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-twx87,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:05:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:05:35.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9245" for this suite.

•
------------------------------
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":-1,"completed":60,"skipped":1115,"failed":0}
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:05:35.660: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:82
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:05:39.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8665" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":-1,"completed":61,"skipped":1115,"failed":0}

SSSS
------------------------------
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:05:26.082: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
May  2 20:05:27.364: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
May  2 20:05:29.390: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118727, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118727, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118727, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118727, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-697cdbd8f4\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  2 20:05:32.521: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:05:32.543: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:05:40.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-3239" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137


• [SLOW TEST:14.823 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":-1,"completed":34,"skipped":780,"failed":0}

SSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:05:41.323: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/init_container.go:162
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
May  2 20:05:41.698: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:05:47.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1922" for this suite.


• [SLOW TEST:5.845 seconds]
[sig-node] InitContainer [NodeConformance]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":-1,"completed":35,"skipped":798,"failed":0}

SSSS
------------------------------
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:05:47.191: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
May  2 20:05:47.318: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7f32f325-d71c-407e-88f2-fc7f5f95e773" in namespace "projected-1285" to be "Succeeded or Failed"
May  2 20:05:47.327: INFO: Pod "downwardapi-volume-7f32f325-d71c-407e-88f2-fc7f5f95e773": Phase="Pending", Reason="", readiness=false. Elapsed: 8.91384ms
May  2 20:05:49.342: INFO: Pod "downwardapi-volume-7f32f325-d71c-407e-88f2-fc7f5f95e773": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023924792s
May  2 20:05:51.368: INFO: Pod "downwardapi-volume-7f32f325-d71c-407e-88f2-fc7f5f95e773": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050096227s
STEP: Saw pod success
May  2 20:05:51.368: INFO: Pod "downwardapi-volume-7f32f325-d71c-407e-88f2-fc7f5f95e773" satisfied condition "Succeeded or Failed"
May  2 20:05:51.377: INFO: Trying to get logs from node node-2 pod downwardapi-volume-7f32f325-d71c-407e-88f2-fc7f5f95e773 container client-container: <nil>
STEP: delete the pod
May  2 20:05:51.546: INFO: Waiting for pod downwardapi-volume-7f32f325-d71c-407e-88f2-fc7f5f95e773 to disappear
May  2 20:05:51.591: INFO: Pod downwardapi-volume-7f32f325-d71c-407e-88f2-fc7f5f95e773 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:05:51.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1285" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":-1,"completed":36,"skipped":802,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:05:40.049: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3607.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-3607.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3607.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3607.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-3607.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-3607.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-3607.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-3607.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3607.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3607.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-3607.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3607.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-3607.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-3607.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-3607.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-3607.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-3607.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3607.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May  2 20:05:48.460: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-3607.svc.cluster.local from pod dns-3607/dns-test-7b7b01ac-ec42-4249-88c0-e39aaa220dcd: the server could not find the requested resource (get pods dns-test-7b7b01ac-ec42-4249-88c0-e39aaa220dcd)
May  2 20:05:48.471: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3607.svc.cluster.local from pod dns-3607/dns-test-7b7b01ac-ec42-4249-88c0-e39aaa220dcd: the server could not find the requested resource (get pods dns-test-7b7b01ac-ec42-4249-88c0-e39aaa220dcd)
May  2 20:05:48.482: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-3607.svc.cluster.local from pod dns-3607/dns-test-7b7b01ac-ec42-4249-88c0-e39aaa220dcd: the server could not find the requested resource (get pods dns-test-7b7b01ac-ec42-4249-88c0-e39aaa220dcd)
May  2 20:05:48.496: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-3607.svc.cluster.local from pod dns-3607/dns-test-7b7b01ac-ec42-4249-88c0-e39aaa220dcd: the server could not find the requested resource (get pods dns-test-7b7b01ac-ec42-4249-88c0-e39aaa220dcd)
May  2 20:05:48.529: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-3607.svc.cluster.local from pod dns-3607/dns-test-7b7b01ac-ec42-4249-88c0-e39aaa220dcd: the server could not find the requested resource (get pods dns-test-7b7b01ac-ec42-4249-88c0-e39aaa220dcd)
May  2 20:05:48.541: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-3607.svc.cluster.local from pod dns-3607/dns-test-7b7b01ac-ec42-4249-88c0-e39aaa220dcd: the server could not find the requested resource (get pods dns-test-7b7b01ac-ec42-4249-88c0-e39aaa220dcd)
May  2 20:05:48.552: INFO: Unable to read jessie_udp@dns-test-service-2.dns-3607.svc.cluster.local from pod dns-3607/dns-test-7b7b01ac-ec42-4249-88c0-e39aaa220dcd: the server could not find the requested resource (get pods dns-test-7b7b01ac-ec42-4249-88c0-e39aaa220dcd)
May  2 20:05:48.569: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-3607.svc.cluster.local from pod dns-3607/dns-test-7b7b01ac-ec42-4249-88c0-e39aaa220dcd: the server could not find the requested resource (get pods dns-test-7b7b01ac-ec42-4249-88c0-e39aaa220dcd)
May  2 20:05:48.630: INFO: Lookups using dns-3607/dns-test-7b7b01ac-ec42-4249-88c0-e39aaa220dcd failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-3607.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3607.svc.cluster.local wheezy_udp@dns-test-service-2.dns-3607.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-3607.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-3607.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-3607.svc.cluster.local jessie_udp@dns-test-service-2.dns-3607.svc.cluster.local jessie_tcp@dns-test-service-2.dns-3607.svc.cluster.local]

May  2 20:05:53.815: INFO: DNS probes using dns-3607/dns-test-7b7b01ac-ec42-4249-88c0-e39aaa220dcd succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:05:53.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3607" for this suite.


• [SLOW TEST:13.896 seconds]
[sig-network] DNS
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":-1,"completed":62,"skipped":1119,"failed":0}
[BeforeEach] version v1
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:05:53.949: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-ts5ck in namespace proxy-9308
I0502 20:05:54.174758      18 runners.go:190] Created replication controller with name: proxy-service-ts5ck, namespace: proxy-9308, replica count: 1
I0502 20:05:55.229526      18 runners.go:190] proxy-service-ts5ck Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0502 20:05:56.231337      18 runners.go:190] proxy-service-ts5ck Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0502 20:05:57.231639      18 runners.go:190] proxy-service-ts5ck Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0502 20:05:58.471757      18 runners.go:190] proxy-service-ts5ck Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  2 20:05:58.926: INFO: setup took 4.81283577s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
May  2 20:05:59.067: INFO: (0) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:160/proxy/: foo (200; 136.050846ms)
May  2 20:05:59.067: INFO: (0) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:160/proxy/: foo (200; 136.129162ms)
May  2 20:05:59.067: INFO: (0) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/rewriteme">test</a> (200; 135.830054ms)
May  2 20:05:59.067: INFO: (0) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/rewriteme">... (200; 135.160265ms)
May  2 20:05:59.067: INFO: (0) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname1/proxy/: foo (200; 136.025841ms)
May  2 20:05:59.067: INFO: (0) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/rewriteme">test<... (200; 135.789018ms)
May  2 20:05:59.067: INFO: (0) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname1/proxy/: foo (200; 135.352783ms)
May  2 20:05:59.067: INFO: (0) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname2/proxy/: bar (200; 135.980957ms)
May  2 20:05:59.067: INFO: (0) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname2/proxy/: bar (200; 135.322718ms)
May  2 20:05:59.067: INFO: (0) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:162/proxy/: bar (200; 135.596178ms)
May  2 20:05:59.067: INFO: (0) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:162/proxy/: bar (200; 136.828349ms)
May  2 20:05:59.117: INFO: (0) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname2/proxy/: tls qux (200; 185.696682ms)
May  2 20:05:59.117: INFO: (0) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:462/proxy/: tls qux (200; 185.757165ms)
May  2 20:05:59.142: INFO: (0) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname1/proxy/: tls baz (200; 211.70391ms)
May  2 20:05:59.142: INFO: (0) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/tlsrewritem... (200; 210.749928ms)
May  2 20:05:59.142: INFO: (0) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:460/proxy/: tls baz (200; 211.535725ms)
May  2 20:05:59.207: INFO: (1) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:162/proxy/: bar (200; 57.382766ms)
May  2 20:05:59.207: INFO: (1) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/rewriteme">... (200; 57.35264ms)
May  2 20:05:59.207: INFO: (1) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:160/proxy/: foo (200; 58.666884ms)
May  2 20:05:59.207: INFO: (1) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname2/proxy/: bar (200; 64.476479ms)
May  2 20:05:59.207: INFO: (1) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:160/proxy/: foo (200; 57.948333ms)
May  2 20:05:59.207: INFO: (1) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/rewriteme">test<... (200; 58.119462ms)
May  2 20:05:59.207: INFO: (1) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:462/proxy/: tls qux (200; 62.140447ms)
May  2 20:05:59.207: INFO: (1) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:162/proxy/: bar (200; 57.315832ms)
May  2 20:05:59.207: INFO: (1) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname2/proxy/: tls qux (200; 62.375036ms)
May  2 20:05:59.207: INFO: (1) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname1/proxy/: foo (200; 57.213731ms)
May  2 20:05:59.207: INFO: (1) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname2/proxy/: bar (200; 56.978191ms)
May  2 20:05:59.207: INFO: (1) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/rewriteme">test</a> (200; 58.550476ms)
May  2 20:05:59.207: INFO: (1) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:460/proxy/: tls baz (200; 57.982436ms)
May  2 20:05:59.207: INFO: (1) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/tlsrewritem... (200; 57.199975ms)
May  2 20:05:59.207: INFO: (1) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname1/proxy/: foo (200; 57.910883ms)
May  2 20:05:59.207: INFO: (1) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname1/proxy/: tls baz (200; 62.237789ms)
May  2 20:05:59.230: INFO: (2) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:160/proxy/: foo (200; 22.851357ms)
May  2 20:05:59.241: INFO: (2) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:160/proxy/: foo (200; 24.364943ms)
May  2 20:05:59.241: INFO: (2) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:462/proxy/: tls qux (200; 24.785498ms)
May  2 20:05:59.241: INFO: (2) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:460/proxy/: tls baz (200; 24.71146ms)
May  2 20:05:59.248: INFO: (2) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:162/proxy/: bar (200; 30.935909ms)
May  2 20:05:59.248: INFO: (2) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/rewriteme">... (200; 31.166629ms)
May  2 20:05:59.248: INFO: (2) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:162/proxy/: bar (200; 31.062916ms)
May  2 20:05:59.254: INFO: (2) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/rewriteme">test<... (200; 37.13479ms)
May  2 20:05:59.254: INFO: (2) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/rewriteme">test</a> (200; 37.27933ms)
May  2 20:05:59.254: INFO: (2) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/tlsrewritem... (200; 37.158354ms)
May  2 20:05:59.254: INFO: (2) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname2/proxy/: tls qux (200; 37.2685ms)
May  2 20:05:59.254: INFO: (2) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname2/proxy/: bar (200; 37.152303ms)
May  2 20:05:59.254: INFO: (2) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname2/proxy/: bar (200; 37.417417ms)
May  2 20:05:59.254: INFO: (2) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname1/proxy/: tls baz (200; 37.096758ms)
May  2 20:05:59.254: INFO: (2) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname1/proxy/: foo (200; 37.233514ms)
May  2 20:05:59.254: INFO: (2) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname1/proxy/: foo (200; 37.519759ms)
May  2 20:05:59.272: INFO: (3) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:462/proxy/: tls qux (200; 17.487625ms)
May  2 20:05:59.272: INFO: (3) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:162/proxy/: bar (200; 17.868115ms)
May  2 20:05:59.274: INFO: (3) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/tlsrewritem... (200; 19.720393ms)
May  2 20:05:59.277: INFO: (3) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:160/proxy/: foo (200; 22.232683ms)
May  2 20:05:59.277: INFO: (3) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:160/proxy/: foo (200; 22.25286ms)
May  2 20:05:59.277: INFO: (3) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:162/proxy/: bar (200; 22.444909ms)
May  2 20:05:59.277: INFO: (3) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/rewriteme">test<... (200; 21.964372ms)
May  2 20:05:59.281: INFO: (3) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/rewriteme">... (200; 26.703477ms)
May  2 20:05:59.282: INFO: (3) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname1/proxy/: foo (200; 27.526644ms)
May  2 20:05:59.282: INFO: (3) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/rewriteme">test</a> (200; 26.923128ms)
May  2 20:05:59.282: INFO: (3) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:460/proxy/: tls baz (200; 27.134813ms)
May  2 20:05:59.282: INFO: (3) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname2/proxy/: bar (200; 27.034105ms)
May  2 20:05:59.284: INFO: (3) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname1/proxy/: foo (200; 28.437804ms)
May  2 20:05:59.286: INFO: (3) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname2/proxy/: tls qux (200; 30.483414ms)
May  2 20:05:59.287: INFO: (3) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname2/proxy/: bar (200; 32.559739ms)
May  2 20:05:59.290: INFO: (3) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname1/proxy/: tls baz (200; 35.204657ms)
May  2 20:05:59.306: INFO: (4) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:160/proxy/: foo (200; 16.187647ms)
May  2 20:05:59.308: INFO: (4) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/rewriteme">test</a> (200; 17.364805ms)
May  2 20:05:59.308: INFO: (4) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/tlsrewritem... (200; 17.131178ms)
May  2 20:05:59.308: INFO: (4) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:460/proxy/: tls baz (200; 17.713726ms)
May  2 20:05:59.308: INFO: (4) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:162/proxy/: bar (200; 16.927159ms)
May  2 20:05:59.308: INFO: (4) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/rewriteme">test<... (200; 17.458129ms)
May  2 20:05:59.314: INFO: (4) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:162/proxy/: bar (200; 23.190319ms)
May  2 20:05:59.314: INFO: (4) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname2/proxy/: bar (200; 23.799767ms)
May  2 20:05:59.315: INFO: (4) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname2/proxy/: bar (200; 23.800869ms)
May  2 20:05:59.315: INFO: (4) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname1/proxy/: foo (200; 24.308487ms)
May  2 20:05:59.315: INFO: (4) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname1/proxy/: foo (200; 24.784295ms)
May  2 20:05:59.317: INFO: (4) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/rewriteme">... (200; 26.133594ms)
May  2 20:05:59.317: INFO: (4) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname1/proxy/: tls baz (200; 25.867166ms)
May  2 20:05:59.317: INFO: (4) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:462/proxy/: tls qux (200; 26.473809ms)
May  2 20:05:59.317: INFO: (4) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:160/proxy/: foo (200; 26.654185ms)
May  2 20:05:59.318: INFO: (4) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname2/proxy/: tls qux (200; 26.821097ms)
May  2 20:05:59.340: INFO: (5) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:160/proxy/: foo (200; 22.109512ms)
May  2 20:05:59.340: INFO: (5) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:160/proxy/: foo (200; 22.075708ms)
May  2 20:05:59.340: INFO: (5) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:162/proxy/: bar (200; 22.099923ms)
May  2 20:05:59.342: INFO: (5) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/rewriteme">test</a> (200; 24.038082ms)
May  2 20:05:59.342: INFO: (5) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname1/proxy/: tls baz (200; 24.322844ms)
May  2 20:05:59.354: INFO: (5) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname1/proxy/: foo (200; 35.544992ms)
May  2 20:05:59.355: INFO: (5) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname2/proxy/: bar (200; 36.977776ms)
May  2 20:05:59.355: INFO: (5) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname2/proxy/: bar (200; 37.287705ms)
May  2 20:05:59.355: INFO: (5) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/rewriteme">... (200; 36.972898ms)
May  2 20:05:59.357: INFO: (5) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:462/proxy/: tls qux (200; 39.077106ms)
May  2 20:05:59.358: INFO: (5) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname1/proxy/: foo (200; 39.205415ms)
May  2 20:05:59.358: INFO: (5) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/rewriteme">test<... (200; 39.318095ms)
May  2 20:05:59.358: INFO: (5) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/tlsrewritem... (200; 39.237454ms)
May  2 20:05:59.358: INFO: (5) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:460/proxy/: tls baz (200; 39.360935ms)
May  2 20:05:59.358: INFO: (5) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:162/proxy/: bar (200; 39.35307ms)
May  2 20:05:59.358: INFO: (5) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname2/proxy/: tls qux (200; 39.688587ms)
May  2 20:05:59.373: INFO: (6) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/rewriteme">... (200; 14.343836ms)
May  2 20:05:59.374: INFO: (6) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/rewriteme">test<... (200; 15.67458ms)
May  2 20:05:59.374: INFO: (6) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:160/proxy/: foo (200; 15.8249ms)
May  2 20:05:59.374: INFO: (6) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:462/proxy/: tls qux (200; 16.397819ms)
May  2 20:05:59.378: INFO: (6) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname1/proxy/: foo (200; 20.280788ms)
May  2 20:05:59.378: INFO: (6) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:162/proxy/: bar (200; 20.054625ms)
May  2 20:05:59.378: INFO: (6) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:460/proxy/: tls baz (200; 19.967133ms)
May  2 20:05:59.379: INFO: (6) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:160/proxy/: foo (200; 19.909545ms)
May  2 20:05:59.380: INFO: (6) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:162/proxy/: bar (200; 21.91629ms)
May  2 20:05:59.383: INFO: (6) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname1/proxy/: foo (200; 24.102011ms)
May  2 20:05:59.383: INFO: (6) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname2/proxy/: bar (200; 24.574533ms)
May  2 20:05:59.383: INFO: (6) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/tlsrewritem... (200; 24.325048ms)
May  2 20:05:59.384: INFO: (6) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname2/proxy/: bar (200; 25.345843ms)
May  2 20:05:59.384: INFO: (6) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/rewriteme">test</a> (200; 25.366422ms)
May  2 20:05:59.387: INFO: (6) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname1/proxy/: tls baz (200; 28.340032ms)
May  2 20:05:59.387: INFO: (6) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname2/proxy/: tls qux (200; 28.712547ms)
May  2 20:05:59.402: INFO: (7) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:160/proxy/: foo (200; 14.721371ms)
May  2 20:05:59.405: INFO: (7) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:462/proxy/: tls qux (200; 17.478347ms)
May  2 20:05:59.405: INFO: (7) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/tlsrewritem... (200; 17.065206ms)
May  2 20:05:59.407: INFO: (7) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:460/proxy/: tls baz (200; 18.710907ms)
May  2 20:05:59.407: INFO: (7) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:162/proxy/: bar (200; 19.018ms)
May  2 20:05:59.407: INFO: (7) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/rewriteme">test</a> (200; 18.750181ms)
May  2 20:05:59.407: INFO: (7) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:162/proxy/: bar (200; 19.15109ms)
May  2 20:05:59.407: INFO: (7) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:160/proxy/: foo (200; 19.082251ms)
May  2 20:05:59.409: INFO: (7) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname2/proxy/: tls qux (200; 21.544687ms)
May  2 20:05:59.414: INFO: (7) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/rewriteme">... (200; 25.946756ms)
May  2 20:05:59.414: INFO: (7) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/rewriteme">test<... (200; 25.673595ms)
May  2 20:05:59.414: INFO: (7) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname1/proxy/: foo (200; 26.338256ms)
May  2 20:05:59.414: INFO: (7) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname1/proxy/: tls baz (200; 26.058734ms)
May  2 20:05:59.414: INFO: (7) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname1/proxy/: foo (200; 26.011867ms)
May  2 20:05:59.419: INFO: (7) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname2/proxy/: bar (200; 30.806037ms)
May  2 20:05:59.419: INFO: (7) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname2/proxy/: bar (200; 30.4276ms)
May  2 20:05:59.432: INFO: (8) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:160/proxy/: foo (200; 13.395405ms)
May  2 20:05:59.434: INFO: (8) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/rewriteme">... (200; 13.615787ms)
May  2 20:05:59.434: INFO: (8) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:162/proxy/: bar (200; 13.630163ms)
May  2 20:05:59.436: INFO: (8) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:160/proxy/: foo (200; 16.790383ms)
May  2 20:05:59.438: INFO: (8) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/rewriteme">test</a> (200; 18.324596ms)
May  2 20:05:59.439: INFO: (8) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname1/proxy/: foo (200; 19.78325ms)
May  2 20:05:59.439: INFO: (8) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/rewriteme">test<... (200; 19.878498ms)
May  2 20:05:59.441: INFO: (8) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/tlsrewritem... (200; 20.662702ms)
May  2 20:05:59.445: INFO: (8) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:162/proxy/: bar (200; 24.826273ms)
May  2 20:05:59.445: INFO: (8) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname2/proxy/: bar (200; 24.801277ms)
May  2 20:05:59.445: INFO: (8) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname2/proxy/: bar (200; 25.493148ms)
May  2 20:05:59.445: INFO: (8) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname2/proxy/: tls qux (200; 25.23138ms)
May  2 20:05:59.445: INFO: (8) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname1/proxy/: foo (200; 24.996702ms)
May  2 20:05:59.445: INFO: (8) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:460/proxy/: tls baz (200; 25.419071ms)
May  2 20:05:59.445: INFO: (8) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname1/proxy/: tls baz (200; 24.904228ms)
May  2 20:05:59.445: INFO: (8) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:462/proxy/: tls qux (200; 25.346545ms)
May  2 20:05:59.474: INFO: (9) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:162/proxy/: bar (200; 25.248932ms)
May  2 20:05:59.474: INFO: (9) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/rewriteme">test<... (200; 23.350468ms)
May  2 20:05:59.474: INFO: (9) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:162/proxy/: bar (200; 25.22666ms)
May  2 20:05:59.474: INFO: (9) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:160/proxy/: foo (200; 23.255631ms)
May  2 20:05:59.477: INFO: (9) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname1/proxy/: foo (200; 28.016729ms)
May  2 20:05:59.477: INFO: (9) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/rewriteme">... (200; 28.693412ms)
May  2 20:05:59.477: INFO: (9) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:460/proxy/: tls baz (200; 26.336021ms)
May  2 20:05:59.478: INFO: (9) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname1/proxy/: foo (200; 26.7853ms)
May  2 20:05:59.478: INFO: (9) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname2/proxy/: bar (200; 28.634391ms)
May  2 20:05:59.478: INFO: (9) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:462/proxy/: tls qux (200; 29.736198ms)
May  2 20:05:59.478: INFO: (9) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:160/proxy/: foo (200; 27.351748ms)
May  2 20:05:59.478: INFO: (9) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname2/proxy/: tls qux (200; 32.748011ms)
May  2 20:05:59.481: INFO: (9) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname1/proxy/: tls baz (200; 30.493642ms)
May  2 20:05:59.481: INFO: (9) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname2/proxy/: bar (200; 35.80118ms)
May  2 20:05:59.481: INFO: (9) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/tlsrewritem... (200; 31.937798ms)
May  2 20:05:59.481: INFO: (9) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/rewriteme">test</a> (200; 30.127308ms)
May  2 20:05:59.503: INFO: (10) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:460/proxy/: tls baz (200; 21.337349ms)
May  2 20:05:59.509: INFO: (10) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:462/proxy/: tls qux (200; 28.107889ms)
May  2 20:05:59.509: INFO: (10) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/rewriteme">... (200; 26.079693ms)
May  2 20:05:59.509: INFO: (10) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/rewriteme">test<... (200; 26.581009ms)
May  2 20:05:59.517: INFO: (10) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:162/proxy/: bar (200; 32.66725ms)
May  2 20:05:59.517: INFO: (10) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:160/proxy/: foo (200; 34.000479ms)
May  2 20:05:59.517: INFO: (10) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:160/proxy/: foo (200; 32.437902ms)
May  2 20:05:59.517: INFO: (10) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/rewriteme">test</a> (200; 34.330033ms)
May  2 20:05:59.517: INFO: (10) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/tlsrewritem... (200; 33.509141ms)
May  2 20:05:59.517: INFO: (10) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:162/proxy/: bar (200; 32.926945ms)
May  2 20:05:59.522: INFO: (10) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname1/proxy/: foo (200; 40.255625ms)
May  2 20:05:59.524: INFO: (10) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname1/proxy/: foo (200; 40.100645ms)
May  2 20:05:59.524: INFO: (10) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname2/proxy/: bar (200; 41.912839ms)
May  2 20:05:59.525: INFO: (10) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname2/proxy/: bar (200; 41.111173ms)
May  2 20:05:59.525: INFO: (10) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname1/proxy/: tls baz (200; 40.83101ms)
May  2 20:05:59.526: INFO: (10) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname2/proxy/: tls qux (200; 43.129971ms)
May  2 20:05:59.539: INFO: (11) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:160/proxy/: foo (200; 12.472742ms)
May  2 20:05:59.539: INFO: (11) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/rewriteme">test<... (200; 12.731805ms)
May  2 20:05:59.540: INFO: (11) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:460/proxy/: tls baz (200; 13.026988ms)
May  2 20:05:59.540: INFO: (11) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:160/proxy/: foo (200; 13.121063ms)
May  2 20:05:59.543: INFO: (11) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/rewriteme">... (200; 15.783463ms)
May  2 20:05:59.544: INFO: (11) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:462/proxy/: tls qux (200; 17.174631ms)
May  2 20:05:59.544: INFO: (11) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname1/proxy/: foo (200; 17.851402ms)
May  2 20:05:59.547: INFO: (11) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/rewriteme">test</a> (200; 19.891952ms)
May  2 20:05:59.547: INFO: (11) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname2/proxy/: bar (200; 20.084652ms)
May  2 20:05:59.550: INFO: (11) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname1/proxy/: foo (200; 23.707184ms)
May  2 20:05:59.551: INFO: (11) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:162/proxy/: bar (200; 23.810277ms)
May  2 20:05:59.551: INFO: (11) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:162/proxy/: bar (200; 23.961509ms)
May  2 20:05:59.551: INFO: (11) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname1/proxy/: tls baz (200; 24.217918ms)
May  2 20:05:59.551: INFO: (11) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname2/proxy/: tls qux (200; 24.073908ms)
May  2 20:05:59.551: INFO: (11) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/tlsrewritem... (200; 23.984311ms)
May  2 20:05:59.552: INFO: (11) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname2/proxy/: bar (200; 25.03913ms)
May  2 20:05:59.570: INFO: (12) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:162/proxy/: bar (200; 17.871331ms)
May  2 20:05:59.570: INFO: (12) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/rewriteme">test</a> (200; 17.666508ms)
May  2 20:05:59.580: INFO: (12) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/rewriteme">test<... (200; 27.565516ms)
May  2 20:05:59.590: INFO: (12) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:162/proxy/: bar (200; 37.074057ms)
May  2 20:05:59.590: INFO: (12) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/rewriteme">... (200; 37.361914ms)
May  2 20:05:59.590: INFO: (12) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:160/proxy/: foo (200; 37.798348ms)
May  2 20:05:59.590: INFO: (12) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:462/proxy/: tls qux (200; 37.744348ms)
May  2 20:05:59.590: INFO: (12) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:160/proxy/: foo (200; 37.862468ms)
May  2 20:05:59.610: INFO: (12) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname1/proxy/: foo (200; 58.164646ms)
May  2 20:05:59.611: INFO: (12) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname2/proxy/: bar (200; 58.982974ms)
May  2 20:05:59.631: INFO: (12) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname1/proxy/: foo (200; 77.994633ms)
May  2 20:05:59.631: INFO: (12) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname2/proxy/: bar (200; 77.951853ms)
May  2 20:05:59.631: INFO: (12) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:460/proxy/: tls baz (200; 78.243067ms)
May  2 20:05:59.631: INFO: (12) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname1/proxy/: tls baz (200; 78.36232ms)
May  2 20:05:59.631: INFO: (12) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname2/proxy/: tls qux (200; 78.273192ms)
May  2 20:05:59.634: INFO: (12) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/tlsrewritem... (200; 81.284945ms)
May  2 20:05:59.666: INFO: (13) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname2/proxy/: bar (200; 31.230779ms)
May  2 20:05:59.666: INFO: (13) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/rewriteme">test</a> (200; 31.607944ms)
May  2 20:05:59.667: INFO: (13) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/tlsrewritem... (200; 31.141633ms)
May  2 20:05:59.667: INFO: (13) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:160/proxy/: foo (200; 31.546588ms)
May  2 20:05:59.667: INFO: (13) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/rewriteme">... (200; 31.257428ms)
May  2 20:05:59.667: INFO: (13) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:460/proxy/: tls baz (200; 31.534516ms)
May  2 20:05:59.667: INFO: (13) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:462/proxy/: tls qux (200; 32.527339ms)
May  2 20:05:59.667: INFO: (13) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/rewriteme">test<... (200; 31.989585ms)
May  2 20:05:59.667: INFO: (13) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:162/proxy/: bar (200; 31.80446ms)
May  2 20:05:59.668: INFO: (13) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:160/proxy/: foo (200; 33.369411ms)
May  2 20:05:59.668: INFO: (13) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname1/proxy/: foo (200; 32.595035ms)
May  2 20:05:59.669: INFO: (13) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname2/proxy/: tls qux (200; 33.997493ms)
May  2 20:05:59.672: INFO: (13) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname1/proxy/: foo (200; 37.377342ms)
May  2 20:05:59.672: INFO: (13) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:162/proxy/: bar (200; 36.696522ms)
May  2 20:05:59.672: INFO: (13) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname1/proxy/: tls baz (200; 36.677616ms)
May  2 20:05:59.673: INFO: (13) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname2/proxy/: bar (200; 37.724872ms)
May  2 20:05:59.688: INFO: (14) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:160/proxy/: foo (200; 14.455855ms)
May  2 20:05:59.689: INFO: (14) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/rewriteme">... (200; 15.13914ms)
May  2 20:05:59.698: INFO: (14) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:160/proxy/: foo (200; 24.132299ms)
May  2 20:05:59.700: INFO: (14) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:162/proxy/: bar (200; 26.153732ms)
May  2 20:05:59.701: INFO: (14) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:460/proxy/: tls baz (200; 27.645927ms)
May  2 20:05:59.704: INFO: (14) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname2/proxy/: bar (200; 30.728851ms)
May  2 20:05:59.706: INFO: (14) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/rewriteme">test</a> (200; 33.038553ms)
May  2 20:05:59.706: INFO: (14) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname1/proxy/: foo (200; 33.402733ms)
May  2 20:05:59.706: INFO: (14) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:462/proxy/: tls qux (200; 32.84882ms)
May  2 20:05:59.706: INFO: (14) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:162/proxy/: bar (200; 32.755506ms)
May  2 20:05:59.707: INFO: (14) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/rewriteme">test<... (200; 33.080903ms)
May  2 20:05:59.707: INFO: (14) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname1/proxy/: foo (200; 33.517197ms)
May  2 20:05:59.718: INFO: (14) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/tlsrewritem... (200; 44.087098ms)
May  2 20:05:59.725: INFO: (14) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname2/proxy/: tls qux (200; 51.7598ms)
May  2 20:05:59.726: INFO: (14) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname1/proxy/: tls baz (200; 52.243934ms)
May  2 20:05:59.727: INFO: (14) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname2/proxy/: bar (200; 53.687439ms)
May  2 20:05:59.751: INFO: (15) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:162/proxy/: bar (200; 22.319855ms)
May  2 20:05:59.760: INFO: (15) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:162/proxy/: bar (200; 31.914005ms)
May  2 20:05:59.760: INFO: (15) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:160/proxy/: foo (200; 32.194208ms)
May  2 20:05:59.761: INFO: (15) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:462/proxy/: tls qux (200; 32.844742ms)
May  2 20:05:59.772: INFO: (15) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:160/proxy/: foo (200; 44.019311ms)
May  2 20:05:59.776: INFO: (15) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/tlsrewritem... (200; 47.663994ms)
May  2 20:05:59.783: INFO: (15) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/rewriteme">test</a> (200; 54.507802ms)
May  2 20:05:59.783: INFO: (15) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/rewriteme">... (200; 54.725296ms)
May  2 20:05:59.783: INFO: (15) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname1/proxy/: foo (200; 54.853966ms)
May  2 20:05:59.783: INFO: (15) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:460/proxy/: tls baz (200; 55.278399ms)
May  2 20:05:59.783: INFO: (15) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname2/proxy/: tls qux (200; 55.054881ms)
May  2 20:05:59.783: INFO: (15) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/rewriteme">test<... (200; 54.713164ms)
May  2 20:05:59.784: INFO: (15) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname1/proxy/: foo (200; 55.675861ms)
May  2 20:05:59.784: INFO: (15) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname2/proxy/: bar (200; 55.860255ms)
May  2 20:05:59.786: INFO: (15) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname2/proxy/: bar (200; 57.69504ms)
May  2 20:05:59.786: INFO: (15) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname1/proxy/: tls baz (200; 57.548867ms)
May  2 20:05:59.815: INFO: (16) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:160/proxy/: foo (200; 27.946158ms)
May  2 20:05:59.815: INFO: (16) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:162/proxy/: bar (200; 27.024798ms)
May  2 20:05:59.815: INFO: (16) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/rewriteme">test</a> (200; 28.418819ms)
May  2 20:05:59.815: INFO: (16) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:460/proxy/: tls baz (200; 28.000098ms)
May  2 20:05:59.815: INFO: (16) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/rewriteme">... (200; 27.381312ms)
May  2 20:05:59.815: INFO: (16) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:160/proxy/: foo (200; 29.139524ms)
May  2 20:05:59.815: INFO: (16) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/tlsrewritem... (200; 29.564317ms)
May  2 20:05:59.815: INFO: (16) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:162/proxy/: bar (200; 27.540991ms)
May  2 20:05:59.815: INFO: (16) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:462/proxy/: tls qux (200; 28.082302ms)
May  2 20:05:59.816: INFO: (16) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/rewriteme">test<... (200; 28.66594ms)
May  2 20:05:59.819: INFO: (16) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname1/proxy/: tls baz (200; 33.177562ms)
May  2 20:05:59.820: INFO: (16) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname1/proxy/: foo (200; 33.112011ms)
May  2 20:05:59.821: INFO: (16) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname2/proxy/: bar (200; 33.944393ms)
May  2 20:05:59.821: INFO: (16) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname2/proxy/: tls qux (200; 33.897436ms)
May  2 20:05:59.822: INFO: (16) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname1/proxy/: foo (200; 34.182409ms)
May  2 20:05:59.823: INFO: (16) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname2/proxy/: bar (200; 35.364073ms)
May  2 20:05:59.840: INFO: (17) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:462/proxy/: tls qux (200; 16.864582ms)
May  2 20:05:59.854: INFO: (17) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:160/proxy/: foo (200; 30.032311ms)
May  2 20:05:59.858: INFO: (17) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname1/proxy/: foo (200; 34.142744ms)
May  2 20:05:59.859: INFO: (17) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:162/proxy/: bar (200; 35.39922ms)
May  2 20:05:59.859: INFO: (17) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/rewriteme">test<... (200; 34.189663ms)
May  2 20:05:59.859: INFO: (17) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:460/proxy/: tls baz (200; 34.704263ms)
May  2 20:05:59.860: INFO: (17) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:160/proxy/: foo (200; 35.703097ms)
May  2 20:05:59.861: INFO: (17) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:162/proxy/: bar (200; 37.257229ms)
May  2 20:05:59.861: INFO: (17) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/rewriteme">test</a> (200; 36.598177ms)
May  2 20:05:59.864: INFO: (17) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/rewriteme">... (200; 40.288185ms)
May  2 20:05:59.864: INFO: (17) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname1/proxy/: tls baz (200; 40.279159ms)
May  2 20:05:59.864: INFO: (17) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/tlsrewritem... (200; 40.892684ms)
May  2 20:05:59.865: INFO: (17) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname2/proxy/: bar (200; 41.195159ms)
May  2 20:05:59.866: INFO: (17) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname1/proxy/: foo (200; 42.912824ms)
May  2 20:05:59.867: INFO: (17) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname2/proxy/: tls qux (200; 41.955971ms)
May  2 20:05:59.873: INFO: (17) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname2/proxy/: bar (200; 48.664171ms)
May  2 20:05:59.894: INFO: (18) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/rewriteme">test<... (200; 19.475626ms)
May  2 20:05:59.894: INFO: (18) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/rewriteme">test</a> (200; 19.665179ms)
May  2 20:05:59.894: INFO: (18) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:160/proxy/: foo (200; 21.113864ms)
May  2 20:05:59.896: INFO: (18) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:460/proxy/: tls baz (200; 21.436555ms)
May  2 20:05:59.897: INFO: (18) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:160/proxy/: foo (200; 22.653047ms)
May  2 20:05:59.898: INFO: (18) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:462/proxy/: tls qux (200; 23.91403ms)
May  2 20:05:59.899: INFO: (18) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/tlsrewritem... (200; 24.802629ms)
May  2 20:05:59.899: INFO: (18) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:162/proxy/: bar (200; 24.978096ms)
May  2 20:05:59.899: INFO: (18) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname1/proxy/: foo (200; 25.411215ms)
May  2 20:05:59.903: INFO: (18) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/rewriteme">... (200; 28.986188ms)
May  2 20:05:59.903: INFO: (18) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:162/proxy/: bar (200; 29.182556ms)
May  2 20:05:59.904: INFO: (18) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname1/proxy/: foo (200; 29.832308ms)
May  2 20:05:59.904: INFO: (18) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname1/proxy/: tls baz (200; 29.50665ms)
May  2 20:05:59.910: INFO: (18) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname2/proxy/: bar (200; 36.246672ms)
May  2 20:05:59.912: INFO: (18) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname2/proxy/: bar (200; 37.552679ms)
May  2 20:05:59.912: INFO: (18) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname2/proxy/: tls qux (200; 37.33822ms)
May  2 20:05:59.926: INFO: (19) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:162/proxy/: bar (200; 14.523872ms)
May  2 20:05:59.930: INFO: (19) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:1080/proxy/rewriteme">test<... (200; 17.893181ms)
May  2 20:05:59.930: INFO: (19) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:462/proxy/: tls qux (200; 17.85467ms)
May  2 20:05:59.930: INFO: (19) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:460/proxy/: tls baz (200; 18.037991ms)
May  2 20:05:59.959: INFO: (19) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname1/proxy/: tls baz (200; 47.323769ms)
May  2 20:05:59.959: INFO: (19) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:160/proxy/: foo (200; 47.284115ms)
May  2 20:05:59.959: INFO: (19) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6/proxy/rewriteme">test</a> (200; 47.221329ms)
May  2 20:05:59.959: INFO: (19) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:162/proxy/: bar (200; 46.974688ms)
May  2 20:05:59.959: INFO: (19) /api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/https:proxy-service-ts5ck-255p6:443/proxy/tlsrewritem... (200; 47.294435ms)
May  2 20:05:59.959: INFO: (19) /api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9308/pods/http:proxy-service-ts5ck-255p6:1080/proxy/rewriteme">... (200; 47.13643ms)
May  2 20:05:59.959: INFO: (19) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname1/proxy/: foo (200; 47.070626ms)
May  2 20:05:59.959: INFO: (19) /api/v1/namespaces/proxy-9308/pods/proxy-service-ts5ck-255p6:160/proxy/: foo (200; 47.2602ms)
May  2 20:05:59.972: INFO: (19) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname1/proxy/: foo (200; 60.016954ms)
May  2 20:05:59.972: INFO: (19) /api/v1/namespaces/proxy-9308/services/http:proxy-service-ts5ck:portname2/proxy/: bar (200; 60.302175ms)
May  2 20:06:00.072: INFO: (19) /api/v1/namespaces/proxy-9308/services/https:proxy-service-ts5ck:tlsportname2/proxy/: tls qux (200; 160.015781ms)
May  2 20:06:00.072: INFO: (19) /api/v1/namespaces/proxy-9308/services/proxy-service-ts5ck:portname2/proxy/: bar (200; 159.955901ms)
STEP: deleting ReplicationController proxy-service-ts5ck in namespace proxy-9308, will wait for the garbage collector to delete the pods
May  2 20:06:00.175: INFO: Deleting ReplicationController proxy-service-ts5ck took: 21.518088ms
May  2 20:06:00.284: INFO: Terminating ReplicationController proxy-service-ts5ck pods took: 108.633717ms
[AfterEach] version v1
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:06:02.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9308" for this suite.


• [SLOW TEST:9.105 seconds]
[sig-network] Proxy
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  version v1
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":-1,"completed":63,"skipped":1119,"failed":0}

SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:06:03.155: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating the pod
May  2 20:06:03.455: INFO: The status of Pod annotationupdate94858359-e43c-4d27-aea7-840b20a01d4d is Pending, waiting for it to be Running (with Ready = true)
May  2 20:06:05.466: INFO: The status of Pod annotationupdate94858359-e43c-4d27-aea7-840b20a01d4d is Pending, waiting for it to be Running (with Ready = true)
May  2 20:06:07.466: INFO: The status of Pod annotationupdate94858359-e43c-4d27-aea7-840b20a01d4d is Running (Ready = true)
May  2 20:06:08.043: INFO: Successfully updated pod "annotationupdate94858359-e43c-4d27-aea7-840b20a01d4d"
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:06:10.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5045" for this suite.


• [SLOW TEST:7.012 seconds]
[sig-storage] Downward API volume
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":-1,"completed":64,"skipped":1141,"failed":0}

S
------------------------------
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:06:10.180: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should test the lifecycle of an Endpoint [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating an Endpoint
STEP: waiting for available Endpoint
STEP: listing all Endpoints
STEP: updating the Endpoint
STEP: fetching the Endpoint
STEP: patching the Endpoint
STEP: fetching the Endpoint
STEP: deleting the Endpoint by Collection
STEP: waiting for Endpoint deletion
STEP: fetching the Endpoint
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:06:10.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8922" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

•
------------------------------
{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","total":-1,"completed":65,"skipped":1142,"failed":0}

SSSSS
------------------------------
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:06:10.488: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:69
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pdb that targets all three pods in a test replica set
STEP: Waiting for the pdb to be processed
STEP: First trying to evict a pod which shouldn't be evictable
STEP: Waiting for all pods to be running
May  2 20:06:10.661: INFO: pods: 0 < 3
May  2 20:06:12.702: INFO: running pods: 0 < 3
STEP: locating a running pod
STEP: Updating the pdb to allow a pod to be evicted
STEP: Waiting for the pdb to be processed
STEP: Trying to evict the same pod we tried earlier which should now be evictable
STEP: Waiting for all pods to be running
STEP: Waiting for the pdb to observed all healthy pods
STEP: Patching the pdb to disallow a pod to be evicted
STEP: Waiting for the pdb to be processed
STEP: Waiting for all pods to be running
May  2 20:06:16.993: INFO: running pods: 2 < 3
May  2 20:06:19.019: INFO: running pods: 2 < 3
STEP: locating a running pod
STEP: Deleting the pdb to allow a pod to be evicted
STEP: Waiting for the pdb to be deleted
STEP: Trying to evict the same pod we tried earlier which should now be evictable
STEP: Waiting for all pods to be running
[AfterEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:06:21.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-7492" for this suite.


• [SLOW TEST:10.744 seconds]
[sig-apps] DisruptionController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","total":-1,"completed":66,"skipped":1147,"failed":0}

SSSSS
------------------------------
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:05:51.768: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
May  2 20:05:51.960: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
May  2 20:06:18.568: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:07:55.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2730" for this suite.


• [SLOW TEST:123.956 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":-1,"completed":37,"skipped":829,"failed":0}

SS
------------------------------
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:07:55.739: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should release no longer matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
May  2 20:07:55.841: INFO: Pod name pod-release: Found 0 pods out of 1
May  2 20:08:00.864: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:08:01.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9792" for this suite.


• [SLOW TEST:6.267 seconds]
[sig-apps] ReplicationController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":-1,"completed":38,"skipped":831,"failed":0}
[BeforeEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:08:02.032: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-c86664d3-5f51-4c1d-863d-6099215538f0
STEP: Creating a pod to test consume secrets
May  2 20:08:02.177: INFO: Waiting up to 5m0s for pod "pod-secrets-621881df-5b73-4603-b9d8-6c35843267fb" in namespace "secrets-5311" to be "Succeeded or Failed"
May  2 20:08:02.186: INFO: Pod "pod-secrets-621881df-5b73-4603-b9d8-6c35843267fb": Phase="Pending", Reason="", readiness=false. Elapsed: 9.36964ms
May  2 20:08:04.200: INFO: Pod "pod-secrets-621881df-5b73-4603-b9d8-6c35843267fb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023470114s
May  2 20:08:06.216: INFO: Pod "pod-secrets-621881df-5b73-4603-b9d8-6c35843267fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039567966s
STEP: Saw pod success
May  2 20:08:06.216: INFO: Pod "pod-secrets-621881df-5b73-4603-b9d8-6c35843267fb" satisfied condition "Succeeded or Failed"
May  2 20:08:06.222: INFO: Trying to get logs from node node-2 pod pod-secrets-621881df-5b73-4603-b9d8-6c35843267fb container secret-env-test: <nil>
STEP: delete the pod
May  2 20:08:06.282: INFO: Waiting for pod pod-secrets-621881df-5b73-4603-b9d8-6c35843267fb to disappear
May  2 20:08:06.288: INFO: Pod pod-secrets-621881df-5b73-4603-b9d8-6c35843267fb no longer exists
[AfterEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:08:06.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5311" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":-1,"completed":39,"skipped":831,"failed":0}

SSSSSS
------------------------------
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:08:06.332: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:08:06.428: INFO: Creating ReplicaSet my-hostname-basic-469a5ee8-42b9-4e69-af89-8c41ebe8d606
May  2 20:08:06.471: INFO: Pod name my-hostname-basic-469a5ee8-42b9-4e69-af89-8c41ebe8d606: Found 0 pods out of 1
May  2 20:08:11.494: INFO: Pod name my-hostname-basic-469a5ee8-42b9-4e69-af89-8c41ebe8d606: Found 1 pods out of 1
May  2 20:08:11.494: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-469a5ee8-42b9-4e69-af89-8c41ebe8d606" is running
May  2 20:08:11.512: INFO: Pod "my-hostname-basic-469a5ee8-42b9-4e69-af89-8c41ebe8d606-ghgdf" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-05-02 20:08:06 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-05-02 20:08:09 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-05-02 20:08:09 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-05-02 20:08:06 +0000 UTC Reason: Message:}])
May  2 20:08:11.519: INFO: Trying to dial the pod
May  2 20:08:16.568: INFO: Controller my-hostname-basic-469a5ee8-42b9-4e69-af89-8c41ebe8d606: Got expected result from replica 1 [my-hostname-basic-469a5ee8-42b9-4e69-af89-8c41ebe8d606-ghgdf]: "my-hostname-basic-469a5ee8-42b9-4e69-af89-8c41ebe8d606-ghgdf", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:08:16.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5843" for this suite.


• [SLOW TEST:10.274 seconds]
[sig-apps] ReplicaSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":-1,"completed":40,"skipped":837,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:08:16.657: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Kubectl replace
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1558
[It] should update a single-container pod's image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-1
May  2 20:08:16.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-3769 run e2e-test-httpd-pod --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
May  2 20:08:17.266: INFO: stderr: ""
May  2 20:08:17.266: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
May  2 20:08:22.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-3769 get pod e2e-test-httpd-pod -o json'
May  2 20:08:22.493: INFO: stderr: ""
May  2 20:08:22.493: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"9861f13ad96ba45119ee37712fdb4de096b6791c900e9189b1a4a66ae07251e7\",\n            \"cni.projectcalico.org/podIP\": \"10.233.69.22/32\",\n            \"cni.projectcalico.org/podIPs\": \"10.233.69.22/32\"\n        },\n        \"creationTimestamp\": \"2022-05-02T20:08:17Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-3769\",\n        \"resourceVersion\": \"2870346\",\n        \"uid\": \"2b0631b9-6eec-4b47-806d-8b381aae0a1b\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"k8s.gcr.io/e2e-test-images/httpd:2.4.38-1\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-b6dsc\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"node-2\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-b6dsc\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-05-02T20:08:17Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-05-02T20:08:19Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-05-02T20:08:19Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-05-02T20:08:17Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://e65ad6b12ba854a69994d65d97489c6792a94d97b3ed06eda4609b2179efed9e\",\n                \"image\": \"k8s.gcr.io/e2e-test-images/httpd:2.4.38-1\",\n                \"imageID\": \"docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-05-02T20:08:19Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.100.20.46\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.233.69.22\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.233.69.22\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-05-02T20:08:17Z\"\n    }\n}\n"
STEP: replace the image in the pod
May  2 20:08:22.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-3769 replace -f -'
May  2 20:08:24.411: INFO: stderr: ""
May  2 20:08:24.411: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image k8s.gcr.io/e2e-test-images/busybox:1.29-1
[AfterEach] Kubectl replace
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1562
May  2 20:08:24.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-3769 delete pods e2e-test-httpd-pod'
May  2 20:08:27.214: INFO: stderr: ""
May  2 20:08:27.214: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:08:27.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3769" for this suite.


• [SLOW TEST:10.594 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1555
    should update a single-container pod's image  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":-1,"completed":41,"skipped":864,"failed":0}

SSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:08:27.269: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:188
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a Pod with a static label
STEP: watching for Pod to be ready
May  2 20:08:27.431: INFO: observed Pod pod-test in namespace pods-3329 in phase Pending with labels: map[test-pod-static:true] & conditions []
May  2 20:08:27.445: INFO: observed Pod pod-test in namespace pods-3329 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:08:27 +0000 UTC  }]
May  2 20:08:27.494: INFO: observed Pod pod-test in namespace pods-3329 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:08:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:08:27 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:08:27 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:08:27 +0000 UTC  }]
May  2 20:08:28.868: INFO: observed Pod pod-test in namespace pods-3329 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:08:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:08:27 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:08:27 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:08:27 +0000 UTC  }]
May  2 20:08:29.465: INFO: Found Pod pod-test in namespace pods-3329 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:08:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:08:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:08:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:08:27 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data
May  2 20:08:29.523: INFO: observed event type ADDED
STEP: getting the Pod and ensuring that it's patched
STEP: replacing the Pod's status Ready condition to False
STEP: check the Pod again to ensure its Ready conditions are False
STEP: deleting the Pod via a Collection with a LabelSelector
STEP: watching for the Pod to be deleted
May  2 20:08:29.593: INFO: observed event type ADDED
May  2 20:08:29.593: INFO: observed event type MODIFIED
May  2 20:08:29.593: INFO: observed event type MODIFIED
May  2 20:08:29.593: INFO: observed event type MODIFIED
May  2 20:08:29.594: INFO: observed event type MODIFIED
May  2 20:08:29.594: INFO: observed event type MODIFIED
May  2 20:08:29.594: INFO: observed event type MODIFIED
May  2 20:08:29.594: INFO: observed event type MODIFIED
May  2 20:08:31.599: INFO: observed event type MODIFIED
May  2 20:08:31.964: INFO: observed event type MODIFIED
May  2 20:08:32.763: INFO: observed event type MODIFIED
May  2 20:08:32.781: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:08:32.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3329" for this suite.


• [SLOW TEST:5.572 seconds]
[sig-node] Pods
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should run through the lifecycle of Pods and PodStatus [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","total":-1,"completed":42,"skipped":875,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:08:32.941: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  2 20:08:34.374: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
May  2 20:08:36.427: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118914, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118914, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118914, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787118914, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  2 20:08:39.478: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:08:40.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8026" for this suite.
STEP: Destroying namespace "webhook-8026-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102


• [SLOW TEST:7.310 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":-1,"completed":43,"skipped":919,"failed":0}

SSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:08:40.501: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating secret secrets-7512/secret-test-4a18f2ee-ae20-4bcb-9c87-f66cb4322b01
STEP: Creating a pod to test consume secrets
May  2 20:08:40.842: INFO: Waiting up to 5m0s for pod "pod-configmaps-43713092-25dc-4ba1-90e7-1a388141c82b" in namespace "secrets-7512" to be "Succeeded or Failed"
May  2 20:08:40.881: INFO: Pod "pod-configmaps-43713092-25dc-4ba1-90e7-1a388141c82b": Phase="Pending", Reason="", readiness=false. Elapsed: 38.508955ms
May  2 20:08:42.895: INFO: Pod "pod-configmaps-43713092-25dc-4ba1-90e7-1a388141c82b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053220148s
May  2 20:08:44.921: INFO: Pod "pod-configmaps-43713092-25dc-4ba1-90e7-1a388141c82b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.078589427s
STEP: Saw pod success
May  2 20:08:44.921: INFO: Pod "pod-configmaps-43713092-25dc-4ba1-90e7-1a388141c82b" satisfied condition "Succeeded or Failed"
May  2 20:08:44.950: INFO: Trying to get logs from node node-2 pod pod-configmaps-43713092-25dc-4ba1-90e7-1a388141c82b container env-test: <nil>
STEP: delete the pod
May  2 20:08:45.056: INFO: Waiting for pod pod-configmaps-43713092-25dc-4ba1-90e7-1a388141c82b to disappear
May  2 20:08:45.063: INFO: Pod pod-configmaps-43713092-25dc-4ba1-90e7-1a388141c82b no longer exists
[AfterEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:08:45.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7512" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":-1,"completed":44,"skipped":928,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:08:45.178: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:54
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod busybox-dbb5069c-51f0-4597-aeed-ffadd909d1f7 in namespace container-probe-4470
May  2 20:08:49.359: INFO: Started pod busybox-dbb5069c-51f0-4597-aeed-ffadd909d1f7 in namespace container-probe-4470
STEP: checking the pod's current state and verifying that restartCount is present
May  2 20:08:49.366: INFO: Initial restart count of pod busybox-dbb5069c-51f0-4597-aeed-ffadd909d1f7 is 0
May  2 20:09:37.801: INFO: Restart count of pod container-probe-4470/busybox-dbb5069c-51f0-4597-aeed-ffadd909d1f7 is now 1 (48.434892143s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:09:37.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4470" for this suite.


• [SLOW TEST:52.738 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":-1,"completed":45,"skipped":957,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:06:21.248: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:54
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod busybox-d5f96407-f50b-4c29-a593-a6ba4e64961b in namespace container-probe-2848
May  2 20:06:25.529: INFO: Started pod busybox-d5f96407-f50b-4c29-a593-a6ba4e64961b in namespace container-probe-2848
STEP: checking the pod's current state and verifying that restartCount is present
May  2 20:06:25.543: INFO: Initial restart count of pod busybox-d5f96407-f50b-4c29-a593-a6ba4e64961b is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:10:25.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2848" for this suite.


• [SLOW TEST:244.636 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":-1,"completed":67,"skipped":1152,"failed":0}

SSSSS
------------------------------
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:10:25.892: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
May  2 20:10:26.070: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3570  27b53dd2-492f-42fb-8c0a-87c20cab1681 2871293 0 2022-05-02 20:10:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-05-02 20:10:26 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
May  2 20:10:26.071: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3570  27b53dd2-492f-42fb-8c0a-87c20cab1681 2871293 0 2022-05-02 20:10:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-05-02 20:10:26 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
May  2 20:10:36.108: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3570  27b53dd2-492f-42fb-8c0a-87c20cab1681 2871357 0 2022-05-02 20:10:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-05-02 20:10:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
May  2 20:10:36.109: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3570  27b53dd2-492f-42fb-8c0a-87c20cab1681 2871357 0 2022-05-02 20:10:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-05-02 20:10:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
May  2 20:10:46.132: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3570  27b53dd2-492f-42fb-8c0a-87c20cab1681 2871411 0 2022-05-02 20:10:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-05-02 20:10:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
May  2 20:10:46.132: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3570  27b53dd2-492f-42fb-8c0a-87c20cab1681 2871411 0 2022-05-02 20:10:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-05-02 20:10:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
May  2 20:10:56.155: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3570  27b53dd2-492f-42fb-8c0a-87c20cab1681 2871468 0 2022-05-02 20:10:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-05-02 20:10:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
May  2 20:10:56.155: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3570  27b53dd2-492f-42fb-8c0a-87c20cab1681 2871468 0 2022-05-02 20:10:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-05-02 20:10:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
May  2 20:11:06.184: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3570  0345834f-1f1c-4863-9186-f4fd99abe3f9 2871525 0 2022-05-02 20:11:06 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-05-02 20:11:06 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
May  2 20:11:06.184: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3570  0345834f-1f1c-4863-9186-f4fd99abe3f9 2871525 0 2022-05-02 20:11:06 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-05-02 20:11:06 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
May  2 20:11:16.208: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3570  0345834f-1f1c-4863-9186-f4fd99abe3f9 2871580 0 2022-05-02 20:11:06 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-05-02 20:11:06 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
May  2 20:11:16.208: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3570  0345834f-1f1c-4863-9186-f4fd99abe3f9 2871580 0 2022-05-02 20:11:06 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-05-02 20:11:06 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:11:26.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3570" for this suite.


• [SLOW TEST:60.361 seconds]
[sig-api-machinery] Watchers
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":-1,"completed":68,"skipped":1157,"failed":0}
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:11:26.258: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create services for rc  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating Agnhost RC
May  2 20:11:26.347: INFO: namespace kubectl-9271
May  2 20:11:26.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-9271 create -f -'
May  2 20:11:27.548: INFO: stderr: ""
May  2 20:11:27.548: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
May  2 20:11:28.562: INFO: Selector matched 1 pods for map[app:agnhost]
May  2 20:11:28.562: INFO: Found 0 / 1
May  2 20:11:29.584: INFO: Selector matched 1 pods for map[app:agnhost]
May  2 20:11:29.584: INFO: Found 0 / 1
May  2 20:11:30.562: INFO: Selector matched 1 pods for map[app:agnhost]
May  2 20:11:30.562: INFO: Found 1 / 1
May  2 20:11:30.562: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May  2 20:11:30.574: INFO: Selector matched 1 pods for map[app:agnhost]
May  2 20:11:30.574: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May  2 20:11:30.574: INFO: wait on agnhost-primary startup in kubectl-9271 
May  2 20:11:30.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-9271 logs agnhost-primary-q6926 agnhost-primary'
May  2 20:11:30.783: INFO: stderr: ""
May  2 20:11:30.783: INFO: stdout: "Paused\n"
STEP: exposing RC
May  2 20:11:30.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-9271 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
May  2 20:11:30.973: INFO: stderr: ""
May  2 20:11:30.973: INFO: stdout: "service/rm2 exposed\n"
May  2 20:11:31.013: INFO: Service rm2 in namespace kubectl-9271 found.
STEP: exposing service
May  2 20:11:33.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-9271 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
May  2 20:11:33.455: INFO: stderr: ""
May  2 20:11:33.455: INFO: stdout: "service/rm3 exposed\n"
May  2 20:11:33.462: INFO: Service rm3 in namespace kubectl-9271 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:11:35.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9271" for this suite.


• [SLOW TEST:9.257 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1233
    should create services for rc  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":-1,"completed":69,"skipped":1157,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Events
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:11:35.640: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
May  2 20:11:39.794: INFO: &Pod{ObjectMeta:{send-events-e82c6baf-e605-400e-9001-c983939683b1  events-401  4d577295-67f5-4a31-982a-92fe8e97f783 2871757 0 2022-05-02 20:11:35 +0000 UTC <nil> <nil> map[name:foo time:740259294] map[cni.projectcalico.org/containerID:77ee72f0cb492455da9ee9bfc66622ee8544dee03387d7f4f0e9902192add9c3 cni.projectcalico.org/podIP:10.233.69.31/32 cni.projectcalico.org/podIPs:10.233.69.31/32] [] []  [{e2e.test Update v1 2022-05-02 20:11:35 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:time":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"p\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":80,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-05-02 20:11:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-05-02 20:11:38 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.69.31\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dxgqx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:p,Image:k8s.gcr.io/e2e-test-images/agnhost:2.32,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dxgqx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:11:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:11:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:11:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:11:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.20.46,PodIP:10.233.69.31,StartTime:2022-05-02 20:11:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-02 20:11:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.32,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/agnhost@sha256:758db666ac7028534dba72e7e9bb1e57bb81b8196f976f7a5cc351ef8b3529e1,ContainerID:docker://1ff507b5494406c702876220ee237b56b1ab25c8ab7b84365833294d245e7158,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.69.31,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
May  2 20:11:41.806: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
May  2 20:11:43.815: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [sig-node] Events
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:11:43.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-401" for this suite.


• [SLOW TEST:8.248 seconds]
[sig-node] Events
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/framework.go:23
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]","total":-1,"completed":70,"skipped":1216,"failed":0}

SSSSSSSS
------------------------------
[BeforeEach] [sig-node] Pods Extended
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:11:43.932: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Pods Set QOS Class
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:149
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [sig-node] Pods Extended
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:11:44.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5972" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":-1,"completed":71,"skipped":1224,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:11:44.380: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-7db299a6-765b-404b-afc3-ec275ff0d08b
STEP: Creating a pod to test consume configMaps
May  2 20:11:44.516: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3f9bc9f3-6cb5-404e-9e93-3074f6d51bc0" in namespace "projected-4693" to be "Succeeded or Failed"
May  2 20:11:44.539: INFO: Pod "pod-projected-configmaps-3f9bc9f3-6cb5-404e-9e93-3074f6d51bc0": Phase="Pending", Reason="", readiness=false. Elapsed: 22.691108ms
May  2 20:11:46.553: INFO: Pod "pod-projected-configmaps-3f9bc9f3-6cb5-404e-9e93-3074f6d51bc0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036837005s
May  2 20:11:48.570: INFO: Pod "pod-projected-configmaps-3f9bc9f3-6cb5-404e-9e93-3074f6d51bc0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054089393s
STEP: Saw pod success
May  2 20:11:48.570: INFO: Pod "pod-projected-configmaps-3f9bc9f3-6cb5-404e-9e93-3074f6d51bc0" satisfied condition "Succeeded or Failed"
May  2 20:11:48.582: INFO: Trying to get logs from node node-2 pod pod-projected-configmaps-3f9bc9f3-6cb5-404e-9e93-3074f6d51bc0 container agnhost-container: <nil>
STEP: delete the pod
May  2 20:11:48.675: INFO: Waiting for pod pod-projected-configmaps-3f9bc9f3-6cb5-404e-9e93-3074f6d51bc0 to disappear
May  2 20:11:48.698: INFO: Pod pod-projected-configmaps-3f9bc9f3-6cb5-404e-9e93-3074f6d51bc0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:11:48.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4693" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":72,"skipped":1319,"failed":0}

SSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:11:48.936: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:188
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating pod
May  2 20:11:49.149: INFO: The status of Pod pod-hostip-29321aea-4532-4169-a567-7bc9448be2c2 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:11:51.165: INFO: The status of Pod pod-hostip-29321aea-4532-4169-a567-7bc9448be2c2 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:11:53.167: INFO: The status of Pod pod-hostip-29321aea-4532-4169-a567-7bc9448be2c2 is Running (Ready = true)
May  2 20:11:53.200: INFO: Pod pod-hostip-29321aea-4532-4169-a567-7bc9448be2c2 has hostIP: 10.100.20.46
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:11:53.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4489" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","total":-1,"completed":73,"skipped":1339,"failed":0}

SSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:11:53.323: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/init_container.go:162
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
May  2 20:11:53.425: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:11:58.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9504" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":-1,"completed":74,"skipped":1350,"failed":0}

S
------------------------------
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:11:58.299: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9631.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-9631.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9631.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9631.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-9631.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9631.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May  2 20:12:04.897: INFO: DNS probes using dns-9631/dns-test-b662a704-2062-4cb9-a0da-ab4bada0dc4f succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:12:04.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9631" for this suite.


• [SLOW TEST:6.694 seconds]
[sig-network] DNS
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]","total":-1,"completed":75,"skipped":1351,"failed":0}

SSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:12:05.033: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a service nodeport-service with the type=NodePort in namespace services-9327
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-9327
STEP: creating replication controller externalsvc in namespace services-9327
I0502 20:12:05.271629      18 runners.go:190] Created replication controller with name: externalsvc, namespace: services-9327, replica count: 2
I0502 20:12:08.322694      18 runners.go:190] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0502 20:12:11.323359      18 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
May  2 20:12:11.419: INFO: Creating new exec pod
May  2 20:12:15.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=services-9327 exec execpodrx92j -- /bin/sh -x -c nslookup nodeport-service.services-9327.svc.cluster.local'
May  2 20:12:15.915: INFO: stderr: "+ nslookup nodeport-service.services-9327.svc.cluster.local\n"
May  2 20:12:15.915: INFO: stdout: "Server:\t\t169.254.25.10\nAddress:\t169.254.25.10#53\n\nnodeport-service.services-9327.svc.cluster.local\tcanonical name = externalsvc.services-9327.svc.cluster.local.\nName:\texternalsvc.services-9327.svc.cluster.local\nAddress: 10.233.32.177\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-9327, will wait for the garbage collector to delete the pods
May  2 20:12:15.995: INFO: Deleting ReplicationController externalsvc took: 20.746637ms
May  2 20:12:16.198: INFO: Terminating ReplicationController externalsvc pods took: 202.734586ms
May  2 20:12:19.345: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:12:19.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9327" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753


• [SLOW TEST:14.372 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":-1,"completed":76,"skipped":1365,"failed":0}

SSSSS
------------------------------
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:12:19.420: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:12:35.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7950" for this suite.


• [SLOW TEST:16.470 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":-1,"completed":77,"skipped":1370,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:12:35.963: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:92
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:107
STEP: Creating service test in namespace statefulset-5449
[It] should validate Statefulset Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating statefulset ss in namespace statefulset-5449
May  2 20:12:36.158: INFO: Found 0 stateful pods, waiting for 1
May  2 20:12:46.172: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label
STEP: Getting /status
May  2 20:12:46.230: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status
May  2 20:12:46.249: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated
May  2 20:12:46.253: INFO: Observed &StatefulSet event: ADDED
May  2 20:12:46.253: INFO: Found Statefulset ss in namespace statefulset-5449 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
May  2 20:12:46.253: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status
May  2 20:12:46.253: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
May  2 20:12:46.281: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched
May  2 20:12:46.285: INFO: Observed &StatefulSet event: ADDED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:118
May  2 20:12:46.286: INFO: Deleting all statefulset in ns statefulset-5449
May  2 20:12:46.295: INFO: Scaling statefulset ss to 0
May  2 20:12:56.355: INFO: Waiting for statefulset status.replicas updated to 0
May  2 20:12:56.371: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:12:56.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5449" for this suite.


• [SLOW TEST:20.461 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:97
    should validate Statefulset Status endpoints [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","total":-1,"completed":78,"skipped":1403,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:12:56.498: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:38
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:12:56.615: INFO: The status of Pod busybox-scheduling-7fa5fda0-8cc5-4ae8-a5e8-5b594076a0fe is Pending, waiting for it to be Running (with Ready = true)
May  2 20:12:58.629: INFO: The status of Pod busybox-scheduling-7fa5fda0-8cc5-4ae8-a5e8-5b594076a0fe is Pending, waiting for it to be Running (with Ready = true)
May  2 20:13:00.625: INFO: The status of Pod busybox-scheduling-7fa5fda0-8cc5-4ae8-a5e8-5b594076a0fe is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:13:00.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9111" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":-1,"completed":79,"skipped":1439,"failed":0}

SSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:13:00.723: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating the pod
May  2 20:13:00.897: INFO: The status of Pod labelsupdatecf291d5e-ab66-4592-8f25-8cd442550c8e is Pending, waiting for it to be Running (with Ready = true)
May  2 20:13:02.917: INFO: The status of Pod labelsupdatecf291d5e-ab66-4592-8f25-8cd442550c8e is Pending, waiting for it to be Running (with Ready = true)
May  2 20:13:04.931: INFO: The status of Pod labelsupdatecf291d5e-ab66-4592-8f25-8cd442550c8e is Running (Ready = true)
May  2 20:13:05.507: INFO: Successfully updated pod "labelsupdatecf291d5e-ab66-4592-8f25-8cd442550c8e"
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:13:09.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9291" for this suite.


• [SLOW TEST:8.881 seconds]
[sig-storage] Downward API volume
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":-1,"completed":80,"skipped":1456,"failed":0}

SSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:13:09.644: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating Pod
STEP: Reading file content from the nginx-container
May  2 20:13:13.826: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-9491 PodName:pod-sharedvolume-7b832738-c9c5-467b-af43-67ff5d38bf5c ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 20:13:13.826: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
May  2 20:13:13.973: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:13:13.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9491" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":-1,"completed":81,"skipped":1467,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:13:14.056: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test env composition
May  2 20:13:14.223: INFO: Waiting up to 5m0s for pod "var-expansion-b05713d0-4720-4be4-bdf5-dc246bcd7d77" in namespace "var-expansion-9998" to be "Succeeded or Failed"
May  2 20:13:14.236: INFO: Pod "var-expansion-b05713d0-4720-4be4-bdf5-dc246bcd7d77": Phase="Pending", Reason="", readiness=false. Elapsed: 12.441766ms
May  2 20:13:16.250: INFO: Pod "var-expansion-b05713d0-4720-4be4-bdf5-dc246bcd7d77": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026351172s
May  2 20:13:18.261: INFO: Pod "var-expansion-b05713d0-4720-4be4-bdf5-dc246bcd7d77": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03775975s
STEP: Saw pod success
May  2 20:13:18.261: INFO: Pod "var-expansion-b05713d0-4720-4be4-bdf5-dc246bcd7d77" satisfied condition "Succeeded or Failed"
May  2 20:13:18.270: INFO: Trying to get logs from node node-2 pod var-expansion-b05713d0-4720-4be4-bdf5-dc246bcd7d77 container dapi-container: <nil>
STEP: delete the pod
May  2 20:13:18.329: INFO: Waiting for pod var-expansion-b05713d0-4720-4be4-bdf5-dc246bcd7d77 to disappear
May  2 20:13:18.338: INFO: Pod var-expansion-b05713d0-4720-4be4-bdf5-dc246bcd7d77 no longer exists
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:13:18.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9998" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":-1,"completed":82,"skipped":1497,"failed":0}

SSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:09:38.083: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
May  2 20:09:38.190: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
May  2 20:11:23.534: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
May  2 20:11:51.548: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:13:33.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1309" for this suite.


• [SLOW TEST:235.751 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":-1,"completed":46,"skipped":1006,"failed":0}
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:13:33.838: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] Replace and Patch tests [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:13:34.010: INFO: Pod name sample-pod: Found 0 pods out of 1
May  2 20:13:39.031: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: Scaling up "test-rs" replicaset 
May  2 20:13:39.069: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet
May  2 20:13:39.092: INFO: observed ReplicaSet test-rs in namespace replicaset-3405 with ReadyReplicas 1, AvailableReplicas 1
May  2 20:13:39.168: INFO: observed ReplicaSet test-rs in namespace replicaset-3405 with ReadyReplicas 1, AvailableReplicas 1
May  2 20:13:39.243: INFO: observed ReplicaSet test-rs in namespace replicaset-3405 with ReadyReplicas 1, AvailableReplicas 1
May  2 20:13:39.266: INFO: observed ReplicaSet test-rs in namespace replicaset-3405 with ReadyReplicas 1, AvailableReplicas 1
May  2 20:13:42.631: INFO: observed ReplicaSet test-rs in namespace replicaset-3405 with ReadyReplicas 2, AvailableReplicas 2
May  2 20:13:43.367: INFO: observed Replicaset test-rs in namespace replicaset-3405 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:13:43.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3405" for this suite.


• [SLOW TEST:9.561 seconds]
[sig-apps] ReplicaSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","total":-1,"completed":47,"skipped":1006,"failed":0}

S
------------------------------
[BeforeEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:13:43.411: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test override arguments
May  2 20:13:43.561: INFO: Waiting up to 5m0s for pod "client-containers-e92a1ea6-d5f9-4e5b-914b-a52826f089c0" in namespace "containers-923" to be "Succeeded or Failed"
May  2 20:13:43.578: INFO: Pod "client-containers-e92a1ea6-d5f9-4e5b-914b-a52826f089c0": Phase="Pending", Reason="", readiness=false. Elapsed: 17.380043ms
May  2 20:13:45.591: INFO: Pod "client-containers-e92a1ea6-d5f9-4e5b-914b-a52826f089c0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030233959s
May  2 20:13:47.611: INFO: Pod "client-containers-e92a1ea6-d5f9-4e5b-914b-a52826f089c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050021789s
STEP: Saw pod success
May  2 20:13:47.611: INFO: Pod "client-containers-e92a1ea6-d5f9-4e5b-914b-a52826f089c0" satisfied condition "Succeeded or Failed"
May  2 20:13:47.619: INFO: Trying to get logs from node node-2 pod client-containers-e92a1ea6-d5f9-4e5b-914b-a52826f089c0 container agnhost-container: <nil>
STEP: delete the pod
May  2 20:13:47.700: INFO: Waiting for pod client-containers-e92a1ea6-d5f9-4e5b-914b-a52826f089c0 to disappear
May  2 20:13:47.717: INFO: Pod client-containers-e92a1ea6-d5f9-4e5b-914b-a52826f089c0 no longer exists
[AfterEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:13:47.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-923" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]","total":-1,"completed":48,"skipped":1007,"failed":0}
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:13:47.755: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-9e27ab54-8f64-43d8-b6d0-c380770f4582
STEP: Creating a pod to test consume configMaps
May  2 20:13:47.942: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-16e84d35-4c50-411e-a2d4-fae1173d3b2c" in namespace "projected-776" to be "Succeeded or Failed"
May  2 20:13:47.956: INFO: Pod "pod-projected-configmaps-16e84d35-4c50-411e-a2d4-fae1173d3b2c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.906468ms
May  2 20:13:49.993: INFO: Pod "pod-projected-configmaps-16e84d35-4c50-411e-a2d4-fae1173d3b2c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05042013s
May  2 20:13:52.034: INFO: Pod "pod-projected-configmaps-16e84d35-4c50-411e-a2d4-fae1173d3b2c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.091051919s
May  2 20:13:54.053: INFO: Pod "pod-projected-configmaps-16e84d35-4c50-411e-a2d4-fae1173d3b2c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.110691894s
STEP: Saw pod success
May  2 20:13:54.053: INFO: Pod "pod-projected-configmaps-16e84d35-4c50-411e-a2d4-fae1173d3b2c" satisfied condition "Succeeded or Failed"
May  2 20:13:54.064: INFO: Trying to get logs from node node-2 pod pod-projected-configmaps-16e84d35-4c50-411e-a2d4-fae1173d3b2c container agnhost-container: <nil>
STEP: delete the pod
May  2 20:13:54.184: INFO: Waiting for pod pod-projected-configmaps-16e84d35-4c50-411e-a2d4-fae1173d3b2c to disappear
May  2 20:13:54.223: INFO: Pod pod-projected-configmaps-16e84d35-4c50-411e-a2d4-fae1173d3b2c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:13:54.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-776" for this suite.


• [SLOW TEST:6.528 seconds]
[sig-storage] Projected configMap
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":-1,"completed":49,"skipped":1007,"failed":0}

SS
------------------------------
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:13:54.293: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:188
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
May  2 20:13:54.415: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying pod deletion was observed
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:14:01.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7226" for this suite.


• [SLOW TEST:7.088 seconds]
[sig-node] Pods
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","total":-1,"completed":50,"skipped":1009,"failed":0}

SSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:14:01.413: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:14:01.544: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:14:07.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-813" for this suite.


• [SLOW TEST:5.803 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:48
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":-1,"completed":51,"skipped":1016,"failed":0}
[BeforeEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:14:07.224: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward api env vars
May  2 20:14:07.373: INFO: Waiting up to 5m0s for pod "downward-api-ffe84f33-88cd-4ce6-af24-4bf50e784c7b" in namespace "downward-api-180" to be "Succeeded or Failed"
May  2 20:14:07.392: INFO: Pod "downward-api-ffe84f33-88cd-4ce6-af24-4bf50e784c7b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.435036ms
May  2 20:14:09.402: INFO: Pod "downward-api-ffe84f33-88cd-4ce6-af24-4bf50e784c7b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022196466s
May  2 20:14:11.418: INFO: Pod "downward-api-ffe84f33-88cd-4ce6-af24-4bf50e784c7b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037824099s
STEP: Saw pod success
May  2 20:14:11.418: INFO: Pod "downward-api-ffe84f33-88cd-4ce6-af24-4bf50e784c7b" satisfied condition "Succeeded or Failed"
May  2 20:14:11.426: INFO: Trying to get logs from node node-2 pod downward-api-ffe84f33-88cd-4ce6-af24-4bf50e784c7b container dapi-container: <nil>
STEP: delete the pod
May  2 20:14:11.498: INFO: Waiting for pod downward-api-ffe84f33-88cd-4ce6-af24-4bf50e784c7b to disappear
May  2 20:14:11.528: INFO: Pod downward-api-ffe84f33-88cd-4ce6-af24-4bf50e784c7b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:14:11.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-180" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":-1,"completed":52,"skipped":1016,"failed":0}
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:14:11.570: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  2 20:14:12.411: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May  2 20:14:14.484: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119252, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119252, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119252, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119252, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  2 20:14:17.526: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:14:17.540: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3338-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:14:25.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1609" for this suite.
STEP: Destroying namespace "webhook-1609-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102


• [SLOW TEST:14.401 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":-1,"completed":53,"skipped":1016,"failed":0}

SSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:13:18.438: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:92
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:107
STEP: Creating service test in namespace statefulset-8591
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a new StatefulSet
May  2 20:13:18.622: INFO: Found 0 stateful pods, waiting for 3
May  2 20:13:28.648: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May  2 20:13:28.648: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May  2 20:13:28.648: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 to k8s.gcr.io/e2e-test-images/httpd:2.4.39-1
May  2 20:13:28.727: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
May  2 20:13:38.826: INFO: Updating stateful set ss2
May  2 20:13:38.891: INFO: Waiting for Pod statefulset-8591/ss2-2 to have revision ss2-5bbbc9fc94 update revision ss2-677d6db895
STEP: Restoring Pods to the correct revision when they are deleted
May  2 20:13:49.360: INFO: Found 2 stateful pods, waiting for 3
May  2 20:13:59.377: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May  2 20:13:59.377: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May  2 20:13:59.377: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
May  2 20:13:59.483: INFO: Updating stateful set ss2
May  2 20:13:59.520: INFO: Waiting for Pod statefulset-8591/ss2-1 to have revision ss2-5bbbc9fc94 update revision ss2-677d6db895
May  2 20:14:09.615: INFO: Updating stateful set ss2
May  2 20:14:09.690: INFO: Waiting for StatefulSet statefulset-8591/ss2 to complete update
May  2 20:14:09.690: INFO: Waiting for Pod statefulset-8591/ss2-0 to have revision ss2-5bbbc9fc94 update revision ss2-677d6db895
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:118
May  2 20:14:19.717: INFO: Deleting all statefulset in ns statefulset-8591
May  2 20:14:19.728: INFO: Scaling statefulset ss2 to 0
May  2 20:14:29.772: INFO: Waiting for statefulset status.replicas updated to 0
May  2 20:14:29.782: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:14:29.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8591" for this suite.


• [SLOW TEST:71.519 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:97
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":-1,"completed":83,"skipped":1510,"failed":0}

SSSS
------------------------------
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:14:26.321: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
May  2 20:14:26.565: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ab3c3c1a-c5ef-439b-b291-d72a619eef36" in namespace "projected-6265" to be "Succeeded or Failed"
May  2 20:14:26.579: INFO: Pod "downwardapi-volume-ab3c3c1a-c5ef-439b-b291-d72a619eef36": Phase="Pending", Reason="", readiness=false. Elapsed: 14.195429ms
May  2 20:14:28.593: INFO: Pod "downwardapi-volume-ab3c3c1a-c5ef-439b-b291-d72a619eef36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02773286s
May  2 20:14:30.639: INFO: Pod "downwardapi-volume-ab3c3c1a-c5ef-439b-b291-d72a619eef36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.074373827s
STEP: Saw pod success
May  2 20:14:30.640: INFO: Pod "downwardapi-volume-ab3c3c1a-c5ef-439b-b291-d72a619eef36" satisfied condition "Succeeded or Failed"
May  2 20:14:30.687: INFO: Trying to get logs from node node-2 pod downwardapi-volume-ab3c3c1a-c5ef-439b-b291-d72a619eef36 container client-container: <nil>
STEP: delete the pod
May  2 20:14:30.782: INFO: Waiting for pod downwardapi-volume-ab3c3c1a-c5ef-439b-b291-d72a619eef36 to disappear
May  2 20:14:30.804: INFO: Pod downwardapi-volume-ab3c3c1a-c5ef-439b-b291-d72a619eef36 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:14:30.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6265" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":-1,"completed":54,"skipped":1033,"failed":0}

SSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:14:30.918: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
May  2 20:14:31.338: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7787  98ee29bf-87ec-4963-8c12-b20970e200c8 2873990 0 2022-05-02 20:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2022-05-02 20:14:31 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
May  2 20:14:31.338: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7787  98ee29bf-87ec-4963-8c12-b20970e200c8 2873993 0 2022-05-02 20:14:31 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2022-05-02 20:14:31 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:14:31.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7787" for this suite.

•
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":-1,"completed":55,"skipped":1051,"failed":0}

SS
------------------------------
[BeforeEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:14:31.431: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward api env vars
May  2 20:14:31.672: INFO: Waiting up to 5m0s for pod "downward-api-5cdc1a65-11a4-4ef6-98cc-c99abf962492" in namespace "downward-api-66" to be "Succeeded or Failed"
May  2 20:14:31.698: INFO: Pod "downward-api-5cdc1a65-11a4-4ef6-98cc-c99abf962492": Phase="Pending", Reason="", readiness=false. Elapsed: 26.343987ms
May  2 20:14:33.740: INFO: Pod "downward-api-5cdc1a65-11a4-4ef6-98cc-c99abf962492": Phase="Pending", Reason="", readiness=false. Elapsed: 2.068264944s
May  2 20:14:35.759: INFO: Pod "downward-api-5cdc1a65-11a4-4ef6-98cc-c99abf962492": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.08678692s
STEP: Saw pod success
May  2 20:14:35.759: INFO: Pod "downward-api-5cdc1a65-11a4-4ef6-98cc-c99abf962492" satisfied condition "Succeeded or Failed"
May  2 20:14:35.771: INFO: Trying to get logs from node node-2 pod downward-api-5cdc1a65-11a4-4ef6-98cc-c99abf962492 container dapi-container: <nil>
STEP: delete the pod
May  2 20:14:35.853: INFO: Waiting for pod downward-api-5cdc1a65-11a4-4ef6-98cc-c99abf962492 to disappear
May  2 20:14:35.864: INFO: Pod downward-api-5cdc1a65-11a4-4ef6-98cc-c99abf962492 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:14:35.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-66" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":-1,"completed":56,"skipped":1053,"failed":0}

SSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:14:35.963: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be immutable if `immutable` field is set [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:14:36.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6571" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","total":-1,"completed":57,"skipped":1067,"failed":0}

SS
------------------------------
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:14:30.016: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name s-test-opt-del-47cbbc55-84f8-4c33-b74d-8d337b6ad0ab
STEP: Creating secret with name s-test-opt-upd-9f32899c-688a-4fe4-b9a8-6395b9c927e4
STEP: Creating the pod
May  2 20:14:30.253: INFO: The status of Pod pod-secrets-3294fb7d-354d-4b82-bb82-f81f3fe2b2c9 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:14:32.284: INFO: The status of Pod pod-secrets-3294fb7d-354d-4b82-bb82-f81f3fe2b2c9 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:14:34.276: INFO: The status of Pod pod-secrets-3294fb7d-354d-4b82-bb82-f81f3fe2b2c9 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:14:36.278: INFO: The status of Pod pod-secrets-3294fb7d-354d-4b82-bb82-f81f3fe2b2c9 is Running (Ready = true)
STEP: Deleting secret s-test-opt-del-47cbbc55-84f8-4c33-b74d-8d337b6ad0ab
STEP: Updating secret s-test-opt-upd-9f32899c-688a-4fe4-b9a8-6395b9c927e4
STEP: Creating secret with name s-test-opt-create-de72b98c-f4bf-438b-8f0e-ada62782e68d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:14:40.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4167" for this suite.


• [SLOW TEST:10.728 seconds]
[sig-storage] Secrets
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":-1,"completed":84,"skipped":1514,"failed":0}

SSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:14:40.774: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
May  2 20:14:46.114: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:14:46.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3630" for this suite.


• [SLOW TEST:5.475 seconds]
[sig-node] Container Runtime
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  blackbox test
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/runtime.go:41
    on terminated container
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/runtime.go:134
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":-1,"completed":85,"skipped":1523,"failed":0}

S
------------------------------
[BeforeEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:14:36.241: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:14:48.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2221" for this suite.


• [SLOW TEST:12.225 seconds]
[sig-apps] Job
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":-1,"completed":58,"skipped":1069,"failed":0}

SSSS
------------------------------
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:14:48.502: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: validating cluster-info
May  2 20:14:48.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-4346 cluster-info'
May  2 20:14:48.807: INFO: stderr: ""
May  2 20:14:48.807: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.233.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:14:48.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4346" for this suite.

•
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","total":-1,"completed":59,"skipped":1073,"failed":0}

SSSSSSSSSSS
------------------------------
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:14:48.869: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a service externalname-service with the type=ExternalName in namespace services-3373
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-3373
I0502 20:14:49.198421      19 runners.go:190] Created replication controller with name: externalname-service, namespace: services-3373, replica count: 2
I0502 20:14:52.250289      19 runners.go:190] externalname-service Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0502 20:14:55.251186      19 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  2 20:14:55.251: INFO: Creating new exec pod
May  2 20:15:00.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-3373 exec execpodp8pb8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
May  2 20:15:00.775: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
May  2 20:15:00.775: INFO: stdout: "externalname-service-9gxc9"
May  2 20:15:00.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-3373 exec execpodp8pb8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.50.27 80'
May  2 20:15:01.183: INFO: stderr: "+ nc -v -t -w 2 10.233.50.27 80\nConnection to 10.233.50.27 80 port [tcp/http] succeeded!\n+ echo hostName\n"
May  2 20:15:01.183: INFO: stdout: ""
May  2 20:15:02.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-3373 exec execpodp8pb8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.50.27 80'
May  2 20:15:02.658: INFO: stderr: "+ nc -v -t -w 2 10.233.50.27 80\n+ echo hostName\nConnection to 10.233.50.27 80 port [tcp/http] succeeded!\n"
May  2 20:15:02.658: INFO: stdout: "externalname-service-9gxc9"
May  2 20:15:02.658: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:15:02.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3373" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753


• [SLOW TEST:13.904 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":-1,"completed":60,"skipped":1084,"failed":0}

SSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:15:02.864: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  2 20:15:03.949: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
May  2 20:15:06.003: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119304, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119304, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119304, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119303, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  2 20:15:09.090: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
May  2 20:15:09.171: INFO: Waiting for webhook configuration to be ready...
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:15:21.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5984" for this suite.
STEP: Destroying namespace "webhook-5984-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102


• [SLOW TEST:19.211 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":-1,"completed":61,"skipped":1095,"failed":0}

SSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:15:22.270: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support proxy with --port 0  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: starting the proxy server
May  2 20:15:22.387: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-5492 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:15:22.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5492" for this suite.

•
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":-1,"completed":62,"skipped":1115,"failed":0}

SSSSS
------------------------------
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:15:22.676: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-map-49e7447e-8b6a-4843-bb1e-56b143d91d09
STEP: Creating a pod to test consume configMaps
May  2 20:15:22.863: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0b03abe7-d53b-4dd5-b0eb-f25ee17a5734" in namespace "projected-3213" to be "Succeeded or Failed"
May  2 20:15:22.889: INFO: Pod "pod-projected-configmaps-0b03abe7-d53b-4dd5-b0eb-f25ee17a5734": Phase="Pending", Reason="", readiness=false. Elapsed: 25.796124ms
May  2 20:15:24.907: INFO: Pod "pod-projected-configmaps-0b03abe7-d53b-4dd5-b0eb-f25ee17a5734": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044428917s
May  2 20:15:26.925: INFO: Pod "pod-projected-configmaps-0b03abe7-d53b-4dd5-b0eb-f25ee17a5734": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.061968741s
STEP: Saw pod success
May  2 20:15:26.925: INFO: Pod "pod-projected-configmaps-0b03abe7-d53b-4dd5-b0eb-f25ee17a5734" satisfied condition "Succeeded or Failed"
May  2 20:15:26.941: INFO: Trying to get logs from node node-2 pod pod-projected-configmaps-0b03abe7-d53b-4dd5-b0eb-f25ee17a5734 container agnhost-container: <nil>
STEP: delete the pod
May  2 20:15:27.038: INFO: Waiting for pod pod-projected-configmaps-0b03abe7-d53b-4dd5-b0eb-f25ee17a5734 to disappear
May  2 20:15:27.053: INFO: Pod pod-projected-configmaps-0b03abe7-d53b-4dd5-b0eb-f25ee17a5734 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:15:27.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3213" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":63,"skipped":1120,"failed":0}

SSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:15:27.175: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Kubectl label
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1318
STEP: creating the pod
May  2 20:15:27.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6956 create -f -'
May  2 20:15:29.435: INFO: stderr: ""
May  2 20:15:29.435: INFO: stdout: "pod/pause created\n"
May  2 20:15:29.435: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
May  2 20:15:29.442: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-6956" to be "running and ready"
May  2 20:15:29.469: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 27.518008ms
May  2 20:15:31.507: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065569321s
May  2 20:15:33.559: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.117287415s
May  2 20:15:33.559: INFO: Pod "pause" satisfied condition "running and ready"
May  2 20:15:33.559: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: adding the label testing-label with value testing-label-value to a pod
May  2 20:15:33.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6956 label pods pause testing-label=testing-label-value'
May  2 20:15:33.810: INFO: stderr: ""
May  2 20:15:33.810: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
May  2 20:15:33.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6956 get pod pause -L testing-label'
May  2 20:15:34.008: INFO: stderr: ""
May  2 20:15:34.008: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
May  2 20:15:34.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6956 label pods pause testing-label-'
May  2 20:15:34.198: INFO: stderr: ""
May  2 20:15:34.198: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
May  2 20:15:34.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6956 get pod pause -L testing-label'
May  2 20:15:34.344: INFO: stderr: ""
May  2 20:15:34.344: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] Kubectl label
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1324
STEP: using delete to clean up resources
May  2 20:15:34.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6956 delete --grace-period=0 --force -f -'
May  2 20:15:34.518: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  2 20:15:34.518: INFO: stdout: "pod \"pause\" force deleted\n"
May  2 20:15:34.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6956 get rc,svc -l name=pause --no-headers'
May  2 20:15:34.677: INFO: stderr: "No resources found in kubectl-6956 namespace.\n"
May  2 20:15:34.677: INFO: stdout: ""
May  2 20:15:34.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-6956 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May  2 20:15:34.797: INFO: stderr: ""
May  2 20:15:34.797: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:15:34.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6956" for this suite.


• [SLOW TEST:7.693 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1316
    should update the label on a resource  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":-1,"completed":64,"skipped":1133,"failed":0}

SSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:15:34.921: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-66687440-b53d-4dc3-b456-165d9f72e06d
STEP: Creating a pod to test consume secrets
May  2 20:15:35.087: INFO: Waiting up to 5m0s for pod "pod-secrets-0db91b2d-7919-4ba4-9253-885460f332fd" in namespace "secrets-6749" to be "Succeeded or Failed"
May  2 20:15:35.111: INFO: Pod "pod-secrets-0db91b2d-7919-4ba4-9253-885460f332fd": Phase="Pending", Reason="", readiness=false. Elapsed: 23.835173ms
May  2 20:15:37.121: INFO: Pod "pod-secrets-0db91b2d-7919-4ba4-9253-885460f332fd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034390217s
May  2 20:15:39.153: INFO: Pod "pod-secrets-0db91b2d-7919-4ba4-9253-885460f332fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.066308923s
STEP: Saw pod success
May  2 20:15:39.153: INFO: Pod "pod-secrets-0db91b2d-7919-4ba4-9253-885460f332fd" satisfied condition "Succeeded or Failed"
May  2 20:15:39.165: INFO: Trying to get logs from node node-2 pod pod-secrets-0db91b2d-7919-4ba4-9253-885460f332fd container secret-volume-test: <nil>
STEP: delete the pod
May  2 20:15:39.314: INFO: Waiting for pod pod-secrets-0db91b2d-7919-4ba4-9253-885460f332fd to disappear
May  2 20:15:39.324: INFO: Pod pod-secrets-0db91b2d-7919-4ba4-9253-885460f332fd no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:15:39.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6749" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":65,"skipped":1153,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:15:39.514: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service in namespace services-3456
STEP: creating service affinity-clusterip-transition in namespace services-3456
STEP: creating replication controller affinity-clusterip-transition in namespace services-3456
I0502 20:15:39.708985      19 runners.go:190] Created replication controller with name: affinity-clusterip-transition, namespace: services-3456, replica count: 3
I0502 20:15:42.760922      19 runners.go:190] affinity-clusterip-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0502 20:15:45.761296      19 runners.go:190] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  2 20:15:45.784: INFO: Creating new exec pod
May  2 20:15:48.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-3456 exec execpod-affinitypdm4n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
May  2 20:15:49.263: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-transition 80\n+ echo hostName\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
May  2 20:15:49.263: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 20:15:49.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-3456 exec execpod-affinitypdm4n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.29.214 80'
May  2 20:15:49.592: INFO: stderr: "+ nc -v -t -w 2 10.233.29.214 80\n+ echo hostName\nConnection to 10.233.29.214 80 port [tcp/http] succeeded!\n"
May  2 20:15:49.593: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 20:15:49.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-3456 exec execpod-affinitypdm4n -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.29.214:80/ ; done'
May  2 20:15:50.289: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n"
May  2 20:15:50.289: INFO: stdout: "\naffinity-clusterip-transition-77p9m\naffinity-clusterip-transition-p8jgp\naffinity-clusterip-transition-tztrm\naffinity-clusterip-transition-77p9m\naffinity-clusterip-transition-p8jgp\naffinity-clusterip-transition-tztrm\naffinity-clusterip-transition-77p9m\naffinity-clusterip-transition-p8jgp\naffinity-clusterip-transition-tztrm\naffinity-clusterip-transition-77p9m\naffinity-clusterip-transition-p8jgp\naffinity-clusterip-transition-tztrm\naffinity-clusterip-transition-77p9m\naffinity-clusterip-transition-p8jgp\naffinity-clusterip-transition-tztrm\naffinity-clusterip-transition-77p9m"
May  2 20:15:50.289: INFO: Received response from host: affinity-clusterip-transition-77p9m
May  2 20:15:50.289: INFO: Received response from host: affinity-clusterip-transition-p8jgp
May  2 20:15:50.289: INFO: Received response from host: affinity-clusterip-transition-tztrm
May  2 20:15:50.289: INFO: Received response from host: affinity-clusterip-transition-77p9m
May  2 20:15:50.289: INFO: Received response from host: affinity-clusterip-transition-p8jgp
May  2 20:15:50.289: INFO: Received response from host: affinity-clusterip-transition-tztrm
May  2 20:15:50.289: INFO: Received response from host: affinity-clusterip-transition-77p9m
May  2 20:15:50.289: INFO: Received response from host: affinity-clusterip-transition-p8jgp
May  2 20:15:50.289: INFO: Received response from host: affinity-clusterip-transition-tztrm
May  2 20:15:50.289: INFO: Received response from host: affinity-clusterip-transition-77p9m
May  2 20:15:50.289: INFO: Received response from host: affinity-clusterip-transition-p8jgp
May  2 20:15:50.289: INFO: Received response from host: affinity-clusterip-transition-tztrm
May  2 20:15:50.289: INFO: Received response from host: affinity-clusterip-transition-77p9m
May  2 20:15:50.289: INFO: Received response from host: affinity-clusterip-transition-p8jgp
May  2 20:15:50.289: INFO: Received response from host: affinity-clusterip-transition-tztrm
May  2 20:15:50.289: INFO: Received response from host: affinity-clusterip-transition-77p9m
May  2 20:15:50.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-3456 exec execpod-affinitypdm4n -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.29.214:80/ ; done'
May  2 20:15:50.979: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.29.214:80/\n"
May  2 20:15:50.979: INFO: stdout: "\naffinity-clusterip-transition-tztrm\naffinity-clusterip-transition-tztrm\naffinity-clusterip-transition-tztrm\naffinity-clusterip-transition-tztrm\naffinity-clusterip-transition-tztrm\naffinity-clusterip-transition-tztrm\naffinity-clusterip-transition-tztrm\naffinity-clusterip-transition-tztrm\naffinity-clusterip-transition-tztrm\naffinity-clusterip-transition-tztrm\naffinity-clusterip-transition-tztrm\naffinity-clusterip-transition-tztrm\naffinity-clusterip-transition-tztrm\naffinity-clusterip-transition-tztrm\naffinity-clusterip-transition-tztrm\naffinity-clusterip-transition-tztrm"
May  2 20:15:50.979: INFO: Received response from host: affinity-clusterip-transition-tztrm
May  2 20:15:50.979: INFO: Received response from host: affinity-clusterip-transition-tztrm
May  2 20:15:50.979: INFO: Received response from host: affinity-clusterip-transition-tztrm
May  2 20:15:50.979: INFO: Received response from host: affinity-clusterip-transition-tztrm
May  2 20:15:50.979: INFO: Received response from host: affinity-clusterip-transition-tztrm
May  2 20:15:50.979: INFO: Received response from host: affinity-clusterip-transition-tztrm
May  2 20:15:50.979: INFO: Received response from host: affinity-clusterip-transition-tztrm
May  2 20:15:50.979: INFO: Received response from host: affinity-clusterip-transition-tztrm
May  2 20:15:50.979: INFO: Received response from host: affinity-clusterip-transition-tztrm
May  2 20:15:50.979: INFO: Received response from host: affinity-clusterip-transition-tztrm
May  2 20:15:50.979: INFO: Received response from host: affinity-clusterip-transition-tztrm
May  2 20:15:50.979: INFO: Received response from host: affinity-clusterip-transition-tztrm
May  2 20:15:50.979: INFO: Received response from host: affinity-clusterip-transition-tztrm
May  2 20:15:50.979: INFO: Received response from host: affinity-clusterip-transition-tztrm
May  2 20:15:50.979: INFO: Received response from host: affinity-clusterip-transition-tztrm
May  2 20:15:50.979: INFO: Received response from host: affinity-clusterip-transition-tztrm
May  2 20:15:50.979: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-3456, will wait for the garbage collector to delete the pods
May  2 20:15:51.171: INFO: Deleting ReplicationController affinity-clusterip-transition took: 33.164518ms
May  2 20:15:51.376: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 204.940974ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:15:54.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3456" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753


• [SLOW TEST:15.348 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","total":-1,"completed":66,"skipped":1211,"failed":0}

SSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:15:54.902: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should find a service from listing all namespaces [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: fetching services
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:15:55.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4291" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

•
------------------------------
{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","total":-1,"completed":67,"skipped":1223,"failed":0}

SSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:15:55.102: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-c3cbe04f-4258-45e6-b30f-62c009370a43
STEP: Creating a pod to test consume configMaps
May  2 20:15:55.252: INFO: Waiting up to 5m0s for pod "pod-configmaps-415ab238-29cc-405e-a348-4c62fd724dc4" in namespace "configmap-6862" to be "Succeeded or Failed"
May  2 20:15:55.282: INFO: Pod "pod-configmaps-415ab238-29cc-405e-a348-4c62fd724dc4": Phase="Pending", Reason="", readiness=false. Elapsed: 29.775451ms
May  2 20:15:57.292: INFO: Pod "pod-configmaps-415ab238-29cc-405e-a348-4c62fd724dc4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039385713s
May  2 20:15:59.304: INFO: Pod "pod-configmaps-415ab238-29cc-405e-a348-4c62fd724dc4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051186473s
STEP: Saw pod success
May  2 20:15:59.304: INFO: Pod "pod-configmaps-415ab238-29cc-405e-a348-4c62fd724dc4" satisfied condition "Succeeded or Failed"
May  2 20:15:59.313: INFO: Trying to get logs from node node-2 pod pod-configmaps-415ab238-29cc-405e-a348-4c62fd724dc4 container agnhost-container: <nil>
STEP: delete the pod
May  2 20:15:59.393: INFO: Waiting for pod pod-configmaps-415ab238-29cc-405e-a348-4c62fd724dc4 to disappear
May  2 20:15:59.403: INFO: Pod pod-configmaps-415ab238-29cc-405e-a348-4c62fd724dc4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:15:59.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6862" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":-1,"completed":68,"skipped":1238,"failed":0}

SSSSSSSSSSS
------------------------------
[BeforeEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:14:46.254: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
[It] should replace jobs when ReplaceConcurrent [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a ReplaceConcurrent cronjob
STEP: Ensuring a job is scheduled
STEP: Ensuring exactly one is scheduled
STEP: Ensuring exactly one running job exists by listing jobs explicitly
STEP: Ensuring the job is replaced with a new one
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:16:00.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-4205" for this suite.


• [SLOW TEST:74.404 seconds]
[sig-apps] CronJob
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","total":-1,"completed":86,"skipped":1524,"failed":0}
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:16:00.664: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a service externalname-service with the type=ExternalName in namespace services-1610
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-1610
I0502 20:16:01.260857      18 runners.go:190] Created replication controller with name: externalname-service, namespace: services-1610, replica count: 2
I0502 20:16:04.312329      18 runners.go:190] externalname-service Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0502 20:16:07.314199      18 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  2 20:16:07.314: INFO: Creating new exec pod
May  2 20:16:12.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=services-1610 exec execpod7mml7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
May  2 20:16:12.827: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
May  2 20:16:12.827: INFO: stdout: ""
May  2 20:16:13.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=services-1610 exec execpod7mml7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
May  2 20:16:14.129: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
May  2 20:16:14.129: INFO: stdout: ""
May  2 20:16:14.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=services-1610 exec execpod7mml7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
May  2 20:16:15.172: INFO: stderr: "+ + echonc -v hostName -t -w\n 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
May  2 20:16:15.172: INFO: stdout: ""
May  2 20:16:15.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=services-1610 exec execpod7mml7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
May  2 20:16:16.098: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
May  2 20:16:16.098: INFO: stdout: "externalname-service-kzx8c"
May  2 20:16:16.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=services-1610 exec execpod7mml7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.28.206 80'
May  2 20:16:16.370: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.28.206 80\nConnection to 10.233.28.206 80 port [tcp/http] succeeded!\n"
May  2 20:16:16.370: INFO: stdout: ""
May  2 20:16:17.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=services-1610 exec execpod7mml7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.28.206 80'
May  2 20:16:17.654: INFO: stderr: "+ nc -v -t -w 2 10.233.28.206 80\n+ echo hostName\nConnection to 10.233.28.206 80 port [tcp/http] succeeded!\n"
May  2 20:16:17.654: INFO: stdout: ""
May  2 20:16:18.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=services-1610 exec execpod7mml7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.28.206 80'
May  2 20:16:18.682: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.28.206 80\nConnection to 10.233.28.206 80 port [tcp/http] succeeded!\n"
May  2 20:16:18.682: INFO: stdout: "externalname-service-hw6m9"
May  2 20:16:18.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=services-1610 exec execpod7mml7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.20.186 32177'
May  2 20:16:19.022: INFO: stderr: "+ nc -v -t -w 2 10.100.20.186 32177\n+ echo hostName\nConnection to 10.100.20.186 32177 port [tcp/*] succeeded!\n"
May  2 20:16:19.023: INFO: stdout: "externalname-service-hw6m9"
May  2 20:16:19.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=services-1610 exec execpod7mml7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.18.197 32177'
May  2 20:16:19.349: INFO: stderr: "+ nc -v -t -w 2 10.100.18.197 32177\n+ echo hostName\nConnection to 10.100.18.197 32177 port [tcp/*] succeeded!\n"
May  2 20:16:19.349: INFO: stdout: ""
May  2 20:16:20.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=services-1610 exec execpod7mml7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.18.197 32177'
May  2 20:16:20.635: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.100.18.197 32177\nConnection to 10.100.18.197 32177 port [tcp/*] succeeded!\n"
May  2 20:16:20.635: INFO: stdout: "externalname-service-kzx8c"
May  2 20:16:20.635: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:16:20.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1610" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753


• [SLOW TEST:20.081 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":-1,"completed":87,"skipped":1524,"failed":0}

SSS
------------------------------
[BeforeEach] [sig-node] PodTemplates
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:16:20.758: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run the lifecycle of PodTemplates [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-node] PodTemplates
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:16:21.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-1242" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","total":-1,"completed":88,"skipped":1527,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:16:21.161: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should provide secure master service  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:16:21.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7401" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

•
------------------------------
{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":-1,"completed":89,"skipped":1553,"failed":0}

SSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:16:21.343: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:16:21.559: INFO: The status of Pod pod-secrets-c20ca9f4-2ea2-40fd-b17b-fe7af40002e7 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:16:23.576: INFO: The status of Pod pod-secrets-c20ca9f4-2ea2-40fd-b17b-fe7af40002e7 is Running (Ready = true)
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:16:23.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1394" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":-1,"completed":90,"skipped":1572,"failed":0}

S
------------------------------
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:15:59.479: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:15:59.690: INFO: created pod
May  2 20:15:59.690: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-2894" to be "Succeeded or Failed"
May  2 20:15:59.717: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 26.957543ms
May  2 20:16:01.733: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043440002s
May  2 20:16:03.767: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.077014258s
STEP: Saw pod success
May  2 20:16:03.767: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
May  2 20:16:33.771: INFO: polling logs
May  2 20:16:33.809: INFO: Pod logs: 
2022/05/02 20:16:03 OK: Got token
2022/05/02 20:16:03 validating with in-cluster discovery
2022/05/02 20:16:03 OK: got issuer https://kubernetes.default.svc.cluster.local
2022/05/02 20:16:03 Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-2894:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1651523159, NotBefore:1651522559, IssuedAt:1651522559, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-2894", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"713e4454-7ba7-461c-868a-5f75e2217c24"}}}
2022/05/02 20:16:03 OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
2022/05/02 20:16:03 OK: Validated signature on JWT
2022/05/02 20:16:03 OK: Got valid claims from token!
2022/05/02 20:16:03 Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-2894:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1651523159, NotBefore:1651522559, IssuedAt:1651522559, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-2894", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"713e4454-7ba7-461c-868a-5f75e2217c24"}}}

May  2 20:16:33.809: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:16:33.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2894" for this suite.


• [SLOW TEST:34.376 seconds]
[sig-auth] ServiceAccounts
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","total":-1,"completed":69,"skipped":1249,"failed":0}

SSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:16:33.917: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-map-8feb9374-d960-4e2d-a1a8-02665e83d8b8
STEP: Creating a pod to test consume secrets
May  2 20:16:34.076: INFO: Waiting up to 5m0s for pod "pod-secrets-093c2084-70e9-4c7b-bf5f-c1c15c2d88c2" in namespace "secrets-6740" to be "Succeeded or Failed"
May  2 20:16:34.089: INFO: Pod "pod-secrets-093c2084-70e9-4c7b-bf5f-c1c15c2d88c2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.322684ms
May  2 20:16:36.170: INFO: Pod "pod-secrets-093c2084-70e9-4c7b-bf5f-c1c15c2d88c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.093618831s
May  2 20:16:38.224: INFO: Pod "pod-secrets-093c2084-70e9-4c7b-bf5f-c1c15c2d88c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.147873071s
STEP: Saw pod success
May  2 20:16:38.224: INFO: Pod "pod-secrets-093c2084-70e9-4c7b-bf5f-c1c15c2d88c2" satisfied condition "Succeeded or Failed"
May  2 20:16:38.238: INFO: Trying to get logs from node node-2 pod pod-secrets-093c2084-70e9-4c7b-bf5f-c1c15c2d88c2 container secret-volume-test: <nil>
STEP: delete the pod
May  2 20:16:38.356: INFO: Waiting for pod pod-secrets-093c2084-70e9-4c7b-bf5f-c1c15c2d88c2 to disappear
May  2 20:16:38.389: INFO: Pod pod-secrets-093c2084-70e9-4c7b-bf5f-c1c15c2d88c2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:16:38.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6740" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":-1,"completed":70,"skipped":1269,"failed":0}

SSSSSSSS
------------------------------
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:16:38.471: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Kubectl logs
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1396
STEP: creating an pod
May  2 20:16:38.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-4458 run logs-generator --image=k8s.gcr.io/e2e-test-images/agnhost:2.32 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
May  2 20:16:38.862: INFO: stderr: ""
May  2 20:16:38.866: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Waiting for log generator to start.
May  2 20:16:38.866: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
May  2 20:16:38.866: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-4458" to be "running and ready, or succeeded"
May  2 20:16:38.942: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 75.569946ms
May  2 20:16:40.953: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.086328421s
May  2 20:16:42.966: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.099519628s
May  2 20:16:42.966: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
May  2 20:16:42.966: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
May  2 20:16:42.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-4458 logs logs-generator logs-generator'
May  2 20:16:43.122: INFO: stderr: ""
May  2 20:16:43.122: INFO: stdout: "I0502 20:16:40.801284       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/2gfz 593\nI0502 20:16:41.001265       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/svzd 516\nI0502 20:16:41.201409       1 logs_generator.go:76] 2 POST /api/v1/namespaces/default/pods/7w7 211\nI0502 20:16:41.401885       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/mpr 366\nI0502 20:16:41.602317       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/jzxm 410\nI0502 20:16:41.803173       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/98k 497\nI0502 20:16:42.001565       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/kube-system/pods/hhk 262\nI0502 20:16:42.201934       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/v62s 418\nI0502 20:16:42.401334       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/6nr 411\nI0502 20:16:42.601817       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/tz8 365\nI0502 20:16:42.801382       1 logs_generator.go:76] 10 POST /api/v1/namespaces/default/pods/rphp 379\nI0502 20:16:43.001853       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/sgsb 368\n"
STEP: limiting log lines
May  2 20:16:43.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-4458 logs logs-generator logs-generator --tail=1'
May  2 20:16:43.348: INFO: stderr: ""
May  2 20:16:43.348: INFO: stdout: "I0502 20:16:43.204588       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/default/pods/c5x 499\n"
May  2 20:16:43.348: INFO: got output "I0502 20:16:43.204588       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/default/pods/c5x 499\n"
STEP: limiting log bytes
May  2 20:16:43.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-4458 logs logs-generator logs-generator --limit-bytes=1'
May  2 20:16:43.558: INFO: stderr: ""
May  2 20:16:43.558: INFO: stdout: "I"
May  2 20:16:43.558: INFO: got output "I"
STEP: exposing timestamps
May  2 20:16:43.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-4458 logs logs-generator logs-generator --tail=1 --timestamps'
May  2 20:16:43.772: INFO: stderr: ""
May  2 20:16:43.772: INFO: stdout: "2022-05-02T20:16:43.602526431Z I0502 20:16:43.602394       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/kube-system/pods/fhsq 533\n"
May  2 20:16:43.772: INFO: got output "2022-05-02T20:16:43.602526431Z I0502 20:16:43.602394       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/kube-system/pods/fhsq 533\n"
STEP: restricting to a time range
May  2 20:16:46.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-4458 logs logs-generator logs-generator --since=1s'
May  2 20:16:46.436: INFO: stderr: ""
May  2 20:16:46.436: INFO: stdout: "I0502 20:16:45.601458       1 logs_generator.go:76] 24 POST /api/v1/namespaces/default/pods/hddh 282\nI0502 20:16:45.802194       1 logs_generator.go:76] 25 GET /api/v1/namespaces/kube-system/pods/hnmq 413\nI0502 20:16:46.003095       1 logs_generator.go:76] 26 GET /api/v1/namespaces/default/pods/5rd2 212\nI0502 20:16:46.202077       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/default/pods/shtp 433\nI0502 20:16:46.402094       1 logs_generator.go:76] 28 GET /api/v1/namespaces/kube-system/pods/hzpc 396\n"
May  2 20:16:46.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-4458 logs logs-generator logs-generator --since=24h'
May  2 20:16:46.617: INFO: stderr: ""
May  2 20:16:46.618: INFO: stdout: "I0502 20:16:40.801284       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/2gfz 593\nI0502 20:16:41.001265       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/svzd 516\nI0502 20:16:41.201409       1 logs_generator.go:76] 2 POST /api/v1/namespaces/default/pods/7w7 211\nI0502 20:16:41.401885       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/mpr 366\nI0502 20:16:41.602317       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/jzxm 410\nI0502 20:16:41.803173       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/98k 497\nI0502 20:16:42.001565       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/kube-system/pods/hhk 262\nI0502 20:16:42.201934       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/v62s 418\nI0502 20:16:42.401334       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/6nr 411\nI0502 20:16:42.601817       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/tz8 365\nI0502 20:16:42.801382       1 logs_generator.go:76] 10 POST /api/v1/namespaces/default/pods/rphp 379\nI0502 20:16:43.001853       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/sgsb 368\nI0502 20:16:43.204588       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/default/pods/c5x 499\nI0502 20:16:43.402270       1 logs_generator.go:76] 13 GET /api/v1/namespaces/default/pods/ffdm 302\nI0502 20:16:43.602394       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/kube-system/pods/fhsq 533\nI0502 20:16:43.802071       1 logs_generator.go:76] 15 GET /api/v1/namespaces/kube-system/pods/5pxq 485\nI0502 20:16:44.001601       1 logs_generator.go:76] 16 GET /api/v1/namespaces/default/pods/s9w 310\nI0502 20:16:44.201864       1 logs_generator.go:76] 17 POST /api/v1/namespaces/kube-system/pods/ptx 440\nI0502 20:16:44.402131       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/sw7p 321\nI0502 20:16:44.601488       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/g9hk 547\nI0502 20:16:44.802070       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/dqr 332\nI0502 20:16:45.001419       1 logs_generator.go:76] 21 POST /api/v1/namespaces/default/pods/5kw 462\nI0502 20:16:45.201809       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/default/pods/qbg 578\nI0502 20:16:45.406119       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/kube-system/pods/crk 457\nI0502 20:16:45.601458       1 logs_generator.go:76] 24 POST /api/v1/namespaces/default/pods/hddh 282\nI0502 20:16:45.802194       1 logs_generator.go:76] 25 GET /api/v1/namespaces/kube-system/pods/hnmq 413\nI0502 20:16:46.003095       1 logs_generator.go:76] 26 GET /api/v1/namespaces/default/pods/5rd2 212\nI0502 20:16:46.202077       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/default/pods/shtp 433\nI0502 20:16:46.402094       1 logs_generator.go:76] 28 GET /api/v1/namespaces/kube-system/pods/hzpc 396\nI0502 20:16:46.601625       1 logs_generator.go:76] 29 PUT /api/v1/namespaces/ns/pods/zc2n 266\n"
[AfterEach] Kubectl logs
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1401
May  2 20:16:46.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-4458 delete pod logs-generator'
May  2 20:16:48.735: INFO: stderr: ""
May  2 20:16:48.735: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:16:48.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4458" for this suite.


• [SLOW TEST:10.312 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1393
    should be able to retrieve and filter logs  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":-1,"completed":71,"skipped":1277,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:16:48.828: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating replication controller my-hostname-basic-1a55153b-25e3-411d-a633-d579efa3df2f
May  2 20:16:48.948: INFO: Pod name my-hostname-basic-1a55153b-25e3-411d-a633-d579efa3df2f: Found 0 pods out of 1
May  2 20:16:53.958: INFO: Pod name my-hostname-basic-1a55153b-25e3-411d-a633-d579efa3df2f: Found 1 pods out of 1
May  2 20:16:53.959: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-1a55153b-25e3-411d-a633-d579efa3df2f" are running
May  2 20:16:53.975: INFO: Pod "my-hostname-basic-1a55153b-25e3-411d-a633-d579efa3df2f-hf2rd" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-05-02 20:16:48 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-05-02 20:16:50 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-05-02 20:16:50 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-05-02 20:16:48 +0000 UTC Reason: Message:}])
May  2 20:16:53.975: INFO: Trying to dial the pod
May  2 20:16:59.022: INFO: Controller my-hostname-basic-1a55153b-25e3-411d-a633-d579efa3df2f: Got expected result from replica 1 [my-hostname-basic-1a55153b-25e3-411d-a633-d579efa3df2f-hf2rd]: "my-hostname-basic-1a55153b-25e3-411d-a633-d579efa3df2f-hf2rd", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:16:59.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7072" for this suite.


• [SLOW TEST:10.241 seconds]
[sig-apps] ReplicationController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":-1,"completed":72,"skipped":1302,"failed":0}

SSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:16:59.147: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:16:59.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-5012 create -f -'
May  2 20:17:01.672: INFO: stderr: ""
May  2 20:17:01.672: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
May  2 20:17:01.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-5012 create -f -'
May  2 20:17:04.225: INFO: stderr: ""
May  2 20:17:04.225: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
May  2 20:17:05.242: INFO: Selector matched 1 pods for map[app:agnhost]
May  2 20:17:05.242: INFO: Found 1 / 1
May  2 20:17:05.242: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May  2 20:17:05.251: INFO: Selector matched 1 pods for map[app:agnhost]
May  2 20:17:05.251: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May  2 20:17:05.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-5012 describe pod agnhost-primary-st9xc'
May  2 20:17:05.488: INFO: stderr: ""
May  2 20:17:05.488: INFO: stdout: "Name:         agnhost-primary-st9xc\nNamespace:    kubectl-5012\nPriority:     0\nNode:         node-2/10.100.20.46\nStart Time:   Mon, 02 May 2022 20:17:01 +0000\nLabels:       app=agnhost\n              role=primary\nAnnotations:  cni.projectcalico.org/containerID: 4bd7a2ade105af45a5a40dc62dc048c7970d4904503df9c41e35ffd112910223\n              cni.projectcalico.org/podIP: 10.233.69.84/32\n              cni.projectcalico.org/podIPs: 10.233.69.84/32\nStatus:       Running\nIP:           10.233.69.84\nIPs:\n  IP:           10.233.69.84\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   docker://2cb742398597a90cbc56b154d3b0eb2a2433b91bcd126e10e79ead56b95d8b58\n    Image:          k8s.gcr.io/e2e-test-images/agnhost:2.32\n    Image ID:       docker-pullable://k8s.gcr.io/e2e-test-images/agnhost@sha256:758db666ac7028534dba72e7e9bb1e57bb81b8196f976f7a5cc351ef8b3529e1\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 02 May 2022 20:17:03 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-pll9m (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-pll9m:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  4s    default-scheduler  Successfully assigned kubectl-5012/agnhost-primary-st9xc to node-2\n  Normal  Pulled     2s    kubelet            Container image \"k8s.gcr.io/e2e-test-images/agnhost:2.32\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    2s    kubelet            Started container agnhost-primary\n"
May  2 20:17:05.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-5012 describe rc agnhost-primary'
May  2 20:17:05.690: INFO: stderr: ""
May  2 20:17:05.690: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-5012\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        k8s.gcr.io/e2e-test-images/agnhost:2.32\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: agnhost-primary-st9xc\n"
May  2 20:17:05.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-5012 describe service agnhost-primary'
May  2 20:17:06.010: INFO: stderr: ""
May  2 20:17:06.010: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-5012\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.233.10.48\nIPs:               10.233.10.48\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.233.69.84:6379\nSession Affinity:  None\nEvents:            <none>\n"
May  2 20:17:06.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-5012 describe node node-0'
May  2 20:17:06.360: INFO: stderr: ""
May  2 20:17:06.361: INFO: stdout: "Name:               node-0\nRoles:              control-plane,master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=node-0\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node-role.kubernetes.io/master=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\n                    whitemist-version=fire-whirl-1-rc1\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"driver.longhorn.io\":\"node-0\"}\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.100.18.197/21\n                    projectcalico.org/IPv4VXLANTunnelAddr: 10.233.95.0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 26 Apr 2022 21:53:17 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  node-0\n  AcquireTime:     <unset>\n  RenewTime:       Mon, 02 May 2022 20:16:56 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Fri, 29 Apr 2022 23:53:17 +0000   Fri, 29 Apr 2022 23:53:17 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Mon, 02 May 2022 20:17:00 +0000   Tue, 26 Apr 2022 21:53:14 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Mon, 02 May 2022 20:17:00 +0000   Tue, 26 Apr 2022 21:53:14 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Mon, 02 May 2022 20:17:00 +0000   Tue, 26 Apr 2022 21:53:14 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Mon, 02 May 2022 20:17:00 +0000   Tue, 26 Apr 2022 21:55:12 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.100.18.197\n  Hostname:    node-0\nCapacity:\n  cpu:                2\n  ephemeral-storage:  40470732Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             4026028Ki\n  pods:               110\nAllocatable:\n  cpu:                1800m\n  ephemeral-storage:  37297826550\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3399340Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 8bdf932bc4fa4750b5b197076b989649\n  System UUID:                8bdf932b-c4fa-4750-b5b1-97076b989649\n  Boot ID:                    665df6ed-d65a-4ba1-b87e-ad09bbc1a637\n  Kernel Version:             5.4.0-109-generic\n  OS Image:                   Ubuntu 20.04.2 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://20.10.11\n  Kubelet Version:            v1.22.5\n  Kube-Proxy Version:         v1.22.5\nPodCIDR:                      10.233.64.0/24\nPodCIDRs:                     10.233.64.0/24\nNon-terminated Pods:          (30 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  default                     openebs-localpv-provisioner-5797cc88bb-s6kjq               0 (0%)        0 (0%)      0 (0%)           0 (0%)         2d20h\n  ingress-nginx               ingress-nginx-controller-gsr5j                             100m (5%)     0 (0%)      90Mi (2%)        0 (0%)         2d20h\n  kube-system                 calico-kube-controllers-78fc6f9f6d-42g5f                   30m (1%)      1 (55%)     64M (1%)         256M (7%)      2d20h\n  kube-system                 calico-node-bkmj2                                          150m (8%)     300m (16%)  64M (1%)         500M (14%)     2d20h\n  kube-system                 coredns-6974b95c6f-5pxzw                                   100m (5%)     0 (0%)      70Mi (2%)        170Mi (5%)     2d20h\n  kube-system                 dns-autoscaler-57d7bffd65-sglm7                            20m (1%)      0 (0%)      10Mi (0%)        0 (0%)         2d20h\n  kube-system                 kube-apiserver-node-0                                      250m (13%)    0 (0%)      0 (0%)           0 (0%)         2d20h\n  kube-system                 kube-controller-manager-node-0                             200m (11%)    0 (0%)      0 (0%)           0 (0%)         2d20h\n  kube-system                 kube-proxy-dr5wk                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         2d20h\n  kube-system                 kube-scheduler-node-0                                      100m (5%)     0 (0%)      0 (0%)           0 (0%)         2d20h\n  kube-system                 kube-vip-ds-2vwtm                                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         2d20h\n  kube-system                 kubernetes-dashboard-9b888cdd5-hdsf6                       50m (2%)      100m (5%)   64M (1%)         256M (7%)      2d20h\n  kube-system                 kubernetes-dashboard-admin-7859f7698f-glz7f                50m (2%)      100m (5%)   64M (1%)         256M (7%)      2d20h\n  kube-system                 nodelocaldns-g27cn                                         100m (5%)     0 (0%)      70Mi (2%)        170Mi (5%)     2d20h\n  longhorn-system             csi-attacher-5f46994f7-6fc86                               0 (0%)        0 (0%)      0 (0%)           0 (0%)         2d20h\n  longhorn-system             csi-attacher-5f46994f7-gvvfz                               0 (0%)        0 (0%)      0 (0%)           0 (0%)         2d20h\n  longhorn-system             csi-provisioner-6ccbfbf86f-2nlnj                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         2d20h\n  longhorn-system             csi-provisioner-6ccbfbf86f-sc46l                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         2d20h\n  longhorn-system             csi-resizer-6dd8bd4c97-6b8pl                               0 (0%)        0 (0%)      0 (0%)           0 (0%)         2d20h\n  longhorn-system             csi-resizer-6dd8bd4c97-rzbks                               0 (0%)        0 (0%)      0 (0%)           0 (0%)         2d20h\n  longhorn-system             csi-snapshotter-86f65d8bc-fkq56                            0 (0%)        0 (0%)      0 (0%)           0 (0%)         2d20h\n  longhorn-system             csi-snapshotter-86f65d8bc-gxsh5                            0 (0%)        0 (0%)      0 (0%)           0 (0%)         2d20h\n  longhorn-system             engine-image-ei-4dbdb778-l8mjl                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         2d20h\n  longhorn-system             instance-manager-e-8aec390b                                216m (12%)    0 (0%)      0 (0%)           0 (0%)         2d20h\n  longhorn-system             instance-manager-r-c107f637                                216m (12%)    0 (0%)      0 (0%)           0 (0%)         2d20h\n  longhorn-system             longhorn-csi-plugin-s9p74                                  0 (0%)        0 (0%)      0 (0%)           0 (0%)         2d20h\n  longhorn-system             longhorn-manager-brmrd                                     0 (0%)        0 (0%)      0 (0%)           0 (0%)         2d20h\n  metallb-system              metallb-speaker-j4fxs                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         2d20h\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-6d4cefb2b2954144-rsdzv    0 (0%)        0 (0%)      0 (0%)           0 (0%)         22m\n  statefulset-6538            ss-1                                                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         10s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests        Limits\n  --------           --------        ------\n  cpu                1582m (87%)     1500m (83%)\n  memory             495760Ki (14%)  1624515840 (46%)\n  ephemeral-storage  0 (0%)          0 (0%)\n  hugepages-1Gi      0 (0%)          0 (0%)\n  hugepages-2Mi      0 (0%)          0 (0%)\nEvents:              <none>\n"
May  2 20:17:06.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-5012 describe namespace kubectl-5012'
May  2 20:17:06.578: INFO: stderr: ""
May  2 20:17:06.578: INFO: stdout: "Name:         kubectl-5012\nLabels:       e2e-framework=kubectl\n              e2e-run=005bda42-ae46-4aa0-89a0-7ee0f6694d26\n              kubernetes.io/metadata.name=kubectl-5012\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:17:06.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5012" for this suite.


• [SLOW TEST:7.468 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1094
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":-1,"completed":73,"skipped":1322,"failed":0}

SSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] Discovery
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:17:06.642: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename discovery
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Discovery
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:39
STEP: Setting up server cert
[It] should validate PreferredVersion for each APIGroup [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:17:06.999: INFO: Checking APIGroup: apiregistration.k8s.io
May  2 20:17:07.000: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
May  2 20:17:07.001: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
May  2 20:17:07.001: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
May  2 20:17:07.001: INFO: Checking APIGroup: apps
May  2 20:17:07.002: INFO: PreferredVersion.GroupVersion: apps/v1
May  2 20:17:07.002: INFO: Versions found [{apps/v1 v1}]
May  2 20:17:07.002: INFO: apps/v1 matches apps/v1
May  2 20:17:07.002: INFO: Checking APIGroup: events.k8s.io
May  2 20:17:07.004: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
May  2 20:17:07.004: INFO: Versions found [{events.k8s.io/v1 v1} {events.k8s.io/v1beta1 v1beta1}]
May  2 20:17:07.004: INFO: events.k8s.io/v1 matches events.k8s.io/v1
May  2 20:17:07.004: INFO: Checking APIGroup: authentication.k8s.io
May  2 20:17:07.006: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
May  2 20:17:07.006: INFO: Versions found [{authentication.k8s.io/v1 v1}]
May  2 20:17:07.006: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
May  2 20:17:07.006: INFO: Checking APIGroup: authorization.k8s.io
May  2 20:17:07.008: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
May  2 20:17:07.008: INFO: Versions found [{authorization.k8s.io/v1 v1}]
May  2 20:17:07.008: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
May  2 20:17:07.008: INFO: Checking APIGroup: autoscaling
May  2 20:17:07.010: INFO: PreferredVersion.GroupVersion: autoscaling/v1
May  2 20:17:07.010: INFO: Versions found [{autoscaling/v1 v1} {autoscaling/v2beta1 v2beta1} {autoscaling/v2beta2 v2beta2}]
May  2 20:17:07.010: INFO: autoscaling/v1 matches autoscaling/v1
May  2 20:17:07.010: INFO: Checking APIGroup: batch
May  2 20:17:07.011: INFO: PreferredVersion.GroupVersion: batch/v1
May  2 20:17:07.011: INFO: Versions found [{batch/v1 v1} {batch/v1beta1 v1beta1}]
May  2 20:17:07.011: INFO: batch/v1 matches batch/v1
May  2 20:17:07.011: INFO: Checking APIGroup: certificates.k8s.io
May  2 20:17:07.012: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
May  2 20:17:07.012: INFO: Versions found [{certificates.k8s.io/v1 v1}]
May  2 20:17:07.012: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
May  2 20:17:07.012: INFO: Checking APIGroup: networking.k8s.io
May  2 20:17:07.013: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
May  2 20:17:07.013: INFO: Versions found [{networking.k8s.io/v1 v1}]
May  2 20:17:07.013: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
May  2 20:17:07.013: INFO: Checking APIGroup: policy
May  2 20:17:07.014: INFO: PreferredVersion.GroupVersion: policy/v1
May  2 20:17:07.014: INFO: Versions found [{policy/v1 v1} {policy/v1beta1 v1beta1}]
May  2 20:17:07.014: INFO: policy/v1 matches policy/v1
May  2 20:17:07.014: INFO: Checking APIGroup: rbac.authorization.k8s.io
May  2 20:17:07.018: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
May  2 20:17:07.018: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
May  2 20:17:07.018: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
May  2 20:17:07.018: INFO: Checking APIGroup: storage.k8s.io
May  2 20:17:07.019: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
May  2 20:17:07.019: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
May  2 20:17:07.019: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
May  2 20:17:07.019: INFO: Checking APIGroup: admissionregistration.k8s.io
May  2 20:17:07.021: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
May  2 20:17:07.021: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
May  2 20:17:07.021: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
May  2 20:17:07.021: INFO: Checking APIGroup: apiextensions.k8s.io
May  2 20:17:07.024: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
May  2 20:17:07.024: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
May  2 20:17:07.024: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
May  2 20:17:07.024: INFO: Checking APIGroup: scheduling.k8s.io
May  2 20:17:07.026: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
May  2 20:17:07.026: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
May  2 20:17:07.026: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
May  2 20:17:07.026: INFO: Checking APIGroup: coordination.k8s.io
May  2 20:17:07.028: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
May  2 20:17:07.028: INFO: Versions found [{coordination.k8s.io/v1 v1}]
May  2 20:17:07.028: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
May  2 20:17:07.028: INFO: Checking APIGroup: node.k8s.io
May  2 20:17:07.030: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
May  2 20:17:07.030: INFO: Versions found [{node.k8s.io/v1 v1} {node.k8s.io/v1beta1 v1beta1}]
May  2 20:17:07.030: INFO: node.k8s.io/v1 matches node.k8s.io/v1
May  2 20:17:07.030: INFO: Checking APIGroup: discovery.k8s.io
May  2 20:17:07.031: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
May  2 20:17:07.031: INFO: Versions found [{discovery.k8s.io/v1 v1} {discovery.k8s.io/v1beta1 v1beta1}]
May  2 20:17:07.031: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
May  2 20:17:07.031: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
May  2 20:17:07.034: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta1
May  2 20:17:07.034: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
May  2 20:17:07.034: INFO: flowcontrol.apiserver.k8s.io/v1beta1 matches flowcontrol.apiserver.k8s.io/v1beta1
May  2 20:17:07.034: INFO: Checking APIGroup: crd.projectcalico.org
May  2 20:17:07.035: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
May  2 20:17:07.035: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
May  2 20:17:07.035: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
May  2 20:17:07.035: INFO: Checking APIGroup: cstor.openebs.io
May  2 20:17:07.038: INFO: PreferredVersion.GroupVersion: cstor.openebs.io/v1
May  2 20:17:07.038: INFO: Versions found [{cstor.openebs.io/v1 v1}]
May  2 20:17:07.038: INFO: cstor.openebs.io/v1 matches cstor.openebs.io/v1
May  2 20:17:07.038: INFO: Checking APIGroup: snapshot.storage.k8s.io
May  2 20:17:07.040: INFO: PreferredVersion.GroupVersion: snapshot.storage.k8s.io/v1
May  2 20:17:07.040: INFO: Versions found [{snapshot.storage.k8s.io/v1 v1} {snapshot.storage.k8s.io/v1beta1 v1beta1}]
May  2 20:17:07.040: INFO: snapshot.storage.k8s.io/v1 matches snapshot.storage.k8s.io/v1
May  2 20:17:07.040: INFO: Checking APIGroup: zfs.openebs.io
May  2 20:17:07.042: INFO: PreferredVersion.GroupVersion: zfs.openebs.io/v1
May  2 20:17:07.042: INFO: Versions found [{zfs.openebs.io/v1 v1} {zfs.openebs.io/v1alpha1 v1alpha1}]
May  2 20:17:07.042: INFO: zfs.openebs.io/v1 matches zfs.openebs.io/v1
May  2 20:17:07.042: INFO: Checking APIGroup: local.openebs.io
May  2 20:17:07.044: INFO: PreferredVersion.GroupVersion: local.openebs.io/v1alpha1
May  2 20:17:07.044: INFO: Versions found [{local.openebs.io/v1alpha1 v1alpha1}]
May  2 20:17:07.044: INFO: local.openebs.io/v1alpha1 matches local.openebs.io/v1alpha1
May  2 20:17:07.044: INFO: Checking APIGroup: openebs.io
May  2 20:17:07.046: INFO: PreferredVersion.GroupVersion: openebs.io/v1alpha1
May  2 20:17:07.046: INFO: Versions found [{openebs.io/v1alpha1 v1alpha1}]
May  2 20:17:07.046: INFO: openebs.io/v1alpha1 matches openebs.io/v1alpha1
May  2 20:17:07.046: INFO: Checking APIGroup: longhorn.io
May  2 20:17:07.047: INFO: PreferredVersion.GroupVersion: longhorn.io/v1beta1
May  2 20:17:07.047: INFO: Versions found [{longhorn.io/v1beta1 v1beta1}]
May  2 20:17:07.047: INFO: longhorn.io/v1beta1 matches longhorn.io/v1beta1
May  2 20:17:07.047: INFO: Checking APIGroup: metrics.k8s.io
May  2 20:17:07.048: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
May  2 20:17:07.048: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
May  2 20:17:07.048: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
[AfterEach] [sig-api-machinery] Discovery
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:17:07.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-8157" for this suite.

•
------------------------------
{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","total":-1,"completed":74,"skipped":1340,"failed":0}

SSSSSSSSSS
------------------------------
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:16:23.715: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:92
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:107
STEP: Creating service test in namespace statefulset-6538
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-6538
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6538
May  2 20:16:23.865: INFO: Found 0 stateful pods, waiting for 1
May  2 20:16:33.875: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
May  2 20:16:33.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=statefulset-6538 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  2 20:16:34.367: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  2 20:16:34.367: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  2 20:16:34.367: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  2 20:16:34.386: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May  2 20:16:44.408: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May  2 20:16:44.408: INFO: Waiting for statefulset status.replicas updated to 0
May  2 20:16:44.500: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999948s
May  2 20:16:45.517: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.976114898s
May  2 20:16:46.528: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.963081523s
May  2 20:16:47.539: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.952102612s
May  2 20:16:48.550: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.940416021s
May  2 20:16:49.563: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.929727283s
May  2 20:16:50.584: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.917218165s
May  2 20:16:51.605: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.895810006s
May  2 20:16:52.619: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.870936488s
May  2 20:16:53.632: INFO: Verifying statefulset ss doesn't scale past 1 for another 861.10015ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6538
May  2 20:16:54.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=statefulset-6538 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  2 20:16:54.949: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May  2 20:16:54.949: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  2 20:16:54.949: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May  2 20:16:54.960: INFO: Found 1 stateful pods, waiting for 3
May  2 20:17:04.971: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May  2 20:17:04.972: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May  2 20:17:04.972: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
May  2 20:17:04.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=statefulset-6538 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  2 20:17:05.323: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  2 20:17:05.323: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  2 20:17:05.323: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  2 20:17:05.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=statefulset-6538 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  2 20:17:05.666: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  2 20:17:05.666: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  2 20:17:05.666: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  2 20:17:05.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=statefulset-6538 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  2 20:17:06.230: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  2 20:17:06.230: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  2 20:17:06.230: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  2 20:17:06.230: INFO: Waiting for statefulset status.replicas updated to 0
May  2 20:17:06.238: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
May  2 20:17:16.263: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May  2 20:17:16.263: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May  2 20:17:16.263: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May  2 20:17:16.294: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999499s
May  2 20:17:17.306: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.990076629s
May  2 20:17:18.320: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.978131163s
May  2 20:17:19.332: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.964449379s
May  2 20:17:20.350: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.952385674s
May  2 20:17:21.376: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.934074627s
May  2 20:17:22.391: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.908330744s
May  2 20:17:23.419: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.8933806s
May  2 20:17:24.432: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.865152058s
May  2 20:17:25.444: INFO: Verifying statefulset ss doesn't scale past 3 for another 852.778465ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6538
May  2 20:17:26.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=statefulset-6538 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  2 20:17:26.789: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May  2 20:17:26.789: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  2 20:17:26.789: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May  2 20:17:26.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=statefulset-6538 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  2 20:17:27.171: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May  2 20:17:27.171: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  2 20:17:27.171: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May  2 20:17:27.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=statefulset-6538 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  2 20:17:27.431: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May  2 20:17:27.431: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  2 20:17:27.431: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May  2 20:17:27.431: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:118
May  2 20:17:37.479: INFO: Deleting all statefulset in ns statefulset-6538
May  2 20:17:37.489: INFO: Scaling statefulset ss to 0
May  2 20:17:37.516: INFO: Waiting for statefulset status.replicas updated to 0
May  2 20:17:37.528: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:17:37.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6538" for this suite.


• [SLOW TEST:73.911 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:97
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":-1,"completed":91,"skipped":1573,"failed":0}

SSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:17:07.089: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/endpointslice.go:49
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: referencing a single matching pod
STEP: referencing matching pods with named port
STEP: creating empty Endpoints and EndpointSlices for no matching Pods
STEP: recreating EndpointSlices after they've been deleted
May  2 20:17:27.660: INFO: EndpointSlice for Service endpointslice-7684/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:17:37.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-7684" for this suite.


• [SLOW TEST:30.656 seconds]
[sig-network] EndpointSlice
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","total":-1,"completed":75,"skipped":1350,"failed":0}

SSSS
------------------------------
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:17:37.755: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service in namespace services-6606
STEP: creating service affinity-nodeport-transition in namespace services-6606
STEP: creating replication controller affinity-nodeport-transition in namespace services-6606
I0502 20:17:37.948329      19 runners.go:190] Created replication controller with name: affinity-nodeport-transition, namespace: services-6606, replica count: 3
I0502 20:17:41.002288      19 runners.go:190] affinity-nodeport-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0502 20:17:44.009923      19 runners.go:190] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  2 20:17:44.108: INFO: Creating new exec pod
May  2 20:17:49.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-6606 exec execpod-affinity8vhbd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
May  2 20:17:49.671: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
May  2 20:17:49.671: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 20:17:49.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-6606 exec execpod-affinity8vhbd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.34.24 80'
May  2 20:17:50.074: INFO: stderr: "+ nc -v -t -w 2 10.233.34.24 80\n+ echo hostName\nConnection to 10.233.34.24 80 port [tcp/http] succeeded!\n"
May  2 20:17:50.074: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 20:17:50.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-6606 exec execpod-affinity8vhbd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.18.197 31474'
May  2 20:17:50.432: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.100.18.197 31474\nConnection to 10.100.18.197 31474 port [tcp/*] succeeded!\n"
May  2 20:17:50.433: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 20:17:50.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-6606 exec execpod-affinity8vhbd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.20.46 31474'
May  2 20:17:50.795: INFO: stderr: "+ nc -v -t -w 2 10.100.20.46 31474\n+ echo hostName\nConnection to 10.100.20.46 31474 port [tcp/*] succeeded!\n"
May  2 20:17:50.795: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 20:17:50.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-6606 exec execpod-affinity8vhbd -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.100.18.197:31474/ ; done'
May  2 20:17:51.563: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n"
May  2 20:17:51.563: INFO: stdout: "\naffinity-nodeport-transition-f25ps\naffinity-nodeport-transition-2sfsx\naffinity-nodeport-transition-frlpr\naffinity-nodeport-transition-f25ps\naffinity-nodeport-transition-2sfsx\naffinity-nodeport-transition-frlpr\naffinity-nodeport-transition-f25ps\naffinity-nodeport-transition-2sfsx\naffinity-nodeport-transition-frlpr\naffinity-nodeport-transition-f25ps\naffinity-nodeport-transition-2sfsx\naffinity-nodeport-transition-frlpr\naffinity-nodeport-transition-f25ps\naffinity-nodeport-transition-2sfsx\naffinity-nodeport-transition-frlpr\naffinity-nodeport-transition-f25ps"
May  2 20:17:51.564: INFO: Received response from host: affinity-nodeport-transition-f25ps
May  2 20:17:51.564: INFO: Received response from host: affinity-nodeport-transition-2sfsx
May  2 20:17:51.564: INFO: Received response from host: affinity-nodeport-transition-frlpr
May  2 20:17:51.564: INFO: Received response from host: affinity-nodeport-transition-f25ps
May  2 20:17:51.564: INFO: Received response from host: affinity-nodeport-transition-2sfsx
May  2 20:17:51.564: INFO: Received response from host: affinity-nodeport-transition-frlpr
May  2 20:17:51.564: INFO: Received response from host: affinity-nodeport-transition-f25ps
May  2 20:17:51.564: INFO: Received response from host: affinity-nodeport-transition-2sfsx
May  2 20:17:51.564: INFO: Received response from host: affinity-nodeport-transition-frlpr
May  2 20:17:51.564: INFO: Received response from host: affinity-nodeport-transition-f25ps
May  2 20:17:51.564: INFO: Received response from host: affinity-nodeport-transition-2sfsx
May  2 20:17:51.564: INFO: Received response from host: affinity-nodeport-transition-frlpr
May  2 20:17:51.564: INFO: Received response from host: affinity-nodeport-transition-f25ps
May  2 20:17:51.564: INFO: Received response from host: affinity-nodeport-transition-2sfsx
May  2 20:17:51.564: INFO: Received response from host: affinity-nodeport-transition-frlpr
May  2 20:17:51.564: INFO: Received response from host: affinity-nodeport-transition-f25ps
May  2 20:17:51.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-6606 exec execpod-affinity8vhbd -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.100.18.197:31474/ ; done'
May  2 20:17:52.321: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31474/\n"
May  2 20:17:52.321: INFO: stdout: "\naffinity-nodeport-transition-frlpr\naffinity-nodeport-transition-frlpr\naffinity-nodeport-transition-frlpr\naffinity-nodeport-transition-frlpr\naffinity-nodeport-transition-frlpr\naffinity-nodeport-transition-frlpr\naffinity-nodeport-transition-frlpr\naffinity-nodeport-transition-frlpr\naffinity-nodeport-transition-frlpr\naffinity-nodeport-transition-frlpr\naffinity-nodeport-transition-frlpr\naffinity-nodeport-transition-frlpr\naffinity-nodeport-transition-frlpr\naffinity-nodeport-transition-frlpr\naffinity-nodeport-transition-frlpr\naffinity-nodeport-transition-frlpr"
May  2 20:17:52.321: INFO: Received response from host: affinity-nodeport-transition-frlpr
May  2 20:17:52.321: INFO: Received response from host: affinity-nodeport-transition-frlpr
May  2 20:17:52.321: INFO: Received response from host: affinity-nodeport-transition-frlpr
May  2 20:17:52.321: INFO: Received response from host: affinity-nodeport-transition-frlpr
May  2 20:17:52.321: INFO: Received response from host: affinity-nodeport-transition-frlpr
May  2 20:17:52.321: INFO: Received response from host: affinity-nodeport-transition-frlpr
May  2 20:17:52.321: INFO: Received response from host: affinity-nodeport-transition-frlpr
May  2 20:17:52.321: INFO: Received response from host: affinity-nodeport-transition-frlpr
May  2 20:17:52.321: INFO: Received response from host: affinity-nodeport-transition-frlpr
May  2 20:17:52.321: INFO: Received response from host: affinity-nodeport-transition-frlpr
May  2 20:17:52.321: INFO: Received response from host: affinity-nodeport-transition-frlpr
May  2 20:17:52.321: INFO: Received response from host: affinity-nodeport-transition-frlpr
May  2 20:17:52.321: INFO: Received response from host: affinity-nodeport-transition-frlpr
May  2 20:17:52.321: INFO: Received response from host: affinity-nodeport-transition-frlpr
May  2 20:17:52.321: INFO: Received response from host: affinity-nodeport-transition-frlpr
May  2 20:17:52.321: INFO: Received response from host: affinity-nodeport-transition-frlpr
May  2 20:17:52.321: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-6606, will wait for the garbage collector to delete the pods
May  2 20:17:52.555: INFO: Deleting ReplicationController affinity-nodeport-transition took: 62.171436ms
May  2 20:17:52.678: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 123.2545ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:17:56.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6606" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753


• [SLOW TEST:18.332 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","total":-1,"completed":76,"skipped":1354,"failed":0}

SSSSS
------------------------------
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:17:37.679: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  2 20:17:38.649: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May  2 20:17:40.722: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119458, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119458, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119458, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119458, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  2 20:17:42.748: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119458, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119458, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119458, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119458, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  2 20:17:45.829: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:17:56.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1386" for this suite.
STEP: Destroying namespace "webhook-1386-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102


• [SLOW TEST:18.991 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":-1,"completed":92,"skipped":1586,"failed":0}

SSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:17:56.901: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:17:57.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-4" for this suite.

•
------------------------------
{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":-1,"completed":93,"skipped":1606,"failed":0}

SSS
------------------------------
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:17:57.107: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  2 20:17:58.624: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May  2 20:18:00.653: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119478, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119478, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119478, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119478, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  2 20:18:03.696: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
May  2 20:18:07.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=webhook-8130 attach --namespace=webhook-8130 to-be-attached-pod -i -c=container1'
May  2 20:18:08.030: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:18:08.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8130" for this suite.
STEP: Destroying namespace "webhook-8130-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102


• [SLOW TEST:11.096 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":-1,"completed":94,"skipped":1609,"failed":0}

SSSSSSS
------------------------------
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:18:08.341: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Given a Pod with a 'name' label pod-adoption-release is created
May  2 20:18:08.593: INFO: The status of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
May  2 20:18:10.608: INFO: The status of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
May  2 20:18:12.609: INFO: The status of Pod pod-adoption-release is Running (Ready = true)
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
May  2 20:18:13.750: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:18:14.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9818" for this suite.


• [SLOW TEST:6.514 seconds]
[sig-apps] ReplicaSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":-1,"completed":95,"skipped":1616,"failed":0}

SSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:18:14.899: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-map-36d9f24e-bc38-4a82-89fb-20fea1764ab6
STEP: Creating a pod to test consume configMaps
May  2 20:18:15.167: INFO: Waiting up to 5m0s for pod "pod-configmaps-b4c656de-cf33-4498-be33-820ca101e402" in namespace "configmap-4786" to be "Succeeded or Failed"
May  2 20:18:15.186: INFO: Pod "pod-configmaps-b4c656de-cf33-4498-be33-820ca101e402": Phase="Pending", Reason="", readiness=false. Elapsed: 18.13309ms
May  2 20:18:17.203: INFO: Pod "pod-configmaps-b4c656de-cf33-4498-be33-820ca101e402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034821003s
May  2 20:18:19.217: INFO: Pod "pod-configmaps-b4c656de-cf33-4498-be33-820ca101e402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049416851s
STEP: Saw pod success
May  2 20:18:19.217: INFO: Pod "pod-configmaps-b4c656de-cf33-4498-be33-820ca101e402" satisfied condition "Succeeded or Failed"
May  2 20:18:19.234: INFO: Trying to get logs from node node-2 pod pod-configmaps-b4c656de-cf33-4498-be33-820ca101e402 container agnhost-container: <nil>
STEP: delete the pod
May  2 20:18:19.329: INFO: Waiting for pod pod-configmaps-b4c656de-cf33-4498-be33-820ca101e402 to disappear
May  2 20:18:19.338: INFO: Pod pod-configmaps-b4c656de-cf33-4498-be33-820ca101e402 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:18:19.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4786" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":96,"skipped":1634,"failed":0}

SSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Projected combined
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:18:19.391: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-projected-all-test-volume-0c39e831-88f7-49d2-a995-463d0fd80979
STEP: Creating secret with name secret-projected-all-test-volume-50a4c186-c329-4f84-8ad7-494619c91e12
STEP: Creating a pod to test Check all projections for projected volume plugin
May  2 20:18:19.589: INFO: Waiting up to 5m0s for pod "projected-volume-0fcec6a9-cc41-4e73-9c0c-c0afb66987ac" in namespace "projected-7620" to be "Succeeded or Failed"
May  2 20:18:19.633: INFO: Pod "projected-volume-0fcec6a9-cc41-4e73-9c0c-c0afb66987ac": Phase="Pending", Reason="", readiness=false. Elapsed: 44.245022ms
May  2 20:18:21.647: INFO: Pod "projected-volume-0fcec6a9-cc41-4e73-9c0c-c0afb66987ac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.058682343s
May  2 20:18:23.663: INFO: Pod "projected-volume-0fcec6a9-cc41-4e73-9c0c-c0afb66987ac": Phase="Pending", Reason="", readiness=false. Elapsed: 4.074218176s
May  2 20:18:25.677: INFO: Pod "projected-volume-0fcec6a9-cc41-4e73-9c0c-c0afb66987ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.088280768s
STEP: Saw pod success
May  2 20:18:25.677: INFO: Pod "projected-volume-0fcec6a9-cc41-4e73-9c0c-c0afb66987ac" satisfied condition "Succeeded or Failed"
May  2 20:18:25.689: INFO: Trying to get logs from node node-2 pod projected-volume-0fcec6a9-cc41-4e73-9c0c-c0afb66987ac container projected-all-volume-test: <nil>
STEP: delete the pod
May  2 20:18:25.766: INFO: Waiting for pod projected-volume-0fcec6a9-cc41-4e73-9c0c-c0afb66987ac to disappear
May  2 20:18:25.772: INFO: Pod projected-volume-0fcec6a9-cc41-4e73-9c0c-c0afb66987ac no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:18:25.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7620" for this suite.


• [SLOW TEST:6.425 seconds]
[sig-storage] Projected combined
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":-1,"completed":97,"skipped":1643,"failed":0}

SSS
------------------------------
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:18:25.825: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test substitution in container's args
May  2 20:18:25.989: INFO: Waiting up to 5m0s for pod "var-expansion-79550be5-5c91-413e-a0d0-ce6b1a9a9cad" in namespace "var-expansion-472" to be "Succeeded or Failed"
May  2 20:18:26.010: INFO: Pod "var-expansion-79550be5-5c91-413e-a0d0-ce6b1a9a9cad": Phase="Pending", Reason="", readiness=false. Elapsed: 20.94582ms
May  2 20:18:28.025: INFO: Pod "var-expansion-79550be5-5c91-413e-a0d0-ce6b1a9a9cad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035999884s
May  2 20:18:30.038: INFO: Pod "var-expansion-79550be5-5c91-413e-a0d0-ce6b1a9a9cad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048949389s
STEP: Saw pod success
May  2 20:18:30.038: INFO: Pod "var-expansion-79550be5-5c91-413e-a0d0-ce6b1a9a9cad" satisfied condition "Succeeded or Failed"
May  2 20:18:30.056: INFO: Trying to get logs from node node-2 pod var-expansion-79550be5-5c91-413e-a0d0-ce6b1a9a9cad container dapi-container: <nil>
STEP: delete the pod
May  2 20:18:30.140: INFO: Waiting for pod var-expansion-79550be5-5c91-413e-a0d0-ce6b1a9a9cad to disappear
May  2 20:18:30.152: INFO: Pod var-expansion-79550be5-5c91-413e-a0d0-ce6b1a9a9cad no longer exists
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:18:30.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-472" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":-1,"completed":98,"skipped":1646,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:18:30.247: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename security-context
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser
May  2 20:18:30.412: INFO: Waiting up to 5m0s for pod "security-context-301654be-f081-4658-98bf-fa36b8a1e5fb" in namespace "security-context-1426" to be "Succeeded or Failed"
May  2 20:18:30.421: INFO: Pod "security-context-301654be-f081-4658-98bf-fa36b8a1e5fb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.653174ms
May  2 20:18:32.578: INFO: Pod "security-context-301654be-f081-4658-98bf-fa36b8a1e5fb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.166041654s
May  2 20:18:34.595: INFO: Pod "security-context-301654be-f081-4658-98bf-fa36b8a1e5fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.183030279s
STEP: Saw pod success
May  2 20:18:34.595: INFO: Pod "security-context-301654be-f081-4658-98bf-fa36b8a1e5fb" satisfied condition "Succeeded or Failed"
May  2 20:18:34.602: INFO: Trying to get logs from node node-2 pod security-context-301654be-f081-4658-98bf-fa36b8a1e5fb container test-container: <nil>
STEP: delete the pod
May  2 20:18:34.649: INFO: Waiting for pod security-context-301654be-f081-4658-98bf-fa36b8a1e5fb to disappear
May  2 20:18:34.657: INFO: Pod security-context-301654be-f081-4658-98bf-fa36b8a1e5fb no longer exists
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:18:34.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-1426" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","total":-1,"completed":99,"skipped":1675,"failed":0}

SSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:18:34.704: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:18:35.041: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"d2ee4ebc-81f4-4e4b-8c25-c2bd551e7b04", Controller:(*bool)(0xc00467a47a), BlockOwnerDeletion:(*bool)(0xc00467a47b)}}
May  2 20:18:35.097: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"b6aae51a-0de7-4281-972e-3a1d1f63ca1f", Controller:(*bool)(0xc0045256e2), BlockOwnerDeletion:(*bool)(0xc0045256e3)}}
May  2 20:18:35.124: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"a4fa796f-bed3-4409-99a0-245737470ba9", Controller:(*bool)(0xc00467a6f2), BlockOwnerDeletion:(*bool)(0xc00467a6f3)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:18:40.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3255" for this suite.


• [SLOW TEST:5.510 seconds]
[sig-api-machinery] Garbage collector
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":-1,"completed":100,"skipped":1683,"failed":0}

SS
------------------------------
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:18:40.226: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:54
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod liveness-81feaa10-47fa-4b5e-bdc3-d10069fa9d24 in namespace container-probe-695
May  2 20:18:44.433: INFO: Started pod liveness-81feaa10-47fa-4b5e-bdc3-d10069fa9d24 in namespace container-probe-695
STEP: checking the pod's current state and verifying that restartCount is present
May  2 20:18:44.445: INFO: Initial restart count of pod liveness-81feaa10-47fa-4b5e-bdc3-d10069fa9d24 is 0
May  2 20:19:02.617: INFO: Restart count of pod container-probe-695/liveness-81feaa10-47fa-4b5e-bdc3-d10069fa9d24 is now 1 (18.17176048s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:19:02.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-695" for this suite.


• [SLOW TEST:22.484 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":-1,"completed":101,"skipped":1685,"failed":0}

SS
------------------------------
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:19:02.750: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
May  2 20:19:03.650: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
May  2 20:19:05.706: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119543, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119543, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119543, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119543, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-697cdbd8f4\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  2 20:19:08.782: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:19:08.790: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:19:17.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-5231" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137


• [SLOW TEST:14.694 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":-1,"completed":102,"skipped":1687,"failed":0}

SSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:19:17.850: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-653c6c4a-a3cb-4340-a669-67a4353f7410
STEP: Creating a pod to test consume secrets
May  2 20:19:18.084: INFO: Waiting up to 5m0s for pod "pod-secrets-1deb45b4-15a9-4476-9741-e712fba21443" in namespace "secrets-9150" to be "Succeeded or Failed"
May  2 20:19:18.094: INFO: Pod "pod-secrets-1deb45b4-15a9-4476-9741-e712fba21443": Phase="Pending", Reason="", readiness=false. Elapsed: 10.345271ms
May  2 20:19:20.159: INFO: Pod "pod-secrets-1deb45b4-15a9-4476-9741-e712fba21443": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075301888s
May  2 20:19:22.179: INFO: Pod "pod-secrets-1deb45b4-15a9-4476-9741-e712fba21443": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.09521439s
STEP: Saw pod success
May  2 20:19:22.179: INFO: Pod "pod-secrets-1deb45b4-15a9-4476-9741-e712fba21443" satisfied condition "Succeeded or Failed"
May  2 20:19:22.186: INFO: Trying to get logs from node node-2 pod pod-secrets-1deb45b4-15a9-4476-9741-e712fba21443 container secret-volume-test: <nil>
STEP: delete the pod
May  2 20:19:22.248: INFO: Waiting for pod pod-secrets-1deb45b4-15a9-4476-9741-e712fba21443 to disappear
May  2 20:19:22.254: INFO: Pod pod-secrets-1deb45b4-15a9-4476-9741-e712fba21443 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:19:22.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9150" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":-1,"completed":103,"skipped":1697,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:19:22.355: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] Deployment should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:19:22.457: INFO: Creating simple deployment test-new-deployment
May  2 20:19:22.531: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119562, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119562, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"test-new-deployment-847dcfb7fb\""}}, CollisionCount:(*int32)(nil)}
May  2 20:19:24.545: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119562, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119562, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119562, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787119562, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-new-deployment-847dcfb7fb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the deployment Spec.Replicas was modified
STEP: Patch a scale subresource
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
May  2 20:19:26.653: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-1998  e6a16bc5-8306-45cf-97f3-ae9d78a8c680 2878049 3 2022-05-02 20:19:22 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-05-02 20:19:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-02 20:19:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc000d63968 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-05-02 20:19:24 +0000 UTC,LastTransitionTime:2022-05-02 20:19:24 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-847dcfb7fb" has successfully progressed.,LastUpdateTime:2022-05-02 20:19:24 +0000 UTC,LastTransitionTime:2022-05-02 20:19:22 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

May  2 20:19:26.726: INFO: New ReplicaSet "test-new-deployment-847dcfb7fb" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-847dcfb7fb  deployment-1998  f42fab74-5ccf-48a3-8d9a-cbae2b224277 2878058 2 2022-05-02 20:19:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment e6a16bc5-8306-45cf-97f3-ae9d78a8c680 0xc000d63d77 0xc000d63d78}] []  [{kube-controller-manager Update apps/v1 2022-05-02 20:19:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e6a16bc5-8306-45cf-97f3-ae9d78a8c680\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-02 20:19:24 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 847dcfb7fb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc000d63e08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
May  2 20:19:26.734: INFO: Pod "test-new-deployment-847dcfb7fb-f6hsr" is not available:
&Pod{ObjectMeta:{test-new-deployment-847dcfb7fb-f6hsr test-new-deployment-847dcfb7fb- deployment-1998  be04dd81-ab7b-4ade-9182-adbeac076d1a 2878059 0 2022-05-02 20:19:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[] [{apps/v1 ReplicaSet test-new-deployment-847dcfb7fb f42fab74-5ccf-48a3-8d9a-cbae2b224277 0xc00379c587 0xc00379c588}] []  [{kube-controller-manager Update v1 2022-05-02 20:19:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f42fab74-5ccf-48a3-8d9a-cbae2b224277\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-02 20:19:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mgpxd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mgpxd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:19:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:19:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:19:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:19:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.20.186,PodIP:,StartTime:2022-05-02 20:19:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:19:26.735: INFO: Pod "test-new-deployment-847dcfb7fb-h22jm" is available:
&Pod{ObjectMeta:{test-new-deployment-847dcfb7fb-h22jm test-new-deployment-847dcfb7fb- deployment-1998  f0770b18-09f3-4a1c-bf4f-00858efa2d36 2878033 0 2022-05-02 20:19:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/containerID:79a0b6fa61cc0fe58f5c6f79d12e2ad04ac442b7920d4640d1b8b5d1f136ce40 cni.projectcalico.org/podIP:10.233.69.111/32 cni.projectcalico.org/podIPs:10.233.69.111/32] [{apps/v1 ReplicaSet test-new-deployment-847dcfb7fb f42fab74-5ccf-48a3-8d9a-cbae2b224277 0xc00379c777 0xc00379c778}] []  [{kube-controller-manager Update v1 2022-05-02 20:19:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f42fab74-5ccf-48a3-8d9a-cbae2b224277\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-05-02 20:19:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-05-02 20:19:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.69.111\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sgmwb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sgmwb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:19:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:19:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:19:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:19:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.20.46,PodIP:10.233.69.111,StartTime:2022-05-02 20:19:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-02 20:19:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:docker://f4398a4eac74298d462f08db07aaa61b7fa3b03c9db7696d85fa90f5df4f7d81,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.69.111,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:19:26.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1998" for this suite.

•
------------------------------
{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","total":-1,"completed":104,"skipped":1729,"failed":0}

SSSSS
------------------------------
[BeforeEach] [sig-node] PodTemplates
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:19:26.790: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a collection of pod templates [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create set of pod templates
May  2 20:19:26.902: INFO: created test-podtemplate-1
May  2 20:19:26.913: INFO: created test-podtemplate-2
May  2 20:19:26.926: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace
STEP: delete collection of pod templates
May  2 20:19:26.933: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity
May  2 20:19:26.979: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:19:26.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-6992" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","total":-1,"completed":105,"skipped":1734,"failed":0}

SSSSSSS
------------------------------
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:19:27.044: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:69
[It] should create a PodDisruptionBudget [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pdb
STEP: Waiting for the pdb to be processed
STEP: updating the pdb
STEP: Waiting for the pdb to be processed
STEP: patching the pdb
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be deleted
[AfterEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:19:33.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2328" for this suite.


• [SLOW TEST:6.458 seconds]
[sig-apps] DisruptionController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","total":-1,"completed":106,"skipped":1741,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] RuntimeClass
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:19:33.591: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
[It]  should support RuntimeClasses API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting /apis
STEP: getting /apis/node.k8s.io
STEP: getting /apis/node.k8s.io/v1
STEP: creating
STEP: watching
May  2 20:19:33.851: INFO: starting watch
STEP: getting
STEP: listing
STEP: patching
STEP: updating
May  2 20:19:33.947: INFO: waiting for watch events with expected annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-node] RuntimeClass
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:19:34.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-1110" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","total":-1,"completed":107,"skipped":1767,"failed":0}

SSSSSSSSSSS
------------------------------
[BeforeEach] [sig-instrumentation] Events
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:19:34.153: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a test event
STEP: listing all events in all namespaces
STEP: patching the test event
STEP: fetching the test event
STEP: deleting the test event
STEP: listing all events in all namespaces
[AfterEach] [sig-instrumentation] Events
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:19:34.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8101" for this suite.

•
------------------------------
{"msg":"PASSED [sig-instrumentation] Events should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","total":-1,"completed":108,"skipped":1778,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:19:34.498: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
May  2 20:19:34.615: INFO: The status of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
May  2 20:19:36.946: INFO: The status of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
May  2 20:19:38.627: INFO: The status of Pod test-pod is Running (Ready = true)
STEP: Creating hostNetwork=true pod
May  2 20:19:38.672: INFO: The status of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
May  2 20:19:40.696: INFO: The status of Pod test-host-network-pod is Running (Ready = true)
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
May  2 20:19:40.708: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3613 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 20:19:40.708: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
May  2 20:19:40.939: INFO: Exec stderr: ""
May  2 20:19:40.939: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3613 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 20:19:40.939: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
May  2 20:19:41.154: INFO: Exec stderr: ""
May  2 20:19:41.154: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3613 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 20:19:41.154: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
May  2 20:19:41.329: INFO: Exec stderr: ""
May  2 20:19:41.329: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3613 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 20:19:41.329: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
May  2 20:19:41.518: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
May  2 20:19:41.518: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3613 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 20:19:41.518: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
May  2 20:19:41.716: INFO: Exec stderr: ""
May  2 20:19:41.716: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3613 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 20:19:41.716: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
May  2 20:19:42.070: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
May  2 20:19:42.070: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3613 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 20:19:42.070: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
May  2 20:19:42.274: INFO: Exec stderr: ""
May  2 20:19:42.274: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3613 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 20:19:42.274: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
May  2 20:19:42.488: INFO: Exec stderr: ""
May  2 20:19:42.488: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3613 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 20:19:42.488: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
May  2 20:19:42.623: INFO: Exec stderr: ""
May  2 20:19:42.624: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3613 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 20:19:42.624: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
May  2 20:19:42.762: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:19:42.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-3613" for this suite.


• [SLOW TEST:8.295 seconds]
[sig-node] KubeletManagedEtcHosts
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":109,"skipped":1809,"failed":0}

SSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-network] IngressClass API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:19:42.868: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename ingressclass
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] IngressClass API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/ingressclass.go:148
[It]  should support creating IngressClass API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting /apis
STEP: getting /apis/networking.k8s.io
STEP: getting /apis/networking.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
May  2 20:19:43.086: INFO: starting watch
STEP: patching
STEP: updating
May  2 20:19:43.121: INFO: waiting for watch events with expected annotations
May  2 20:19:43.121: INFO: saw patched and updated annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] IngressClass API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:19:43.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-8897" for this suite.

•
------------------------------
{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","total":-1,"completed":110,"skipped":1827,"failed":0}

SSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:19:43.297: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with secret that has name projected-secret-test-map-8a638e27-8eaf-42d9-bf95-97fa522be55f
STEP: Creating a pod to test consume secrets
May  2 20:19:43.483: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-093e30d1-2bc5-40f7-a91e-a27976a93c69" in namespace "projected-9520" to be "Succeeded or Failed"
May  2 20:19:43.512: INFO: Pod "pod-projected-secrets-093e30d1-2bc5-40f7-a91e-a27976a93c69": Phase="Pending", Reason="", readiness=false. Elapsed: 28.592214ms
May  2 20:19:45.530: INFO: Pod "pod-projected-secrets-093e30d1-2bc5-40f7-a91e-a27976a93c69": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046628253s
May  2 20:19:47.546: INFO: Pod "pod-projected-secrets-093e30d1-2bc5-40f7-a91e-a27976a93c69": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.062420104s
STEP: Saw pod success
May  2 20:19:47.546: INFO: Pod "pod-projected-secrets-093e30d1-2bc5-40f7-a91e-a27976a93c69" satisfied condition "Succeeded or Failed"
May  2 20:19:47.559: INFO: Trying to get logs from node node-2 pod pod-projected-secrets-093e30d1-2bc5-40f7-a91e-a27976a93c69 container projected-secret-volume-test: <nil>
STEP: delete the pod
May  2 20:19:47.649: INFO: Waiting for pod pod-projected-secrets-093e30d1-2bc5-40f7-a91e-a27976a93c69 to disappear
May  2 20:19:47.664: INFO: Pod pod-projected-secrets-093e30d1-2bc5-40f7-a91e-a27976a93c69 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:19:47.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9520" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":-1,"completed":111,"skipped":1838,"failed":0}

SS
------------------------------
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:19:47.729: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:82
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:19:48.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9040" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":-1,"completed":112,"skipped":1840,"failed":0}

SSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:17:56.136: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
May  2 20:17:56.374: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
May  2 20:18:26.710: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:20:23.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2552" for this suite.


• [SLOW TEST:147.217 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":-1,"completed":77,"skipped":1359,"failed":0}

S
------------------------------
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:20:23.361: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-2bdff9f3-4a4b-46b4-a81a-069bd178951d
STEP: Creating a pod to test consume secrets
May  2 20:20:23.582: INFO: Waiting up to 5m0s for pod "pod-secrets-c8e66e44-612d-4fb1-97a3-491483600508" in namespace "secrets-3688" to be "Succeeded or Failed"
May  2 20:20:23.602: INFO: Pod "pod-secrets-c8e66e44-612d-4fb1-97a3-491483600508": Phase="Pending", Reason="", readiness=false. Elapsed: 19.57936ms
May  2 20:20:25.621: INFO: Pod "pod-secrets-c8e66e44-612d-4fb1-97a3-491483600508": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038670619s
May  2 20:20:27.641: INFO: Pod "pod-secrets-c8e66e44-612d-4fb1-97a3-491483600508": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059029674s
STEP: Saw pod success
May  2 20:20:27.641: INFO: Pod "pod-secrets-c8e66e44-612d-4fb1-97a3-491483600508" satisfied condition "Succeeded or Failed"
May  2 20:20:27.651: INFO: Trying to get logs from node node-2 pod pod-secrets-c8e66e44-612d-4fb1-97a3-491483600508 container secret-volume-test: <nil>
STEP: delete the pod
May  2 20:20:27.736: INFO: Waiting for pod pod-secrets-c8e66e44-612d-4fb1-97a3-491483600508 to disappear
May  2 20:20:27.746: INFO: Pod pod-secrets-c8e66e44-612d-4fb1-97a3-491483600508 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:20:27.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3688" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":-1,"completed":78,"skipped":1360,"failed":0}
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:20:27.773: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0777 on node default medium
May  2 20:20:27.957: INFO: Waiting up to 5m0s for pod "pod-21d416ee-9422-46ac-866e-54c4748ffeaa" in namespace "emptydir-5686" to be "Succeeded or Failed"
May  2 20:20:27.971: INFO: Pod "pod-21d416ee-9422-46ac-866e-54c4748ffeaa": Phase="Pending", Reason="", readiness=false. Elapsed: 13.543722ms
May  2 20:20:30.003: INFO: Pod "pod-21d416ee-9422-46ac-866e-54c4748ffeaa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04588828s
May  2 20:20:32.024: INFO: Pod "pod-21d416ee-9422-46ac-866e-54c4748ffeaa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.066589566s
STEP: Saw pod success
May  2 20:20:32.024: INFO: Pod "pod-21d416ee-9422-46ac-866e-54c4748ffeaa" satisfied condition "Succeeded or Failed"
May  2 20:20:32.038: INFO: Trying to get logs from node node-2 pod pod-21d416ee-9422-46ac-866e-54c4748ffeaa container test-container: <nil>
STEP: delete the pod
May  2 20:20:32.108: INFO: Waiting for pod pod-21d416ee-9422-46ac-866e-54c4748ffeaa to disappear
May  2 20:20:32.125: INFO: Pod pod-21d416ee-9422-46ac-866e-54c4748ffeaa no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:20:32.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5686" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":79,"skipped":1360,"failed":0}
[BeforeEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:20:32.153: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
May  2 20:20:35.376: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:20:35.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6389" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":-1,"completed":80,"skipped":1360,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:20:35.619: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] deployment should support proportional scaling [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:20:35.728: INFO: Creating deployment "webserver-deployment"
May  2 20:20:35.737: INFO: Waiting for observed generation 1
May  2 20:20:37.786: INFO: Waiting for all required pods to come up
May  2 20:20:37.797: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
May  2 20:20:41.879: INFO: Waiting for deployment "webserver-deployment" to complete
May  2 20:20:41.905: INFO: Updating deployment "webserver-deployment" with a non-existent image
May  2 20:20:41.939: INFO: Updating deployment webserver-deployment
May  2 20:20:41.939: INFO: Waiting for observed generation 2
May  2 20:20:43.980: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
May  2 20:20:43.998: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
May  2 20:20:44.006: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
May  2 20:20:44.034: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
May  2 20:20:44.034: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
May  2 20:20:44.039: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
May  2 20:20:44.048: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
May  2 20:20:44.048: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
May  2 20:20:44.070: INFO: Updating deployment webserver-deployment
May  2 20:20:44.070: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
May  2 20:20:44.091: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
May  2 20:20:44.101: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
May  2 20:20:44.199: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-8263  7766faf4-5fc5-45fc-bd9c-f6970463244b 2879100 3 2022-05-02 20:20:35 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-05-02 20:20:35 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-02 20:20:42 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004d881c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-795d758f88" is progressing.,LastUpdateTime:2022-05-02 20:20:42 +0000 UTC,LastTransitionTime:2022-05-02 20:20:35 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-05-02 20:20:44 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

May  2 20:20:44.318: INFO: New ReplicaSet "webserver-deployment-795d758f88" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-795d758f88  deployment-8263  fd883384-1933-4b16-b4a4-3e6b9c715883 2879089 3 2022-05-02 20:20:41 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 7766faf4-5fc5-45fc-bd9c-f6970463244b 0xc004d885c7 0xc004d885c8}] []  [{kube-controller-manager Update apps/v1 2022-05-02 20:20:41 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7766faf4-5fc5-45fc-bd9c-f6970463244b\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-02 20:20:42 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 795d758f88,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004d88668 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May  2 20:20:44.318: INFO: All old ReplicaSets of Deployment "webserver-deployment":
May  2 20:20:44.318: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-847dcfb7fb  deployment-8263  e4867203-e095-4573-ac5d-4f02e35477bc 2879086 3 2022-05-02 20:20:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 7766faf4-5fc5-45fc-bd9c-f6970463244b 0xc004d886c7 0xc004d886c8}] []  [{kube-controller-manager Update apps/v1 2022-05-02 20:20:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7766faf4-5fc5-45fc-bd9c-f6970463244b\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-02 20:20:39 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 847dcfb7fb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-1 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004d887a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
May  2 20:20:44.344: INFO: Pod "webserver-deployment-795d758f88-6gb9t" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-6gb9t webserver-deployment-795d758f88- deployment-8263  ce63ac30-9fe7-4694-9ff4-2191a2ded48a 2879131 0 2022-05-02 20:20:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 fd883384-1933-4b16-b4a4-3e6b9c715883 0xc004d88dd7 0xc004d88dd8}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fd883384-1933-4b16-b4a4-3e6b9c715883\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-v85ks,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-v85ks,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.344: INFO: Pod "webserver-deployment-795d758f88-7rjld" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-7rjld webserver-deployment-795d758f88- deployment-8263  c83b9e44-40ed-4140-a64e-1ba59be8cf3d 2879133 0 2022-05-02 20:20:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 fd883384-1933-4b16-b4a4-3e6b9c715883 0xc004d88fd7 0xc004d88fd8}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fd883384-1933-4b16-b4a4-3e6b9c715883\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-975j2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-975j2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.344: INFO: Pod "webserver-deployment-795d758f88-87ptp" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-87ptp webserver-deployment-795d758f88- deployment-8263  376d3976-6fe7-41fe-ab99-50ae5aec8a82 2879137 0 2022-05-02 20:20:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 fd883384-1933-4b16-b4a4-3e6b9c715883 0xc004d891d7 0xc004d891d8}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fd883384-1933-4b16-b4a4-3e6b9c715883\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-02 20:20:44 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2zdb7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2zdb7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.18.197,PodIP:,StartTime:2022-05-02 20:20:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.345: INFO: Pod "webserver-deployment-795d758f88-97tph" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-97tph webserver-deployment-795d758f88- deployment-8263  9f57d87a-df79-4692-8572-2464612ade2d 2879037 0 2022-05-02 20:20:41 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 fd883384-1933-4b16-b4a4-3e6b9c715883 0xc004d89457 0xc004d89458}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:41 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fd883384-1933-4b16-b4a4-3e6b9c715883\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-02 20:20:42 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m7zpx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m7zpx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.20.46,PodIP:,StartTime:2022-05-02 20:20:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.345: INFO: Pod "webserver-deployment-795d758f88-c2hxz" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-c2hxz webserver-deployment-795d758f88- deployment-8263  6ba64519-95ac-47a9-bedb-820316a17e4c 2879068 0 2022-05-02 20:20:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 fd883384-1933-4b16-b4a4-3e6b9c715883 0xc004d89697 0xc004d89698}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fd883384-1933-4b16-b4a4-3e6b9c715883\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-02 20:20:42 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k4k87,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k4k87,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.20.46,PodIP:,StartTime:2022-05-02 20:20:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.346: INFO: Pod "webserver-deployment-795d758f88-lv6nr" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-lv6nr webserver-deployment-795d758f88- deployment-8263  6c820288-fa54-4d1b-a7a6-218563f17e26 2879048 0 2022-05-02 20:20:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 fd883384-1933-4b16-b4a4-3e6b9c715883 0xc004d89977 0xc004d89978}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fd883384-1933-4b16-b4a4-3e6b9c715883\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-02 20:20:42 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8s9np,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8s9np,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.20.186,PodIP:,StartTime:2022-05-02 20:20:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.346: INFO: Pod "webserver-deployment-795d758f88-lztmv" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-lztmv webserver-deployment-795d758f88- deployment-8263  85e5eb2f-3ef9-4f38-88e3-0d7ce7bf665b 2879118 0 2022-05-02 20:20:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 fd883384-1933-4b16-b4a4-3e6b9c715883 0xc004d89c87 0xc004d89c88}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fd883384-1933-4b16-b4a4-3e6b9c715883\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hfjt4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hfjt4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.347: INFO: Pod "webserver-deployment-795d758f88-ncwpc" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-ncwpc webserver-deployment-795d758f88- deployment-8263  f12a1189-31cb-4b1a-a66d-8ca7c4df5730 2879113 0 2022-05-02 20:20:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 fd883384-1933-4b16-b4a4-3e6b9c715883 0xc004d89e97 0xc004d89e98}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fd883384-1933-4b16-b4a4-3e6b9c715883\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jl724,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jl724,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.347: INFO: Pod "webserver-deployment-795d758f88-pkn72" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-pkn72 webserver-deployment-795d758f88- deployment-8263  f5f8088a-d517-4ec2-bd20-168c1ad7f55f 2879049 0 2022-05-02 20:20:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 fd883384-1933-4b16-b4a4-3e6b9c715883 0xc004daa0a7 0xc004daa0a8}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fd883384-1933-4b16-b4a4-3e6b9c715883\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-02 20:20:42 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fplg4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fplg4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.18.197,PodIP:,StartTime:2022-05-02 20:20:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.347: INFO: Pod "webserver-deployment-795d758f88-q2rq5" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-q2rq5 webserver-deployment-795d758f88- deployment-8263  b1bef4d9-8b47-4e35-a033-423c0c635c9c 2879132 0 2022-05-02 20:20:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 fd883384-1933-4b16-b4a4-3e6b9c715883 0xc004daa2e7 0xc004daa2e8}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fd883384-1933-4b16-b4a4-3e6b9c715883\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5zk4r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5zk4r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.347: INFO: Pod "webserver-deployment-795d758f88-s7xlb" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-s7xlb webserver-deployment-795d758f88- deployment-8263  eec8578d-3159-49db-bbb1-08b9d071a071 2879073 0 2022-05-02 20:20:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 fd883384-1933-4b16-b4a4-3e6b9c715883 0xc004daa477 0xc004daa478}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fd883384-1933-4b16-b4a4-3e6b9c715883\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-02 20:20:42 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nw887,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nw887,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.20.186,PodIP:,StartTime:2022-05-02 20:20:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.349: INFO: Pod "webserver-deployment-795d758f88-vrp95" is not available:
&Pod{ObjectMeta:{webserver-deployment-795d758f88-vrp95 webserver-deployment-795d758f88- deployment-8263  eeb43cfe-b58f-4751-9cc0-57ce197f02b9 2879136 0 2022-05-02 20:20:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:795d758f88] map[] [{apps/v1 ReplicaSet webserver-deployment-795d758f88 fd883384-1933-4b16-b4a4-3e6b9c715883 0xc004daa767 0xc004daa768}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fd883384-1933-4b16-b4a4-3e6b9c715883\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5kz9f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5kz9f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.349: INFO: Pod "webserver-deployment-847dcfb7fb-5wdbf" is not available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-5wdbf webserver-deployment-847dcfb7fb- deployment-8263  f2789b74-b882-42c4-87cd-3b244bd1b93d 2879112 0 2022-05-02 20:20:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb e4867203-e095-4573-ac5d-4f02e35477bc 0xc004daa997 0xc004daa998}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e4867203-e095-4573-ac5d-4f02e35477bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-02 20:20:44 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-r95w6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-r95w6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.20.46,PodIP:,StartTime:2022-05-02 20:20:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.349: INFO: Pod "webserver-deployment-847dcfb7fb-8tvjg" is not available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-8tvjg webserver-deployment-847dcfb7fb- deployment-8263  817490f4-012b-4524-9d32-cdfcca0bf236 2879111 0 2022-05-02 20:20:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb e4867203-e095-4573-ac5d-4f02e35477bc 0xc004daacb7 0xc004daacb8}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e4867203-e095-4573-ac5d-4f02e35477bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-64rjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-64rjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.349: INFO: Pod "webserver-deployment-847dcfb7fb-8xtgt" is not available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-8xtgt webserver-deployment-847dcfb7fb- deployment-8263  87909dd4-ea8e-4dd9-be95-e16d95c203f1 2879128 0 2022-05-02 20:20:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb e4867203-e095-4573-ac5d-4f02e35477bc 0xc004daaf07 0xc004daaf08}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e4867203-e095-4573-ac5d-4f02e35477bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4jm96,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4jm96,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.349: INFO: Pod "webserver-deployment-847dcfb7fb-929mg" is available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-929mg webserver-deployment-847dcfb7fb- deployment-8263  348abd7d-7e50-4354-9bf6-d8d6ae07e8e4 2878981 0 2022-05-02 20:20:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/containerID:21ef84258f55625941b750a79a393beb222a4f529a8c1ea923f8745cfa8948b2 cni.projectcalico.org/podIP:10.233.69.104/32 cni.projectcalico.org/podIPs:10.233.69.104/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb e4867203-e095-4573-ac5d-4f02e35477bc 0xc004dab120 0xc004dab121}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e4867203-e095-4573-ac5d-4f02e35477bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-05-02 20:20:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-05-02 20:20:40 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.69.104\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l572l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l572l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.20.46,PodIP:10.233.69.104,StartTime:2022-05-02 20:20:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-02 20:20:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:docker://c575cf85504703447ff530be98142573f033d9528e47c03ca92c563522359f63,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.69.104,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.349: INFO: Pod "webserver-deployment-847dcfb7fb-ccknt" is available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-ccknt webserver-deployment-847dcfb7fb- deployment-8263  40f17ef1-8048-4123-a214-f616f9a26f10 2878997 0 2022-05-02 20:20:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/containerID:12c932a4685aebacdf03453d4911fbbdb66b932f99f0c5211ed9c98ece65f60f cni.projectcalico.org/podIP:10.233.112.241/32 cni.projectcalico.org/podIPs:10.233.112.241/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb e4867203-e095-4573-ac5d-4f02e35477bc 0xc004dab3b7 0xc004dab3b8}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e4867203-e095-4573-ac5d-4f02e35477bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-05-02 20:20:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-05-02 20:20:41 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.112.241\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cn4qz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cn4qz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.20.186,PodIP:10.233.112.241,StartTime:2022-05-02 20:20:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-02 20:20:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:docker://1192039c432ba1c4fb863947a9f4a8868f5eb01240aa666066c156cd656b5045,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.112.241,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.349: INFO: Pod "webserver-deployment-847dcfb7fb-cwm78" is not available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-cwm78 webserver-deployment-847dcfb7fb- deployment-8263  46c301e8-8d63-435a-82de-4bac4e1b5c99 2879096 0 2022-05-02 20:20:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb e4867203-e095-4573-ac5d-4f02e35477bc 0xc004dab717 0xc004dab718}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e4867203-e095-4573-ac5d-4f02e35477bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mrcfb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mrcfb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.350: INFO: Pod "webserver-deployment-847dcfb7fb-ghjpp" is not available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-ghjpp webserver-deployment-847dcfb7fb- deployment-8263  3122ff8c-ce86-446d-a5ff-a0ab5d47cd7c 2879135 0 2022-05-02 20:20:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb e4867203-e095-4573-ac5d-4f02e35477bc 0xc004dab927 0xc004dab928}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e4867203-e095-4573-ac5d-4f02e35477bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wm9jt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wm9jt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.350: INFO: Pod "webserver-deployment-847dcfb7fb-hdrz6" is available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-hdrz6 webserver-deployment-847dcfb7fb- deployment-8263  d86a459c-0abe-4d55-b9a1-1eea09027f21 2879004 0 2022-05-02 20:20:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/containerID:d56432701c41bb7a06b6df531f70d6037e1204392b2b43c36e7a455783a7cec3 cni.projectcalico.org/podIP:10.233.95.218/32 cni.projectcalico.org/podIPs:10.233.95.218/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb e4867203-e095-4573-ac5d-4f02e35477bc 0xc004dabb47 0xc004dabb48}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e4867203-e095-4573-ac5d-4f02e35477bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-05-02 20:20:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-05-02 20:20:41 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.95.218\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tsgpj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tsgpj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.18.197,PodIP:10.233.95.218,StartTime:2022-05-02 20:20:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-02 20:20:40 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:docker://3e2261c904f25fc117468b195d6d968b4f0adee38fd7b7343bb0bba85c3eec4c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.95.218,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.350: INFO: Pod "webserver-deployment-847dcfb7fb-jbfbh" is not available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-jbfbh webserver-deployment-847dcfb7fb- deployment-8263  266e53a1-935c-45e5-b3ca-dae5875f1458 2879117 0 2022-05-02 20:20:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb e4867203-e095-4573-ac5d-4f02e35477bc 0xc004dabdd7 0xc004dabdd8}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e4867203-e095-4573-ac5d-4f02e35477bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-smcg8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-smcg8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.350: INFO: Pod "webserver-deployment-847dcfb7fb-jtp6h" is available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-jtp6h webserver-deployment-847dcfb7fb- deployment-8263  9b851bc5-8d38-4a2f-996e-dd1cb6ac748c 2878965 0 2022-05-02 20:20:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/containerID:a04d458e1a1d2e444be7517f387757928242b9e067f4857cf549dc57f6292035 cni.projectcalico.org/podIP:10.233.112.238/32 cni.projectcalico.org/podIPs:10.233.112.238/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb e4867203-e095-4573-ac5d-4f02e35477bc 0xc004dabfe7 0xc004dabfe8}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e4867203-e095-4573-ac5d-4f02e35477bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-05-02 20:20:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-05-02 20:20:39 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.112.238\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lkphw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lkphw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.20.186,PodIP:10.233.112.238,StartTime:2022-05-02 20:20:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-02 20:20:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:docker://c7fa6ed466d1384d6d0532c90665959739686fea57ea833cd068a23c5d6c6ee2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.112.238,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.350: INFO: Pod "webserver-deployment-847dcfb7fb-kbsfm" is not available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-kbsfm webserver-deployment-847dcfb7fb- deployment-8263  48c17c04-c121-4b61-959c-8fc703babbec 2879127 0 2022-05-02 20:20:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb e4867203-e095-4573-ac5d-4f02e35477bc 0xc004dcc217 0xc004dcc218}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e4867203-e095-4573-ac5d-4f02e35477bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dzx97,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dzx97,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.351: INFO: Pod "webserver-deployment-847dcfb7fb-kgtz2" is not available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-kgtz2 webserver-deployment-847dcfb7fb- deployment-8263  f66b44b8-beee-495b-88ce-acc9323d5fae 2879134 0 2022-05-02 20:20:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb e4867203-e095-4573-ac5d-4f02e35477bc 0xc004dcc387 0xc004dcc388}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e4867203-e095-4573-ac5d-4f02e35477bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-02 20:20:44 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xlsfn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xlsfn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.20.186,PodIP:,StartTime:2022-05-02 20:20:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.351: INFO: Pod "webserver-deployment-847dcfb7fb-r54mk" is available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-r54mk webserver-deployment-847dcfb7fb- deployment-8263  a417a82d-cad4-4767-b593-a9a0a25966f4 2878985 0 2022-05-02 20:20:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/containerID:beacc179a164a3ab9b16e892c7e36f89c69f60739bd212480ff2e10c429f9b0c cni.projectcalico.org/podIP:10.233.69.232/32 cni.projectcalico.org/podIPs:10.233.69.232/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb e4867203-e095-4573-ac5d-4f02e35477bc 0xc004dcc627 0xc004dcc628}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e4867203-e095-4573-ac5d-4f02e35477bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-05-02 20:20:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-05-02 20:20:40 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.69.232\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-h6zxh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-h6zxh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.20.46,PodIP:10.233.69.232,StartTime:2022-05-02 20:20:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-02 20:20:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:docker://3f5424e1afd3bdb4ce47ce610e1fdce23a605e19f22c738c2fb4333d894b1e6a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.69.232,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.351: INFO: Pod "webserver-deployment-847dcfb7fb-sj4kh" is not available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-sj4kh webserver-deployment-847dcfb7fb- deployment-8263  1a1aeba7-917a-4c29-b025-d6d1443a1699 2879115 0 2022-05-02 20:20:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb e4867203-e095-4573-ac5d-4f02e35477bc 0xc004dcc837 0xc004dcc838}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e4867203-e095-4573-ac5d-4f02e35477bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mwcj8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mwcj8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.351: INFO: Pod "webserver-deployment-847dcfb7fb-v7ks7" is available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-v7ks7 webserver-deployment-847dcfb7fb- deployment-8263  6807ecee-061d-413e-ba2c-750c75646687 2879001 0 2022-05-02 20:20:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/containerID:d256b1d9a3c6dd722bfd4abf72937b38976a622088a29ecba1933897640d9e38 cni.projectcalico.org/podIP:10.233.95.224/32 cni.projectcalico.org/podIPs:10.233.95.224/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb e4867203-e095-4573-ac5d-4f02e35477bc 0xc004dcca27 0xc004dcca28}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e4867203-e095-4573-ac5d-4f02e35477bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-05-02 20:20:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-05-02 20:20:41 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.95.224\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9wctf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9wctf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.18.197,PodIP:10.233.95.224,StartTime:2022-05-02 20:20:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-02 20:20:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:docker://9e8f098df81370e984326dc8676591935dbff3d4c238b15d9d91de1ccd623ba1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.95.224,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.351: INFO: Pod "webserver-deployment-847dcfb7fb-vh7tk" is available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-vh7tk webserver-deployment-847dcfb7fb- deployment-8263  e74b9a40-3274-4ee5-b257-6950b79564c8 2878963 0 2022-05-02 20:20:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/containerID:667d917f876c2e7ce5d833bf930d125a7cb2fce5d6d3279b8842050c408b40f4 cni.projectcalico.org/podIP:10.233.95.152/32 cni.projectcalico.org/podIPs:10.233.95.152/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb e4867203-e095-4573-ac5d-4f02e35477bc 0xc004dccca7 0xc004dccca8}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e4867203-e095-4573-ac5d-4f02e35477bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-05-02 20:20:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-05-02 20:20:39 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.95.152\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6p4c4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6p4c4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.18.197,PodIP:10.233.95.152,StartTime:2022-05-02 20:20:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-02 20:20:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:docker://2572aca6ebb3447ea70fc1ad34df693621288f4160ca5f286753f2cd20a6e8ef,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.95.152,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.351: INFO: Pod "webserver-deployment-847dcfb7fb-vlhxw" is not available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-vlhxw webserver-deployment-847dcfb7fb- deployment-8263  ef9845e6-395e-4195-8a52-155d034634ca 2879138 0 2022-05-02 20:20:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb e4867203-e095-4573-ac5d-4f02e35477bc 0xc004dccf97 0xc004dccf98}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e4867203-e095-4573-ac5d-4f02e35477bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vcmmx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vcmmx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.351: INFO: Pod "webserver-deployment-847dcfb7fb-xl6kc" is not available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-xl6kc webserver-deployment-847dcfb7fb- deployment-8263  3f5a5098-cea1-466e-9930-2f7c61976353 2879122 0 2022-05-02 20:20:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb e4867203-e095-4573-ac5d-4f02e35477bc 0xc004dcd147 0xc004dcd148}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e4867203-e095-4573-ac5d-4f02e35477bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dlwrr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dlwrr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.351: INFO: Pod "webserver-deployment-847dcfb7fb-xqdkp" is available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-xqdkp webserver-deployment-847dcfb7fb- deployment-8263  d5ef3529-b862-4bda-affd-41803924c3dc 2878952 0 2022-05-02 20:20:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[cni.projectcalico.org/containerID:0ce46e392005fbdb49d87eb9bcfb3d4a7672e00f2dc7b7af100a640902c3efbf cni.projectcalico.org/podIP:10.233.112.239/32 cni.projectcalico.org/podIPs:10.233.112.239/32] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb e4867203-e095-4573-ac5d-4f02e35477bc 0xc004dcd300 0xc004dcd301}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e4867203-e095-4573-ac5d-4f02e35477bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-05-02 20:20:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-05-02 20:20:39 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.112.239\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nwrdb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nwrdb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.20.186,PodIP:10.233.112.239,StartTime:2022-05-02 20:20:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-02 20:20:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:b913fa234cc3473cfe16e937d106b455a7609f927f59031c81aca791e2689b50,ContainerID:docker://67ecfd1673d4fcb5426c5144c9e88d8cfe979800ddf99bcf364e0c5445ac8f17,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.112.239,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:20:44.352: INFO: Pod "webserver-deployment-847dcfb7fb-z62k2" is not available:
&Pod{ObjectMeta:{webserver-deployment-847dcfb7fb-z62k2 webserver-deployment-847dcfb7fb- deployment-8263  e2eb0911-de14-45a2-b093-6943e550f18f 2879114 0 2022-05-02 20:20:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:847dcfb7fb] map[] [{apps/v1 ReplicaSet webserver-deployment-847dcfb7fb e4867203-e095-4573-ac5d-4f02e35477bc 0xc004dcd5a7 0xc004dcd5a8}] []  [{kube-controller-manager Update v1 2022-05-02 20:20:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e4867203-e095-4573-ac5d-4f02e35477bc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5552f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5552f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-02 20:20:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:20:44.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8263" for this suite.


• [SLOW TEST:8.876 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":-1,"completed":81,"skipped":1403,"failed":0}

SSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:20:44.572: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:54
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod liveness-93541679-7c56-4551-b72c-b0d2f2998c45 in namespace container-probe-7144
May  2 20:20:53.375: INFO: Started pod liveness-93541679-7c56-4551-b72c-b0d2f2998c45 in namespace container-probe-7144
STEP: checking the pod's current state and verifying that restartCount is present
May  2 20:20:53.396: INFO: Initial restart count of pod liveness-93541679-7c56-4551-b72c-b0d2f2998c45 is 0
May  2 20:21:07.606: INFO: Restart count of pod container-probe-7144/liveness-93541679-7c56-4551-b72c-b0d2f2998c45 is now 1 (14.2097802s elapsed)
May  2 20:21:27.792: INFO: Restart count of pod container-probe-7144/liveness-93541679-7c56-4551-b72c-b0d2f2998c45 is now 2 (34.395795845s elapsed)
May  2 20:21:47.970: INFO: Restart count of pod container-probe-7144/liveness-93541679-7c56-4551-b72c-b0d2f2998c45 is now 3 (54.573788831s elapsed)
May  2 20:22:08.230: INFO: Restart count of pod container-probe-7144/liveness-93541679-7c56-4551-b72c-b0d2f2998c45 is now 4 (1m14.83354729s elapsed)
May  2 20:23:14.855: INFO: Restart count of pod container-probe-7144/liveness-93541679-7c56-4551-b72c-b0d2f2998c45 is now 5 (2m21.458434899s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:23:14.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7144" for this suite.


• [SLOW TEST:150.470 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":-1,"completed":82,"skipped":1413,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:23:15.123: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:23:15.222: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:23:23.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-221" for this suite.


• [SLOW TEST:8.763 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":-1,"completed":83,"skipped":1440,"failed":0}

SSSSSSSSS
------------------------------
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:23:23.913: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should list and delete a collection of ReplicaSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create a ReplicaSet
STEP: Verify that the required pods have come up
May  2 20:23:24.029: INFO: Pod name sample-pod: Found 0 pods out of 3
May  2 20:23:29.063: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running
May  2 20:23:29.069: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets
STEP: DeleteCollection of the ReplicaSets
STEP: After DeleteCollection verify that ReplicaSets have been deleted
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:23:29.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8047" for this suite.


• [SLOW TEST:5.312 seconds]
[sig-apps] ReplicaSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","total":-1,"completed":84,"skipped":1449,"failed":0}

SSSS
------------------------------
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:23:29.294: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:23:45.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5648" for this suite.


• [SLOW TEST:16.598 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":-1,"completed":85,"skipped":1453,"failed":0}

SSSS
------------------------------
[BeforeEach] version v1
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:23:45.903: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:23:46.044: INFO: Creating pod...
May  2 20:23:46.090: INFO: Pod Quantity: 1 Status: Pending
May  2 20:23:47.108: INFO: Pod Quantity: 1 Status: Pending
May  2 20:23:48.106: INFO: Pod Quantity: 1 Status: Pending
May  2 20:23:49.105: INFO: Pod Status: Running
May  2 20:23:49.105: INFO: Creating service...
May  2 20:23:49.151: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8555/pods/agnhost/proxy/some/path/with/DELETE
May  2 20:23:49.184: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
May  2 20:23:49.184: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8555/pods/agnhost/proxy/some/path/with/GET
May  2 20:23:49.200: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
May  2 20:23:49.201: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8555/pods/agnhost/proxy/some/path/with/HEAD
May  2 20:23:49.211: INFO: http.Client request:HEAD | StatusCode:200
May  2 20:23:49.211: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8555/pods/agnhost/proxy/some/path/with/OPTIONS
May  2 20:23:49.215: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
May  2 20:23:49.215: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8555/pods/agnhost/proxy/some/path/with/PATCH
May  2 20:23:49.221: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
May  2 20:23:49.221: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8555/pods/agnhost/proxy/some/path/with/POST
May  2 20:23:49.236: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
May  2 20:23:49.236: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8555/pods/agnhost/proxy/some/path/with/PUT
May  2 20:23:49.244: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
May  2 20:23:49.244: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8555/services/test-service/proxy/some/path/with/DELETE
May  2 20:23:49.259: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
May  2 20:23:49.259: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8555/services/test-service/proxy/some/path/with/GET
May  2 20:23:49.277: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
May  2 20:23:49.277: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8555/services/test-service/proxy/some/path/with/HEAD
May  2 20:23:49.284: INFO: http.Client request:HEAD | StatusCode:200
May  2 20:23:49.284: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8555/services/test-service/proxy/some/path/with/OPTIONS
May  2 20:23:49.300: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
May  2 20:23:49.300: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8555/services/test-service/proxy/some/path/with/PATCH
May  2 20:23:49.322: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
May  2 20:23:49.322: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8555/services/test-service/proxy/some/path/with/POST
May  2 20:23:49.332: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
May  2 20:23:49.332: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8555/services/test-service/proxy/some/path/with/PUT
May  2 20:23:49.351: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:23:49.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8555" for this suite.

•
------------------------------
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","total":-1,"completed":86,"skipped":1457,"failed":0}

SSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:23:49.422: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
May  2 20:23:55.755: INFO: The status of Pod kube-controller-manager-node-2 is Running (Ready = true)
May  2 20:23:56.150: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:23:56.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3106" for this suite.


• [SLOW TEST:6.797 seconds]
[sig-api-machinery] Garbage collector
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":-1,"completed":87,"skipped":1463,"failed":0}

SSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:23:56.265: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test override all
May  2 20:23:56.461: INFO: Waiting up to 5m0s for pod "client-containers-032145a1-e341-416f-b7c8-9a8483d94134" in namespace "containers-8998" to be "Succeeded or Failed"
May  2 20:23:56.479: INFO: Pod "client-containers-032145a1-e341-416f-b7c8-9a8483d94134": Phase="Pending", Reason="", readiness=false. Elapsed: 17.396081ms
May  2 20:23:58.492: INFO: Pod "client-containers-032145a1-e341-416f-b7c8-9a8483d94134": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031294709s
May  2 20:24:00.526: INFO: Pod "client-containers-032145a1-e341-416f-b7c8-9a8483d94134": Phase="Pending", Reason="", readiness=false. Elapsed: 4.064417953s
May  2 20:24:02.547: INFO: Pod "client-containers-032145a1-e341-416f-b7c8-9a8483d94134": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.08608922s
STEP: Saw pod success
May  2 20:24:02.547: INFO: Pod "client-containers-032145a1-e341-416f-b7c8-9a8483d94134" satisfied condition "Succeeded or Failed"
May  2 20:24:02.559: INFO: Trying to get logs from node node-2 pod client-containers-032145a1-e341-416f-b7c8-9a8483d94134 container agnhost-container: <nil>
STEP: delete the pod
May  2 20:24:02.653: INFO: Waiting for pod client-containers-032145a1-e341-416f-b7c8-9a8483d94134 to disappear
May  2 20:24:02.665: INFO: Pod client-containers-032145a1-e341-416f-b7c8-9a8483d94134 no longer exists
[AfterEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:24:02.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8998" for this suite.


• [SLOW TEST:6.458 seconds]
[sig-node] Docker Containers
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":-1,"completed":88,"skipped":1477,"failed":0}

SSSSSS
------------------------------
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:24:02.753: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:69
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:24:02.911: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename disruption-2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be processed
STEP: listing a collection of PDBs across all namespaces
STEP: listing a collection of PDBs in namespace disruption-9912
STEP: deleting a collection of PDBs
STEP: Waiting for the PDB collection to be deleted
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:24:05.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-1056" for this suite.
[AfterEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:24:05.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-9912" for this suite.

•
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","total":-1,"completed":89,"skipped":1483,"failed":0}

SS
------------------------------
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:24:05.479: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-63617660-0af1-4fff-9154-0ac03e9a53c7
STEP: Creating a pod to test consume configMaps
May  2 20:24:05.622: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4282ea41-3560-4235-9197-abaefb0982ea" in namespace "projected-2885" to be "Succeeded or Failed"
May  2 20:24:05.634: INFO: Pod "pod-projected-configmaps-4282ea41-3560-4235-9197-abaefb0982ea": Phase="Pending", Reason="", readiness=false. Elapsed: 11.760421ms
May  2 20:24:07.653: INFO: Pod "pod-projected-configmaps-4282ea41-3560-4235-9197-abaefb0982ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030564756s
May  2 20:24:09.668: INFO: Pod "pod-projected-configmaps-4282ea41-3560-4235-9197-abaefb0982ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045892872s
STEP: Saw pod success
May  2 20:24:09.668: INFO: Pod "pod-projected-configmaps-4282ea41-3560-4235-9197-abaefb0982ea" satisfied condition "Succeeded or Failed"
May  2 20:24:09.678: INFO: Trying to get logs from node node-2 pod pod-projected-configmaps-4282ea41-3560-4235-9197-abaefb0982ea container projected-configmap-volume-test: <nil>
STEP: delete the pod
May  2 20:24:09.745: INFO: Waiting for pod pod-projected-configmaps-4282ea41-3560-4235-9197-abaefb0982ea to disappear
May  2 20:24:09.753: INFO: Pod pod-projected-configmaps-4282ea41-3560-4235-9197-abaefb0982ea no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:24:09.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2885" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":-1,"completed":90,"skipped":1485,"failed":0}
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:24:09.783: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create deployment with httpd image
May  2 20:24:09.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-1838 create -f -'
May  2 20:24:12.906: INFO: stderr: ""
May  2 20:24:12.906: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image
May  2 20:24:12.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-1838 diff -f -'
May  2 20:24:15.241: INFO: rc: 1
May  2 20:24:15.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-1838 delete -f -'
May  2 20:24:15.421: INFO: stderr: ""
May  2 20:24:15.421: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:24:15.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1838" for this suite.


• [SLOW TEST:5.706 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl diff
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:882
    should check if kubectl diff finds a difference for Deployments [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","total":-1,"completed":91,"skipped":1485,"failed":0}
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:24:15.532: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0777 on tmpfs
May  2 20:24:15.666: INFO: Waiting up to 5m0s for pod "pod-80f9f0b3-8493-4475-85d8-94e0808ea65b" in namespace "emptydir-4779" to be "Succeeded or Failed"
May  2 20:24:15.694: INFO: Pod "pod-80f9f0b3-8493-4475-85d8-94e0808ea65b": Phase="Pending", Reason="", readiness=false. Elapsed: 27.672551ms
May  2 20:24:17.707: INFO: Pod "pod-80f9f0b3-8493-4475-85d8-94e0808ea65b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04156446s
May  2 20:24:19.726: INFO: Pod "pod-80f9f0b3-8493-4475-85d8-94e0808ea65b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.060360339s
STEP: Saw pod success
May  2 20:24:19.726: INFO: Pod "pod-80f9f0b3-8493-4475-85d8-94e0808ea65b" satisfied condition "Succeeded or Failed"
May  2 20:24:19.740: INFO: Trying to get logs from node node-2 pod pod-80f9f0b3-8493-4475-85d8-94e0808ea65b container test-container: <nil>
STEP: delete the pod
May  2 20:24:19.811: INFO: Waiting for pod pod-80f9f0b3-8493-4475-85d8-94e0808ea65b to disappear
May  2 20:24:19.820: INFO: Pod pod-80f9f0b3-8493-4475-85d8-94e0808ea65b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:24:19.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4779" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":92,"skipped":1485,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:24:20.120: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:24:33.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9147" for this suite.


• [SLOW TEST:13.415 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":-1,"completed":93,"skipped":1559,"failed":0}

SSSSSSSS
------------------------------
[BeforeEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:19:48.153: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not schedule jobs when suspended [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a suspended cronjob
STEP: Ensuring no jobs are scheduled
STEP: Ensuring no job exists by listing jobs explicitly
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:24:48.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-5160" for this suite.


• [SLOW TEST:300.310 seconds]
[sig-apps] CronJob
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","total":-1,"completed":113,"skipped":1851,"failed":0}

SSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:24:33.572: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:54
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:24:33.720: INFO: The status of Pod test-webserver-7055f252-1d8c-4873-bda3-7528c30caf3c is Pending, waiting for it to be Running (with Ready = true)
May  2 20:24:35.730: INFO: The status of Pod test-webserver-7055f252-1d8c-4873-bda3-7528c30caf3c is Pending, waiting for it to be Running (with Ready = true)
May  2 20:24:37.736: INFO: The status of Pod test-webserver-7055f252-1d8c-4873-bda3-7528c30caf3c is Running (Ready = false)
May  2 20:24:39.739: INFO: The status of Pod test-webserver-7055f252-1d8c-4873-bda3-7528c30caf3c is Running (Ready = false)
May  2 20:24:41.734: INFO: The status of Pod test-webserver-7055f252-1d8c-4873-bda3-7528c30caf3c is Running (Ready = false)
May  2 20:24:43.736: INFO: The status of Pod test-webserver-7055f252-1d8c-4873-bda3-7528c30caf3c is Running (Ready = false)
May  2 20:24:45.731: INFO: The status of Pod test-webserver-7055f252-1d8c-4873-bda3-7528c30caf3c is Running (Ready = false)
May  2 20:24:47.737: INFO: The status of Pod test-webserver-7055f252-1d8c-4873-bda3-7528c30caf3c is Running (Ready = false)
May  2 20:24:49.734: INFO: The status of Pod test-webserver-7055f252-1d8c-4873-bda3-7528c30caf3c is Running (Ready = false)
May  2 20:24:51.729: INFO: The status of Pod test-webserver-7055f252-1d8c-4873-bda3-7528c30caf3c is Running (Ready = false)
May  2 20:24:53.740: INFO: The status of Pod test-webserver-7055f252-1d8c-4873-bda3-7528c30caf3c is Running (Ready = false)
May  2 20:24:55.742: INFO: The status of Pod test-webserver-7055f252-1d8c-4873-bda3-7528c30caf3c is Running (Ready = true)
May  2 20:24:55.750: INFO: Container started at 2022-05-02 20:24:35 +0000 UTC, pod became ready at 2022-05-02 20:24:53 +0000 UTC
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:24:55.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6666" for this suite.


• [SLOW TEST:22.238 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":-1,"completed":94,"skipped":1567,"failed":0}

SS
------------------------------
[BeforeEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:24:55.817: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/instrumentation/events.go:81
[It] should delete a collection of events [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create set of events
STEP: get a list of Events with a label in the current namespace
STEP: delete a list of events
May  2 20:24:56.059: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity
[AfterEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:24:56.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-2383" for this suite.

•
------------------------------
{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","total":-1,"completed":95,"skipped":1569,"failed":0}

SSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:24:48.538: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Creating a NodePort Service
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota
STEP: Ensuring resource quota status captures service creation
STEP: Deleting Services
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:25:00.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9341" for this suite.


• [SLOW TEST:11.760 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":-1,"completed":114,"skipped":1872,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:25:00.494: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap configmap-6950/configmap-test-9f4fe90f-59a6-48b2-a357-b10345a24568
STEP: Creating a pod to test consume configMaps
May  2 20:25:00.707: INFO: Waiting up to 5m0s for pod "pod-configmaps-00f28a53-8756-4f63-b690-331779e74960" in namespace "configmap-6950" to be "Succeeded or Failed"
May  2 20:25:00.730: INFO: Pod "pod-configmaps-00f28a53-8756-4f63-b690-331779e74960": Phase="Pending", Reason="", readiness=false. Elapsed: 22.670255ms
May  2 20:25:02.750: INFO: Pod "pod-configmaps-00f28a53-8756-4f63-b690-331779e74960": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042596564s
May  2 20:25:04.761: INFO: Pod "pod-configmaps-00f28a53-8756-4f63-b690-331779e74960": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054175746s
STEP: Saw pod success
May  2 20:25:04.762: INFO: Pod "pod-configmaps-00f28a53-8756-4f63-b690-331779e74960" satisfied condition "Succeeded or Failed"
May  2 20:25:04.773: INFO: Trying to get logs from node node-2 pod pod-configmaps-00f28a53-8756-4f63-b690-331779e74960 container env-test: <nil>
STEP: delete the pod
May  2 20:25:04.882: INFO: Waiting for pod pod-configmaps-00f28a53-8756-4f63-b690-331779e74960 to disappear
May  2 20:25:04.890: INFO: Pod pod-configmaps-00f28a53-8756-4f63-b690-331779e74960 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:25:04.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6950" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":-1,"completed":115,"skipped":1911,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:24:56.218: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:52
STEP: create the container to handle the HTTPGet hook request.
May  2 20:24:56.353: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
May  2 20:24:58.368: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
May  2 20:25:00.371: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the pod with lifecycle hook
May  2 20:25:00.437: INFO: The status of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
May  2 20:25:02.452: INFO: The status of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
May  2 20:25:04.449: INFO: The status of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
May  2 20:25:06.460: INFO: The status of Pod pod-with-poststart-http-hook is Running (Ready = true)
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May  2 20:25:06.547: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May  2 20:25:06.585: INFO: Pod pod-with-poststart-http-hook still exists
May  2 20:25:08.587: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May  2 20:25:08.596: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:25:08.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-800" for this suite.


• [SLOW TEST:12.440 seconds]
[sig-node] Container Lifecycle Hook
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:43
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":-1,"completed":96,"skipped":1589,"failed":0}

SS
------------------------------
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:25:04.975: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:38
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:25:05.193: INFO: The status of Pod busybox-host-aliases51f4c82b-928e-4d09-9c8d-f3d4b478a727 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:25:07.209: INFO: The status of Pod busybox-host-aliases51f4c82b-928e-4d09-9c8d-f3d4b478a727 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:25:09.209: INFO: The status of Pod busybox-host-aliases51f4c82b-928e-4d09-9c8d-f3d4b478a727 is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:25:09.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-947" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":116,"skipped":1937,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:25:09.434: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:25:09.538: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:25:15.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5199" for this suite.


• [SLOW TEST:6.413 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:48
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":-1,"completed":117,"skipped":1976,"failed":0}

SSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:25:08.667: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod pod-subpath-test-projected-rm5t
STEP: Creating a pod to test atomic-volume-subpath
May  2 20:25:08.842: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-rm5t" in namespace "subpath-2131" to be "Succeeded or Failed"
May  2 20:25:08.869: INFO: Pod "pod-subpath-test-projected-rm5t": Phase="Pending", Reason="", readiness=false. Elapsed: 26.387742ms
May  2 20:25:10.894: INFO: Pod "pod-subpath-test-projected-rm5t": Phase="Running", Reason="", readiness=true. Elapsed: 2.051392763s
May  2 20:25:12.916: INFO: Pod "pod-subpath-test-projected-rm5t": Phase="Running", Reason="", readiness=true. Elapsed: 4.073779424s
May  2 20:25:14.947: INFO: Pod "pod-subpath-test-projected-rm5t": Phase="Running", Reason="", readiness=true. Elapsed: 6.104490054s
May  2 20:25:16.961: INFO: Pod "pod-subpath-test-projected-rm5t": Phase="Running", Reason="", readiness=true. Elapsed: 8.118830218s
May  2 20:25:18.983: INFO: Pod "pod-subpath-test-projected-rm5t": Phase="Running", Reason="", readiness=true. Elapsed: 10.140170738s
May  2 20:25:21.000: INFO: Pod "pod-subpath-test-projected-rm5t": Phase="Running", Reason="", readiness=true. Elapsed: 12.157007012s
May  2 20:25:23.022: INFO: Pod "pod-subpath-test-projected-rm5t": Phase="Running", Reason="", readiness=true. Elapsed: 14.179358861s
May  2 20:25:25.055: INFO: Pod "pod-subpath-test-projected-rm5t": Phase="Running", Reason="", readiness=true. Elapsed: 16.21288288s
May  2 20:25:27.065: INFO: Pod "pod-subpath-test-projected-rm5t": Phase="Running", Reason="", readiness=true. Elapsed: 18.222315275s
May  2 20:25:29.282: INFO: Pod "pod-subpath-test-projected-rm5t": Phase="Running", Reason="", readiness=true. Elapsed: 20.439727565s
May  2 20:25:31.299: INFO: Pod "pod-subpath-test-projected-rm5t": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.456868445s
STEP: Saw pod success
May  2 20:25:31.300: INFO: Pod "pod-subpath-test-projected-rm5t" satisfied condition "Succeeded or Failed"
May  2 20:25:31.342: INFO: Trying to get logs from node node-2 pod pod-subpath-test-projected-rm5t container test-container-subpath-projected-rm5t: <nil>
STEP: delete the pod
May  2 20:25:31.466: INFO: Waiting for pod pod-subpath-test-projected-rm5t to disappear
May  2 20:25:31.504: INFO: Pod pod-subpath-test-projected-rm5t no longer exists
STEP: Deleting pod pod-subpath-test-projected-rm5t
May  2 20:25:31.504: INFO: Deleting pod "pod-subpath-test-projected-rm5t" in namespace "subpath-2131"
[AfterEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:25:31.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2131" for this suite.


• [SLOW TEST:22.901 seconds]
[sig-storage] Subpath
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [LinuxOnly] [Conformance]","total":-1,"completed":97,"skipped":1591,"failed":0}

SSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:25:31.723: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service multi-endpoint-test in namespace services-9546
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9546 to expose endpoints map[]
May  2 20:25:31.959: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
May  2 20:25:32.982: INFO: successfully validated that service multi-endpoint-test in namespace services-9546 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-9546
May  2 20:25:33.045: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:25:35.069: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:25:37.058: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9546 to expose endpoints map[pod1:[100]]
May  2 20:25:37.101: INFO: successfully validated that service multi-endpoint-test in namespace services-9546 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-9546
May  2 20:25:37.147: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:25:39.170: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:25:41.162: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9546 to expose endpoints map[pod1:[100] pod2:[101]]
May  2 20:25:41.204: INFO: successfully validated that service multi-endpoint-test in namespace services-9546 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods
May  2 20:25:41.204: INFO: Creating new exec pod
May  2 20:25:46.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-9546 exec execpod9rxdx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
May  2 20:25:46.822: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
May  2 20:25:46.822: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 20:25:46.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-9546 exec execpod9rxdx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.27.114 80'
May  2 20:25:47.276: INFO: stderr: "+ nc -v -t -w 2 10.233.27.114 80\nConnection to 10.233.27.114 80 port [tcp/http] succeeded!\n+ echo hostName\n"
May  2 20:25:47.276: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 20:25:47.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-9546 exec execpod9rxdx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
May  2 20:25:47.787: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
May  2 20:25:47.787: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 20:25:47.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-9546 exec execpod9rxdx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.27.114 81'
May  2 20:25:48.110: INFO: stderr: "+ nc -v -t -w 2 10.233.27.114 81\n+ echo hostName\nConnection to 10.233.27.114 81 port [tcp/*] succeeded!\n"
May  2 20:25:48.110: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-9546
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9546 to expose endpoints map[pod2:[101]]
May  2 20:25:49.260: INFO: successfully validated that service multi-endpoint-test in namespace services-9546 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-9546
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9546 to expose endpoints map[]
May  2 20:25:51.358: INFO: successfully validated that service multi-endpoint-test in namespace services-9546 exposes endpoints map[]
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:25:51.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9546" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753


• [SLOW TEST:19.729 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":-1,"completed":98,"skipped":1610,"failed":0}

SSSSSSS
------------------------------
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:25:51.501: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
May  2 20:25:51.631: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d3a139e4-b4ce-4ad4-ad22-04a1f0c969ed" in namespace "projected-8887" to be "Succeeded or Failed"
May  2 20:25:51.665: INFO: Pod "downwardapi-volume-d3a139e4-b4ce-4ad4-ad22-04a1f0c969ed": Phase="Pending", Reason="", readiness=false. Elapsed: 33.887712ms
May  2 20:25:53.694: INFO: Pod "downwardapi-volume-d3a139e4-b4ce-4ad4-ad22-04a1f0c969ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.062309679s
May  2 20:25:55.709: INFO: Pod "downwardapi-volume-d3a139e4-b4ce-4ad4-ad22-04a1f0c969ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.077126311s
STEP: Saw pod success
May  2 20:25:55.709: INFO: Pod "downwardapi-volume-d3a139e4-b4ce-4ad4-ad22-04a1f0c969ed" satisfied condition "Succeeded or Failed"
May  2 20:25:55.715: INFO: Trying to get logs from node node-2 pod downwardapi-volume-d3a139e4-b4ce-4ad4-ad22-04a1f0c969ed container client-container: <nil>
STEP: delete the pod
May  2 20:25:55.770: INFO: Waiting for pod downwardapi-volume-d3a139e4-b4ce-4ad4-ad22-04a1f0c969ed to disappear
May  2 20:25:55.776: INFO: Pod downwardapi-volume-d3a139e4-b4ce-4ad4-ad22-04a1f0c969ed no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:25:55.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8887" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":-1,"completed":99,"skipped":1617,"failed":0}

SSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:25:55.841: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Performing setup for networking test in namespace pod-network-test-9004
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May  2 20:25:55.985: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
May  2 20:25:56.166: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:25:58.271: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:26:00.197: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 20:26:02.176: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 20:26:04.179: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 20:26:06.175: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 20:26:08.181: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 20:26:10.176: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 20:26:12.192: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 20:26:14.183: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 20:26:16.190: INFO: The status of Pod netserver-0 is Running (Ready = true)
May  2 20:26:16.221: INFO: The status of Pod netserver-1 is Running (Ready = true)
May  2 20:26:16.242: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
May  2 20:26:20.298: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
May  2 20:26:20.298: INFO: Breadth first check of 10.233.95.227 on host 10.100.18.197...
May  2 20:26:20.304: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.69.141:9080/dial?request=hostname&protocol=http&host=10.233.95.227&port=8083&tries=1'] Namespace:pod-network-test-9004 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 20:26:20.304: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
May  2 20:26:20.557: INFO: Waiting for responses: map[]
May  2 20:26:20.557: INFO: reached 10.233.95.227 after 0/1 tries
May  2 20:26:20.557: INFO: Breadth first check of 10.233.112.254 on host 10.100.20.186...
May  2 20:26:20.566: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.69.141:9080/dial?request=hostname&protocol=http&host=10.233.112.254&port=8083&tries=1'] Namespace:pod-network-test-9004 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 20:26:20.567: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
May  2 20:26:20.807: INFO: Waiting for responses: map[]
May  2 20:26:20.808: INFO: reached 10.233.112.254 after 0/1 tries
May  2 20:26:20.808: INFO: Breadth first check of 10.233.69.171 on host 10.100.20.46...
May  2 20:26:20.815: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.69.141:9080/dial?request=hostname&protocol=http&host=10.233.69.171&port=8083&tries=1'] Namespace:pod-network-test-9004 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 20:26:20.815: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
May  2 20:26:20.968: INFO: Waiting for responses: map[]
May  2 20:26:20.968: INFO: reached 10.233.69.171 after 0/1 tries
May  2 20:26:20.968: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:26:20.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9004" for this suite.


• [SLOW TEST:25.154 seconds]
[sig-network] Networking
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/networking.go:30
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","total":-1,"completed":100,"skipped":1632,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:26:21.054: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/init_container.go:162
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod
May  2 20:26:21.158: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:26:26.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1393" for this suite.


• [SLOW TEST:5.924 seconds]
[sig-node] InitContainer [NodeConformance]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":-1,"completed":101,"skipped":1658,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:26:27.045: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-cef6b8ba-ba25-45bf-8cf0-e7d3a7fdbde6
STEP: Creating a pod to test consume configMaps
May  2 20:26:27.227: INFO: Waiting up to 5m0s for pod "pod-configmaps-dde21d53-7390-4cd3-bfa6-b6baaacafc18" in namespace "configmap-4203" to be "Succeeded or Failed"
May  2 20:26:27.245: INFO: Pod "pod-configmaps-dde21d53-7390-4cd3-bfa6-b6baaacafc18": Phase="Pending", Reason="", readiness=false. Elapsed: 17.607866ms
May  2 20:26:29.315: INFO: Pod "pod-configmaps-dde21d53-7390-4cd3-bfa6-b6baaacafc18": Phase="Pending", Reason="", readiness=false. Elapsed: 2.087505588s
May  2 20:26:31.336: INFO: Pod "pod-configmaps-dde21d53-7390-4cd3-bfa6-b6baaacafc18": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.108315267s
STEP: Saw pod success
May  2 20:26:31.336: INFO: Pod "pod-configmaps-dde21d53-7390-4cd3-bfa6-b6baaacafc18" satisfied condition "Succeeded or Failed"
May  2 20:26:31.348: INFO: Trying to get logs from node node-1 pod pod-configmaps-dde21d53-7390-4cd3-bfa6-b6baaacafc18 container agnhost-container: <nil>
STEP: delete the pod
May  2 20:26:31.430: INFO: Waiting for pod pod-configmaps-dde21d53-7390-4cd3-bfa6-b6baaacafc18 to disappear
May  2 20:26:31.436: INFO: Pod pod-configmaps-dde21d53-7390-4cd3-bfa6-b6baaacafc18 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:26:31.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4203" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":102,"skipped":1681,"failed":0}

SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:26:31.554: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:92
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:107
STEP: Creating service test in namespace statefulset-85
[It] Should recreate evicted statefulset [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-85
STEP: Waiting until pod test-pod will start running in namespace statefulset-85
STEP: Creating statefulset with conflicting port in namespace statefulset-85
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-85
May  2 20:26:35.949: INFO: Observed stateful pod in namespace: statefulset-85, name: ss-0, uid: 48b07b64-c15a-4667-9564-8325cafc533b, status phase: Pending. Waiting for statefulset controller to delete.
May  2 20:26:36.018: INFO: Observed stateful pod in namespace: statefulset-85, name: ss-0, uid: 48b07b64-c15a-4667-9564-8325cafc533b, status phase: Failed. Waiting for statefulset controller to delete.
May  2 20:26:36.112: INFO: Observed stateful pod in namespace: statefulset-85, name: ss-0, uid: 48b07b64-c15a-4667-9564-8325cafc533b, status phase: Failed. Waiting for statefulset controller to delete.
May  2 20:26:36.126: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-85
STEP: Removing pod with conflicting port in namespace statefulset-85
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-85 and will be in running state
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:118
May  2 20:26:40.230: INFO: Deleting all statefulset in ns statefulset-85
May  2 20:26:40.237: INFO: Scaling statefulset ss to 0
May  2 20:26:50.331: INFO: Waiting for statefulset status.replicas updated to 0
May  2 20:26:50.346: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:26:50.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-85" for this suite.


• [SLOW TEST:18.847 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:97
    Should recreate evicted statefulset [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":-1,"completed":103,"skipped":1703,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:26:50.532: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:26:50.672: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
May  2 20:27:23.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=crd-publish-openapi-8188 --namespace=crd-publish-openapi-8188 create -f -'
May  2 20:27:24.652: INFO: stderr: ""
May  2 20:27:24.652: INFO: stdout: "e2e-test-crd-publish-openapi-6206-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
May  2 20:27:24.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=crd-publish-openapi-8188 --namespace=crd-publish-openapi-8188 delete e2e-test-crd-publish-openapi-6206-crds test-cr'
May  2 20:27:24.904: INFO: stderr: ""
May  2 20:27:24.904: INFO: stdout: "e2e-test-crd-publish-openapi-6206-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
May  2 20:27:24.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=crd-publish-openapi-8188 --namespace=crd-publish-openapi-8188 apply -f -'
May  2 20:27:26.142: INFO: stderr: ""
May  2 20:27:26.143: INFO: stdout: "e2e-test-crd-publish-openapi-6206-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
May  2 20:27:26.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=crd-publish-openapi-8188 --namespace=crd-publish-openapi-8188 delete e2e-test-crd-publish-openapi-6206-crds test-cr'
May  2 20:27:26.333: INFO: stderr: ""
May  2 20:27:26.333: INFO: stdout: "e2e-test-crd-publish-openapi-6206-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
May  2 20:27:26.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=crd-publish-openapi-8188 explain e2e-test-crd-publish-openapi-6206-crds'
May  2 20:27:26.708: INFO: stderr: ""
May  2 20:27:26.708: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6206-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:27:46.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8188" for this suite.


• [SLOW TEST:56.380 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":-1,"completed":104,"skipped":1789,"failed":0}

SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:27:46.952: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  2 20:27:48.359: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May  2 20:27:50.423: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120068, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120068, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120068, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120068, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  2 20:27:53.481: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:27:54.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9887" for this suite.
STEP: Destroying namespace "webhook-9887-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102


• [SLOW TEST:7.382 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":-1,"completed":105,"skipped":1811,"failed":0}

SSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:27:54.396: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with secret that has name projected-secret-test-map-2fe28170-8959-45e6-a019-7082bd45fd8c
STEP: Creating a pod to test consume secrets
May  2 20:27:54.583: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f9e88539-4cb7-4b29-bc30-e6c94accb8dd" in namespace "projected-738" to be "Succeeded or Failed"
May  2 20:27:54.603: INFO: Pod "pod-projected-secrets-f9e88539-4cb7-4b29-bc30-e6c94accb8dd": Phase="Pending", Reason="", readiness=false. Elapsed: 18.920014ms
May  2 20:27:56.667: INFO: Pod "pod-projected-secrets-f9e88539-4cb7-4b29-bc30-e6c94accb8dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.082964531s
May  2 20:27:58.679: INFO: Pod "pod-projected-secrets-f9e88539-4cb7-4b29-bc30-e6c94accb8dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.095119204s
STEP: Saw pod success
May  2 20:27:58.679: INFO: Pod "pod-projected-secrets-f9e88539-4cb7-4b29-bc30-e6c94accb8dd" satisfied condition "Succeeded or Failed"
May  2 20:27:58.690: INFO: Trying to get logs from node node-2 pod pod-projected-secrets-f9e88539-4cb7-4b29-bc30-e6c94accb8dd container projected-secret-volume-test: <nil>
STEP: delete the pod
May  2 20:27:58.768: INFO: Waiting for pod pod-projected-secrets-f9e88539-4cb7-4b29-bc30-e6c94accb8dd to disappear
May  2 20:27:58.774: INFO: Pod pod-projected-secrets-f9e88539-4cb7-4b29-bc30-e6c94accb8dd no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:27:58.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-738" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":106,"skipped":1821,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:25:15.891: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: set up a multi version CRD
May  2 20:25:16.035: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:28:03.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9363" for this suite.


• [SLOW TEST:167.866 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":-1,"completed":118,"skipped":1985,"failed":0}

SSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:27:58.842: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting a starting resourceVersion
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:28:03.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8760" for this suite.

•S
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":-1,"completed":107,"skipped":1844,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:28:03.781: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should test the lifecycle of a ReplicationController [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a ReplicationController
STEP: waiting for RC to be added
STEP: waiting for available Replicas
STEP: patching ReplicationController
STEP: waiting for RC to be modified
STEP: patching ReplicationController status
STEP: waiting for RC to be modified
STEP: waiting for available Replicas
STEP: fetching ReplicationController status
STEP: patching ReplicationController scale
STEP: waiting for RC to be modified
STEP: waiting for ReplicationController's scale to be the max amount
STEP: fetching ReplicationController; ensuring that it's patched
STEP: updating ReplicationController status
STEP: waiting for RC to be modified
STEP: listing all ReplicationControllers
STEP: checking that ReplicationController has expected values
STEP: deleting ReplicationControllers by collection
STEP: waiting for ReplicationController to have a DELETED watchEvent
[AfterEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:28:08.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9019" for this suite.

•
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","total":-1,"completed":119,"skipped":1992,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:28:03.863: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:69
[It] should observe PodDisruptionBudget status updated [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Waiting for the pdb to be processed
STEP: Waiting for all pods to be running
May  2 20:28:06.223: INFO: running pods: 0 < 3
May  2 20:28:08.243: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:28:10.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-4701" for this suite.


• [SLOW TEST:6.466 seconds]
[sig-apps] DisruptionController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","total":-1,"completed":108,"skipped":1867,"failed":0}

SSSS
------------------------------
[BeforeEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:28:09.609: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward api env vars
May  2 20:28:09.799: INFO: Waiting up to 5m0s for pod "downward-api-d83de3f1-c5b6-4bd3-b707-e72b32a3f8ad" in namespace "downward-api-8657" to be "Succeeded or Failed"
May  2 20:28:09.808: INFO: Pod "downward-api-d83de3f1-c5b6-4bd3-b707-e72b32a3f8ad": Phase="Pending", Reason="", readiness=false. Elapsed: 9.260524ms
May  2 20:28:11.831: INFO: Pod "downward-api-d83de3f1-c5b6-4bd3-b707-e72b32a3f8ad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031720774s
May  2 20:28:13.851: INFO: Pod "downward-api-d83de3f1-c5b6-4bd3-b707-e72b32a3f8ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052043434s
STEP: Saw pod success
May  2 20:28:13.851: INFO: Pod "downward-api-d83de3f1-c5b6-4bd3-b707-e72b32a3f8ad" satisfied condition "Succeeded or Failed"
May  2 20:28:13.856: INFO: Trying to get logs from node node-2 pod downward-api-d83de3f1-c5b6-4bd3-b707-e72b32a3f8ad container dapi-container: <nil>
STEP: delete the pod
May  2 20:28:13.953: INFO: Waiting for pod downward-api-d83de3f1-c5b6-4bd3-b707-e72b32a3f8ad to disappear
May  2 20:28:13.966: INFO: Pod downward-api-d83de3f1-c5b6-4bd3-b707-e72b32a3f8ad no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:28:13.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8657" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":-1,"completed":120,"skipped":2081,"failed":0}

SSSSS
------------------------------
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:28:14.041: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9915.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-9915.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9915.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9915.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-9915.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9915.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May  2 20:28:18.410: INFO: DNS probes using dns-9915/dns-test-d5f82791-dac8-440c-8630-e2bfa833125e succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:28:18.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9915" for this suite.

•
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [LinuxOnly] [Conformance]","total":-1,"completed":121,"skipped":2086,"failed":0}

SSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:28:18.812: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
May  2 20:28:19.820: INFO: The status of Pod kube-controller-manager-node-2 is Running (Ready = true)
May  2 20:28:20.045: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:28:20.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3515" for this suite.

•
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":-1,"completed":122,"skipped":2107,"failed":0}

SSSSSSS
------------------------------
[BeforeEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:28:10.387: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:52
STEP: create the container to handle the HTTPGet hook request.
May  2 20:28:10.693: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
May  2 20:28:12.724: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
May  2 20:28:14.732: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the pod with lifecycle hook
May  2 20:28:14.843: INFO: The status of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
May  2 20:28:16.863: INFO: The status of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
May  2 20:28:18.859: INFO: The status of Pod pod-with-prestop-exec-hook is Running (Ready = true)
STEP: delete the pod with lifecycle hook
May  2 20:28:18.891: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May  2 20:28:18.909: INFO: Pod pod-with-prestop-exec-hook still exists
May  2 20:28:20.910: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May  2 20:28:20.935: INFO: Pod pod-with-prestop-exec-hook still exists
May  2 20:28:22.910: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May  2 20:28:22.921: INFO: Pod pod-with-prestop-exec-hook still exists
May  2 20:28:24.909: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May  2 20:28:24.934: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:28:24.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-451" for this suite.


• [SLOW TEST:14.672 seconds]
[sig-node] Container Lifecycle Hook
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:43
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":-1,"completed":109,"skipped":1871,"failed":0}

SSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:28:25.106: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check is all data is printed  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:28:25.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=kubectl-1075 version'
May  2 20:28:25.356: INFO: stderr: ""
May  2 20:28:25.357: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"22\", GitVersion:\"v1.22.5\", GitCommit:\"5c99e2ac2ff9a3c549d9ca665e7bc05a3e18f07e\", GitTreeState:\"clean\", BuildDate:\"2021-12-16T08:38:33Z\", GoVersion:\"go1.16.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"22\", GitVersion:\"v1.22.5\", GitCommit:\"5c99e2ac2ff9a3c549d9ca665e7bc05a3e18f07e\", GitTreeState:\"clean\", BuildDate:\"2021-12-16T08:32:32Z\", GoVersion:\"go1.16.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:28:25.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1075" for this suite.

•
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":-1,"completed":110,"skipped":1887,"failed":0}

SSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:28:25.503: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0777 on tmpfs
May  2 20:28:25.707: INFO: Waiting up to 5m0s for pod "pod-7a9ca25a-49ed-4865-aa21-eda8f5e3c778" in namespace "emptydir-8582" to be "Succeeded or Failed"
May  2 20:28:25.715: INFO: Pod "pod-7a9ca25a-49ed-4865-aa21-eda8f5e3c778": Phase="Pending", Reason="", readiness=false. Elapsed: 8.526976ms
May  2 20:28:27.745: INFO: Pod "pod-7a9ca25a-49ed-4865-aa21-eda8f5e3c778": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038727003s
May  2 20:28:29.778: INFO: Pod "pod-7a9ca25a-49ed-4865-aa21-eda8f5e3c778": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.07188522s
STEP: Saw pod success
May  2 20:28:29.779: INFO: Pod "pod-7a9ca25a-49ed-4865-aa21-eda8f5e3c778" satisfied condition "Succeeded or Failed"
May  2 20:28:29.786: INFO: Trying to get logs from node node-2 pod pod-7a9ca25a-49ed-4865-aa21-eda8f5e3c778 container test-container: <nil>
STEP: delete the pod
May  2 20:28:29.872: INFO: Waiting for pod pod-7a9ca25a-49ed-4865-aa21-eda8f5e3c778 to disappear
May  2 20:28:29.885: INFO: Pod pod-7a9ca25a-49ed-4865-aa21-eda8f5e3c778 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:28:29.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8582" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":111,"skipped":1905,"failed":0}

SSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-network] Ingress API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:28:30.021: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename ingress
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support creating Ingress API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting /apis
STEP: getting /apis/networking.k8s.io
STEP: getting /apis/networking.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
May  2 20:28:30.343: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
May  2 20:28:30.393: INFO: starting watch
STEP: patching
STEP: updating
May  2 20:28:30.465: INFO: waiting for watch events with expected annotations
May  2 20:28:30.465: INFO: saw patched and updated annotations
STEP: patching /status
STEP: updating /status
STEP: get /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] Ingress API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:28:30.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-3949" for this suite.

•
------------------------------
{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","total":-1,"completed":112,"skipped":1917,"failed":0}

SSSSSSSS
------------------------------
[BeforeEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:28:30.847: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap configmap-9010/configmap-test-c5240a98-2040-4948-8adb-5d19789cf4f9
STEP: Creating a pod to test consume configMaps
May  2 20:28:31.073: INFO: Waiting up to 5m0s for pod "pod-configmaps-484bc268-3cba-48a2-90f0-535180441518" in namespace "configmap-9010" to be "Succeeded or Failed"
May  2 20:28:31.128: INFO: Pod "pod-configmaps-484bc268-3cba-48a2-90f0-535180441518": Phase="Pending", Reason="", readiness=false. Elapsed: 55.181656ms
May  2 20:28:33.162: INFO: Pod "pod-configmaps-484bc268-3cba-48a2-90f0-535180441518": Phase="Pending", Reason="", readiness=false. Elapsed: 2.089424227s
May  2 20:28:35.173: INFO: Pod "pod-configmaps-484bc268-3cba-48a2-90f0-535180441518": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.100143913s
STEP: Saw pod success
May  2 20:28:35.173: INFO: Pod "pod-configmaps-484bc268-3cba-48a2-90f0-535180441518" satisfied condition "Succeeded or Failed"
May  2 20:28:35.189: INFO: Trying to get logs from node node-2 pod pod-configmaps-484bc268-3cba-48a2-90f0-535180441518 container env-test: <nil>
STEP: delete the pod
May  2 20:28:35.364: INFO: Waiting for pod pod-configmaps-484bc268-3cba-48a2-90f0-535180441518 to disappear
May  2 20:28:35.415: INFO: Pod pod-configmaps-484bc268-3cba-48a2-90f0-535180441518 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:28:35.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9010" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":-1,"completed":113,"skipped":1925,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:28:20.171: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:28:20.336: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
May  2 20:28:45.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=crd-publish-openapi-3566 --namespace=crd-publish-openapi-3566 create -f -'
May  2 20:28:47.635: INFO: stderr: ""
May  2 20:28:47.635: INFO: stdout: "e2e-test-crd-publish-openapi-2957-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
May  2 20:28:47.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=crd-publish-openapi-3566 --namespace=crd-publish-openapi-3566 delete e2e-test-crd-publish-openapi-2957-crds test-foo'
May  2 20:28:47.827: INFO: stderr: ""
May  2 20:28:47.827: INFO: stdout: "e2e-test-crd-publish-openapi-2957-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
May  2 20:28:47.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=crd-publish-openapi-3566 --namespace=crd-publish-openapi-3566 apply -f -'
May  2 20:28:49.368: INFO: stderr: ""
May  2 20:28:49.368: INFO: stdout: "e2e-test-crd-publish-openapi-2957-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
May  2 20:28:49.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=crd-publish-openapi-3566 --namespace=crd-publish-openapi-3566 delete e2e-test-crd-publish-openapi-2957-crds test-foo'
May  2 20:28:49.518: INFO: stderr: ""
May  2 20:28:49.518: INFO: stdout: "e2e-test-crd-publish-openapi-2957-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
May  2 20:28:49.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=crd-publish-openapi-3566 --namespace=crd-publish-openapi-3566 create -f -'
May  2 20:28:50.914: INFO: rc: 1
May  2 20:28:50.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=crd-publish-openapi-3566 --namespace=crd-publish-openapi-3566 apply -f -'
May  2 20:28:51.382: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
May  2 20:28:51.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=crd-publish-openapi-3566 --namespace=crd-publish-openapi-3566 create -f -'
May  2 20:28:51.794: INFO: rc: 1
May  2 20:28:51.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=crd-publish-openapi-3566 --namespace=crd-publish-openapi-3566 apply -f -'
May  2 20:28:52.286: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
May  2 20:28:52.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=crd-publish-openapi-3566 explain e2e-test-crd-publish-openapi-2957-crds'
May  2 20:28:52.773: INFO: stderr: ""
May  2 20:28:52.774: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2957-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
May  2 20:28:52.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=crd-publish-openapi-3566 explain e2e-test-crd-publish-openapi-2957-crds.metadata'
May  2 20:28:53.154: INFO: stderr: ""
May  2 20:28:53.154: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2957-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     NOT return a 409 - instead, it will either return 201 Created or 500 with\n     Reason ServerTimeout indicating a unique name could not be found in the\n     time allotted, and the client should retry (optionally after the time\n     indicated in the Retry-After header).\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only.\n\n     DEPRECATED Kubernetes will stop propagating this field in 1.20 release and\n     the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
May  2 20:28:53.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=crd-publish-openapi-3566 explain e2e-test-crd-publish-openapi-2957-crds.spec'
May  2 20:28:53.670: INFO: stderr: ""
May  2 20:28:53.670: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2957-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
May  2 20:28:53.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=crd-publish-openapi-3566 explain e2e-test-crd-publish-openapi-2957-crds.spec.bars'
May  2 20:28:54.049: INFO: stderr: ""
May  2 20:28:54.049: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2957-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
May  2 20:28:54.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=crd-publish-openapi-3566 explain e2e-test-crd-publish-openapi-2957-crds.spec.bars2'
May  2 20:28:54.397: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:29:14.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3566" for this suite.


• [SLOW TEST:54.389 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":-1,"completed":123,"skipped":2114,"failed":0}

SS
------------------------------
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:29:14.569: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/security_context.go:46
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:29:14.679: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-cb812917-4131-4b44-aabb-4e82c9ebee82" in namespace "security-context-test-7472" to be "Succeeded or Failed"
May  2 20:29:14.704: INFO: Pod "busybox-readonly-false-cb812917-4131-4b44-aabb-4e82c9ebee82": Phase="Pending", Reason="", readiness=false. Elapsed: 25.281498ms
May  2 20:29:16.714: INFO: Pod "busybox-readonly-false-cb812917-4131-4b44-aabb-4e82c9ebee82": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034833785s
May  2 20:29:18.730: INFO: Pod "busybox-readonly-false-cb812917-4131-4b44-aabb-4e82c9ebee82": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051189219s
May  2 20:29:18.730: INFO: Pod "busybox-readonly-false-cb812917-4131-4b44-aabb-4e82c9ebee82" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:29:18.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7472" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":-1,"completed":124,"skipped":2116,"failed":0}

SSS
------------------------------
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:29:18.771: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:188
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:29:18.955: INFO: The status of Pod server-envvars-2dfd4c82-02fb-4a9c-a7da-31cb92dd199e is Pending, waiting for it to be Running (with Ready = true)
May  2 20:29:20.970: INFO: The status of Pod server-envvars-2dfd4c82-02fb-4a9c-a7da-31cb92dd199e is Pending, waiting for it to be Running (with Ready = true)
May  2 20:29:22.973: INFO: The status of Pod server-envvars-2dfd4c82-02fb-4a9c-a7da-31cb92dd199e is Running (Ready = true)
May  2 20:29:23.066: INFO: Waiting up to 5m0s for pod "client-envvars-4401b416-bb06-4289-9021-0904bf0201cb" in namespace "pods-1182" to be "Succeeded or Failed"
May  2 20:29:23.106: INFO: Pod "client-envvars-4401b416-bb06-4289-9021-0904bf0201cb": Phase="Pending", Reason="", readiness=false. Elapsed: 40.056185ms
May  2 20:29:25.123: INFO: Pod "client-envvars-4401b416-bb06-4289-9021-0904bf0201cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056613597s
May  2 20:29:27.141: INFO: Pod "client-envvars-4401b416-bb06-4289-9021-0904bf0201cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.074819266s
STEP: Saw pod success
May  2 20:29:27.141: INFO: Pod "client-envvars-4401b416-bb06-4289-9021-0904bf0201cb" satisfied condition "Succeeded or Failed"
May  2 20:29:27.162: INFO: Trying to get logs from node node-2 pod client-envvars-4401b416-bb06-4289-9021-0904bf0201cb container env3cont: <nil>
STEP: delete the pod
May  2 20:29:27.267: INFO: Waiting for pod client-envvars-4401b416-bb06-4289-9021-0904bf0201cb to disappear
May  2 20:29:27.279: INFO: Pod client-envvars-4401b416-bb06-4289-9021-0904bf0201cb no longer exists
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:29:27.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1182" for this suite.


• [SLOW TEST:8.543 seconds]
[sig-node] Pods
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":-1,"completed":125,"skipped":2119,"failed":0}

S
------------------------------
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:29:27.350: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:29:29.509: INFO: Deleting pod "var-expansion-27cde14e-932c-46a4-a5e1-3e038652f25b" in namespace "var-expansion-5414"
May  2 20:29:29.537: INFO: Wait up to 5m0s for pod "var-expansion-27cde14e-932c-46a4-a5e1-3e038652f25b" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:29:35.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5414" for this suite.


• [SLOW TEST:8.269 seconds]
[sig-node] Variable Expansion
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","total":-1,"completed":126,"skipped":2120,"failed":0}

SSSSS
------------------------------
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:29:35.649: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting the auto-created API token
STEP: reading a file in the container
May  2 20:29:40.353: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1063 pod-service-account-481155d1-cd9b-42f1-aee5-899357fea9c1 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
May  2 20:29:40.775: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1063 pod-service-account-481155d1-cd9b-42f1-aee5-899357fea9c1 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
May  2 20:29:41.194: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1063 pod-service-account-481155d1-cd9b-42f1-aee5-899357fea9c1 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:29:41.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1063" for this suite.


• [SLOW TEST:5.994 seconds]
[sig-auth] ServiceAccounts
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":-1,"completed":127,"skipped":2125,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:29:41.823: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-2850, will wait for the garbage collector to delete the pods
May  2 20:29:46.128: INFO: Deleting Job.batch foo took: 19.778036ms
May  2 20:29:46.329: INFO: Terminating Job.batch foo pods took: 200.585183ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:30:19.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2850" for this suite.


• [SLOW TEST:37.651 seconds]
[sig-apps] Job
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":-1,"completed":128,"skipped":2194,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:30:19.503: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name cm-test-opt-del-b02f2893-bc61-43b4-bddb-374e77d311bf
STEP: Creating configMap with name cm-test-opt-upd-2c0fa9de-c9b4-4632-a95c-08539b71200a
STEP: Creating the pod
May  2 20:30:19.691: INFO: The status of Pod pod-configmaps-ac366e3f-4c66-4dd2-82e0-cfb7aedfbbab is Pending, waiting for it to be Running (with Ready = true)
May  2 20:30:21.726: INFO: The status of Pod pod-configmaps-ac366e3f-4c66-4dd2-82e0-cfb7aedfbbab is Pending, waiting for it to be Running (with Ready = true)
May  2 20:30:23.702: INFO: The status of Pod pod-configmaps-ac366e3f-4c66-4dd2-82e0-cfb7aedfbbab is Running (Ready = true)
STEP: Deleting configmap cm-test-opt-del-b02f2893-bc61-43b4-bddb-374e77d311bf
STEP: Updating configmap cm-test-opt-upd-2c0fa9de-c9b4-4632-a95c-08539b71200a
STEP: Creating configMap with name cm-test-opt-create-59a25af0-2b5a-487b-8aa2-b210b1a76384
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:30:25.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8592" for this suite.


• [SLOW TEST:6.484 seconds]
[sig-storage] ConfigMap
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":-1,"completed":129,"skipped":2218,"failed":0}

SSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:30:26.009: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-map-5fd4d1d1-cb8d-438c-b8a0-53e904a34a7b
STEP: Creating a pod to test consume configMaps
May  2 20:30:26.236: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8d4d220c-1d7a-458e-a06c-633df6b8926a" in namespace "projected-2240" to be "Succeeded or Failed"
May  2 20:30:26.246: INFO: Pod "pod-projected-configmaps-8d4d220c-1d7a-458e-a06c-633df6b8926a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.903125ms
May  2 20:30:28.274: INFO: Pod "pod-projected-configmaps-8d4d220c-1d7a-458e-a06c-633df6b8926a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038630011s
May  2 20:30:30.302: INFO: Pod "pod-projected-configmaps-8d4d220c-1d7a-458e-a06c-633df6b8926a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.066388139s
STEP: Saw pod success
May  2 20:30:30.302: INFO: Pod "pod-projected-configmaps-8d4d220c-1d7a-458e-a06c-633df6b8926a" satisfied condition "Succeeded or Failed"
May  2 20:30:30.324: INFO: Trying to get logs from node node-2 pod pod-projected-configmaps-8d4d220c-1d7a-458e-a06c-633df6b8926a container agnhost-container: <nil>
STEP: delete the pod
May  2 20:30:30.400: INFO: Waiting for pod pod-projected-configmaps-8d4d220c-1d7a-458e-a06c-633df6b8926a to disappear
May  2 20:30:30.408: INFO: Pod pod-projected-configmaps-8d4d220c-1d7a-458e-a06c-633df6b8926a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:30:30.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2240" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":-1,"completed":130,"skipped":2231,"failed":0}

SSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:30:30.481: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting the auto-created API token
May  2 20:30:31.206: INFO: created pod pod-service-account-defaultsa
May  2 20:30:31.206: INFO: pod pod-service-account-defaultsa service account token volume mount: true
May  2 20:30:31.235: INFO: created pod pod-service-account-mountsa
May  2 20:30:31.235: INFO: pod pod-service-account-mountsa service account token volume mount: true
May  2 20:30:31.264: INFO: created pod pod-service-account-nomountsa
May  2 20:30:31.265: INFO: pod pod-service-account-nomountsa service account token volume mount: false
May  2 20:30:31.284: INFO: created pod pod-service-account-defaultsa-mountspec
May  2 20:30:31.284: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
May  2 20:30:31.317: INFO: created pod pod-service-account-mountsa-mountspec
May  2 20:30:31.317: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
May  2 20:30:31.378: INFO: created pod pod-service-account-nomountsa-mountspec
May  2 20:30:31.378: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
May  2 20:30:31.405: INFO: created pod pod-service-account-defaultsa-nomountspec
May  2 20:30:31.405: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
May  2 20:30:31.418: INFO: created pod pod-service-account-mountsa-nomountspec
May  2 20:30:31.418: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
May  2 20:30:31.447: INFO: created pod pod-service-account-nomountsa-nomountspec
May  2 20:30:31.447: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:30:31.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-307" for this suite.

•
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":-1,"completed":131,"skipped":2250,"failed":0}

SSSSS
------------------------------
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:30:31.601: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  2 20:30:33.695: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-78988fc6cd\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
May  2 20:30:35.717: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  2 20:30:37.714: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  2 20:30:39.735: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  2 20:30:41.708: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  2 20:30:43.706: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  2 20:30:45.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120233, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  2 20:30:48.746: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
May  2 20:30:48.821: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:30:48.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9137" for this suite.
STEP: Destroying namespace "webhook-9137-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102


• [SLOW TEST:17.491 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":-1,"completed":132,"skipped":2255,"failed":0}

SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:30:49.389: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
May  2 20:30:50.896: INFO: The status of Pod kube-controller-manager-node-2 is Running (Ready = true)
May  2 20:30:51.181: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:30:51.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4190" for this suite.

•
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":-1,"completed":133,"skipped":2277,"failed":0}

SSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:28:35.598: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:54
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod test-webserver-a462095e-26b6-4b65-9f03-8805bb58ec21 in namespace container-probe-3867
May  2 20:28:40.225: INFO: Started pod test-webserver-a462095e-26b6-4b65-9f03-8805bb58ec21 in namespace container-probe-3867
STEP: checking the pod's current state and verifying that restartCount is present
May  2 20:28:40.236: INFO: Initial restart count of pod test-webserver-a462095e-26b6-4b65-9f03-8805bb58ec21 is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:32:40.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3867" for this suite.


• [SLOW TEST:244.913 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":-1,"completed":114,"skipped":1952,"failed":0}

SSSS
------------------------------
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:32:40.590: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:32:40.760: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: creating replication controller svc-latency-rc in namespace svc-latency-4419
I0502 20:32:40.854441      19 runners.go:190] Created replication controller with name: svc-latency-rc, namespace: svc-latency-4419, replica count: 1
I0502 20:32:41.947431      19 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0502 20:32:42.947939      19 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0502 20:32:43.948435      19 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  2 20:32:44.081: INFO: Created: latency-svc-4vlsb
May  2 20:32:44.108: INFO: Got endpoints: latency-svc-4vlsb [58.964827ms]
May  2 20:32:44.144: INFO: Created: latency-svc-stfp8
May  2 20:32:44.164: INFO: Created: latency-svc-bvffr
May  2 20:32:44.176: INFO: Got endpoints: latency-svc-stfp8 [67.198116ms]
May  2 20:32:44.190: INFO: Created: latency-svc-cph6n
May  2 20:32:44.197: INFO: Got endpoints: latency-svc-bvffr [88.410318ms]
May  2 20:32:44.218: INFO: Created: latency-svc-6rxbr
May  2 20:32:44.234: INFO: Got endpoints: latency-svc-cph6n [125.34689ms]
May  2 20:32:44.249: INFO: Created: latency-svc-h8zrj
May  2 20:32:44.258: INFO: Got endpoints: latency-svc-6rxbr [148.867141ms]
May  2 20:32:44.273: INFO: Got endpoints: latency-svc-h8zrj [163.688474ms]
May  2 20:32:44.296: INFO: Created: latency-svc-c8tnc
May  2 20:32:44.316: INFO: Got endpoints: latency-svc-c8tnc [206.929404ms]
May  2 20:32:44.316: INFO: Created: latency-svc-7226p
May  2 20:32:44.338: INFO: Got endpoints: latency-svc-7226p [228.776893ms]
May  2 20:32:44.339: INFO: Created: latency-svc-q7xw8
May  2 20:32:44.361: INFO: Created: latency-svc-t5z9p
May  2 20:32:44.370: INFO: Got endpoints: latency-svc-q7xw8 [260.805744ms]
May  2 20:32:44.384: INFO: Got endpoints: latency-svc-t5z9p [274.14911ms]
May  2 20:32:44.394: INFO: Created: latency-svc-wlbtd
May  2 20:32:44.408: INFO: Created: latency-svc-wfqzn
May  2 20:32:44.417: INFO: Got endpoints: latency-svc-wlbtd [307.439578ms]
May  2 20:32:44.430: INFO: Got endpoints: latency-svc-wfqzn [320.403494ms]
May  2 20:32:44.431: INFO: Created: latency-svc-4tpcc
May  2 20:32:44.449: INFO: Created: latency-svc-m9gh8
May  2 20:32:44.466: INFO: Got endpoints: latency-svc-4tpcc [356.995062ms]
May  2 20:32:44.465: INFO: Created: latency-svc-6n7jj
May  2 20:32:44.493: INFO: Created: latency-svc-5lrlc
May  2 20:32:44.503: INFO: Got endpoints: latency-svc-m9gh8 [394.048312ms]
May  2 20:32:44.507: INFO: Got endpoints: latency-svc-5lrlc [397.66928ms]
May  2 20:32:44.508: INFO: Got endpoints: latency-svc-6n7jj [398.359499ms]
May  2 20:32:44.508: INFO: Created: latency-svc-bg5pf
May  2 20:32:44.524: INFO: Created: latency-svc-6hz4t
May  2 20:32:44.551: INFO: Got endpoints: latency-svc-6hz4t [375.421685ms]
May  2 20:32:44.565: INFO: Got endpoints: latency-svc-bg5pf [98.889067ms]
May  2 20:32:44.571: INFO: Created: latency-svc-rvxdr
May  2 20:32:44.581: INFO: Got endpoints: latency-svc-rvxdr [384.341564ms]
May  2 20:32:44.582: INFO: Created: latency-svc-lzkf7
May  2 20:32:44.591: INFO: Created: latency-svc-9bzxq
May  2 20:32:44.618: INFO: Created: latency-svc-wmn2v
May  2 20:32:44.618: INFO: Got endpoints: latency-svc-lzkf7 [384.003835ms]
May  2 20:32:44.628: INFO: Created: latency-svc-cr64k
May  2 20:32:44.632: INFO: Got endpoints: latency-svc-wmn2v [359.210518ms]
May  2 20:32:44.632: INFO: Got endpoints: latency-svc-9bzxq [374.490028ms]
May  2 20:32:44.647: INFO: Got endpoints: latency-svc-cr64k [331.277069ms]
May  2 20:32:44.652: INFO: Created: latency-svc-gfbvd
May  2 20:32:44.661: INFO: Got endpoints: latency-svc-gfbvd [322.817129ms]
May  2 20:32:44.666: INFO: Created: latency-svc-jx9m5
May  2 20:32:44.700: INFO: Got endpoints: latency-svc-jx9m5 [327.775433ms]
May  2 20:32:44.722: INFO: Created: latency-svc-lfnvm
May  2 20:32:44.732: INFO: Got endpoints: latency-svc-lfnvm [347.226769ms]
May  2 20:32:44.734: INFO: Created: latency-svc-ng8bq
May  2 20:32:44.755: INFO: Got endpoints: latency-svc-ng8bq [338.286522ms]
May  2 20:32:44.772: INFO: Created: latency-svc-tf7kp
May  2 20:32:44.796: INFO: Got endpoints: latency-svc-tf7kp [365.928017ms]
May  2 20:32:44.802: INFO: Created: latency-svc-zlvpt
May  2 20:32:44.813: INFO: Got endpoints: latency-svc-zlvpt [306.043351ms]
May  2 20:32:44.814: INFO: Created: latency-svc-rxw82
May  2 20:32:44.837: INFO: Got endpoints: latency-svc-rxw82 [329.630997ms]
May  2 20:32:44.843: INFO: Created: latency-svc-ttz5b
May  2 20:32:44.867: INFO: Got endpoints: latency-svc-ttz5b [363.146214ms]
May  2 20:32:44.870: INFO: Created: latency-svc-xvcvd
May  2 20:32:44.889: INFO: Created: latency-svc-8m4bk
May  2 20:32:44.889: INFO: Got endpoints: latency-svc-xvcvd [331.162016ms]
May  2 20:32:44.906: INFO: Created: latency-svc-rsgqc
May  2 20:32:44.928: INFO: Got endpoints: latency-svc-8m4bk [360.479204ms]
May  2 20:32:44.936: INFO: Created: latency-svc-hjr2m
May  2 20:32:44.957: INFO: Got endpoints: latency-svc-rsgqc [375.912883ms]
May  2 20:32:44.975: INFO: Got endpoints: latency-svc-hjr2m [357.27763ms]
May  2 20:32:44.992: INFO: Created: latency-svc-xswl8
May  2 20:32:45.025: INFO: Got endpoints: latency-svc-xswl8 [392.684728ms]
May  2 20:32:45.045: INFO: Created: latency-svc-xk9w4
May  2 20:32:45.107: INFO: Got endpoints: latency-svc-xk9w4 [471.146827ms]
May  2 20:32:45.108: INFO: Created: latency-svc-5mkzq
May  2 20:32:45.128: INFO: Got endpoints: latency-svc-5mkzq [478.798449ms]
May  2 20:32:45.156: INFO: Created: latency-svc-kmt4t
May  2 20:32:45.175: INFO: Created: latency-svc-bdsd5
May  2 20:32:45.179: INFO: Got endpoints: latency-svc-kmt4t [517.732229ms]
May  2 20:32:45.212: INFO: Got endpoints: latency-svc-bdsd5 [510.468832ms]
May  2 20:32:45.241: INFO: Created: latency-svc-zcmsd
May  2 20:32:45.259: INFO: Got endpoints: latency-svc-zcmsd [526.689588ms]
May  2 20:32:45.280: INFO: Created: latency-svc-qvjrq
May  2 20:32:45.281: INFO: Created: latency-svc-r9qbq
May  2 20:32:45.299: INFO: Got endpoints: latency-svc-qvjrq [543.961395ms]
May  2 20:32:45.305: INFO: Created: latency-svc-q2tcs
May  2 20:32:45.312: INFO: Got endpoints: latency-svc-r9qbq [516.091717ms]
May  2 20:32:45.327: INFO: Got endpoints: latency-svc-q2tcs [512.862269ms]
May  2 20:32:45.342: INFO: Created: latency-svc-ctttv
May  2 20:32:45.342: INFO: Created: latency-svc-r7gsf
May  2 20:32:45.364: INFO: Got endpoints: latency-svc-r7gsf [496.75219ms]
May  2 20:32:45.375: INFO: Got endpoints: latency-svc-ctttv [537.520245ms]
May  2 20:32:45.379: INFO: Created: latency-svc-gtbll
May  2 20:32:45.393: INFO: Got endpoints: latency-svc-gtbll [504.164165ms]
May  2 20:32:45.413: INFO: Created: latency-svc-flrc4
May  2 20:32:45.432: INFO: Created: latency-svc-96m45
May  2 20:32:45.432: INFO: Got endpoints: latency-svc-96m45 [503.912075ms]
May  2 20:32:45.433: INFO: Got endpoints: latency-svc-flrc4 [475.67017ms]
May  2 20:32:45.447: INFO: Created: latency-svc-jdbmt
May  2 20:32:45.474: INFO: Got endpoints: latency-svc-jdbmt [498.534535ms]
May  2 20:32:45.471: INFO: Created: latency-svc-lsh6q
May  2 20:32:45.486: INFO: Got endpoints: latency-svc-lsh6q [461.203738ms]
May  2 20:32:45.488: INFO: Created: latency-svc-ldh5s
May  2 20:32:45.511: INFO: Got endpoints: latency-svc-ldh5s [403.863202ms]
May  2 20:32:45.521: INFO: Created: latency-svc-splfb
May  2 20:32:45.546: INFO: Got endpoints: latency-svc-splfb [418.136594ms]
May  2 20:32:45.546: INFO: Created: latency-svc-r2wtm
May  2 20:32:45.558: INFO: Created: latency-svc-qpbqv
May  2 20:32:45.570: INFO: Created: latency-svc-9mkrd
May  2 20:32:45.581: INFO: Got endpoints: latency-svc-qpbqv [369.030296ms]
May  2 20:32:45.581: INFO: Got endpoints: latency-svc-r2wtm [402.413786ms]
May  2 20:32:45.590: INFO: Created: latency-svc-5ls7s
May  2 20:32:45.603: INFO: Created: latency-svc-tn9q5
May  2 20:32:45.612: INFO: Got endpoints: latency-svc-9mkrd [353.411774ms]
May  2 20:32:45.616: INFO: Got endpoints: latency-svc-5ls7s [303.654021ms]
May  2 20:32:45.624: INFO: Created: latency-svc-x7864
May  2 20:32:45.637: INFO: Got endpoints: latency-svc-tn9q5 [337.676415ms]
May  2 20:32:45.690: INFO: Created: latency-svc-zpxxc
May  2 20:32:45.690: INFO: Created: latency-svc-qw8nc
May  2 20:32:45.690: INFO: Created: latency-svc-wfc6d
May  2 20:32:45.691: INFO: Got endpoints: latency-svc-wfc6d [315.079096ms]
May  2 20:32:45.693: INFO: Got endpoints: latency-svc-x7864 [366.312724ms]
May  2 20:32:45.690: INFO: Got endpoints: latency-svc-zpxxc [326.730243ms]
May  2 20:32:45.707: INFO: Created: latency-svc-fx7bn
May  2 20:32:45.741: INFO: Got endpoints: latency-svc-qw8nc [347.145818ms]
May  2 20:32:45.745: INFO: Created: latency-svc-hxxtg
May  2 20:32:45.768: INFO: Created: latency-svc-j9qw5
May  2 20:32:45.768: INFO: Created: latency-svc-sqq5k
May  2 20:32:45.784: INFO: Got endpoints: latency-svc-fx7bn [351.139262ms]
May  2 20:32:45.794: INFO: Created: latency-svc-nghvj
May  2 20:32:45.812: INFO: Got endpoints: latency-svc-hxxtg [378.851397ms]
May  2 20:32:45.823: INFO: Created: latency-svc-jxglc
May  2 20:32:45.882: INFO: Created: latency-svc-kgcmx
May  2 20:32:45.882: INFO: Got endpoints: latency-svc-sqq5k [408.103708ms]
May  2 20:32:45.885: INFO: Created: latency-svc-p7cwn
May  2 20:32:45.883: INFO: Created: latency-svc-hr47q
May  2 20:32:45.904: INFO: Created: latency-svc-zfndm
May  2 20:32:45.913: INFO: Got endpoints: latency-svc-j9qw5 [427.090006ms]
May  2 20:32:45.925: INFO: Created: latency-svc-pgf6m
May  2 20:32:45.945: INFO: Created: latency-svc-vhlzj
May  2 20:32:45.956: INFO: Created: latency-svc-2bf9q
May  2 20:32:45.990: INFO: Got endpoints: latency-svc-nghvj [479.549742ms]
May  2 20:32:45.999: INFO: Created: latency-svc-qtjsz
May  2 20:32:46.046: INFO: Got endpoints: latency-svc-jxglc [499.999231ms]
May  2 20:32:46.054: INFO: Created: latency-svc-jz86j
May  2 20:32:46.084: INFO: Created: latency-svc-6wg6r
May  2 20:32:46.086: INFO: Got endpoints: latency-svc-kgcmx [505.489208ms]
May  2 20:32:46.129: INFO: Got endpoints: latency-svc-p7cwn [547.850966ms]
May  2 20:32:46.160: INFO: Created: latency-svc-d8mr2
May  2 20:32:46.179: INFO: Got endpoints: latency-svc-hr47q [566.938724ms]
May  2 20:32:46.207: INFO: Created: latency-svc-vnbh2
May  2 20:32:46.234: INFO: Got endpoints: latency-svc-zfndm [617.050577ms]
May  2 20:32:46.262: INFO: Created: latency-svc-frl7f
May  2 20:32:46.286: INFO: Got endpoints: latency-svc-pgf6m [648.867925ms]
May  2 20:32:46.287: INFO: Created: latency-svc-ctvhj
May  2 20:32:46.318: INFO: Got endpoints: latency-svc-vhlzj [624.733527ms]
May  2 20:32:46.318: INFO: Created: latency-svc-gbnlt
May  2 20:32:46.337: INFO: Created: latency-svc-wlh44
May  2 20:32:46.351: INFO: Created: latency-svc-lwd2t
May  2 20:32:46.359: INFO: Got endpoints: latency-svc-2bf9q [667.882625ms]
May  2 20:32:46.371: INFO: Created: latency-svc-4nz4q
May  2 20:32:46.381: INFO: Created: latency-svc-xvttr
May  2 20:32:46.394: INFO: Created: latency-svc-sfctl
May  2 20:32:46.415: INFO: Got endpoints: latency-svc-qtjsz [710.995576ms]
May  2 20:32:46.417: INFO: Created: latency-svc-9pqml
May  2 20:32:46.431: INFO: Created: latency-svc-gf5j2
May  2 20:32:46.460: INFO: Created: latency-svc-5z55f
May  2 20:32:46.462: INFO: Got endpoints: latency-svc-jz86j [721.742145ms]
May  2 20:32:46.505: INFO: Created: latency-svc-tm2sp
May  2 20:32:46.513: INFO: Got endpoints: latency-svc-6wg6r [729.068539ms]
May  2 20:32:46.549: INFO: Created: latency-svc-d9jvd
May  2 20:32:46.563: INFO: Got endpoints: latency-svc-d8mr2 [750.446551ms]
May  2 20:32:46.586: INFO: Created: latency-svc-dnhpc
May  2 20:32:46.605: INFO: Got endpoints: latency-svc-vnbh2 [720.964303ms]
May  2 20:32:46.638: INFO: Created: latency-svc-wcxpq
May  2 20:32:46.658: INFO: Got endpoints: latency-svc-frl7f [745.115732ms]
May  2 20:32:46.684: INFO: Created: latency-svc-4qq2g
May  2 20:32:46.707: INFO: Got endpoints: latency-svc-ctvhj [716.421824ms]
May  2 20:32:46.741: INFO: Created: latency-svc-6l7fj
May  2 20:32:46.760: INFO: Got endpoints: latency-svc-gbnlt [713.335444ms]
May  2 20:32:46.815: INFO: Created: latency-svc-f24qr
May  2 20:32:46.815: INFO: Got endpoints: latency-svc-wlh44 [728.677388ms]
May  2 20:32:46.852: INFO: Created: latency-svc-wt4bd
May  2 20:32:46.859: INFO: Got endpoints: latency-svc-lwd2t [729.968699ms]
May  2 20:32:46.891: INFO: Created: latency-svc-s8q25
May  2 20:32:46.920: INFO: Got endpoints: latency-svc-4nz4q [741.11794ms]
May  2 20:32:46.970: INFO: Got endpoints: latency-svc-xvttr [736.534935ms]
May  2 20:32:46.971: INFO: Created: latency-svc-725tt
May  2 20:32:47.001: INFO: Created: latency-svc-qpj68
May  2 20:32:47.048: INFO: Got endpoints: latency-svc-sfctl [762.27042ms]
May  2 20:32:47.066: INFO: Got endpoints: latency-svc-9pqml [748.466086ms]
May  2 20:32:47.103: INFO: Created: latency-svc-7t7vf
May  2 20:32:47.176: INFO: Got endpoints: latency-svc-gf5j2 [816.438505ms]
May  2 20:32:47.178: INFO: Got endpoints: latency-svc-5z55f [763.06303ms]
May  2 20:32:47.182: INFO: Created: latency-svc-fks8z
May  2 20:32:47.211: INFO: Got endpoints: latency-svc-tm2sp [748.25456ms]
May  2 20:32:47.221: INFO: Created: latency-svc-sml9f
May  2 20:32:47.235: INFO: Created: latency-svc-9r942
May  2 20:32:47.273: INFO: Created: latency-svc-ckmjp
May  2 20:32:47.276: INFO: Got endpoints: latency-svc-d9jvd [762.712125ms]
May  2 20:32:47.332: INFO: Got endpoints: latency-svc-dnhpc [769.464117ms]
May  2 20:32:47.381: INFO: Created: latency-svc-c7dfz
May  2 20:32:47.382: INFO: Got endpoints: latency-svc-wcxpq [776.346043ms]
May  2 20:32:47.407: INFO: Created: latency-svc-q4dst
May  2 20:32:47.440: INFO: Created: latency-svc-tg2dr
May  2 20:32:47.441: INFO: Got endpoints: latency-svc-4qq2g [782.472569ms]
May  2 20:32:47.462: INFO: Got endpoints: latency-svc-6l7fj [755.070332ms]
May  2 20:32:47.530: INFO: Got endpoints: latency-svc-f24qr [769.63139ms]
May  2 20:32:47.538: INFO: Created: latency-svc-zqwmm
May  2 20:32:47.568: INFO: Created: latency-svc-vtbvh
May  2 20:32:47.572: INFO: Got endpoints: latency-svc-wt4bd [753.689074ms]
May  2 20:32:47.583: INFO: Created: latency-svc-r6l7n
May  2 20:32:47.619: INFO: Got endpoints: latency-svc-s8q25 [760.080564ms]
May  2 20:32:47.630: INFO: Created: latency-svc-mbq24
May  2 20:32:47.668: INFO: Got endpoints: latency-svc-725tt [747.280752ms]
May  2 20:32:47.668: INFO: Created: latency-svc-8l8n9
May  2 20:32:47.694: INFO: Created: latency-svc-twfn7
May  2 20:32:47.723: INFO: Got endpoints: latency-svc-qpj68 [752.490507ms]
May  2 20:32:47.765: INFO: Got endpoints: latency-svc-7t7vf [716.482838ms]
May  2 20:32:47.768: INFO: Created: latency-svc-4mhx5
May  2 20:32:47.817: INFO: Got endpoints: latency-svc-fks8z [750.892514ms]
May  2 20:32:47.818: INFO: Created: latency-svc-z8bkp
May  2 20:32:47.874: INFO: Got endpoints: latency-svc-sml9f [695.780058ms]
May  2 20:32:47.911: INFO: Created: latency-svc-ln4nf
May  2 20:32:47.927: INFO: Got endpoints: latency-svc-9r942 [750.691329ms]
May  2 20:32:47.957: INFO: Created: latency-svc-sn8bz
May  2 20:32:47.993: INFO: Got endpoints: latency-svc-ckmjp [781.760208ms]
May  2 20:32:48.028: INFO: Created: latency-svc-2klst
May  2 20:32:48.029: INFO: Got endpoints: latency-svc-c7dfz [751.705162ms]
May  2 20:32:48.055: INFO: Got endpoints: latency-svc-q4dst [722.635783ms]
May  2 20:32:48.126: INFO: Created: latency-svc-z9kxn
May  2 20:32:48.127: INFO: Got endpoints: latency-svc-tg2dr [745.832249ms]
May  2 20:32:48.154: INFO: Created: latency-svc-7rt89
May  2 20:32:48.179: INFO: Got endpoints: latency-svc-zqwmm [738.156431ms]
May  2 20:32:48.188: INFO: Created: latency-svc-gkw2b
May  2 20:32:48.250: INFO: Got endpoints: latency-svc-vtbvh [787.710714ms]
May  2 20:32:48.280: INFO: Got endpoints: latency-svc-r6l7n [749.864054ms]
May  2 20:32:48.289: INFO: Created: latency-svc-d2zv2
May  2 20:32:48.316: INFO: Created: latency-svc-vm6v7
May  2 20:32:48.340: INFO: Got endpoints: latency-svc-mbq24 [767.621628ms]
May  2 20:32:48.354: INFO: Created: latency-svc-t6crw
May  2 20:32:48.369: INFO: Got endpoints: latency-svc-8l8n9 [749.461211ms]
May  2 20:32:48.388: INFO: Created: latency-svc-87rrc
May  2 20:32:48.415: INFO: Created: latency-svc-kcv5l
May  2 20:32:48.432: INFO: Got endpoints: latency-svc-twfn7 [764.571185ms]
May  2 20:32:48.433: INFO: Created: latency-svc-rcjcc
May  2 20:32:48.470: INFO: Got endpoints: latency-svc-4mhx5 [745.295957ms]
May  2 20:32:48.471: INFO: Created: latency-svc-ztx2x
May  2 20:32:48.508: INFO: Created: latency-svc-7ptqp
May  2 20:32:48.510: INFO: Got endpoints: latency-svc-z8bkp [744.52638ms]
May  2 20:32:48.548: INFO: Created: latency-svc-k2bsh
May  2 20:32:48.560: INFO: Got endpoints: latency-svc-ln4nf [742.281091ms]
May  2 20:32:48.596: INFO: Created: latency-svc-vzhcz
May  2 20:32:48.611: INFO: Got endpoints: latency-svc-sn8bz [737.374883ms]
May  2 20:32:48.646: INFO: Created: latency-svc-4slg9
May  2 20:32:48.663: INFO: Got endpoints: latency-svc-2klst [735.946927ms]
May  2 20:32:48.691: INFO: Created: latency-svc-4d887
May  2 20:32:48.706: INFO: Got endpoints: latency-svc-z9kxn [713.089984ms]
May  2 20:32:48.740: INFO: Created: latency-svc-lv6lx
May  2 20:32:48.755: INFO: Got endpoints: latency-svc-7rt89 [725.705961ms]
May  2 20:32:48.787: INFO: Created: latency-svc-k8xq2
May  2 20:32:48.818: INFO: Got endpoints: latency-svc-gkw2b [762.520957ms]
May  2 20:32:48.851: INFO: Created: latency-svc-r74lr
May  2 20:32:48.870: INFO: Got endpoints: latency-svc-d2zv2 [742.02379ms]
May  2 20:32:48.928: INFO: Created: latency-svc-xqgdm
May  2 20:32:48.935: INFO: Got endpoints: latency-svc-vm6v7 [755.843634ms]
May  2 20:32:48.975: INFO: Got endpoints: latency-svc-t6crw [724.652215ms]
May  2 20:32:48.989: INFO: Created: latency-svc-wz9jc
May  2 20:32:49.013: INFO: Got endpoints: latency-svc-87rrc [730.248319ms]
May  2 20:32:49.046: INFO: Created: latency-svc-84r79
May  2 20:32:49.074: INFO: Got endpoints: latency-svc-kcv5l [734.549689ms]
May  2 20:32:49.081: INFO: Created: latency-svc-cft5t
May  2 20:32:49.120: INFO: Got endpoints: latency-svc-rcjcc [751.476674ms]
May  2 20:32:49.144: INFO: Created: latency-svc-src2k
May  2 20:32:49.173: INFO: Got endpoints: latency-svc-ztx2x [740.852644ms]
May  2 20:32:49.187: INFO: Created: latency-svc-r4v4d
May  2 20:32:49.226: INFO: Got endpoints: latency-svc-7ptqp [756.208305ms]
May  2 20:32:49.254: INFO: Got endpoints: latency-svc-k2bsh [744.046365ms]
May  2 20:32:49.264: INFO: Created: latency-svc-x5s9j
May  2 20:32:49.313: INFO: Created: latency-svc-95qvv
May  2 20:32:49.328: INFO: Got endpoints: latency-svc-vzhcz [768.38877ms]
May  2 20:32:49.330: INFO: Created: latency-svc-982xv
May  2 20:32:49.377: INFO: Got endpoints: latency-svc-4slg9 [765.669384ms]
May  2 20:32:49.378: INFO: Created: latency-svc-fsxmm
May  2 20:32:49.420: INFO: Got endpoints: latency-svc-4d887 [756.702498ms]
May  2 20:32:49.435: INFO: Created: latency-svc-65sfw
May  2 20:32:49.449: INFO: Created: latency-svc-6nf47
May  2 20:32:49.475: INFO: Got endpoints: latency-svc-lv6lx [768.596155ms]
May  2 20:32:49.504: INFO: Created: latency-svc-fc4j9
May  2 20:32:49.515: INFO: Got endpoints: latency-svc-k8xq2 [759.615464ms]
May  2 20:32:49.551: INFO: Created: latency-svc-zvdn8
May  2 20:32:49.557: INFO: Got endpoints: latency-svc-r74lr [739.249752ms]
May  2 20:32:49.587: INFO: Created: latency-svc-ldqbt
May  2 20:32:49.611: INFO: Got endpoints: latency-svc-xqgdm [741.471748ms]
May  2 20:32:49.641: INFO: Created: latency-svc-c2z9b
May  2 20:32:49.675: INFO: Got endpoints: latency-svc-wz9jc [739.472378ms]
May  2 20:32:49.725: INFO: Created: latency-svc-89t2n
May  2 20:32:49.725: INFO: Got endpoints: latency-svc-84r79 [750.337157ms]
May  2 20:32:49.748: INFO: Created: latency-svc-zqgfd
May  2 20:32:49.779: INFO: Got endpoints: latency-svc-cft5t [765.759123ms]
May  2 20:32:49.812: INFO: Got endpoints: latency-svc-src2k [737.432661ms]
May  2 20:32:49.814: INFO: Created: latency-svc-mqp2c
May  2 20:32:49.850: INFO: Created: latency-svc-nhbdt
May  2 20:32:49.928: INFO: Got endpoints: latency-svc-x5s9j [754.320171ms]
May  2 20:32:49.928: INFO: Got endpoints: latency-svc-r4v4d [807.843222ms]
May  2 20:32:49.964: INFO: Got endpoints: latency-svc-95qvv [709.681343ms]
May  2 20:32:49.972: INFO: Created: latency-svc-w9j9r
May  2 20:32:49.979: INFO: Created: latency-svc-w4vb4
May  2 20:32:49.998: INFO: Created: latency-svc-8mgv8
May  2 20:32:50.031: INFO: Got endpoints: latency-svc-982xv [805.089553ms]
May  2 20:32:50.081: INFO: Got endpoints: latency-svc-fsxmm [752.256419ms]
May  2 20:32:50.085: INFO: Created: latency-svc-thtlx
May  2 20:32:50.124: INFO: Got endpoints: latency-svc-65sfw [746.911543ms]
May  2 20:32:50.125: INFO: Created: latency-svc-bvlh2
May  2 20:32:50.187: INFO: Got endpoints: latency-svc-6nf47 [767.278308ms]
May  2 20:32:50.188: INFO: Created: latency-svc-j9jhl
May  2 20:32:50.227: INFO: Got endpoints: latency-svc-fc4j9 [751.989823ms]
May  2 20:32:50.276: INFO: Created: latency-svc-l544x
May  2 20:32:50.276: INFO: Got endpoints: latency-svc-zvdn8 [760.388498ms]
May  2 20:32:50.293: INFO: Created: latency-svc-8c2m9
May  2 20:32:50.334: INFO: Got endpoints: latency-svc-ldqbt [776.456621ms]
May  2 20:32:50.359: INFO: Got endpoints: latency-svc-c2z9b [746.151325ms]
May  2 20:32:50.360: INFO: Created: latency-svc-tdsvg
May  2 20:32:50.371: INFO: Created: latency-svc-bczn6
May  2 20:32:50.413: INFO: Got endpoints: latency-svc-89t2n [737.760163ms]
May  2 20:32:50.430: INFO: Created: latency-svc-6mgx9
May  2 20:32:50.490: INFO: Got endpoints: latency-svc-zqgfd [765.024472ms]
May  2 20:32:50.505: INFO: Created: latency-svc-nczpp
May  2 20:32:50.518: INFO: Got endpoints: latency-svc-mqp2c [739.15687ms]
May  2 20:32:50.541: INFO: Created: latency-svc-p2tsj
May  2 20:32:50.574: INFO: Got endpoints: latency-svc-nhbdt [761.994708ms]
May  2 20:32:50.598: INFO: Created: latency-svc-fqn7v
May  2 20:32:50.645: INFO: Got endpoints: latency-svc-w9j9r [717.151507ms]
May  2 20:32:50.646: INFO: Created: latency-svc-bgp8n
May  2 20:32:50.677: INFO: Got endpoints: latency-svc-w4vb4 [748.282793ms]
May  2 20:32:50.710: INFO: Created: latency-svc-jqmlt
May  2 20:32:50.719: INFO: Got endpoints: latency-svc-8mgv8 [754.8167ms]
May  2 20:32:50.750: INFO: Created: latency-svc-2f8bg
May  2 20:32:50.768: INFO: Got endpoints: latency-svc-thtlx [736.586943ms]
May  2 20:32:50.791: INFO: Created: latency-svc-nxsd8
May  2 20:32:50.815: INFO: Got endpoints: latency-svc-bvlh2 [734.321244ms]
May  2 20:32:50.859: INFO: Created: latency-svc-cd5sr
May  2 20:32:50.869: INFO: Got endpoints: latency-svc-j9jhl [744.933823ms]
May  2 20:32:50.872: INFO: Created: latency-svc-52tw2
May  2 20:32:50.902: INFO: Created: latency-svc-4d5wf
May  2 20:32:50.908: INFO: Got endpoints: latency-svc-l544x [719.929701ms]
May  2 20:32:50.933: INFO: Created: latency-svc-br55l
May  2 20:32:50.964: INFO: Got endpoints: latency-svc-8c2m9 [737.108997ms]
May  2 20:32:51.011: INFO: Created: latency-svc-74css
May  2 20:32:51.023: INFO: Got endpoints: latency-svc-tdsvg [747.098922ms]
May  2 20:32:51.066: INFO: Got endpoints: latency-svc-bczn6 [732.721908ms]
May  2 20:32:51.076: INFO: Created: latency-svc-gwkfm
May  2 20:32:51.109: INFO: Got endpoints: latency-svc-6mgx9 [749.608647ms]
May  2 20:32:51.112: INFO: Created: latency-svc-bq8sv
May  2 20:32:51.162: INFO: Got endpoints: latency-svc-nczpp [749.443007ms]
May  2 20:32:51.171: INFO: Created: latency-svc-26ddv
May  2 20:32:51.201: INFO: Created: latency-svc-2vht5
May  2 20:32:51.212: INFO: Got endpoints: latency-svc-p2tsj [721.504219ms]
May  2 20:32:51.242: INFO: Created: latency-svc-5mz5r
May  2 20:32:51.267: INFO: Got endpoints: latency-svc-fqn7v [749.073347ms]
May  2 20:32:51.311: INFO: Created: latency-svc-gcznx
May  2 20:32:51.315: INFO: Got endpoints: latency-svc-bgp8n [740.366346ms]
May  2 20:32:51.356: INFO: Created: latency-svc-96749
May  2 20:32:51.370: INFO: Got endpoints: latency-svc-jqmlt [725.233891ms]
May  2 20:32:51.430: INFO: Got endpoints: latency-svc-2f8bg [753.000528ms]
May  2 20:32:51.434: INFO: Created: latency-svc-c97k4
May  2 20:32:51.460: INFO: Got endpoints: latency-svc-nxsd8 [740.718174ms]
May  2 20:32:51.464: INFO: Created: latency-svc-jr829
May  2 20:32:51.554: INFO: Created: latency-svc-sjqfm
May  2 20:32:51.555: INFO: Got endpoints: latency-svc-cd5sr [786.849929ms]
May  2 20:32:51.575: INFO: Got endpoints: latency-svc-52tw2 [759.608962ms]
May  2 20:32:51.627: INFO: Created: latency-svc-6rshd
May  2 20:32:51.643: INFO: Created: latency-svc-nhq2x
May  2 20:32:51.673: INFO: Got endpoints: latency-svc-4d5wf [804.157742ms]
May  2 20:32:51.713: INFO: Got endpoints: latency-svc-br55l [804.889057ms]
May  2 20:32:51.743: INFO: Got endpoints: latency-svc-74css [778.842282ms]
May  2 20:32:51.755: INFO: Created: latency-svc-2d2gx
May  2 20:32:51.758: INFO: Got endpoints: latency-svc-gwkfm [734.900644ms]
May  2 20:32:51.783: INFO: Created: latency-svc-phmg5
May  2 20:32:51.789: INFO: Created: latency-svc-krd8l
May  2 20:32:51.824: INFO: Got endpoints: latency-svc-bq8sv [757.76472ms]
May  2 20:32:51.826: INFO: Created: latency-svc-4pvmk
May  2 20:32:51.862: INFO: Got endpoints: latency-svc-26ddv [753.216271ms]
May  2 20:32:51.862: INFO: Created: latency-svc-9nl4l
May  2 20:32:51.910: INFO: Got endpoints: latency-svc-2vht5 [747.756039ms]
May  2 20:32:51.911: INFO: Created: latency-svc-lwppk
May  2 20:32:51.961: INFO: Created: latency-svc-c5kv4
May  2 20:32:51.961: INFO: Got endpoints: latency-svc-5mz5r [748.781262ms]
May  2 20:32:52.026: INFO: Got endpoints: latency-svc-gcznx [758.827926ms]
May  2 20:32:52.052: INFO: Got endpoints: latency-svc-96749 [737.291486ms]
May  2 20:32:52.115: INFO: Got endpoints: latency-svc-c97k4 [744.305129ms]
May  2 20:32:52.157: INFO: Got endpoints: latency-svc-jr829 [727.08172ms]
May  2 20:32:52.220: INFO: Got endpoints: latency-svc-sjqfm [760.356629ms]
May  2 20:32:52.253: INFO: Got endpoints: latency-svc-nhq2x [698.243572ms]
May  2 20:32:52.324: INFO: Got endpoints: latency-svc-6rshd [749.319888ms]
May  2 20:32:52.359: INFO: Got endpoints: latency-svc-2d2gx [685.299585ms]
May  2 20:32:52.425: INFO: Got endpoints: latency-svc-phmg5 [712.246211ms]
May  2 20:32:52.458: INFO: Got endpoints: latency-svc-krd8l [715.007554ms]
May  2 20:32:52.529: INFO: Got endpoints: latency-svc-4pvmk [770.871835ms]
May  2 20:32:52.562: INFO: Got endpoints: latency-svc-9nl4l [737.218191ms]
May  2 20:32:52.625: INFO: Got endpoints: latency-svc-lwppk [762.265933ms]
May  2 20:32:52.685: INFO: Got endpoints: latency-svc-c5kv4 [774.922876ms]
May  2 20:32:52.685: INFO: Latencies: [67.198116ms 88.410318ms 98.889067ms 125.34689ms 148.867141ms 163.688474ms 206.929404ms 228.776893ms 260.805744ms 274.14911ms 303.654021ms 306.043351ms 307.439578ms 315.079096ms 320.403494ms 322.817129ms 326.730243ms 327.775433ms 329.630997ms 331.162016ms 331.277069ms 337.676415ms 338.286522ms 347.145818ms 347.226769ms 351.139262ms 353.411774ms 356.995062ms 357.27763ms 359.210518ms 360.479204ms 363.146214ms 365.928017ms 366.312724ms 369.030296ms 374.490028ms 375.421685ms 375.912883ms 378.851397ms 384.003835ms 384.341564ms 392.684728ms 394.048312ms 397.66928ms 398.359499ms 402.413786ms 403.863202ms 408.103708ms 418.136594ms 427.090006ms 461.203738ms 471.146827ms 475.67017ms 478.798449ms 479.549742ms 496.75219ms 498.534535ms 499.999231ms 503.912075ms 504.164165ms 505.489208ms 510.468832ms 512.862269ms 516.091717ms 517.732229ms 526.689588ms 537.520245ms 543.961395ms 547.850966ms 566.938724ms 617.050577ms 624.733527ms 648.867925ms 667.882625ms 685.299585ms 695.780058ms 698.243572ms 709.681343ms 710.995576ms 712.246211ms 713.089984ms 713.335444ms 715.007554ms 716.421824ms 716.482838ms 717.151507ms 719.929701ms 720.964303ms 721.504219ms 721.742145ms 722.635783ms 724.652215ms 725.233891ms 725.705961ms 727.08172ms 728.677388ms 729.068539ms 729.968699ms 730.248319ms 732.721908ms 734.321244ms 734.549689ms 734.900644ms 735.946927ms 736.534935ms 736.586943ms 737.108997ms 737.218191ms 737.291486ms 737.374883ms 737.432661ms 737.760163ms 738.156431ms 739.15687ms 739.249752ms 739.472378ms 740.366346ms 740.718174ms 740.852644ms 741.11794ms 741.471748ms 742.02379ms 742.281091ms 744.046365ms 744.305129ms 744.52638ms 744.933823ms 745.115732ms 745.295957ms 745.832249ms 746.151325ms 746.911543ms 747.098922ms 747.280752ms 747.756039ms 748.25456ms 748.282793ms 748.466086ms 748.781262ms 749.073347ms 749.319888ms 749.443007ms 749.461211ms 749.608647ms 749.864054ms 750.337157ms 750.446551ms 750.691329ms 750.892514ms 751.476674ms 751.705162ms 751.989823ms 752.256419ms 752.490507ms 753.000528ms 753.216271ms 753.689074ms 754.320171ms 754.8167ms 755.070332ms 755.843634ms 756.208305ms 756.702498ms 757.76472ms 758.827926ms 759.608962ms 759.615464ms 760.080564ms 760.356629ms 760.388498ms 761.994708ms 762.265933ms 762.27042ms 762.520957ms 762.712125ms 763.06303ms 764.571185ms 765.024472ms 765.669384ms 765.759123ms 767.278308ms 767.621628ms 768.38877ms 768.596155ms 769.464117ms 769.63139ms 770.871835ms 774.922876ms 776.346043ms 776.456621ms 778.842282ms 781.760208ms 782.472569ms 786.849929ms 787.710714ms 804.157742ms 804.889057ms 805.089553ms 807.843222ms 816.438505ms]
May  2 20:32:52.685: INFO: 50 %ile: 734.321244ms
May  2 20:32:52.685: INFO: 90 %ile: 767.278308ms
May  2 20:32:52.685: INFO: 99 %ile: 807.843222ms
May  2 20:32:52.685: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:32:52.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-4419" for this suite.


• [SLOW TEST:12.151 seconds]
[sig-network] Service endpoints latency
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":-1,"completed":115,"skipped":1956,"failed":0}

SSSSS
------------------------------
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:32:52.794: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-map-c371fa29-e91f-49c4-a539-73ea922747fa
STEP: Creating a pod to test consume configMaps
May  2 20:32:52.945: INFO: Waiting up to 5m0s for pod "pod-configmaps-b5e12c97-f55f-4747-b799-cfad91370dd1" in namespace "configmap-8091" to be "Succeeded or Failed"
May  2 20:32:52.958: INFO: Pod "pod-configmaps-b5e12c97-f55f-4747-b799-cfad91370dd1": Phase="Pending", Reason="", readiness=false. Elapsed: 13.712023ms
May  2 20:32:54.983: INFO: Pod "pod-configmaps-b5e12c97-f55f-4747-b799-cfad91370dd1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038706552s
May  2 20:32:56.991: INFO: Pod "pod-configmaps-b5e12c97-f55f-4747-b799-cfad91370dd1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046568414s
STEP: Saw pod success
May  2 20:32:56.991: INFO: Pod "pod-configmaps-b5e12c97-f55f-4747-b799-cfad91370dd1" satisfied condition "Succeeded or Failed"
May  2 20:32:56.998: INFO: Trying to get logs from node node-2 pod pod-configmaps-b5e12c97-f55f-4747-b799-cfad91370dd1 container agnhost-container: <nil>
STEP: delete the pod
May  2 20:32:57.058: INFO: Waiting for pod pod-configmaps-b5e12c97-f55f-4747-b799-cfad91370dd1 to disappear
May  2 20:32:57.073: INFO: Pod pod-configmaps-b5e12c97-f55f-4747-b799-cfad91370dd1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:32:57.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8091" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":-1,"completed":116,"skipped":1961,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:32:57.329: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating the pod with failed condition
STEP: updating the pod
May  2 20:34:58.038: INFO: Successfully updated pod "var-expansion-144ec381-04eb-4f83-9fdd-0633f5019180"
STEP: waiting for pod running
STEP: deleting the pod gracefully
May  2 20:35:00.106: INFO: Deleting pod "var-expansion-144ec381-04eb-4f83-9fdd-0633f5019180" in namespace "var-expansion-7614"
May  2 20:35:00.132: INFO: Wait up to 5m0s for pod "var-expansion-144ec381-04eb-4f83-9fdd-0633f5019180" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:35:34.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7614" for this suite.


• [SLOW TEST:156.858 seconds]
[sig-node] Variable Expansion
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","total":-1,"completed":117,"skipped":1989,"failed":0}

S
------------------------------
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:35:34.192: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0644 on tmpfs
May  2 20:35:34.333: INFO: Waiting up to 5m0s for pod "pod-60bc15f9-2c21-439c-a763-2b018903dc0d" in namespace "emptydir-2654" to be "Succeeded or Failed"
May  2 20:35:34.347: INFO: Pod "pod-60bc15f9-2c21-439c-a763-2b018903dc0d": Phase="Pending", Reason="", readiness=false. Elapsed: 13.470142ms
May  2 20:35:36.364: INFO: Pod "pod-60bc15f9-2c21-439c-a763-2b018903dc0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03087756s
May  2 20:35:38.374: INFO: Pod "pod-60bc15f9-2c21-439c-a763-2b018903dc0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041279784s
STEP: Saw pod success
May  2 20:35:38.374: INFO: Pod "pod-60bc15f9-2c21-439c-a763-2b018903dc0d" satisfied condition "Succeeded or Failed"
May  2 20:35:38.386: INFO: Trying to get logs from node node-2 pod pod-60bc15f9-2c21-439c-a763-2b018903dc0d container test-container: <nil>
STEP: delete the pod
May  2 20:35:38.460: INFO: Waiting for pod pod-60bc15f9-2c21-439c-a763-2b018903dc0d to disappear
May  2 20:35:38.465: INFO: Pod pod-60bc15f9-2c21-439c-a763-2b018903dc0d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:35:38.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2654" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":118,"skipped":1990,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:35:38.549: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
May  2 20:35:38.709: INFO: Waiting up to 5m0s for pod "downwardapi-volume-232ab1c0-18fa-4038-a502-9b700d5fda09" in namespace "downward-api-9749" to be "Succeeded or Failed"
May  2 20:35:38.735: INFO: Pod "downwardapi-volume-232ab1c0-18fa-4038-a502-9b700d5fda09": Phase="Pending", Reason="", readiness=false. Elapsed: 26.175307ms
May  2 20:35:40.765: INFO: Pod "downwardapi-volume-232ab1c0-18fa-4038-a502-9b700d5fda09": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055909822s
May  2 20:35:42.790: INFO: Pod "downwardapi-volume-232ab1c0-18fa-4038-a502-9b700d5fda09": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.080952572s
STEP: Saw pod success
May  2 20:35:42.790: INFO: Pod "downwardapi-volume-232ab1c0-18fa-4038-a502-9b700d5fda09" satisfied condition "Succeeded or Failed"
May  2 20:35:42.799: INFO: Trying to get logs from node node-2 pod downwardapi-volume-232ab1c0-18fa-4038-a502-9b700d5fda09 container client-container: <nil>
STEP: delete the pod
May  2 20:35:42.867: INFO: Waiting for pod downwardapi-volume-232ab1c0-18fa-4038-a502-9b700d5fda09 to disappear
May  2 20:35:42.876: INFO: Pod downwardapi-volume-232ab1c0-18fa-4038-a502-9b700d5fda09 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:35:42.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9749" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":-1,"completed":119,"skipped":2033,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:35:43.068: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
May  2 20:35:43.239: INFO: Waiting up to 5m0s for pod "downwardapi-volume-51ba9c4b-1074-4b50-8f9b-e5c5a189c695" in namespace "projected-4877" to be "Succeeded or Failed"
May  2 20:35:43.258: INFO: Pod "downwardapi-volume-51ba9c4b-1074-4b50-8f9b-e5c5a189c695": Phase="Pending", Reason="", readiness=false. Elapsed: 18.861595ms
May  2 20:35:45.283: INFO: Pod "downwardapi-volume-51ba9c4b-1074-4b50-8f9b-e5c5a189c695": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043675727s
May  2 20:35:47.295: INFO: Pod "downwardapi-volume-51ba9c4b-1074-4b50-8f9b-e5c5a189c695": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056075767s
STEP: Saw pod success
May  2 20:35:47.295: INFO: Pod "downwardapi-volume-51ba9c4b-1074-4b50-8f9b-e5c5a189c695" satisfied condition "Succeeded or Failed"
May  2 20:35:47.303: INFO: Trying to get logs from node node-2 pod downwardapi-volume-51ba9c4b-1074-4b50-8f9b-e5c5a189c695 container client-container: <nil>
STEP: delete the pod
May  2 20:35:47.358: INFO: Waiting for pod downwardapi-volume-51ba9c4b-1074-4b50-8f9b-e5c5a189c695 to disappear
May  2 20:35:47.367: INFO: Pod downwardapi-volume-51ba9c4b-1074-4b50-8f9b-e5c5a189c695 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:35:47.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4877" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":120,"skipped":2089,"failed":0}

SS
------------------------------
[BeforeEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:35:47.414: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a secret [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a secret
STEP: listing secrets in all namespaces to ensure that there are more than zero
STEP: patching the secret
STEP: deleting the secret using a LabelSelector
STEP: listing secrets in all namespaces, searching for label name and value in patch
[AfterEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:35:47.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7416" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","total":-1,"completed":121,"skipped":2091,"failed":0}

SS
------------------------------
[BeforeEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:30:51.294: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a ForbidConcurrent cronjob
STEP: Ensuring a job is scheduled
STEP: Ensuring exactly one is scheduled
STEP: Ensuring exactly one running job exists by listing jobs explicitly
STEP: Ensuring no more jobs are scheduled
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:36:01.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-1116" for this suite.


• [SLOW TEST:310.349 seconds]
[sig-apps] CronJob
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","total":-1,"completed":134,"skipped":2292,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:35:47.772: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-7552
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-7552
STEP: creating replication controller externalsvc in namespace services-7552
I0502 20:35:47.977805      19 runners.go:190] Created replication controller with name: externalsvc, namespace: services-7552, replica count: 2
I0502 20:35:51.034171      19 runners.go:190] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0502 20:35:54.034678      19 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
May  2 20:35:54.103: INFO: Creating new exec pod
May  2 20:35:58.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-7552 exec execpodb92qk -- /bin/sh -x -c nslookup clusterip-service.services-7552.svc.cluster.local'
May  2 20:35:58.626: INFO: stderr: "+ nslookup clusterip-service.services-7552.svc.cluster.local\n"
May  2 20:35:58.626: INFO: stdout: "Server:\t\t169.254.25.10\nAddress:\t169.254.25.10#53\n\nclusterip-service.services-7552.svc.cluster.local\tcanonical name = externalsvc.services-7552.svc.cluster.local.\nName:\texternalsvc.services-7552.svc.cluster.local\nAddress: 10.233.16.160\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-7552, will wait for the garbage collector to delete the pods
May  2 20:35:58.706: INFO: Deleting ReplicationController externalsvc took: 20.882478ms
May  2 20:35:58.807: INFO: Terminating ReplicationController externalsvc pods took: 100.781919ms
May  2 20:36:02.192: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:36:02.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7552" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753


• [SLOW TEST:14.552 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":-1,"completed":122,"skipped":2093,"failed":0}

SSSSS
------------------------------
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/sysctl.go:36
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:36:02.378: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename sysctl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/sysctl.go:65
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod with one valid and two invalid sysctls
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:36:02.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-8515" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","total":-1,"completed":123,"skipped":2098,"failed":0}

SSSSS
------------------------------
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:36:01.746: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0666 on tmpfs
May  2 20:36:01.890: INFO: Waiting up to 5m0s for pod "pod-61eb2bf7-5699-4469-89ae-8f967cae53e3" in namespace "emptydir-1487" to be "Succeeded or Failed"
May  2 20:36:01.901: INFO: Pod "pod-61eb2bf7-5699-4469-89ae-8f967cae53e3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.311626ms
May  2 20:36:03.970: INFO: Pod "pod-61eb2bf7-5699-4469-89ae-8f967cae53e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.079270666s
May  2 20:36:05.992: INFO: Pod "pod-61eb2bf7-5699-4469-89ae-8f967cae53e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.10206059s
STEP: Saw pod success
May  2 20:36:05.993: INFO: Pod "pod-61eb2bf7-5699-4469-89ae-8f967cae53e3" satisfied condition "Succeeded or Failed"
May  2 20:36:06.026: INFO: Trying to get logs from node node-2 pod pod-61eb2bf7-5699-4469-89ae-8f967cae53e3 container test-container: <nil>
STEP: delete the pod
May  2 20:36:06.140: INFO: Waiting for pod pod-61eb2bf7-5699-4469-89ae-8f967cae53e3 to disappear
May  2 20:36:06.177: INFO: Pod pod-61eb2bf7-5699-4469-89ae-8f967cae53e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:36:06.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1487" for this suite.

•
------------------------------
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:36:02.763: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service nodeport-test with type=NodePort in namespace services-2603
STEP: creating replication controller nodeport-test in namespace services-2603
I0502 20:36:03.071443      19 runners.go:190] Created replication controller with name: nodeport-test, namespace: services-2603, replica count: 2
I0502 20:36:06.134667      19 runners.go:190] nodeport-test Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0502 20:36:09.139019      19 runners.go:190] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  2 20:36:09.139: INFO: Creating new exec pod
May  2 20:36:14.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-2603 exec execpod7v279 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
May  2 20:36:14.678: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
May  2 20:36:14.678: INFO: stdout: "nodeport-test-f78c2"
May  2 20:36:14.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-2603 exec execpod7v279 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.56.163 80'
May  2 20:36:15.092: INFO: stderr: "+ nc -v -t -w 2 10.233.56.163 80\n+ echo hostName\nConnection to 10.233.56.163 80 port [tcp/http] succeeded!\n"
May  2 20:36:15.092: INFO: stdout: "nodeport-test-jw7mv"
May  2 20:36:15.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-2603 exec execpod7v279 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.20.186 30333'
May  2 20:36:15.438: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.100.20.186 30333\nConnection to 10.100.20.186 30333 port [tcp/*] succeeded!\n"
May  2 20:36:15.438: INFO: stdout: "nodeport-test-f78c2"
May  2 20:36:15.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-2603 exec execpod7v279 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.20.46 30333'
May  2 20:36:15.787: INFO: stderr: "+ nc -v -t -w 2 10.100.20.46 30333\n+ echo hostName\nConnection to 10.100.20.46 30333 port [tcp/*] succeeded!\n"
May  2 20:36:15.788: INFO: stdout: ""
May  2 20:36:16.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-2603 exec execpod7v279 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.20.46 30333'
May  2 20:36:17.096: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.100.20.46 30333\nConnection to 10.100.20.46 30333 port [tcp/*] succeeded!\n"
May  2 20:36:17.097: INFO: stdout: "nodeport-test-jw7mv"
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:36:17.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2603" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753


• [SLOW TEST:14.366 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":-1,"completed":124,"skipped":2103,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:36:17.316: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
May  2 20:36:17.428: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fa217d40-34f1-456a-8413-c72de81cdd64" in namespace "downward-api-7152" to be "Succeeded or Failed"
May  2 20:36:17.437: INFO: Pod "downwardapi-volume-fa217d40-34f1-456a-8413-c72de81cdd64": Phase="Pending", Reason="", readiness=false. Elapsed: 8.292127ms
May  2 20:36:19.456: INFO: Pod "downwardapi-volume-fa217d40-34f1-456a-8413-c72de81cdd64": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027462716s
May  2 20:36:21.472: INFO: Pod "downwardapi-volume-fa217d40-34f1-456a-8413-c72de81cdd64": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043088899s
STEP: Saw pod success
May  2 20:36:21.472: INFO: Pod "downwardapi-volume-fa217d40-34f1-456a-8413-c72de81cdd64" satisfied condition "Succeeded or Failed"
May  2 20:36:21.479: INFO: Trying to get logs from node node-2 pod downwardapi-volume-fa217d40-34f1-456a-8413-c72de81cdd64 container client-container: <nil>
STEP: delete the pod
May  2 20:36:21.546: INFO: Waiting for pod downwardapi-volume-fa217d40-34f1-456a-8413-c72de81cdd64 to disappear
May  2 20:36:21.553: INFO: Pod downwardapi-volume-fa217d40-34f1-456a-8413-c72de81cdd64 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:36:21.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7152" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":-1,"completed":125,"skipped":2209,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":135,"skipped":2331,"failed":0}
[BeforeEach] [sig-network] HostPort
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:36:06.281: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename hostport
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] HostPort
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/hostport.go:47
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled
May  2 20:36:06.593: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:36:08.614: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:36:10.610: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.100.18.197 on the node which pod1 resides and expect scheduled
May  2 20:36:10.654: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:36:12.673: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:36:14.670: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.100.18.197 but use UDP protocol on the node which pod2 resides
May  2 20:36:14.704: INFO: The status of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:36:16.722: INFO: The status of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:36:18.720: INFO: The status of Pod pod3 is Running (Ready = true)
May  2 20:36:18.761: INFO: The status of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
May  2 20:36:20.769: INFO: The status of Pod e2e-host-exec is Running (Ready = true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323
May  2 20:36:20.794: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.100.18.197 http://127.0.0.1:54323/hostname] Namespace:hostport-3529 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 20:36:20.794: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.100.18.197, port: 54323
May  2 20:36:21.082: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.100.18.197:54323/hostname] Namespace:hostport-3529 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 20:36:21.082: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.100.18.197, port: 54323 UDP
May  2 20:36:21.259: INFO: ExecWithOptions {Command:[/bin/sh -c nc -vuz -w 5 10.100.18.197 54323] Namespace:hostport-3529 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 20:36:21.259: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
[AfterEach] [sig-network] HostPort
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:36:26.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-3529" for this suite.


• [SLOW TEST:20.357 seconds]
[sig-network] HostPort
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","total":-1,"completed":136,"skipped":2331,"failed":0}

SSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:36:26.679: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be immutable if `immutable` field is set [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:36:26.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1909" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","total":-1,"completed":137,"skipped":2348,"failed":0}

SSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:36:21.644: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:36:32.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1817" for this suite.


• [SLOW TEST:11.339 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":-1,"completed":126,"skipped":2240,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:36:27.110: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:188
[It] should delete a collection of pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create set of pods
May  2 20:36:27.297: INFO: created test-pod-1
May  2 20:36:27.334: INFO: created test-pod-2
May  2 20:36:27.374: INFO: created test-pod-3
STEP: waiting for all 3 pods to be located
STEP: waiting for all pods to be deleted
May  2 20:36:27.512: INFO: Pod quantity 3 is different from expected quantity 0
May  2 20:36:28.527: INFO: Pod quantity 3 is different from expected quantity 0
May  2 20:36:29.540: INFO: Pod quantity 3 is different from expected quantity 0
May  2 20:36:30.544: INFO: Pod quantity 3 is different from expected quantity 0
May  2 20:36:31.537: INFO: Pod quantity 3 is different from expected quantity 0
May  2 20:36:32.541: INFO: Pod quantity 2 is different from expected quantity 0
May  2 20:36:33.663: INFO: Pod quantity 2 is different from expected quantity 0
May  2 20:36:34.529: INFO: Pod quantity 2 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:36:35.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-683" for this suite.


• [SLOW TEST:8.466 seconds]
[sig-node] Pods
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","total":-1,"completed":138,"skipped":2363,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:36:35.627: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-794e117a-e6a6-479b-8fc8-2c858959f072
STEP: Creating a pod to test consume configMaps
May  2 20:36:35.756: INFO: Waiting up to 5m0s for pod "pod-configmaps-b7fed0d5-e174-4785-bb53-10403acfd72f" in namespace "configmap-8733" to be "Succeeded or Failed"
May  2 20:36:35.773: INFO: Pod "pod-configmaps-b7fed0d5-e174-4785-bb53-10403acfd72f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.689081ms
May  2 20:36:37.782: INFO: Pod "pod-configmaps-b7fed0d5-e174-4785-bb53-10403acfd72f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025944123s
May  2 20:36:40.210: INFO: Pod "pod-configmaps-b7fed0d5-e174-4785-bb53-10403acfd72f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.453888511s
STEP: Saw pod success
May  2 20:36:40.210: INFO: Pod "pod-configmaps-b7fed0d5-e174-4785-bb53-10403acfd72f" satisfied condition "Succeeded or Failed"
May  2 20:36:40.259: INFO: Trying to get logs from node node-2 pod pod-configmaps-b7fed0d5-e174-4785-bb53-10403acfd72f container agnhost-container: <nil>
STEP: delete the pod
May  2 20:36:40.398: INFO: Waiting for pod pod-configmaps-b7fed0d5-e174-4785-bb53-10403acfd72f to disappear
May  2 20:36:40.448: INFO: Pod pod-configmaps-b7fed0d5-e174-4785-bb53-10403acfd72f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:36:40.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8733" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":-1,"completed":139,"skipped":2393,"failed":0}

SSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:36:40.619: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0666 on node default medium
May  2 20:36:40.883: INFO: Waiting up to 5m0s for pod "pod-9b6d6032-44cb-47e0-b40b-41af91455b0f" in namespace "emptydir-7405" to be "Succeeded or Failed"
May  2 20:36:40.910: INFO: Pod "pod-9b6d6032-44cb-47e0-b40b-41af91455b0f": Phase="Pending", Reason="", readiness=false. Elapsed: 27.628609ms
May  2 20:36:42.926: INFO: Pod "pod-9b6d6032-44cb-47e0-b40b-41af91455b0f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043080608s
May  2 20:36:44.971: INFO: Pod "pod-9b6d6032-44cb-47e0-b40b-41af91455b0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.088165417s
STEP: Saw pod success
May  2 20:36:44.971: INFO: Pod "pod-9b6d6032-44cb-47e0-b40b-41af91455b0f" satisfied condition "Succeeded or Failed"
May  2 20:36:44.984: INFO: Trying to get logs from node node-2 pod pod-9b6d6032-44cb-47e0-b40b-41af91455b0f container test-container: <nil>
STEP: delete the pod
May  2 20:36:45.067: INFO: Waiting for pod pod-9b6d6032-44cb-47e0-b40b-41af91455b0f to disappear
May  2 20:36:45.073: INFO: Pod pod-9b6d6032-44cb-47e0-b40b-41af91455b0f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:36:45.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7405" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":140,"skipped":2410,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:36:45.193: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
May  2 20:36:51.871: INFO: Successfully updated pod "adopt-release--1-6v6zs"
STEP: Checking that the Job readopts the Pod
May  2 20:36:51.872: INFO: Waiting up to 15m0s for pod "adopt-release--1-6v6zs" in namespace "job-3097" to be "adopted"
May  2 20:36:51.897: INFO: Pod "adopt-release--1-6v6zs": Phase="Running", Reason="", readiness=true. Elapsed: 25.635779ms
May  2 20:36:53.906: INFO: Pod "adopt-release--1-6v6zs": Phase="Running", Reason="", readiness=true. Elapsed: 2.034482008s
May  2 20:36:53.906: INFO: Pod "adopt-release--1-6v6zs" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
May  2 20:36:54.427: INFO: Successfully updated pod "adopt-release--1-6v6zs"
STEP: Checking that the Job releases the Pod
May  2 20:36:54.432: INFO: Waiting up to 15m0s for pod "adopt-release--1-6v6zs" in namespace "job-3097" to be "released"
May  2 20:36:54.466: INFO: Pod "adopt-release--1-6v6zs": Phase="Running", Reason="", readiness=true. Elapsed: 33.759301ms
May  2 20:36:54.466: INFO: Pod "adopt-release--1-6v6zs" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:36:54.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3097" for this suite.


• [SLOW TEST:9.356 seconds]
[sig-apps] Job
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":-1,"completed":141,"skipped":2450,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:36:54.594: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
May  2 20:36:54.724: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4001  0230eb8c-93b9-41ba-9dcb-7b7b0f9f51fd 2890094 0 2022-05-02 20:36:54 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-05-02 20:36:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
May  2 20:36:54.725: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4001  0230eb8c-93b9-41ba-9dcb-7b7b0f9f51fd 2890095 0 2022-05-02 20:36:54 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-05-02 20:36:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
May  2 20:36:54.760: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4001  0230eb8c-93b9-41ba-9dcb-7b7b0f9f51fd 2890096 0 2022-05-02 20:36:54 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-05-02 20:36:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
May  2 20:36:54.760: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4001  0230eb8c-93b9-41ba-9dcb-7b7b0f9f51fd 2890098 0 2022-05-02 20:36:54 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-05-02 20:36:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:36:54.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4001" for this suite.

•
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":-1,"completed":142,"skipped":2475,"failed":0}

SSSSSSSS
------------------------------
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:36:54.795: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
May  2 20:36:54.909: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-7011  6c236948-dddd-44f6-a1ee-1f8ff0ba9703 2890105 0 2022-05-02 20:36:54 +0000 UTC <nil> <nil> map[] map[] [] []  [{e2e.test Update v1 2022-05-02 20:36:54 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-95tvl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:k8s.gcr.io/e2e-test-images/agnhost:2.32,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-95tvl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 20:36:54.930: INFO: The status of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
May  2 20:36:56.940: INFO: The status of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
May  2 20:36:58.940: INFO: The status of Pod test-dns-nameservers is Running (Ready = true)
STEP: Verifying customized DNS suffix list is configured on pod...
May  2 20:36:58.940: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-7011 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 20:36:58.940: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Verifying customized DNS server is configured on pod...
May  2 20:36:59.230: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-7011 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 20:36:59.230: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
May  2 20:36:59.418: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:36:59.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7011" for this suite.

•
------------------------------
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":-1,"completed":143,"skipped":2483,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:36:59.743: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/instrumentation/events.go:81
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a test event
STEP: listing events in all namespaces
STEP: listing events in test namespace
STEP: listing events with field selection filtering on source
STEP: listing events with field selection filtering on reportingController
STEP: getting the test event
STEP: patching the test event
STEP: getting the test event
STEP: updating the test event
STEP: getting the test event
STEP: deleting the test event
STEP: listing events in all namespaces
STEP: listing events in test namespace
[AfterEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:37:00.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8877" for this suite.

•
------------------------------
{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","total":-1,"completed":144,"skipped":2516,"failed":0}

SSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:37:00.480: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
May  2 20:37:00.795: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c12d48bd-b633-4246-945c-94f719455b63" in namespace "downward-api-6431" to be "Succeeded or Failed"
May  2 20:37:00.806: INFO: Pod "downwardapi-volume-c12d48bd-b633-4246-945c-94f719455b63": Phase="Pending", Reason="", readiness=false. Elapsed: 11.104547ms
May  2 20:37:02.886: INFO: Pod "downwardapi-volume-c12d48bd-b633-4246-945c-94f719455b63": Phase="Pending", Reason="", readiness=false. Elapsed: 2.090615001s
May  2 20:37:04.918: INFO: Pod "downwardapi-volume-c12d48bd-b633-4246-945c-94f719455b63": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.122710585s
STEP: Saw pod success
May  2 20:37:04.918: INFO: Pod "downwardapi-volume-c12d48bd-b633-4246-945c-94f719455b63" satisfied condition "Succeeded or Failed"
May  2 20:37:04.931: INFO: Trying to get logs from node node-2 pod downwardapi-volume-c12d48bd-b633-4246-945c-94f719455b63 container client-container: <nil>
STEP: delete the pod
May  2 20:37:05.017: INFO: Waiting for pod downwardapi-volume-c12d48bd-b633-4246-945c-94f719455b63 to disappear
May  2 20:37:05.058: INFO: Pod downwardapi-volume-c12d48bd-b633-4246-945c-94f719455b63 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:37:05.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6431" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":-1,"completed":145,"skipped":2532,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:36:33.165: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:36:33.455: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
May  2 20:37:01.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=crd-publish-openapi-2956 --namespace=crd-publish-openapi-2956 create -f -'
May  2 20:37:03.712: INFO: stderr: ""
May  2 20:37:03.712: INFO: stdout: "e2e-test-crd-publish-openapi-1880-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
May  2 20:37:03.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=crd-publish-openapi-2956 --namespace=crd-publish-openapi-2956 delete e2e-test-crd-publish-openapi-1880-crds test-cr'
May  2 20:37:03.845: INFO: stderr: ""
May  2 20:37:03.845: INFO: stdout: "e2e-test-crd-publish-openapi-1880-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
May  2 20:37:03.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=crd-publish-openapi-2956 --namespace=crd-publish-openapi-2956 apply -f -'
May  2 20:37:05.794: INFO: stderr: ""
May  2 20:37:05.794: INFO: stdout: "e2e-test-crd-publish-openapi-1880-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
May  2 20:37:05.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=crd-publish-openapi-2956 --namespace=crd-publish-openapi-2956 delete e2e-test-crd-publish-openapi-1880-crds test-cr'
May  2 20:37:05.979: INFO: stderr: ""
May  2 20:37:05.979: INFO: stdout: "e2e-test-crd-publish-openapi-1880-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
May  2 20:37:05.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=crd-publish-openapi-2956 explain e2e-test-crd-publish-openapi-1880-crds'
May  2 20:37:07.786: INFO: stderr: ""
May  2 20:37:07.786: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1880-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:37:27.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2956" for this suite.


• [SLOW TEST:53.914 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":-1,"completed":127,"skipped":2265,"failed":0}

SSSSSSSS
------------------------------
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:37:27.108: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0644 on node default medium
May  2 20:37:27.235: INFO: Waiting up to 5m0s for pod "pod-be3839ce-f01e-4eac-a939-9d29a12bd432" in namespace "emptydir-7461" to be "Succeeded or Failed"
May  2 20:37:27.263: INFO: Pod "pod-be3839ce-f01e-4eac-a939-9d29a12bd432": Phase="Pending", Reason="", readiness=false. Elapsed: 27.881812ms
May  2 20:37:29.274: INFO: Pod "pod-be3839ce-f01e-4eac-a939-9d29a12bd432": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039560648s
May  2 20:37:31.307: INFO: Pod "pod-be3839ce-f01e-4eac-a939-9d29a12bd432": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.072370827s
STEP: Saw pod success
May  2 20:37:31.307: INFO: Pod "pod-be3839ce-f01e-4eac-a939-9d29a12bd432" satisfied condition "Succeeded or Failed"
May  2 20:37:31.315: INFO: Trying to get logs from node node-2 pod pod-be3839ce-f01e-4eac-a939-9d29a12bd432 container test-container: <nil>
STEP: delete the pod
May  2 20:37:31.368: INFO: Waiting for pod pod-be3839ce-f01e-4eac-a939-9d29a12bd432 to disappear
May  2 20:37:31.379: INFO: Pod pod-be3839ce-f01e-4eac-a939-9d29a12bd432 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:37:31.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7461" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":128,"skipped":2273,"failed":0}
[BeforeEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:37:31.433: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:38:00.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5110" for this suite.


• [SLOW TEST:29.158 seconds]
[sig-node] Container Runtime
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  blackbox test
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/runtime.go:41
    when starting a container that exits
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/runtime.go:42
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":-1,"completed":129,"skipped":2273,"failed":0}

SSSS
------------------------------
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:38:00.601: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:38:00.760: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
May  2 20:38:26.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=crd-publish-openapi-4229 --namespace=crd-publish-openapi-4229 create -f -'
May  2 20:38:28.076: INFO: stderr: ""
May  2 20:38:28.076: INFO: stdout: "e2e-test-crd-publish-openapi-5248-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
May  2 20:38:28.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=crd-publish-openapi-4229 --namespace=crd-publish-openapi-4229 delete e2e-test-crd-publish-openapi-5248-crds test-cr'
May  2 20:38:28.190: INFO: stderr: ""
May  2 20:38:28.190: INFO: stdout: "e2e-test-crd-publish-openapi-5248-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
May  2 20:38:28.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=crd-publish-openapi-4229 --namespace=crd-publish-openapi-4229 apply -f -'
May  2 20:38:29.818: INFO: stderr: ""
May  2 20:38:29.818: INFO: stdout: "e2e-test-crd-publish-openapi-5248-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
May  2 20:38:29.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=crd-publish-openapi-4229 --namespace=crd-publish-openapi-4229 delete e2e-test-crd-publish-openapi-5248-crds test-cr'
May  2 20:38:30.012: INFO: stderr: ""
May  2 20:38:30.012: INFO: stdout: "e2e-test-crd-publish-openapi-5248-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
May  2 20:38:30.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=crd-publish-openapi-4229 explain e2e-test-crd-publish-openapi-5248-crds'
May  2 20:38:31.349: INFO: stderr: ""
May  2 20:38:31.349: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5248-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:38:51.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4229" for this suite.


• [SLOW TEST:50.554 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":-1,"completed":130,"skipped":2277,"failed":0}

SSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:38:51.174: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name secret-test-5364d6b9-013d-49c6-ae95-7b7598b6ac80
STEP: Creating a pod to test consume secrets
May  2 20:38:51.290: INFO: Waiting up to 5m0s for pod "pod-secrets-23c54550-543a-4fc0-a613-186a03b8d13b" in namespace "secrets-1527" to be "Succeeded or Failed"
May  2 20:38:51.329: INFO: Pod "pod-secrets-23c54550-543a-4fc0-a613-186a03b8d13b": Phase="Pending", Reason="", readiness=false. Elapsed: 38.941866ms
May  2 20:38:53.354: INFO: Pod "pod-secrets-23c54550-543a-4fc0-a613-186a03b8d13b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063870752s
May  2 20:38:55.376: INFO: Pod "pod-secrets-23c54550-543a-4fc0-a613-186a03b8d13b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.085127093s
STEP: Saw pod success
May  2 20:38:55.376: INFO: Pod "pod-secrets-23c54550-543a-4fc0-a613-186a03b8d13b" satisfied condition "Succeeded or Failed"
May  2 20:38:55.384: INFO: Trying to get logs from node node-2 pod pod-secrets-23c54550-543a-4fc0-a613-186a03b8d13b container secret-volume-test: <nil>
STEP: delete the pod
May  2 20:38:55.499: INFO: Waiting for pod pod-secrets-23c54550-543a-4fc0-a613-186a03b8d13b to disappear
May  2 20:38:55.522: INFO: Pod pod-secrets-23c54550-543a-4fc0-a613-186a03b8d13b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:38:55.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1527" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":131,"skipped":2287,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:38:55.866: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  2 20:38:56.649: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May  2 20:38:58.676: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120736, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120736, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120736, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787120736, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  2 20:39:01.766: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:39:02.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9092" for this suite.
STEP: Destroying namespace "webhook-9092-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102


• [SLOW TEST:6.427 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":-1,"completed":132,"skipped":2426,"failed":0}

SSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:39:02.458: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
May  2 20:39:02.673: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a892ead0-312f-448f-bd85-748c4dd81a13" in namespace "downward-api-826" to be "Succeeded or Failed"
May  2 20:39:02.741: INFO: Pod "downwardapi-volume-a892ead0-312f-448f-bd85-748c4dd81a13": Phase="Pending", Reason="", readiness=false. Elapsed: 67.89314ms
May  2 20:39:04.754: INFO: Pod "downwardapi-volume-a892ead0-312f-448f-bd85-748c4dd81a13": Phase="Pending", Reason="", readiness=false. Elapsed: 2.080665438s
May  2 20:39:06.773: INFO: Pod "downwardapi-volume-a892ead0-312f-448f-bd85-748c4dd81a13": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.099507616s
STEP: Saw pod success
May  2 20:39:06.773: INFO: Pod "downwardapi-volume-a892ead0-312f-448f-bd85-748c4dd81a13" satisfied condition "Succeeded or Failed"
May  2 20:39:06.783: INFO: Trying to get logs from node node-2 pod downwardapi-volume-a892ead0-312f-448f-bd85-748c4dd81a13 container client-container: <nil>
STEP: delete the pod
May  2 20:39:06.831: INFO: Waiting for pod downwardapi-volume-a892ead0-312f-448f-bd85-748c4dd81a13 to disappear
May  2 20:39:06.842: INFO: Pod downwardapi-volume-a892ead0-312f-448f-bd85-748c4dd81a13 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:39:06.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-826" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":133,"skipped":2439,"failed":0}

SS
------------------------------
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:37:05.292: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service in namespace services-9041
May  2 20:37:05.534: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
May  2 20:37:07.550: INFO: The status of Pod kube-proxy-mode-detector is Running (Ready = true)
May  2 20:37:07.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=services-9041 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
May  2 20:37:08.035: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
May  2 20:37:08.035: INFO: stdout: "ipvs"
May  2 20:37:08.035: INFO: proxyMode: ipvs
May  2 20:37:08.101: INFO: Waiting for pod kube-proxy-mode-detector to disappear
May  2 20:37:08.112: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-9041
STEP: creating replication controller affinity-clusterip-timeout in namespace services-9041
I0502 20:37:08.194228      18 runners.go:190] Created replication controller with name: affinity-clusterip-timeout, namespace: services-9041, replica count: 3
I0502 20:37:11.264208      18 runners.go:190] affinity-clusterip-timeout Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0502 20:37:14.264895      18 runners.go:190] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  2 20:37:14.285: INFO: Creating new exec pod
May  2 20:37:17.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=services-9041 exec execpod-affinityzlsg8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
May  2 20:37:18.182: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-timeout 80\n+ echo hostName\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
May  2 20:37:18.182: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 20:37:18.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=services-9041 exec execpod-affinityzlsg8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.62.91 80'
May  2 20:37:18.562: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.62.91 80\nConnection to 10.233.62.91 80 port [tcp/http] succeeded!\n"
May  2 20:37:18.562: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 20:37:18.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=services-9041 exec execpod-affinityzlsg8 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.62.91:80/ ; done'
May  2 20:37:19.207: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.91:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.91:80/\n"
May  2 20:37:19.207: INFO: stdout: "\naffinity-clusterip-timeout-bxz7g\naffinity-clusterip-timeout-bxz7g\naffinity-clusterip-timeout-bxz7g\naffinity-clusterip-timeout-bxz7g\naffinity-clusterip-timeout-bxz7g\naffinity-clusterip-timeout-bxz7g\naffinity-clusterip-timeout-bxz7g\naffinity-clusterip-timeout-bxz7g\naffinity-clusterip-timeout-bxz7g\naffinity-clusterip-timeout-bxz7g\naffinity-clusterip-timeout-bxz7g\naffinity-clusterip-timeout-bxz7g\naffinity-clusterip-timeout-bxz7g\naffinity-clusterip-timeout-bxz7g\naffinity-clusterip-timeout-bxz7g\naffinity-clusterip-timeout-bxz7g"
May  2 20:37:19.207: INFO: Received response from host: affinity-clusterip-timeout-bxz7g
May  2 20:37:19.207: INFO: Received response from host: affinity-clusterip-timeout-bxz7g
May  2 20:37:19.207: INFO: Received response from host: affinity-clusterip-timeout-bxz7g
May  2 20:37:19.207: INFO: Received response from host: affinity-clusterip-timeout-bxz7g
May  2 20:37:19.207: INFO: Received response from host: affinity-clusterip-timeout-bxz7g
May  2 20:37:19.207: INFO: Received response from host: affinity-clusterip-timeout-bxz7g
May  2 20:37:19.207: INFO: Received response from host: affinity-clusterip-timeout-bxz7g
May  2 20:37:19.207: INFO: Received response from host: affinity-clusterip-timeout-bxz7g
May  2 20:37:19.207: INFO: Received response from host: affinity-clusterip-timeout-bxz7g
May  2 20:37:19.207: INFO: Received response from host: affinity-clusterip-timeout-bxz7g
May  2 20:37:19.207: INFO: Received response from host: affinity-clusterip-timeout-bxz7g
May  2 20:37:19.207: INFO: Received response from host: affinity-clusterip-timeout-bxz7g
May  2 20:37:19.207: INFO: Received response from host: affinity-clusterip-timeout-bxz7g
May  2 20:37:19.207: INFO: Received response from host: affinity-clusterip-timeout-bxz7g
May  2 20:37:19.207: INFO: Received response from host: affinity-clusterip-timeout-bxz7g
May  2 20:37:19.207: INFO: Received response from host: affinity-clusterip-timeout-bxz7g
May  2 20:37:19.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=services-9041 exec execpod-affinityzlsg8 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.233.62.91:80/'
May  2 20:37:19.558: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.233.62.91:80/\n"
May  2 20:37:19.558: INFO: stdout: "affinity-clusterip-timeout-bxz7g"
May  2 20:39:29.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=services-9041 exec execpod-affinityzlsg8 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.233.62.91:80/'
May  2 20:39:29.957: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.233.62.91:80/\n"
May  2 20:39:29.957: INFO: stdout: "affinity-clusterip-timeout-zfgp7"
May  2 20:39:29.957: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-9041, will wait for the garbage collector to delete the pods
May  2 20:39:30.237: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 46.306226ms
May  2 20:39:30.438: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 200.817269ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:39:33.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9041" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753


• [SLOW TEST:148.548 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","total":-1,"completed":146,"skipped":2559,"failed":0}

SSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:39:06.872: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:39:06.998: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Creating first CR 
May  2 20:39:14.751: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-05-02T20:39:14Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-05-02T20:39:14Z]] name:name1 resourceVersion:2891385 uid:62a02e1e-222e-40e9-b08c-d74df129a0a7] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
May  2 20:39:24.785: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-05-02T20:39:24Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-05-02T20:39:24Z]] name:name2 resourceVersion:2891444 uid:f2bce7ac-8cbd-4513-b49b-a3f9c1320102] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
May  2 20:39:34.814: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-05-02T20:39:14Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-05-02T20:39:34Z]] name:name1 resourceVersion:2891557 uid:62a02e1e-222e-40e9-b08c-d74df129a0a7] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
May  2 20:39:44.841: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-05-02T20:39:24Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-05-02T20:39:44Z]] name:name2 resourceVersion:2891651 uid:f2bce7ac-8cbd-4513-b49b-a3f9c1320102] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
May  2 20:39:54.869: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-05-02T20:39:14Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-05-02T20:39:34Z]] name:name1 resourceVersion:2891706 uid:62a02e1e-222e-40e9-b08c-d74df129a0a7] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
May  2 20:40:04.896: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-05-02T20:39:24Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-05-02T20:39:44Z]] name:name2 resourceVersion:2891760 uid:f2bce7ac-8cbd-4513-b49b-a3f9c1320102] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:40:15.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-2966" for this suite.


• [SLOW TEST:68.697 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":-1,"completed":134,"skipped":2441,"failed":0}

SSSS
------------------------------
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:40:15.584: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir volume type on tmpfs
May  2 20:40:16.132: INFO: Waiting up to 5m0s for pod "pod-8e925199-6cc6-4de7-92cb-c9aa04f14a53" in namespace "emptydir-7621" to be "Succeeded or Failed"
May  2 20:40:16.217: INFO: Pod "pod-8e925199-6cc6-4de7-92cb-c9aa04f14a53": Phase="Pending", Reason="", readiness=false. Elapsed: 85.310571ms
May  2 20:40:18.226: INFO: Pod "pod-8e925199-6cc6-4de7-92cb-c9aa04f14a53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.093927173s
STEP: Saw pod success
May  2 20:40:18.226: INFO: Pod "pod-8e925199-6cc6-4de7-92cb-c9aa04f14a53" satisfied condition "Succeeded or Failed"
May  2 20:40:18.233: INFO: Trying to get logs from node node-2 pod pod-8e925199-6cc6-4de7-92cb-c9aa04f14a53 container test-container: <nil>
STEP: delete the pod
May  2 20:40:18.286: INFO: Waiting for pod pod-8e925199-6cc6-4de7-92cb-c9aa04f14a53 to disappear
May  2 20:40:18.295: INFO: Pod pod-8e925199-6cc6-4de7-92cb-c9aa04f14a53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:40:18.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7621" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":135,"skipped":2445,"failed":0}

SSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:40:18.374: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8622.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8622.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May  2 20:40:22.686: INFO: DNS probes using dns-8622/dns-test-d204e759-d041-4260-8df9-5765dc02fe8b succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:40:22.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8622" for this suite.

•
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":-1,"completed":136,"skipped":2463,"failed":0}

SSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:40:22.852: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name configmap-test-volume-map-8a89cc33-217a-4f45-b0c7-5f8189e41d1e
STEP: Creating a pod to test consume configMaps
May  2 20:40:23.069: INFO: Waiting up to 5m0s for pod "pod-configmaps-de1563cd-6b07-4fd7-82fb-d8e81d7c6ee6" in namespace "configmap-107" to be "Succeeded or Failed"
May  2 20:40:23.078: INFO: Pod "pod-configmaps-de1563cd-6b07-4fd7-82fb-d8e81d7c6ee6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.999749ms
May  2 20:40:25.098: INFO: Pod "pod-configmaps-de1563cd-6b07-4fd7-82fb-d8e81d7c6ee6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028902399s
May  2 20:40:27.115: INFO: Pod "pod-configmaps-de1563cd-6b07-4fd7-82fb-d8e81d7c6ee6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046397242s
STEP: Saw pod success
May  2 20:40:27.116: INFO: Pod "pod-configmaps-de1563cd-6b07-4fd7-82fb-d8e81d7c6ee6" satisfied condition "Succeeded or Failed"
May  2 20:40:27.127: INFO: Trying to get logs from node node-2 pod pod-configmaps-de1563cd-6b07-4fd7-82fb-d8e81d7c6ee6 container agnhost-container: <nil>
STEP: delete the pod
May  2 20:40:27.212: INFO: Waiting for pod pod-configmaps-de1563cd-6b07-4fd7-82fb-d8e81d7c6ee6 to disappear
May  2 20:40:27.234: INFO: Pod pod-configmaps-de1563cd-6b07-4fd7-82fb-d8e81d7c6ee6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:40:27.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-107" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":-1,"completed":137,"skipped":2478,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:40:27.354: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/security_context.go:46
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:40:27.468: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-5bd8c3ea-2fc6-4703-8b27-d77a5812a5f8" in namespace "security-context-test-3713" to be "Succeeded or Failed"
May  2 20:40:27.475: INFO: Pod "busybox-privileged-false-5bd8c3ea-2fc6-4703-8b27-d77a5812a5f8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.578509ms
May  2 20:40:29.483: INFO: Pod "busybox-privileged-false-5bd8c3ea-2fc6-4703-8b27-d77a5812a5f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014694425s
May  2 20:40:31.490: INFO: Pod "busybox-privileged-false-5bd8c3ea-2fc6-4703-8b27-d77a5812a5f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022077211s
May  2 20:40:31.491: INFO: Pod "busybox-privileged-false-5bd8c3ea-2fc6-4703-8b27-d77a5812a5f8" satisfied condition "Succeeded or Failed"
May  2 20:40:31.510: INFO: Got logs for pod "busybox-privileged-false-5bd8c3ea-2fc6-4703-8b27-d77a5812a5f8": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:40:31.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3713" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":138,"skipped":2509,"failed":0}

SS
------------------------------
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:40:31.575: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a ServiceAccount
STEP: watching for the ServiceAccount to be added
STEP: patching the ServiceAccount
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector)
STEP: deleting the ServiceAccount
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:40:31.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3900" for this suite.

•
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","total":-1,"completed":139,"skipped":2511,"failed":0}

SSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:40:31.916: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating secret with name s-test-opt-del-5a191cd6-bdcf-4fe5-a4b7-3caf1ef4459d
STEP: Creating secret with name s-test-opt-upd-aa8aa497-6042-4d03-8938-71e4dc59a75a
STEP: Creating the pod
May  2 20:40:32.201: INFO: The status of Pod pod-projected-secrets-d9a178d6-e266-423a-a4df-8f0cfda2259d is Pending, waiting for it to be Running (with Ready = true)
May  2 20:40:34.211: INFO: The status of Pod pod-projected-secrets-d9a178d6-e266-423a-a4df-8f0cfda2259d is Pending, waiting for it to be Running (with Ready = true)
May  2 20:40:36.217: INFO: The status of Pod pod-projected-secrets-d9a178d6-e266-423a-a4df-8f0cfda2259d is Running (Ready = true)
STEP: Deleting secret s-test-opt-del-5a191cd6-bdcf-4fe5-a4b7-3caf1ef4459d
STEP: Updating secret s-test-opt-upd-aa8aa497-6042-4d03-8938-71e4dc59a75a
STEP: Creating secret with name s-test-opt-create-16474914-c8a1-479c-af43-a157f13d8d73
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:40:40.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4847" for this suite.


• [SLOW TEST:8.598 seconds]
[sig-storage] Projected secret
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":-1,"completed":140,"skipped":2521,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:40:40.676: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:40:40.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8784" for this suite.

•
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":-1,"completed":141,"skipped":2587,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:40:41.081: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
May  2 20:40:41.200: INFO: Waiting up to 5m0s for pod "downwardapi-volume-66325e20-d458-4dad-ae9c-3839161a10fd" in namespace "projected-4497" to be "Succeeded or Failed"
May  2 20:40:41.255: INFO: Pod "downwardapi-volume-66325e20-d458-4dad-ae9c-3839161a10fd": Phase="Pending", Reason="", readiness=false. Elapsed: 54.665039ms
May  2 20:40:43.267: INFO: Pod "downwardapi-volume-66325e20-d458-4dad-ae9c-3839161a10fd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.066477717s
May  2 20:40:45.306: INFO: Pod "downwardapi-volume-66325e20-d458-4dad-ae9c-3839161a10fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.105861768s
STEP: Saw pod success
May  2 20:40:45.306: INFO: Pod "downwardapi-volume-66325e20-d458-4dad-ae9c-3839161a10fd" satisfied condition "Succeeded or Failed"
May  2 20:40:45.315: INFO: Trying to get logs from node node-2 pod downwardapi-volume-66325e20-d458-4dad-ae9c-3839161a10fd container client-container: <nil>
STEP: delete the pod
May  2 20:40:45.422: INFO: Waiting for pod downwardapi-volume-66325e20-d458-4dad-ae9c-3839161a10fd to disappear
May  2 20:40:45.439: INFO: Pod downwardapi-volume-66325e20-d458-4dad-ae9c-3839161a10fd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:40:45.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4497" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":-1,"completed":142,"skipped":2627,"failed":0}

S
------------------------------
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:40:45.487: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should complete a service status lifecycle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a Service
STEP: watching for the Service to be added
May  2 20:40:45.679: INFO: Found Service test-service-hx7sg in namespace services-1110 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
May  2 20:40:45.679: INFO: Service test-service-hx7sg created
STEP: Getting /status
May  2 20:40:45.697: INFO: Service test-service-hx7sg has LoadBalancer: {[]}
STEP: patching the ServiceStatus
STEP: watching for the Service to be patched
May  2 20:40:45.718: INFO: observed Service test-service-hx7sg in namespace services-1110 with annotations: map[] & LoadBalancer: {[]}
May  2 20:40:45.718: INFO: Found Service test-service-hx7sg in namespace services-1110 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
May  2 20:40:45.718: INFO: Service test-service-hx7sg has service status patched
STEP: updating the ServiceStatus
May  2 20:40:45.818: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated
May  2 20:40:45.830: INFO: Observed Service test-service-hx7sg in namespace services-1110 with annotations: map[] & Conditions: {[]}
May  2 20:40:45.830: INFO: Observed event: &Service{ObjectMeta:{test-service-hx7sg  services-1110  79e2950c-abb5-4c87-b84d-cfaa0793131a 2892235 0 2022-05-02 20:40:45 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] []  [{e2e.test Update v1 2022-05-02 20:40:45 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-05-02 20:40:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.233.26.4,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.233.26.4],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
May  2 20:40:45.833: INFO: Observed event: &Service{ObjectMeta:{test-service-hx7sg  services-1110  79e2950c-abb5-4c87-b84d-cfaa0793131a 2892239 0 2022-05-02 20:40:45 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] []  [{e2e.test Update v1 2022-05-02 20:40:45 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-05-02 20:40:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.233.26.4,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.233.26.4],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}
May  2 20:40:45.833: INFO: Found Service test-service-hx7sg in namespace services-1110 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
May  2 20:40:45.833: INFO: Service test-service-hx7sg has service status updated
STEP: patching the service
STEP: watching for the Service to be patched
May  2 20:40:45.899: INFO: observed Service test-service-hx7sg in namespace services-1110 with labels: map[test-service-static:true]
May  2 20:40:45.899: INFO: observed Service test-service-hx7sg in namespace services-1110 with labels: map[test-service-static:true]
May  2 20:40:45.899: INFO: observed Service test-service-hx7sg in namespace services-1110 with labels: map[test-service-static:true]
May  2 20:40:45.899: INFO: observed Service test-service-hx7sg in namespace services-1110 with labels: map[test-service-static:true]
May  2 20:40:45.899: INFO: Found Service test-service-hx7sg in namespace services-1110 with labels: map[test-service:patched test-service-static:true]
May  2 20:40:45.899: INFO: Service test-service-hx7sg patched
STEP: deleting the service
STEP: watching for the Service to be deleted
May  2 20:40:45.957: INFO: Observed event: ADDED
May  2 20:40:45.957: INFO: Observed event: MODIFIED
May  2 20:40:45.958: INFO: Observed event: MODIFIED
May  2 20:40:45.958: INFO: Observed event: MODIFIED
May  2 20:40:45.958: INFO: Observed event: MODIFIED
May  2 20:40:45.958: INFO: Found Service test-service-hx7sg in namespace services-1110 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
May  2 20:40:45.958: INFO: Service test-service-hx7sg deleted
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:40:45.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1110" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753

•
------------------------------
{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","total":-1,"completed":143,"skipped":2628,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] PreStop
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:40:46.124: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] PreStop
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:157
[It] should call prestop when killing a pod  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating server pod server in namespace prestop-9433
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-9433
STEP: Deleting pre-stop pod
May  2 20:40:57.476: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [sig-node] PreStop
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:40:57.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-9433" for this suite.


• [SLOW TEST:11.499 seconds]
[sig-node] PreStop
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":-1,"completed":144,"skipped":2653,"failed":0}

SSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:40:57.675: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
May  2 20:40:57.813: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a33002eb-a46d-4681-bff0-a6a52563870b" in namespace "downward-api-840" to be "Succeeded or Failed"
May  2 20:40:57.822: INFO: Pod "downwardapi-volume-a33002eb-a46d-4681-bff0-a6a52563870b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.617085ms
May  2 20:40:59.839: INFO: Pod "downwardapi-volume-a33002eb-a46d-4681-bff0-a6a52563870b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025284132s
May  2 20:41:01.850: INFO: Pod "downwardapi-volume-a33002eb-a46d-4681-bff0-a6a52563870b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036392573s
STEP: Saw pod success
May  2 20:41:01.850: INFO: Pod "downwardapi-volume-a33002eb-a46d-4681-bff0-a6a52563870b" satisfied condition "Succeeded or Failed"
May  2 20:41:01.861: INFO: Trying to get logs from node node-2 pod downwardapi-volume-a33002eb-a46d-4681-bff0-a6a52563870b container client-container: <nil>
STEP: delete the pod
May  2 20:41:01.951: INFO: Waiting for pod downwardapi-volume-a33002eb-a46d-4681-bff0-a6a52563870b to disappear
May  2 20:41:01.959: INFO: Pod downwardapi-volume-a33002eb-a46d-4681-bff0-a6a52563870b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:41:01.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-840" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":-1,"completed":145,"skipped":2663,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:41:02.155: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2638.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2638.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2638.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2638.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2638.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-2638.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2638.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-2638.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2638.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-2638.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2638.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-2638.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2638.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 178.12.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.12.178_udp@PTR;check="$$(dig +tcp +noall +answer +search 178.12.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.12.178_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2638.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2638.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2638.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2638.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2638.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2638.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2638.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2638.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2638.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2638.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2638.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2638.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2638.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 178.12.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.12.178_udp@PTR;check="$$(dig +tcp +noall +answer +search 178.12.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.12.178_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May  2 20:41:06.372: INFO: Unable to read wheezy_udp@dns-test-service.dns-2638.svc.cluster.local from pod dns-2638/dns-test-17871784-8c08-4d90-a022-db95f6c43c2c: the server could not find the requested resource (get pods dns-test-17871784-8c08-4d90-a022-db95f6c43c2c)
May  2 20:41:06.383: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2638.svc.cluster.local from pod dns-2638/dns-test-17871784-8c08-4d90-a022-db95f6c43c2c: the server could not find the requested resource (get pods dns-test-17871784-8c08-4d90-a022-db95f6c43c2c)
May  2 20:41:06.407: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2638.svc.cluster.local from pod dns-2638/dns-test-17871784-8c08-4d90-a022-db95f6c43c2c: the server could not find the requested resource (get pods dns-test-17871784-8c08-4d90-a022-db95f6c43c2c)
May  2 20:41:06.424: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2638.svc.cluster.local from pod dns-2638/dns-test-17871784-8c08-4d90-a022-db95f6c43c2c: the server could not find the requested resource (get pods dns-test-17871784-8c08-4d90-a022-db95f6c43c2c)
May  2 20:41:06.515: INFO: Unable to read jessie_udp@dns-test-service.dns-2638.svc.cluster.local from pod dns-2638/dns-test-17871784-8c08-4d90-a022-db95f6c43c2c: the server could not find the requested resource (get pods dns-test-17871784-8c08-4d90-a022-db95f6c43c2c)
May  2 20:41:06.543: INFO: Unable to read jessie_tcp@dns-test-service.dns-2638.svc.cluster.local from pod dns-2638/dns-test-17871784-8c08-4d90-a022-db95f6c43c2c: the server could not find the requested resource (get pods dns-test-17871784-8c08-4d90-a022-db95f6c43c2c)
May  2 20:41:06.551: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2638.svc.cluster.local from pod dns-2638/dns-test-17871784-8c08-4d90-a022-db95f6c43c2c: the server could not find the requested resource (get pods dns-test-17871784-8c08-4d90-a022-db95f6c43c2c)
May  2 20:41:06.561: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2638.svc.cluster.local from pod dns-2638/dns-test-17871784-8c08-4d90-a022-db95f6c43c2c: the server could not find the requested resource (get pods dns-test-17871784-8c08-4d90-a022-db95f6c43c2c)
May  2 20:41:06.621: INFO: Lookups using dns-2638/dns-test-17871784-8c08-4d90-a022-db95f6c43c2c failed for: [wheezy_udp@dns-test-service.dns-2638.svc.cluster.local wheezy_tcp@dns-test-service.dns-2638.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2638.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2638.svc.cluster.local jessie_udp@dns-test-service.dns-2638.svc.cluster.local jessie_tcp@dns-test-service.dns-2638.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2638.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2638.svc.cluster.local]

May  2 20:41:11.912: INFO: DNS probes using dns-2638/dns-test-17871784-8c08-4d90-a022-db95f6c43c2c succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:41:12.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2638" for this suite.


• [SLOW TEST:9.994 seconds]
[sig-network] DNS
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":-1,"completed":146,"skipped":2778,"failed":0}

SSSSS
------------------------------
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:41:12.194: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating projection with secret that has name projected-secret-test-7da76317-4b70-4b0b-9989-28c4efd67052
STEP: Creating a pod to test consume secrets
May  2 20:41:12.452: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-afb84655-bfe4-4ccd-ad81-9e75a88df7e3" in namespace "projected-4420" to be "Succeeded or Failed"
May  2 20:41:12.462: INFO: Pod "pod-projected-secrets-afb84655-bfe4-4ccd-ad81-9e75a88df7e3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.566417ms
May  2 20:41:14.474: INFO: Pod "pod-projected-secrets-afb84655-bfe4-4ccd-ad81-9e75a88df7e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021124969s
May  2 20:41:16.484: INFO: Pod "pod-projected-secrets-afb84655-bfe4-4ccd-ad81-9e75a88df7e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03182598s
STEP: Saw pod success
May  2 20:41:16.485: INFO: Pod "pod-projected-secrets-afb84655-bfe4-4ccd-ad81-9e75a88df7e3" satisfied condition "Succeeded or Failed"
May  2 20:41:16.492: INFO: Trying to get logs from node node-2 pod pod-projected-secrets-afb84655-bfe4-4ccd-ad81-9e75a88df7e3 container projected-secret-volume-test: <nil>
STEP: delete the pod
May  2 20:41:16.544: INFO: Waiting for pod pod-projected-secrets-afb84655-bfe4-4ccd-ad81-9e75a88df7e3 to disappear
May  2 20:41:16.555: INFO: Pod pod-projected-secrets-afb84655-bfe4-4ccd-ad81-9e75a88df7e3 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:41:16.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4420" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":147,"skipped":2783,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:41:16.648: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:188
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:41:16.742: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: creating the pod
STEP: submitting the pod to kubernetes
May  2 20:41:16.792: INFO: The status of Pod pod-exec-websocket-6fcd5cc2-5c56-40d6-bb99-ef91f5700868 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:41:18.805: INFO: The status of Pod pod-exec-websocket-6fcd5cc2-5c56-40d6-bb99-ef91f5700868 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:41:20.812: INFO: The status of Pod pod-exec-websocket-6fcd5cc2-5c56-40d6-bb99-ef91f5700868 is Running (Ready = true)
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:41:21.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7919" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":-1,"completed":148,"skipped":2820,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:41:21.205: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod pod-subpath-test-downwardapi-svdr
STEP: Creating a pod to test atomic-volume-subpath
May  2 20:41:21.467: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-svdr" in namespace "subpath-3690" to be "Succeeded or Failed"
May  2 20:41:21.494: INFO: Pod "pod-subpath-test-downwardapi-svdr": Phase="Pending", Reason="", readiness=false. Elapsed: 26.793863ms
May  2 20:41:23.509: INFO: Pod "pod-subpath-test-downwardapi-svdr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042010244s
May  2 20:41:25.522: INFO: Pod "pod-subpath-test-downwardapi-svdr": Phase="Running", Reason="", readiness=true. Elapsed: 4.054553784s
May  2 20:41:27.550: INFO: Pod "pod-subpath-test-downwardapi-svdr": Phase="Running", Reason="", readiness=true. Elapsed: 6.082599763s
May  2 20:41:29.561: INFO: Pod "pod-subpath-test-downwardapi-svdr": Phase="Running", Reason="", readiness=true. Elapsed: 8.094228885s
May  2 20:41:31.582: INFO: Pod "pod-subpath-test-downwardapi-svdr": Phase="Running", Reason="", readiness=true. Elapsed: 10.114870896s
May  2 20:41:33.603: INFO: Pod "pod-subpath-test-downwardapi-svdr": Phase="Running", Reason="", readiness=true. Elapsed: 12.136118703s
May  2 20:41:35.617: INFO: Pod "pod-subpath-test-downwardapi-svdr": Phase="Running", Reason="", readiness=true. Elapsed: 14.150261578s
May  2 20:41:37.630: INFO: Pod "pod-subpath-test-downwardapi-svdr": Phase="Running", Reason="", readiness=true. Elapsed: 16.163030208s
May  2 20:41:39.645: INFO: Pod "pod-subpath-test-downwardapi-svdr": Phase="Running", Reason="", readiness=true. Elapsed: 18.178331095s
May  2 20:41:41.667: INFO: Pod "pod-subpath-test-downwardapi-svdr": Phase="Running", Reason="", readiness=true. Elapsed: 20.200302133s
May  2 20:41:43.680: INFO: Pod "pod-subpath-test-downwardapi-svdr": Phase="Running", Reason="", readiness=true. Elapsed: 22.213186089s
May  2 20:41:45.690: INFO: Pod "pod-subpath-test-downwardapi-svdr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.222672782s
STEP: Saw pod success
May  2 20:41:45.690: INFO: Pod "pod-subpath-test-downwardapi-svdr" satisfied condition "Succeeded or Failed"
May  2 20:41:45.698: INFO: Trying to get logs from node node-2 pod pod-subpath-test-downwardapi-svdr container test-container-subpath-downwardapi-svdr: <nil>
STEP: delete the pod
May  2 20:41:45.754: INFO: Waiting for pod pod-subpath-test-downwardapi-svdr to disappear
May  2 20:41:45.762: INFO: Pod pod-subpath-test-downwardapi-svdr no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-svdr
May  2 20:41:45.762: INFO: Deleting pod "pod-subpath-test-downwardapi-svdr" in namespace "subpath-3690"
[AfterEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:41:45.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3690" for this suite.


• [SLOW TEST:24.593 seconds]
[sig-storage] Subpath
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [LinuxOnly] [Conformance]","total":-1,"completed":149,"skipped":2866,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:41:45.847: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
May  2 20:41:45.983: INFO: Waiting up to 5m0s for pod "downwardapi-volume-86430b47-223c-4ff0-8ceb-d6c407b611de" in namespace "projected-6273" to be "Succeeded or Failed"
May  2 20:41:46.002: INFO: Pod "downwardapi-volume-86430b47-223c-4ff0-8ceb-d6c407b611de": Phase="Pending", Reason="", readiness=false. Elapsed: 18.494272ms
May  2 20:41:48.010: INFO: Pod "downwardapi-volume-86430b47-223c-4ff0-8ceb-d6c407b611de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027284706s
May  2 20:41:50.037: INFO: Pod "downwardapi-volume-86430b47-223c-4ff0-8ceb-d6c407b611de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053717562s
STEP: Saw pod success
May  2 20:41:50.037: INFO: Pod "downwardapi-volume-86430b47-223c-4ff0-8ceb-d6c407b611de" satisfied condition "Succeeded or Failed"
May  2 20:41:50.064: INFO: Trying to get logs from node node-2 pod downwardapi-volume-86430b47-223c-4ff0-8ceb-d6c407b611de container client-container: <nil>
STEP: delete the pod
May  2 20:41:50.230: INFO: Waiting for pod downwardapi-volume-86430b47-223c-4ff0-8ceb-d6c407b611de to disappear
May  2 20:41:50.239: INFO: Pod downwardapi-volume-86430b47-223c-4ff0-8ceb-d6c407b611de no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:41:50.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6273" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":150,"skipped":2896,"failed":0}

SSSS
------------------------------
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:41:50.297: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:92
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:107
STEP: Creating service test in namespace statefulset-293
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating stateful set ss in namespace statefulset-293
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-293
May  2 20:41:50.474: INFO: Found 0 stateful pods, waiting for 1
May  2 20:42:00.489: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
May  2 20:42:00.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=statefulset-293 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  2 20:42:00.844: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  2 20:42:00.844: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  2 20:42:00.844: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  2 20:42:00.857: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May  2 20:42:10.867: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May  2 20:42:10.867: INFO: Waiting for statefulset status.replicas updated to 0
May  2 20:42:10.933: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
May  2 20:42:10.933: INFO: ss-0  node-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:41:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:41:50 +0000 UTC  }]
May  2 20:42:10.933: INFO: 
May  2 20:42:10.933: INFO: StatefulSet ss has not reached scale 3, at 1
May  2 20:42:11.945: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.979343342s
May  2 20:42:12.963: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.967185962s
May  2 20:42:13.977: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.948907404s
May  2 20:42:14.988: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.936104258s
May  2 20:42:15.999: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.923472111s
May  2 20:42:17.013: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.913445858s
May  2 20:42:18.026: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.898828586s
May  2 20:42:19.037: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.886004862s
May  2 20:42:20.047: INFO: Verifying statefulset ss doesn't scale past 3 for another 876.017313ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-293
May  2 20:42:21.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=statefulset-293 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  2 20:42:21.385: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May  2 20:42:21.385: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  2 20:42:21.385: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May  2 20:42:21.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=statefulset-293 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  2 20:42:21.728: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
May  2 20:42:21.729: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  2 20:42:21.729: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May  2 20:42:21.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=statefulset-293 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  2 20:42:22.096: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
May  2 20:42:22.097: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  2 20:42:22.097: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May  2 20:42:22.106: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May  2 20:42:22.106: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May  2 20:42:22.106: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
May  2 20:42:22.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=statefulset-293 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  2 20:42:22.498: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  2 20:42:22.498: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  2 20:42:22.498: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  2 20:42:22.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=statefulset-293 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  2 20:42:22.856: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  2 20:42:22.856: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  2 20:42:22.856: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  2 20:42:22.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=statefulset-293 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  2 20:42:23.205: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  2 20:42:23.206: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  2 20:42:23.206: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  2 20:42:23.206: INFO: Waiting for statefulset status.replicas updated to 0
May  2 20:42:23.217: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
May  2 20:42:33.238: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May  2 20:42:33.238: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May  2 20:42:33.238: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May  2 20:42:33.270: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
May  2 20:42:33.270: INFO: ss-0  node-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:41:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:41:50 +0000 UTC  }]
May  2 20:42:33.270: INFO: ss-1  node-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:10 +0000 UTC  }]
May  2 20:42:33.271: INFO: ss-2  node-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:10 +0000 UTC  }]
May  2 20:42:33.271: INFO: 
May  2 20:42:33.271: INFO: StatefulSet ss has not reached scale 0, at 3
May  2 20:42:34.281: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
May  2 20:42:34.281: INFO: ss-0  node-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:41:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:41:50 +0000 UTC  }]
May  2 20:42:34.281: INFO: ss-1  node-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:10 +0000 UTC  }]
May  2 20:42:34.281: INFO: ss-2  node-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:10 +0000 UTC  }]
May  2 20:42:34.281: INFO: 
May  2 20:42:34.281: INFO: StatefulSet ss has not reached scale 0, at 3
May  2 20:42:35.292: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
May  2 20:42:35.292: INFO: ss-1  node-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:10 +0000 UTC  }]
May  2 20:42:35.293: INFO: ss-2  node-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-02 20:42:10 +0000 UTC  }]
May  2 20:42:35.293: INFO: 
May  2 20:42:35.293: INFO: StatefulSet ss has not reached scale 0, at 2
May  2 20:42:36.305: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.966841142s
May  2 20:42:37.318: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.954920173s
May  2 20:42:38.327: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.941306833s
May  2 20:42:39.342: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.932039137s
May  2 20:42:40.352: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.917752341s
May  2 20:42:41.361: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.908085469s
May  2 20:42:42.368: INFO: Verifying statefulset ss doesn't scale past 0 for another 898.632595ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-293
May  2 20:42:43.380: INFO: Scaling statefulset ss to 0
May  2 20:42:43.405: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:118
May  2 20:42:43.414: INFO: Deleting all statefulset in ns statefulset-293
May  2 20:42:43.426: INFO: Scaling statefulset ss to 0
May  2 20:42:43.448: INFO: Waiting for statefulset status.replicas updated to 0
May  2 20:42:43.458: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:42:43.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-293" for this suite.


• [SLOW TEST:53.264 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:97
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":-1,"completed":151,"skipped":2900,"failed":0}

SSSSS
------------------------------
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:42:43.590: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:42:54.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5112" for this suite.


• [SLOW TEST:11.304 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":-1,"completed":152,"skipped":2905,"failed":0}

S
------------------------------
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:39:33.852: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:54
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating pod liveness-544ddc2b-729a-49ef-822c-18784097110e in namespace container-probe-201
May  2 20:39:36.014: INFO: Started pod liveness-544ddc2b-729a-49ef-822c-18784097110e in namespace container-probe-201
STEP: checking the pod's current state and verifying that restartCount is present
May  2 20:39:36.022: INFO: Initial restart count of pod liveness-544ddc2b-729a-49ef-822c-18784097110e is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:43:36.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-201" for this suite.


• [SLOW TEST:242.391 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","total":-1,"completed":147,"skipped":2565,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:43:36.423: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  2 20:43:37.633: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May  2 20:43:39.670: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787121017, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787121017, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787121017, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787121017, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  2 20:43:42.701: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:43:42.726: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4663-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:43:51.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3601" for this suite.
STEP: Destroying namespace "webhook-3601-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102


• [SLOW TEST:14.821 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":-1,"completed":148,"skipped":2607,"failed":0}

SSSSSS
------------------------------
[BeforeEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:43:51.527: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Performing setup for networking test in namespace pod-network-test-8606
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May  2 20:43:51.682: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
May  2 20:43:51.996: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:43:54.022: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:43:56.025: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 20:43:58.029: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 20:44:00.012: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 20:44:02.026: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 20:44:04.007: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 20:44:06.008: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 20:44:08.005: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 20:44:10.015: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 20:44:12.027: INFO: The status of Pod netserver-0 is Running (Ready = true)
May  2 20:44:12.064: INFO: The status of Pod netserver-1 is Running (Ready = true)
May  2 20:44:12.095: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
May  2 20:44:16.251: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
May  2 20:44:16.251: INFO: Going to poll 10.233.95.244 on port 8083 at least 0 times, with a maximum of 39 tries before failing
May  2 20:44:16.258: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.95.244:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8606 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 20:44:16.258: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
May  2 20:44:16.471: INFO: Found all 1 expected endpoints: [netserver-0]
May  2 20:44:16.471: INFO: Going to poll 10.233.112.18 on port 8083 at least 0 times, with a maximum of 39 tries before failing
May  2 20:44:16.482: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.112.18:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8606 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 20:44:16.482: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
May  2 20:44:16.655: INFO: Found all 1 expected endpoints: [netserver-1]
May  2 20:44:16.655: INFO: Going to poll 10.233.69.219 on port 8083 at least 0 times, with a maximum of 39 tries before failing
May  2 20:44:16.670: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.69.219:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8606 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 20:44:16.670: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
May  2 20:44:16.860: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:44:16.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8606" for this suite.


• [SLOW TEST:25.374 seconds]
[sig-network] Networking
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/networking.go:30
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":149,"skipped":2613,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:44:17.021: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/endpointslice.go:49
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
[AfterEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:44:17.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-9103" for this suite.

•
------------------------------
{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","total":-1,"completed":150,"skipped":2663,"failed":0}

SSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:44:17.219: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service in namespace services-8212
STEP: creating service affinity-nodeport in namespace services-8212
STEP: creating replication controller affinity-nodeport in namespace services-8212
I0502 20:44:17.358868      18 runners.go:190] Created replication controller with name: affinity-nodeport, namespace: services-8212, replica count: 3
I0502 20:44:20.410984      18 runners.go:190] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  2 20:44:20.447: INFO: Creating new exec pod
May  2 20:44:25.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=services-8212 exec execpod-affinitywrrgp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
May  2 20:44:25.931: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
May  2 20:44:25.932: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 20:44:25.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=services-8212 exec execpod-affinitywrrgp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.61.71 80'
May  2 20:44:26.218: INFO: stderr: "+ nc -v -t -w 2 10.233.61.71 80\n+ echo hostName\nConnection to 10.233.61.71 80 port [tcp/http] succeeded!\n"
May  2 20:44:26.218: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 20:44:26.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=services-8212 exec execpod-affinitywrrgp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.20.46 31275'
May  2 20:44:26.570: INFO: stderr: "+ nc -v -t -w 2 10.100.20.46 31275\nConnection to 10.100.20.46 31275 port [tcp/*] succeeded!\n+ echo hostName\n"
May  2 20:44:26.570: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 20:44:26.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=services-8212 exec execpod-affinitywrrgp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.18.197 31275'
May  2 20:44:26.950: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.100.18.197 31275\nConnection to 10.100.18.197 31275 port [tcp/*] succeeded!\n"
May  2 20:44:26.950: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 20:44:26.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=services-8212 exec execpod-affinitywrrgp -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.100.18.197:31275/ ; done'
May  2 20:44:27.432: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31275/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31275/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31275/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31275/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31275/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31275/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31275/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31275/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31275/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31275/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31275/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31275/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31275/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31275/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31275/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:31275/\n"
May  2 20:44:27.433: INFO: stdout: "\naffinity-nodeport-zggxx\naffinity-nodeport-zggxx\naffinity-nodeport-zggxx\naffinity-nodeport-zggxx\naffinity-nodeport-zggxx\naffinity-nodeport-zggxx\naffinity-nodeport-zggxx\naffinity-nodeport-zggxx\naffinity-nodeport-zggxx\naffinity-nodeport-zggxx\naffinity-nodeport-zggxx\naffinity-nodeport-zggxx\naffinity-nodeport-zggxx\naffinity-nodeport-zggxx\naffinity-nodeport-zggxx\naffinity-nodeport-zggxx"
May  2 20:44:27.433: INFO: Received response from host: affinity-nodeport-zggxx
May  2 20:44:27.433: INFO: Received response from host: affinity-nodeport-zggxx
May  2 20:44:27.433: INFO: Received response from host: affinity-nodeport-zggxx
May  2 20:44:27.433: INFO: Received response from host: affinity-nodeport-zggxx
May  2 20:44:27.433: INFO: Received response from host: affinity-nodeport-zggxx
May  2 20:44:27.433: INFO: Received response from host: affinity-nodeport-zggxx
May  2 20:44:27.433: INFO: Received response from host: affinity-nodeport-zggxx
May  2 20:44:27.433: INFO: Received response from host: affinity-nodeport-zggxx
May  2 20:44:27.433: INFO: Received response from host: affinity-nodeport-zggxx
May  2 20:44:27.433: INFO: Received response from host: affinity-nodeport-zggxx
May  2 20:44:27.433: INFO: Received response from host: affinity-nodeport-zggxx
May  2 20:44:27.433: INFO: Received response from host: affinity-nodeport-zggxx
May  2 20:44:27.433: INFO: Received response from host: affinity-nodeport-zggxx
May  2 20:44:27.433: INFO: Received response from host: affinity-nodeport-zggxx
May  2 20:44:27.433: INFO: Received response from host: affinity-nodeport-zggxx
May  2 20:44:27.433: INFO: Received response from host: affinity-nodeport-zggxx
May  2 20:44:27.433: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-8212, will wait for the garbage collector to delete the pods
May  2 20:44:27.639: INFO: Deleting ReplicationController affinity-nodeport took: 28.713367ms
May  2 20:44:27.842: INFO: Terminating ReplicationController affinity-nodeport pods took: 202.934871ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:44:31.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8212" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753


• [SLOW TEST:14.133 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","total":-1,"completed":151,"skipped":2675,"failed":0}

SSSSSSSSS
------------------------------
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:44:31.398: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-324 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-324;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-324 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-324;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-324.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-324.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-324.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-324.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-324.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-324.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-324.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-324.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-324.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-324.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-324.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-324.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-324.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 55.39.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.39.55_udp@PTR;check="$$(dig +tcp +noall +answer +search 55.39.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.39.55_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-324 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-324;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-324 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-324;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-324.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-324.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-324.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-324.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-324.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-324.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-324.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-324.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-324.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-324.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-324.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-324.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-324.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 55.39.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.39.55_udp@PTR;check="$$(dig +tcp +noall +answer +search 55.39.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.39.55_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May  2 20:44:35.836: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-324/dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb: the server could not find the requested resource (get pods dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb)
May  2 20:44:35.853: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-324/dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb: the server could not find the requested resource (get pods dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb)
May  2 20:44:35.863: INFO: Unable to read wheezy_udp@dns-test-service.dns-324 from pod dns-324/dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb: the server could not find the requested resource (get pods dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb)
May  2 20:44:35.871: INFO: Unable to read wheezy_tcp@dns-test-service.dns-324 from pod dns-324/dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb: the server could not find the requested resource (get pods dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb)
May  2 20:44:35.878: INFO: Unable to read wheezy_udp@dns-test-service.dns-324.svc from pod dns-324/dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb: the server could not find the requested resource (get pods dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb)
May  2 20:44:35.886: INFO: Unable to read wheezy_tcp@dns-test-service.dns-324.svc from pod dns-324/dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb: the server could not find the requested resource (get pods dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb)
May  2 20:44:35.894: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-324.svc from pod dns-324/dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb: the server could not find the requested resource (get pods dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb)
May  2 20:44:35.906: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-324.svc from pod dns-324/dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb: the server could not find the requested resource (get pods dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb)
May  2 20:44:35.964: INFO: Unable to read jessie_udp@dns-test-service from pod dns-324/dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb: the server could not find the requested resource (get pods dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb)
May  2 20:44:35.971: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-324/dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb: the server could not find the requested resource (get pods dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb)
May  2 20:44:35.978: INFO: Unable to read jessie_udp@dns-test-service.dns-324 from pod dns-324/dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb: the server could not find the requested resource (get pods dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb)
May  2 20:44:35.987: INFO: Unable to read jessie_tcp@dns-test-service.dns-324 from pod dns-324/dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb: the server could not find the requested resource (get pods dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb)
May  2 20:44:35.995: INFO: Unable to read jessie_udp@dns-test-service.dns-324.svc from pod dns-324/dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb: the server could not find the requested resource (get pods dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb)
May  2 20:44:36.009: INFO: Unable to read jessie_tcp@dns-test-service.dns-324.svc from pod dns-324/dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb: the server could not find the requested resource (get pods dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb)
May  2 20:44:36.029: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-324.svc from pod dns-324/dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb: the server could not find the requested resource (get pods dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb)
May  2 20:44:36.046: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-324.svc from pod dns-324/dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb: the server could not find the requested resource (get pods dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb)
May  2 20:44:36.146: INFO: Lookups using dns-324/dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-324 wheezy_tcp@dns-test-service.dns-324 wheezy_udp@dns-test-service.dns-324.svc wheezy_tcp@dns-test-service.dns-324.svc wheezy_udp@_http._tcp.dns-test-service.dns-324.svc wheezy_tcp@_http._tcp.dns-test-service.dns-324.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-324 jessie_tcp@dns-test-service.dns-324 jessie_udp@dns-test-service.dns-324.svc jessie_tcp@dns-test-service.dns-324.svc jessie_udp@_http._tcp.dns-test-service.dns-324.svc jessie_tcp@_http._tcp.dns-test-service.dns-324.svc]

May  2 20:44:41.696: INFO: DNS probes using dns-324/dns-test-b1f3f394-03af-49dd-ae4c-f32ee8d3b2bb succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:44:41.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-324" for this suite.


• [SLOW TEST:10.609 seconds]
[sig-network] DNS
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":-1,"completed":152,"skipped":2684,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:44:42.122: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-map-703b9309-aa10-486f-999e-612a92d28e45
STEP: Creating a pod to test consume configMaps
May  2 20:44:42.246: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c0185708-e26a-461e-8fd9-97c1a3b3c0a7" in namespace "projected-36" to be "Succeeded or Failed"
May  2 20:44:42.327: INFO: Pod "pod-projected-configmaps-c0185708-e26a-461e-8fd9-97c1a3b3c0a7": Phase="Pending", Reason="", readiness=false. Elapsed: 80.825901ms
May  2 20:44:44.342: INFO: Pod "pod-projected-configmaps-c0185708-e26a-461e-8fd9-97c1a3b3c0a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.095219245s
May  2 20:44:46.355: INFO: Pod "pod-projected-configmaps-c0185708-e26a-461e-8fd9-97c1a3b3c0a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.108766097s
STEP: Saw pod success
May  2 20:44:46.355: INFO: Pod "pod-projected-configmaps-c0185708-e26a-461e-8fd9-97c1a3b3c0a7" satisfied condition "Succeeded or Failed"
May  2 20:44:46.371: INFO: Trying to get logs from node node-2 pod pod-projected-configmaps-c0185708-e26a-461e-8fd9-97c1a3b3c0a7 container agnhost-container: <nil>
STEP: delete the pod
May  2 20:44:46.476: INFO: Waiting for pod pod-projected-configmaps-c0185708-e26a-461e-8fd9-97c1a3b3c0a7 to disappear
May  2 20:44:46.513: INFO: Pod pod-projected-configmaps-c0185708-e26a-461e-8fd9-97c1a3b3c0a7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:44:46.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-36" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":-1,"completed":153,"skipped":2711,"failed":0}

SSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:44:46.586: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test emptydir 0666 on node default medium
May  2 20:44:46.729: INFO: Waiting up to 5m0s for pod "pod-91993f01-c6ee-412e-9d0b-0e42e8fe2a30" in namespace "emptydir-7720" to be "Succeeded or Failed"
May  2 20:44:46.760: INFO: Pod "pod-91993f01-c6ee-412e-9d0b-0e42e8fe2a30": Phase="Pending", Reason="", readiness=false. Elapsed: 31.373142ms
May  2 20:44:48.778: INFO: Pod "pod-91993f01-c6ee-412e-9d0b-0e42e8fe2a30": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049026279s
May  2 20:44:50.791: INFO: Pod "pod-91993f01-c6ee-412e-9d0b-0e42e8fe2a30": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.061650021s
STEP: Saw pod success
May  2 20:44:50.791: INFO: Pod "pod-91993f01-c6ee-412e-9d0b-0e42e8fe2a30" satisfied condition "Succeeded or Failed"
May  2 20:44:50.798: INFO: Trying to get logs from node node-2 pod pod-91993f01-c6ee-412e-9d0b-0e42e8fe2a30 container test-container: <nil>
STEP: delete the pod
May  2 20:44:50.851: INFO: Waiting for pod pod-91993f01-c6ee-412e-9d0b-0e42e8fe2a30 to disappear
May  2 20:44:50.857: INFO: Pod pod-91993f01-c6ee-412e-9d0b-0e42e8fe2a30 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:44:50.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7720" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":154,"skipped":2725,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:44:51.001: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create and stop a working application  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating all guestbook components
May  2 20:44:51.099: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

May  2 20:44:51.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-1270 create -f -'
May  2 20:44:53.423: INFO: stderr: ""
May  2 20:44:53.423: INFO: stdout: "service/agnhost-replica created\n"
May  2 20:44:53.423: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

May  2 20:44:53.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-1270 create -f -'
May  2 20:44:55.414: INFO: stderr: ""
May  2 20:44:55.414: INFO: stdout: "service/agnhost-primary created\n"
May  2 20:44:55.415: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

May  2 20:44:55.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-1270 create -f -'
May  2 20:44:57.573: INFO: stderr: ""
May  2 20:44:57.573: INFO: stdout: "service/frontend created\n"
May  2 20:44:57.574: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: k8s.gcr.io/e2e-test-images/agnhost:2.32
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

May  2 20:44:57.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-1270 create -f -'
May  2 20:44:58.058: INFO: stderr: ""
May  2 20:44:58.058: INFO: stdout: "deployment.apps/frontend created\n"
May  2 20:44:58.058: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: k8s.gcr.io/e2e-test-images/agnhost:2.32
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May  2 20:44:58.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-1270 create -f -'
May  2 20:44:58.708: INFO: stderr: ""
May  2 20:44:58.729: INFO: stdout: "deployment.apps/agnhost-primary created\n"
May  2 20:44:58.729: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: k8s.gcr.io/e2e-test-images/agnhost:2.32
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May  2 20:44:58.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-1270 create -f -'
May  2 20:44:59.811: INFO: stderr: ""
May  2 20:44:59.811: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app
May  2 20:44:59.811: INFO: Waiting for all frontend pods to be Running.
May  2 20:45:04.863: INFO: Waiting for frontend to serve content.
May  2 20:45:04.907: INFO: Trying to add a new entry to the guestbook.
May  2 20:45:04.938: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
May  2 20:45:04.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-1270 delete --grace-period=0 --force -f -'
May  2 20:45:05.159: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  2 20:45:05.159: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources
May  2 20:45:05.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-1270 delete --grace-period=0 --force -f -'
May  2 20:45:05.417: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  2 20:45:05.417: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources
May  2 20:45:05.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-1270 delete --grace-period=0 --force -f -'
May  2 20:45:05.733: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  2 20:45:05.733: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May  2 20:45:05.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-1270 delete --grace-period=0 --force -f -'
May  2 20:45:05.917: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  2 20:45:05.918: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May  2 20:45:05.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-1270 delete --grace-period=0 --force -f -'
May  2 20:45:06.232: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  2 20:45:06.232: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources
May  2 20:45:06.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300316069 --namespace=kubectl-1270 delete --grace-period=0 --force -f -'
May  2 20:45:06.529: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  2 20:45:06.529: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:45:06.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1270" for this suite.


• [SLOW TEST:15.582 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:339
    should create and stop a working application  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":-1,"completed":155,"skipped":2752,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:45:06.959: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test downward API volume plugin
May  2 20:45:07.257: INFO: Waiting up to 5m0s for pod "downwardapi-volume-528e4a62-0498-453b-9033-5d206b5c7ffc" in namespace "projected-5451" to be "Succeeded or Failed"
May  2 20:45:07.298: INFO: Pod "downwardapi-volume-528e4a62-0498-453b-9033-5d206b5c7ffc": Phase="Pending", Reason="", readiness=false. Elapsed: 40.274979ms
May  2 20:45:09.323: INFO: Pod "downwardapi-volume-528e4a62-0498-453b-9033-5d206b5c7ffc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.066019079s
May  2 20:45:11.346: INFO: Pod "downwardapi-volume-528e4a62-0498-453b-9033-5d206b5c7ffc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.088898533s
STEP: Saw pod success
May  2 20:45:11.346: INFO: Pod "downwardapi-volume-528e4a62-0498-453b-9033-5d206b5c7ffc" satisfied condition "Succeeded or Failed"
May  2 20:45:11.357: INFO: Trying to get logs from node node-1 pod downwardapi-volume-528e4a62-0498-453b-9033-5d206b5c7ffc container client-container: <nil>
STEP: delete the pod
May  2 20:45:11.480: INFO: Waiting for pod downwardapi-volume-528e4a62-0498-453b-9033-5d206b5c7ffc to disappear
May  2 20:45:11.499: INFO: Pod downwardapi-volume-528e4a62-0498-453b-9033-5d206b5c7ffc no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:45:11.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5451" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":-1,"completed":156,"skipped":2853,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:45:11.641: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename certificates
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support CSR API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: getting /apis
STEP: getting /apis/certificates.k8s.io
STEP: getting /apis/certificates.k8s.io/v1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
May  2 20:45:13.863: INFO: starting watch
STEP: patching
STEP: updating
May  2 20:45:13.922: INFO: waiting for watch events with expected annotations
May  2 20:45:13.922: INFO: saw patched and updated annotations
STEP: getting /approval
STEP: patching /approval
STEP: updating /approval
STEP: getting /status
STEP: patching /status
STEP: updating /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:45:14.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-9522" for this suite.

•
------------------------------
{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","total":-1,"completed":157,"skipped":2883,"failed":0}

SSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:45:14.169: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
May  2 20:45:14.301: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6184  292dbe34-d4f6-45b3-bf6c-cdad596e7f6c 2895193 0 2022-05-02 20:45:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-05-02 20:45:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
May  2 20:45:14.301: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6184  292dbe34-d4f6-45b3-bf6c-cdad596e7f6c 2895195 0 2022-05-02 20:45:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-05-02 20:45:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
May  2 20:45:14.301: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6184  292dbe34-d4f6-45b3-bf6c-cdad596e7f6c 2895196 0 2022-05-02 20:45:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-05-02 20:45:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
May  2 20:45:24.435: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6184  292dbe34-d4f6-45b3-bf6c-cdad596e7f6c 2895284 0 2022-05-02 20:45:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-05-02 20:45:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
May  2 20:45:24.435: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6184  292dbe34-d4f6-45b3-bf6c-cdad596e7f6c 2895286 0 2022-05-02 20:45:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-05-02 20:45:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
May  2 20:45:24.435: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6184  292dbe34-d4f6-45b3-bf6c-cdad596e7f6c 2895289 0 2022-05-02 20:45:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-05-02 20:45:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:45:24.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6184" for this suite.


• [SLOW TEST:10.307 seconds]
[sig-api-machinery] Watchers
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":-1,"completed":158,"skipped":2889,"failed":0}

SSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:45:24.514: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap that has name configmap-test-emptyKey-a1bc6077-88cc-478c-85c8-34a74e3be674
[AfterEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:45:24.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-998" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":-1,"completed":159,"skipped":2903,"failed":0}

SSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:42:54.906: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:749
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: creating service in namespace services-2563
May  2 20:42:55.042: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
May  2 20:42:57.062: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
May  2 20:42:59.054: INFO: The status of Pod kube-proxy-mode-detector is Running (Ready = true)
May  2 20:42:59.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-2563 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
May  2 20:42:59.491: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
May  2 20:42:59.491: INFO: stdout: "ipvs"
May  2 20:42:59.491: INFO: proxyMode: ipvs
May  2 20:42:59.552: INFO: Waiting for pod kube-proxy-mode-detector to disappear
May  2 20:42:59.564: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-2563
STEP: creating replication controller affinity-nodeport-timeout in namespace services-2563
I0502 20:42:59.720256      19 runners.go:190] Created replication controller with name: affinity-nodeport-timeout, namespace: services-2563, replica count: 3
I0502 20:43:02.774190      19 runners.go:190] affinity-nodeport-timeout Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0502 20:43:05.775539      19 runners.go:190] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  2 20:43:05.816: INFO: Creating new exec pod
May  2 20:43:10.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-2563 exec execpod-affinitygnvpl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
May  2 20:43:11.302: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport-timeout 80\n+ echo hostName\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
May  2 20:43:11.302: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 20:43:11.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-2563 exec execpod-affinitygnvpl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.20.185 80'
May  2 20:43:11.596: INFO: stderr: "+ nc -v -t -w 2 10.233.20.185 80\n+ echo hostName\nConnection to 10.233.20.185 80 port [tcp/http] succeeded!\n"
May  2 20:43:11.596: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 20:43:11.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-2563 exec execpod-affinitygnvpl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.20.46 30836'
May  2 20:43:12.055: INFO: stderr: "+ nc -v -t -w 2 10.100.20.46 30836\n+ echo hostName\nConnection to 10.100.20.46 30836 port [tcp/*] succeeded!\n"
May  2 20:43:12.055: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 20:43:12.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-2563 exec execpod-affinitygnvpl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.100.20.186 30836'
May  2 20:43:12.666: INFO: stderr: "+ nc -v -t -w 2 10.100.20.186 30836\n+ echo hostName\nConnection to 10.100.20.186 30836 port [tcp/*] succeeded!\n"
May  2 20:43:12.666: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 20:43:12.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-2563 exec execpod-affinitygnvpl -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.100.18.197:30836/ ; done'
May  2 20:43:13.260: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:30836/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:30836/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:30836/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:30836/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:30836/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:30836/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:30836/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:30836/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:30836/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:30836/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:30836/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:30836/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:30836/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:30836/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:30836/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.100.18.197:30836/\n"
May  2 20:43:13.260: INFO: stdout: "\naffinity-nodeport-timeout-xdh6g\naffinity-nodeport-timeout-xdh6g\naffinity-nodeport-timeout-xdh6g\naffinity-nodeport-timeout-xdh6g\naffinity-nodeport-timeout-xdh6g\naffinity-nodeport-timeout-xdh6g\naffinity-nodeport-timeout-xdh6g\naffinity-nodeport-timeout-xdh6g\naffinity-nodeport-timeout-xdh6g\naffinity-nodeport-timeout-xdh6g\naffinity-nodeport-timeout-xdh6g\naffinity-nodeport-timeout-xdh6g\naffinity-nodeport-timeout-xdh6g\naffinity-nodeport-timeout-xdh6g\naffinity-nodeport-timeout-xdh6g\naffinity-nodeport-timeout-xdh6g"
May  2 20:43:13.260: INFO: Received response from host: affinity-nodeport-timeout-xdh6g
May  2 20:43:13.260: INFO: Received response from host: affinity-nodeport-timeout-xdh6g
May  2 20:43:13.260: INFO: Received response from host: affinity-nodeport-timeout-xdh6g
May  2 20:43:13.260: INFO: Received response from host: affinity-nodeport-timeout-xdh6g
May  2 20:43:13.260: INFO: Received response from host: affinity-nodeport-timeout-xdh6g
May  2 20:43:13.260: INFO: Received response from host: affinity-nodeport-timeout-xdh6g
May  2 20:43:13.260: INFO: Received response from host: affinity-nodeport-timeout-xdh6g
May  2 20:43:13.260: INFO: Received response from host: affinity-nodeport-timeout-xdh6g
May  2 20:43:13.260: INFO: Received response from host: affinity-nodeport-timeout-xdh6g
May  2 20:43:13.260: INFO: Received response from host: affinity-nodeport-timeout-xdh6g
May  2 20:43:13.260: INFO: Received response from host: affinity-nodeport-timeout-xdh6g
May  2 20:43:13.260: INFO: Received response from host: affinity-nodeport-timeout-xdh6g
May  2 20:43:13.260: INFO: Received response from host: affinity-nodeport-timeout-xdh6g
May  2 20:43:13.260: INFO: Received response from host: affinity-nodeport-timeout-xdh6g
May  2 20:43:13.260: INFO: Received response from host: affinity-nodeport-timeout-xdh6g
May  2 20:43:13.260: INFO: Received response from host: affinity-nodeport-timeout-xdh6g
May  2 20:43:13.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-2563 exec execpod-affinitygnvpl -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.100.18.197:30836/'
May  2 20:43:13.582: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.100.18.197:30836/\n"
May  2 20:43:13.582: INFO: stdout: "affinity-nodeport-timeout-xdh6g"
May  2 20:45:23.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-267064716 --namespace=services-2563 exec execpod-affinitygnvpl -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.100.18.197:30836/'
May  2 20:45:23.952: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.100.18.197:30836/\n"
May  2 20:45:23.952: INFO: stdout: "affinity-nodeport-timeout-9jwjt"
May  2 20:45:23.952: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-2563, will wait for the garbage collector to delete the pods
May  2 20:45:24.174: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 76.749381ms
May  2 20:45:24.275: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 101.458775ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:45:27.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2563" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:753


• [SLOW TEST:152.988 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","total":-1,"completed":153,"skipped":2906,"failed":0}

SSSSSSSSSSS
------------------------------
[BeforeEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:45:24.707: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a pod to test override command
May  2 20:45:24.791: INFO: Waiting up to 5m0s for pod "client-containers-9f93ebe4-892a-4db2-bfb6-9c58f401492e" in namespace "containers-3868" to be "Succeeded or Failed"
May  2 20:45:24.814: INFO: Pod "client-containers-9f93ebe4-892a-4db2-bfb6-9c58f401492e": Phase="Pending", Reason="", readiness=false. Elapsed: 23.566449ms
May  2 20:45:26.828: INFO: Pod "client-containers-9f93ebe4-892a-4db2-bfb6-9c58f401492e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037366767s
May  2 20:45:28.855: INFO: Pod "client-containers-9f93ebe4-892a-4db2-bfb6-9c58f401492e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063905391s
STEP: Saw pod success
May  2 20:45:28.855: INFO: Pod "client-containers-9f93ebe4-892a-4db2-bfb6-9c58f401492e" satisfied condition "Succeeded or Failed"
May  2 20:45:28.870: INFO: Trying to get logs from node node-2 pod client-containers-9f93ebe4-892a-4db2-bfb6-9c58f401492e container agnhost-container: <nil>
STEP: delete the pod
May  2 20:45:28.988: INFO: Waiting for pod client-containers-9f93ebe4-892a-4db2-bfb6-9c58f401492e to disappear
May  2 20:45:29.008: INFO: Pod client-containers-9f93ebe4-892a-4db2-bfb6-9c58f401492e no longer exists
[AfterEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:45:29.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3868" for this suite.

•
------------------------------
{"msg":"PASSED [sig-node] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]","total":-1,"completed":160,"skipped":2919,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:45:29.234: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should validate Replicaset Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Create a Replicaset
STEP: Verify that the required pods have come up.
May  2 20:45:29.392: INFO: Pod name sample-pod: Found 0 pods out of 1
May  2 20:45:34.409: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: Getting /status
May  2 20:45:34.417: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status
May  2 20:45:34.458: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated
May  2 20:45:34.461: INFO: Observed &ReplicaSet event: ADDED
May  2 20:45:34.461: INFO: Observed &ReplicaSet event: MODIFIED
May  2 20:45:34.462: INFO: Observed &ReplicaSet event: MODIFIED
May  2 20:45:34.462: INFO: Observed &ReplicaSet event: MODIFIED
May  2 20:45:34.462: INFO: Found replicaset test-rs in namespace replicaset-6859 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
May  2 20:45:34.462: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status
May  2 20:45:34.462: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
May  2 20:45:34.495: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched
May  2 20:45:34.499: INFO: Observed &ReplicaSet event: ADDED
May  2 20:45:34.499: INFO: Observed &ReplicaSet event: MODIFIED
May  2 20:45:34.499: INFO: Observed &ReplicaSet event: MODIFIED
May  2 20:45:34.499: INFO: Observed &ReplicaSet event: MODIFIED
May  2 20:45:34.499: INFO: Observed replicaset test-rs in namespace replicaset-6859 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
May  2 20:45:34.500: INFO: Observed &ReplicaSet event: MODIFIED
May  2 20:45:34.500: INFO: Found replicaset test-rs in namespace replicaset-6859 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
May  2 20:45:34.500: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:45:34.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6859" for this suite.


• [SLOW TEST:5.291 seconds]
[sig-apps] ReplicaSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","total":-1,"completed":161,"skipped":2949,"failed":0}

SSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:45:34.537: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating the pod
May  2 20:45:34.669: INFO: The status of Pod annotationupdateff390a8c-571f-46de-9466-d0e3bc69e208 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:45:36.681: INFO: The status of Pod annotationupdateff390a8c-571f-46de-9466-d0e3bc69e208 is Running (Ready = true)
May  2 20:45:37.265: INFO: Successfully updated pod "annotationupdateff390a8c-571f-46de-9466-d0e3bc69e208"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:45:39.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9238" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":-1,"completed":162,"skipped":2960,"failed":0}

SSSSSS
------------------------------
[BeforeEach] [sig-scheduling] LimitRange
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:45:39.350: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename limitrange
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a LimitRange
STEP: Setting up watch
STEP: Submitting a LimitRange
May  2 20:45:39.470: INFO: observed the limitRanges list
STEP: Verifying LimitRange creation was observed
STEP: Fetching the LimitRange to ensure it has proper values
May  2 20:45:39.503: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
May  2 20:45:39.504: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements
STEP: Ensuring Pod has resource requirements applied from LimitRange
May  2 20:45:39.539: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
May  2 20:45:39.540: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements
STEP: Ensuring Pod has merged resource requirements applied from LimitRange
May  2 20:45:39.628: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
May  2 20:45:39.628: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources
STEP: Failing to create a Pod with more than max resources
STEP: Updating a LimitRange
STEP: Verifying LimitRange updating is effective
STEP: Creating a Pod with less than former min resources
STEP: Failing to create a Pod with more than max resources
STEP: Deleting a LimitRange
STEP: Verifying the LimitRange was deleted
May  2 20:45:46.759: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources
[AfterEach] [sig-scheduling] LimitRange
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:45:46.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-2875" for this suite.


• [SLOW TEST:7.501 seconds]
[sig-scheduling] LimitRange
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","total":-1,"completed":163,"skipped":2966,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-network] EndpointSliceMirroring
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:45:47.011: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename endpointslicemirroring
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSliceMirroring
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/endpointslicemirroring.go:39
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: mirroring a new custom Endpoint
May  2 20:45:47.194: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint
May  2 20:45:49.224: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
STEP: mirroring deletion of a custom Endpoint
[AfterEach] [sig-network] EndpointSliceMirroring
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:45:51.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-5057" for this suite.

•
------------------------------
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","total":-1,"completed":164,"skipped":3009,"failed":0}

SSSSS
------------------------------
[BeforeEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:45:27.940: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Performing setup for networking test in namespace pod-network-test-4938
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May  2 20:45:28.056: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
May  2 20:45:28.159: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:45:30.182: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May  2 20:45:32.183: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 20:45:34.175: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 20:45:36.197: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 20:45:38.170: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 20:45:40.180: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 20:45:42.183: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 20:45:44.185: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 20:45:46.171: INFO: The status of Pod netserver-0 is Running (Ready = false)
May  2 20:45:48.186: INFO: The status of Pod netserver-0 is Running (Ready = true)
May  2 20:45:48.219: INFO: The status of Pod netserver-1 is Running (Ready = false)
May  2 20:45:50.252: INFO: The status of Pod netserver-1 is Running (Ready = true)
May  2 20:45:50.264: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
May  2 20:45:56.581: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
May  2 20:45:56.581: INFO: Going to poll 10.233.95.245 on port 8081 at least 0 times, with a maximum of 39 tries before failing
May  2 20:45:56.600: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.95.245 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4938 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 20:45:56.600: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
May  2 20:45:58.409: INFO: Found all 1 expected endpoints: [netserver-0]
May  2 20:45:58.409: INFO: Going to poll 10.233.112.26 on port 8081 at least 0 times, with a maximum of 39 tries before failing
May  2 20:45:58.431: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.112.26 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4938 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 20:45:58.431: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
May  2 20:45:59.662: INFO: Found all 1 expected endpoints: [netserver-1]
May  2 20:45:59.662: INFO: Going to poll 10.233.69.234 on port 8081 at least 0 times, with a maximum of 39 tries before failing
May  2 20:45:59.690: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.69.234 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4938 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 20:45:59.691: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
May  2 20:46:00.975: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:46:00.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4938" for this suite.


• [SLOW TEST:33.082 seconds]
[sig-network] Networking
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/networking.go:30
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":-1,"completed":154,"skipped":2917,"failed":0}

SSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:46:01.051: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  2 20:46:01.852: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
May  2 20:46:03.884: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787121161, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787121161, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787121161, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787121161, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  2 20:46:06.955: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
May  2 20:46:06.991: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8821-crds.webhook.example.com via the AdmissionRegistration API
May  2 20:46:12.582: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:46:15.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9307" for this suite.
STEP: Destroying namespace "webhook-9307-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102


• [SLOW TEST:14.550 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":-1,"completed":155,"skipped":2923,"failed":0}

SSSSS
------------------------------
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:45:51.379: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
May  2 20:46:31.868: INFO: The status of Pod kube-controller-manager-node-2 is Running (Ready = true)
May  2 20:46:32.051: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

May  2 20:46:32.051: INFO: Deleting pod "simpletest.rc-2c58d" in namespace "gc-9647"
May  2 20:46:32.121: INFO: Deleting pod "simpletest.rc-99lnr" in namespace "gc-9647"
May  2 20:46:32.235: INFO: Deleting pod "simpletest.rc-cx54k" in namespace "gc-9647"
May  2 20:46:32.338: INFO: Deleting pod "simpletest.rc-gnztl" in namespace "gc-9647"
May  2 20:46:32.394: INFO: Deleting pod "simpletest.rc-hwpj2" in namespace "gc-9647"
May  2 20:46:32.437: INFO: Deleting pod "simpletest.rc-jh6mv" in namespace "gc-9647"
May  2 20:46:32.479: INFO: Deleting pod "simpletest.rc-ktwdp" in namespace "gc-9647"
May  2 20:46:32.587: INFO: Deleting pod "simpletest.rc-vpfxm" in namespace "gc-9647"
May  2 20:46:32.696: INFO: Deleting pod "simpletest.rc-xtjjx" in namespace "gc-9647"
May  2 20:46:32.744: INFO: Deleting pod "simpletest.rc-z7c4b" in namespace "gc-9647"
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:46:32.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9647" for this suite.


• [SLOW TEST:41.506 seconds]
[sig-api-machinery] Garbage collector
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":-1,"completed":165,"skipped":3014,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:46:15.625: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:92
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:107
STEP: Creating service test in namespace statefulset-3603
[It] should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating statefulset ss in namespace statefulset-3603
May  2 20:46:15.842: INFO: Found 0 stateful pods, waiting for 1
May  2 20:46:25.859: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
STEP: Patch a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:118
May  2 20:46:25.979: INFO: Deleting all statefulset in ns statefulset-3603
May  2 20:46:26.008: INFO: Scaling statefulset ss to 0
May  2 20:46:36.090: INFO: Waiting for statefulset status.replicas updated to 0
May  2 20:46:36.105: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:46:36.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3603" for this suite.


• [SLOW TEST:20.672 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:97
    should have a working scale subresource [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":-1,"completed":156,"skipped":2928,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:46:33.150: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
May  2 20:46:44.051: INFO: The status of Pod kube-controller-manager-node-2 is Running (Ready = true)
May  2 20:46:44.161: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

May  2 20:46:44.161: INFO: Deleting pod "simpletest-rc-to-be-deleted-78z6k" in namespace "gc-5195"
May  2 20:46:44.214: INFO: Deleting pod "simpletest-rc-to-be-deleted-7kxcl" in namespace "gc-5195"
May  2 20:46:44.329: INFO: Deleting pod "simpletest-rc-to-be-deleted-8wjjk" in namespace "gc-5195"
May  2 20:46:44.405: INFO: Deleting pod "simpletest-rc-to-be-deleted-9dgmg" in namespace "gc-5195"
May  2 20:46:44.624: INFO: Deleting pod "simpletest-rc-to-be-deleted-df5pm" in namespace "gc-5195"
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:46:44.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5195" for this suite.


• [SLOW TEST:11.572 seconds]
[sig-api-machinery] Garbage collector
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":-1,"completed":166,"skipped":3045,"failed":0}

SSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:46:36.770: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  2 20:46:38.177: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May  2 20:46:40.214: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787121198, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787121198, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787121198, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787121198, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  2 20:46:42.253: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787121198, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787121198, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63787121198, loc:(*time.Location)(0xa0a4dc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63787121198, loc:(*time.Location)(0xa0a4dc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-78988fc6cd\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  2 20:46:45.249: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating a validating webhook configuration
May  2 20:46:45.329: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:46:45.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8366" for this suite.
STEP: Destroying namespace "webhook-8366-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102


• [SLOW TEST:9.373 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":-1,"completed":157,"skipped":2987,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:46:46.401: INFO: >>> kubeConfig: /tmp/kubeconfig-267064716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: Creating configMap with name projected-configmap-test-volume-d3a91ba2-9f0e-4e20-a0b3-b1e2823068ca
STEP: Creating a pod to test consume configMaps
May  2 20:46:46.647: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5fe7cc74-6572-42dd-8e5d-293890abbae7" in namespace "projected-242" to be "Succeeded or Failed"
May  2 20:46:46.669: INFO: Pod "pod-projected-configmaps-5fe7cc74-6572-42dd-8e5d-293890abbae7": Phase="Pending", Reason="", readiness=false. Elapsed: 21.258372ms
May  2 20:46:48.688: INFO: Pod "pod-projected-configmaps-5fe7cc74-6572-42dd-8e5d-293890abbae7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040109165s
May  2 20:46:50.705: INFO: Pod "pod-projected-configmaps-5fe7cc74-6572-42dd-8e5d-293890abbae7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057440933s
STEP: Saw pod success
May  2 20:46:50.705: INFO: Pod "pod-projected-configmaps-5fe7cc74-6572-42dd-8e5d-293890abbae7" satisfied condition "Succeeded or Failed"
May  2 20:46:50.715: INFO: Trying to get logs from node node-2 pod pod-projected-configmaps-5fe7cc74-6572-42dd-8e5d-293890abbae7 container agnhost-container: <nil>
STEP: delete the pod
May  2 20:46:50.799: INFO: Waiting for pod pod-projected-configmaps-5fe7cc74-6572-42dd-8e5d-293890abbae7 to disappear
May  2 20:46:50.814: INFO: Pod pod-projected-configmaps-5fe7cc74-6572-42dd-8e5d-293890abbae7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:46:50.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-242" for this suite.

•
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":-1,"completed":158,"skipped":3015,"failed":0}

SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
May  2 20:46:50.940: INFO: Running AfterSuite actions on all nodes
May  2 20:46:50.941: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func17.2
May  2 20:46:50.941: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func8.2
May  2 20:46:50.941: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func7.2
May  2 20:46:50.941: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
May  2 20:46:50.942: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
May  2 20:46:50.942: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
May  2 20:46:50.942: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3


[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
May  2 20:46:44.809: INFO: >>> kubeConfig: /tmp/kubeconfig-300316069
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
May  2 20:46:55.183: INFO: The status of Pod kube-controller-manager-node-2 is Running (Ready = true)
May  2 20:46:55.310: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
May  2 20:46:55.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4399" for this suite.


• [SLOW TEST:10.557 seconds]
[sig-api-machinery] Garbage collector
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:630
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":-1,"completed":167,"skipped":3060,"failed":0}
May  2 20:46:55.368: INFO: Running AfterSuite actions on all nodes
May  2 20:46:55.368: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func17.2
May  2 20:46:55.368: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func8.2
May  2 20:46:55.368: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func7.2
May  2 20:46:55.368: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
May  2 20:46:55.368: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
May  2 20:46:55.368: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
May  2 20:46:55.368: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
May  2 20:46:55.370: INFO: Running AfterSuite actions on node 1
May  2 20:46:55.370: INFO: Skipping dumping logs from cluster


Ran 325 of 6433 Specs in 3126.823 seconds
SUCCESS! -- 325 Passed | 0 Failed | 0 Pending | 6108 Skipped


Ginkgo ran 1 suite in 52m11.887717471s
Test Suite Passed

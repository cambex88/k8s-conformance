Conformance test: not doing test setup.
Feb 20 18:07:40.506: INFO: Overriding default scale value of zero to 1
Feb 20 18:07:40.506: INFO: Overriding default milliseconds value of zero to 5000
I0220 18:07:41.080929   29709 e2e.go:304] Starting e2e run "6964e7e0-353a-11e9-997a-8a6f774fb32b" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1550686060 - Will randomize all specs
Will run 188 of 2011 specs

Feb 20 18:07:41.475: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 18:07:41.479: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb 20 18:07:41.678: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 20 18:07:41.885: INFO: 14 / 14 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 20 18:07:41.885: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
Feb 20 18:07:41.885: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb 20 18:07:41.935: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Feb 20 18:07:41.935: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Feb 20 18:07:41.935: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Feb 20 18:07:41.935: INFO: e2e test version: v1.12.5
Feb 20 18:07:41.977: INFO: kube-apiserver version: v1.12.5
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:07:41.977: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename replicaset
Feb 20 18:07:43.492: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Feb 20 18:07:43.626: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-djrbk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 18:07:43.900: INFO: Creating ReplicaSet my-hostname-basic-6b796571-353a-11e9-997a-8a6f774fb32b
Feb 20 18:07:43.984: INFO: Pod name my-hostname-basic-6b796571-353a-11e9-997a-8a6f774fb32b: Found 1 pods out of 1
Feb 20 18:07:43.984: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-6b796571-353a-11e9-997a-8a6f774fb32b" is running
Feb 20 18:07:48.070: INFO: Pod "my-hostname-basic-6b796571-353a-11e9-997a-8a6f774fb32b-l9prp" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-20 18:07:43 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-20 18:07:43 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-6b796571-353a-11e9-997a-8a6f774fb32b]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-20 18:07:43 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-6b796571-353a-11e9-997a-8a6f774fb32b]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-20 18:07:43 +0000 UTC Reason: Message:}])
Feb 20 18:07:48.070: INFO: Trying to dial the pod
Feb 20 18:07:53.285: INFO: Controller my-hostname-basic-6b796571-353a-11e9-997a-8a6f774fb32b: Got expected result from replica 1 [my-hostname-basic-6b796571-353a-11e9-997a-8a6f774fb32b-l9prp]: "my-hostname-basic-6b796571-353a-11e9-997a-8a6f774fb32b-l9prp", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:07:53.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-djrbk" for this suite.
Feb 20 18:07:59.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:08:00.469: INFO: namespace: e2e-tests-replicaset-djrbk, resource: bindings, ignored listing per whitelist
Feb 20 18:08:01.132: INFO: namespace e2e-tests-replicaset-djrbk deletion completed in 7.802390774s

• [SLOW TEST:19.155 seconds]
[sig-apps] ReplicaSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:08:01.133: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-z4pnn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-76c7a635-353a-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume configMaps
Feb 20 18:08:02.954: INFO: Waiting up to 5m0s for pod "pod-configmaps-76ce17d2-353a-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-configmap-z4pnn" to be "success or failure"
Feb 20 18:08:02.996: INFO: Pod "pod-configmaps-76ce17d2-353a-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 42.058601ms
Feb 20 18:08:05.040: INFO: Pod "pod-configmaps-76ce17d2-353a-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.08594957s
Feb 20 18:08:07.083: INFO: Pod "pod-configmaps-76ce17d2-353a-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.129119048s
STEP: Saw pod success
Feb 20 18:08:07.083: INFO: Pod "pod-configmaps-76ce17d2-353a-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:08:07.125: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-configmaps-76ce17d2-353a-11e9-997a-8a6f774fb32b container configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 18:08:07.393: INFO: Waiting for pod pod-configmaps-76ce17d2-353a-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:08:07.435: INFO: Pod pod-configmaps-76ce17d2-353a-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:08:07.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-z4pnn" for this suite.
Feb 20 18:08:13.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:08:14.333: INFO: namespace: e2e-tests-configmap-z4pnn, resource: bindings, ignored listing per whitelist
Feb 20 18:08:15.261: INFO: namespace e2e-tests-configmap-z4pnn deletion completed in 7.783333776s

• [SLOW TEST:14.128 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:08:15.261: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8xcf6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-7f2f7407-353a-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume secrets
Feb 20 18:08:17.056: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7f35de9e-353a-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-projected-8xcf6" to be "success or failure"
Feb 20 18:08:17.097: INFO: Pod "pod-projected-secrets-7f35de9e-353a-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.424578ms
Feb 20 18:08:19.142: INFO: Pod "pod-projected-secrets-7f35de9e-353a-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.086179622s
STEP: Saw pod success
Feb 20 18:08:19.142: INFO: Pod "pod-projected-secrets-7f35de9e-353a-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:08:19.185: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-projected-secrets-7f35de9e-353a-11e9-997a-8a6f774fb32b container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 20 18:08:19.277: INFO: Waiting for pod pod-projected-secrets-7f35de9e-353a-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:08:19.319: INFO: Pod pod-projected-secrets-7f35de9e-353a-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:08:19.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8xcf6" for this suite.
Feb 20 18:08:25.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:08:26.186: INFO: namespace: e2e-tests-projected-8xcf6, resource: bindings, ignored listing per whitelist
Feb 20 18:08:27.125: INFO: namespace e2e-tests-projected-8xcf6 deletion completed in 7.763945943s

• [SLOW TEST:11.864 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:08:27.126: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-5wbxk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-5wbxk
Feb 20 18:08:34.997: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-5wbxk
STEP: checking the pod's current state and verifying that restartCount is present
Feb 20 18:08:35.040: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:12:36.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-5wbxk" for this suite.
Feb 20 18:12:42.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:12:42.659: INFO: namespace: e2e-tests-container-probe-5wbxk, resource: bindings, ignored listing per whitelist
Feb 20 18:12:44.105: INFO: namespace e2e-tests-container-probe-5wbxk deletion completed in 7.78483354s

• [SLOW TEST:256.979 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:12:44.105: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-wksjj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb 20 18:12:46.089: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-wksjj,SelfLink:/api/v1/namespaces/e2e-tests-watch-wksjj/configmaps/e2e-watch-test-configmap-a,UID:1f93d5a5-353b-11e9-936d-1e925ead141b,ResourceVersion:2904,Generation:0,CreationTimestamp:2019-02-20 18:12:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 20 18:12:46.089: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-wksjj,SelfLink:/api/v1/namespaces/e2e-tests-watch-wksjj/configmaps/e2e-watch-test-configmap-a,UID:1f93d5a5-353b-11e9-936d-1e925ead141b,ResourceVersion:2904,Generation:0,CreationTimestamp:2019-02-20 18:12:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb 20 18:12:56.174: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-wksjj,SelfLink:/api/v1/namespaces/e2e-tests-watch-wksjj/configmaps/e2e-watch-test-configmap-a,UID:1f93d5a5-353b-11e9-936d-1e925ead141b,ResourceVersion:2924,Generation:0,CreationTimestamp:2019-02-20 18:12:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 20 18:12:56.174: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-wksjj,SelfLink:/api/v1/namespaces/e2e-tests-watch-wksjj/configmaps/e2e-watch-test-configmap-a,UID:1f93d5a5-353b-11e9-936d-1e925ead141b,ResourceVersion:2924,Generation:0,CreationTimestamp:2019-02-20 18:12:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb 20 18:13:06.259: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-wksjj,SelfLink:/api/v1/namespaces/e2e-tests-watch-wksjj/configmaps/e2e-watch-test-configmap-a,UID:1f93d5a5-353b-11e9-936d-1e925ead141b,ResourceVersion:2943,Generation:0,CreationTimestamp:2019-02-20 18:12:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 20 18:13:06.259: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-wksjj,SelfLink:/api/v1/namespaces/e2e-tests-watch-wksjj/configmaps/e2e-watch-test-configmap-a,UID:1f93d5a5-353b-11e9-936d-1e925ead141b,ResourceVersion:2943,Generation:0,CreationTimestamp:2019-02-20 18:12:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb 20 18:13:16.303: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-wksjj,SelfLink:/api/v1/namespaces/e2e-tests-watch-wksjj/configmaps/e2e-watch-test-configmap-a,UID:1f93d5a5-353b-11e9-936d-1e925ead141b,ResourceVersion:2962,Generation:0,CreationTimestamp:2019-02-20 18:12:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 20 18:13:16.303: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-wksjj,SelfLink:/api/v1/namespaces/e2e-tests-watch-wksjj/configmaps/e2e-watch-test-configmap-a,UID:1f93d5a5-353b-11e9-936d-1e925ead141b,ResourceVersion:2962,Generation:0,CreationTimestamp:2019-02-20 18:12:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb 20 18:13:26.347: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-wksjj,SelfLink:/api/v1/namespaces/e2e-tests-watch-wksjj/configmaps/e2e-watch-test-configmap-b,UID:3792b1ff-353b-11e9-936d-1e925ead141b,ResourceVersion:2982,Generation:0,CreationTimestamp:2019-02-20 18:13:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 20 18:13:26.347: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-wksjj,SelfLink:/api/v1/namespaces/e2e-tests-watch-wksjj/configmaps/e2e-watch-test-configmap-b,UID:3792b1ff-353b-11e9-936d-1e925ead141b,ResourceVersion:2982,Generation:0,CreationTimestamp:2019-02-20 18:13:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb 20 18:13:36.391: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-wksjj,SelfLink:/api/v1/namespaces/e2e-tests-watch-wksjj/configmaps/e2e-watch-test-configmap-b,UID:3792b1ff-353b-11e9-936d-1e925ead141b,ResourceVersion:3001,Generation:0,CreationTimestamp:2019-02-20 18:13:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 20 18:13:36.391: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-wksjj,SelfLink:/api/v1/namespaces/e2e-tests-watch-wksjj/configmaps/e2e-watch-test-configmap-b,UID:3792b1ff-353b-11e9-936d-1e925ead141b,ResourceVersion:3001,Generation:0,CreationTimestamp:2019-02-20 18:13:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:13:46.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-wksjj" for this suite.
Feb 20 18:13:52.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:13:52.778: INFO: namespace: e2e-tests-watch-wksjj, resource: bindings, ignored listing per whitelist
Feb 20 18:13:54.230: INFO: namespace e2e-tests-watch-wksjj deletion completed in 7.795982834s

• [SLOW TEST:70.125 seconds]
[sig-api-machinery] Watchers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:13:54.230: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-hrmsg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 18:13:56.110: INFO: Waiting up to 5m0s for pod "downwardapi-volume-494d6d85-353b-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-projected-hrmsg" to be "success or failure"
Feb 20 18:13:56.153: INFO: Pod "downwardapi-volume-494d6d85-353b-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 43.176936ms
Feb 20 18:13:58.196: INFO: Pod "downwardapi-volume-494d6d85-353b-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.086299547s
STEP: Saw pod success
Feb 20 18:13:58.196: INFO: Pod "downwardapi-volume-494d6d85-353b-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:13:58.239: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod downwardapi-volume-494d6d85-353b-11e9-997a-8a6f774fb32b container client-container: <nil>
STEP: delete the pod
Feb 20 18:13:58.336: INFO: Waiting for pod downwardapi-volume-494d6d85-353b-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:13:58.379: INFO: Pod downwardapi-volume-494d6d85-353b-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:13:58.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hrmsg" for this suite.
Feb 20 18:14:04.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:14:05.143: INFO: namespace: e2e-tests-projected-hrmsg, resource: bindings, ignored listing per whitelist
Feb 20 18:14:06.196: INFO: namespace e2e-tests-projected-hrmsg deletion completed in 7.768222024s

• [SLOW TEST:11.966 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:14:06.196: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-5gg8t
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-506c40f4-353b-11e9-997a-8a6f774fb32b
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-506c40f4-353b-11e9-997a-8a6f774fb32b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:14:12.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5gg8t" for this suite.
Feb 20 18:14:34.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:14:35.382: INFO: namespace: e2e-tests-configmap-5gg8t, resource: bindings, ignored listing per whitelist
Feb 20 18:14:36.189: INFO: namespace e2e-tests-configmap-5gg8t deletion completed in 23.729334516s

• [SLOW TEST:29.992 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:14:36.189: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wtnxq
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb 20 18:14:37.929: INFO: Waiting up to 5m0s for pod "pod-623a8848-353b-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-emptydir-wtnxq" to be "success or failure"
Feb 20 18:14:37.971: INFO: Pod "pod-623a8848-353b-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.651405ms
Feb 20 18:14:40.013: INFO: Pod "pod-623a8848-353b-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084282258s
STEP: Saw pod success
Feb 20 18:14:40.013: INFO: Pod "pod-623a8848-353b-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:14:40.055: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-623a8848-353b-11e9-997a-8a6f774fb32b container test-container: <nil>
STEP: delete the pod
Feb 20 18:14:40.147: INFO: Waiting for pod pod-623a8848-353b-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:14:40.189: INFO: Pod pod-623a8848-353b-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:14:40.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wtnxq" for this suite.
Feb 20 18:14:46.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:14:47.804: INFO: namespace: e2e-tests-emptydir-wtnxq, resource: bindings, ignored listing per whitelist
Feb 20 18:14:47.971: INFO: namespace e2e-tests-emptydir-wtnxq deletion completed in 7.739891741s

• [SLOW TEST:11.782 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:14:47.971: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-6jpbh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-694fdffc-353b-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume secrets
Feb 20 18:14:49.855: INFO: Waiting up to 5m0s for pod "pod-secrets-69564813-353b-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-secrets-6jpbh" to be "success or failure"
Feb 20 18:14:49.898: INFO: Pod "pod-secrets-69564813-353b-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 42.749877ms
Feb 20 18:14:51.941: INFO: Pod "pod-secrets-69564813-353b-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085844006s
STEP: Saw pod success
Feb 20 18:14:51.941: INFO: Pod "pod-secrets-69564813-353b-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:14:51.983: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-secrets-69564813-353b-11e9-997a-8a6f774fb32b container secret-volume-test: <nil>
STEP: delete the pod
Feb 20 18:14:52.080: INFO: Waiting for pod pod-secrets-69564813-353b-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:14:52.122: INFO: Pod pod-secrets-69564813-353b-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:14:52.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6jpbh" for this suite.
Feb 20 18:14:58.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:14:59.727: INFO: namespace: e2e-tests-secrets-6jpbh, resource: bindings, ignored listing per whitelist
Feb 20 18:14:59.937: INFO: namespace e2e-tests-secrets-6jpbh deletion completed in 7.772616444s

• [SLOW TEST:11.966 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:14:59.937: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-bwsnp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 20 18:15:08.056: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 20 18:15:08.098: INFO: Pod pod-with-prestop-http-hook still exists
Feb 20 18:15:10.098: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 20 18:15:10.141: INFO: Pod pod-with-prestop-http-hook still exists
Feb 20 18:15:12.099: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 20 18:15:12.141: INFO: Pod pod-with-prestop-http-hook still exists
Feb 20 18:15:14.100: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 20 18:15:14.143: INFO: Pod pod-with-prestop-http-hook still exists
Feb 20 18:15:16.098: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 20 18:15:16.141: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:15:16.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-bwsnp" for this suite.
Feb 20 18:15:38.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:15:38.954: INFO: namespace: e2e-tests-container-lifecycle-hook-bwsnp, resource: bindings, ignored listing per whitelist
Feb 20 18:15:39.963: INFO: namespace e2e-tests-container-lifecycle-hook-bwsnp deletion completed in 23.730868808s

• [SLOW TEST:40.026 seconds]
[k8s.io] Container Lifecycle Hook
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:15:39.963: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-x6cbn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-8840323b-353b-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume configMaps
Feb 20 18:15:41.764: INFO: Waiting up to 5m0s for pod "pod-configmaps-8846b605-353b-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-configmap-x6cbn" to be "success or failure"
Feb 20 18:15:41.805: INFO: Pod "pod-configmaps-8846b605-353b-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.408666ms
Feb 20 18:15:43.848: INFO: Pod "pod-configmaps-8846b605-353b-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.083929087s
STEP: Saw pod success
Feb 20 18:15:43.848: INFO: Pod "pod-configmaps-8846b605-353b-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:15:43.890: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-configmaps-8846b605-353b-11e9-997a-8a6f774fb32b container configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 18:15:44.011: INFO: Waiting for pod pod-configmaps-8846b605-353b-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:15:44.055: INFO: Pod pod-configmaps-8846b605-353b-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:15:44.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-x6cbn" for this suite.
Feb 20 18:15:50.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:15:51.260: INFO: namespace: e2e-tests-configmap-x6cbn, resource: bindings, ignored listing per whitelist
Feb 20 18:15:51.856: INFO: namespace e2e-tests-configmap-x6cbn deletion completed in 7.752484411s

• [SLOW TEST:11.893 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:15:51.856: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8hlb4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 18:15:53.621: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8f57d649-353b-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-projected-8hlb4" to be "success or failure"
Feb 20 18:15:53.663: INFO: Pod "downwardapi-volume-8f57d649-353b-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 42.01674ms
Feb 20 18:15:55.715: INFO: Pod "downwardapi-volume-8f57d649-353b-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.094175179s
STEP: Saw pod success
Feb 20 18:15:55.715: INFO: Pod "downwardapi-volume-8f57d649-353b-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:15:55.758: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod downwardapi-volume-8f57d649-353b-11e9-997a-8a6f774fb32b container client-container: <nil>
STEP: delete the pod
Feb 20 18:15:55.851: INFO: Waiting for pod downwardapi-volume-8f57d649-353b-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:15:55.896: INFO: Pod downwardapi-volume-8f57d649-353b-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:15:55.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8hlb4" for this suite.
Feb 20 18:16:02.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:16:02.334: INFO: namespace: e2e-tests-projected-8hlb4, resource: bindings, ignored listing per whitelist
Feb 20 18:16:03.789: INFO: namespace e2e-tests-projected-8hlb4 deletion completed in 7.850595677s

• [SLOW TEST:11.933 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:16:03.790: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-slk6z
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 20 18:16:06.012: INFO: Number of nodes with available pods: 0
Feb 20 18:16:06.012: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:07.099: INFO: Number of nodes with available pods: 0
Feb 20 18:16:07.100: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:08.108: INFO: Number of nodes with available pods: 1
Feb 20 18:16:08.108: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:09.098: INFO: Number of nodes with available pods: 2
Feb 20 18:16:09.098: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb 20 18:16:09.310: INFO: Number of nodes with available pods: 1
Feb 20 18:16:09.310: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:10.395: INFO: Number of nodes with available pods: 1
Feb 20 18:16:10.395: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:11.395: INFO: Number of nodes with available pods: 1
Feb 20 18:16:11.395: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:12.397: INFO: Number of nodes with available pods: 1
Feb 20 18:16:12.397: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:13.397: INFO: Number of nodes with available pods: 1
Feb 20 18:16:13.398: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:14.396: INFO: Number of nodes with available pods: 1
Feb 20 18:16:14.396: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:15.396: INFO: Number of nodes with available pods: 1
Feb 20 18:16:15.396: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:16.400: INFO: Number of nodes with available pods: 1
Feb 20 18:16:16.400: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:17.395: INFO: Number of nodes with available pods: 1
Feb 20 18:16:17.395: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:18.397: INFO: Number of nodes with available pods: 1
Feb 20 18:16:18.397: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:19.399: INFO: Number of nodes with available pods: 1
Feb 20 18:16:19.399: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:20.394: INFO: Number of nodes with available pods: 1
Feb 20 18:16:20.394: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:21.435: INFO: Number of nodes with available pods: 1
Feb 20 18:16:21.435: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:22.399: INFO: Number of nodes with available pods: 1
Feb 20 18:16:22.399: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:23.399: INFO: Number of nodes with available pods: 1
Feb 20 18:16:23.399: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:24.395: INFO: Number of nodes with available pods: 1
Feb 20 18:16:24.395: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:25.397: INFO: Number of nodes with available pods: 1
Feb 20 18:16:25.397: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:26.396: INFO: Number of nodes with available pods: 1
Feb 20 18:16:26.396: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:27.396: INFO: Number of nodes with available pods: 1
Feb 20 18:16:27.396: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:28.401: INFO: Number of nodes with available pods: 1
Feb 20 18:16:28.401: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:29.397: INFO: Number of nodes with available pods: 1
Feb 20 18:16:29.398: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:30.396: INFO: Number of nodes with available pods: 1
Feb 20 18:16:30.396: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:31.399: INFO: Number of nodes with available pods: 1
Feb 20 18:16:31.399: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:32.417: INFO: Number of nodes with available pods: 1
Feb 20 18:16:32.418: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:33.401: INFO: Number of nodes with available pods: 1
Feb 20 18:16:33.401: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:34.404: INFO: Number of nodes with available pods: 1
Feb 20 18:16:34.404: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:35.412: INFO: Number of nodes with available pods: 1
Feb 20 18:16:35.412: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:36.396: INFO: Number of nodes with available pods: 1
Feb 20 18:16:36.396: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:37.395: INFO: Number of nodes with available pods: 1
Feb 20 18:16:37.395: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:38.401: INFO: Number of nodes with available pods: 1
Feb 20 18:16:38.401: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:39.395: INFO: Number of nodes with available pods: 1
Feb 20 18:16:39.395: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:40.395: INFO: Number of nodes with available pods: 1
Feb 20 18:16:40.396: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:41.395: INFO: Number of nodes with available pods: 1
Feb 20 18:16:41.395: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:42.394: INFO: Number of nodes with available pods: 1
Feb 20 18:16:42.394: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:43.403: INFO: Number of nodes with available pods: 1
Feb 20 18:16:43.403: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:44.400: INFO: Number of nodes with available pods: 1
Feb 20 18:16:44.400: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:45.401: INFO: Number of nodes with available pods: 1
Feb 20 18:16:45.401: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:16:46.395: INFO: Number of nodes with available pods: 2
Feb 20 18:16:46.395: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-slk6z, will wait for the garbage collector to delete the pods
Feb 20 18:16:46.576: INFO: Deleting {extensions DaemonSet} daemon-set took: 44.510607ms
Feb 20 18:16:46.677: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.899003ms
Feb 20 18:17:24.320: INFO: Number of nodes with available pods: 0
Feb 20 18:17:24.320: INFO: Number of running nodes: 0, number of available pods: 0
Feb 20 18:17:24.363: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-slk6z/daemonsets","resourceVersion":"3614"},"items":null}

Feb 20 18:17:24.405: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-slk6z/pods","resourceVersion":"3614"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:17:24.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-slk6z" for this suite.
Feb 20 18:17:30.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:17:31.596: INFO: namespace: e2e-tests-daemonsets-slk6z, resource: bindings, ignored listing per whitelist
Feb 20 18:17:32.364: INFO: namespace e2e-tests-daemonsets-slk6z deletion completed in 7.790564964s

• [SLOW TEST:88.574 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:17:32.364: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-zhlww
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-zhlww.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-zhlww.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-zhlww.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-zhlww.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-zhlww.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-zhlww.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 20 18:18:01.489: INFO: DNS probes using e2e-tests-dns-zhlww/dns-test-cb5b8dad-353b-11e9-997a-8a6f774fb32b succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:18:01.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-zhlww" for this suite.
Feb 20 18:18:07.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:18:08.996: INFO: namespace: e2e-tests-dns-zhlww, resource: bindings, ignored listing per whitelist
Feb 20 18:18:09.380: INFO: namespace e2e-tests-dns-zhlww deletion completed in 7.794636536s

• [SLOW TEST:37.016 seconds]
[sig-network] DNS
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:18:09.380: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-t8jrs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 20 18:18:11.415: INFO: Number of nodes with available pods: 0
Feb 20 18:18:11.415: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:18:12.500: INFO: Number of nodes with available pods: 0
Feb 20 18:18:12.500: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:18:13.502: INFO: Number of nodes with available pods: 2
Feb 20 18:18:13.502: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb 20 18:18:13.717: INFO: Number of nodes with available pods: 1
Feb 20 18:18:13.717: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:18:14.802: INFO: Number of nodes with available pods: 1
Feb 20 18:18:14.802: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:18:15.804: INFO: Number of nodes with available pods: 2
Feb 20 18:18:15.804: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-t8jrs, will wait for the garbage collector to delete the pods
Feb 20 18:18:16.022: INFO: Deleting {extensions DaemonSet} daemon-set took: 43.200457ms
Feb 20 18:18:16.122: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.207281ms
Feb 20 18:18:54.438: INFO: Number of nodes with available pods: 0
Feb 20 18:18:54.438: INFO: Number of running nodes: 0, number of available pods: 0
Feb 20 18:18:54.479: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-t8jrs/daemonsets","resourceVersion":"3847"},"items":null}

Feb 20 18:18:54.523: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-t8jrs/pods","resourceVersion":"3847"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:18:54.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-t8jrs" for this suite.
Feb 20 18:19:00.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:19:02.042: INFO: namespace: e2e-tests-daemonsets-t8jrs, resource: bindings, ignored listing per whitelist
Feb 20 18:19:02.420: INFO: namespace e2e-tests-daemonsets-t8jrs deletion completed in 7.728821932s

• [SLOW TEST:53.040 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:19:02.420: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-67225
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-67225
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 20 18:19:04.260: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 20 18:19:29.074: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 100.96.1.18 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-67225 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 18:19:29.074: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 18:19:30.836: INFO: Found all expected endpoints: [netserver-0]
Feb 20 18:19:30.879: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 100.96.0.13 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-67225 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 18:19:30.879: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 18:19:32.570: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:19:32.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-67225" for this suite.
Feb 20 18:19:54.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:19:54.961: INFO: namespace: e2e-tests-pod-network-test-67225, resource: bindings, ignored listing per whitelist
Feb 20 18:19:56.405: INFO: namespace e2e-tests-pod-network-test-67225 deletion completed in 23.792989399s

• [SLOW TEST:53.985 seconds]
[sig-network] Networking
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:19:56.406: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-h96sg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-2121c4df-353c-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume secrets
Feb 20 18:19:58.254: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-21282857-353c-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-projected-h96sg" to be "success or failure"
Feb 20 18:19:58.305: INFO: Pod "pod-projected-secrets-21282857-353c-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 50.829223ms
Feb 20 18:20:00.349: INFO: Pod "pod-projected-secrets-21282857-353c-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.094716825s
STEP: Saw pod success
Feb 20 18:20:00.349: INFO: Pod "pod-projected-secrets-21282857-353c-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:20:00.390: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-projected-secrets-21282857-353c-11e9-997a-8a6f774fb32b container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 20 18:20:00.485: INFO: Waiting for pod pod-projected-secrets-21282857-353c-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:20:00.527: INFO: Pod pod-projected-secrets-21282857-353c-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:20:00.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h96sg" for this suite.
Feb 20 18:20:06.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:20:07.471: INFO: namespace: e2e-tests-projected-h96sg, resource: bindings, ignored listing per whitelist
Feb 20 18:20:08.334: INFO: namespace e2e-tests-projected-h96sg deletion completed in 7.761583998s

• [SLOW TEST:11.928 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:20:08.334: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-frbq6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb 20 18:20:10.325: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-frbq6,SelfLink:/api/v1/namespaces/e2e-tests-watch-frbq6/configmaps/e2e-watch-test-watch-closed,UID:28505e8a-353c-11e9-936d-1e925ead141b,ResourceVersion:4064,Generation:0,CreationTimestamp:2019-02-20 18:20:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 20 18:20:10.325: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-frbq6,SelfLink:/api/v1/namespaces/e2e-tests-watch-frbq6/configmaps/e2e-watch-test-watch-closed,UID:28505e8a-353c-11e9-936d-1e925ead141b,ResourceVersion:4065,Generation:0,CreationTimestamp:2019-02-20 18:20:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb 20 18:20:10.493: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-frbq6,SelfLink:/api/v1/namespaces/e2e-tests-watch-frbq6/configmaps/e2e-watch-test-watch-closed,UID:28505e8a-353c-11e9-936d-1e925ead141b,ResourceVersion:4066,Generation:0,CreationTimestamp:2019-02-20 18:20:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 20 18:20:10.493: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-frbq6,SelfLink:/api/v1/namespaces/e2e-tests-watch-frbq6/configmaps/e2e-watch-test-watch-closed,UID:28505e8a-353c-11e9-936d-1e925ead141b,ResourceVersion:4067,Generation:0,CreationTimestamp:2019-02-20 18:20:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:20:10.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-frbq6" for this suite.
Feb 20 18:20:16.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:20:17.739: INFO: namespace: e2e-tests-watch-frbq6, resource: bindings, ignored listing per whitelist
Feb 20 18:20:18.303: INFO: namespace e2e-tests-watch-frbq6 deletion completed in 7.76727881s

• [SLOW TEST:9.969 seconds]
[sig-api-machinery] Watchers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:20:18.303: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-hrd8t
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Feb 20 18:20:20.204: INFO: Waiting up to 5m0s for pod "pod-2e3d7977-353c-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-emptydir-hrd8t" to be "success or failure"
Feb 20 18:20:20.246: INFO: Pod "pod-2e3d7977-353c-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.850781ms
Feb 20 18:20:22.288: INFO: Pod "pod-2e3d7977-353c-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084069676s
STEP: Saw pod success
Feb 20 18:20:22.288: INFO: Pod "pod-2e3d7977-353c-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:20:22.330: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-2e3d7977-353c-11e9-997a-8a6f774fb32b container test-container: <nil>
STEP: delete the pod
Feb 20 18:20:22.427: INFO: Waiting for pod pod-2e3d7977-353c-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:20:22.469: INFO: Pod pod-2e3d7977-353c-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:20:22.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hrd8t" for this suite.
Feb 20 18:20:28.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:20:30.026: INFO: namespace: e2e-tests-emptydir-hrd8t, resource: bindings, ignored listing per whitelist
Feb 20 18:20:30.277: INFO: namespace e2e-tests-emptydir-hrd8t deletion completed in 7.765323291s

• [SLOW TEST:11.974 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:20:30.277: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-28c6j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 20 18:20:32.207: INFO: Waiting up to 5m0s for pod "downward-api-356515e4-353c-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-downward-api-28c6j" to be "success or failure"
Feb 20 18:20:32.249: INFO: Pod "downward-api-356515e4-353c-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.945122ms
Feb 20 18:20:34.294: INFO: Pod "downward-api-356515e4-353c-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.086589061s
Feb 20 18:20:36.338: INFO: Pod "downward-api-356515e4-353c-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.130622247s
STEP: Saw pod success
Feb 20 18:20:36.338: INFO: Pod "downward-api-356515e4-353c-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:20:36.381: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod downward-api-356515e4-353c-11e9-997a-8a6f774fb32b container dapi-container: <nil>
STEP: delete the pod
Feb 20 18:20:36.480: INFO: Waiting for pod downward-api-356515e4-353c-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:20:36.521: INFO: Pod downward-api-356515e4-353c-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:20:36.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-28c6j" for this suite.
Feb 20 18:20:42.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:20:43.386: INFO: namespace: e2e-tests-downward-api-28c6j, resource: bindings, ignored listing per whitelist
Feb 20 18:20:44.359: INFO: namespace e2e-tests-downward-api-28c6j deletion completed in 7.794925566s

• [SLOW TEST:14.082 seconds]
[sig-api-machinery] Downward API
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:20:44.359: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-tzs7w
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb 20 18:20:46.425: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-tzs7w,SelfLink:/api/v1/namespaces/e2e-tests-watch-tzs7w/configmaps/e2e-watch-test-label-changed,UID:3dc7a029-353c-11e9-936d-1e925ead141b,ResourceVersion:4181,Generation:0,CreationTimestamp:2019-02-20 18:20:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 20 18:20:46.425: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-tzs7w,SelfLink:/api/v1/namespaces/e2e-tests-watch-tzs7w/configmaps/e2e-watch-test-label-changed,UID:3dc7a029-353c-11e9-936d-1e925ead141b,ResourceVersion:4182,Generation:0,CreationTimestamp:2019-02-20 18:20:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 20 18:20:46.425: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-tzs7w,SelfLink:/api/v1/namespaces/e2e-tests-watch-tzs7w/configmaps/e2e-watch-test-label-changed,UID:3dc7a029-353c-11e9-936d-1e925ead141b,ResourceVersion:4183,Generation:0,CreationTimestamp:2019-02-20 18:20:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb 20 18:20:56.727: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-tzs7w,SelfLink:/api/v1/namespaces/e2e-tests-watch-tzs7w/configmaps/e2e-watch-test-label-changed,UID:3dc7a029-353c-11e9-936d-1e925ead141b,ResourceVersion:4204,Generation:0,CreationTimestamp:2019-02-20 18:20:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 20 18:20:56.727: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-tzs7w,SelfLink:/api/v1/namespaces/e2e-tests-watch-tzs7w/configmaps/e2e-watch-test-label-changed,UID:3dc7a029-353c-11e9-936d-1e925ead141b,ResourceVersion:4205,Generation:0,CreationTimestamp:2019-02-20 18:20:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb 20 18:20:56.728: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-tzs7w,SelfLink:/api/v1/namespaces/e2e-tests-watch-tzs7w/configmaps/e2e-watch-test-label-changed,UID:3dc7a029-353c-11e9-936d-1e925ead141b,ResourceVersion:4206,Generation:0,CreationTimestamp:2019-02-20 18:20:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:20:56.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-tzs7w" for this suite.
Feb 20 18:21:02.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:21:03.672: INFO: namespace: e2e-tests-watch-tzs7w, resource: bindings, ignored listing per whitelist
Feb 20 18:21:04.563: INFO: namespace e2e-tests-watch-tzs7w deletion completed in 7.791844724s

• [SLOW TEST:20.204 seconds]
[sig-api-machinery] Watchers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:21:04.563: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-zkv4f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 20 18:21:06.485: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:21:09.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-zkv4f" for this suite.
Feb 20 18:21:15.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:21:15.587: INFO: namespace: e2e-tests-init-container-zkv4f, resource: bindings, ignored listing per whitelist
Feb 20 18:21:17.176: INFO: namespace e2e-tests-init-container-zkv4f deletion completed in 7.850567323s

• [SLOW TEST:12.613 seconds]
[k8s.io] InitContainer [NodeConformance]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:21:17.176: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-h7d9v
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-514dfb41-353c-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume secrets
Feb 20 18:21:19.075: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-51548cab-353c-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-projected-h7d9v" to be "success or failure"
Feb 20 18:21:19.117: INFO: Pod "pod-projected-secrets-51548cab-353c-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.950216ms
Feb 20 18:21:21.160: INFO: Pod "pod-projected-secrets-51548cab-353c-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084234353s
STEP: Saw pod success
Feb 20 18:21:21.160: INFO: Pod "pod-projected-secrets-51548cab-353c-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:21:21.234: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-projected-secrets-51548cab-353c-11e9-997a-8a6f774fb32b container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 20 18:21:21.333: INFO: Waiting for pod pod-projected-secrets-51548cab-353c-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:21:21.375: INFO: Pod pod-projected-secrets-51548cab-353c-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:21:21.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h7d9v" for this suite.
Feb 20 18:21:27.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:21:27.715: INFO: namespace: e2e-tests-projected-h7d9v, resource: bindings, ignored listing per whitelist
Feb 20 18:21:29.207: INFO: namespace e2e-tests-projected-h7d9v deletion completed in 7.789879021s

• [SLOW TEST:12.031 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:21:29.207: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-5mgvb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0220 18:21:41.658571   29709 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 20 18:21:41.658: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:21:41.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-5mgvb" for this suite.
Feb 20 18:21:47.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:21:48.268: INFO: namespace: e2e-tests-gc-5mgvb, resource: bindings, ignored listing per whitelist
Feb 20 18:21:49.533: INFO: namespace e2e-tests-gc-5mgvb deletion completed in 7.82574028s

• [SLOW TEST:20.326 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:21:49.533: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-czd8d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 18:22:11.533: INFO: Container started at 2019-02-20 18:21:52 +0000 UTC, pod became ready at 2019-02-20 18:22:10 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:22:11.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-czd8d" for this suite.
Feb 20 18:22:33.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:22:34.883: INFO: namespace: e2e-tests-container-probe-czd8d, resource: bindings, ignored listing per whitelist
Feb 20 18:22:35.386: INFO: namespace e2e-tests-container-probe-czd8d deletion completed in 23.810355613s

• [SLOW TEST:45.853 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:22:35.387: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-q9pt4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 20 18:22:37.501: INFO: Waiting up to 5m0s for pod "downward-api-80138660-353c-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-downward-api-q9pt4" to be "success or failure"
Feb 20 18:22:37.543: INFO: Pod "downward-api-80138660-353c-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.908695ms
Feb 20 18:22:39.586: INFO: Pod "downward-api-80138660-353c-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084399406s
STEP: Saw pod success
Feb 20 18:22:39.586: INFO: Pod "downward-api-80138660-353c-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:22:39.628: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod downward-api-80138660-353c-11e9-997a-8a6f774fb32b container dapi-container: <nil>
STEP: delete the pod
Feb 20 18:22:39.722: INFO: Waiting for pod downward-api-80138660-353c-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:22:39.764: INFO: Pod downward-api-80138660-353c-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:22:39.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-q9pt4" for this suite.
Feb 20 18:22:45.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:22:46.067: INFO: namespace: e2e-tests-downward-api-q9pt4, resource: bindings, ignored listing per whitelist
Feb 20 18:22:47.637: INFO: namespace e2e-tests-downward-api-q9pt4 deletion completed in 7.830580614s

• [SLOW TEST:12.250 seconds]
[sig-api-machinery] Downward API
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:22:47.637: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-hthhw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-cl22d in namespace e2e-tests-proxy-hthhw
I0220 18:22:49.645388   29709 runners.go:180] Created replication controller with name: proxy-service-cl22d, namespace: e2e-tests-proxy-hthhw, replica count: 1
I0220 18:22:50.695725   29709 runners.go:180] proxy-service-cl22d Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0220 18:22:51.695919   29709 runners.go:180] proxy-service-cl22d Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0220 18:22:52.696118   29709 runners.go:180] proxy-service-cl22d Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0220 18:22:53.696341   29709 runners.go:180] proxy-service-cl22d Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0220 18:22:54.696476   29709 runners.go:180] proxy-service-cl22d Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0220 18:22:55.696703   29709 runners.go:180] proxy-service-cl22d Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0220 18:22:56.697210   29709 runners.go:180] proxy-service-cl22d Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0220 18:22:57.698058   29709 runners.go:180] proxy-service-cl22d Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0220 18:22:58.700432   29709 runners.go:180] proxy-service-cl22d Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0220 18:22:59.705181   29709 runners.go:180] proxy-service-cl22d Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 20 18:22:59.750: INFO: setup took 10.192964317s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb 20 18:22:59.796: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:162/proxy/: bar (200; 45.699788ms)
Feb 20 18:22:59.799: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/... (200; 48.541888ms)
Feb 20 18:22:59.894: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname2/proxy/: bar (200; 143.43793ms)
Feb 20 18:22:59.894: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname1/proxy/: foo (200; 143.612824ms)
Feb 20 18:22:59.894: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:160/proxy/: foo (200; 143.607894ms)
Feb 20 18:22:59.894: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/rewriteme"... (200; 143.602147ms)
Feb 20 18:22:59.894: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:162/proxy/: bar (200; 143.66885ms)
Feb 20 18:22:59.894: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname1/proxy/: foo (200; 143.636627ms)
Feb 20 18:22:59.894: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:160/proxy/: foo (200; 143.732483ms)
Feb 20 18:22:59.894: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname2/proxy/: bar (200; 143.856071ms)
Feb 20 18:22:59.894: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/rewri... (200; 143.809154ms)
Feb 20 18:22:59.897: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname1/proxy/: tls baz (200; 146.727776ms)
Feb 20 18:22:59.897: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname2/proxy/: tls qux (200; 146.921699ms)
Feb 20 18:22:59.901: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:460/proxy/: tls baz (200; 150.409796ms)
Feb 20 18:22:59.901: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:462/proxy/: tls qux (200; 150.38034ms)
Feb 20 18:22:59.901: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/... (200; 150.497095ms)
Feb 20 18:22:59.945: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:160/proxy/: foo (200; 43.388781ms)
Feb 20 18:22:59.945: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:162/proxy/: bar (200; 43.644149ms)
Feb 20 18:22:59.945: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/rewriteme"... (200; 43.975064ms)
Feb 20 18:22:59.945: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:462/proxy/: tls qux (200; 43.913053ms)
Feb 20 18:22:59.946: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/... (200; 44.308451ms)
Feb 20 18:22:59.946: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:162/proxy/: bar (200; 44.779094ms)
Feb 20 18:22:59.946: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname2/proxy/: tls qux (200; 44.317617ms)
Feb 20 18:22:59.946: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:160/proxy/: foo (200; 44.551643ms)
Feb 20 18:22:59.946: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/rewri... (200; 44.596156ms)
Feb 20 18:22:59.946: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:460/proxy/: tls baz (200; 44.446009ms)
Feb 20 18:22:59.946: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/... (200; 44.519783ms)
Feb 20 18:22:59.946: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname1/proxy/: tls baz (200; 44.958794ms)
Feb 20 18:22:59.946: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname1/proxy/: foo (200; 44.719416ms)
Feb 20 18:22:59.947: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname2/proxy/: bar (200; 45.198859ms)
Feb 20 18:22:59.947: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname1/proxy/: foo (200; 45.761723ms)
Feb 20 18:22:59.947: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname2/proxy/: bar (200; 45.948386ms)
Feb 20 18:22:59.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/... (200; 43.601092ms)
Feb 20 18:22:59.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:160/proxy/: foo (200; 43.924471ms)
Feb 20 18:22:59.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:162/proxy/: bar (200; 43.638639ms)
Feb 20 18:22:59.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/rewriteme"... (200; 43.540828ms)
Feb 20 18:22:59.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/rewri... (200; 43.353336ms)
Feb 20 18:22:59.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:162/proxy/: bar (200; 43.65535ms)
Feb 20 18:22:59.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:160/proxy/: foo (200; 43.525771ms)
Feb 20 18:22:59.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/... (200; 43.644067ms)
Feb 20 18:22:59.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:460/proxy/: tls baz (200; 43.627446ms)
Feb 20 18:22:59.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:462/proxy/: tls qux (200; 43.927491ms)
Feb 20 18:22:59.992: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname1/proxy/: tls baz (200; 43.815759ms)
Feb 20 18:22:59.992: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname2/proxy/: tls qux (200; 43.933055ms)
Feb 20 18:22:59.992: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname2/proxy/: bar (200; 44.161693ms)
Feb 20 18:22:59.992: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname1/proxy/: foo (200; 44.435988ms)
Feb 20 18:22:59.992: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname1/proxy/: foo (200; 45.070528ms)
Feb 20 18:22:59.993: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname2/proxy/: bar (200; 44.704061ms)
Feb 20 18:23:00.037: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:460/proxy/: tls baz (200; 44.329836ms)
Feb 20 18:23:00.042: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:162/proxy/: bar (200; 48.797753ms)
Feb 20 18:23:00.042: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:160/proxy/: foo (200; 49.320589ms)
Feb 20 18:23:00.042: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/... (200; 48.980515ms)
Feb 20 18:23:00.042: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname2/proxy/: tls qux (200; 49.472884ms)
Feb 20 18:23:00.042: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname2/proxy/: bar (200; 49.118999ms)
Feb 20 18:23:00.042: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:162/proxy/: bar (200; 49.353472ms)
Feb 20 18:23:00.042: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/... (200; 49.312193ms)
Feb 20 18:23:00.042: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname1/proxy/: foo (200; 49.80697ms)
Feb 20 18:23:00.042: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:462/proxy/: tls qux (200; 48.886889ms)
Feb 20 18:23:00.042: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/rewri... (200; 49.066908ms)
Feb 20 18:23:00.043: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/rewriteme"... (200; 48.895529ms)
Feb 20 18:23:00.043: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname1/proxy/: tls baz (200; 48.785701ms)
Feb 20 18:23:00.043: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:160/proxy/: foo (200; 49.098714ms)
Feb 20 18:23:00.043: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname2/proxy/: bar (200; 48.893819ms)
Feb 20 18:23:00.043: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname1/proxy/: foo (200; 49.265857ms)
Feb 20 18:23:00.086: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:160/proxy/: foo (200; 43.340897ms)
Feb 20 18:23:00.086: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:162/proxy/: bar (200; 42.808946ms)
Feb 20 18:23:00.086: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:162/proxy/: bar (200; 43.791803ms)
Feb 20 18:23:00.086: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:462/proxy/: tls qux (200; 43.392305ms)
Feb 20 18:23:00.086: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/rewri... (200; 43.531927ms)
Feb 20 18:23:00.087: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/rewriteme"... (200; 43.662802ms)
Feb 20 18:23:00.089: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname1/proxy/: tls baz (200; 45.196453ms)
Feb 20 18:23:00.089: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/... (200; 44.674038ms)
Feb 20 18:23:00.089: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname2/proxy/: bar (200; 45.155668ms)
Feb 20 18:23:00.089: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:460/proxy/: tls baz (200; 44.826262ms)
Feb 20 18:23:00.089: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname1/proxy/: foo (200; 44.761298ms)
Feb 20 18:23:00.089: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname2/proxy/: tls qux (200; 45.109592ms)
Feb 20 18:23:00.089: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname2/proxy/: bar (200; 45.368432ms)
Feb 20 18:23:00.089: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/... (200; 44.679333ms)
Feb 20 18:23:00.089: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:160/proxy/: foo (200; 45.085172ms)
Feb 20 18:23:00.090: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname1/proxy/: foo (200; 46.744174ms)
Feb 20 18:23:00.135: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:160/proxy/: foo (200; 44.977831ms)
Feb 20 18:23:00.135: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:462/proxy/: tls qux (200; 44.945235ms)
Feb 20 18:23:00.135: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/rewriteme"... (200; 44.915756ms)
Feb 20 18:23:00.135: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:460/proxy/: tls baz (200; 45.009039ms)
Feb 20 18:23:00.135: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/rewri... (200; 44.923133ms)
Feb 20 18:23:00.135: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname2/proxy/: tls qux (200; 44.988391ms)
Feb 20 18:23:00.135: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname1/proxy/: tls baz (200; 44.951575ms)
Feb 20 18:23:00.135: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:160/proxy/: foo (200; 44.937895ms)
Feb 20 18:23:00.135: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/... (200; 45.144647ms)
Feb 20 18:23:00.135: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/... (200; 45.047269ms)
Feb 20 18:23:00.135: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:162/proxy/: bar (200; 45.059076ms)
Feb 20 18:23:00.135: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:162/proxy/: bar (200; 45.202786ms)
Feb 20 18:23:00.140: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname2/proxy/: bar (200; 49.410879ms)
Feb 20 18:23:00.141: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname1/proxy/: foo (200; 50.315604ms)
Feb 20 18:23:00.141: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname2/proxy/: bar (200; 50.453668ms)
Feb 20 18:23:00.141: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname1/proxy/: foo (200; 50.51366ms)
Feb 20 18:23:00.185: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/... (200; 44.366897ms)
Feb 20 18:23:00.185: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:160/proxy/: foo (200; 44.722736ms)
Feb 20 18:23:00.185: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:460/proxy/: tls baz (200; 44.523468ms)
Feb 20 18:23:00.185: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/rewriteme"... (200; 44.470471ms)
Feb 20 18:23:00.186: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/... (200; 44.586075ms)
Feb 20 18:23:00.186: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname1/proxy/: tls baz (200; 45.05382ms)
Feb 20 18:23:00.186: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/rewri... (200; 45.277152ms)
Feb 20 18:23:00.186: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:160/proxy/: foo (200; 45.048054ms)
Feb 20 18:23:00.186: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:162/proxy/: bar (200; 45.050276ms)
Feb 20 18:23:00.186: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:162/proxy/: bar (200; 45.333623ms)
Feb 20 18:23:00.186: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname2/proxy/: tls qux (200; 45.140944ms)
Feb 20 18:23:00.186: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:462/proxy/: tls qux (200; 45.267513ms)
Feb 20 18:23:00.187: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname1/proxy/: foo (200; 46.25989ms)
Feb 20 18:23:00.188: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname2/proxy/: bar (200; 46.895922ms)
Feb 20 18:23:00.188: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname1/proxy/: foo (200; 46.761449ms)
Feb 20 18:23:00.188: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname2/proxy/: bar (200; 46.884086ms)
Feb 20 18:23:00.232: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/... (200; 43.742357ms)
Feb 20 18:23:00.233: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/rewri... (200; 44.517926ms)
Feb 20 18:23:00.233: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/... (200; 44.67142ms)
Feb 20 18:23:00.233: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:462/proxy/: tls qux (200; 44.539977ms)
Feb 20 18:23:00.233: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:160/proxy/: foo (200; 44.586044ms)
Feb 20 18:23:00.233: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/rewriteme"... (200; 44.592479ms)
Feb 20 18:23:00.233: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:162/proxy/: bar (200; 44.616554ms)
Feb 20 18:23:00.233: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:460/proxy/: tls baz (200; 44.596433ms)
Feb 20 18:23:00.233: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:160/proxy/: foo (200; 44.937411ms)
Feb 20 18:23:00.233: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname1/proxy/: tls baz (200; 45.032638ms)
Feb 20 18:23:00.233: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname2/proxy/: bar (200; 45.088076ms)
Feb 20 18:23:00.234: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname2/proxy/: tls qux (200; 45.711156ms)
Feb 20 18:23:00.234: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname1/proxy/: foo (200; 45.977702ms)
Feb 20 18:23:00.234: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname2/proxy/: bar (200; 46.052995ms)
Feb 20 18:23:00.234: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:162/proxy/: bar (200; 46.373013ms)
Feb 20 18:23:00.236: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname1/proxy/: foo (200; 47.741105ms)
Feb 20 18:23:00.282: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:162/proxy/: bar (200; 46.486509ms)
Feb 20 18:23:00.282: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/rewri... (200; 46.301822ms)
Feb 20 18:23:00.282: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:162/proxy/: bar (200; 45.783026ms)
Feb 20 18:23:00.282: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:160/proxy/: foo (200; 46.274098ms)
Feb 20 18:23:00.282: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/rewriteme"... (200; 46.458652ms)
Feb 20 18:23:00.282: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:462/proxy/: tls qux (200; 46.274037ms)
Feb 20 18:23:00.283: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/... (200; 45.732708ms)
Feb 20 18:23:00.283: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:160/proxy/: foo (200; 46.018175ms)
Feb 20 18:23:00.283: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/... (200; 45.929958ms)
Feb 20 18:23:00.283: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:460/proxy/: tls baz (200; 46.853611ms)
Feb 20 18:23:00.283: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname2/proxy/: tls qux (200; 46.783327ms)
Feb 20 18:23:00.283: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname1/proxy/: tls baz (200; 47.004466ms)
Feb 20 18:23:00.283: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname1/proxy/: foo (200; 47.17358ms)
Feb 20 18:23:00.285: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname1/proxy/: foo (200; 48.124728ms)
Feb 20 18:23:00.285: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname2/proxy/: bar (200; 48.626672ms)
Feb 20 18:23:00.285: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname2/proxy/: bar (200; 48.480463ms)
Feb 20 18:23:00.328: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/... (200; 42.868218ms)
Feb 20 18:23:00.329: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/... (200; 43.940231ms)
Feb 20 18:23:00.329: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:460/proxy/: tls baz (200; 43.919093ms)
Feb 20 18:23:00.329: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:162/proxy/: bar (200; 43.789287ms)
Feb 20 18:23:00.329: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:462/proxy/: tls qux (200; 43.584782ms)
Feb 20 18:23:00.329: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/rewri... (200; 43.717026ms)
Feb 20 18:23:00.329: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:162/proxy/: bar (200; 44.124286ms)
Feb 20 18:23:00.330: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname2/proxy/: tls qux (200; 44.25522ms)
Feb 20 18:23:00.330: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:160/proxy/: foo (200; 43.723514ms)
Feb 20 18:23:00.330: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:160/proxy/: foo (200; 44.319541ms)
Feb 20 18:23:00.330: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/rewriteme"... (200; 44.739425ms)
Feb 20 18:23:00.330: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname1/proxy/: tls baz (200; 44.558894ms)
Feb 20 18:23:00.331: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname1/proxy/: foo (200; 45.254016ms)
Feb 20 18:23:00.331: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname1/proxy/: foo (200; 45.783896ms)
Feb 20 18:23:00.331: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname2/proxy/: bar (200; 45.47477ms)
Feb 20 18:23:00.331: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname2/proxy/: bar (200; 45.953197ms)
Feb 20 18:23:00.375: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:462/proxy/: tls qux (200; 43.365118ms)
Feb 20 18:23:00.375: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:162/proxy/: bar (200; 43.673501ms)
Feb 20 18:23:00.375: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/... (200; 43.940099ms)
Feb 20 18:23:00.375: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/rewriteme"... (200; 43.615605ms)
Feb 20 18:23:00.375: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/rewri... (200; 43.831579ms)
Feb 20 18:23:00.375: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:160/proxy/: foo (200; 43.799285ms)
Feb 20 18:23:00.378: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname1/proxy/: tls baz (200; 46.122371ms)
Feb 20 18:23:00.378: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname2/proxy/: tls qux (200; 46.038406ms)
Feb 20 18:23:00.378: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/... (200; 45.884384ms)
Feb 20 18:23:00.378: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname2/proxy/: bar (200; 46.819017ms)
Feb 20 18:23:00.378: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname1/proxy/: foo (200; 46.565582ms)
Feb 20 18:23:00.378: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:460/proxy/: tls baz (200; 45.889523ms)
Feb 20 18:23:00.378: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:160/proxy/: foo (200; 46.627044ms)
Feb 20 18:23:00.379: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname2/proxy/: bar (200; 46.904956ms)
Feb 20 18:23:00.379: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname1/proxy/: foo (200; 46.798191ms)
Feb 20 18:23:00.379: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:162/proxy/: bar (200; 46.638164ms)
Feb 20 18:23:00.422: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/rewriteme"... (200; 43.555762ms)
Feb 20 18:23:00.426: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname1/proxy/: foo (200; 46.755186ms)
Feb 20 18:23:00.426: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:162/proxy/: bar (200; 47.085406ms)
Feb 20 18:23:00.426: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:162/proxy/: bar (200; 47.387764ms)
Feb 20 18:23:00.426: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/rewri... (200; 47.020287ms)
Feb 20 18:23:00.426: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:160/proxy/: foo (200; 46.985443ms)
Feb 20 18:23:00.426: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:462/proxy/: tls qux (200; 46.950846ms)
Feb 20 18:23:00.426: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/... (200; 47.246343ms)
Feb 20 18:23:00.426: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname1/proxy/: foo (200; 47.334724ms)
Feb 20 18:23:00.426: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname2/proxy/: tls qux (200; 46.645464ms)
Feb 20 18:23:00.426: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/... (200; 46.823589ms)
Feb 20 18:23:00.426: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname1/proxy/: tls baz (200; 46.899811ms)
Feb 20 18:23:00.426: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:460/proxy/: tls baz (200; 46.846658ms)
Feb 20 18:23:00.426: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname2/proxy/: bar (200; 46.820943ms)
Feb 20 18:23:00.426: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname2/proxy/: bar (200; 47.05078ms)
Feb 20 18:23:00.426: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:160/proxy/: foo (200; 46.748986ms)
Feb 20 18:23:00.470: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:460/proxy/: tls baz (200; 43.488278ms)
Feb 20 18:23:00.471: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/rewriteme"... (200; 43.361404ms)
Feb 20 18:23:00.471: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:160/proxy/: foo (200; 43.776361ms)
Feb 20 18:23:00.471: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/... (200; 43.524216ms)
Feb 20 18:23:00.471: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/rewri... (200; 43.698386ms)
Feb 20 18:23:00.471: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/... (200; 44.055322ms)
Feb 20 18:23:00.471: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:462/proxy/: tls qux (200; 44.660598ms)
Feb 20 18:23:00.471: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:162/proxy/: bar (200; 43.882542ms)
Feb 20 18:23:00.471: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:160/proxy/: foo (200; 43.743208ms)
Feb 20 18:23:00.471: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:162/proxy/: bar (200; 44.197639ms)
Feb 20 18:23:00.471: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname2/proxy/: tls qux (200; 44.364868ms)
Feb 20 18:23:00.471: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname1/proxy/: tls baz (200; 44.517217ms)
Feb 20 18:23:00.472: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname1/proxy/: foo (200; 45.637846ms)
Feb 20 18:23:00.473: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname2/proxy/: bar (200; 46.109474ms)
Feb 20 18:23:00.473: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname1/proxy/: foo (200; 45.787224ms)
Feb 20 18:23:00.473: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname2/proxy/: bar (200; 46.28872ms)
Feb 20 18:23:00.517: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:460/proxy/: tls baz (200; 44.27389ms)
Feb 20 18:23:00.517: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:462/proxy/: tls qux (200; 43.873985ms)
Feb 20 18:23:00.517: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:162/proxy/: bar (200; 44.118709ms)
Feb 20 18:23:00.517: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/rewriteme"... (200; 44.075298ms)
Feb 20 18:23:00.517: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/rewri... (200; 44.041859ms)
Feb 20 18:23:00.517: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/... (200; 44.256636ms)
Feb 20 18:23:00.517: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:160/proxy/: foo (200; 44.054019ms)
Feb 20 18:23:00.518: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname1/proxy/: foo (200; 44.718677ms)
Feb 20 18:23:00.519: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname2/proxy/: bar (200; 45.441279ms)
Feb 20 18:23:00.519: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:162/proxy/: bar (200; 45.450972ms)
Feb 20 18:23:00.519: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/... (200; 45.457352ms)
Feb 20 18:23:00.519: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname2/proxy/: tls qux (200; 45.553719ms)
Feb 20 18:23:00.519: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname1/proxy/: tls baz (200; 45.682635ms)
Feb 20 18:23:00.519: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname1/proxy/: foo (200; 46.032966ms)
Feb 20 18:23:00.520: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname2/proxy/: bar (200; 46.804231ms)
Feb 20 18:23:00.520: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:160/proxy/: foo (200; 46.422365ms)
Feb 20 18:23:00.566: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname2/proxy/: bar (200; 45.321644ms)
Feb 20 18:23:00.566: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname1/proxy/: tls baz (200; 45.348531ms)
Feb 20 18:23:00.566: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:460/proxy/: tls baz (200; 45.290015ms)
Feb 20 18:23:00.566: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname1/proxy/: foo (200; 45.52833ms)
Feb 20 18:23:00.566: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/rewriteme"... (200; 44.805332ms)
Feb 20 18:23:00.566: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:162/proxy/: bar (200; 44.88528ms)
Feb 20 18:23:00.566: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/... (200; 44.966663ms)
Feb 20 18:23:00.566: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:160/proxy/: foo (200; 44.767732ms)
Feb 20 18:23:00.566: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/rewri... (200; 44.847017ms)
Feb 20 18:23:00.566: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/... (200; 45.14446ms)
Feb 20 18:23:00.566: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:462/proxy/: tls qux (200; 45.838081ms)
Feb 20 18:23:00.567: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname1/proxy/: foo (200; 46.042779ms)
Feb 20 18:23:00.567: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:162/proxy/: bar (200; 46.208015ms)
Feb 20 18:23:00.567: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname2/proxy/: bar (200; 46.410167ms)
Feb 20 18:23:00.568: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:160/proxy/: foo (200; 46.736695ms)
Feb 20 18:23:00.567: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname2/proxy/: tls qux (200; 45.755995ms)
Feb 20 18:23:00.615: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:460/proxy/: tls baz (200; 43.627195ms)
Feb 20 18:23:00.615: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:160/proxy/: foo (200; 43.51581ms)
Feb 20 18:23:00.615: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:162/proxy/: bar (200; 43.463952ms)
Feb 20 18:23:00.615: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:462/proxy/: tls qux (200; 44.24401ms)
Feb 20 18:23:00.618: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:160/proxy/: foo (200; 45.962045ms)
Feb 20 18:23:00.618: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:162/proxy/: bar (200; 46.201408ms)
Feb 20 18:23:00.618: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/... (200; 46.778792ms)
Feb 20 18:23:00.618: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/... (200; 46.305795ms)
Feb 20 18:23:00.618: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/rewri... (200; 46.135969ms)
Feb 20 18:23:00.618: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname1/proxy/: tls baz (200; 46.902568ms)
Feb 20 18:23:00.618: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/rewriteme"... (200; 46.245702ms)
Feb 20 18:23:00.618: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname2/proxy/: tls qux (200; 46.687098ms)
Feb 20 18:23:00.618: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname1/proxy/: foo (200; 47.136959ms)
Feb 20 18:23:00.618: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname1/proxy/: foo (200; 46.52612ms)
Feb 20 18:23:00.618: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname2/proxy/: bar (200; 47.08595ms)
Feb 20 18:23:00.618: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname2/proxy/: bar (200; 46.834305ms)
Feb 20 18:23:00.663: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:160/proxy/: foo (200; 44.729799ms)
Feb 20 18:23:00.663: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:162/proxy/: bar (200; 44.696791ms)
Feb 20 18:23:00.663: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/rewri... (200; 44.574705ms)
Feb 20 18:23:00.663: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/rewriteme"... (200; 44.455565ms)
Feb 20 18:23:00.663: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:162/proxy/: bar (200; 44.697498ms)
Feb 20 18:23:00.663: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/... (200; 44.776871ms)
Feb 20 18:23:00.663: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname2/proxy/: tls qux (200; 44.850666ms)
Feb 20 18:23:00.663: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:460/proxy/: tls baz (200; 44.790979ms)
Feb 20 18:23:00.663: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:462/proxy/: tls qux (200; 44.584765ms)
Feb 20 18:23:00.663: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname1/proxy/: tls baz (200; 44.72467ms)
Feb 20 18:23:00.663: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:160/proxy/: foo (200; 45.049045ms)
Feb 20 18:23:00.663: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/... (200; 45.282868ms)
Feb 20 18:23:00.664: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname1/proxy/: foo (200; 45.493285ms)
Feb 20 18:23:00.664: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname2/proxy/: bar (200; 45.800575ms)
Feb 20 18:23:00.664: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname1/proxy/: foo (200; 45.657944ms)
Feb 20 18:23:00.665: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname2/proxy/: bar (200; 45.85812ms)
Feb 20 18:23:00.709: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:162/proxy/: bar (200; 44.192497ms)
Feb 20 18:23:00.709: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:462/proxy/: tls qux (200; 44.658793ms)
Feb 20 18:23:00.709: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:160/proxy/: foo (200; 44.22311ms)
Feb 20 18:23:00.710: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/... (200; 44.270938ms)
Feb 20 18:23:00.710: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/rewri... (200; 44.241566ms)
Feb 20 18:23:00.710: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:162/proxy/: bar (200; 44.391274ms)
Feb 20 18:23:00.710: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/... (200; 44.831065ms)
Feb 20 18:23:00.710: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:460/proxy/: tls baz (200; 44.600325ms)
Feb 20 18:23:00.710: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:160/proxy/: foo (200; 44.459813ms)
Feb 20 18:23:00.710: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname2/proxy/: tls qux (200; 44.822032ms)
Feb 20 18:23:00.711: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/rewriteme"... (200; 46.133438ms)
Feb 20 18:23:00.711: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname1/proxy/: foo (200; 46.588673ms)
Feb 20 18:23:00.711: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname2/proxy/: bar (200; 46.455008ms)
Feb 20 18:23:00.712: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname1/proxy/: foo (200; 46.315761ms)
Feb 20 18:23:00.712: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname2/proxy/: bar (200; 46.62874ms)
Feb 20 18:23:00.712: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname1/proxy/: tls baz (200; 46.623713ms)
Feb 20 18:23:00.756: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:162/proxy/: bar (200; 44.506641ms)
Feb 20 18:23:00.756: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:160/proxy/: foo (200; 44.515158ms)
Feb 20 18:23:00.756: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:160/proxy/: foo (200; 44.642973ms)
Feb 20 18:23:00.756: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:460/proxy/: tls baz (200; 44.671685ms)
Feb 20 18:23:00.757: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname1/proxy/: tls baz (200; 44.826232ms)
Feb 20 18:23:00.757: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/rewri... (200; 44.82654ms)
Feb 20 18:23:00.757: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/rewriteme"... (200; 45.012113ms)
Feb 20 18:23:00.757: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:462/proxy/: tls qux (200; 45.128736ms)
Feb 20 18:23:00.757: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname2/proxy/: tls qux (200; 45.065897ms)
Feb 20 18:23:00.757: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/... (200; 45.030172ms)
Feb 20 18:23:00.757: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/... (200; 45.018471ms)
Feb 20 18:23:00.757: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:162/proxy/: bar (200; 45.237856ms)
Feb 20 18:23:00.757: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname2/proxy/: bar (200; 45.553446ms)
Feb 20 18:23:00.758: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname1/proxy/: foo (200; 46.186631ms)
Feb 20 18:23:00.758: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname1/proxy/: foo (200; 46.003709ms)
Feb 20 18:23:00.758: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname2/proxy/: bar (200; 46.438089ms)
Feb 20 18:23:00.802: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:162/proxy/: bar (200; 44.083781ms)
Feb 20 18:23:00.803: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:1080/proxy/rewri... (200; 44.17754ms)
Feb 20 18:23:00.803: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:462/proxy/: tls qux (200; 44.166714ms)
Feb 20 18:23:00.803: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld/proxy/rewriteme"... (200; 44.24792ms)
Feb 20 18:23:00.806: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname1/proxy/: foo (200; 47.38769ms)
Feb 20 18:23:00.806: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:160/proxy/: foo (200; 47.662645ms)
Feb 20 18:23:00.806: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/proxy-service-cl22d-bdkld:160/proxy/: foo (200; 47.610917ms)
Feb 20 18:23:00.806: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname1/proxy/: tls baz (200; 47.8363ms)
Feb 20 18:23:00.806: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/https:proxy-service-cl22d:tlsportname2/proxy/: tls qux (200; 47.85544ms)
Feb 20 18:23:00.806: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:1080/proxy/... (200; 47.53742ms)
Feb 20 18:23:00.806: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:460/proxy/: tls baz (200; 47.757534ms)
Feb 20 18:23:00.806: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hthhw/pods/https:proxy-service-cl22d-bdkld:443/proxy/... (200; 47.618914ms)
Feb 20 18:23:00.806: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hthhw/pods/http:proxy-service-cl22d-bdkld:162/proxy/: bar (200; 47.670076ms)
Feb 20 18:23:00.806: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/proxy-service-cl22d:portname2/proxy/: bar (200; 47.744999ms)
Feb 20 18:23:00.806: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname2/proxy/: bar (200; 47.74326ms)
Feb 20 18:23:00.806: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hthhw/services/http:proxy-service-cl22d:portname1/proxy/: foo (200; 47.816208ms)
STEP: deleting { ReplicationController} proxy-service-cl22d in namespace e2e-tests-proxy-hthhw, will wait for the garbage collector to delete the pods
Feb 20 18:23:00.943: INFO: Deleting { ReplicationController} proxy-service-cl22d took: 43.537163ms
Feb 20 18:23:01.044: INFO: Terminating { ReplicationController} proxy-service-cl22d pods took: 101.029089ms
[AfterEach] version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:23:02.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-hthhw" for this suite.
Feb 20 18:23:08.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:23:10.377: INFO: namespace: e2e-tests-proxy-hthhw, resource: bindings, ignored listing per whitelist
Feb 20 18:23:10.419: INFO: namespace e2e-tests-proxy-hthhw deletion completed in 7.73121078s

• [SLOW TEST:22.782 seconds]
[sig-network] Proxy
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:23:10.420: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-6mxz9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-jdfqm
STEP: Creating secret with name secret-test-94c43172-353c-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume secrets
Feb 20 18:23:12.569: INFO: Waiting up to 5m0s for pod "pod-secrets-94f9d405-353c-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-secrets-6mxz9" to be "success or failure"
Feb 20 18:23:12.611: INFO: Pod "pod-secrets-94f9d405-353c-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.626933ms
Feb 20 18:23:14.656: INFO: Pod "pod-secrets-94f9d405-353c-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.08654937s
STEP: Saw pod success
Feb 20 18:23:14.656: INFO: Pod "pod-secrets-94f9d405-353c-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:23:14.698: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-secrets-94f9d405-353c-11e9-997a-8a6f774fb32b container secret-volume-test: <nil>
STEP: delete the pod
Feb 20 18:23:14.792: INFO: Waiting for pod pod-secrets-94f9d405-353c-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:23:14.833: INFO: Pod pod-secrets-94f9d405-353c-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:23:14.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6mxz9" for this suite.
Feb 20 18:23:21.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:23:21.256: INFO: namespace: e2e-tests-secrets-6mxz9, resource: bindings, ignored listing per whitelist
Feb 20 18:23:22.650: INFO: namespace e2e-tests-secrets-6mxz9 deletion completed in 7.773507075s
STEP: Destroying namespace "e2e-tests-secret-namespace-jdfqm" for this suite.
Feb 20 18:23:28.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:23:30.306: INFO: namespace: e2e-tests-secret-namespace-jdfqm, resource: bindings, ignored listing per whitelist
Feb 20 18:23:30.431: INFO: namespace e2e-tests-secret-namespace-jdfqm deletion completed in 7.781749824s

• [SLOW TEST:20.012 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:23:30.432: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-pvn4l
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-a0b093eb-353c-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume secrets
Feb 20 18:23:32.261: INFO: Waiting up to 5m0s for pod "pod-secrets-a0b701c2-353c-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-secrets-pvn4l" to be "success or failure"
Feb 20 18:23:32.303: INFO: Pod "pod-secrets-a0b701c2-353c-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.928379ms
Feb 20 18:23:34.345: INFO: Pod "pod-secrets-a0b701c2-353c-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084363436s
STEP: Saw pod success
Feb 20 18:23:34.345: INFO: Pod "pod-secrets-a0b701c2-353c-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:23:34.387: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-secrets-a0b701c2-353c-11e9-997a-8a6f774fb32b container secret-volume-test: <nil>
STEP: delete the pod
Feb 20 18:23:34.481: INFO: Waiting for pod pod-secrets-a0b701c2-353c-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:23:34.523: INFO: Pod pod-secrets-a0b701c2-353c-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:23:34.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-pvn4l" for this suite.
Feb 20 18:23:40.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:23:42.131: INFO: namespace: e2e-tests-secrets-pvn4l, resource: bindings, ignored listing per whitelist
Feb 20 18:23:42.300: INFO: namespace e2e-tests-secrets-pvn4l deletion completed in 7.734668838s

• [SLOW TEST:11.869 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:23:42.301: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-955qh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 20 18:23:47.006: INFO: Successfully updated pod "labelsupdatea7d842bf-353c-11e9-997a-8a6f774fb32b"
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:23:49.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-955qh" for this suite.
Feb 20 18:24:11.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:24:12.998: INFO: namespace: e2e-tests-projected-955qh, resource: bindings, ignored listing per whitelist
Feb 20 18:24:13.046: INFO: namespace e2e-tests-projected-955qh deletion completed in 23.885546935s

• [SLOW TEST:30.746 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:24:13.046: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rgkdb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-ba3137fa-353c-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume secrets
Feb 20 18:24:15.049: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ba37d511-353c-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-projected-rgkdb" to be "success or failure"
Feb 20 18:24:15.091: INFO: Pod "pod-projected-secrets-ba37d511-353c-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 42.106624ms
Feb 20 18:24:17.135: INFO: Pod "pod-projected-secrets-ba37d511-353c-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085732673s
STEP: Saw pod success
Feb 20 18:24:17.135: INFO: Pod "pod-projected-secrets-ba37d511-353c-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:24:17.178: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-projected-secrets-ba37d511-353c-11e9-997a-8a6f774fb32b container secret-volume-test: <nil>
STEP: delete the pod
Feb 20 18:24:17.273: INFO: Waiting for pod pod-projected-secrets-ba37d511-353c-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:24:17.314: INFO: Pod pod-projected-secrets-ba37d511-353c-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:24:17.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rgkdb" for this suite.
Feb 20 18:24:23.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:24:24.288: INFO: namespace: e2e-tests-projected-rgkdb, resource: bindings, ignored listing per whitelist
Feb 20 18:24:25.122: INFO: namespace e2e-tests-projected-rgkdb deletion completed in 7.764225773s

• [SLOW TEST:12.075 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:24:25.122: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-j9sjp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-c14a271d-353c-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume configMaps
Feb 20 18:24:26.957: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c151209d-353c-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-projected-j9sjp" to be "success or failure"
Feb 20 18:24:26.999: INFO: Pod "pod-projected-configmaps-c151209d-353c-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.469615ms
Feb 20 18:24:29.042: INFO: Pod "pod-projected-configmaps-c151209d-353c-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084286971s
STEP: Saw pod success
Feb 20 18:24:29.042: INFO: Pod "pod-projected-configmaps-c151209d-353c-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:24:29.084: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-projected-configmaps-c151209d-353c-11e9-997a-8a6f774fb32b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 18:24:29.177: INFO: Waiting for pod pod-projected-configmaps-c151209d-353c-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:24:29.219: INFO: Pod pod-projected-configmaps-c151209d-353c-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:24:29.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j9sjp" for this suite.
Feb 20 18:24:35.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:24:35.642: INFO: namespace: e2e-tests-projected-j9sjp, resource: bindings, ignored listing per whitelist
Feb 20 18:24:37.001: INFO: namespace e2e-tests-projected-j9sjp deletion completed in 7.739533143s

• [SLOW TEST:11.879 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:24:37.001: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-b4s5n
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-c86960f2-353c-11e9-997a-8a6f774fb32b
STEP: Creating secret with name s-test-opt-upd-c8696145-353c-11e9-997a-8a6f774fb32b
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-c86960f2-353c-11e9-997a-8a6f774fb32b
STEP: Updating secret s-test-opt-upd-c8696145-353c-11e9-997a-8a6f774fb32b
STEP: Creating secret with name s-test-opt-create-c869615e-353c-11e9-997a-8a6f774fb32b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:24:45.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-b4s5n" for this suite.
Feb 20 18:25:07.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:25:08.600: INFO: namespace: e2e-tests-secrets-b4s5n, resource: bindings, ignored listing per whitelist
Feb 20 18:25:09.500: INFO: namespace e2e-tests-secrets-b4s5n deletion completed in 23.756986109s

• [SLOW TEST:32.500 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:25:09.501: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-rjvvg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 20 18:25:11.363: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-rjvvg'
Feb 20 18:25:13.803: INFO: stderr: ""
Feb 20 18:25:13.803: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 20 18:25:13.803: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rjvvg'
Feb 20 18:25:14.188: INFO: stderr: ""
Feb 20 18:25:14.188: INFO: stdout: "update-demo-nautilus-gs66m update-demo-nautilus-pbnn7 "
Feb 20 18:25:14.188: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-gs66m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rjvvg'
Feb 20 18:25:14.537: INFO: stderr: ""
Feb 20 18:25:14.537: INFO: stdout: ""
Feb 20 18:25:14.537: INFO: update-demo-nautilus-gs66m is created but not running
Feb 20 18:25:19.537: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rjvvg'
Feb 20 18:25:19.811: INFO: stderr: ""
Feb 20 18:25:19.811: INFO: stdout: "update-demo-nautilus-gs66m update-demo-nautilus-pbnn7 "
Feb 20 18:25:19.811: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-gs66m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rjvvg'
Feb 20 18:25:20.134: INFO: stderr: ""
Feb 20 18:25:20.134: INFO: stdout: "true"
Feb 20 18:25:20.135: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-gs66m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rjvvg'
Feb 20 18:25:20.485: INFO: stderr: ""
Feb 20 18:25:20.485: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 18:25:20.485: INFO: validating pod update-demo-nautilus-gs66m
Feb 20 18:25:20.616: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 18:25:20.616: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 18:25:20.616: INFO: update-demo-nautilus-gs66m is verified up and running
Feb 20 18:25:20.616: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-pbnn7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rjvvg'
Feb 20 18:25:20.943: INFO: stderr: ""
Feb 20 18:25:20.943: INFO: stdout: "true"
Feb 20 18:25:20.943: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-pbnn7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rjvvg'
Feb 20 18:25:21.224: INFO: stderr: ""
Feb 20 18:25:21.224: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 18:25:21.224: INFO: validating pod update-demo-nautilus-pbnn7
Feb 20 18:25:21.356: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 18:25:21.356: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 18:25:21.356: INFO: update-demo-nautilus-pbnn7 is verified up and running
STEP: scaling down the replication controller
Feb 20 18:25:21.365: INFO: scanned /root for discovery docs: <nil>
Feb 20 18:25:21.365: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-rjvvg'
Feb 20 18:25:21.831: INFO: stderr: ""
Feb 20 18:25:21.831: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 20 18:25:21.831: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rjvvg'
Feb 20 18:25:22.107: INFO: stderr: ""
Feb 20 18:25:22.107: INFO: stdout: "update-demo-nautilus-gs66m update-demo-nautilus-pbnn7 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 20 18:25:27.121: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rjvvg'
Feb 20 18:25:27.636: INFO: stderr: ""
Feb 20 18:25:27.636: INFO: stdout: "update-demo-nautilus-gs66m update-demo-nautilus-pbnn7 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 20 18:25:32.636: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rjvvg'
Feb 20 18:25:32.890: INFO: stderr: ""
Feb 20 18:25:32.890: INFO: stdout: "update-demo-nautilus-gs66m update-demo-nautilus-pbnn7 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 20 18:25:37.890: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rjvvg'
Feb 20 18:25:38.167: INFO: stderr: ""
Feb 20 18:25:38.167: INFO: stdout: "update-demo-nautilus-pbnn7 "
Feb 20 18:25:38.167: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-pbnn7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rjvvg'
Feb 20 18:25:38.485: INFO: stderr: ""
Feb 20 18:25:38.485: INFO: stdout: "true"
Feb 20 18:25:38.485: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-pbnn7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rjvvg'
Feb 20 18:25:38.792: INFO: stderr: ""
Feb 20 18:25:38.792: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 18:25:38.792: INFO: validating pod update-demo-nautilus-pbnn7
Feb 20 18:25:38.836: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 18:25:38.836: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 18:25:38.836: INFO: update-demo-nautilus-pbnn7 is verified up and running
STEP: scaling up the replication controller
Feb 20 18:25:38.840: INFO: scanned /root for discovery docs: <nil>
Feb 20 18:25:38.840: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-rjvvg'
Feb 20 18:25:39.380: INFO: stderr: ""
Feb 20 18:25:39.380: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 20 18:25:39.381: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rjvvg'
Feb 20 18:25:39.684: INFO: stderr: ""
Feb 20 18:25:39.684: INFO: stdout: "update-demo-nautilus-8hln6 update-demo-nautilus-pbnn7 "
Feb 20 18:25:39.684: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-8hln6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rjvvg'
Feb 20 18:25:39.988: INFO: stderr: ""
Feb 20 18:25:39.989: INFO: stdout: ""
Feb 20 18:25:39.989: INFO: update-demo-nautilus-8hln6 is created but not running
Feb 20 18:25:44.989: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rjvvg'
Feb 20 18:25:45.341: INFO: stderr: ""
Feb 20 18:25:45.341: INFO: stdout: "update-demo-nautilus-8hln6 update-demo-nautilus-pbnn7 "
Feb 20 18:25:45.342: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-8hln6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rjvvg'
Feb 20 18:25:45.749: INFO: stderr: ""
Feb 20 18:25:45.749: INFO: stdout: "true"
Feb 20 18:25:45.749: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-8hln6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rjvvg'
Feb 20 18:25:46.133: INFO: stderr: ""
Feb 20 18:25:46.133: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 18:25:46.133: INFO: validating pod update-demo-nautilus-8hln6
Feb 20 18:25:46.265: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 18:25:46.265: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 18:25:46.265: INFO: update-demo-nautilus-8hln6 is verified up and running
Feb 20 18:25:46.265: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-pbnn7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rjvvg'
Feb 20 18:25:46.676: INFO: stderr: ""
Feb 20 18:25:46.676: INFO: stdout: "true"
Feb 20 18:25:46.676: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-pbnn7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rjvvg'
Feb 20 18:25:47.004: INFO: stderr: ""
Feb 20 18:25:47.004: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 18:25:47.004: INFO: validating pod update-demo-nautilus-pbnn7
Feb 20 18:25:47.047: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 18:25:47.047: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 18:25:47.047: INFO: update-demo-nautilus-pbnn7 is verified up and running
STEP: using delete to clean up resources
Feb 20 18:25:47.047: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rjvvg'
Feb 20 18:25:47.443: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 18:25:47.443: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 20 18:25:47.443: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-rjvvg'
Feb 20 18:25:47.950: INFO: stderr: "No resources found.\n"
Feb 20 18:25:47.950: INFO: stdout: ""
Feb 20 18:25:47.950: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -l name=update-demo --namespace=e2e-tests-kubectl-rjvvg -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 20 18:25:48.562: INFO: stderr: ""
Feb 20 18:25:48.562: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:25:48.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rjvvg" for this suite.
Feb 20 18:26:10.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:26:11.074: INFO: namespace: e2e-tests-kubectl-rjvvg, resource: bindings, ignored listing per whitelist
Feb 20 18:26:12.349: INFO: namespace e2e-tests-kubectl-rjvvg deletion completed in 23.743421396s

• [SLOW TEST:62.848 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:26:12.349: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rhvvb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 18:26:14.207: INFO: Waiting up to 5m0s for pod "downwardapi-volume-013e125f-353d-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-projected-rhvvb" to be "success or failure"
Feb 20 18:26:14.250: INFO: Pod "downwardapi-volume-013e125f-353d-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 42.811376ms
Feb 20 18:26:16.293: INFO: Pod "downwardapi-volume-013e125f-353d-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085152025s
STEP: Saw pod success
Feb 20 18:26:16.293: INFO: Pod "downwardapi-volume-013e125f-353d-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:26:16.335: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod downwardapi-volume-013e125f-353d-11e9-997a-8a6f774fb32b container client-container: <nil>
STEP: delete the pod
Feb 20 18:26:16.429: INFO: Waiting for pod downwardapi-volume-013e125f-353d-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:26:16.471: INFO: Pod downwardapi-volume-013e125f-353d-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:26:16.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rhvvb" for this suite.
Feb 20 18:26:22.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:26:23.506: INFO: namespace: e2e-tests-projected-rhvvb, resource: bindings, ignored listing per whitelist
Feb 20 18:26:24.445: INFO: namespace e2e-tests-projected-rhvvb deletion completed in 7.930802005s

• [SLOW TEST:12.096 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:26:24.445: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-2v6pd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-d5wf
STEP: Creating a pod to test atomic-volume-subpath
Feb 20 18:26:26.304: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-d5wf" in namespace "e2e-tests-subpath-2v6pd" to be "success or failure"
Feb 20 18:26:26.347: INFO: Pod "pod-subpath-test-secret-d5wf": Phase="Pending", Reason="", readiness=false. Elapsed: 42.966222ms
Feb 20 18:26:28.389: INFO: Pod "pod-subpath-test-secret-d5wf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0852598s
Feb 20 18:26:30.433: INFO: Pod "pod-subpath-test-secret-d5wf": Phase="Running", Reason="", readiness=false. Elapsed: 4.128722288s
Feb 20 18:26:32.476: INFO: Pod "pod-subpath-test-secret-d5wf": Phase="Running", Reason="", readiness=false. Elapsed: 6.171589581s
Feb 20 18:26:34.520: INFO: Pod "pod-subpath-test-secret-d5wf": Phase="Running", Reason="", readiness=false. Elapsed: 8.215999251s
Feb 20 18:26:36.562: INFO: Pod "pod-subpath-test-secret-d5wf": Phase="Running", Reason="", readiness=false. Elapsed: 10.258353999s
Feb 20 18:26:38.606: INFO: Pod "pod-subpath-test-secret-d5wf": Phase="Running", Reason="", readiness=false. Elapsed: 12.302014402s
Feb 20 18:26:40.648: INFO: Pod "pod-subpath-test-secret-d5wf": Phase="Running", Reason="", readiness=false. Elapsed: 14.344306703s
Feb 20 18:26:42.693: INFO: Pod "pod-subpath-test-secret-d5wf": Phase="Running", Reason="", readiness=false. Elapsed: 16.389114425s
Feb 20 18:26:44.744: INFO: Pod "pod-subpath-test-secret-d5wf": Phase="Running", Reason="", readiness=false. Elapsed: 18.439880391s
Feb 20 18:26:46.791: INFO: Pod "pod-subpath-test-secret-d5wf": Phase="Running", Reason="", readiness=false. Elapsed: 20.48703927s
Feb 20 18:26:48.834: INFO: Pod "pod-subpath-test-secret-d5wf": Phase="Running", Reason="", readiness=false. Elapsed: 22.53019809s
Feb 20 18:26:50.883: INFO: Pod "pod-subpath-test-secret-d5wf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.579065303s
STEP: Saw pod success
Feb 20 18:26:50.883: INFO: Pod "pod-subpath-test-secret-d5wf" satisfied condition "success or failure"
Feb 20 18:26:50.925: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-subpath-test-secret-d5wf container test-container-subpath-secret-d5wf: <nil>
STEP: delete the pod
Feb 20 18:26:51.019: INFO: Waiting for pod pod-subpath-test-secret-d5wf to disappear
Feb 20 18:26:51.064: INFO: Pod pod-subpath-test-secret-d5wf no longer exists
STEP: Deleting pod pod-subpath-test-secret-d5wf
Feb 20 18:26:51.064: INFO: Deleting pod "pod-subpath-test-secret-d5wf" in namespace "e2e-tests-subpath-2v6pd"
[AfterEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:26:51.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-2v6pd" for this suite.
Feb 20 18:26:57.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:26:58.046: INFO: namespace: e2e-tests-subpath-2v6pd, resource: bindings, ignored listing per whitelist
Feb 20 18:26:58.898: INFO: namespace e2e-tests-subpath-2v6pd deletion completed in 7.748582754s

• [SLOW TEST:34.453 seconds]
[sig-storage] Subpath
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:26:58.898: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-gkfd6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 18:27:00.807: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1d04a996-353d-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-downward-api-gkfd6" to be "success or failure"
Feb 20 18:27:00.849: INFO: Pod "downwardapi-volume-1d04a996-353d-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 42.069886ms
Feb 20 18:27:02.893: INFO: Pod "downwardapi-volume-1d04a996-353d-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.086189688s
STEP: Saw pod success
Feb 20 18:27:02.893: INFO: Pod "downwardapi-volume-1d04a996-353d-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:27:02.936: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod downwardapi-volume-1d04a996-353d-11e9-997a-8a6f774fb32b container client-container: <nil>
STEP: delete the pod
Feb 20 18:27:03.030: INFO: Waiting for pod downwardapi-volume-1d04a996-353d-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:27:03.072: INFO: Pod downwardapi-volume-1d04a996-353d-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:27:03.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gkfd6" for this suite.
Feb 20 18:27:09.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:27:09.915: INFO: namespace: e2e-tests-downward-api-gkfd6, resource: bindings, ignored listing per whitelist
Feb 20 18:27:10.852: INFO: namespace e2e-tests-downward-api-gkfd6 deletion completed in 7.737028819s

• [SLOW TEST:11.954 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:27:10.852: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-krb2x
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-24320b14-353d-11e9-997a-8a6f774fb32b
STEP: Creating configMap with name cm-test-opt-upd-24320b59-353d-11e9-997a-8a6f774fb32b
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-24320b14-353d-11e9-997a-8a6f774fb32b
STEP: Updating configmap cm-test-opt-upd-24320b59-353d-11e9-997a-8a6f774fb32b
STEP: Creating configMap with name cm-test-opt-create-24320c8f-353d-11e9-997a-8a6f774fb32b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:27:17.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-krb2x" for this suite.
Feb 20 18:27:39.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:27:41.233: INFO: namespace: e2e-tests-configmap-krb2x, resource: bindings, ignored listing per whitelist
Feb 20 18:27:41.318: INFO: namespace e2e-tests-configmap-krb2x deletion completed in 23.723819555s

• [SLOW TEST:30.466 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:27:41.318: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-mg4qw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 20 18:27:43.070: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-mg4qw'
Feb 20 18:27:43.822: INFO: stderr: ""
Feb 20 18:27:43.822: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 20 18:27:43.822: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mg4qw'
Feb 20 18:27:44.104: INFO: stderr: ""
Feb 20 18:27:44.104: INFO: stdout: "update-demo-nautilus-vzfcj update-demo-nautilus-zpx6x "
Feb 20 18:27:44.104: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-vzfcj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mg4qw'
Feb 20 18:27:44.358: INFO: stderr: ""
Feb 20 18:27:44.358: INFO: stdout: ""
Feb 20 18:27:44.358: INFO: update-demo-nautilus-vzfcj is created but not running
Feb 20 18:27:49.358: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mg4qw'
Feb 20 18:27:49.672: INFO: stderr: ""
Feb 20 18:27:49.672: INFO: stdout: "update-demo-nautilus-vzfcj update-demo-nautilus-zpx6x "
Feb 20 18:27:49.672: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-vzfcj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mg4qw'
Feb 20 18:27:49.987: INFO: stderr: ""
Feb 20 18:27:49.987: INFO: stdout: "true"
Feb 20 18:27:49.987: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-vzfcj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mg4qw'
Feb 20 18:27:50.254: INFO: stderr: ""
Feb 20 18:27:50.254: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 18:27:50.254: INFO: validating pod update-demo-nautilus-vzfcj
Feb 20 18:27:50.383: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 18:27:50.383: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 18:27:50.383: INFO: update-demo-nautilus-vzfcj is verified up and running
Feb 20 18:27:50.384: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-zpx6x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mg4qw'
Feb 20 18:27:50.638: INFO: stderr: ""
Feb 20 18:27:50.638: INFO: stdout: "true"
Feb 20 18:27:50.638: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-zpx6x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mg4qw'
Feb 20 18:27:50.896: INFO: stderr: ""
Feb 20 18:27:50.896: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 18:27:50.896: INFO: validating pod update-demo-nautilus-zpx6x
Feb 20 18:27:51.029: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 18:27:51.030: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 18:27:51.030: INFO: update-demo-nautilus-zpx6x is verified up and running
STEP: using delete to clean up resources
Feb 20 18:27:51.030: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-mg4qw'
Feb 20 18:27:51.379: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 18:27:51.379: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 20 18:27:51.379: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-mg4qw'
Feb 20 18:27:51.674: INFO: stderr: "No resources found.\n"
Feb 20 18:27:51.674: INFO: stdout: ""
Feb 20 18:27:51.674: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -l name=update-demo --namespace=e2e-tests-kubectl-mg4qw -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 20 18:27:51.932: INFO: stderr: ""
Feb 20 18:27:51.932: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:27:51.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mg4qw" for this suite.
Feb 20 18:28:16.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:28:16.924: INFO: namespace: e2e-tests-kubectl-mg4qw, resource: bindings, ignored listing per whitelist
Feb 20 18:28:17.735: INFO: namespace e2e-tests-kubectl-mg4qw deletion completed in 25.759944481s

• [SLOW TEST:36.417 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:28:17.735: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-wxzkz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-wxzkz
[It] Should recreate evicted statefulset [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-wxzkz
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-wxzkz
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-wxzkz
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-wxzkz
Feb 20 18:28:21.798: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-wxzkz, name: ss-0, uid: 4d4d9c99-353d-11e9-936d-1e925ead141b, status phase: Pending. Waiting for statefulset controller to delete.
Feb 20 18:28:21.807: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-wxzkz, name: ss-0, uid: 4d4d9c99-353d-11e9-936d-1e925ead141b, status phase: Failed. Waiting for statefulset controller to delete.
Feb 20 18:28:21.848: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-wxzkz, name: ss-0, uid: 4d4d9c99-353d-11e9-936d-1e925ead141b, status phase: Failed. Waiting for statefulset controller to delete.
Feb 20 18:28:21.857: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-wxzkz
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-wxzkz
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-wxzkz and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 20 18:28:23.985: INFO: Deleting all statefulset in ns e2e-tests-statefulset-wxzkz
Feb 20 18:28:24.027: INFO: Scaling statefulset ss to 0
Feb 20 18:28:34.195: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 18:28:34.237: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:28:34.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-wxzkz" for this suite.
Feb 20 18:28:40.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:28:41.588: INFO: namespace: e2e-tests-statefulset-wxzkz, resource: bindings, ignored listing per whitelist
Feb 20 18:28:42.180: INFO: namespace e2e-tests-statefulset-wxzkz deletion completed in 7.773436521s

• [SLOW TEST:24.445 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:28:42.180: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-rcjrh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-d8wn
STEP: Creating a pod to test atomic-volume-subpath
Feb 20 18:28:44.201: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-d8wn" in namespace "e2e-tests-subpath-rcjrh" to be "success or failure"
Feb 20 18:28:44.244: INFO: Pod "pod-subpath-test-downwardapi-d8wn": Phase="Pending", Reason="", readiness=false. Elapsed: 42.991795ms
Feb 20 18:28:46.287: INFO: Pod "pod-subpath-test-downwardapi-d8wn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.085735665s
Feb 20 18:28:48.333: INFO: Pod "pod-subpath-test-downwardapi-d8wn": Phase="Running", Reason="", readiness=false. Elapsed: 4.132328125s
Feb 20 18:28:50.376: INFO: Pod "pod-subpath-test-downwardapi-d8wn": Phase="Running", Reason="", readiness=false. Elapsed: 6.174740683s
Feb 20 18:28:52.420: INFO: Pod "pod-subpath-test-downwardapi-d8wn": Phase="Running", Reason="", readiness=false. Elapsed: 8.219450363s
Feb 20 18:28:54.464: INFO: Pod "pod-subpath-test-downwardapi-d8wn": Phase="Running", Reason="", readiness=false. Elapsed: 10.263213791s
Feb 20 18:28:56.507: INFO: Pod "pod-subpath-test-downwardapi-d8wn": Phase="Running", Reason="", readiness=false. Elapsed: 12.305984401s
Feb 20 18:28:58.549: INFO: Pod "pod-subpath-test-downwardapi-d8wn": Phase="Running", Reason="", readiness=false. Elapsed: 14.34838764s
Feb 20 18:29:00.592: INFO: Pod "pod-subpath-test-downwardapi-d8wn": Phase="Running", Reason="", readiness=false. Elapsed: 16.390915652s
Feb 20 18:29:02.635: INFO: Pod "pod-subpath-test-downwardapi-d8wn": Phase="Running", Reason="", readiness=false. Elapsed: 18.433737313s
Feb 20 18:29:04.677: INFO: Pod "pod-subpath-test-downwardapi-d8wn": Phase="Running", Reason="", readiness=false. Elapsed: 20.476334533s
Feb 20 18:29:06.720: INFO: Pod "pod-subpath-test-downwardapi-d8wn": Phase="Running", Reason="", readiness=false. Elapsed: 22.518561057s
Feb 20 18:29:08.762: INFO: Pod "pod-subpath-test-downwardapi-d8wn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.560953775s
STEP: Saw pod success
Feb 20 18:29:08.762: INFO: Pod "pod-subpath-test-downwardapi-d8wn" satisfied condition "success or failure"
Feb 20 18:29:08.804: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-subpath-test-downwardapi-d8wn container test-container-subpath-downwardapi-d8wn: <nil>
STEP: delete the pod
Feb 20 18:29:08.897: INFO: Waiting for pod pod-subpath-test-downwardapi-d8wn to disappear
Feb 20 18:29:08.938: INFO: Pod pod-subpath-test-downwardapi-d8wn no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-d8wn
Feb 20 18:29:08.938: INFO: Deleting pod "pod-subpath-test-downwardapi-d8wn" in namespace "e2e-tests-subpath-rcjrh"
[AfterEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:29:08.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-rcjrh" for this suite.
Feb 20 18:29:15.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:29:15.928: INFO: namespace: e2e-tests-subpath-rcjrh, resource: bindings, ignored listing per whitelist
Feb 20 18:29:16.817: INFO: namespace e2e-tests-subpath-rcjrh deletion completed in 7.794805078s

• [SLOW TEST:34.637 seconds]
[sig-storage] Subpath
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:29:16.819: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-86lf4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-6f2ef994-353d-11e9-997a-8a6f774fb32b
STEP: Creating secret with name s-test-opt-upd-6f2ef9f1-353d-11e9-997a-8a6f774fb32b
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-6f2ef994-353d-11e9-997a-8a6f774fb32b
STEP: Updating secret s-test-opt-upd-6f2ef9f1-353d-11e9-997a-8a6f774fb32b
STEP: Creating secret with name s-test-opt-create-6f2efa37-353d-11e9-997a-8a6f774fb32b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:29:23.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-86lf4" for this suite.
Feb 20 18:29:45.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:29:46.600: INFO: namespace: e2e-tests-projected-86lf4, resource: bindings, ignored listing per whitelist
Feb 20 18:29:47.199: INFO: namespace e2e-tests-projected-86lf4 deletion completed in 23.810073803s

• [SLOW TEST:30.380 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:29:47.199: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-h895s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 18:29:48.963: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml version'
Feb 20 18:29:49.749: INFO: stderr: ""
Feb 20 18:29:49.749: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.5\", GitCommit:\"51dd616cdd25d6ee22c83a858773b607328a18ec\", GitTreeState:\"archive\", BuildDate:\"2019-02-20T18:05:25Z\", GoVersion:\"go1.11.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.5\", GitCommit:\"51dd616cdd25d6ee22c83a858773b607328a18ec\", GitTreeState:\"clean\", BuildDate:\"2019-01-16T18:14:49Z\", GoVersion:\"go1.10.7\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:29:49.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-h895s" for this suite.
Feb 20 18:29:55.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:29:56.808: INFO: namespace: e2e-tests-kubectl-h895s, resource: bindings, ignored listing per whitelist
Feb 20 18:29:57.644: INFO: namespace e2e-tests-kubectl-h895s deletion completed in 7.85299868s

• [SLOW TEST:10.445 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:29:57.644: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-rg524
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 20 18:29:59.369: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:30:02.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-rg524" for this suite.
Feb 20 18:30:08.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:30:09.440: INFO: namespace: e2e-tests-init-container-rg524, resource: bindings, ignored listing per whitelist
Feb 20 18:30:10.452: INFO: namespace e2e-tests-init-container-rg524 deletion completed in 7.73000742s

• [SLOW TEST:12.808 seconds]
[k8s.io] InitContainer [NodeConformance]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:30:10.452: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-cnpqw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Feb 20 18:30:12.309: INFO: Waiting up to 5m0s for pod "client-containers-8f2995fa-353d-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-containers-cnpqw" to be "success or failure"
Feb 20 18:30:12.354: INFO: Pod "client-containers-8f2995fa-353d-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 44.444935ms
Feb 20 18:30:14.396: INFO: Pod "client-containers-8f2995fa-353d-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.086965842s
Feb 20 18:30:16.440: INFO: Pod "client-containers-8f2995fa-353d-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.130957243s
STEP: Saw pod success
Feb 20 18:30:16.440: INFO: Pod "client-containers-8f2995fa-353d-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:30:16.485: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod client-containers-8f2995fa-353d-11e9-997a-8a6f774fb32b container test-container: <nil>
STEP: delete the pod
Feb 20 18:30:16.578: INFO: Waiting for pod client-containers-8f2995fa-353d-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:30:16.621: INFO: Pod client-containers-8f2995fa-353d-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:30:16.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-cnpqw" for this suite.
Feb 20 18:30:22.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:30:23.814: INFO: namespace: e2e-tests-containers-cnpqw, resource: bindings, ignored listing per whitelist
Feb 20 18:30:24.422: INFO: namespace e2e-tests-containers-cnpqw deletion completed in 7.756497039s

• [SLOW TEST:13.969 seconds]
[k8s.io] Docker Containers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:30:24.422: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2sfrn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-97881774-353d-11e9-997a-8a6f774fb32b
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-97881774-353d-11e9-997a-8a6f774fb32b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:30:30.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2sfrn" for this suite.
Feb 20 18:30:52.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:30:54.160: INFO: namespace: e2e-tests-projected-2sfrn, resource: bindings, ignored listing per whitelist
Feb 20 18:30:54.540: INFO: namespace e2e-tests-projected-2sfrn deletion completed in 23.794535738s

• [SLOW TEST:30.118 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:30:54.541: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-29h9t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 20 18:30:56.361: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-29h9t'
Feb 20 18:30:56.663: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 20 18:30:56.663: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Feb 20 18:30:56.750: INFO: scanned /root for discovery docs: <nil>
Feb 20 18:30:56.750: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-29h9t'
Feb 20 18:31:08.540: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 20 18:31:08.540: INFO: stdout: "Created e2e-test-nginx-rc-dc91497eb7d58a41e606d152fcf40a55\nScaling up e2e-test-nginx-rc-dc91497eb7d58a41e606d152fcf40a55 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-dc91497eb7d58a41e606d152fcf40a55 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-dc91497eb7d58a41e606d152fcf40a55 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb 20 18:31:08.540: INFO: stdout: "Created e2e-test-nginx-rc-dc91497eb7d58a41e606d152fcf40a55\nScaling up e2e-test-nginx-rc-dc91497eb7d58a41e606d152fcf40a55 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-dc91497eb7d58a41e606d152fcf40a55 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-dc91497eb7d58a41e606d152fcf40a55 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb 20 18:31:08.540: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-29h9t'
Feb 20 18:31:08.828: INFO: stderr: ""
Feb 20 18:31:08.828: INFO: stdout: "e2e-test-nginx-rc-dc91497eb7d58a41e606d152fcf40a55-c2wgs "
Feb 20 18:31:08.828: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods e2e-test-nginx-rc-dc91497eb7d58a41e606d152fcf40a55-c2wgs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-29h9t'
Feb 20 18:31:09.171: INFO: stderr: ""
Feb 20 18:31:09.172: INFO: stdout: "true"
Feb 20 18:31:09.172: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods e2e-test-nginx-rc-dc91497eb7d58a41e606d152fcf40a55-c2wgs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-29h9t'
Feb 20 18:31:09.645: INFO: stderr: ""
Feb 20 18:31:09.645: INFO: stdout: "nginx:1.14-alpine"
Feb 20 18:31:09.645: INFO: e2e-test-nginx-rc-dc91497eb7d58a41e606d152fcf40a55-c2wgs is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Feb 20 18:31:09.646: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-29h9t'
Feb 20 18:31:10.118: INFO: stderr: ""
Feb 20 18:31:10.118: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:31:10.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-29h9t" for this suite.
Feb 20 18:31:16.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:31:16.748: INFO: namespace: e2e-tests-kubectl-29h9t, resource: bindings, ignored listing per whitelist
Feb 20 18:31:17.904: INFO: namespace e2e-tests-kubectl-29h9t deletion completed in 7.742775267s

• [SLOW TEST:23.364 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:31:17.904: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-9dqbm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 20 18:31:19.670: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-9dqbm'
Feb 20 18:31:20.046: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 20 18:31:20.046: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Feb 20 18:31:22.130: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-9dqbm'
Feb 20 18:31:22.552: INFO: stderr: ""
Feb 20 18:31:22.552: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:31:22.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9dqbm" for this suite.
Feb 20 18:31:44.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:31:45.222: INFO: namespace: e2e-tests-kubectl-9dqbm, resource: bindings, ignored listing per whitelist
Feb 20 18:31:46.404: INFO: namespace e2e-tests-kubectl-9dqbm deletion completed in 23.809277684s

• [SLOW TEST:28.500 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:31:46.404: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-4vcd6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Feb 20 18:31:48.312: INFO: Waiting up to 5m0s for pod "var-expansion-c86276e4-353d-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-var-expansion-4vcd6" to be "success or failure"
Feb 20 18:31:48.357: INFO: Pod "var-expansion-c86276e4-353d-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 44.544862ms
Feb 20 18:31:50.400: INFO: Pod "var-expansion-c86276e4-353d-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.087310946s
STEP: Saw pod success
Feb 20 18:31:50.400: INFO: Pod "var-expansion-c86276e4-353d-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:31:50.441: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod var-expansion-c86276e4-353d-11e9-997a-8a6f774fb32b container dapi-container: <nil>
STEP: delete the pod
Feb 20 18:31:50.537: INFO: Waiting for pod var-expansion-c86276e4-353d-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:31:50.579: INFO: Pod var-expansion-c86276e4-353d-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:31:50.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-4vcd6" for this suite.
Feb 20 18:31:56.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:31:57.871: INFO: namespace: e2e-tests-var-expansion-4vcd6, resource: bindings, ignored listing per whitelist
Feb 20 18:31:58.430: INFO: namespace e2e-tests-var-expansion-4vcd6 deletion completed in 7.808153403s

• [SLOW TEST:12.026 seconds]
[k8s.io] Variable Expansion
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:31:58.431: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5jrw7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-cf7b6348-353d-11e9-997a-8a6f774fb32b
STEP: Creating secret with name secret-projected-all-test-volume-cf7b632a-353d-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb 20 18:32:00.309: INFO: Waiting up to 5m0s for pod "projected-volume-cf7b62f4-353d-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-projected-5jrw7" to be "success or failure"
Feb 20 18:32:00.363: INFO: Pod "projected-volume-cf7b62f4-353d-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 54.055372ms
Feb 20 18:32:02.421: INFO: Pod "projected-volume-cf7b62f4-353d-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.111875259s
STEP: Saw pod success
Feb 20 18:32:02.421: INFO: Pod "projected-volume-cf7b62f4-353d-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:32:02.464: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod projected-volume-cf7b62f4-353d-11e9-997a-8a6f774fb32b container projected-all-volume-test: <nil>
STEP: delete the pod
Feb 20 18:32:02.594: INFO: Waiting for pod projected-volume-cf7b62f4-353d-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:32:02.636: INFO: Pod projected-volume-cf7b62f4-353d-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:32:02.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5jrw7" for this suite.
Feb 20 18:32:08.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:32:10.177: INFO: namespace: e2e-tests-projected-5jrw7, resource: bindings, ignored listing per whitelist
Feb 20 18:32:10.427: INFO: namespace e2e-tests-projected-5jrw7 deletion completed in 7.748631119s

• [SLOW TEST:11.997 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:32:10.427: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-stljc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-stljc/secret-test-d6a1f115-353d-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume secrets
Feb 20 18:32:12.264: INFO: Waiting up to 5m0s for pod "pod-configmaps-d6a8f459-353d-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-secrets-stljc" to be "success or failure"
Feb 20 18:32:12.306: INFO: Pod "pod-configmaps-d6a8f459-353d-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.662985ms
Feb 20 18:32:14.349: INFO: Pod "pod-configmaps-d6a8f459-353d-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085147736s
STEP: Saw pod success
Feb 20 18:32:14.349: INFO: Pod "pod-configmaps-d6a8f459-353d-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:32:14.391: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-configmaps-d6a8f459-353d-11e9-997a-8a6f774fb32b container env-test: <nil>
STEP: delete the pod
Feb 20 18:32:14.498: INFO: Waiting for pod pod-configmaps-d6a8f459-353d-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:32:14.540: INFO: Pod pod-configmaps-d6a8f459-353d-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:32:14.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-stljc" for this suite.
Feb 20 18:32:20.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:32:22.225: INFO: namespace: e2e-tests-secrets-stljc, resource: bindings, ignored listing per whitelist
Feb 20 18:32:22.309: INFO: namespace e2e-tests-secrets-stljc deletion completed in 7.7259165s

• [SLOW TEST:11.881 seconds]
[sig-api-machinery] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:32:22.309: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bdzbt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 18:32:24.218: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ddb98cdb-353d-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-projected-bdzbt" to be "success or failure"
Feb 20 18:32:24.260: INFO: Pod "downwardapi-volume-ddb98cdb-353d-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.443247ms
Feb 20 18:32:26.303: INFO: Pod "downwardapi-volume-ddb98cdb-353d-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084697277s
STEP: Saw pod success
Feb 20 18:32:26.303: INFO: Pod "downwardapi-volume-ddb98cdb-353d-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:32:26.345: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod downwardapi-volume-ddb98cdb-353d-11e9-997a-8a6f774fb32b container client-container: <nil>
STEP: delete the pod
Feb 20 18:32:26.439: INFO: Waiting for pod downwardapi-volume-ddb98cdb-353d-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:32:26.480: INFO: Pod downwardapi-volume-ddb98cdb-353d-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:32:26.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bdzbt" for this suite.
Feb 20 18:32:32.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:32:33.551: INFO: namespace: e2e-tests-projected-bdzbt, resource: bindings, ignored listing per whitelist
Feb 20 18:32:34.265: INFO: namespace e2e-tests-projected-bdzbt deletion completed in 7.74210772s

• [SLOW TEST:11.956 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:32:34.265: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-74pd8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-e4d0d57a-353d-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume secrets
Feb 20 18:32:36.054: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e4d74708-353d-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-projected-74pd8" to be "success or failure"
Feb 20 18:32:36.096: INFO: Pod "pod-projected-secrets-e4d74708-353d-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.776968ms
Feb 20 18:32:38.138: INFO: Pod "pod-projected-secrets-e4d74708-353d-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.083964005s
STEP: Saw pod success
Feb 20 18:32:38.138: INFO: Pod "pod-projected-secrets-e4d74708-353d-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:32:38.180: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-projected-secrets-e4d74708-353d-11e9-997a-8a6f774fb32b container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 20 18:32:38.274: INFO: Waiting for pod pod-projected-secrets-e4d74708-353d-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:32:38.317: INFO: Pod pod-projected-secrets-e4d74708-353d-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:32:38.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-74pd8" for this suite.
Feb 20 18:32:44.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:32:46.160: INFO: namespace: e2e-tests-projected-74pd8, resource: bindings, ignored listing per whitelist
Feb 20 18:32:46.205: INFO: namespace e2e-tests-projected-74pd8 deletion completed in 7.839926639s

• [SLOW TEST:11.940 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:32:46.205: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-7nk69
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 18:32:48.152: INFO: (0) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 137.234628ms)
Feb 20 18:32:48.237: INFO: (1) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 84.748664ms)
Feb 20 18:32:48.282: INFO: (2) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 44.43247ms)
Feb 20 18:32:48.331: INFO: (3) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 48.969291ms)
Feb 20 18:32:48.382: INFO: (4) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 51.330977ms)
Feb 20 18:32:48.425: INFO: (5) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.338038ms)
Feb 20 18:32:48.472: INFO: (6) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 46.383472ms)
Feb 20 18:32:48.518: INFO: (7) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 45.905208ms)
Feb 20 18:32:48.561: INFO: (8) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.169528ms)
Feb 20 18:32:48.605: INFO: (9) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.651578ms)
Feb 20 18:32:48.649: INFO: (10) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.739618ms)
Feb 20 18:32:48.695: INFO: (11) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 45.943843ms)
Feb 20 18:32:48.741: INFO: (12) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 46.135848ms)
Feb 20 18:32:48.786: INFO: (13) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 44.945619ms)
Feb 20 18:32:48.829: INFO: (14) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.213859ms)
Feb 20 18:32:48.873: INFO: (15) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.557366ms)
Feb 20 18:32:48.917: INFO: (16) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 44.109131ms)
Feb 20 18:32:48.961: INFO: (17) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.793377ms)
Feb 20 18:32:49.005: INFO: (18) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 44.65368ms)
Feb 20 18:32:49.051: INFO: (19) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 45.333127ms)
[AfterEach] version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:32:49.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-7nk69" for this suite.
Feb 20 18:32:55.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:32:55.653: INFO: namespace: e2e-tests-proxy-7nk69, resource: bindings, ignored listing per whitelist
Feb 20 18:32:56.832: INFO: namespace e2e-tests-proxy-7nk69 deletion completed in 7.736105243s

• [SLOW TEST:10.627 seconds]
[sig-network] Proxy
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:32:56.833: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-nh9pc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Feb 20 18:33:00.900: INFO: Pod pod-hostip-f2574cab-353d-11e9-997a-8a6f774fb32b has hostIP: 10.250.8.15
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:33:00.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-nh9pc" for this suite.
Feb 20 18:33:23.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:33:23.950: INFO: namespace: e2e-tests-pods-nh9pc, resource: bindings, ignored listing per whitelist
Feb 20 18:33:24.762: INFO: namespace e2e-tests-pods-nh9pc deletion completed in 23.819418237s

• [SLOW TEST:27.929 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:33:24.762: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-58s97
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-58s97
Feb 20 18:33:30.693: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-58s97
STEP: checking the pod's current state and verifying that restartCount is present
Feb 20 18:33:30.737: INFO: Initial restart count of pod liveness-http is 0
Feb 20 18:33:45.084: INFO: Restart count of pod e2e-tests-container-probe-58s97/liveness-http is now 1 (14.346647542s elapsed)
Feb 20 18:34:05.537: INFO: Restart count of pod e2e-tests-container-probe-58s97/liveness-http is now 2 (34.799935925s elapsed)
Feb 20 18:34:25.971: INFO: Restart count of pod e2e-tests-container-probe-58s97/liveness-http is now 3 (55.233788953s elapsed)
Feb 20 18:34:44.361: INFO: Restart count of pod e2e-tests-container-probe-58s97/liveness-http is now 4 (1m13.623581002s elapsed)
Feb 20 18:35:57.960: INFO: Restart count of pod e2e-tests-container-probe-58s97/liveness-http is now 5 (2m27.222894328s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:35:58.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-58s97" for this suite.
Feb 20 18:36:04.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:36:05.100: INFO: namespace: e2e-tests-container-probe-58s97, resource: bindings, ignored listing per whitelist
Feb 20 18:36:05.816: INFO: namespace e2e-tests-container-probe-58s97 deletion completed in 7.767439743s

• [SLOW TEST:161.053 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:36:05.816: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-2fxjm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-2fxjm/configmap-test-630f5c56-353e-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume configMaps
Feb 20 18:36:07.858: INFO: Waiting up to 5m0s for pod "pod-configmaps-631609a6-353e-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-configmap-2fxjm" to be "success or failure"
Feb 20 18:36:07.900: INFO: Pod "pod-configmaps-631609a6-353e-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.948551ms
Feb 20 18:36:09.942: INFO: Pod "pod-configmaps-631609a6-353e-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0839938s
STEP: Saw pod success
Feb 20 18:36:09.942: INFO: Pod "pod-configmaps-631609a6-353e-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:36:09.984: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-configmaps-631609a6-353e-11e9-997a-8a6f774fb32b container env-test: <nil>
STEP: delete the pod
Feb 20 18:36:10.079: INFO: Waiting for pod pod-configmaps-631609a6-353e-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:36:10.121: INFO: Pod pod-configmaps-631609a6-353e-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:36:10.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2fxjm" for this suite.
Feb 20 18:36:16.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:36:17.197: INFO: namespace: e2e-tests-configmap-2fxjm, resource: bindings, ignored listing per whitelist
Feb 20 18:36:17.999: INFO: namespace e2e-tests-configmap-2fxjm deletion completed in 7.835635183s

• [SLOW TEST:12.183 seconds]
[sig-api-machinery] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:36:17.999: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-fncj2
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 18:36:19.816: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:36:20.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-fncj2" for this suite.
Feb 20 18:36:26.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:36:26.748: INFO: namespace: e2e-tests-custom-resource-definition-fncj2, resource: bindings, ignored listing per whitelist
Feb 20 18:36:28.187: INFO: namespace e2e-tests-custom-resource-definition-fncj2 deletion completed in 7.73590223s

• [SLOW TEST:10.187 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:36:28.187: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qxrdt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-704af7ac-353e-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume configMaps
Feb 20 18:36:30.057: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-705168ec-353e-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-projected-qxrdt" to be "success or failure"
Feb 20 18:36:30.099: INFO: Pod "pod-projected-configmaps-705168ec-353e-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.883165ms
Feb 20 18:36:32.142: INFO: Pod "pod-projected-configmaps-705168ec-353e-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084450819s
STEP: Saw pod success
Feb 20 18:36:32.142: INFO: Pod "pod-projected-configmaps-705168ec-353e-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:36:32.184: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-projected-configmaps-705168ec-353e-11e9-997a-8a6f774fb32b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 18:36:32.276: INFO: Waiting for pod pod-projected-configmaps-705168ec-353e-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:36:32.318: INFO: Pod pod-projected-configmaps-705168ec-353e-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:36:32.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qxrdt" for this suite.
Feb 20 18:36:38.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:36:39.394: INFO: namespace: e2e-tests-projected-qxrdt, resource: bindings, ignored listing per whitelist
Feb 20 18:36:40.110: INFO: namespace e2e-tests-projected-qxrdt deletion completed in 7.749134792s

• [SLOW TEST:11.923 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:36:40.110: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-zfbdj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 18:36:42.207: INFO: Waiting up to 5m0s for pod "downwardapi-volume-778f4251-353e-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-projected-zfbdj" to be "success or failure"
Feb 20 18:36:42.249: INFO: Pod "downwardapi-volume-778f4251-353e-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.654151ms
Feb 20 18:36:44.291: INFO: Pod "downwardapi-volume-778f4251-353e-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084312517s
STEP: Saw pod success
Feb 20 18:36:44.291: INFO: Pod "downwardapi-volume-778f4251-353e-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:36:44.335: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod downwardapi-volume-778f4251-353e-11e9-997a-8a6f774fb32b container client-container: <nil>
STEP: delete the pod
Feb 20 18:36:44.431: INFO: Waiting for pod downwardapi-volume-778f4251-353e-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:36:44.473: INFO: Pod downwardapi-volume-778f4251-353e-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:36:44.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zfbdj" for this suite.
Feb 20 18:36:50.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:36:51.187: INFO: namespace: e2e-tests-projected-zfbdj, resource: bindings, ignored listing per whitelist
Feb 20 18:36:52.283: INFO: namespace e2e-tests-projected-zfbdj deletion completed in 7.727256482s

• [SLOW TEST:12.173 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:36:52.283: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-wfwqx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 20 18:36:58.495: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 18:36:58.537: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 20 18:37:00.537: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 18:37:00.580: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 20 18:37:02.537: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 18:37:02.579: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 20 18:37:04.537: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 18:37:04.579: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 20 18:37:06.537: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 18:37:06.583: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 20 18:37:08.537: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 18:37:08.579: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 20 18:37:10.537: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 18:37:10.580: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 20 18:37:12.541: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 18:37:12.586: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 20 18:37:14.537: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 18:37:14.582: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 20 18:37:16.537: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 18:37:16.581: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 20 18:37:18.537: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 18:37:18.582: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 20 18:37:20.537: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 18:37:20.580: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 20 18:37:22.538: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 18:37:22.580: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 20 18:37:24.538: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 18:37:24.581: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:37:24.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-wfwqx" for this suite.
Feb 20 18:37:46.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:37:47.746: INFO: namespace: e2e-tests-container-lifecycle-hook-wfwqx, resource: bindings, ignored listing per whitelist
Feb 20 18:37:48.420: INFO: namespace e2e-tests-container-lifecycle-hook-wfwqx deletion completed in 23.794316087s

• [SLOW TEST:56.137 seconds]
[k8s.io] Container Lifecycle Hook
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:37:48.420: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-z566t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 18:37:50.383: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Feb 20 18:37:50.467: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-z566t/daemonsets","resourceVersion":"7272"},"items":null}

Feb 20 18:37:50.509: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-z566t/pods","resourceVersion":"7272"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:37:50.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-z566t" for this suite.
Feb 20 18:37:56.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:37:57.437: INFO: namespace: e2e-tests-daemonsets-z566t, resource: bindings, ignored listing per whitelist
Feb 20 18:37:58.447: INFO: namespace e2e-tests-daemonsets-z566t deletion completed in 7.768624278s

S [SKIPPING] [10.026 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Feb 20 18:37:50.383: Requires at least 2 nodes (not -1)

  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:37:58.447: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-mt8xn
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-a623c70c-353e-11e9-997a-8a6f774fb32b
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:38:02.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mt8xn" for this suite.
Feb 20 18:38:24.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:38:26.360: INFO: namespace: e2e-tests-configmap-mt8xn, resource: bindings, ignored listing per whitelist
Feb 20 18:38:26.443: INFO: namespace e2e-tests-configmap-mt8xn deletion completed in 23.779088783s

• [SLOW TEST:27.996 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:38:26.443: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-t9gpx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 20 18:38:28.213: INFO: Waiting up to 5m0s for pod "pod-b6be8f43-353e-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-emptydir-t9gpx" to be "success or failure"
Feb 20 18:38:28.255: INFO: Pod "pod-b6be8f43-353e-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.734435ms
Feb 20 18:38:30.297: INFO: Pod "pod-b6be8f43-353e-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084074314s
Feb 20 18:38:32.341: INFO: Pod "pod-b6be8f43-353e-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.127990646s
STEP: Saw pod success
Feb 20 18:38:32.341: INFO: Pod "pod-b6be8f43-353e-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:38:32.383: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-b6be8f43-353e-11e9-997a-8a6f774fb32b container test-container: <nil>
STEP: delete the pod
Feb 20 18:38:32.492: INFO: Waiting for pod pod-b6be8f43-353e-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:38:32.537: INFO: Pod pod-b6be8f43-353e-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:38:32.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-t9gpx" for this suite.
Feb 20 18:38:38.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:38:39.963: INFO: namespace: e2e-tests-emptydir-t9gpx, resource: bindings, ignored listing per whitelist
Feb 20 18:38:40.300: INFO: namespace e2e-tests-emptydir-t9gpx deletion completed in 7.721083773s

• [SLOW TEST:13.857 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:38:40.301: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-sl4jj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-sl4jj
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Feb 20 18:38:42.107: INFO: Found 1 stateful pods, waiting for 3
Feb 20 18:38:52.151: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 18:38:52.151: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 18:38:52.151: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 20 18:38:52.371: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb 20 18:38:52.551: INFO: Updating stateful set ss2
Feb 20 18:38:52.635: INFO: Waiting for Pod e2e-tests-statefulset-sl4jj/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Feb 20 18:39:02.853: INFO: Found 2 stateful pods, waiting for 3
Feb 20 18:39:12.896: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 18:39:12.896: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 18:39:12.896: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb 20 18:39:13.078: INFO: Updating stateful set ss2
Feb 20 18:39:13.167: INFO: Waiting for Pod e2e-tests-statefulset-sl4jj/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 20 18:39:23.252: INFO: Waiting for Pod e2e-tests-statefulset-sl4jj/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 20 18:39:33.357: INFO: Updating stateful set ss2
Feb 20 18:39:33.446: INFO: Waiting for StatefulSet e2e-tests-statefulset-sl4jj/ss2 to complete update
Feb 20 18:39:33.446: INFO: Waiting for Pod e2e-tests-statefulset-sl4jj/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 20 18:39:43.531: INFO: Deleting all statefulset in ns e2e-tests-statefulset-sl4jj
Feb 20 18:39:43.573: INFO: Scaling statefulset ss2 to 0
Feb 20 18:40:13.745: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 18:40:13.787: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:40:13.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-sl4jj" for this suite.
Feb 20 18:40:20.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:40:21.512: INFO: namespace: e2e-tests-statefulset-sl4jj, resource: bindings, ignored listing per whitelist
Feb 20 18:40:21.720: INFO: namespace e2e-tests-statefulset-sl4jj deletion completed in 7.764716579s

• [SLOW TEST:101.419 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:40:21.720: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-vm22d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Feb 20 18:40:23.472: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/_output/bin/kubectl kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml proxy --unix-socket=/tmp/kubectl-proxy-unix775391652/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:40:23.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vm22d" for this suite.
Feb 20 18:40:29.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:40:30.665: INFO: namespace: e2e-tests-kubectl-vm22d, resource: bindings, ignored listing per whitelist
Feb 20 18:40:31.349: INFO: namespace e2e-tests-kubectl-vm22d deletion completed in 7.730201194s

• [SLOW TEST:9.629 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:40:31.349: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-dd5v4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 18:40:33.204: INFO: Waiting up to 5m0s for pod "downwardapi-volume-013ea83a-353f-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-downward-api-dd5v4" to be "success or failure"
Feb 20 18:40:33.246: INFO: Pod "downwardapi-volume-013ea83a-353f-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 42.270178ms
Feb 20 18:40:35.289: INFO: Pod "downwardapi-volume-013ea83a-353f-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084690352s
STEP: Saw pod success
Feb 20 18:40:35.289: INFO: Pod "downwardapi-volume-013ea83a-353f-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:40:35.330: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod downwardapi-volume-013ea83a-353f-11e9-997a-8a6f774fb32b container client-container: <nil>
STEP: delete the pod
Feb 20 18:40:35.423: INFO: Waiting for pod downwardapi-volume-013ea83a-353f-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:40:35.464: INFO: Pod downwardapi-volume-013ea83a-353f-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:40:35.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dd5v4" for this suite.
Feb 20 18:40:41.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:40:43.153: INFO: namespace: e2e-tests-downward-api-dd5v4, resource: bindings, ignored listing per whitelist
Feb 20 18:40:43.238: INFO: namespace e2e-tests-downward-api-dd5v4 deletion completed in 7.731941102s

• [SLOW TEST:11.889 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:40:43.238: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-dmzvv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-dmzvv
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-dmzvv
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-dmzvv
Feb 20 18:40:45.240: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Feb 20 18:40:55.284: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb 20 18:40:55.326: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 20 18:40:56.312: INFO: stderr: ""
Feb 20 18:40:56.312: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 20 18:40:56.312: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 20 18:40:56.354: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 20 18:41:06.397: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 20 18:41:06.397: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 18:41:06.566: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999329s
Feb 20 18:41:07.609: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.957684193s
Feb 20 18:41:08.652: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.915026645s
Feb 20 18:41:09.696: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.871869608s
Feb 20 18:41:10.739: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.827587867s
Feb 20 18:41:11.782: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.7848138s
Feb 20 18:41:12.825: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.741923895s
Feb 20 18:41:13.871: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.698998212s
Feb 20 18:41:14.918: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.651465073s
Feb 20 18:41:15.960: INFO: Verifying statefulset ss doesn't scale past 1 for another 606.296285ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-dmzvv
Feb 20 18:41:17.007: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:41:17.890: INFO: stderr: ""
Feb 20 18:41:17.890: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 20 18:41:17.890: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 20 18:41:17.932: INFO: Found 1 stateful pods, waiting for 3
Feb 20 18:41:27.985: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 18:41:27.985: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 18:41:27.985: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb 20 18:41:28.069: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 20 18:41:28.950: INFO: stderr: ""
Feb 20 18:41:28.950: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 20 18:41:28.950: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 20 18:41:28.950: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 20 18:41:29.860: INFO: stderr: ""
Feb 20 18:41:29.860: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 20 18:41:29.860: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 20 18:41:29.860: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 20 18:41:30.722: INFO: stderr: ""
Feb 20 18:41:30.722: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 20 18:41:30.722: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 20 18:41:30.722: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 18:41:30.767: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Feb 20 18:41:40.852: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 20 18:41:40.852: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 20 18:41:40.852: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 20 18:41:40.978: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999529s
Feb 20 18:41:42.021: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.958013555s
Feb 20 18:41:43.064: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.915424641s
Feb 20 18:41:44.109: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.870491897s
Feb 20 18:41:45.154: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.827427755s
Feb 20 18:41:46.198: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.781421877s
Feb 20 18:41:47.242: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.737228826s
Feb 20 18:41:48.287: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.693807005s
Feb 20 18:41:49.330: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.648906865s
Feb 20 18:41:50.373: INFO: Verifying statefulset ss doesn't scale past 3 for another 605.82099ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-dmzvv
Feb 20 18:41:51.416: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:41:52.288: INFO: stderr: ""
Feb 20 18:41:52.288: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 20 18:41:52.288: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 20 18:41:52.288: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:41:53.153: INFO: stderr: ""
Feb 20 18:41:53.153: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 20 18:41:53.153: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 20 18:41:53.153: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:41:53.728: INFO: rc: 1
Feb 20 18:41:53.728: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc001123980 exit status 1 <nil> <nil> true [0xc0021502d0 0xc0021502e8 0xc002150308] [0xc0021502d0 0xc0021502e8 0xc002150308] [0xc0021502e0 0xc0021502f8] [0x932420 0x932420] 0xc001c84900 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Feb 20 18:42:03.728: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:42:04.003: INFO: rc: 1
Feb 20 18:42:04.003: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0017244b0 exit status 1 <nil> <nil> true [0xc001cbc000 0xc001cbc030 0xc001cbc078] [0xc001cbc000 0xc001cbc030 0xc001cbc078] [0xc001cbc020 0xc001cbc068] [0x932420 0x932420] 0xc001f0c3c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:42:14.003: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:42:14.294: INFO: rc: 1
Feb 20 18:42:14.295: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001123c80 exit status 1 <nil> <nil> true [0xc002150310 0xc002150328 0xc002150340] [0xc002150310 0xc002150328 0xc002150340] [0xc002150320 0xc002150338] [0x932420 0x932420] 0xc001c84d20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:42:24.295: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:42:24.540: INFO: rc: 1
Feb 20 18:42:24.540: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001724750 exit status 1 <nil> <nil> true [0xc001cbc0a8 0xc001cbc0f0 0xc001cbc128] [0xc001cbc0a8 0xc001cbc0f0 0xc001cbc128] [0xc001cbc0d8 0xc001cbc118] [0x932420 0x932420] 0xc001f0c7e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:42:34.540: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:42:34.787: INFO: rc: 1
Feb 20 18:42:34.787: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00033af90 exit status 1 <nil> <nil> true [0xc0024a6390 0xc0024a63d0 0xc0024a6400] [0xc0024a6390 0xc0024a63d0 0xc0024a6400] [0xc0024a63c8 0xc0024a63f8] [0x932420 0x932420] 0xc001003260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:42:44.788: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:42:45.106: INFO: rc: 1
Feb 20 18:42:45.106: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00033b3e0 exit status 1 <nil> <nil> true [0xc0024a6418 0xc0024a6440 0xc0024a6490] [0xc0024a6418 0xc0024a6440 0xc0024a6490] [0xc0024a6428 0xc0024a6478] [0x932420 0x932420] 0xc0010036e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:42:55.106: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:42:55.349: INFO: rc: 1
Feb 20 18:42:55.349: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00033b770 exit status 1 <nil> <nil> true [0xc0024a64a8 0xc0024a64c0 0xc0024a64d8] [0xc0024a64a8 0xc0024a64c0 0xc0024a64d8] [0xc0024a64b8 0xc0024a64d0] [0x932420 0x932420] 0xc001003b00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:43:05.349: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:43:05.659: INFO: rc: 1
Feb 20 18:43:05.659: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00033ba70 exit status 1 <nil> <nil> true [0xc0024a64e0 0xc0024a6518 0xc0024a6530] [0xc0024a64e0 0xc0024a6518 0xc0024a6530] [0xc0024a6500 0xc0024a6528] [0x932420 0x932420] 0xc001003e00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:43:15.659: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:43:15.964: INFO: rc: 1
Feb 20 18:43:15.964: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0019420c0 exit status 1 <nil> <nil> true [0xc00000f510 0xc00000f568 0xc00000f638] [0xc00000f510 0xc00000f568 0xc00000f638] [0xc00000f560 0xc00000f5b8] [0x932420 0x932420] 0xc00126b740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:43:25.964: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:43:26.211: INFO: rc: 1
Feb 20 18:43:26.211: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00033bd10 exit status 1 <nil> <nil> true [0xc0024a6538 0xc0024a6550 0xc0024a6568] [0xc0024a6538 0xc0024a6550 0xc0024a6568] [0xc0024a6548 0xc0024a6560] [0x932420 0x932420] 0xc0012a6fc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:43:36.212: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:43:36.541: INFO: rc: 1
Feb 20 18:43:36.541: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0024362a0 exit status 1 <nil> <nil> true [0xc001cbc010 0xc001cbc048 0xc001cbc0a8] [0xc001cbc010 0xc001cbc048 0xc001cbc0a8] [0xc001cbc030 0xc001cbc078] [0x932420 0x932420] 0xc001002000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:43:46.541: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:43:46.798: INFO: rc: 1
Feb 20 18:43:46.798: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002538300 exit status 1 <nil> <nil> true [0xc00000e048 0xc00000e5c8 0xc00000e9b0] [0xc00000e048 0xc00000e5c8 0xc00000e9b0] [0xc00000e550 0xc00000e988] [0x932420 0x932420] 0xc000c1c540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:43:56.798: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:43:57.116: INFO: rc: 1
Feb 20 18:43:57.116: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002436540 exit status 1 <nil> <nil> true [0xc001cbc0c8 0xc001cbc100 0xc001cbc148] [0xc001cbc0c8 0xc001cbc100 0xc001cbc148] [0xc001cbc0f0 0xc001cbc128] [0x932420 0x932420] 0xc001002300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:44:07.116: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:44:07.384: INFO: rc: 1
Feb 20 18:44:07.385: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00201c270 exit status 1 <nil> <nil> true [0xc0024a6010 0xc0024a60b0 0xc0024a60d0] [0xc0024a6010 0xc0024a60b0 0xc0024a60d0] [0xc0024a6098 0xc0024a60c8] [0x932420 0x932420] 0xc0025c3020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:44:17.385: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:44:17.639: INFO: rc: 1
Feb 20 18:44:17.639: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00143e2d0 exit status 1 <nil> <nil> true [0xc002150018 0xc0021500c0 0xc0021500e8] [0xc002150018 0xc0021500c0 0xc0021500e8] [0xc0021500a0 0xc0021500e0] [0x932420 0x932420] 0xc001f0c3c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:44:27.639: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:44:27.882: INFO: rc: 1
Feb 20 18:44:27.882: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00143e570 exit status 1 <nil> <nil> true [0xc0021500f0 0xc002150108 0xc002150130] [0xc0021500f0 0xc002150108 0xc002150130] [0xc002150100 0xc002150120] [0x932420 0x932420] 0xc001f0c7e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:44:37.882: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:44:38.156: INFO: rc: 1
Feb 20 18:44:38.156: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00143e7e0 exit status 1 <nil> <nil> true [0xc002150148 0xc002150160 0xc0021501b0] [0xc002150148 0xc002150160 0xc0021501b0] [0xc002150158 0xc002150198] [0x932420 0x932420] 0xc001f0cc60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:44:48.157: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:44:48.435: INFO: rc: 1
Feb 20 18:44:48.435: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00201c5a0 exit status 1 <nil> <nil> true [0xc0024a60d8 0xc0024a60f0 0xc0024a6128] [0xc0024a60d8 0xc0024a60f0 0xc0024a6128] [0xc0024a60e8 0xc0024a6110] [0x932420 0x932420] 0xc0025c3320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:44:58.436: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:44:58.678: INFO: rc: 1
Feb 20 18:44:58.678: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0024367e0 exit status 1 <nil> <nil> true [0xc001cbc158 0xc001cbc198 0xc001cbc210] [0xc001cbc158 0xc001cbc198 0xc001cbc210] [0xc001cbc180 0xc001cbc1e0] [0x932420 0x932420] 0xc0010028a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:45:08.678: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:45:08.980: INFO: rc: 1
Feb 20 18:45:08.980: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00201c870 exit status 1 <nil> <nil> true [0xc0024a6130 0xc0024a6148 0xc0024a6180] [0xc0024a6130 0xc0024a6148 0xc0024a6180] [0xc0024a6140 0xc0024a6178] [0x932420 0x932420] 0xc0025c36e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:45:18.980: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:45:19.229: INFO: rc: 1
Feb 20 18:45:19.229: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0025385a0 exit status 1 <nil> <nil> true [0xc00000ea98 0xc00000f058 0xc00000f150] [0xc00000ea98 0xc00000f058 0xc00000f150] [0xc00000ef60 0xc00000f110] [0x932420 0x932420] 0xc000c1daa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:45:29.229: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:45:29.496: INFO: rc: 1
Feb 20 18:45:29.496: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00201cc30 exit status 1 <nil> <nil> true [0xc0024a6188 0xc0024a61a0 0xc0024a61b8] [0xc0024a6188 0xc0024a61a0 0xc0024a61b8] [0xc0024a6198 0xc0024a61b0] [0x932420 0x932420] 0xc0025c39e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:45:39.496: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:45:39.905: INFO: rc: 1
Feb 20 18:45:39.905: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002538330 exit status 1 <nil> <nil> true [0xc00000e4e8 0xc00000e860 0xc00000ea98] [0xc00000e4e8 0xc00000e860 0xc00000ea98] [0xc00000e5c8 0xc00000e9b0] [0x932420 0x932420] 0xc000c1c540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:45:49.906: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:45:50.173: INFO: rc: 1
Feb 20 18:45:50.173: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002538600 exit status 1 <nil> <nil> true [0xc00000ecb8 0xc00000f0a8 0xc00000f210] [0xc00000ecb8 0xc00000f0a8 0xc00000f210] [0xc00000f058 0xc00000f150] [0x932420 0x932420] 0xc000c1daa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:46:00.173: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:46:00.427: INFO: rc: 1
Feb 20 18:46:00.427: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00201c2a0 exit status 1 <nil> <nil> true [0xc0024a6010 0xc0024a60b0 0xc0024a60d0] [0xc0024a6010 0xc0024a60b0 0xc0024a60d0] [0xc0024a6098 0xc0024a60c8] [0x932420 0x932420] 0xc0025c23c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:46:10.427: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:46:10.725: INFO: rc: 1
Feb 20 18:46:10.725: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00143e300 exit status 1 <nil> <nil> true [0xc002150018 0xc0021500c0 0xc0021500e8] [0xc002150018 0xc0021500c0 0xc0021500e8] [0xc0021500a0 0xc0021500e0] [0x932420 0x932420] 0xc001f0c3c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:46:20.725: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:46:21.139: INFO: rc: 1
Feb 20 18:46:21.139: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00143e5d0 exit status 1 <nil> <nil> true [0xc0021500f0 0xc002150108 0xc002150130] [0xc0021500f0 0xc002150108 0xc002150130] [0xc002150100 0xc002150120] [0x932420 0x932420] 0xc001f0c7e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:46:31.139: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:46:31.443: INFO: rc: 1
Feb 20 18:46:31.443: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0025388a0 exit status 1 <nil> <nil> true [0xc00000f228 0xc00000f2e8 0xc00000f478] [0xc00000f228 0xc00000f2e8 0xc00000f478] [0xc00000f2c0 0xc00000f428] [0x932420 0x932420] 0xc001002240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:46:41.444: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:46:41.768: INFO: rc: 1
Feb 20 18:46:41.768: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00201c540 exit status 1 <nil> <nil> true [0xc0024a60d8 0xc0024a60f0 0xc0024a6128] [0xc0024a60d8 0xc0024a60f0 0xc0024a6128] [0xc0024a60e8 0xc0024a6110] [0x932420 0x932420] 0xc0025c30e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:46:51.769: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:46:52.024: INFO: rc: 1
Feb 20 18:46:52.024: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00201c810 exit status 1 <nil> <nil> true [0xc0024a6130 0xc0024a6148 0xc0024a6180] [0xc0024a6130 0xc0024a6148 0xc0024a6180] [0xc0024a6140 0xc0024a6178] [0x932420 0x932420] 0xc0025c33e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 20 18:47:02.024: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-dmzvv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 18:47:02.315: INFO: rc: 1
Feb 20 18:47:02.316: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Feb 20 18:47:02.316: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 20 18:47:02.442: INFO: Deleting all statefulset in ns e2e-tests-statefulset-dmzvv
Feb 20 18:47:02.485: INFO: Scaling statefulset ss to 0
Feb 20 18:47:02.610: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 18:47:02.652: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:47:02.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-dmzvv" for this suite.
Feb 20 18:47:08.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:47:10.167: INFO: namespace: e2e-tests-statefulset-dmzvv, resource: bindings, ignored listing per whitelist
Feb 20 18:47:10.550: INFO: namespace e2e-tests-statefulset-dmzvv deletion completed in 7.728753652s

• [SLOW TEST:387.312 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:47:10.550: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-kdc5c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Feb 20 18:47:12.323: INFO: Waiting up to 5m0s for pod "client-containers-ef235489-353f-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-containers-kdc5c" to be "success or failure"
Feb 20 18:47:12.365: INFO: Pod "client-containers-ef235489-353f-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.879162ms
Feb 20 18:47:14.409: INFO: Pod "client-containers-ef235489-353f-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085903343s
STEP: Saw pod success
Feb 20 18:47:14.409: INFO: Pod "client-containers-ef235489-353f-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:47:14.450: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod client-containers-ef235489-353f-11e9-997a-8a6f774fb32b container test-container: <nil>
STEP: delete the pod
Feb 20 18:47:14.560: INFO: Waiting for pod client-containers-ef235489-353f-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:47:14.611: INFO: Pod client-containers-ef235489-353f-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:47:14.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-kdc5c" for this suite.
Feb 20 18:47:20.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:47:22.286: INFO: namespace: e2e-tests-containers-kdc5c, resource: bindings, ignored listing per whitelist
Feb 20 18:47:22.370: INFO: namespace e2e-tests-containers-kdc5c deletion completed in 7.715356216s

• [SLOW TEST:11.819 seconds]
[k8s.io] Docker Containers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:47:22.370: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8tgfh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-f62bf1fd-353f-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume secrets
Feb 20 18:47:24.168: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f632c009-353f-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-projected-8tgfh" to be "success or failure"
Feb 20 18:47:24.210: INFO: Pod "pod-projected-secrets-f632c009-353f-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.791245ms
Feb 20 18:47:26.252: INFO: Pod "pod-projected-secrets-f632c009-353f-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084294163s
STEP: Saw pod success
Feb 20 18:47:26.252: INFO: Pod "pod-projected-secrets-f632c009-353f-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:47:26.294: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-projected-secrets-f632c009-353f-11e9-997a-8a6f774fb32b container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 20 18:47:26.386: INFO: Waiting for pod pod-projected-secrets-f632c009-353f-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:47:26.427: INFO: Pod pod-projected-secrets-f632c009-353f-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:47:26.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8tgfh" for this suite.
Feb 20 18:47:32.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:47:33.361: INFO: namespace: e2e-tests-projected-8tgfh, resource: bindings, ignored listing per whitelist
Feb 20 18:47:34.201: INFO: namespace e2e-tests-projected-8tgfh deletion completed in 7.730584192s

• [SLOW TEST:11.831 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:47:34.201: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-bvwnk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 20 18:47:36.009: INFO: Waiting up to 5m0s for pod "pod-fd41b4b5-353f-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-emptydir-bvwnk" to be "success or failure"
Feb 20 18:47:36.052: INFO: Pod "pod-fd41b4b5-353f-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 42.094027ms
Feb 20 18:47:38.093: INFO: Pod "pod-fd41b4b5-353f-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084013749s
STEP: Saw pod success
Feb 20 18:47:38.094: INFO: Pod "pod-fd41b4b5-353f-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:47:38.137: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-fd41b4b5-353f-11e9-997a-8a6f774fb32b container test-container: <nil>
STEP: delete the pod
Feb 20 18:47:38.237: INFO: Waiting for pod pod-fd41b4b5-353f-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:47:38.280: INFO: Pod pod-fd41b4b5-353f-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:47:38.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bvwnk" for this suite.
Feb 20 18:47:44.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:47:45.209: INFO: namespace: e2e-tests-emptydir-bvwnk, resource: bindings, ignored listing per whitelist
Feb 20 18:47:46.105: INFO: namespace e2e-tests-emptydir-bvwnk deletion completed in 7.78232027s

• [SLOW TEST:11.904 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:47:46.105: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-zjp9t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-04619fcc-3540-11e9-997a-8a6f774fb32b
STEP: Creating configMap with name cm-test-opt-upd-0461a017-3540-11e9-997a-8a6f774fb32b
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-04619fcc-3540-11e9-997a-8a6f774fb32b
STEP: Updating configmap cm-test-opt-upd-0461a017-3540-11e9-997a-8a6f774fb32b
STEP: Creating configMap with name cm-test-opt-create-0461a037-3540-11e9-997a-8a6f774fb32b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:47:54.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zjp9t" for this suite.
Feb 20 18:48:16.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:48:18.095: INFO: namespace: e2e-tests-projected-zjp9t, resource: bindings, ignored listing per whitelist
Feb 20 18:48:18.525: INFO: namespace e2e-tests-projected-zjp9t deletion completed in 23.754812327s

• [SLOW TEST:32.420 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:48:18.526: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-k9wdm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 20 18:48:20.347: INFO: Waiting up to 5m0s for pod "pod-17aebfb5-3540-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-emptydir-k9wdm" to be "success or failure"
Feb 20 18:48:20.391: INFO: Pod "pod-17aebfb5-3540-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 43.123216ms
Feb 20 18:48:22.434: INFO: Pod "pod-17aebfb5-3540-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.08678159s
STEP: Saw pod success
Feb 20 18:48:22.434: INFO: Pod "pod-17aebfb5-3540-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:48:22.476: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-17aebfb5-3540-11e9-997a-8a6f774fb32b container test-container: <nil>
STEP: delete the pod
Feb 20 18:48:22.569: INFO: Waiting for pod pod-17aebfb5-3540-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:48:22.611: INFO: Pod pod-17aebfb5-3540-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:48:22.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-k9wdm" for this suite.
Feb 20 18:48:28.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:48:29.345: INFO: namespace: e2e-tests-emptydir-k9wdm, resource: bindings, ignored listing per whitelist
Feb 20 18:48:30.471: INFO: namespace e2e-tests-emptydir-k9wdm deletion completed in 7.817774664s

• [SLOW TEST:11.946 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:48:30.472: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-j6vwj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 18:48:32.182: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb 20 18:48:32.265: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 20 18:48:34.349: INFO: Creating deployment "test-rolling-update-deployment"
Feb 20 18:48:34.391: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb 20 18:48:34.475: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb 20 18:48:34.517: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686285314, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686285314, loc:(*time.Location)(0x78fbda0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686285314, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686285314, loc:(*time.Location)(0x78fbda0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 18:48:36.559: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686285314, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686285314, loc:(*time.Location)(0x78fbda0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686285314, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686285314, loc:(*time.Location)(0x78fbda0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 18:48:38.559: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 20 18:48:38.693: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-j6vwj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j6vwj/deployments/test-rolling-update-deployment,UID:20109510-3540-11e9-936d-1e925ead141b,ResourceVersion:8932,Generation:1,CreationTimestamp:2019-02-20 18:48:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-20 18:48:34 +0000 UTC 2019-02-20 18:48:34 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-20 18:48:37 +0000 UTC 2019-02-20 18:48:34 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 20 18:48:38.741: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-j6vwj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j6vwj/replicasets/test-rolling-update-deployment-65b7695dcf,UID:20120ae7-3540-11e9-936d-1e925ead141b,ResourceVersion:8925,Generation:1,CreationTimestamp:2019-02-20 18:48:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 20109510-3540-11e9-936d-1e925ead141b 0xc001e81887 0xc001e81888}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 20 18:48:38.741: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb 20 18:48:38.741: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-j6vwj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j6vwj/replicasets/test-rolling-update-controller,UID:1ec5d509-3540-11e9-936d-1e925ead141b,ResourceVersion:8931,Generation:2,CreationTimestamp:2019-02-20 18:48:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 20109510-3540-11e9-936d-1e925ead141b 0xc001e817bf 0xc001e817d0}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 20 18:48:38.798: INFO: Pod "test-rolling-update-deployment-65b7695dcf-cngph" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-cngph,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-j6vwj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j6vwj/pods/test-rolling-update-deployment-65b7695dcf-cngph,UID:201259a3-3540-11e9-936d-1e925ead141b,ResourceVersion:8924,Generation:0,CreationTimestamp:2019-02-20 18:48:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.87/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf 20120ae7-3540-11e9-936d-1e925ead141b 0xc001e98597 0xc001e98598}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kxgdq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kxgdq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-kxgdq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-15.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e98600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e98620}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:48:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:48:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:48:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:48:34 +0000 UTC  }],Message:,Reason:,HostIP:10.250.8.15,PodIP:100.96.1.87,StartTime:2019-02-20 18:48:34 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-20 18:48:37 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://666372a76aeaf81d1360fafda2e7bc29a176331d35f0c5b8de02425815a5d269}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:48:38.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-j6vwj" for this suite.
Feb 20 18:48:44.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:48:46.539: INFO: namespace: e2e-tests-deployment-j6vwj, resource: bindings, ignored listing per whitelist
Feb 20 18:48:46.581: INFO: namespace e2e-tests-deployment-j6vwj deletion completed in 7.738836353s

• [SLOW TEST:16.109 seconds]
[sig-apps] Deployment
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:48:46.581: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-pvrvx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:49:48.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-pvrvx" for this suite.
Feb 20 18:50:10.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:50:10.799: INFO: namespace: e2e-tests-container-probe-pvrvx, resource: bindings, ignored listing per whitelist
Feb 20 18:50:12.245: INFO: namespace e2e-tests-container-probe-pvrvx deletion completed in 23.739444654s

• [SLOW TEST:85.664 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:50:12.246: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-kk7rh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 18:50:14.121: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5b7f6ade-3540-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-downward-api-kk7rh" to be "success or failure"
Feb 20 18:50:14.163: INFO: Pod "downwardapi-volume-5b7f6ade-3540-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 42.471791ms
Feb 20 18:50:16.206: INFO: Pod "downwardapi-volume-5b7f6ade-3540-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085201773s
STEP: Saw pod success
Feb 20 18:50:16.206: INFO: Pod "downwardapi-volume-5b7f6ade-3540-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:50:16.248: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod downwardapi-volume-5b7f6ade-3540-11e9-997a-8a6f774fb32b container client-container: <nil>
STEP: delete the pod
Feb 20 18:50:16.346: INFO: Waiting for pod downwardapi-volume-5b7f6ade-3540-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:50:16.389: INFO: Pod downwardapi-volume-5b7f6ade-3540-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:50:16.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kk7rh" for this suite.
Feb 20 18:50:22.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:50:23.528: INFO: namespace: e2e-tests-downward-api-kk7rh, resource: bindings, ignored listing per whitelist
Feb 20 18:50:24.170: INFO: namespace e2e-tests-downward-api-kk7rh deletion completed in 7.738046439s

• [SLOW TEST:11.925 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:50:24.171: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-cv4p7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 18:50:28.126: INFO: Waiting up to 5m0s for pod "client-envvars-63d8ddb8-3540-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-pods-cv4p7" to be "success or failure"
Feb 20 18:50:28.173: INFO: Pod "client-envvars-63d8ddb8-3540-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 46.129214ms
Feb 20 18:50:30.216: INFO: Pod "client-envvars-63d8ddb8-3540-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.089142285s
STEP: Saw pod success
Feb 20 18:50:30.216: INFO: Pod "client-envvars-63d8ddb8-3540-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:50:30.257: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod client-envvars-63d8ddb8-3540-11e9-997a-8a6f774fb32b container env3cont: <nil>
STEP: delete the pod
Feb 20 18:50:30.351: INFO: Waiting for pod client-envvars-63d8ddb8-3540-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:50:30.393: INFO: Pod client-envvars-63d8ddb8-3540-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:50:30.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-cv4p7" for this suite.
Feb 20 18:51:16.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:51:17.973: INFO: namespace: e2e-tests-pods-cv4p7, resource: bindings, ignored listing per whitelist
Feb 20 18:51:18.186: INFO: namespace e2e-tests-pods-cv4p7 deletion completed in 47.751409662s

• [SLOW TEST:54.016 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:51:18.187: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-lncmw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Feb 20 18:51:20.110: INFO: Waiting up to 5m0s for pod "var-expansion-82d49303-3540-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-var-expansion-lncmw" to be "success or failure"
Feb 20 18:51:20.164: INFO: Pod "var-expansion-82d49303-3540-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 53.48869ms
Feb 20 18:51:22.206: INFO: Pod "var-expansion-82d49303-3540-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.095903457s
STEP: Saw pod success
Feb 20 18:51:22.206: INFO: Pod "var-expansion-82d49303-3540-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:51:22.250: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod var-expansion-82d49303-3540-11e9-997a-8a6f774fb32b container dapi-container: <nil>
STEP: delete the pod
Feb 20 18:51:22.345: INFO: Waiting for pod var-expansion-82d49303-3540-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:51:22.386: INFO: Pod var-expansion-82d49303-3540-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:51:22.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-lncmw" for this suite.
Feb 20 18:51:28.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:51:29.910: INFO: namespace: e2e-tests-var-expansion-lncmw, resource: bindings, ignored listing per whitelist
Feb 20 18:51:30.203: INFO: namespace e2e-tests-var-expansion-lncmw deletion completed in 7.774475671s

• [SLOW TEST:12.016 seconds]
[k8s.io] Variable Expansion
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:51:30.203: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-9jtmm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-89e01a4d-3540-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume secrets
Feb 20 18:51:31.973: INFO: Waiting up to 5m0s for pod "pod-secrets-89e67c6a-3540-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-secrets-9jtmm" to be "success or failure"
Feb 20 18:51:32.015: INFO: Pod "pod-secrets-89e67c6a-3540-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.647906ms
Feb 20 18:51:34.059: INFO: Pod "pod-secrets-89e67c6a-3540-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085300429s
STEP: Saw pod success
Feb 20 18:51:34.059: INFO: Pod "pod-secrets-89e67c6a-3540-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:51:34.101: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-secrets-89e67c6a-3540-11e9-997a-8a6f774fb32b container secret-volume-test: <nil>
STEP: delete the pod
Feb 20 18:51:34.193: INFO: Waiting for pod pod-secrets-89e67c6a-3540-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:51:34.234: INFO: Pod pod-secrets-89e67c6a-3540-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:51:34.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9jtmm" for this suite.
Feb 20 18:51:40.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:51:41.537: INFO: namespace: e2e-tests-secrets-9jtmm, resource: bindings, ignored listing per whitelist
Feb 20 18:51:42.007: INFO: namespace e2e-tests-secrets-9jtmm deletion completed in 7.730121982s

• [SLOW TEST:11.804 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:51:42.007: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-kw54d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 20 18:51:43.867: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-kw54d'
Feb 20 18:51:46.421: INFO: stderr: ""
Feb 20 18:51:46.421: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb 20 18:51:51.471: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-kw54d -o json'
Feb 20 18:51:51.845: INFO: stderr: ""
Feb 20 18:51:51.845: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"100.96.1.94/32\",\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-02-20T18:51:46Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-kw54d\",\n        \"resourceVersion\": \"9421\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-kw54d/pods/e2e-test-nginx-pod\",\n        \"uid\": \"9284443c-3540-11e9-936d-1e925ead141b\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-f2vk6\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"ip-10-250-8-15.eu-west-1.compute.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-f2vk6\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-f2vk6\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-20T18:51:46Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-20T18:51:47Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-20T18:51:47Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-20T18:51:46Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://9fe638b0a5f0ed8bfd157940bc234d7323e4ba89b9f305bcba3d6b93f20a6102\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-02-20T18:51:47Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.250.8.15\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.96.1.94\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-02-20T18:51:46Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb 20 18:51:51.845: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml replace -f - --namespace=e2e-tests-kubectl-kw54d'
Feb 20 18:51:52.465: INFO: stderr: ""
Feb 20 18:51:52.465: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Feb 20 18:51:52.506: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-kw54d'
Feb 20 18:52:04.235: INFO: stderr: ""
Feb 20 18:52:04.235: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:52:04.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kw54d" for this suite.
Feb 20 18:52:10.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:52:11.709: INFO: namespace: e2e-tests-kubectl-kw54d, resource: bindings, ignored listing per whitelist
Feb 20 18:52:12.011: INFO: namespace e2e-tests-kubectl-kw54d deletion completed in 7.732862928s

• [SLOW TEST:30.004 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:52:12.011: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-rlk2l
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 20 18:52:13.828: INFO: Waiting up to 5m0s for pod "downward-api-a2d7ab52-3540-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-downward-api-rlk2l" to be "success or failure"
Feb 20 18:52:13.871: INFO: Pod "downward-api-a2d7ab52-3540-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 42.54972ms
Feb 20 18:52:15.915: INFO: Pod "downward-api-a2d7ab52-3540-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.086204187s
STEP: Saw pod success
Feb 20 18:52:15.915: INFO: Pod "downward-api-a2d7ab52-3540-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:52:15.957: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod downward-api-a2d7ab52-3540-11e9-997a-8a6f774fb32b container dapi-container: <nil>
STEP: delete the pod
Feb 20 18:52:16.053: INFO: Waiting for pod downward-api-a2d7ab52-3540-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:52:16.094: INFO: Pod downward-api-a2d7ab52-3540-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:52:16.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rlk2l" for this suite.
Feb 20 18:52:22.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:52:23.613: INFO: namespace: e2e-tests-downward-api-rlk2l, resource: bindings, ignored listing per whitelist
Feb 20 18:52:23.913: INFO: namespace e2e-tests-downward-api-rlk2l deletion completed in 7.775150132s

• [SLOW TEST:11.902 seconds]
[sig-api-machinery] Downward API
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:52:23.913: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-2gpnj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 20 18:52:25.688: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-2gpnj'
Feb 20 18:52:26.094: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 20 18:52:26.094: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Feb 20 18:52:26.136: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-2gpnj'
Feb 20 18:52:26.560: INFO: stderr: ""
Feb 20 18:52:26.560: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:52:26.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2gpnj" for this suite.
Feb 20 18:52:32.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:52:34.303: INFO: namespace: e2e-tests-kubectl-2gpnj, resource: bindings, ignored listing per whitelist
Feb 20 18:52:34.345: INFO: namespace e2e-tests-kubectl-2gpnj deletion completed in 7.743022542s

• [SLOW TEST:10.432 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:52:34.345: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-vqf5j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 18:52:36.253: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"b0331f74-3540-11e9-936d-1e925ead141b", Controller:(*bool)(0xc0019b304e), BlockOwnerDeletion:(*bool)(0xc0019b304f)}}
Feb 20 18:52:36.297: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"b02577a6-3540-11e9-936d-1e925ead141b", Controller:(*bool)(0xc0025ee396), BlockOwnerDeletion:(*bool)(0xc0025ee397)}}
Feb 20 18:52:36.341: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"b02ca532-3540-11e9-936d-1e925ead141b", Controller:(*bool)(0xc0019b3246), BlockOwnerDeletion:(*bool)(0xc0019b3247)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:52:41.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-vqf5j" for this suite.
Feb 20 18:52:47.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:52:49.069: INFO: namespace: e2e-tests-gc-vqf5j, resource: bindings, ignored listing per whitelist
Feb 20 18:52:49.278: INFO: namespace e2e-tests-gc-vqf5j deletion completed in 7.808491391s

• [SLOW TEST:14.932 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:52:49.278: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-tngjv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-tngjv
Feb 20 18:52:53.293: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-tngjv
STEP: checking the pod's current state and verifying that restartCount is present
Feb 20 18:52:53.339: INFO: Initial restart count of pod liveness-http is 0
Feb 20 18:53:17.895: INFO: Restart count of pod e2e-tests-container-probe-tngjv/liveness-http is now 1 (24.554289806s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:53:17.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-tngjv" for this suite.
Feb 20 18:53:24.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:53:25.629: INFO: namespace: e2e-tests-container-probe-tngjv, resource: bindings, ignored listing per whitelist
Feb 20 18:53:25.756: INFO: namespace e2e-tests-container-probe-tngjv deletion completed in 7.773378345s

• [SLOW TEST:36.478 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:53:25.756: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-dg466
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 20 18:53:27.566: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-dg466'
Feb 20 18:53:27.916: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 20 18:53:27.916: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb 20 18:53:28.000: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-pqzq7]
Feb 20 18:53:28.000: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-pqzq7" in namespace "e2e-tests-kubectl-dg466" to be "running and ready"
Feb 20 18:53:28.042: INFO: Pod "e2e-test-nginx-rc-pqzq7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.898466ms
Feb 20 18:53:30.087: INFO: Pod "e2e-test-nginx-rc-pqzq7": Phase="Running", Reason="", readiness=true. Elapsed: 2.087340025s
Feb 20 18:53:30.087: INFO: Pod "e2e-test-nginx-rc-pqzq7" satisfied condition "running and ready"
Feb 20 18:53:30.087: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-pqzq7]
Feb 20 18:53:30.087: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-dg466'
Feb 20 18:53:30.559: INFO: stderr: ""
Feb 20 18:53:30.559: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Feb 20 18:53:30.560: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-dg466'
Feb 20 18:53:31.058: INFO: stderr: ""
Feb 20 18:53:31.058: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:53:31.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dg466" for this suite.
Feb 20 18:53:53.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:53:54.694: INFO: namespace: e2e-tests-kubectl-dg466, resource: bindings, ignored listing per whitelist
Feb 20 18:53:54.862: INFO: namespace e2e-tests-kubectl-dg466 deletion completed in 23.762082936s

• [SLOW TEST:29.107 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:53:54.863: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-6pp97
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 20 18:54:01.010: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 20 18:54:01.053: INFO: Pod pod-with-poststart-http-hook still exists
Feb 20 18:54:03.053: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 20 18:54:03.096: INFO: Pod pod-with-poststart-http-hook still exists
Feb 20 18:54:05.053: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 20 18:54:05.095: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:54:05.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-6pp97" for this suite.
Feb 20 18:54:27.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:54:27.874: INFO: namespace: e2e-tests-container-lifecycle-hook-6pp97, resource: bindings, ignored listing per whitelist
Feb 20 18:54:28.949: INFO: namespace e2e-tests-container-lifecycle-hook-6pp97 deletion completed in 23.810915514s

• [SLOW TEST:34.086 seconds]
[k8s.io] Container Lifecycle Hook
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:54:28.949: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-sn2zc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 20 18:54:30.715: INFO: Waiting up to 5m0s for pod "pod-f4708f15-3540-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-emptydir-sn2zc" to be "success or failure"
Feb 20 18:54:30.757: INFO: Pod "pod-f4708f15-3540-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 42.050999ms
Feb 20 18:54:32.800: INFO: Pod "pod-f4708f15-3540-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085223084s
STEP: Saw pod success
Feb 20 18:54:32.800: INFO: Pod "pod-f4708f15-3540-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:54:32.844: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-f4708f15-3540-11e9-997a-8a6f774fb32b container test-container: <nil>
STEP: delete the pod
Feb 20 18:54:32.938: INFO: Waiting for pod pod-f4708f15-3540-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:54:32.980: INFO: Pod pod-f4708f15-3540-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:54:32.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-sn2zc" for this suite.
Feb 20 18:54:39.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:54:40.627: INFO: namespace: e2e-tests-emptydir-sn2zc, resource: bindings, ignored listing per whitelist
Feb 20 18:54:40.753: INFO: namespace e2e-tests-emptydir-sn2zc deletion completed in 7.7284075s

• [SLOW TEST:11.804 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:54:40.753: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-ldr2p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 20 18:54:42.572: INFO: Waiting up to 5m0s for pod "downward-api-fb81eda6-3540-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-downward-api-ldr2p" to be "success or failure"
Feb 20 18:54:42.614: INFO: Pod "downward-api-fb81eda6-3540-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.968208ms
Feb 20 18:54:44.657: INFO: Pod "downward-api-fb81eda6-3540-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084203588s
STEP: Saw pod success
Feb 20 18:54:44.657: INFO: Pod "downward-api-fb81eda6-3540-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:54:44.699: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod downward-api-fb81eda6-3540-11e9-997a-8a6f774fb32b container dapi-container: <nil>
STEP: delete the pod
Feb 20 18:54:44.791: INFO: Waiting for pod downward-api-fb81eda6-3540-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:54:44.835: INFO: Pod downward-api-fb81eda6-3540-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:54:44.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ldr2p" for this suite.
Feb 20 18:54:51.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:54:51.800: INFO: namespace: e2e-tests-downward-api-ldr2p, resource: bindings, ignored listing per whitelist
Feb 20 18:54:52.738: INFO: namespace e2e-tests-downward-api-ldr2p deletion completed in 7.842953706s

• [SLOW TEST:11.985 seconds]
[sig-api-machinery] Downward API
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:54:52.738: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-rrfwh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Feb 20 18:54:54.562: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/_output/bin/kubectl kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:54:54.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rrfwh" for this suite.
Feb 20 18:55:01.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:55:01.273: INFO: namespace: e2e-tests-kubectl-rrfwh, resource: bindings, ignored listing per whitelist
Feb 20 18:55:02.697: INFO: namespace e2e-tests-kubectl-rrfwh deletion completed in 7.760229014s

• [SLOW TEST:9.959 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:55:02.697: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-mwtxv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Feb 20 18:55:06.764: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-08951541-3541-11e9-997a-8a6f774fb32b", GenerateName:"", Namespace:"e2e-tests-pods-mwtxv", SelfLink:"/api/v1/namespaces/e2e-tests-pods-mwtxv/pods/pod-submit-remove-08951541-3541-11e9-997a-8a6f774fb32b", UID:"08a48839-3541-11e9-936d-1e925ead141b", ResourceVersion:"10001", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63686285704, loc:(*time.Location)(0x78fbda0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"464523589"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"100.96.1.103/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-9qq7f", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0021c3dc0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-9qq7f", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0025ec0e8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-250-8-15.eu-west-1.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001f566c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0025ec120)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0025ec160)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0025ec168), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686285704, loc:(*time.Location)(0x78fbda0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686285705, loc:(*time.Location)(0x78fbda0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686285705, loc:(*time.Location)(0x78fbda0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686285704, loc:(*time.Location)(0x78fbda0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.8.15", PodIP:"100.96.1.103", StartTime:(*v1.Time)(0xc00227fec0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc00227fee0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632", ContainerID:"docker://62998bd419d718c9d6d9d3b1fd8361782968ec3e78a55054a5a6c321727b5ed1"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:55:14.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-mwtxv" for this suite.
Feb 20 18:55:20.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:55:21.453: INFO: namespace: e2e-tests-pods-mwtxv, resource: bindings, ignored listing per whitelist
Feb 20 18:55:22.104: INFO: namespace e2e-tests-pods-mwtxv deletion completed in 7.784289765s

• [SLOW TEST:19.407 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:55:22.105: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-rl5rf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-9dwd
STEP: Creating a pod to test atomic-volume-subpath
Feb 20 18:55:24.092: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-9dwd" in namespace "e2e-tests-subpath-rl5rf" to be "success or failure"
Feb 20 18:55:24.134: INFO: Pod "pod-subpath-test-configmap-9dwd": Phase="Pending", Reason="", readiness=false. Elapsed: 41.892824ms
Feb 20 18:55:26.177: INFO: Pod "pod-subpath-test-configmap-9dwd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.085572836s
Feb 20 18:55:28.222: INFO: Pod "pod-subpath-test-configmap-9dwd": Phase="Running", Reason="", readiness=false. Elapsed: 4.129831935s
Feb 20 18:55:30.298: INFO: Pod "pod-subpath-test-configmap-9dwd": Phase="Running", Reason="", readiness=false. Elapsed: 6.20600845s
Feb 20 18:55:32.341: INFO: Pod "pod-subpath-test-configmap-9dwd": Phase="Running", Reason="", readiness=false. Elapsed: 8.249555898s
Feb 20 18:55:34.384: INFO: Pod "pod-subpath-test-configmap-9dwd": Phase="Running", Reason="", readiness=false. Elapsed: 10.292003888s
Feb 20 18:55:36.427: INFO: Pod "pod-subpath-test-configmap-9dwd": Phase="Running", Reason="", readiness=false. Elapsed: 12.334680787s
Feb 20 18:55:38.470: INFO: Pod "pod-subpath-test-configmap-9dwd": Phase="Running", Reason="", readiness=false. Elapsed: 14.378484987s
Feb 20 18:55:40.517: INFO: Pod "pod-subpath-test-configmap-9dwd": Phase="Running", Reason="", readiness=false. Elapsed: 16.424942692s
Feb 20 18:55:42.559: INFO: Pod "pod-subpath-test-configmap-9dwd": Phase="Running", Reason="", readiness=false. Elapsed: 18.467397052s
Feb 20 18:55:44.603: INFO: Pod "pod-subpath-test-configmap-9dwd": Phase="Running", Reason="", readiness=false. Elapsed: 20.511422935s
Feb 20 18:55:46.646: INFO: Pod "pod-subpath-test-configmap-9dwd": Phase="Running", Reason="", readiness=false. Elapsed: 22.553848535s
Feb 20 18:55:48.688: INFO: Pod "pod-subpath-test-configmap-9dwd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.596469476s
STEP: Saw pod success
Feb 20 18:55:48.688: INFO: Pod "pod-subpath-test-configmap-9dwd" satisfied condition "success or failure"
Feb 20 18:55:48.730: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-subpath-test-configmap-9dwd container test-container-subpath-configmap-9dwd: <nil>
STEP: delete the pod
Feb 20 18:55:48.825: INFO: Waiting for pod pod-subpath-test-configmap-9dwd to disappear
Feb 20 18:55:48.867: INFO: Pod pod-subpath-test-configmap-9dwd no longer exists
STEP: Deleting pod pod-subpath-test-configmap-9dwd
Feb 20 18:55:48.867: INFO: Deleting pod "pod-subpath-test-configmap-9dwd" in namespace "e2e-tests-subpath-rl5rf"
[AfterEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:55:48.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-rl5rf" for this suite.
Feb 20 18:55:55.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:55:56.624: INFO: namespace: e2e-tests-subpath-rl5rf, resource: bindings, ignored listing per whitelist
Feb 20 18:55:56.707: INFO: namespace e2e-tests-subpath-rl5rf deletion completed in 7.755892381s

• [SLOW TEST:34.602 seconds]
[sig-storage] Subpath
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:55:56.707: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-rfkfq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 18:55:58.467: INFO: Creating deployment "nginx-deployment"
Feb 20 18:55:58.509: INFO: Waiting for observed generation 1
Feb 20 18:55:58.551: INFO: Waiting for all required pods to come up
Feb 20 18:55:58.593: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb 20 18:56:02.681: INFO: Waiting for deployment "nginx-deployment" to complete
Feb 20 18:56:02.765: INFO: Updating deployment "nginx-deployment" with a non-existent image
Feb 20 18:56:02.851: INFO: Updating deployment nginx-deployment
Feb 20 18:56:02.851: INFO: Waiting for observed generation 2
Feb 20 18:56:04.936: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb 20 18:56:04.978: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb 20 18:56:05.021: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 20 18:56:05.147: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb 20 18:56:05.147: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb 20 18:56:05.189: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 20 18:56:05.274: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Feb 20 18:56:05.275: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Feb 20 18:56:05.358: INFO: Updating deployment nginx-deployment
Feb 20 18:56:05.358: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Feb 20 18:56:05.449: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb 20 18:56:05.491: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 20 18:56:05.637: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rfkfq/deployments/nginx-deployment,UID:28c79aa2-3541-11e9-936d-1e925ead141b,ResourceVersion:10327,Generation:3,CreationTimestamp:2019-02-20 18:55:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-02-20 18:56:05 +0000 UTC 2019-02-20 18:56:05 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-20 18:56:05 +0000 UTC 2019-02-20 18:55:58 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Feb 20 18:56:05.737: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rfkfq/replicasets/nginx-deployment-7dc8f79789,UID:2b5e5f70-3541-11e9-936d-1e925ead141b,ResourceVersion:10324,Generation:3,CreationTimestamp:2019-02-20 18:56:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 28c79aa2-3541-11e9-936d-1e925ead141b 0xc001e21407 0xc001e21408}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 20 18:56:05.737: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Feb 20 18:56:05.737: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rfkfq/replicasets/nginx-deployment-7f9675fb8b,UID:28c84732-3541-11e9-936d-1e925ead141b,ResourceVersion:10325,Generation:3,CreationTimestamp:2019-02-20 18:55:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 28c79aa2-3541-11e9-936d-1e925ead141b 0xc001e214c7 0xc001e214c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Feb 20 18:56:05.782: INFO: Pod "nginx-deployment-7dc8f79789-22c4h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-22c4h,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7dc8f79789-22c4h,UID:2cde6a34-3541-11e9-936d-1e925ead141b,ResourceVersion:10337,Generation:0,CreationTimestamp:2019-02-20 18:56:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 2b5e5f70-3541-11e9-936d-1e925ead141b 0xc002082ad7 0xc002082ad8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-29-201.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002082b40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002082b60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.29.201,PodIP:,StartTime:2019-02-20 18:56:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.782: INFO: Pod "nginx-deployment-7dc8f79789-6qpjb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-6qpjb,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7dc8f79789-6qpjb,UID:2b5eacc6-3541-11e9-936d-1e925ead141b,ResourceVersion:10265,Generation:0,CreationTimestamp:2019-02-20 18:56:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.112/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 2b5e5f70-3541-11e9-936d-1e925ead141b 0xc002082ca0 0xc002082ca1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-15.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002082d10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002082d30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:02 +0000 UTC  }],Message:,Reason:,HostIP:10.250.8.15,PodIP:,StartTime:2019-02-20 18:56:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.782: INFO: Pod "nginx-deployment-7dc8f79789-cwsmh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-cwsmh,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7dc8f79789-cwsmh,UID:2cddfc96-3541-11e9-936d-1e925ead141b,ResourceVersion:10334,Generation:0,CreationTimestamp:2019-02-20 18:56:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 2b5e5f70-3541-11e9-936d-1e925ead141b 0xc002082e40 0xc002082e41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-29-201.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002082eb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002082ed0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.29.201,PodIP:,StartTime:2019-02-20 18:56:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.782: INFO: Pod "nginx-deployment-7dc8f79789-dp2pl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-dp2pl,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7dc8f79789-dp2pl,UID:2cde6c4d-3541-11e9-936d-1e925ead141b,ResourceVersion:10336,Generation:0,CreationTimestamp:2019-02-20 18:56:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 2b5e5f70-3541-11e9-936d-1e925ead141b 0xc002082f90 0xc002082f91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-29-201.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002083010} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002083030}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.29.201,PodIP:,StartTime:2019-02-20 18:56:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.783: INFO: Pod "nginx-deployment-7dc8f79789-fkt7t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-fkt7t,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7dc8f79789-fkt7t,UID:2cde6dbf-3541-11e9-936d-1e925ead141b,ResourceVersion:10330,Generation:0,CreationTimestamp:2019-02-20 18:56:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 2b5e5f70-3541-11e9-936d-1e925ead141b 0xc0020830f0 0xc0020830f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-15.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002083160} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002083180}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.8.15,PodIP:,StartTime:2019-02-20 18:56:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.783: INFO: Pod "nginx-deployment-7dc8f79789-glp5q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-glp5q,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7dc8f79789-glp5q,UID:2ce88f10-3541-11e9-936d-1e925ead141b,ResourceVersion:10331,Generation:0,CreationTimestamp:2019-02-20 18:56:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 2b5e5f70-3541-11e9-936d-1e925ead141b 0xc002083270 0xc002083271}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-15.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020832f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002083310}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.8.15,PodIP:,StartTime:2019-02-20 18:56:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.783: INFO: Pod "nginx-deployment-7dc8f79789-jrtw4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-jrtw4,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7dc8f79789-jrtw4,UID:2cde7630-3541-11e9-936d-1e925ead141b,ResourceVersion:10338,Generation:0,CreationTimestamp:2019-02-20 18:56:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 2b5e5f70-3541-11e9-936d-1e925ead141b 0xc0020833d0 0xc0020833d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-29-201.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002083490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020834b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.29.201,PodIP:,StartTime:2019-02-20 18:56:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.783: INFO: Pod "nginx-deployment-7dc8f79789-kfvjh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-kfvjh,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7dc8f79789-kfvjh,UID:2cddf7a8-3541-11e9-936d-1e925ead141b,ResourceVersion:10306,Generation:0,CreationTimestamp:2019-02-20 18:56:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 2b5e5f70-3541-11e9-936d-1e925ead141b 0xc002083570 0xc002083571}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-15.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020835e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002083dd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.8.15,PodIP:,StartTime:2019-02-20 18:56:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.783: INFO: Pod "nginx-deployment-7dc8f79789-nn4p8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-nn4p8,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7dc8f79789-nn4p8,UID:2b5f40fc-3541-11e9-936d-1e925ead141b,ResourceVersion:10264,Generation:0,CreationTimestamp:2019-02-20 18:56:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.111/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 2b5e5f70-3541-11e9-936d-1e925ead141b 0xc002083ea0 0xc002083ea1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-15.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002083f10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002083f60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:02 +0000 UTC  }],Message:,Reason:,HostIP:10.250.8.15,PodIP:,StartTime:2019-02-20 18:56:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.783: INFO: Pod "nginx-deployment-7dc8f79789-q57xw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-q57xw,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7dc8f79789-q57xw,UID:2b5f3bfe-3541-11e9-936d-1e925ead141b,ResourceVersion:10268,Generation:0,CreationTimestamp:2019-02-20 18:56:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.29/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 2b5e5f70-3541-11e9-936d-1e925ead141b 0xc00194c030 0xc00194c031}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-29-201.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00194c0d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00194c0f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:02 +0000 UTC  }],Message:,Reason:,HostIP:10.250.29.201,PodIP:100.96.0.29,StartTime:2019-02-20 18:56:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.783: INFO: Pod "nginx-deployment-7dc8f79789-s72gw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-s72gw,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7dc8f79789-s72gw,UID:2b6b3f10-3541-11e9-936d-1e925ead141b,ResourceVersion:10267,Generation:0,CreationTimestamp:2019-02-20 18:56:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.113/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 2b5e5f70-3541-11e9-936d-1e925ead141b 0xc00194c1e0 0xc00194c1e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-15.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00194c260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00194c280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:02 +0000 UTC  }],Message:,Reason:,HostIP:10.250.8.15,PodIP:,StartTime:2019-02-20 18:56:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.783: INFO: Pod "nginx-deployment-7dc8f79789-w7ctf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-w7ctf,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7dc8f79789-w7ctf,UID:2cdda71c-3541-11e9-936d-1e925ead141b,ResourceVersion:10304,Generation:0,CreationTimestamp:2019-02-20 18:56:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 2b5e5f70-3541-11e9-936d-1e925ead141b 0xc00194c340 0xc00194c341}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-15.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00194c3c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00194c420}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.8.15,PodIP:,StartTime:2019-02-20 18:56:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.784: INFO: Pod "nginx-deployment-7dc8f79789-xc8hw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-xc8hw,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7dc8f79789-xc8hw,UID:2b9a8f5e-3541-11e9-936d-1e925ead141b,ResourceVersion:10263,Generation:0,CreationTimestamp:2019-02-20 18:56:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.30/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 2b5e5f70-3541-11e9-936d-1e925ead141b 0xc00194c4f0 0xc00194c4f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-29-201.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00194c560} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00194c5f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:03 +0000 UTC  }],Message:,Reason:,HostIP:10.250.29.201,PodIP:,StartTime:2019-02-20 18:56:03 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.784: INFO: Pod "nginx-deployment-7f9675fb8b-2td7c" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-2td7c,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7f9675fb8b-2td7c,UID:28cb92d3-3541-11e9-936d-1e925ead141b,ResourceVersion:10191,Generation:0,CreationTimestamp:2019-02-20 18:55:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.27/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 28c84732-3541-11e9-936d-1e925ead141b 0xc00194c6c0 0xc00194c6c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-29-201.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00194c720} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00194c740}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:55:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:55:58 +0000 UTC  }],Message:,Reason:,HostIP:10.250.29.201,PodIP:100.96.0.27,StartTime:2019-02-20 18:55:58 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-20 18:56:00 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://b4594aabf38e91b61f9fb5baf7b07ea7e7d2d49d0d888db47646556267f24021}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.784: INFO: Pod "nginx-deployment-7f9675fb8b-67c72" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-67c72,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7f9675fb8b-67c72,UID:2cde6a75-3541-11e9-936d-1e925ead141b,ResourceVersion:10329,Generation:0,CreationTimestamp:2019-02-20 18:56:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 28c84732-3541-11e9-936d-1e925ead141b 0xc00194c860 0xc00194c861}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-15.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00194c8c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00194c8e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.8.15,PodIP:,StartTime:2019-02-20 18:56:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.784: INFO: Pod "nginx-deployment-7f9675fb8b-92v7v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-92v7v,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7f9675fb8b-92v7v,UID:2cde68e0-3541-11e9-936d-1e925ead141b,ResourceVersion:10328,Generation:0,CreationTimestamp:2019-02-20 18:56:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 28c84732-3541-11e9-936d-1e925ead141b 0xc00194c9e0 0xc00194c9e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-15.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00194ca40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00194ca60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.8.15,PodIP:,StartTime:2019-02-20 18:56:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.784: INFO: Pod "nginx-deployment-7f9675fb8b-9865t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-9865t,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7f9675fb8b-9865t,UID:2ce892e8-3541-11e9-936d-1e925ead141b,ResourceVersion:10323,Generation:0,CreationTimestamp:2019-02-20 18:56:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 28c84732-3541-11e9-936d-1e925ead141b 0xc00194cb10 0xc00194cb11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-29-201.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00194cb70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00194cb90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.784: INFO: Pod "nginx-deployment-7f9675fb8b-bzqgh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-bzqgh,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7f9675fb8b-bzqgh,UID:28cb9be3-3541-11e9-936d-1e925ead141b,ResourceVersion:10220,Generation:0,CreationTimestamp:2019-02-20 18:55:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.110/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 28c84732-3541-11e9-936d-1e925ead141b 0xc00194cc10 0xc00194cc11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-15.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00194cc70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00194cc90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:55:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:55:58 +0000 UTC  }],Message:,Reason:,HostIP:10.250.8.15,PodIP:100.96.1.110,StartTime:2019-02-20 18:55:58 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-20 18:56:00 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://18822c1002adc6cdbbb7faeb965320dc6135d235ef5688250436bdaeeeaafab6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.784: INFO: Pod "nginx-deployment-7f9675fb8b-czrzk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-czrzk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7f9675fb8b-czrzk,UID:28c9dc2e-3541-11e9-936d-1e925ead141b,ResourceVersion:10212,Generation:0,CreationTimestamp:2019-02-20 18:55:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.108/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 28c84732-3541-11e9-936d-1e925ead141b 0xc00194cd60 0xc00194cd61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-15.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00194cdc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00194cde0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:55:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:55:58 +0000 UTC  }],Message:,Reason:,HostIP:10.250.8.15,PodIP:100.96.1.108,StartTime:2019-02-20 18:55:58 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-20 18:56:00 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://cea4db4504941eab2c3ef0ec9577218110b33995563d673e2a070a7bae0960a1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.784: INFO: Pod "nginx-deployment-7f9675fb8b-f9gg6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-f9gg6,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7f9675fb8b-f9gg6,UID:2cdde470-3541-11e9-936d-1e925ead141b,ResourceVersion:10305,Generation:0,CreationTimestamp:2019-02-20 18:56:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 28c84732-3541-11e9-936d-1e925ead141b 0xc00194ceb0 0xc00194ceb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-15.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00194cf10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00194cf30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.8.15,PodIP:,StartTime:2019-02-20 18:56:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.784: INFO: Pod "nginx-deployment-7f9675fb8b-fphtn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-fphtn,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7f9675fb8b-fphtn,UID:2cdd587e-3541-11e9-936d-1e925ead141b,ResourceVersion:10307,Generation:0,CreationTimestamp:2019-02-20 18:56:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 28c84732-3541-11e9-936d-1e925ead141b 0xc00194d060 0xc00194d061}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-29-201.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00194d0c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00194d0e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.29.201,PodIP:,StartTime:2019-02-20 18:56:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.784: INFO: Pod "nginx-deployment-7f9675fb8b-ftczr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ftczr,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7f9675fb8b-ftczr,UID:28c9dcee-3541-11e9-936d-1e925ead141b,ResourceVersion:10203,Generation:0,CreationTimestamp:2019-02-20 18:55:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.109/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 28c84732-3541-11e9-936d-1e925ead141b 0xc00194d1a7 0xc00194d1a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-15.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00194d4d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00194d4f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:55:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:55:58 +0000 UTC  }],Message:,Reason:,HostIP:10.250.8.15,PodIP:100.96.1.109,StartTime:2019-02-20 18:55:58 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-20 18:56:00 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://509384b6893859511877af3b64641265b4f6fdd6218ebca1619a71fc243ef11f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.785: INFO: Pod "nginx-deployment-7f9675fb8b-gnf7t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-gnf7t,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7f9675fb8b-gnf7t,UID:2cdde7d5-3541-11e9-936d-1e925ead141b,ResourceVersion:10309,Generation:0,CreationTimestamp:2019-02-20 18:56:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 28c84732-3541-11e9-936d-1e925ead141b 0xc00194d5c0 0xc00194d5c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-29-201.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00194d7c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00194d7e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.29.201,PodIP:,StartTime:2019-02-20 18:56:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.785: INFO: Pod "nginx-deployment-7f9675fb8b-gv66g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-gv66g,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7f9675fb8b-gv66g,UID:2ce88f8c-3541-11e9-936d-1e925ead141b,ResourceVersion:10333,Generation:0,CreationTimestamp:2019-02-20 18:56:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 28c84732-3541-11e9-936d-1e925ead141b 0xc00194d897 0xc00194d898}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-15.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00194d940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00194d960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.8.15,PodIP:,StartTime:2019-02-20 18:56:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.785: INFO: Pod "nginx-deployment-7f9675fb8b-h6wxw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-h6wxw,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7f9675fb8b-h6wxw,UID:2cde5da3-3541-11e9-936d-1e925ead141b,ResourceVersion:10335,Generation:0,CreationTimestamp:2019-02-20 18:56:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 28c84732-3541-11e9-936d-1e925ead141b 0xc00194dd80 0xc00194dd81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-29-201.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00194dde0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00194de90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.29.201,PodIP:,StartTime:2019-02-20 18:56:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.785: INFO: Pod "nginx-deployment-7f9675fb8b-mhsgw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-mhsgw,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7f9675fb8b-mhsgw,UID:2ce897a7-3541-11e9-936d-1e925ead141b,ResourceVersion:10321,Generation:0,CreationTimestamp:2019-02-20 18:56:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 28c84732-3541-11e9-936d-1e925ead141b 0xc00194dfb7 0xc00194dfb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-29-201.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e5c040} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e5c060}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.785: INFO: Pod "nginx-deployment-7f9675fb8b-ntrpr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ntrpr,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7f9675fb8b-ntrpr,UID:28c97f11-3541-11e9-936d-1e925ead141b,ResourceVersion:10217,Generation:0,CreationTimestamp:2019-02-20 18:55:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.106/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 28c84732-3541-11e9-936d-1e925ead141b 0xc001e5c0e0 0xc001e5c0e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-15.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e5c140} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e5c160}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:55:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:55:58 +0000 UTC  }],Message:,Reason:,HostIP:10.250.8.15,PodIP:100.96.1.106,StartTime:2019-02-20 18:55:58 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-20 18:56:00 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://5442972a9ffeed0a8887a8bc7f85ff609ed5d929e288914a484227386e7ade0b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.785: INFO: Pod "nginx-deployment-7f9675fb8b-p98n8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-p98n8,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7f9675fb8b-p98n8,UID:2ce894e2-3541-11e9-936d-1e925ead141b,ResourceVersion:10332,Generation:0,CreationTimestamp:2019-02-20 18:56:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 28c84732-3541-11e9-936d-1e925ead141b 0xc001e5c220 0xc001e5c221}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-15.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e5c280} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e5c2a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.8.15,PodIP:,StartTime:2019-02-20 18:56:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.785: INFO: Pod "nginx-deployment-7f9675fb8b-rgfvl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-rgfvl,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7f9675fb8b-rgfvl,UID:28c9e031-3541-11e9-936d-1e925ead141b,ResourceVersion:10209,Generation:0,CreationTimestamp:2019-02-20 18:55:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.107/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 28c84732-3541-11e9-936d-1e925ead141b 0xc001e5c390 0xc001e5c391}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-15.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e5c3f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e5c410}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:55:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:55:58 +0000 UTC  }],Message:,Reason:,HostIP:10.250.8.15,PodIP:100.96.1.107,StartTime:2019-02-20 18:55:58 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-20 18:56:00 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://9059df34c39acc88bfacac2e454083a29d748e3aa9b7b3537b2e7b43df4c9bb5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.786: INFO: Pod "nginx-deployment-7f9675fb8b-rk889" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-rk889,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7f9675fb8b-rk889,UID:28cb986a-3541-11e9-936d-1e925ead141b,ResourceVersion:10197,Generation:0,CreationTimestamp:2019-02-20 18:55:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.26/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 28c84732-3541-11e9-936d-1e925ead141b 0xc001e5c550 0xc001e5c551}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-29-201.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e5c5b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e5c5d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:55:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:55:58 +0000 UTC  }],Message:,Reason:,HostIP:10.250.29.201,PodIP:100.96.0.26,StartTime:2019-02-20 18:55:58 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-20 18:56:00 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://0574403d9b59323c1d123a8aced3d7c8b1eba298a58452ea414d7a1f03444dce}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.786: INFO: Pod "nginx-deployment-7f9675fb8b-sbk82" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-sbk82,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7f9675fb8b-sbk82,UID:28c9db37-3541-11e9-936d-1e925ead141b,ResourceVersion:10194,Generation:0,CreationTimestamp:2019-02-20 18:55:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.28/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 28c84732-3541-11e9-936d-1e925ead141b 0xc001e5c6a0 0xc001e5c6a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-29-201.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e5c700} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e5c7b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:55:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:55:58 +0000 UTC  }],Message:,Reason:,HostIP:10.250.29.201,PodIP:100.96.0.28,StartTime:2019-02-20 18:55:58 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-20 18:56:00 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://a96552732d4a6a3988715e12cb1bf0a239f0fba3a3fb9dbbfd5971235006aab0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.786: INFO: Pod "nginx-deployment-7f9675fb8b-shm8g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-shm8g,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7f9675fb8b-shm8g,UID:2ce893b9-3541-11e9-936d-1e925ead141b,ResourceVersion:10339,Generation:0,CreationTimestamp:2019-02-20 18:56:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 28c84732-3541-11e9-936d-1e925ead141b 0xc001e5c870 0xc001e5c871}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-29-201.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e5c8d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e5c8f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.29.201,PodIP:,StartTime:2019-02-20 18:56:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 20 18:56:05.786: INFO: Pod "nginx-deployment-7f9675fb8b-xxnnj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-xxnnj,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-rfkfq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rfkfq/pods/nginx-deployment-7f9675fb8b-xxnnj,UID:2cde5cae-3541-11e9-936d-1e925ead141b,ResourceVersion:10310,Generation:0,CreationTimestamp:2019-02-20 18:56:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 28c84732-3541-11e9-936d-1e925ead141b 0xc001e5ca17 0xc001e5ca18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8n5fb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8n5fb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8n5fb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-15.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e5ca80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e5caa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 18:56:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.8.15,PodIP:,StartTime:2019-02-20 18:56:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:56:05.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-rfkfq" for this suite.
Feb 20 18:56:13.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:56:14.295: INFO: namespace: e2e-tests-deployment-rfkfq, resource: bindings, ignored listing per whitelist
Feb 20 18:56:15.558: INFO: namespace e2e-tests-deployment-rfkfq deletion completed in 9.729890188s

• [SLOW TEST:18.851 seconds]
[sig-apps] Deployment
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:56:15.558: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-wlwp4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-34089814-3541-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume configMaps
Feb 20 18:56:17.449: INFO: Waiting up to 5m0s for pod "pod-configmaps-340efc0d-3541-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-configmap-wlwp4" to be "success or failure"
Feb 20 18:56:17.491: INFO: Pod "pod-configmaps-340efc0d-3541-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.859015ms
Feb 20 18:56:19.533: INFO: Pod "pod-configmaps-340efc0d-3541-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084407379s
STEP: Saw pod success
Feb 20 18:56:19.533: INFO: Pod "pod-configmaps-340efc0d-3541-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:56:19.575: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-configmaps-340efc0d-3541-11e9-997a-8a6f774fb32b container configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 18:56:19.741: INFO: Waiting for pod pod-configmaps-340efc0d-3541-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:56:19.782: INFO: Pod pod-configmaps-340efc0d-3541-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:56:19.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wlwp4" for this suite.
Feb 20 18:56:25.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:56:27.154: INFO: namespace: e2e-tests-configmap-wlwp4, resource: bindings, ignored listing per whitelist
Feb 20 18:56:27.573: INFO: namespace e2e-tests-configmap-wlwp4 deletion completed in 7.730268446s

• [SLOW TEST:12.015 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:56:27.574: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-xp4vm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-3b21105a-3541-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume secrets
Feb 20 18:56:29.354: INFO: Waiting up to 5m0s for pod "pod-secrets-3b278911-3541-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-secrets-xp4vm" to be "success or failure"
Feb 20 18:56:29.397: INFO: Pod "pod-secrets-3b278911-3541-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 42.829203ms
Feb 20 18:56:31.442: INFO: Pod "pod-secrets-3b278911-3541-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.088134227s
STEP: Saw pod success
Feb 20 18:56:31.442: INFO: Pod "pod-secrets-3b278911-3541-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:56:31.485: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-secrets-3b278911-3541-11e9-997a-8a6f774fb32b container secret-volume-test: <nil>
STEP: delete the pod
Feb 20 18:56:31.577: INFO: Waiting for pod pod-secrets-3b278911-3541-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:56:31.619: INFO: Pod pod-secrets-3b278911-3541-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:56:31.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-xp4vm" for this suite.
Feb 20 18:56:37.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:56:39.010: INFO: namespace: e2e-tests-secrets-xp4vm, resource: bindings, ignored listing per whitelist
Feb 20 18:56:39.386: INFO: namespace e2e-tests-secrets-xp4vm deletion completed in 7.724033392s

• [SLOW TEST:11.813 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:56:39.387: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-6x962
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-6x962
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 20 18:56:41.162: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 20 18:56:59.926: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.127:8080/dial?request=hostName&protocol=udp&host=100.96.1.126&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-6x962 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 18:56:59.926: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 18:57:00.690: INFO: Waiting for endpoints: map[]
Feb 20 18:57:00.732: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.127:8080/dial?request=hostName&protocol=udp&host=100.96.0.41&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-6x962 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 18:57:00.732: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 18:57:01.320: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:57:01.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-6x962" for this suite.
Feb 20 18:57:23.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:57:24.540: INFO: namespace: e2e-tests-pod-network-test-6x962, resource: bindings, ignored listing per whitelist
Feb 20 18:57:25.081: INFO: namespace e2e-tests-pod-network-test-6x962 deletion completed in 23.717764612s

• [SLOW TEST:45.694 seconds]
[sig-network] Networking
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:57:25.081: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-jrlwr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 20 18:57:26.905: INFO: Waiting up to 5m0s for pod "pod-5d752620-3541-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-emptydir-jrlwr" to be "success or failure"
Feb 20 18:57:26.947: INFO: Pod "pod-5d752620-3541-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.81045ms
Feb 20 18:57:28.990: INFO: Pod "pod-5d752620-3541-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084792622s
STEP: Saw pod success
Feb 20 18:57:28.990: INFO: Pod "pod-5d752620-3541-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:57:29.032: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-5d752620-3541-11e9-997a-8a6f774fb32b container test-container: <nil>
STEP: delete the pod
Feb 20 18:57:29.126: INFO: Waiting for pod pod-5d752620-3541-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:57:29.168: INFO: Pod pod-5d752620-3541-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:57:29.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jrlwr" for this suite.
Feb 20 18:57:35.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:57:35.930: INFO: namespace: e2e-tests-emptydir-jrlwr, resource: bindings, ignored listing per whitelist
Feb 20 18:57:36.946: INFO: namespace e2e-tests-emptydir-jrlwr deletion completed in 7.736143661s

• [SLOW TEST:11.866 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:57:36.947: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-cjfkd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-648d952c-3541-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume configMaps
Feb 20 18:57:38.851: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-64940c20-3541-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-projected-cjfkd" to be "success or failure"
Feb 20 18:57:38.893: INFO: Pod "pod-projected-configmaps-64940c20-3541-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.692983ms
Feb 20 18:57:40.936: INFO: Pod "pod-projected-configmaps-64940c20-3541-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084415249s
STEP: Saw pod success
Feb 20 18:57:40.936: INFO: Pod "pod-projected-configmaps-64940c20-3541-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:57:40.978: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-projected-configmaps-64940c20-3541-11e9-997a-8a6f774fb32b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 18:57:41.070: INFO: Waiting for pod pod-projected-configmaps-64940c20-3541-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:57:41.113: INFO: Pod pod-projected-configmaps-64940c20-3541-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:57:41.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cjfkd" for this suite.
Feb 20 18:57:47.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:57:47.832: INFO: namespace: e2e-tests-projected-cjfkd, resource: bindings, ignored listing per whitelist
Feb 20 18:57:48.893: INFO: namespace e2e-tests-projected-cjfkd deletion completed in 7.732609196s

• [SLOW TEST:11.947 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:57:48.893: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-m2csl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0220 18:58:00.921784   29709 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 20 18:58:00.921: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:58:00.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-m2csl" for this suite.
Feb 20 18:58:07.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:58:08.612: INFO: namespace: e2e-tests-gc-m2csl, resource: bindings, ignored listing per whitelist
Feb 20 18:58:08.696: INFO: namespace e2e-tests-gc-m2csl deletion completed in 7.732159799s

• [SLOW TEST:19.803 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:58:08.696: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-wlsz8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-77831e03-3541-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume secrets
Feb 20 18:58:10.659: INFO: Waiting up to 5m0s for pod "pod-secrets-77898721-3541-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-secrets-wlsz8" to be "success or failure"
Feb 20 18:58:10.701: INFO: Pod "pod-secrets-77898721-3541-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.807174ms
Feb 20 18:58:12.744: INFO: Pod "pod-secrets-77898721-3541-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085106016s
STEP: Saw pod success
Feb 20 18:58:12.745: INFO: Pod "pod-secrets-77898721-3541-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 18:58:12.790: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-secrets-77898721-3541-11e9-997a-8a6f774fb32b container secret-volume-test: <nil>
STEP: delete the pod
Feb 20 18:58:12.885: INFO: Waiting for pod pod-secrets-77898721-3541-11e9-997a-8a6f774fb32b to disappear
Feb 20 18:58:12.927: INFO: Pod pod-secrets-77898721-3541-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:58:12.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-wlsz8" for this suite.
Feb 20 18:58:19.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:58:20.657: INFO: namespace: e2e-tests-secrets-wlsz8, resource: bindings, ignored listing per whitelist
Feb 20 18:58:20.699: INFO: namespace e2e-tests-secrets-wlsz8 deletion completed in 7.727571894s

• [SLOW TEST:12.003 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:58:20.700: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-xwp9f
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0220 18:58:28.769047   29709 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 20 18:58:28.769: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 18:58:28.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-xwp9f" for this suite.
Feb 20 18:58:34.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 18:58:35.359: INFO: namespace: e2e-tests-gc-xwp9f, resource: bindings, ignored listing per whitelist
Feb 20 18:58:36.578: INFO: namespace e2e-tests-gc-xwp9f deletion completed in 7.76602558s

• [SLOW TEST:15.878 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 18:58:36.578: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-cxsv9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 18:58:38.752: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb 20 18:58:38.879: INFO: Number of nodes with available pods: 0
Feb 20 18:58:38.880: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:58:39.964: INFO: Number of nodes with available pods: 2
Feb 20 18:58:39.964: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb 20 18:58:40.218: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:40.218: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:41.304: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:41.304: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:42.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:42.303: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:43.304: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:43.304: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:44.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:44.303: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:45.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:45.304: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:46.304: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:46.304: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:47.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:47.303: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:48.305: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:48.305: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:49.305: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:49.305: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:50.304: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:50.304: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:51.304: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:51.304: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:52.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:52.303: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:53.304: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:53.304: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:54.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:54.303: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:55.304: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:55.304: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:56.304: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:56.304: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:57.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:57.304: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:58.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:58.304: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:59.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:58:59.303: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:00.304: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:00.304: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:01.304: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:01.304: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:02.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:02.303: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:03.304: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:03.304: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:04.305: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:04.305: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:05.304: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:05.304: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:06.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:06.303: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:07.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:07.304: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:08.306: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:08.306: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:09.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:09.303: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:10.304: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:10.304: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:11.306: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:11.306: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:12.304: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:12.304: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:13.308: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:13.308: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:14.304: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:14.304: INFO: Wrong image for pod: daemon-set-lwsxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:14.304: INFO: Pod daemon-set-lwsxh is not available
Feb 20 18:59:15.307: INFO: Pod daemon-set-dq7gv is not available
Feb 20 18:59:15.307: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:16.303: INFO: Pod daemon-set-dq7gv is not available
Feb 20 18:59:16.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:17.303: INFO: Pod daemon-set-dq7gv is not available
Feb 20 18:59:17.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:18.305: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:19.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:20.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:21.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:22.305: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:23.305: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:24.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:25.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:26.304: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:27.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:28.306: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:29.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:30.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:31.304: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:32.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:33.305: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:34.306: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:35.304: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:36.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:37.304: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:38.304: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:39.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:40.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:41.305: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:42.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:43.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:44.306: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:45.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:46.305: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:47.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:48.304: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:48.304: INFO: Pod daemon-set-kzwzx is not available
Feb 20 18:59:49.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:49.303: INFO: Pod daemon-set-kzwzx is not available
Feb 20 18:59:50.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:50.303: INFO: Pod daemon-set-kzwzx is not available
Feb 20 18:59:51.304: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:51.304: INFO: Pod daemon-set-kzwzx is not available
Feb 20 18:59:52.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:52.303: INFO: Pod daemon-set-kzwzx is not available
Feb 20 18:59:53.303: INFO: Wrong image for pod: daemon-set-kzwzx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 20 18:59:53.303: INFO: Pod daemon-set-kzwzx is not available
Feb 20 18:59:54.303: INFO: Pod daemon-set-cgsnr is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Feb 20 18:59:54.430: INFO: Number of nodes with available pods: 1
Feb 20 18:59:54.430: INFO: Node ip-10-250-8-15.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 18:59:55.514: INFO: Number of nodes with available pods: 2
Feb 20 18:59:55.514: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-cxsv9, will wait for the garbage collector to delete the pods
Feb 20 18:59:55.866: INFO: Deleting {extensions DaemonSet} daemon-set took: 44.593899ms
Feb 20 18:59:55.966: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.272432ms
Feb 20 19:00:04.308: INFO: Number of nodes with available pods: 0
Feb 20 19:00:04.308: INFO: Number of running nodes: 0, number of available pods: 0
Feb 20 19:00:04.350: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-cxsv9/daemonsets","resourceVersion":"11268"},"items":null}

Feb 20 19:00:04.392: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-cxsv9/pods","resourceVersion":"11268"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:00:04.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-cxsv9" for this suite.
Feb 20 19:00:10.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:00:11.980: INFO: namespace: e2e-tests-daemonsets-cxsv9, resource: bindings, ignored listing per whitelist
Feb 20 19:00:12.358: INFO: namespace e2e-tests-daemonsets-cxsv9 deletion completed in 7.794356164s

• [SLOW TEST:95.780 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:00:12.358: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-mr27w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:84
[It] should serve a basic endpoint from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-mr27w
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-mr27w to expose endpoints map[]
Feb 20 19:00:14.158: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-mr27w exposes endpoints map[] (42.735206ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-mr27w
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-mr27w to expose endpoints map[pod1:[80]]
Feb 20 19:00:16.460: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-mr27w exposes endpoints map[pod1:[80]] (2.256789419s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-mr27w
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-mr27w to expose endpoints map[pod1:[80] pod2:[80]]
Feb 20 19:00:18.886: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-mr27w exposes endpoints map[pod1:[80] pod2:[80]] (2.38294921s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-mr27w
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-mr27w to expose endpoints map[pod2:[80]]
Feb 20 19:00:19.013: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-mr27w exposes endpoints map[pod2:[80]] (83.578309ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-mr27w
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-mr27w to expose endpoints map[]
Feb 20 19:00:19.097: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-mr27w exposes endpoints map[] (41.57805ms elapsed)
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:00:19.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-mr27w" for this suite.
Feb 20 19:00:25.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:00:26.321: INFO: namespace: e2e-tests-services-mr27w, resource: bindings, ignored listing per whitelist
Feb 20 19:00:26.904: INFO: namespace e2e-tests-services-mr27w deletion completed in 7.716720218s
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:89

• [SLOW TEST:14.546 seconds]
[sig-network] Services
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:00:26.904: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-f5pzp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Feb 20 19:00:28.668: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml cluster-info'
Feb 20 19:00:29.052: INFO: stderr: ""
Feb 20 19:00:29.052: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:00:29.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-f5pzp" for this suite.
Feb 20 19:00:35.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:00:35.934: INFO: namespace: e2e-tests-kubectl-f5pzp, resource: bindings, ignored listing per whitelist
Feb 20 19:00:36.856: INFO: namespace e2e-tests-kubectl-f5pzp deletion completed in 7.762383843s

• [SLOW TEST:9.953 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:00:36.857: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-r2qk4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 19:00:38.616: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cfb9dd91-3541-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-downward-api-r2qk4" to be "success or failure"
Feb 20 19:00:38.660: INFO: Pod "downwardapi-volume-cfb9dd91-3541-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 43.43261ms
Feb 20 19:00:40.702: INFO: Pod "downwardapi-volume-cfb9dd91-3541-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.086010072s
STEP: Saw pod success
Feb 20 19:00:40.702: INFO: Pod "downwardapi-volume-cfb9dd91-3541-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:00:40.744: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod downwardapi-volume-cfb9dd91-3541-11e9-997a-8a6f774fb32b container client-container: <nil>
STEP: delete the pod
Feb 20 19:00:40.838: INFO: Waiting for pod downwardapi-volume-cfb9dd91-3541-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:00:40.880: INFO: Pod downwardapi-volume-cfb9dd91-3541-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:00:40.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-r2qk4" for this suite.
Feb 20 19:00:47.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:00:47.857: INFO: namespace: e2e-tests-downward-api-r2qk4, resource: bindings, ignored listing per whitelist
Feb 20 19:00:48.743: INFO: namespace e2e-tests-downward-api-r2qk4 deletion completed in 7.817304388s

• [SLOW TEST:11.886 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:00:48.743: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-562cm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 20 19:00:54.857: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 19:00:54.899: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 19:00:56.899: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 19:00:56.942: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 19:00:58.899: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 19:00:58.941: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 19:01:00.899: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 19:01:00.942: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 19:01:02.899: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 19:01:02.941: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 19:01:04.900: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 19:01:04.942: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 19:01:06.901: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 19:01:06.944: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 19:01:08.899: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 19:01:08.942: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 19:01:10.899: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 19:01:10.942: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 19:01:12.899: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 19:01:12.942: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 19:01:14.899: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 19:01:14.942: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 19:01:16.900: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 19:01:16.942: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 19:01:18.899: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 19:01:18.942: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 19:01:20.901: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 19:01:20.944: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 19:01:22.900: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 19:01:22.943: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 19:01:24.900: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 19:01:24.943: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:01:24.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-562cm" for this suite.
Feb 20 19:01:47.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:01:47.966: INFO: namespace: e2e-tests-container-lifecycle-hook-562cm, resource: bindings, ignored listing per whitelist
Feb 20 19:01:48.771: INFO: namespace e2e-tests-container-lifecycle-hook-562cm deletion completed in 23.738887498s

• [SLOW TEST:60.028 seconds]
[k8s.io] Container Lifecycle Hook
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:01:48.772: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-pnj2j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 20 19:01:50.566: INFO: namespace e2e-tests-kubectl-pnj2j
Feb 20 19:01:50.566: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-pnj2j'
Feb 20 19:01:53.119: INFO: stderr: ""
Feb 20 19:01:53.119: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 20 19:01:54.162: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 19:01:54.162: INFO: Found 0 / 1
Feb 20 19:01:55.162: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 19:01:55.162: INFO: Found 1 / 1
Feb 20 19:01:55.162: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 20 19:01:55.207: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 19:01:55.207: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 20 19:01:55.207: INFO: wait on redis-master startup in e2e-tests-kubectl-pnj2j 
Feb 20 19:01:55.207: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml logs redis-master-xtx5z redis-master --namespace=e2e-tests-kubectl-pnj2j'
Feb 20 19:01:55.514: INFO: stderr: ""
Feb 20 19:01:55.514: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 20 Feb 19:01:53.957 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 20 Feb 19:01:53.958 # Server started, Redis version 3.2.12\n1:M 20 Feb 19:01:53.958 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 20 Feb 19:01:53.958 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb 20 19:01:55.514: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-pnj2j'
Feb 20 19:01:55.835: INFO: stderr: ""
Feb 20 19:01:55.835: INFO: stdout: "service/rm2 exposed\n"
Feb 20 19:01:55.877: INFO: Service rm2 in namespace e2e-tests-kubectl-pnj2j found.
STEP: exposing service
Feb 20 19:01:57.961: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-pnj2j'
Feb 20 19:01:58.281: INFO: stderr: ""
Feb 20 19:01:58.281: INFO: stdout: "service/rm3 exposed\n"
Feb 20 19:01:58.323: INFO: Service rm3 in namespace e2e-tests-kubectl-pnj2j found.
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:02:00.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pnj2j" for this suite.
Feb 20 19:02:22.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:02:23.712: INFO: namespace: e2e-tests-kubectl-pnj2j, resource: bindings, ignored listing per whitelist
Feb 20 19:02:24.218: INFO: namespace e2e-tests-kubectl-pnj2j deletion completed in 23.767071709s

• [SLOW TEST:35.446 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:02:24.218: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-x9sf8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:84
[It] should serve multiport endpoints from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-x9sf8
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-x9sf8 to expose endpoints map[]
Feb 20 19:02:26.250: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-x9sf8 exposes endpoints map[] (41.412009ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-x9sf8
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-x9sf8 to expose endpoints map[pod1:[100]]
Feb 20 19:02:28.546: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-x9sf8 exposes endpoints map[pod1:[100]] (2.252110083s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-x9sf8
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-x9sf8 to expose endpoints map[pod1:[100] pod2:[101]]
Feb 20 19:02:29.842: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-x9sf8 exposes endpoints map[pod1:[100] pod2:[101]] (1.253287608s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-x9sf8
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-x9sf8 to expose endpoints map[pod2:[101]]
Feb 20 19:02:29.968: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-x9sf8 exposes endpoints map[pod2:[101]] (83.314653ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-x9sf8
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-x9sf8 to expose endpoints map[]
Feb 20 19:02:30.052: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-x9sf8 exposes endpoints map[] (41.494086ms elapsed)
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:02:30.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-x9sf8" for this suite.
Feb 20 19:02:36.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:02:36.396: INFO: namespace: e2e-tests-services-x9sf8, resource: bindings, ignored listing per whitelist
Feb 20 19:02:37.870: INFO: namespace e2e-tests-services-x9sf8 deletion completed in 7.728165857s
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:89

• [SLOW TEST:13.652 seconds]
[sig-network] Services
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:02:37.870: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-6654n
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Feb 20 19:02:39.612: INFO: Waiting up to 5m0s for pod "client-containers-17d880f6-3542-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-containers-6654n" to be "success or failure"
Feb 20 19:02:39.657: INFO: Pod "client-containers-17d880f6-3542-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 44.376671ms
Feb 20 19:02:41.698: INFO: Pod "client-containers-17d880f6-3542-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.086314758s
STEP: Saw pod success
Feb 20 19:02:41.699: INFO: Pod "client-containers-17d880f6-3542-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:02:41.741: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod client-containers-17d880f6-3542-11e9-997a-8a6f774fb32b container test-container: <nil>
STEP: delete the pod
Feb 20 19:02:41.833: INFO: Waiting for pod client-containers-17d880f6-3542-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:02:41.875: INFO: Pod client-containers-17d880f6-3542-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:02:41.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-6654n" for this suite.
Feb 20 19:02:48.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:02:49.200: INFO: namespace: e2e-tests-containers-6654n, resource: bindings, ignored listing per whitelist
Feb 20 19:02:49.739: INFO: namespace e2e-tests-containers-6654n deletion completed in 7.821040336s

• [SLOW TEST:11.869 seconds]
[k8s.io] Docker Containers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:02:49.739: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-4twt2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-1efa014b-3542-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume configMaps
Feb 20 19:02:51.623: INFO: Waiting up to 5m0s for pod "pod-configmaps-1f012cb3-3542-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-configmap-4twt2" to be "success or failure"
Feb 20 19:02:51.666: INFO: Pod "pod-configmaps-1f012cb3-3542-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 42.904866ms
Feb 20 19:02:53.709: INFO: Pod "pod-configmaps-1f012cb3-3542-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085512063s
STEP: Saw pod success
Feb 20 19:02:53.709: INFO: Pod "pod-configmaps-1f012cb3-3542-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:02:53.751: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-configmaps-1f012cb3-3542-11e9-997a-8a6f774fb32b container configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 19:02:53.844: INFO: Waiting for pod pod-configmaps-1f012cb3-3542-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:02:53.886: INFO: Pod pod-configmaps-1f012cb3-3542-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:02:53.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4twt2" for this suite.
Feb 20 19:03:00.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:03:00.809: INFO: namespace: e2e-tests-configmap-4twt2, resource: bindings, ignored listing per whitelist
Feb 20 19:03:02.688: INFO: namespace e2e-tests-configmap-4twt2 deletion completed in 8.757920483s

• [SLOW TEST:12.949 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:03:02.688: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-g6zfj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 20 19:03:05.071: INFO: Waiting up to 5m0s for pod "pod-26ff38b4-3542-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-emptydir-g6zfj" to be "success or failure"
Feb 20 19:03:05.113: INFO: Pod "pod-26ff38b4-3542-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.881658ms
Feb 20 19:03:07.159: INFO: Pod "pod-26ff38b4-3542-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.087520163s
STEP: Saw pod success
Feb 20 19:03:07.159: INFO: Pod "pod-26ff38b4-3542-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:03:07.268: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-26ff38b4-3542-11e9-997a-8a6f774fb32b container test-container: <nil>
STEP: delete the pod
Feb 20 19:03:07.434: INFO: Waiting for pod pod-26ff38b4-3542-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:03:07.524: INFO: Pod pod-26ff38b4-3542-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:03:07.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-g6zfj" for this suite.
Feb 20 19:03:13.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:03:16.158: INFO: namespace: e2e-tests-emptydir-g6zfj, resource: bindings, ignored listing per whitelist
Feb 20 19:03:16.159: INFO: namespace e2e-tests-emptydir-g6zfj deletion completed in 8.570454657s

• [SLOW TEST:13.470 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:03:16.159: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-xcfss
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 19:03:18.674: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2f20a44e-3542-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-downward-api-xcfss" to be "success or failure"
Feb 20 19:03:18.716: INFO: Pod "downwardapi-volume-2f20a44e-3542-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.880938ms
Feb 20 19:03:20.794: INFO: Pod "downwardapi-volume-2f20a44e-3542-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.120327461s
STEP: Saw pod success
Feb 20 19:03:20.794: INFO: Pod "downwardapi-volume-2f20a44e-3542-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:03:20.876: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod downwardapi-volume-2f20a44e-3542-11e9-997a-8a6f774fb32b container client-container: <nil>
STEP: delete the pod
Feb 20 19:03:20.973: INFO: Waiting for pod downwardapi-volume-2f20a44e-3542-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:03:21.054: INFO: Pod downwardapi-volume-2f20a44e-3542-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:03:21.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xcfss" for this suite.
Feb 20 19:03:27.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:03:27.796: INFO: namespace: e2e-tests-downward-api-xcfss, resource: bindings, ignored listing per whitelist
Feb 20 19:03:29.747: INFO: namespace e2e-tests-downward-api-xcfss deletion completed in 8.596994017s

• [SLOW TEST:13.588 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:03:29.747: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-ktprf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-gl8g
STEP: Creating a pod to test atomic-volume-subpath
Feb 20 19:03:32.123: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-gl8g" in namespace "e2e-tests-subpath-ktprf" to be "success or failure"
Feb 20 19:03:32.165: INFO: Pod "pod-subpath-test-configmap-gl8g": Phase="Pending", Reason="", readiness=false. Elapsed: 41.759873ms
Feb 20 19:03:34.245: INFO: Pod "pod-subpath-test-configmap-gl8g": Phase="Pending", Reason="", readiness=false. Elapsed: 2.122019004s
Feb 20 19:03:36.289: INFO: Pod "pod-subpath-test-configmap-gl8g": Phase="Running", Reason="", readiness=false. Elapsed: 4.16551871s
Feb 20 19:03:38.332: INFO: Pod "pod-subpath-test-configmap-gl8g": Phase="Running", Reason="", readiness=false. Elapsed: 6.209111266s
Feb 20 19:03:40.375: INFO: Pod "pod-subpath-test-configmap-gl8g": Phase="Running", Reason="", readiness=false. Elapsed: 8.251865893s
Feb 20 19:03:42.458: INFO: Pod "pod-subpath-test-configmap-gl8g": Phase="Running", Reason="", readiness=false. Elapsed: 10.334525464s
Feb 20 19:03:44.539: INFO: Pod "pod-subpath-test-configmap-gl8g": Phase="Running", Reason="", readiness=false. Elapsed: 12.415603795s
Feb 20 19:03:46.582: INFO: Pod "pod-subpath-test-configmap-gl8g": Phase="Running", Reason="", readiness=false. Elapsed: 14.458920053s
Feb 20 19:03:48.657: INFO: Pod "pod-subpath-test-configmap-gl8g": Phase="Running", Reason="", readiness=false. Elapsed: 16.533747103s
Feb 20 19:03:50.699: INFO: Pod "pod-subpath-test-configmap-gl8g": Phase="Running", Reason="", readiness=false. Elapsed: 18.575913642s
Feb 20 19:03:52.742: INFO: Pod "pod-subpath-test-configmap-gl8g": Phase="Running", Reason="", readiness=false. Elapsed: 20.618816321s
Feb 20 19:03:54.829: INFO: Pod "pod-subpath-test-configmap-gl8g": Phase="Running", Reason="", readiness=false. Elapsed: 22.706327755s
Feb 20 19:03:56.909: INFO: Pod "pod-subpath-test-configmap-gl8g": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.785829776s
STEP: Saw pod success
Feb 20 19:03:56.909: INFO: Pod "pod-subpath-test-configmap-gl8g" satisfied condition "success or failure"
Feb 20 19:03:56.951: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-subpath-test-configmap-gl8g container test-container-subpath-configmap-gl8g: <nil>
STEP: delete the pod
Feb 20 19:03:57.113: INFO: Waiting for pod pod-subpath-test-configmap-gl8g to disappear
Feb 20 19:03:57.212: INFO: Pod pod-subpath-test-configmap-gl8g no longer exists
STEP: Deleting pod pod-subpath-test-configmap-gl8g
Feb 20 19:03:57.212: INFO: Deleting pod "pod-subpath-test-configmap-gl8g" in namespace "e2e-tests-subpath-ktprf"
[AfterEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:03:57.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-ktprf" for this suite.
Feb 20 19:04:03.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:04:04.455: INFO: namespace: e2e-tests-subpath-ktprf, resource: bindings, ignored listing per whitelist
Feb 20 19:04:05.567: INFO: namespace e2e-tests-subpath-ktprf deletion completed in 8.270098056s

• [SLOW TEST:35.820 seconds]
[sig-storage] Subpath
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:04:05.567: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mdw42
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 19:04:08.044: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4c8956c0-3542-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-projected-mdw42" to be "success or failure"
Feb 20 19:04:08.086: INFO: Pod "downwardapi-volume-4c8956c0-3542-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.702354ms
Feb 20 19:04:10.166: INFO: Pod "downwardapi-volume-4c8956c0-3542-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.121926449s
STEP: Saw pod success
Feb 20 19:04:10.166: INFO: Pod "downwardapi-volume-4c8956c0-3542-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:04:10.270: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod downwardapi-volume-4c8956c0-3542-11e9-997a-8a6f774fb32b container client-container: <nil>
STEP: delete the pod
Feb 20 19:04:10.490: INFO: Waiting for pod downwardapi-volume-4c8956c0-3542-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:04:10.534: INFO: Pod downwardapi-volume-4c8956c0-3542-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:04:10.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mdw42" for this suite.
Feb 20 19:04:16.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:04:18.507: INFO: namespace: e2e-tests-projected-mdw42, resource: bindings, ignored listing per whitelist
Feb 20 19:04:19.302: INFO: namespace e2e-tests-projected-mdw42 deletion completed in 8.698500441s

• [SLOW TEST:13.735 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:04:19.302: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-kn78q
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-kn78q
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-kn78q
STEP: Deleting pre-stop pod
Feb 20 19:04:33.241: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:04:33.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-kn78q" for this suite.
Feb 20 19:05:11.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:05:12.206: INFO: namespace: e2e-tests-prestop-kn78q, resource: bindings, ignored listing per whitelist
Feb 20 19:05:13.906: INFO: namespace e2e-tests-prestop-kn78q deletion completed in 40.557092081s

• [SLOW TEST:54.603 seconds]
[k8s.io] [sig-node] PreStop
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:05:13.906: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-7s2sx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-7559e90d-3542-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume configMaps
Feb 20 19:05:16.590: INFO: Waiting up to 5m0s for pod "pod-configmaps-75606fb8-3542-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-configmap-7s2sx" to be "success or failure"
Feb 20 19:05:16.631: INFO: Pod "pod-configmaps-75606fb8-3542-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.754539ms
Feb 20 19:05:18.682: INFO: Pod "pod-configmaps-75606fb8-3542-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.092230883s
STEP: Saw pod success
Feb 20 19:05:18.682: INFO: Pod "pod-configmaps-75606fb8-3542-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:05:18.728: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-configmaps-75606fb8-3542-11e9-997a-8a6f774fb32b container configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 19:05:18.874: INFO: Waiting for pod pod-configmaps-75606fb8-3542-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:05:18.972: INFO: Pod pod-configmaps-75606fb8-3542-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:05:18.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7s2sx" for this suite.
Feb 20 19:05:25.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:05:26.314: INFO: namespace: e2e-tests-configmap-7s2sx, resource: bindings, ignored listing per whitelist
Feb 20 19:05:27.735: INFO: namespace e2e-tests-configmap-7s2sx deletion completed in 8.659828643s

• [SLOW TEST:13.829 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:05:27.735: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-5v66w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-5v66w
Feb 20 19:05:32.679: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-5v66w
STEP: checking the pod's current state and verifying that restartCount is present
Feb 20 19:05:32.782: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:09:32.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-5v66w" for this suite.
Feb 20 19:09:39.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:09:40.256: INFO: namespace: e2e-tests-container-probe-5v66w, resource: bindings, ignored listing per whitelist
Feb 20 19:09:40.720: INFO: namespace e2e-tests-container-probe-5v66w deletion completed in 7.763471862s

• [SLOW TEST:252.985 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:09:40.721: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-r2l2t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 20 19:09:45.273: INFO: Successfully updated pod "pod-update-13eaa37b-3543-11e9-997a-8a6f774fb32b"
STEP: verifying the updated pod is in kubernetes
Feb 20 19:09:45.359: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:09:45.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-r2l2t" for this suite.
Feb 20 19:10:07.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:10:08.953: INFO: namespace: e2e-tests-pods-r2l2t, resource: bindings, ignored listing per whitelist
Feb 20 19:10:09.302: INFO: namespace e2e-tests-pods-r2l2t deletion completed in 23.90058243s

• [SLOW TEST:28.582 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:10:09.303: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-6mfkv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 19:10:11.062: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml version --client'
Feb 20 19:10:11.161: INFO: stderr: ""
Feb 20 19:10:11.161: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.5\", GitCommit:\"51dd616cdd25d6ee22c83a858773b607328a18ec\", GitTreeState:\"archive\", BuildDate:\"2019-02-20T18:05:25Z\", GoVersion:\"go1.11.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Feb 20 19:10:11.203: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-6mfkv'
Feb 20 19:10:11.747: INFO: stderr: ""
Feb 20 19:10:11.747: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb 20 19:10:11.747: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-6mfkv'
Feb 20 19:10:12.154: INFO: stderr: ""
Feb 20 19:10:12.154: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 20 19:10:13.199: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 19:10:13.199: INFO: Found 0 / 1
Feb 20 19:10:14.199: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 19:10:14.199: INFO: Found 1 / 1
Feb 20 19:10:14.199: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 20 19:10:14.241: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 19:10:14.241: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 20 19:10:14.241: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml describe pod redis-master-9fnn7 --namespace=e2e-tests-kubectl-6mfkv'
Feb 20 19:10:14.604: INFO: stderr: ""
Feb 20 19:10:14.604: INFO: stdout: "Name:               redis-master-9fnn7\nNamespace:          e2e-tests-kubectl-6mfkv\nPriority:           0\nPriorityClassName:  <none>\nNode:               ip-10-250-8-15.eu-west-1.compute.internal/10.250.8.15\nStart Time:         Wed, 20 Feb 2019 19:10:11 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 100.96.1.157/32\n                    kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 100.96.1.157\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://b0f1ff127fc25ce76b71690d60b396900435aee45958999a7b79e85e98f2888c\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 20 Feb 2019 19:10:12 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-sghmj (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-sghmj:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-sghmj\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                Message\n  ----    ------     ----  ----                                                -------\n  Normal  Scheduled  3s    default-scheduler                                   Successfully assigned e2e-tests-kubectl-6mfkv/redis-master-9fnn7 to ip-10-250-8-15.eu-west-1.compute.internal\n  Normal  Pulled     2s    kubelet, ip-10-250-8-15.eu-west-1.compute.internal  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, ip-10-250-8-15.eu-west-1.compute.internal  Created container\n  Normal  Started    2s    kubelet, ip-10-250-8-15.eu-west-1.compute.internal  Started container\n"
Feb 20 19:10:14.604: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml describe rc redis-master --namespace=e2e-tests-kubectl-6mfkv'
Feb 20 19:10:15.096: INFO: stderr: ""
Feb 20 19:10:15.097: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-6mfkv\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-9fnn7\n"
Feb 20 19:10:15.097: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml describe service redis-master --namespace=e2e-tests-kubectl-6mfkv'
Feb 20 19:10:15.552: INFO: stderr: ""
Feb 20 19:10:15.552: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-6mfkv\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                100.68.61.232\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         100.96.1.157:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb 20 19:10:15.595: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml describe node ip-10-250-29-201.eu-west-1.compute.internal'
Feb 20 19:10:16.034: INFO: stderr: ""
Feb 20 19:10:16.034: INFO: stdout: "Name:               ip-10-250-29-201.eu-west-1.compute.internal\nRoles:              node\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=m4.large\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-west-1\n                    failure-domain.beta.kubernetes.io/zone=eu-west-1a\n                    kubernetes.io/hostname=ip-10-250-29-201.eu-west-1.compute.internal\n                    kubernetes.io/role=node\n                    node-role.kubernetes.io/node=\n                    worker.garden.sapcloud.io/group=cpu-worker\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.250.29.201/19\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 20 Feb 2019 17:54:43 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Wed, 20 Feb 2019 19:10:08 +0000   Wed, 20 Feb 2019 17:54:43 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Wed, 20 Feb 2019 19:10:08 +0000   Wed, 20 Feb 2019 17:54:43 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 20 Feb 2019 19:10:08 +0000   Wed, 20 Feb 2019 17:54:43 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 20 Feb 2019 19:10:08 +0000   Wed, 20 Feb 2019 17:54:43 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 20 Feb 2019 19:10:08 +0000   Wed, 20 Feb 2019 17:55:03 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:   10.250.29.201\n  InternalDNS:  ip-10-250-29-201.eu-west-1.compute.internal\n  Hostname:     ip-10-250-29-201.eu-west-1.compute.internal\nCapacity:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           17897500Ki\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      8169012Ki\n pods:                        110\nAllocatable:\n attachable-volumes-aws-ebs:  39\n cpu:                         1920m\n ephemeral-storage:           17410687987\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      6873073044\n pods:                        110\nSystem Info:\n Machine ID:                 eefc36d5751c4f2ebb757a8264ea5b27\n System UUID:                EC2FF86F-DD3A-8130-F78F-D88FF996C539\n Boot ID:                    0e33d555-5759-48ca-807b-796992994304\n Kernel Version:             4.14.96-coreos\n OS Image:                   Container Linux by CoreOS 1967.5.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.12.5\n Kube-Proxy Version:         v1.12.5\nPodCIDR:                     100.96.0.0/24\nProviderID:                  aws:///eu-west-1a/i-0e74d9713047d7659\nNon-terminated Pods:         (11 in total)\n  Namespace                  Name                                                               CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                               ------------  ----------  ---------------  -------------\n  kube-system                addons-kube-lego-648f8c9f5c-72vfs                                  20m (1%)      50m (2%)    8Mi (0%)         32Mi (0%)\n  kube-system                addons-kubernetes-dashboard-5f64f76bd-fghf5                        50m (2%)      100m (5%)   50Mi (0%)        256Mi (3%)\n  kube-system                addons-nginx-ingress-controller-6574bbbf6f-vvn47                   100m (5%)     2 (104%)    100Mi (1%)       800Mi (12%)\n  kube-system                addons-nginx-ingress-nginx-ingress-k8s-backend-6498456576-7cql9    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                blackbox-exporter-64f6f7f998-4jrfr                                 5m (0%)       10m (0%)    5Mi (0%)         35Mi (0%)\n  kube-system                calico-node-dp8b4                                                  100m (5%)     500m (26%)  100Mi (1%)       700Mi (10%)\n  kube-system                coredns-5f4748c5f-ln884                                            50m (2%)      100m (5%)   15Mi (0%)        100Mi (1%)\n  kube-system                kube-proxy-95xsf                                                   20m (1%)      900m (46%)  64Mi (0%)        200Mi (3%)\n  kube-system                metrics-server-67d85b8585-xjbtx                                    20m (1%)      80m (4%)    100Mi (1%)       400Mi (6%)\n  kube-system                node-exporter-hr89s                                                5m (0%)       15m (0%)    10Mi (0%)        50Mi (0%)\n  kube-system                vpn-shoot-7c466dcf55-7l9tt                                         50m (2%)      100m (5%)   50Mi (0%)        100Mi (1%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                    Requests    Limits\n  --------                    --------    ------\n  cpu                         420m (21%)  3855m (200%)\n  memory                      502Mi (7%)  2673Mi (40%)\n  attachable-volumes-aws-ebs  0           0\nEvents:                       <none>\n"
Feb 20 19:10:16.034: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml describe namespace e2e-tests-kubectl-6mfkv'
Feb 20 19:10:16.435: INFO: stderr: ""
Feb 20 19:10:16.435: INFO: stdout: "Name:         e2e-tests-kubectl-6mfkv\nLabels:       e2e-framework=kubectl\n              e2e-run=6964e7e0-353a-11e9-997a-8a6f774fb32b\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:10:16.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6mfkv" for this suite.
Feb 20 19:10:38.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:10:39.482: INFO: namespace: e2e-tests-kubectl-6mfkv, resource: bindings, ignored listing per whitelist
Feb 20 19:10:40.194: INFO: namespace e2e-tests-kubectl-6mfkv deletion completed in 23.716248361s

• [SLOW TEST:30.892 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:10:40.194: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-zfc8q
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 20 19:10:42.005: INFO: Waiting up to 5m0s for pod "pod-375fcc59-3543-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-emptydir-zfc8q" to be "success or failure"
Feb 20 19:10:42.048: INFO: Pod "pod-375fcc59-3543-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 42.369432ms
Feb 20 19:10:44.092: INFO: Pod "pod-375fcc59-3543-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.086580641s
STEP: Saw pod success
Feb 20 19:10:44.092: INFO: Pod "pod-375fcc59-3543-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:10:44.134: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-375fcc59-3543-11e9-997a-8a6f774fb32b container test-container: <nil>
STEP: delete the pod
Feb 20 19:10:44.233: INFO: Waiting for pod pod-375fcc59-3543-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:10:44.275: INFO: Pod pod-375fcc59-3543-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:10:44.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-zfc8q" for this suite.
Feb 20 19:10:50.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:10:51.868: INFO: namespace: e2e-tests-emptydir-zfc8q, resource: bindings, ignored listing per whitelist
Feb 20 19:10:52.076: INFO: namespace e2e-tests-emptydir-zfc8q deletion completed in 7.759214804s

• [SLOW TEST:11.882 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:10:52.077: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-qm9wc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:84
[It] should provide secure master service  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:10:54.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-qm9wc" for this suite.
Feb 20 19:11:00.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:11:01.396: INFO: namespace: e2e-tests-services-qm9wc, resource: bindings, ignored listing per whitelist
Feb 20 19:11:01.779: INFO: namespace e2e-tests-services-qm9wc deletion completed in 7.733975797s
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:89

• [SLOW TEST:9.703 seconds]
[sig-network] Services
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:11:01.780: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-mt8mh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-ml2cx
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-vb62l
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:11:10.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-mt8mh" for this suite.
Feb 20 19:11:16.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:11:17.589: INFO: namespace: e2e-tests-namespaces-mt8mh, resource: bindings, ignored listing per whitelist
Feb 20 19:11:18.142: INFO: namespace e2e-tests-namespaces-mt8mh deletion completed in 7.738485982s
STEP: Destroying namespace "e2e-tests-nsdeletetest-ml2cx" for this suite.
Feb 20 19:11:18.185: INFO: Namespace e2e-tests-nsdeletetest-ml2cx was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-vb62l" for this suite.
Feb 20 19:11:24.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:11:25.508: INFO: namespace: e2e-tests-nsdeletetest-vb62l, resource: bindings, ignored listing per whitelist
Feb 20 19:11:26.051: INFO: namespace e2e-tests-nsdeletetest-vb62l deletion completed in 7.86587202s

• [SLOW TEST:24.271 seconds]
[sig-api-machinery] Namespaces [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:11:26.051: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-wjmfx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-wjmfx
I0220 19:11:27.828436   29709 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-wjmfx, replica count: 1
I0220 19:11:28.883041   29709 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0220 19:11:29.883278   29709 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 20 19:11:30.030: INFO: Created: latency-svc-7xnq9
Feb 20 19:11:30.034: INFO: Got endpoints: latency-svc-7xnq9 [50.955786ms]
Feb 20 19:11:30.082: INFO: Created: latency-svc-ml5ls
Feb 20 19:11:30.083: INFO: Got endpoints: latency-svc-ml5ls [49.141412ms]
Feb 20 19:11:30.088: INFO: Created: latency-svc-72xrz
Feb 20 19:11:30.091: INFO: Created: latency-svc-cnr7m
Feb 20 19:11:30.091: INFO: Got endpoints: latency-svc-72xrz [53.806292ms]
Feb 20 19:11:30.094: INFO: Got endpoints: latency-svc-cnr7m [56.765566ms]
Feb 20 19:11:30.094: INFO: Created: latency-svc-8ktz4
Feb 20 19:11:30.095: INFO: Got endpoints: latency-svc-8ktz4 [58.121189ms]
Feb 20 19:11:30.099: INFO: Created: latency-svc-tt55p
Feb 20 19:11:30.100: INFO: Got endpoints: latency-svc-tt55p [62.641326ms]
Feb 20 19:11:30.103: INFO: Created: latency-svc-jjtf5
Feb 20 19:11:30.104: INFO: Got endpoints: latency-svc-jjtf5 [66.418997ms]
Feb 20 19:11:30.106: INFO: Created: latency-svc-kdxv6
Feb 20 19:11:30.108: INFO: Got endpoints: latency-svc-kdxv6 [69.897477ms]
Feb 20 19:11:30.111: INFO: Created: latency-svc-h8jgr
Feb 20 19:11:30.112: INFO: Got endpoints: latency-svc-h8jgr [74.007059ms]
Feb 20 19:11:30.115: INFO: Created: latency-svc-bfqzl
Feb 20 19:11:30.117: INFO: Got endpoints: latency-svc-bfqzl [78.833214ms]
Feb 20 19:11:30.120: INFO: Created: latency-svc-drqll
Feb 20 19:11:30.124: INFO: Got endpoints: latency-svc-drqll [86.141112ms]
Feb 20 19:11:30.125: INFO: Created: latency-svc-btczg
Feb 20 19:11:30.127: INFO: Got endpoints: latency-svc-btczg [88.619795ms]
Feb 20 19:11:30.130: INFO: Created: latency-svc-vk9nr
Feb 20 19:11:30.131: INFO: Got endpoints: latency-svc-vk9nr [92.604044ms]
Feb 20 19:11:30.135: INFO: Created: latency-svc-v4mmf
Feb 20 19:11:30.139: INFO: Got endpoints: latency-svc-v4mmf [100.42691ms]
Feb 20 19:11:30.139: INFO: Created: latency-svc-ntpfc
Feb 20 19:11:30.142: INFO: Got endpoints: latency-svc-ntpfc [103.636545ms]
Feb 20 19:11:30.143: INFO: Created: latency-svc-g6ntj
Feb 20 19:11:30.144: INFO: Got endpoints: latency-svc-g6ntj [105.551521ms]
Feb 20 19:11:30.147: INFO: Created: latency-svc-564tp
Feb 20 19:11:30.150: INFO: Got endpoints: latency-svc-564tp [66.396771ms]
Feb 20 19:11:30.151: INFO: Created: latency-svc-8xjvl
Feb 20 19:11:30.155: INFO: Created: latency-svc-rsqpx
Feb 20 19:11:30.155: INFO: Got endpoints: latency-svc-8xjvl [64.609028ms]
Feb 20 19:11:30.163: INFO: Got endpoints: latency-svc-rsqpx [69.343646ms]
Feb 20 19:11:30.163: INFO: Created: latency-svc-f4qzg
Feb 20 19:11:30.165: INFO: Got endpoints: latency-svc-f4qzg [69.369861ms]
Feb 20 19:11:30.167: INFO: Created: latency-svc-xb7g4
Feb 20 19:11:30.169: INFO: Got endpoints: latency-svc-xb7g4 [68.698498ms]
Feb 20 19:11:30.172: INFO: Created: latency-svc-nwm5f
Feb 20 19:11:30.174: INFO: Got endpoints: latency-svc-nwm5f [70.406488ms]
Feb 20 19:11:30.176: INFO: Created: latency-svc-wrtjj
Feb 20 19:11:30.178: INFO: Got endpoints: latency-svc-wrtjj [70.382462ms]
Feb 20 19:11:30.181: INFO: Created: latency-svc-82gxx
Feb 20 19:11:30.183: INFO: Got endpoints: latency-svc-82gxx [70.89442ms]
Feb 20 19:11:30.186: INFO: Created: latency-svc-bh9rt
Feb 20 19:11:30.186: INFO: Got endpoints: latency-svc-bh9rt [69.189156ms]
Feb 20 19:11:30.189: INFO: Created: latency-svc-dj96w
Feb 20 19:11:30.190: INFO: Got endpoints: latency-svc-dj96w [66.274105ms]
Feb 20 19:11:30.193: INFO: Created: latency-svc-zcxbj
Feb 20 19:11:30.196: INFO: Created: latency-svc-68bfs
Feb 20 19:11:30.203: INFO: Created: latency-svc-bmwtn
Feb 20 19:11:30.208: INFO: Created: latency-svc-njtv6
Feb 20 19:11:30.213: INFO: Created: latency-svc-c6plw
Feb 20 19:11:30.217: INFO: Created: latency-svc-xl42l
Feb 20 19:11:30.223: INFO: Created: latency-svc-ljmd2
Feb 20 19:11:30.236: INFO: Created: latency-svc-lntll
Feb 20 19:11:30.236: INFO: Got endpoints: latency-svc-c6plw [91.99103ms]
Feb 20 19:11:30.236: INFO: Got endpoints: latency-svc-zcxbj [109.646525ms]
Feb 20 19:11:30.237: INFO: Got endpoints: latency-svc-68bfs [105.669428ms]
Feb 20 19:11:30.237: INFO: Got endpoints: latency-svc-njtv6 [94.555727ms]
Feb 20 19:11:30.237: INFO: Got endpoints: latency-svc-bmwtn [97.929961ms]
Feb 20 19:11:30.237: INFO: Got endpoints: latency-svc-lntll [73.740731ms]
Feb 20 19:11:30.237: INFO: Got endpoints: latency-svc-xl42l [87.317505ms]
Feb 20 19:11:30.237: INFO: Got endpoints: latency-svc-ljmd2 [81.842398ms]
Feb 20 19:11:30.239: INFO: Created: latency-svc-pr4f4
Feb 20 19:11:30.244: INFO: Created: latency-svc-9x6bc
Feb 20 19:11:30.247: INFO: Created: latency-svc-n6nsv
Feb 20 19:11:30.251: INFO: Created: latency-svc-4p7gk
Feb 20 19:11:30.255: INFO: Created: latency-svc-b8s69
Feb 20 19:11:30.259: INFO: Created: latency-svc-wjh8s
Feb 20 19:11:30.262: INFO: Created: latency-svc-zrxl8
Feb 20 19:11:30.281: INFO: Created: latency-svc-n9r4t
Feb 20 19:11:30.285: INFO: Got endpoints: latency-svc-pr4f4 [120.27686ms]
Feb 20 19:11:30.285: INFO: Created: latency-svc-96jz7
Feb 20 19:11:30.289: INFO: Created: latency-svc-2l8cv
Feb 20 19:11:30.293: INFO: Created: latency-svc-fc2vm
Feb 20 19:11:30.297: INFO: Created: latency-svc-b5lzp
Feb 20 19:11:30.300: INFO: Created: latency-svc-5x64v
Feb 20 19:11:30.304: INFO: Created: latency-svc-8jrgf
Feb 20 19:11:30.307: INFO: Created: latency-svc-t5x29
Feb 20 19:11:30.331: INFO: Created: latency-svc-xg7kb
Feb 20 19:11:30.334: INFO: Got endpoints: latency-svc-9x6bc [165.091999ms]
Feb 20 19:11:30.379: INFO: Created: latency-svc-qtwtp
Feb 20 19:11:30.384: INFO: Got endpoints: latency-svc-n6nsv [209.719936ms]
Feb 20 19:11:30.430: INFO: Created: latency-svc-sqh45
Feb 20 19:11:30.436: INFO: Got endpoints: latency-svc-4p7gk [257.651842ms]
Feb 20 19:11:30.481: INFO: Created: latency-svc-t8jhs
Feb 20 19:11:30.484: INFO: Got endpoints: latency-svc-b8s69 [300.977679ms]
Feb 20 19:11:30.530: INFO: Created: latency-svc-nz275
Feb 20 19:11:30.534: INFO: Got endpoints: latency-svc-wjh8s [348.01521ms]
Feb 20 19:11:30.579: INFO: Created: latency-svc-nwhmc
Feb 20 19:11:30.584: INFO: Got endpoints: latency-svc-zrxl8 [393.264107ms]
Feb 20 19:11:30.630: INFO: Created: latency-svc-9kx59
Feb 20 19:11:30.634: INFO: Got endpoints: latency-svc-n9r4t [398.196102ms]
Feb 20 19:11:30.681: INFO: Created: latency-svc-gmgmw
Feb 20 19:11:30.684: INFO: Got endpoints: latency-svc-96jz7 [447.599257ms]
Feb 20 19:11:30.730: INFO: Created: latency-svc-t6xb5
Feb 20 19:11:30.734: INFO: Got endpoints: latency-svc-2l8cv [497.23882ms]
Feb 20 19:11:30.780: INFO: Created: latency-svc-v2llt
Feb 20 19:11:30.784: INFO: Got endpoints: latency-svc-fc2vm [547.403506ms]
Feb 20 19:11:30.830: INFO: Created: latency-svc-htrvh
Feb 20 19:11:30.834: INFO: Got endpoints: latency-svc-b5lzp [596.93936ms]
Feb 20 19:11:30.882: INFO: Created: latency-svc-rzkrv
Feb 20 19:11:30.884: INFO: Got endpoints: latency-svc-5x64v [646.787039ms]
Feb 20 19:11:30.930: INFO: Created: latency-svc-4csfw
Feb 20 19:11:30.934: INFO: Got endpoints: latency-svc-8jrgf [696.777276ms]
Feb 20 19:11:30.982: INFO: Created: latency-svc-xbnkb
Feb 20 19:11:30.984: INFO: Got endpoints: latency-svc-t5x29 [747.195739ms]
Feb 20 19:11:31.032: INFO: Created: latency-svc-ffgj6
Feb 20 19:11:31.035: INFO: Got endpoints: latency-svc-xg7kb [749.705003ms]
Feb 20 19:11:31.080: INFO: Created: latency-svc-92sbk
Feb 20 19:11:31.084: INFO: Got endpoints: latency-svc-qtwtp [749.75258ms]
Feb 20 19:11:31.131: INFO: Created: latency-svc-9lpvz
Feb 20 19:11:31.134: INFO: Got endpoints: latency-svc-sqh45 [750.008788ms]
Feb 20 19:11:31.180: INFO: Created: latency-svc-w97gv
Feb 20 19:11:31.184: INFO: Got endpoints: latency-svc-t8jhs [748.149224ms]
Feb 20 19:11:31.230: INFO: Created: latency-svc-r4gmb
Feb 20 19:11:31.236: INFO: Got endpoints: latency-svc-nz275 [751.84962ms]
Feb 20 19:11:31.282: INFO: Created: latency-svc-cfp6g
Feb 20 19:11:31.284: INFO: Got endpoints: latency-svc-nwhmc [750.393143ms]
Feb 20 19:11:31.330: INFO: Created: latency-svc-gwrwt
Feb 20 19:11:31.334: INFO: Got endpoints: latency-svc-9kx59 [750.601666ms]
Feb 20 19:11:31.381: INFO: Created: latency-svc-gtf5s
Feb 20 19:11:31.384: INFO: Got endpoints: latency-svc-gmgmw [749.477572ms]
Feb 20 19:11:31.429: INFO: Created: latency-svc-prh6t
Feb 20 19:11:31.434: INFO: Got endpoints: latency-svc-t6xb5 [749.892137ms]
Feb 20 19:11:31.481: INFO: Created: latency-svc-lcn7s
Feb 20 19:11:31.484: INFO: Got endpoints: latency-svc-v2llt [749.897044ms]
Feb 20 19:11:31.529: INFO: Created: latency-svc-dvg2n
Feb 20 19:11:31.534: INFO: Got endpoints: latency-svc-htrvh [749.671088ms]
Feb 20 19:11:31.580: INFO: Created: latency-svc-gsg6r
Feb 20 19:11:31.584: INFO: Got endpoints: latency-svc-rzkrv [750.482712ms]
Feb 20 19:11:31.630: INFO: Created: latency-svc-vpbfq
Feb 20 19:11:31.636: INFO: Got endpoints: latency-svc-4csfw [751.602497ms]
Feb 20 19:11:31.682: INFO: Created: latency-svc-w2rdx
Feb 20 19:11:31.684: INFO: Got endpoints: latency-svc-xbnkb [749.785857ms]
Feb 20 19:11:31.730: INFO: Created: latency-svc-fvrtc
Feb 20 19:11:31.734: INFO: Got endpoints: latency-svc-ffgj6 [750.236053ms]
Feb 20 19:11:31.780: INFO: Created: latency-svc-tp8dh
Feb 20 19:11:31.784: INFO: Got endpoints: latency-svc-92sbk [748.904ms]
Feb 20 19:11:31.829: INFO: Created: latency-svc-lp8sr
Feb 20 19:11:31.834: INFO: Got endpoints: latency-svc-9lpvz [750.228772ms]
Feb 20 19:11:31.881: INFO: Created: latency-svc-rlfj6
Feb 20 19:11:31.884: INFO: Got endpoints: latency-svc-w97gv [749.884198ms]
Feb 20 19:11:31.931: INFO: Created: latency-svc-brg6j
Feb 20 19:11:31.934: INFO: Got endpoints: latency-svc-r4gmb [750.077693ms]
Feb 20 19:11:31.979: INFO: Created: latency-svc-pbqzn
Feb 20 19:11:31.984: INFO: Got endpoints: latency-svc-cfp6g [748.267418ms]
Feb 20 19:11:32.030: INFO: Created: latency-svc-cpfjm
Feb 20 19:11:32.034: INFO: Got endpoints: latency-svc-gwrwt [749.748487ms]
Feb 20 19:11:32.084: INFO: Got endpoints: latency-svc-gtf5s [749.693013ms]
Feb 20 19:11:32.085: INFO: Created: latency-svc-2gmbw
Feb 20 19:11:32.136: INFO: Got endpoints: latency-svc-prh6t [751.858146ms]
Feb 20 19:11:32.136: INFO: Created: latency-svc-8dpqk
Feb 20 19:11:32.181: INFO: Created: latency-svc-6zzw4
Feb 20 19:11:32.184: INFO: Got endpoints: latency-svc-lcn7s [749.708778ms]
Feb 20 19:11:32.230: INFO: Created: latency-svc-9tv27
Feb 20 19:11:32.234: INFO: Got endpoints: latency-svc-dvg2n [749.9357ms]
Feb 20 19:11:32.280: INFO: Created: latency-svc-tww6t
Feb 20 19:11:32.286: INFO: Got endpoints: latency-svc-gsg6r [752.49667ms]
Feb 20 19:11:32.335: INFO: Got endpoints: latency-svc-vpbfq [750.563346ms]
Feb 20 19:11:32.335: INFO: Created: latency-svc-sntxq
Feb 20 19:11:32.381: INFO: Created: latency-svc-lh665
Feb 20 19:11:32.384: INFO: Got endpoints: latency-svc-w2rdx [748.28593ms]
Feb 20 19:11:32.433: INFO: Created: latency-svc-svt7p
Feb 20 19:11:32.434: INFO: Got endpoints: latency-svc-fvrtc [750.391581ms]
Feb 20 19:11:32.481: INFO: Created: latency-svc-sx772
Feb 20 19:11:32.487: INFO: Got endpoints: latency-svc-tp8dh [752.686633ms]
Feb 20 19:11:32.533: INFO: Created: latency-svc-p4sm7
Feb 20 19:11:32.534: INFO: Got endpoints: latency-svc-lp8sr [750.320964ms]
Feb 20 19:11:32.580: INFO: Created: latency-svc-gdnhm
Feb 20 19:11:32.584: INFO: Got endpoints: latency-svc-rlfj6 [750.074469ms]
Feb 20 19:11:32.630: INFO: Created: latency-svc-h6sdn
Feb 20 19:11:32.635: INFO: Got endpoints: latency-svc-brg6j [750.628934ms]
Feb 20 19:11:32.682: INFO: Created: latency-svc-5trsg
Feb 20 19:11:32.684: INFO: Got endpoints: latency-svc-pbqzn [750.193289ms]
Feb 20 19:11:32.730: INFO: Created: latency-svc-t5lc4
Feb 20 19:11:32.734: INFO: Got endpoints: latency-svc-cpfjm [749.963255ms]
Feb 20 19:11:32.782: INFO: Created: latency-svc-dqngf
Feb 20 19:11:32.785: INFO: Got endpoints: latency-svc-2gmbw [750.281924ms]
Feb 20 19:11:32.832: INFO: Created: latency-svc-6dr68
Feb 20 19:11:32.834: INFO: Got endpoints: latency-svc-8dpqk [749.646224ms]
Feb 20 19:11:32.884: INFO: Created: latency-svc-f7zsq
Feb 20 19:11:32.886: INFO: Got endpoints: latency-svc-6zzw4 [749.686194ms]
Feb 20 19:11:32.935: INFO: Got endpoints: latency-svc-9tv27 [751.122206ms]
Feb 20 19:11:32.935: INFO: Created: latency-svc-q552r
Feb 20 19:11:32.982: INFO: Created: latency-svc-wn5v5
Feb 20 19:11:32.985: INFO: Got endpoints: latency-svc-tww6t [750.934417ms]
Feb 20 19:11:33.034: INFO: Got endpoints: latency-svc-sntxq [747.496024ms]
Feb 20 19:11:33.034: INFO: Created: latency-svc-74msq
Feb 20 19:11:33.080: INFO: Created: latency-svc-s7svk
Feb 20 19:11:33.084: INFO: Got endpoints: latency-svc-lh665 [748.672767ms]
Feb 20 19:11:33.132: INFO: Created: latency-svc-l5lds
Feb 20 19:11:33.134: INFO: Got endpoints: latency-svc-svt7p [749.741961ms]
Feb 20 19:11:33.180: INFO: Created: latency-svc-sngps
Feb 20 19:11:33.184: INFO: Got endpoints: latency-svc-sx772 [749.423727ms]
Feb 20 19:11:33.231: INFO: Created: latency-svc-pdkkc
Feb 20 19:11:33.237: INFO: Got endpoints: latency-svc-p4sm7 [749.551404ms]
Feb 20 19:11:33.286: INFO: Got endpoints: latency-svc-gdnhm [751.794675ms]
Feb 20 19:11:33.286: INFO: Created: latency-svc-jqnxg
Feb 20 19:11:33.334: INFO: Created: latency-svc-gd7pm
Feb 20 19:11:33.335: INFO: Got endpoints: latency-svc-h6sdn [751.020195ms]
Feb 20 19:11:33.381: INFO: Created: latency-svc-wgdwl
Feb 20 19:11:33.384: INFO: Got endpoints: latency-svc-5trsg [749.537895ms]
Feb 20 19:11:33.431: INFO: Created: latency-svc-dzjnj
Feb 20 19:11:33.435: INFO: Got endpoints: latency-svc-t5lc4 [750.702467ms]
Feb 20 19:11:33.481: INFO: Created: latency-svc-vjx4b
Feb 20 19:11:33.486: INFO: Got endpoints: latency-svc-dqngf [752.100037ms]
Feb 20 19:11:33.532: INFO: Created: latency-svc-9xf7k
Feb 20 19:11:33.534: INFO: Got endpoints: latency-svc-6dr68 [749.322452ms]
Feb 20 19:11:33.580: INFO: Created: latency-svc-49ndf
Feb 20 19:11:33.584: INFO: Got endpoints: latency-svc-f7zsq [749.663548ms]
Feb 20 19:11:33.630: INFO: Created: latency-svc-8rfpz
Feb 20 19:11:33.635: INFO: Got endpoints: latency-svc-q552r [748.93806ms]
Feb 20 19:11:33.681: INFO: Created: latency-svc-bvlz8
Feb 20 19:11:33.684: INFO: Got endpoints: latency-svc-wn5v5 [748.850859ms]
Feb 20 19:11:33.729: INFO: Created: latency-svc-x85tc
Feb 20 19:11:33.734: INFO: Got endpoints: latency-svc-74msq [748.905012ms]
Feb 20 19:11:33.780: INFO: Created: latency-svc-xkfxt
Feb 20 19:11:33.784: INFO: Got endpoints: latency-svc-s7svk [749.714747ms]
Feb 20 19:11:33.830: INFO: Created: latency-svc-wczr8
Feb 20 19:11:33.834: INFO: Got endpoints: latency-svc-l5lds [750.114648ms]
Feb 20 19:11:33.880: INFO: Created: latency-svc-9hqdm
Feb 20 19:11:33.884: INFO: Got endpoints: latency-svc-sngps [750.307789ms]
Feb 20 19:11:33.930: INFO: Created: latency-svc-txjq2
Feb 20 19:11:33.934: INFO: Got endpoints: latency-svc-pdkkc [749.813761ms]
Feb 20 19:11:33.980: INFO: Created: latency-svc-fjbwg
Feb 20 19:11:33.984: INFO: Got endpoints: latency-svc-jqnxg [747.197026ms]
Feb 20 19:11:34.030: INFO: Created: latency-svc-g5d8b
Feb 20 19:11:34.034: INFO: Got endpoints: latency-svc-gd7pm [747.923264ms]
Feb 20 19:11:34.080: INFO: Created: latency-svc-w58hz
Feb 20 19:11:34.084: INFO: Got endpoints: latency-svc-wgdwl [748.657888ms]
Feb 20 19:11:34.130: INFO: Created: latency-svc-wzghd
Feb 20 19:11:34.135: INFO: Got endpoints: latency-svc-dzjnj [749.941586ms]
Feb 20 19:11:34.180: INFO: Created: latency-svc-45c45
Feb 20 19:11:34.184: INFO: Got endpoints: latency-svc-vjx4b [749.375626ms]
Feb 20 19:11:34.230: INFO: Created: latency-svc-qvplg
Feb 20 19:11:34.234: INFO: Got endpoints: latency-svc-9xf7k [747.785955ms]
Feb 20 19:11:34.281: INFO: Created: latency-svc-pf88g
Feb 20 19:11:34.284: INFO: Got endpoints: latency-svc-49ndf [749.896929ms]
Feb 20 19:11:34.330: INFO: Created: latency-svc-tjthn
Feb 20 19:11:34.334: INFO: Got endpoints: latency-svc-8rfpz [750.107192ms]
Feb 20 19:11:34.382: INFO: Created: latency-svc-r7mn9
Feb 20 19:11:34.384: INFO: Got endpoints: latency-svc-bvlz8 [749.53675ms]
Feb 20 19:11:34.433: INFO: Created: latency-svc-6jffm
Feb 20 19:11:34.434: INFO: Got endpoints: latency-svc-x85tc [749.897002ms]
Feb 20 19:11:34.479: INFO: Created: latency-svc-4f7bf
Feb 20 19:11:34.485: INFO: Got endpoints: latency-svc-xkfxt [750.820272ms]
Feb 20 19:11:34.534: INFO: Created: latency-svc-jtm9j
Feb 20 19:11:34.534: INFO: Got endpoints: latency-svc-wczr8 [750.536737ms]
Feb 20 19:11:34.580: INFO: Created: latency-svc-qcp9f
Feb 20 19:11:34.584: INFO: Got endpoints: latency-svc-9hqdm [749.899254ms]
Feb 20 19:11:34.630: INFO: Created: latency-svc-4f6gx
Feb 20 19:11:34.634: INFO: Got endpoints: latency-svc-txjq2 [749.839612ms]
Feb 20 19:11:34.681: INFO: Created: latency-svc-wb2df
Feb 20 19:11:34.684: INFO: Got endpoints: latency-svc-fjbwg [750.069251ms]
Feb 20 19:11:34.733: INFO: Created: latency-svc-jjxpr
Feb 20 19:11:34.734: INFO: Got endpoints: latency-svc-g5d8b [749.824154ms]
Feb 20 19:11:34.780: INFO: Created: latency-svc-pcr2k
Feb 20 19:11:34.784: INFO: Got endpoints: latency-svc-w58hz [750.361127ms]
Feb 20 19:11:34.831: INFO: Created: latency-svc-ptm4p
Feb 20 19:11:34.834: INFO: Got endpoints: latency-svc-wzghd [749.940853ms]
Feb 20 19:11:34.880: INFO: Created: latency-svc-58xs2
Feb 20 19:11:34.884: INFO: Got endpoints: latency-svc-45c45 [749.14042ms]
Feb 20 19:11:34.930: INFO: Created: latency-svc-mps9d
Feb 20 19:11:34.934: INFO: Got endpoints: latency-svc-qvplg [749.660002ms]
Feb 20 19:11:34.980: INFO: Created: latency-svc-rzj27
Feb 20 19:11:34.984: INFO: Got endpoints: latency-svc-pf88g [749.988418ms]
Feb 20 19:11:35.036: INFO: Got endpoints: latency-svc-tjthn [752.259703ms]
Feb 20 19:11:35.037: INFO: Created: latency-svc-7sgtn
Feb 20 19:11:35.138: INFO: Got endpoints: latency-svc-r7mn9 [803.889781ms]
Feb 20 19:11:35.138: INFO: Got endpoints: latency-svc-6jffm [753.883859ms]
Feb 20 19:11:35.141: INFO: Created: latency-svc-fvwsl
Feb 20 19:11:35.183: INFO: Created: latency-svc-fqtn4
Feb 20 19:11:35.185: INFO: Got endpoints: latency-svc-4f7bf [751.10474ms]
Feb 20 19:11:35.187: INFO: Created: latency-svc-nsrdg
Feb 20 19:11:35.231: INFO: Created: latency-svc-c6x2r
Feb 20 19:11:35.234: INFO: Got endpoints: latency-svc-jtm9j [749.120908ms]
Feb 20 19:11:35.279: INFO: Created: latency-svc-n82ll
Feb 20 19:11:35.284: INFO: Got endpoints: latency-svc-qcp9f [749.475239ms]
Feb 20 19:11:35.330: INFO: Created: latency-svc-tfxcb
Feb 20 19:11:35.334: INFO: Got endpoints: latency-svc-4f6gx [749.839356ms]
Feb 20 19:11:35.379: INFO: Created: latency-svc-nbntk
Feb 20 19:11:35.384: INFO: Got endpoints: latency-svc-wb2df [749.846473ms]
Feb 20 19:11:35.429: INFO: Created: latency-svc-7k5jr
Feb 20 19:11:35.434: INFO: Got endpoints: latency-svc-jjxpr [749.921264ms]
Feb 20 19:11:35.479: INFO: Created: latency-svc-mb9tc
Feb 20 19:11:35.484: INFO: Got endpoints: latency-svc-pcr2k [750.061951ms]
Feb 20 19:11:35.529: INFO: Created: latency-svc-6qpl6
Feb 20 19:11:35.534: INFO: Got endpoints: latency-svc-ptm4p [749.714061ms]
Feb 20 19:11:35.580: INFO: Created: latency-svc-b2794
Feb 20 19:11:35.584: INFO: Got endpoints: latency-svc-58xs2 [750.069588ms]
Feb 20 19:11:35.630: INFO: Created: latency-svc-jxnh8
Feb 20 19:11:35.634: INFO: Got endpoints: latency-svc-mps9d [750.157691ms]
Feb 20 19:11:35.679: INFO: Created: latency-svc-mfpfw
Feb 20 19:11:35.684: INFO: Got endpoints: latency-svc-rzj27 [750.086315ms]
Feb 20 19:11:35.733: INFO: Created: latency-svc-l8pdk
Feb 20 19:11:35.734: INFO: Got endpoints: latency-svc-7sgtn [749.996931ms]
Feb 20 19:11:35.780: INFO: Created: latency-svc-6jkfm
Feb 20 19:11:35.784: INFO: Got endpoints: latency-svc-fvwsl [747.590892ms]
Feb 20 19:11:35.833: INFO: Created: latency-svc-tdtwr
Feb 20 19:11:35.835: INFO: Got endpoints: latency-svc-fqtn4 [696.732764ms]
Feb 20 19:11:35.881: INFO: Created: latency-svc-tg58p
Feb 20 19:11:35.884: INFO: Got endpoints: latency-svc-nsrdg [745.793679ms]
Feb 20 19:11:35.929: INFO: Created: latency-svc-svrb9
Feb 20 19:11:35.934: INFO: Got endpoints: latency-svc-c6x2r [748.74671ms]
Feb 20 19:11:35.981: INFO: Created: latency-svc-57bzh
Feb 20 19:11:35.984: INFO: Got endpoints: latency-svc-n82ll [749.972325ms]
Feb 20 19:11:36.030: INFO: Created: latency-svc-5zn8j
Feb 20 19:11:36.037: INFO: Got endpoints: latency-svc-tfxcb [752.632433ms]
Feb 20 19:11:36.083: INFO: Created: latency-svc-q2g56
Feb 20 19:11:36.084: INFO: Got endpoints: latency-svc-nbntk [749.908342ms]
Feb 20 19:11:36.130: INFO: Created: latency-svc-l8ztl
Feb 20 19:11:36.134: INFO: Got endpoints: latency-svc-7k5jr [750.557295ms]
Feb 20 19:11:36.180: INFO: Created: latency-svc-4cmgw
Feb 20 19:11:36.184: INFO: Got endpoints: latency-svc-mb9tc [749.922841ms]
Feb 20 19:11:36.229: INFO: Created: latency-svc-z27vn
Feb 20 19:11:36.238: INFO: Got endpoints: latency-svc-6qpl6 [754.200847ms]
Feb 20 19:11:36.283: INFO: Created: latency-svc-k5n2p
Feb 20 19:11:36.284: INFO: Got endpoints: latency-svc-b2794 [749.679046ms]
Feb 20 19:11:36.329: INFO: Created: latency-svc-kt2t8
Feb 20 19:11:36.334: INFO: Got endpoints: latency-svc-jxnh8 [750.276866ms]
Feb 20 19:11:36.380: INFO: Created: latency-svc-bs9xq
Feb 20 19:11:36.384: INFO: Got endpoints: latency-svc-mfpfw [749.82345ms]
Feb 20 19:11:36.430: INFO: Created: latency-svc-gcq7f
Feb 20 19:11:36.434: INFO: Got endpoints: latency-svc-l8pdk [749.881583ms]
Feb 20 19:11:36.480: INFO: Created: latency-svc-n6zvx
Feb 20 19:11:36.485: INFO: Got endpoints: latency-svc-6jkfm [750.86695ms]
Feb 20 19:11:36.531: INFO: Created: latency-svc-6jj6p
Feb 20 19:11:36.534: INFO: Got endpoints: latency-svc-tdtwr [750.097329ms]
Feb 20 19:11:36.580: INFO: Created: latency-svc-vc85x
Feb 20 19:11:36.635: INFO: Got endpoints: latency-svc-svrb9 [750.913992ms]
Feb 20 19:11:36.635: INFO: Got endpoints: latency-svc-tg58p [800.511467ms]
Feb 20 19:11:36.681: INFO: Created: latency-svc-j2m4r
Feb 20 19:11:36.684: INFO: Created: latency-svc-k97fn
Feb 20 19:11:36.735: INFO: Got endpoints: latency-svc-57bzh [801.619056ms]
Feb 20 19:11:36.736: INFO: Got endpoints: latency-svc-5zn8j [752.058595ms]
Feb 20 19:11:36.782: INFO: Created: latency-svc-rnk7w
Feb 20 19:11:36.794: INFO: Created: latency-svc-2v8zg
Feb 20 19:11:36.794: INFO: Got endpoints: latency-svc-q2g56 [757.576165ms]
Feb 20 19:11:36.834: INFO: Got endpoints: latency-svc-l8ztl [750.24409ms]
Feb 20 19:11:36.840: INFO: Created: latency-svc-pfbqp
Feb 20 19:11:36.880: INFO: Created: latency-svc-rfjbc
Feb 20 19:11:36.884: INFO: Got endpoints: latency-svc-4cmgw [749.597001ms]
Feb 20 19:11:36.930: INFO: Created: latency-svc-d7wx5
Feb 20 19:11:36.934: INFO: Got endpoints: latency-svc-z27vn [750.06183ms]
Feb 20 19:11:36.979: INFO: Created: latency-svc-x2shm
Feb 20 19:11:36.984: INFO: Got endpoints: latency-svc-k5n2p [746.226139ms]
Feb 20 19:11:37.030: INFO: Created: latency-svc-sfl48
Feb 20 19:11:37.034: INFO: Got endpoints: latency-svc-kt2t8 [750.328746ms]
Feb 20 19:11:37.080: INFO: Created: latency-svc-m7mq4
Feb 20 19:11:37.084: INFO: Got endpoints: latency-svc-bs9xq [749.839933ms]
Feb 20 19:11:37.131: INFO: Created: latency-svc-6h9gj
Feb 20 19:11:37.134: INFO: Got endpoints: latency-svc-gcq7f [750.023375ms]
Feb 20 19:11:37.180: INFO: Created: latency-svc-dw6x8
Feb 20 19:11:37.184: INFO: Got endpoints: latency-svc-n6zvx [749.806311ms]
Feb 20 19:11:37.229: INFO: Created: latency-svc-ll6ns
Feb 20 19:11:37.234: INFO: Got endpoints: latency-svc-6jj6p [748.903159ms]
Feb 20 19:11:37.282: INFO: Created: latency-svc-th6sw
Feb 20 19:11:37.284: INFO: Got endpoints: latency-svc-vc85x [749.956205ms]
Feb 20 19:11:37.330: INFO: Created: latency-svc-68p7w
Feb 20 19:11:37.334: INFO: Got endpoints: latency-svc-j2m4r [698.993424ms]
Feb 20 19:11:37.382: INFO: Created: latency-svc-ljtb6
Feb 20 19:11:37.384: INFO: Got endpoints: latency-svc-k97fn [748.495864ms]
Feb 20 19:11:37.429: INFO: Created: latency-svc-24ndk
Feb 20 19:11:37.434: INFO: Got endpoints: latency-svc-rnk7w [698.001405ms]
Feb 20 19:11:37.480: INFO: Created: latency-svc-g7t4v
Feb 20 19:11:37.485: INFO: Got endpoints: latency-svc-2v8zg [749.635554ms]
Feb 20 19:11:37.531: INFO: Created: latency-svc-4ktsn
Feb 20 19:11:37.534: INFO: Got endpoints: latency-svc-pfbqp [739.600194ms]
Feb 20 19:11:37.581: INFO: Created: latency-svc-sp2zv
Feb 20 19:11:37.584: INFO: Got endpoints: latency-svc-rfjbc [750.247476ms]
Feb 20 19:11:37.630: INFO: Created: latency-svc-cdgf4
Feb 20 19:11:37.634: INFO: Got endpoints: latency-svc-d7wx5 [749.767421ms]
Feb 20 19:11:37.680: INFO: Created: latency-svc-c452z
Feb 20 19:11:37.684: INFO: Got endpoints: latency-svc-x2shm [749.775247ms]
Feb 20 19:11:37.729: INFO: Created: latency-svc-cpvml
Feb 20 19:11:37.734: INFO: Got endpoints: latency-svc-sfl48 [749.594683ms]
Feb 20 19:11:37.780: INFO: Created: latency-svc-dn9wd
Feb 20 19:11:37.784: INFO: Got endpoints: latency-svc-m7mq4 [749.929198ms]
Feb 20 19:11:37.831: INFO: Created: latency-svc-vnp9k
Feb 20 19:11:37.834: INFO: Got endpoints: latency-svc-6h9gj [750.067866ms]
Feb 20 19:11:37.880: INFO: Created: latency-svc-qj8s7
Feb 20 19:11:37.884: INFO: Got endpoints: latency-svc-dw6x8 [750.091145ms]
Feb 20 19:11:37.934: INFO: Got endpoints: latency-svc-ll6ns [750.389719ms]
Feb 20 19:11:37.984: INFO: Got endpoints: latency-svc-th6sw [750.362237ms]
Feb 20 19:11:38.034: INFO: Got endpoints: latency-svc-68p7w [750.381178ms]
Feb 20 19:11:38.084: INFO: Got endpoints: latency-svc-ljtb6 [750.292483ms]
Feb 20 19:11:38.134: INFO: Got endpoints: latency-svc-24ndk [750.265071ms]
Feb 20 19:11:38.186: INFO: Got endpoints: latency-svc-g7t4v [751.755857ms]
Feb 20 19:11:38.235: INFO: Got endpoints: latency-svc-4ktsn [749.347772ms]
Feb 20 19:11:38.284: INFO: Got endpoints: latency-svc-sp2zv [750.395346ms]
Feb 20 19:11:38.334: INFO: Got endpoints: latency-svc-cdgf4 [750.110638ms]
Feb 20 19:11:38.384: INFO: Got endpoints: latency-svc-c452z [750.193401ms]
Feb 20 19:11:38.434: INFO: Got endpoints: latency-svc-cpvml [750.417937ms]
Feb 20 19:11:38.484: INFO: Got endpoints: latency-svc-dn9wd [750.463757ms]
Feb 20 19:11:38.534: INFO: Got endpoints: latency-svc-vnp9k [750.177066ms]
Feb 20 19:11:38.584: INFO: Got endpoints: latency-svc-qj8s7 [749.644956ms]
Feb 20 19:11:38.584: INFO: Latencies: [49.141412ms 53.806292ms 56.765566ms 58.121189ms 62.641326ms 64.609028ms 66.274105ms 66.396771ms 66.418997ms 68.698498ms 69.189156ms 69.343646ms 69.369861ms 69.897477ms 70.382462ms 70.406488ms 70.89442ms 73.740731ms 74.007059ms 78.833214ms 81.842398ms 86.141112ms 87.317505ms 88.619795ms 91.99103ms 92.604044ms 94.555727ms 97.929961ms 100.42691ms 103.636545ms 105.551521ms 105.669428ms 109.646525ms 120.27686ms 165.091999ms 209.719936ms 257.651842ms 300.977679ms 348.01521ms 393.264107ms 398.196102ms 447.599257ms 497.23882ms 547.403506ms 596.93936ms 646.787039ms 696.732764ms 696.777276ms 698.001405ms 698.993424ms 739.600194ms 745.793679ms 746.226139ms 747.195739ms 747.197026ms 747.496024ms 747.590892ms 747.785955ms 747.923264ms 748.149224ms 748.267418ms 748.28593ms 748.495864ms 748.657888ms 748.672767ms 748.74671ms 748.850859ms 748.903159ms 748.904ms 748.905012ms 748.93806ms 749.120908ms 749.14042ms 749.322452ms 749.347772ms 749.375626ms 749.423727ms 749.475239ms 749.477572ms 749.53675ms 749.537895ms 749.551404ms 749.594683ms 749.597001ms 749.635554ms 749.644956ms 749.646224ms 749.660002ms 749.663548ms 749.671088ms 749.679046ms 749.686194ms 749.693013ms 749.705003ms 749.708778ms 749.714061ms 749.714747ms 749.741961ms 749.748487ms 749.75258ms 749.767421ms 749.775247ms 749.785857ms 749.806311ms 749.813761ms 749.82345ms 749.824154ms 749.839356ms 749.839612ms 749.839933ms 749.846473ms 749.881583ms 749.884198ms 749.892137ms 749.896929ms 749.897002ms 749.897044ms 749.899254ms 749.908342ms 749.921264ms 749.922841ms 749.929198ms 749.9357ms 749.940853ms 749.941586ms 749.956205ms 749.963255ms 749.972325ms 749.988418ms 749.996931ms 750.008788ms 750.023375ms 750.06183ms 750.061951ms 750.067866ms 750.069251ms 750.069588ms 750.074469ms 750.077693ms 750.086315ms 750.091145ms 750.097329ms 750.107192ms 750.110638ms 750.114648ms 750.157691ms 750.177066ms 750.193289ms 750.193401ms 750.228772ms 750.236053ms 750.24409ms 750.247476ms 750.265071ms 750.276866ms 750.281924ms 750.292483ms 750.307789ms 750.320964ms 750.328746ms 750.361127ms 750.362237ms 750.381178ms 750.389719ms 750.391581ms 750.393143ms 750.395346ms 750.417937ms 750.463757ms 750.482712ms 750.536737ms 750.557295ms 750.563346ms 750.601666ms 750.628934ms 750.702467ms 750.820272ms 750.86695ms 750.913992ms 750.934417ms 751.020195ms 751.10474ms 751.122206ms 751.602497ms 751.755857ms 751.794675ms 751.84962ms 751.858146ms 752.058595ms 752.100037ms 752.259703ms 752.49667ms 752.632433ms 752.686633ms 753.883859ms 754.200847ms 757.576165ms 800.511467ms 801.619056ms 803.889781ms]
Feb 20 19:11:38.584: INFO: 50 %ile: 749.767421ms
Feb 20 19:11:38.584: INFO: 90 %ile: 751.020195ms
Feb 20 19:11:38.584: INFO: 99 %ile: 801.619056ms
Feb 20 19:11:38.584: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:11:38.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-wjmfx" for this suite.
Feb 20 19:11:48.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:11:49.970: INFO: namespace: e2e-tests-svc-latency-wjmfx, resource: bindings, ignored listing per whitelist
Feb 20 19:11:50.346: INFO: namespace e2e-tests-svc-latency-wjmfx deletion completed in 11.719124098s

• [SLOW TEST:24.295 seconds]
[sig-network] Service endpoints latency
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:11:50.346: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-zhv6h
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 20 19:11:52.069: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:11:56.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-zhv6h" for this suite.
Feb 20 19:12:18.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:12:19.212: INFO: namespace: e2e-tests-init-container-zhv6h, resource: bindings, ignored listing per whitelist
Feb 20 19:12:20.228: INFO: namespace e2e-tests-init-container-zhv6h deletion completed in 23.774869215s

• [SLOW TEST:29.884 seconds]
[k8s.io] InitContainer [NodeConformance]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:12:20.231: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-rqc9w
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 19:12:22.057: INFO: (0) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 45.677148ms)
Feb 20 19:12:22.102: INFO: (1) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 44.60801ms)
Feb 20 19:12:22.146: INFO: (2) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.955941ms)
Feb 20 19:12:22.190: INFO: (3) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.708497ms)
Feb 20 19:12:22.234: INFO: (4) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 44.475331ms)
Feb 20 19:12:22.278: INFO: (5) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.564775ms)
Feb 20 19:12:22.322: INFO: (6) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.870576ms)
Feb 20 19:12:22.366: INFO: (7) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 44.183234ms)
Feb 20 19:12:22.410: INFO: (8) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 44.127487ms)
Feb 20 19:12:22.454: INFO: (9) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.675803ms)
Feb 20 19:12:22.498: INFO: (10) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.981896ms)
Feb 20 19:12:22.542: INFO: (11) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.966745ms)
Feb 20 19:12:22.630: INFO: (12) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 87.257593ms)
Feb 20 19:12:22.674: INFO: (13) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 44.381404ms)
Feb 20 19:12:22.719: INFO: (14) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 44.46338ms)
Feb 20 19:12:22.762: INFO: (15) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.699868ms)
Feb 20 19:12:22.806: INFO: (16) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.78634ms)
Feb 20 19:12:22.850: INFO: (17) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.886275ms)
Feb 20 19:12:22.895: INFO: (18) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 45.065525ms)
Feb 20 19:12:22.940: INFO: (19) /api/v1/nodes/ip-10-250-29-201.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 44.620348ms)
[AfterEach] version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:12:22.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-rqc9w" for this suite.
Feb 20 19:12:29.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:12:30.482: INFO: namespace: e2e-tests-proxy-rqc9w, resource: bindings, ignored listing per whitelist
Feb 20 19:12:30.776: INFO: namespace e2e-tests-proxy-rqc9w deletion completed in 7.793110375s

• [SLOW TEST:10.545 seconds]
[sig-network] Proxy
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:12:30.776: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-zp8kw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-zp8kw A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-zp8kw;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-zp8kw A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-zp8kw;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-zp8kw.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-zp8kw.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-zp8kw.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-zp8kw.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-zp8kw.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-zp8kw.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-zp8kw.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zp8kw.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-zp8kw.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-zp8kw.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-zp8kw.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-zp8kw.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-zp8kw.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 40.9.69.100.in-addr.arpa. PTR)" && echo OK > /results/100.69.9.40_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 40.9.69.100.in-addr.arpa. PTR)" && echo OK > /results/100.69.9.40_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-zp8kw A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-zp8kw;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-zp8kw A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-zp8kw;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-zp8kw.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-zp8kw.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-zp8kw.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-zp8kw.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-zp8kw.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-zp8kw.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-zp8kw.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zp8kw.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-zp8kw.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-zp8kw.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-zp8kw.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-zp8kw.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-zp8kw.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 40.9.69.100.in-addr.arpa. PTR)" && echo OK > /results/100.69.9.40_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 40.9.69.100.in-addr.arpa. PTR)" && echo OK > /results/100.69.9.40_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 20 19:12:44.926: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:44.970: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:45.014: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-zp8kw from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:45.061: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-zp8kw from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:45.109: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-zp8kw.svc from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:45.153: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-zp8kw.svc from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:45.198: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-zp8kw.svc from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:45.242: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zp8kw.svc from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:45.559: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:45.603: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:45.647: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-zp8kw from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:45.693: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-zp8kw from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:45.739: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-zp8kw.svc from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:45.785: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-zp8kw.svc from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:45.830: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-zp8kw.svc from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:45.874: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zp8kw.svc from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:46.151: INFO: Lookups using e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-zp8kw wheezy_tcp@dns-test-service.e2e-tests-dns-zp8kw wheezy_udp@dns-test-service.e2e-tests-dns-zp8kw.svc wheezy_tcp@dns-test-service.e2e-tests-dns-zp8kw.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-zp8kw.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zp8kw.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-zp8kw jessie_tcp@dns-test-service.e2e-tests-dns-zp8kw jessie_udp@dns-test-service.e2e-tests-dns-zp8kw.svc jessie_tcp@dns-test-service.e2e-tests-dns-zp8kw.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-zp8kw.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zp8kw.svc]

Feb 20 19:12:54.864: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:54.911: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:54.955: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-zp8kw from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:54.998: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-zp8kw from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:55.042: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-zp8kw.svc from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:55.086: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-zp8kw.svc from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:55.130: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-zp8kw.svc from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:55.174: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zp8kw.svc from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:55.490: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:55.534: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:55.578: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-zp8kw from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:55.622: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-zp8kw from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:55.666: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-zp8kw.svc from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:55.710: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-zp8kw.svc from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:55.754: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-zp8kw.svc from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:55.802: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zp8kw.svc from pod e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b: the server could not find the requested resource (get pods dns-test-79595624-3543-11e9-997a-8a6f774fb32b)
Feb 20 19:12:56.067: INFO: Lookups using e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-zp8kw wheezy_tcp@dns-test-service.e2e-tests-dns-zp8kw wheezy_udp@dns-test-service.e2e-tests-dns-zp8kw.svc wheezy_tcp@dns-test-service.e2e-tests-dns-zp8kw.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-zp8kw.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zp8kw.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-zp8kw jessie_tcp@dns-test-service.e2e-tests-dns-zp8kw jessie_udp@dns-test-service.e2e-tests-dns-zp8kw.svc jessie_tcp@dns-test-service.e2e-tests-dns-zp8kw.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-zp8kw.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-zp8kw.svc]

Feb 20 19:13:06.092: INFO: DNS probes using e2e-tests-dns-zp8kw/dns-test-79595624-3543-11e9-997a-8a6f774fb32b succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:13:06.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-zp8kw" for this suite.
Feb 20 19:13:12.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:13:13.465: INFO: namespace: e2e-tests-dns-zp8kw, resource: bindings, ignored listing per whitelist
Feb 20 19:13:14.060: INFO: namespace e2e-tests-dns-zp8kw deletion completed in 7.786963482s

• [SLOW TEST:43.284 seconds]
[sig-network] DNS
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:13:14.060: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-zjkk7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Feb 20 19:13:16.107: INFO: Waiting up to 5m0s for pod "client-containers-9339e053-3543-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-containers-zjkk7" to be "success or failure"
Feb 20 19:13:16.148: INFO: Pod "client-containers-9339e053-3543-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.521654ms
Feb 20 19:13:18.192: INFO: Pod "client-containers-9339e053-3543-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085320021s
STEP: Saw pod success
Feb 20 19:13:18.192: INFO: Pod "client-containers-9339e053-3543-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:13:18.236: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod client-containers-9339e053-3543-11e9-997a-8a6f774fb32b container test-container: <nil>
STEP: delete the pod
Feb 20 19:13:18.332: INFO: Waiting for pod client-containers-9339e053-3543-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:13:18.374: INFO: Pod client-containers-9339e053-3543-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:13:18.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-zjkk7" for this suite.
Feb 20 19:13:24.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:13:25.936: INFO: namespace: e2e-tests-containers-zjkk7, resource: bindings, ignored listing per whitelist
Feb 20 19:13:26.188: INFO: namespace e2e-tests-containers-zjkk7 deletion completed in 7.767692103s

• [SLOW TEST:12.128 seconds]
[k8s.io] Docker Containers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:13:26.189: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-z76tl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 19:13:27.967: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 20 19:13:30.052: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb 20 19:13:32.094: INFO: Creating deployment "test-rollover-deployment"
Feb 20 19:13:32.183: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb 20 19:13:32.224: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb 20 19:13:32.308: INFO: Ensure that both replica sets have 1 created replica
Feb 20 19:13:32.392: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb 20 19:13:32.476: INFO: Updating deployment test-rollover-deployment
Feb 20 19:13:32.476: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb 20 19:13:32.518: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb 20 19:13:32.602: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb 20 19:13:32.686: INFO: all replica sets need to contain the pod-template-hash label
Feb 20 19:13:32.686: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286812, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286812, loc:(*time.Location)(0x78fbda0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286812, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286812, loc:(*time.Location)(0x78fbda0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 19:13:34.770: INFO: all replica sets need to contain the pod-template-hash label
Feb 20 19:13:34.770: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286812, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286812, loc:(*time.Location)(0x78fbda0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286814, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286812, loc:(*time.Location)(0x78fbda0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 19:13:36.771: INFO: all replica sets need to contain the pod-template-hash label
Feb 20 19:13:36.771: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286812, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286812, loc:(*time.Location)(0x78fbda0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286814, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286812, loc:(*time.Location)(0x78fbda0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 19:13:38.770: INFO: all replica sets need to contain the pod-template-hash label
Feb 20 19:13:38.770: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286812, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286812, loc:(*time.Location)(0x78fbda0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286814, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286812, loc:(*time.Location)(0x78fbda0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 19:13:40.772: INFO: all replica sets need to contain the pod-template-hash label
Feb 20 19:13:40.772: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286812, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286812, loc:(*time.Location)(0x78fbda0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286814, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286812, loc:(*time.Location)(0x78fbda0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 19:13:42.778: INFO: all replica sets need to contain the pod-template-hash label
Feb 20 19:13:42.778: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286812, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286812, loc:(*time.Location)(0x78fbda0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286814, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286812, loc:(*time.Location)(0x78fbda0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 19:13:44.770: INFO: 
Feb 20 19:13:44.770: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 20 19:13:44.896: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-z76tl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z76tl/deployments/test-rollover-deployment,UID:9cca71e7-3543-11e9-936d-1e925ead141b,ResourceVersion:14686,Generation:2,CreationTimestamp:2019-02-20 19:13:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-20 19:13:32 +0000 UTC 2019-02-20 19:13:32 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-20 19:13:44 +0000 UTC 2019-02-20 19:13:32 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 20 19:13:44.938: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-z76tl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z76tl/replicasets/test-rollover-deployment-5b76ff8c4,UID:9cfe8e6c-3543-11e9-936d-1e925ead141b,ResourceVersion:14679,Generation:2,CreationTimestamp:2019-02-20 19:13:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 9cca71e7-3543-11e9-936d-1e925ead141b 0xc001e63560 0xc001e63561}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 20 19:13:44.939: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb 20 19:13:44.939: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-z76tl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z76tl/replicasets/test-rollover-controller,UID:9a47d009-3543-11e9-936d-1e925ead141b,ResourceVersion:14685,Generation:2,CreationTimestamp:2019-02-20 19:13:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 9cca71e7-3543-11e9-936d-1e925ead141b 0xc001e63437 0xc001e63438}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 20 19:13:44.939: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-z76tl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z76tl/replicasets/test-rollover-deployment-6975f4fb87,UID:9ccbc318-3543-11e9-936d-1e925ead141b,ResourceVersion:14648,Generation:2,CreationTimestamp:2019-02-20 19:13:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 9cca71e7-3543-11e9-936d-1e925ead141b 0xc001e63627 0xc001e63628}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 20 19:13:44.981: INFO: Pod "test-rollover-deployment-5b76ff8c4-xv8ck" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-xv8ck,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-z76tl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z76tl/pods/test-rollover-deployment-5b76ff8c4-xv8ck,UID:9cfff5f6-3543-11e9-936d-1e925ead141b,ResourceVersion:14657,Generation:0,CreationTimestamp:2019-02-20 19:13:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.164/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 9cfe8e6c-3543-11e9-936d-1e925ead141b 0xc000d3b4e0 0xc000d3b4e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wvhzf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wvhzf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-wvhzf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-15.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d3b540} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d3b560}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:13:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:13:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:13:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:13:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.8.15,PodIP:100.96.1.164,StartTime:2019-02-20 19:13:32 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-20 19:13:33 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://456fcef01dc8145b7a090bea57b132a4dead054b62372c9abac8e6b5c4b9f653}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:13:44.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-z76tl" for this suite.
Feb 20 19:13:51.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:13:51.531: INFO: namespace: e2e-tests-deployment-z76tl, resource: bindings, ignored listing per whitelist
Feb 20 19:13:52.859: INFO: namespace e2e-tests-deployment-z76tl deletion completed in 7.831230346s

• [SLOW TEST:26.670 seconds]
[sig-apps] Deployment
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:13:52.859: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-jxcw9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 20 19:13:54.707: INFO: Waiting up to 5m0s for pod "pod-aa3bc98e-3543-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-emptydir-jxcw9" to be "success or failure"
Feb 20 19:13:54.749: INFO: Pod "pod-aa3bc98e-3543-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.876436ms
Feb 20 19:13:56.792: INFO: Pod "pod-aa3bc98e-3543-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084853779s
STEP: Saw pod success
Feb 20 19:13:56.792: INFO: Pod "pod-aa3bc98e-3543-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:13:56.834: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-aa3bc98e-3543-11e9-997a-8a6f774fb32b container test-container: <nil>
STEP: delete the pod
Feb 20 19:13:56.930: INFO: Waiting for pod pod-aa3bc98e-3543-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:13:56.972: INFO: Pod pod-aa3bc98e-3543-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:13:56.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jxcw9" for this suite.
Feb 20 19:14:03.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:14:03.737: INFO: namespace: e2e-tests-emptydir-jxcw9, resource: bindings, ignored listing per whitelist
Feb 20 19:14:04.765: INFO: namespace e2e-tests-emptydir-jxcw9 deletion completed in 7.749331221s

• [SLOW TEST:11.906 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:14:04.765: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-p644s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-24q4j
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
Feb 20 19:14:16.161: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-dvpb7
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:14:33.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-p644s" for this suite.
Feb 20 19:14:39.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:14:40.347: INFO: namespace: e2e-tests-namespaces-p644s, resource: bindings, ignored listing per whitelist
Feb 20 19:14:41.309: INFO: namespace e2e-tests-namespaces-p644s deletion completed in 7.759415382s
STEP: Destroying namespace "e2e-tests-nsdeletetest-24q4j" for this suite.
Feb 20 19:14:41.351: INFO: Namespace e2e-tests-nsdeletetest-24q4j was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-dvpb7" for this suite.
Feb 20 19:14:47.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:14:48.107: INFO: namespace: e2e-tests-nsdeletetest-dvpb7, resource: bindings, ignored listing per whitelist
Feb 20 19:14:49.114: INFO: namespace e2e-tests-nsdeletetest-dvpb7 deletion completed in 7.762934806s

• [SLOW TEST:44.350 seconds]
[sig-api-machinery] Namespaces [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:14:49.115: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-bp6nb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 20 19:14:50.796: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-bp6nb'
Feb 20 19:14:52.929: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 20 19:14:52.929: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Feb 20 19:14:52.971: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-bp6nb'
Feb 20 19:14:53.268: INFO: stderr: ""
Feb 20 19:14:53.268: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:14:53.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bp6nb" for this suite.
Feb 20 19:14:59.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:15:00.654: INFO: namespace: e2e-tests-kubectl-bp6nb, resource: bindings, ignored listing per whitelist
Feb 20 19:15:01.073: INFO: namespace e2e-tests-kubectl-bp6nb deletion completed in 7.762631573s

• [SLOW TEST:11.959 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:15:01.073: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-25gsf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 19:15:02.909: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d2e27031-3543-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-downward-api-25gsf" to be "success or failure"
Feb 20 19:15:02.950: INFO: Pod "downwardapi-volume-d2e27031-3543-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.789014ms
Feb 20 19:15:04.993: INFO: Pod "downwardapi-volume-d2e27031-3543-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084523863s
STEP: Saw pod success
Feb 20 19:15:04.993: INFO: Pod "downwardapi-volume-d2e27031-3543-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:15:05.035: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod downwardapi-volume-d2e27031-3543-11e9-997a-8a6f774fb32b container client-container: <nil>
STEP: delete the pod
Feb 20 19:15:05.130: INFO: Waiting for pod downwardapi-volume-d2e27031-3543-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:15:05.172: INFO: Pod downwardapi-volume-d2e27031-3543-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:15:05.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-25gsf" for this suite.
Feb 20 19:15:11.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:15:11.765: INFO: namespace: e2e-tests-downward-api-25gsf, resource: bindings, ignored listing per whitelist
Feb 20 19:15:12.993: INFO: namespace e2e-tests-downward-api-25gsf deletion completed in 7.778276194s

• [SLOW TEST:11.920 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:15:12.994: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-mg99l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Feb 20 19:15:14.868: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 20 19:15:14.953: INFO: Waiting for terminating namespaces to be deleted...
Feb 20 19:15:14.994: INFO: 
Logging pods the kubelet thinks is on node ip-10-250-29-201.eu-west-1.compute.internal before test
Feb 20 19:15:15.091: INFO: addons-kube-lego-648f8c9f5c-72vfs from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:15:15.091: INFO: 	Container kube-lego ready: true, restart count 0
Feb 20 19:15:15.091: INFO: kube-proxy-95xsf from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:15:15.091: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 20 19:15:15.091: INFO: node-exporter-hr89s from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:15:15.091: INFO: 	Container node-exporter ready: true, restart count 0
Feb 20 19:15:15.091: INFO: coredns-5f4748c5f-ln884 from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:15:15.091: INFO: 	Container coredns ready: true, restart count 0
Feb 20 19:15:15.091: INFO: addons-nginx-ingress-controller-6574bbbf6f-vvn47 from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:15:15.091: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 20 19:15:15.091: INFO: addons-kubernetes-dashboard-5f64f76bd-fghf5 from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:15:15.091: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb 20 19:15:15.091: INFO: calico-node-dp8b4 from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:15:15.091: INFO: 	Container calico-node ready: true, restart count 0
Feb 20 19:15:15.091: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6498456576-7cql9 from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:15:15.091: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Feb 20 19:15:15.091: INFO: blackbox-exporter-64f6f7f998-4jrfr from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:15:15.091: INFO: 	Container blackbox-exporter ready: true, restart count 0
Feb 20 19:15:15.091: INFO: vpn-shoot-7c466dcf55-7l9tt from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:15:15.091: INFO: 	Container vpn-shoot ready: true, restart count 0
Feb 20 19:15:15.091: INFO: metrics-server-67d85b8585-xjbtx from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:15:15.091: INFO: 	Container metrics-server ready: true, restart count 0
Feb 20 19:15:15.091: INFO: 
Logging pods the kubelet thinks is on node ip-10-250-8-15.eu-west-1.compute.internal before test
Feb 20 19:15:15.138: INFO: kube-proxy-q6jfv from kube-system started at 2019-02-20 17:54:44 +0000 UTC (1 container statuses recorded)
Feb 20 19:15:15.138: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 20 19:15:15.138: INFO: calico-node-vgnmn from kube-system started at 2019-02-20 17:54:44 +0000 UTC (1 container statuses recorded)
Feb 20 19:15:15.138: INFO: 	Container calico-node ready: true, restart count 0
Feb 20 19:15:15.138: INFO: node-exporter-jvhwp from kube-system started at 2019-02-20 17:54:44 +0000 UTC (1 container statuses recorded)
Feb 20 19:15:15.138: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-db860d1b-3543-11e9-997a-8a6f774fb32b 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-db860d1b-3543-11e9-997a-8a6f774fb32b off the node ip-10-250-8-15.eu-west-1.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-db860d1b-3543-11e9-997a-8a6f774fb32b
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:15:19.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-mg99l" for this suite.
Feb 20 19:15:37.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:15:38.710: INFO: namespace: e2e-tests-sched-pred-mg99l, resource: bindings, ignored listing per whitelist
Feb 20 19:15:39.568: INFO: namespace e2e-tests-sched-pred-mg99l deletion completed in 19.784926889s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:26.575 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:15:39.569: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-p7wk4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 19:15:41.318: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e9c751c5-3543-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-projected-p7wk4" to be "success or failure"
Feb 20 19:15:41.362: INFO: Pod "downwardapi-volume-e9c751c5-3543-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 44.233031ms
Feb 20 19:15:43.405: INFO: Pod "downwardapi-volume-e9c751c5-3543-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.087593283s
STEP: Saw pod success
Feb 20 19:15:43.405: INFO: Pod "downwardapi-volume-e9c751c5-3543-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:15:43.448: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod downwardapi-volume-e9c751c5-3543-11e9-997a-8a6f774fb32b container client-container: <nil>
STEP: delete the pod
Feb 20 19:15:43.548: INFO: Waiting for pod downwardapi-volume-e9c751c5-3543-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:15:43.590: INFO: Pod downwardapi-volume-e9c751c5-3543-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:15:43.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p7wk4" for this suite.
Feb 20 19:15:49.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:15:49.988: INFO: namespace: e2e-tests-projected-p7wk4, resource: bindings, ignored listing per whitelist
Feb 20 19:15:51.373: INFO: namespace e2e-tests-projected-p7wk4 deletion completed in 7.736558116s

• [SLOW TEST:11.804 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:15:51.373: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-w5ntt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 19:15:53.070: INFO: Creating deployment "test-recreate-deployment"
Feb 20 19:15:53.190: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb 20 19:15:53.274: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb 20 19:15:53.315: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286953, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286953, loc:(*time.Location)(0x78fbda0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286953, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286953, loc:(*time.Location)(0x78fbda0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 19:15:55.362: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb 20 19:15:55.448: INFO: Updating deployment test-recreate-deployment
Feb 20 19:15:55.448: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 20 19:15:55.581: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-w5ntt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-w5ntt/deployments/test-recreate-deployment,UID:f0d18f92-3543-11e9-936d-1e925ead141b,ResourceVersion:15132,Generation:2,CreationTimestamp:2019-02-20 19:15:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-02-20 19:15:55 +0000 UTC 2019-02-20 19:15:55 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-20 19:15:55 +0000 UTC 2019-02-20 19:15:53 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Feb 20 19:15:55.624: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-w5ntt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-w5ntt/replicasets/test-recreate-deployment-7cf749666b,UID:f237c4a6-3543-11e9-936d-1e925ead141b,ResourceVersion:15131,Generation:1,CreationTimestamp:2019-02-20 19:15:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment f0d18f92-3543-11e9-936d-1e925ead141b 0xc0019266a7 0xc0019266a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 20 19:15:55.624: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb 20 19:15:55.624: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-w5ntt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-w5ntt/replicasets/test-recreate-deployment-79f694ff59,UID:f0d2491e-3543-11e9-936d-1e925ead141b,ResourceVersion:15123,Generation:2,CreationTimestamp:2019-02-20 19:15:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment f0d18f92-3543-11e9-936d-1e925ead141b 0xc001926517 0xc001926518}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 20 19:15:55.666: INFO: Pod "test-recreate-deployment-7cf749666b-kfdkj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-kfdkj,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-w5ntt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5ntt/pods/test-recreate-deployment-7cf749666b-kfdkj,UID:f23805b0-3543-11e9-936d-1e925ead141b,ResourceVersion:15130,Generation:0,CreationTimestamp:2019-02-20 19:15:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b f237c4a6-3543-11e9-936d-1e925ead141b 0xc0019d2a27 0xc0019d2a28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h4khp {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h4khp,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-h4khp true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-15.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019d2a90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019d2ab0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:15:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:15:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:15:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:15:55 +0000 UTC  }],Message:,Reason:,HostIP:10.250.8.15,PodIP:,StartTime:2019-02-20 19:15:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:15:55.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-w5ntt" for this suite.
Feb 20 19:16:01.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:16:03.313: INFO: namespace: e2e-tests-deployment-w5ntt, resource: bindings, ignored listing per whitelist
Feb 20 19:16:03.441: INFO: namespace e2e-tests-deployment-w5ntt deletion completed in 7.73228442s

• [SLOW TEST:12.068 seconds]
[sig-apps] Deployment
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:16:03.441: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-f76z6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 20 19:16:05.266: INFO: PodSpec: initContainers in spec.initContainers
Feb 20 19:16:50.591: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-f81437c2-3543-11e9-997a-8a6f774fb32b", GenerateName:"", Namespace:"e2e-tests-init-container-f76z6", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-f76z6/pods/pod-init-f81437c2-3543-11e9-997a-8a6f774fb32b", UID:"f816d603-3543-11e9-936d-1e925ead141b", ResourceVersion:"15268", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63686286965, loc:(*time.Location)(0x78fbda0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"266642594"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"100.96.1.174/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-b8z96", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001b39c40), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-b8z96", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-b8z96", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-b8z96", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001e21e68), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-250-8-15.eu-west-1.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000211aa0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001e21f50)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001e21f70)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001e21f78), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286965, loc:(*time.Location)(0x78fbda0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286965, loc:(*time.Location)(0x78fbda0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286965, loc:(*time.Location)(0x78fbda0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686286965, loc:(*time.Location)(0x78fbda0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.8.15", PodIP:"100.96.1.174", StartTime:(*v1.Time)(0xc0013d9100), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001ae00e0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001ae0150)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://78e0451e447ed7eb852990e4c13e9d69618f78ca2fca1e3e8380c7e8aab4225b"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0013d9140), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0013d9120), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:16:50.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-f76z6" for this suite.
Feb 20 19:17:12.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:17:14.185: INFO: namespace: e2e-tests-init-container-f76z6, resource: bindings, ignored listing per whitelist
Feb 20 19:17:14.403: INFO: namespace e2e-tests-init-container-f76z6 deletion completed in 23.767756435s

• [SLOW TEST:70.962 seconds]
[k8s.io] InitContainer [NodeConformance]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:17:14.403: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-mrqbt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 20 19:17:16.309: INFO: Waiting up to 5m0s for pod "pod-2265c566-3544-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-emptydir-mrqbt" to be "success or failure"
Feb 20 19:17:16.351: INFO: Pod "pod-2265c566-3544-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.955173ms
Feb 20 19:17:18.395: INFO: Pod "pod-2265c566-3544-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.08552684s
STEP: Saw pod success
Feb 20 19:17:18.395: INFO: Pod "pod-2265c566-3544-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:17:18.438: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-2265c566-3544-11e9-997a-8a6f774fb32b container test-container: <nil>
STEP: delete the pod
Feb 20 19:17:18.533: INFO: Waiting for pod pod-2265c566-3544-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:17:18.574: INFO: Pod pod-2265c566-3544-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:17:18.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mrqbt" for this suite.
Feb 20 19:17:24.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:17:26.098: INFO: namespace: e2e-tests-emptydir-mrqbt, resource: bindings, ignored listing per whitelist
Feb 20 19:17:26.474: INFO: namespace e2e-tests-emptydir-mrqbt deletion completed in 7.856721604s

• [SLOW TEST:12.071 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:17:26.474: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-zbcrf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-297e7305-3544-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume configMaps
Feb 20 19:17:28.259: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-29851067-3544-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-projected-zbcrf" to be "success or failure"
Feb 20 19:17:28.301: INFO: Pod "pod-projected-configmaps-29851067-3544-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.936122ms
Feb 20 19:17:30.344: INFO: Pod "pod-projected-configmaps-29851067-3544-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084574508s
STEP: Saw pod success
Feb 20 19:17:30.344: INFO: Pod "pod-projected-configmaps-29851067-3544-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:17:30.386: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-projected-configmaps-29851067-3544-11e9-997a-8a6f774fb32b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 19:17:30.478: INFO: Waiting for pod pod-projected-configmaps-29851067-3544-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:17:30.520: INFO: Pod pod-projected-configmaps-29851067-3544-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:17:30.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zbcrf" for this suite.
Feb 20 19:17:36.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:17:37.029: INFO: namespace: e2e-tests-projected-zbcrf, resource: bindings, ignored listing per whitelist
Feb 20 19:17:38.287: INFO: namespace e2e-tests-projected-zbcrf deletion completed in 7.724677558s

• [SLOW TEST:11.813 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:17:38.287: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-lx79f
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-30866887-3544-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume secrets
Feb 20 19:17:40.054: INFO: Waiting up to 5m0s for pod "pod-secrets-308cce1d-3544-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-secrets-lx79f" to be "success or failure"
Feb 20 19:17:40.096: INFO: Pod "pod-secrets-308cce1d-3544-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 42.17095ms
Feb 20 19:17:42.140: INFO: Pod "pod-secrets-308cce1d-3544-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085691426s
STEP: Saw pod success
Feb 20 19:17:42.140: INFO: Pod "pod-secrets-308cce1d-3544-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:17:42.183: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-secrets-308cce1d-3544-11e9-997a-8a6f774fb32b container secret-env-test: <nil>
STEP: delete the pod
Feb 20 19:17:42.277: INFO: Waiting for pod pod-secrets-308cce1d-3544-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:17:42.321: INFO: Pod pod-secrets-308cce1d-3544-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:17:42.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-lx79f" for this suite.
Feb 20 19:17:48.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:17:49.579: INFO: namespace: e2e-tests-secrets-lx79f, resource: bindings, ignored listing per whitelist
Feb 20 19:17:50.121: INFO: namespace e2e-tests-secrets-lx79f deletion completed in 7.757142446s

• [SLOW TEST:11.833 seconds]
[sig-api-machinery] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:17:50.121: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-d8c7w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-37ad25bc-3544-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume configMaps
Feb 20 19:17:52.051: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-37b38598-3544-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-projected-d8c7w" to be "success or failure"
Feb 20 19:17:52.093: INFO: Pod "pod-projected-configmaps-37b38598-3544-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.809317ms
Feb 20 19:17:54.135: INFO: Pod "pod-projected-configmaps-37b38598-3544-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084107686s
STEP: Saw pod success
Feb 20 19:17:54.135: INFO: Pod "pod-projected-configmaps-37b38598-3544-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:17:54.177: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-projected-configmaps-37b38598-3544-11e9-997a-8a6f774fb32b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 19:17:54.268: INFO: Waiting for pod pod-projected-configmaps-37b38598-3544-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:17:54.309: INFO: Pod pod-projected-configmaps-37b38598-3544-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:17:54.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d8c7w" for this suite.
Feb 20 19:18:00.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:18:01.726: INFO: namespace: e2e-tests-projected-d8c7w, resource: bindings, ignored listing per whitelist
Feb 20 19:18:02.183: INFO: namespace e2e-tests-projected-d8c7w deletion completed in 7.830651874s

• [SLOW TEST:12.062 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:18:02.184: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-4sj9m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 19:18:03.917: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3ec626a0-3544-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-downward-api-4sj9m" to be "success or failure"
Feb 20 19:18:03.959: INFO: Pod "downwardapi-volume-3ec626a0-3544-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 42.301622ms
Feb 20 19:18:06.003: INFO: Pod "downwardapi-volume-3ec626a0-3544-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085760334s
STEP: Saw pod success
Feb 20 19:18:06.003: INFO: Pod "downwardapi-volume-3ec626a0-3544-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:18:06.045: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod downwardapi-volume-3ec626a0-3544-11e9-997a-8a6f774fb32b container client-container: <nil>
STEP: delete the pod
Feb 20 19:18:06.136: INFO: Waiting for pod downwardapi-volume-3ec626a0-3544-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:18:06.178: INFO: Pod downwardapi-volume-3ec626a0-3544-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:18:06.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4sj9m" for this suite.
Feb 20 19:18:12.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:18:13.875: INFO: namespace: e2e-tests-downward-api-4sj9m, resource: bindings, ignored listing per whitelist
Feb 20 19:18:14.044: INFO: namespace e2e-tests-downward-api-4sj9m deletion completed in 7.823390868s

• [SLOW TEST:11.860 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:18:14.044: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-x74p6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Feb 20 19:18:16.490: INFO: created pod pod-service-account-defaultsa
Feb 20 19:18:16.490: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb 20 19:18:16.532: INFO: created pod pod-service-account-mountsa
Feb 20 19:18:16.532: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb 20 19:18:16.579: INFO: created pod pod-service-account-nomountsa
Feb 20 19:18:16.579: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb 20 19:18:16.621: INFO: created pod pod-service-account-defaultsa-mountspec
Feb 20 19:18:16.621: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb 20 19:18:16.664: INFO: created pod pod-service-account-mountsa-mountspec
Feb 20 19:18:16.664: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb 20 19:18:16.706: INFO: created pod pod-service-account-nomountsa-mountspec
Feb 20 19:18:16.706: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb 20 19:18:16.749: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb 20 19:18:16.749: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb 20 19:18:16.792: INFO: created pod pod-service-account-mountsa-nomountspec
Feb 20 19:18:16.792: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb 20 19:18:16.835: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb 20 19:18:16.835: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:18:16.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-x74p6" for this suite.
Feb 20 19:18:23.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:18:23.132: INFO: namespace: e2e-tests-svcaccounts-x74p6, resource: bindings, ignored listing per whitelist
Feb 20 19:18:24.654: INFO: namespace e2e-tests-svcaccounts-x74p6 deletion completed in 7.776358364s

• [SLOW TEST:10.610 seconds]
[sig-auth] ServiceAccounts
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:18:24.655: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-vmqdv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Feb 20 19:18:26.515: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-vmqdv" to be "success or failure"
Feb 20 19:18:26.557: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 41.573354ms
Feb 20 19:18:28.600: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084198484s
STEP: Saw pod success
Feb 20 19:18:28.600: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb 20 19:18:28.642: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb 20 19:18:28.733: INFO: Waiting for pod pod-host-path-test to disappear
Feb 20 19:18:28.775: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:18:28.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-vmqdv" for this suite.
Feb 20 19:18:34.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:18:35.787: INFO: namespace: e2e-tests-hostpath-vmqdv, resource: bindings, ignored listing per whitelist
Feb 20 19:18:36.579: INFO: namespace e2e-tests-hostpath-vmqdv deletion completed in 7.761981223s

• [SLOW TEST:11.925 seconds]
[sig-storage] HostPath
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:18:36.580: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-7kb8p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 19:18:38.359: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 20 19:18:40.445: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 20 19:18:42.783: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-7kb8p,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7kb8p/deployments/test-cleanup-deployment,UID:54a1a26a-3544-11e9-936d-1e925ead141b,ResourceVersion:15718,Generation:1,CreationTimestamp:2019-02-20 19:18:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-20 19:18:40 +0000 UTC 2019-02-20 19:18:40 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-20 19:18:42 +0000 UTC 2019-02-20 19:18:40 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-755f6b95cc" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 20 19:18:42.827: INFO: New ReplicaSet "test-cleanup-deployment-755f6b95cc" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc,GenerateName:,Namespace:e2e-tests-deployment-7kb8p,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7kb8p/replicasets/test-cleanup-deployment-755f6b95cc,UID:54a2d450-3544-11e9-936d-1e925ead141b,ResourceVersion:15711,Generation:1,CreationTimestamp:2019-02-20 19:18:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 54a1a26a-3544-11e9-936d-1e925ead141b 0xc00001d757 0xc00001d758}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 20 19:18:42.871: INFO: Pod "test-cleanup-deployment-755f6b95cc-sb8gd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc-sb8gd,GenerateName:test-cleanup-deployment-755f6b95cc-,Namespace:e2e-tests-deployment-7kb8p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7kb8p/pods/test-cleanup-deployment-755f6b95cc-sb8gd,UID:54a31e9f-3544-11e9-936d-1e925ead141b,ResourceVersion:15710,Generation:0,CreationTimestamp:2019-02-20 19:18:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.190/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-755f6b95cc 54a2d450-3544-11e9-936d-1e925ead141b 0xc00005c497 0xc00005c498}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vl4dg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vl4dg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-vl4dg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-15.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00005c510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00005c570}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:18:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:18:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:18:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:18:40 +0000 UTC  }],Message:,Reason:,HostIP:10.250.8.15,PodIP:100.96.1.190,StartTime:2019-02-20 19:18:40 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-20 19:18:41 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://e5f3b6a60962871807ce5e25a15f59ee0a59236b7dd73a0fb7979d99fea0fb27}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:18:42.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-7kb8p" for this suite.
Feb 20 19:18:49.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:18:49.995: INFO: namespace: e2e-tests-deployment-7kb8p, resource: bindings, ignored listing per whitelist
Feb 20 19:18:50.707: INFO: namespace e2e-tests-deployment-7kb8p deletion completed in 7.792063354s

• [SLOW TEST:14.127 seconds]
[sig-apps] Deployment
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:18:50.707: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-g6hbx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-5bb01da0-3544-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume configMaps
Feb 20 19:18:52.468: INFO: Waiting up to 5m0s for pod "pod-configmaps-5bb6796e-3544-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-configmap-g6hbx" to be "success or failure"
Feb 20 19:18:52.509: INFO: Pod "pod-configmaps-5bb6796e-3544-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.429404ms
Feb 20 19:18:54.552: INFO: Pod "pod-configmaps-5bb6796e-3544-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.083850639s
STEP: Saw pod success
Feb 20 19:18:54.552: INFO: Pod "pod-configmaps-5bb6796e-3544-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:18:54.593: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-configmaps-5bb6796e-3544-11e9-997a-8a6f774fb32b container configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 19:18:54.686: INFO: Waiting for pod pod-configmaps-5bb6796e-3544-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:18:54.728: INFO: Pod pod-configmaps-5bb6796e-3544-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:18:54.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-g6hbx" for this suite.
Feb 20 19:19:00.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:19:01.898: INFO: namespace: e2e-tests-configmap-g6hbx, resource: bindings, ignored listing per whitelist
Feb 20 19:19:02.486: INFO: namespace e2e-tests-configmap-g6hbx deletion completed in 7.715393932s

• [SLOW TEST:11.779 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:19:02.486: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-rvjx2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 20 19:19:04.449: INFO: Waiting up to 5m0s for pod "downward-api-62daa190-3544-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-downward-api-rvjx2" to be "success or failure"
Feb 20 19:19:04.491: INFO: Pod "downward-api-62daa190-3544-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.660972ms
Feb 20 19:19:06.533: INFO: Pod "downward-api-62daa190-3544-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.083671104s
STEP: Saw pod success
Feb 20 19:19:06.533: INFO: Pod "downward-api-62daa190-3544-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:19:06.575: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod downward-api-62daa190-3544-11e9-997a-8a6f774fb32b container dapi-container: <nil>
STEP: delete the pod
Feb 20 19:19:06.668: INFO: Waiting for pod downward-api-62daa190-3544-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:19:06.709: INFO: Pod downward-api-62daa190-3544-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:19:06.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rvjx2" for this suite.
Feb 20 19:19:12.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:19:13.473: INFO: namespace: e2e-tests-downward-api-rvjx2, resource: bindings, ignored listing per whitelist
Feb 20 19:19:14.539: INFO: namespace e2e-tests-downward-api-rvjx2 deletion completed in 7.787247973s

• [SLOW TEST:12.053 seconds]
[sig-api-machinery] Downward API
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:19:14.540: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-tndt6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Feb 20 19:19:16.366: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-tndt6'
Feb 20 19:19:17.016: INFO: stderr: ""
Feb 20 19:19:17.016: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 20 19:19:17.016: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tndt6'
Feb 20 19:19:17.304: INFO: stderr: ""
Feb 20 19:19:17.304: INFO: stdout: "update-demo-nautilus-5wrmz update-demo-nautilus-7knx8 "
Feb 20 19:19:17.304: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-5wrmz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tndt6'
Feb 20 19:19:17.577: INFO: stderr: ""
Feb 20 19:19:17.577: INFO: stdout: ""
Feb 20 19:19:17.577: INFO: update-demo-nautilus-5wrmz is created but not running
Feb 20 19:19:22.577: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tndt6'
Feb 20 19:19:22.853: INFO: stderr: ""
Feb 20 19:19:22.853: INFO: stdout: "update-demo-nautilus-5wrmz update-demo-nautilus-7knx8 "
Feb 20 19:19:22.853: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-5wrmz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tndt6'
Feb 20 19:19:23.121: INFO: stderr: ""
Feb 20 19:19:23.121: INFO: stdout: "true"
Feb 20 19:19:23.121: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-5wrmz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tndt6'
Feb 20 19:19:23.404: INFO: stderr: ""
Feb 20 19:19:23.404: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 19:19:23.404: INFO: validating pod update-demo-nautilus-5wrmz
Feb 20 19:19:23.533: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 19:19:23.533: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 19:19:23.533: INFO: update-demo-nautilus-5wrmz is verified up and running
Feb 20 19:19:23.533: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-7knx8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tndt6'
Feb 20 19:19:23.778: INFO: stderr: ""
Feb 20 19:19:23.778: INFO: stdout: "true"
Feb 20 19:19:23.778: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-nautilus-7knx8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tndt6'
Feb 20 19:19:24.018: INFO: stderr: ""
Feb 20 19:19:24.018: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 19:19:24.018: INFO: validating pod update-demo-nautilus-7knx8
Feb 20 19:19:24.154: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 19:19:24.154: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 19:19:24.154: INFO: update-demo-nautilus-7knx8 is verified up and running
STEP: rolling-update to new replication controller
Feb 20 19:19:24.159: INFO: scanned /root for discovery docs: <nil>
Feb 20 19:19:24.159: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-tndt6'
Feb 20 19:19:40.376: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 20 19:19:40.376: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 20 19:19:40.376: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tndt6'
Feb 20 19:19:40.637: INFO: stderr: ""
Feb 20 19:19:40.637: INFO: stdout: "update-demo-kitten-8hlxp update-demo-kitten-fwcgj "
Feb 20 19:19:40.637: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-kitten-8hlxp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tndt6'
Feb 20 19:19:40.894: INFO: stderr: ""
Feb 20 19:19:40.894: INFO: stdout: "true"
Feb 20 19:19:40.894: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-kitten-8hlxp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tndt6'
Feb 20 19:19:41.171: INFO: stderr: ""
Feb 20 19:19:41.171: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 20 19:19:41.171: INFO: validating pod update-demo-kitten-8hlxp
Feb 20 19:19:41.301: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 20 19:19:41.302: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 20 19:19:41.302: INFO: update-demo-kitten-8hlxp is verified up and running
Feb 20 19:19:41.302: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-kitten-fwcgj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tndt6'
Feb 20 19:19:41.592: INFO: stderr: ""
Feb 20 19:19:41.592: INFO: stdout: "true"
Feb 20 19:19:41.592: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods update-demo-kitten-fwcgj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tndt6'
Feb 20 19:19:41.878: INFO: stderr: ""
Feb 20 19:19:41.878: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 20 19:19:41.878: INFO: validating pod update-demo-kitten-fwcgj
Feb 20 19:19:42.009: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 20 19:19:42.009: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 20 19:19:42.009: INFO: update-demo-kitten-fwcgj is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:19:42.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tndt6" for this suite.
Feb 20 19:20:04.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:20:05.526: INFO: namespace: e2e-tests-kubectl-tndt6, resource: bindings, ignored listing per whitelist
Feb 20 19:20:05.820: INFO: namespace e2e-tests-kubectl-tndt6 deletion completed in 23.768028959s

• [SLOW TEST:51.280 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:20:05.820: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-wmhqx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-wmhqx
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Feb 20 19:20:07.695: INFO: Found 1 stateful pods, waiting for 3
Feb 20 19:20:17.738: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 19:20:17.738: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 19:20:17.738: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 19:20:17.865: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-wmhqx ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 20 19:20:18.796: INFO: stderr: ""
Feb 20 19:20:18.796: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 20 19:20:18.796: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 20 19:20:29.062: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb 20 19:20:29.188: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-wmhqx ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:20:30.060: INFO: stderr: ""
Feb 20 19:20:30.061: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 20 19:20:30.061: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 20 19:20:40.351: INFO: Waiting for StatefulSet e2e-tests-statefulset-wmhqx/ss2 to complete update
Feb 20 19:20:40.351: INFO: Waiting for Pod e2e-tests-statefulset-wmhqx/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Feb 20 19:20:50.436: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-wmhqx ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 20 19:20:51.306: INFO: stderr: ""
Feb 20 19:20:51.306: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 20 19:20:51.306: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 20 19:21:01.569: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb 20 19:21:01.695: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-wmhqx ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:21:02.612: INFO: stderr: ""
Feb 20 19:21:02.612: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 20 19:21:02.612: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 20 19:21:12.870: INFO: Waiting for StatefulSet e2e-tests-statefulset-wmhqx/ss2 to complete update
Feb 20 19:21:12.870: INFO: Waiting for Pod e2e-tests-statefulset-wmhqx/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 20 19:21:12.870: INFO: Waiting for Pod e2e-tests-statefulset-wmhqx/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 20 19:21:12.870: INFO: Waiting for Pod e2e-tests-statefulset-wmhqx/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 20 19:21:22.956: INFO: Waiting for StatefulSet e2e-tests-statefulset-wmhqx/ss2 to complete update
Feb 20 19:21:22.956: INFO: Waiting for Pod e2e-tests-statefulset-wmhqx/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 20 19:21:22.956: INFO: Waiting for Pod e2e-tests-statefulset-wmhqx/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 20 19:21:32.955: INFO: Deleting all statefulset in ns e2e-tests-statefulset-wmhqx
Feb 20 19:21:32.997: INFO: Scaling statefulset ss2 to 0
Feb 20 19:21:53.169: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 19:21:53.212: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:21:53.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-wmhqx" for this suite.
Feb 20 19:21:59.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:22:00.321: INFO: namespace: e2e-tests-statefulset-wmhqx, resource: bindings, ignored listing per whitelist
Feb 20 19:22:01.117: INFO: namespace e2e-tests-statefulset-wmhqx deletion completed in 7.732332243s

• [SLOW TEST:115.297 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:22:01.117: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-ppnv8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Feb 20 19:22:02.870: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-ppnv8'
Feb 20 19:22:04.017: INFO: stderr: ""
Feb 20 19:22:04.017: INFO: stdout: "pod/pause created\n"
Feb 20 19:22:04.017: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb 20 19:22:04.017: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-ppnv8" to be "running and ready"
Feb 20 19:22:04.058: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 41.516589ms
Feb 20 19:22:06.101: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.084501902s
Feb 20 19:22:06.102: INFO: Pod "pause" satisfied condition "running and ready"
Feb 20 19:22:06.102: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Feb 20 19:22:06.102: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-ppnv8'
Feb 20 19:22:06.391: INFO: stderr: ""
Feb 20 19:22:06.391: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb 20 19:22:06.391: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pod pause -L testing-label --namespace=e2e-tests-kubectl-ppnv8'
Feb 20 19:22:06.639: INFO: stderr: ""
Feb 20 19:22:06.639: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb 20 19:22:06.639: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml label pods pause testing-label- --namespace=e2e-tests-kubectl-ppnv8'
Feb 20 19:22:06.934: INFO: stderr: ""
Feb 20 19:22:06.934: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb 20 19:22:06.934: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pod pause -L testing-label --namespace=e2e-tests-kubectl-ppnv8'
Feb 20 19:22:07.187: INFO: stderr: ""
Feb 20 19:22:07.187: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Feb 20 19:22:07.187: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ppnv8'
Feb 20 19:22:07.507: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 19:22:07.507: INFO: stdout: "pod \"pause\" force deleted\n"
Feb 20 19:22:07.507: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-ppnv8'
Feb 20 19:22:07.911: INFO: stderr: "No resources found.\n"
Feb 20 19:22:07.911: INFO: stdout: ""
Feb 20 19:22:07.911: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -l name=pause --namespace=e2e-tests-kubectl-ppnv8 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 20 19:22:08.205: INFO: stderr: ""
Feb 20 19:22:08.205: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:22:08.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ppnv8" for this suite.
Feb 20 19:22:14.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:22:15.158: INFO: namespace: e2e-tests-kubectl-ppnv8, resource: bindings, ignored listing per whitelist
Feb 20 19:22:16.073: INFO: namespace e2e-tests-kubectl-ppnv8 deletion completed in 7.826116415s

• [SLOW TEST:14.956 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:22:16.074: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-zk8xb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 19:22:18.007: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d63908cf-3544-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-downward-api-zk8xb" to be "success or failure"
Feb 20 19:22:18.048: INFO: Pod "downwardapi-volume-d63908cf-3544-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.523531ms
Feb 20 19:22:20.090: INFO: Pod "downwardapi-volume-d63908cf-3544-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.083389946s
STEP: Saw pod success
Feb 20 19:22:20.090: INFO: Pod "downwardapi-volume-d63908cf-3544-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:22:20.132: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod downwardapi-volume-d63908cf-3544-11e9-997a-8a6f774fb32b container client-container: <nil>
STEP: delete the pod
Feb 20 19:22:20.229: INFO: Waiting for pod downwardapi-volume-d63908cf-3544-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:22:20.271: INFO: Pod downwardapi-volume-d63908cf-3544-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:22:20.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zk8xb" for this suite.
Feb 20 19:22:26.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:22:27.996: INFO: namespace: e2e-tests-downward-api-zk8xb, resource: bindings, ignored listing per whitelist
Feb 20 19:22:28.080: INFO: namespace e2e-tests-downward-api-zk8xb deletion completed in 7.7660098s

• [SLOW TEST:12.006 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:22:28.080: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-5hbh5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb 20 19:22:30.167: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-5hbh5,SelfLink:/api/v1/namespaces/e2e-tests-watch-5hbh5/configmaps/e2e-watch-test-resource-version,UID:dd54bdbe-3544-11e9-936d-1e925ead141b,ResourceVersion:16511,Generation:0,CreationTimestamp:2019-02-20 19:22:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 20 19:22:30.167: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-5hbh5,SelfLink:/api/v1/namespaces/e2e-tests-watch-5hbh5/configmaps/e2e-watch-test-resource-version,UID:dd54bdbe-3544-11e9-936d-1e925ead141b,ResourceVersion:16512,Generation:0,CreationTimestamp:2019-02-20 19:22:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:22:30.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-5hbh5" for this suite.
Feb 20 19:22:36.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:22:37.338: INFO: namespace: e2e-tests-watch-5hbh5, resource: bindings, ignored listing per whitelist
Feb 20 19:22:37.924: INFO: namespace e2e-tests-watch-5hbh5 deletion completed in 7.713678667s

• [SLOW TEST:9.845 seconds]
[sig-api-machinery] Watchers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:22:37.925: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-475pl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 20 19:22:42.522: INFO: Successfully updated pod "annotationupdatee3298cc2-3544-11e9-997a-8a6f774fb32b"
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:22:44.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-475pl" for this suite.
Feb 20 19:23:06.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:23:07.473: INFO: namespace: e2e-tests-downward-api-475pl, resource: bindings, ignored listing per whitelist
Feb 20 19:23:08.402: INFO: namespace e2e-tests-downward-api-475pl deletion completed in 23.742135863s

• [SLOW TEST:30.477 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:23:08.402: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-694lv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-694lv
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-694lv
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-694lv
Feb 20 19:23:10.286: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Feb 20 19:23:20.328: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb 20 19:23:20.371: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-694lv ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 20 19:23:21.307: INFO: stderr: ""
Feb 20 19:23:21.307: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 20 19:23:21.307: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 20 19:23:21.349: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 20 19:23:31.391: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 20 19:23:31.391: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 19:23:31.559: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999961s
Feb 20 19:23:32.602: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.957774171s
Feb 20 19:23:33.644: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.915258134s
Feb 20 19:23:34.687: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.872622145s
Feb 20 19:23:35.729: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.829797215s
Feb 20 19:23:36.774: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.787523941s
Feb 20 19:23:37.818: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.74275431s
Feb 20 19:23:38.861: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.698973667s
Feb 20 19:23:39.904: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.656037815s
Feb 20 19:23:40.946: INFO: Verifying statefulset ss doesn't scale past 3 for another 613.372936ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-694lv
Feb 20 19:23:41.990: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-694lv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:23:42.881: INFO: stderr: ""
Feb 20 19:23:42.881: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 20 19:23:42.881: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 20 19:23:42.881: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-694lv ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:23:43.801: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 20 19:23:43.801: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 20 19:23:43.801: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 20 19:23:43.801: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-694lv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 20 19:23:44.655: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 20 19:23:44.655: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 20 19:23:44.655: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 20 19:23:44.698: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 19:23:44.698: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 19:23:44.698: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb 20 19:23:44.740: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-694lv ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 20 19:23:45.637: INFO: stderr: ""
Feb 20 19:23:45.637: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 20 19:23:45.637: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 20 19:23:45.637: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-694lv ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 20 19:23:46.561: INFO: stderr: ""
Feb 20 19:23:46.561: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 20 19:23:46.561: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 20 19:23:46.561: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-694lv ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 20 19:23:47.431: INFO: stderr: ""
Feb 20 19:23:47.431: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 20 19:23:47.431: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 20 19:23:47.431: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 19:23:47.473: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Feb 20 19:23:57.559: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 20 19:23:57.559: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 20 19:23:57.559: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 20 19:23:57.686: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 20 19:23:57.686: INFO: ss-0  ip-10-250-8-15.eu-west-1.compute.internal    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:10 +0000 UTC  }]
Feb 20 19:23:57.686: INFO: ss-1  ip-10-250-29-201.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  }]
Feb 20 19:23:57.686: INFO: ss-2  ip-10-250-8-15.eu-west-1.compute.internal    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  }]
Feb 20 19:23:57.686: INFO: 
Feb 20 19:23:57.686: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 20 19:23:58.729: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 20 19:23:58.729: INFO: ss-0  ip-10-250-8-15.eu-west-1.compute.internal    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:10 +0000 UTC  }]
Feb 20 19:23:58.729: INFO: ss-1  ip-10-250-29-201.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  }]
Feb 20 19:23:58.729: INFO: ss-2  ip-10-250-8-15.eu-west-1.compute.internal    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  }]
Feb 20 19:23:58.729: INFO: 
Feb 20 19:23:58.729: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 20 19:23:59.772: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 20 19:23:59.772: INFO: ss-0  ip-10-250-8-15.eu-west-1.compute.internal    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:10 +0000 UTC  }]
Feb 20 19:23:59.772: INFO: ss-1  ip-10-250-29-201.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  }]
Feb 20 19:23:59.772: INFO: ss-2  ip-10-250-8-15.eu-west-1.compute.internal    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  }]
Feb 20 19:23:59.772: INFO: 
Feb 20 19:23:59.772: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 20 19:24:00.815: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 20 19:24:00.815: INFO: ss-0  ip-10-250-8-15.eu-west-1.compute.internal    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:10 +0000 UTC  }]
Feb 20 19:24:00.815: INFO: ss-1  ip-10-250-29-201.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  }]
Feb 20 19:24:00.815: INFO: ss-2  ip-10-250-8-15.eu-west-1.compute.internal    Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  }]
Feb 20 19:24:00.815: INFO: 
Feb 20 19:24:00.815: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 20 19:24:01.858: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 20 19:24:01.858: INFO: ss-0  ip-10-250-8-15.eu-west-1.compute.internal    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:10 +0000 UTC  }]
Feb 20 19:24:01.858: INFO: ss-1  ip-10-250-29-201.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  }]
Feb 20 19:24:01.858: INFO: ss-2  ip-10-250-8-15.eu-west-1.compute.internal    Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  }]
Feb 20 19:24:01.858: INFO: 
Feb 20 19:24:01.858: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 20 19:24:02.901: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 20 19:24:02.901: INFO: ss-0  ip-10-250-8-15.eu-west-1.compute.internal    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:10 +0000 UTC  }]
Feb 20 19:24:02.901: INFO: ss-1  ip-10-250-29-201.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  }]
Feb 20 19:24:02.901: INFO: ss-2  ip-10-250-8-15.eu-west-1.compute.internal    Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  }]
Feb 20 19:24:02.901: INFO: 
Feb 20 19:24:02.901: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 20 19:24:03.943: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb 20 19:24:03.943: INFO: ss-0  ip-10-250-8-15.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:10 +0000 UTC  }]
Feb 20 19:24:03.943: INFO: ss-2  ip-10-250-8-15.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:23:31 +0000 UTC  }]
Feb 20 19:24:03.943: INFO: 
Feb 20 19:24:03.943: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 20 19:24:04.986: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.700948787s
Feb 20 19:24:06.028: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.658572258s
Feb 20 19:24:07.070: INFO: Verifying statefulset ss doesn't scale past 0 for another 616.322737ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-694lv
Feb 20 19:24:08.113: INFO: Scaling statefulset ss to 0
Feb 20 19:24:08.239: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 20 19:24:08.282: INFO: Deleting all statefulset in ns e2e-tests-statefulset-694lv
Feb 20 19:24:08.325: INFO: Scaling statefulset ss to 0
Feb 20 19:24:08.453: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 19:24:08.495: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:24:08.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-694lv" for this suite.
Feb 20 19:24:14.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:24:15.341: INFO: namespace: e2e-tests-statefulset-694lv, resource: bindings, ignored listing per whitelist
Feb 20 19:24:16.438: INFO: namespace e2e-tests-statefulset-694lv deletion completed in 7.771880167s

• [SLOW TEST:68.036 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:24:16.438: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-zjj2p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 20 19:24:18.178: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-zjj2p'
Feb 20 19:24:18.504: INFO: stderr: ""
Feb 20 19:24:18.504: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Feb 20 19:24:18.546: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-zjj2p'
Feb 20 19:24:21.140: INFO: stderr: ""
Feb 20 19:24:21.140: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:24:21.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zjj2p" for this suite.
Feb 20 19:24:27.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:24:27.686: INFO: namespace: e2e-tests-kubectl-zjj2p, resource: bindings, ignored listing per whitelist
Feb 20 19:24:28.923: INFO: namespace e2e-tests-kubectl-zjj2p deletion completed in 7.740027662s

• [SLOW TEST:12.485 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:24:28.924: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-8lgct
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Feb 20 19:24:30.766: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-8lgct'
Feb 20 19:24:31.305: INFO: stderr: ""
Feb 20 19:24:31.305: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Feb 20 19:24:32.348: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 19:24:32.348: INFO: Found 1 / 1
Feb 20 19:24:32.348: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 20 19:24:32.390: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 19:24:32.390: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb 20 19:24:32.390: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml logs redis-master-hzcdz redis-master --namespace=e2e-tests-kubectl-8lgct'
Feb 20 19:24:32.774: INFO: stderr: ""
Feb 20 19:24:32.774: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 20 Feb 19:24:32.135 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 20 Feb 19:24:32.136 # Server started, Redis version 3.2.12\n1:M 20 Feb 19:24:32.136 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 20 Feb 19:24:32.136 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb 20 19:24:32.775: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml log redis-master-hzcdz redis-master --namespace=e2e-tests-kubectl-8lgct --tail=1'
Feb 20 19:24:33.101: INFO: stderr: ""
Feb 20 19:24:33.101: INFO: stdout: "1:M 20 Feb 19:24:32.136 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb 20 19:24:33.101: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml log redis-master-hzcdz redis-master --namespace=e2e-tests-kubectl-8lgct --limit-bytes=1'
Feb 20 19:24:33.452: INFO: stderr: ""
Feb 20 19:24:33.452: INFO: stdout: " "
STEP: exposing timestamps
Feb 20 19:24:33.452: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml log redis-master-hzcdz redis-master --namespace=e2e-tests-kubectl-8lgct --tail=1 --timestamps'
Feb 20 19:24:33.797: INFO: stderr: ""
Feb 20 19:24:33.797: INFO: stdout: "2019-02-20T19:24:32.136436785Z 1:M 20 Feb 19:24:32.136 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb 20 19:24:36.298: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml log redis-master-hzcdz redis-master --namespace=e2e-tests-kubectl-8lgct --since=1s'
Feb 20 19:24:36.613: INFO: stderr: ""
Feb 20 19:24:36.613: INFO: stdout: ""
Feb 20 19:24:36.613: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml log redis-master-hzcdz redis-master --namespace=e2e-tests-kubectl-8lgct --since=24h'
Feb 20 19:24:36.948: INFO: stderr: ""
Feb 20 19:24:36.949: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 20 Feb 19:24:32.135 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 20 Feb 19:24:32.136 # Server started, Redis version 3.2.12\n1:M 20 Feb 19:24:32.136 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 20 Feb 19:24:32.136 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Feb 20 19:24:36.949: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-8lgct'
Feb 20 19:24:37.275: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 19:24:37.275: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb 20 19:24:37.275: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-8lgct'
Feb 20 19:24:37.597: INFO: stderr: "No resources found.\n"
Feb 20 19:24:37.597: INFO: stdout: ""
Feb 20 19:24:37.597: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml get pods -l name=nginx --namespace=e2e-tests-kubectl-8lgct -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 20 19:24:37.848: INFO: stderr: ""
Feb 20 19:24:37.848: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:24:37.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8lgct" for this suite.
Feb 20 19:25:00.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:25:00.857: INFO: namespace: e2e-tests-kubectl-8lgct, resource: bindings, ignored listing per whitelist
Feb 20 19:25:01.619: INFO: namespace e2e-tests-kubectl-8lgct deletion completed in 23.728848696s

• [SLOW TEST:32.696 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:25:01.620: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-7snd2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-38edbb28-3545-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume configMaps
Feb 20 19:25:03.651: INFO: Waiting up to 5m0s for pod "pod-configmaps-38f42c0a-3545-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-configmap-7snd2" to be "success or failure"
Feb 20 19:25:03.693: INFO: Pod "pod-configmaps-38f42c0a-3545-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 42.567943ms
Feb 20 19:25:05.736: INFO: Pod "pod-configmaps-38f42c0a-3545-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085334206s
STEP: Saw pod success
Feb 20 19:25:05.736: INFO: Pod "pod-configmaps-38f42c0a-3545-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:25:05.778: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-configmaps-38f42c0a-3545-11e9-997a-8a6f774fb32b container configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 19:25:05.875: INFO: Waiting for pod pod-configmaps-38f42c0a-3545-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:25:05.917: INFO: Pod pod-configmaps-38f42c0a-3545-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:25:05.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7snd2" for this suite.
Feb 20 19:25:12.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:25:13.450: INFO: namespace: e2e-tests-configmap-7snd2, resource: bindings, ignored listing per whitelist
Feb 20 19:25:13.705: INFO: namespace e2e-tests-configmap-7snd2 deletion completed in 7.74504396s

• [SLOW TEST:12.085 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:25:13.705: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-fhndl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-4014b516-3545-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume secrets
Feb 20 19:25:15.650: INFO: Waiting up to 5m0s for pod "pod-secrets-401b48ac-3545-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-secrets-fhndl" to be "success or failure"
Feb 20 19:25:15.693: INFO: Pod "pod-secrets-401b48ac-3545-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 42.934033ms
Feb 20 19:25:17.736: INFO: Pod "pod-secrets-401b48ac-3545-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085484549s
STEP: Saw pod success
Feb 20 19:25:17.736: INFO: Pod "pod-secrets-401b48ac-3545-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:25:17.778: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-secrets-401b48ac-3545-11e9-997a-8a6f774fb32b container secret-volume-test: <nil>
STEP: delete the pod
Feb 20 19:25:17.870: INFO: Waiting for pod pod-secrets-401b48ac-3545-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:25:17.912: INFO: Pod pod-secrets-401b48ac-3545-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:25:17.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fhndl" for this suite.
Feb 20 19:25:24.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:25:24.499: INFO: namespace: e2e-tests-secrets-fhndl, resource: bindings, ignored listing per whitelist
Feb 20 19:25:25.668: INFO: namespace e2e-tests-secrets-fhndl deletion completed in 7.714170829s

• [SLOW TEST:11.963 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:25:25.668: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-t78fn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb 20 19:25:33.714: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-t78fn PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 19:25:33.714: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 19:25:34.369: INFO: Exec stderr: ""
Feb 20 19:25:34.369: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-t78fn PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 19:25:34.369: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 19:25:34.965: INFO: Exec stderr: ""
Feb 20 19:25:34.965: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-t78fn PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 19:25:34.965: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 19:25:35.530: INFO: Exec stderr: ""
Feb 20 19:25:35.530: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-t78fn PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 19:25:35.530: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 19:25:36.127: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb 20 19:25:36.127: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-t78fn PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 19:25:36.127: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 19:25:36.778: INFO: Exec stderr: ""
Feb 20 19:25:36.779: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-t78fn PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 19:25:36.779: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 19:25:37.385: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb 20 19:25:37.385: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-t78fn PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 19:25:37.385: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 19:25:37.993: INFO: Exec stderr: ""
Feb 20 19:25:37.993: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-t78fn PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 19:25:37.993: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 19:25:38.628: INFO: Exec stderr: ""
Feb 20 19:25:38.628: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-t78fn PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 19:25:38.628: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 19:25:39.303: INFO: Exec stderr: ""
Feb 20 19:25:39.303: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-t78fn PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 19:25:39.303: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 19:25:39.937: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:25:39.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-t78fn" for this suite.
Feb 20 19:26:26.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:26:27.508: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-t78fn, resource: bindings, ignored listing per whitelist
Feb 20 19:26:27.970: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-t78fn deletion completed in 47.990299992s

• [SLOW TEST:62.302 seconds]
[k8s.io] KubeletManagedEtcHosts
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:26:27.971: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-wlm4j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0220 19:27:00.108941   29709 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 20 19:27:00.109: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:27:00.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-wlm4j" for this suite.
Feb 20 19:27:06.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:27:07.882: INFO: namespace: e2e-tests-gc-wlm4j, resource: bindings, ignored listing per whitelist
Feb 20 19:27:07.882: INFO: namespace e2e-tests-gc-wlm4j deletion completed in 7.73133767s

• [SLOW TEST:39.912 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:27:07.883: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-bqb8c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-89lw
STEP: Creating a pod to test atomic-volume-subpath
Feb 20 19:27:09.794: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-89lw" in namespace "e2e-tests-subpath-bqb8c" to be "success or failure"
Feb 20 19:27:09.836: INFO: Pod "pod-subpath-test-projected-89lw": Phase="Pending", Reason="", readiness=false. Elapsed: 41.473021ms
Feb 20 19:27:11.879: INFO: Pod "pod-subpath-test-projected-89lw": Phase="Running", Reason="", readiness=false. Elapsed: 2.084363476s
Feb 20 19:27:13.921: INFO: Pod "pod-subpath-test-projected-89lw": Phase="Running", Reason="", readiness=false. Elapsed: 4.126804649s
Feb 20 19:27:15.964: INFO: Pod "pod-subpath-test-projected-89lw": Phase="Running", Reason="", readiness=false. Elapsed: 6.169867594s
Feb 20 19:27:18.007: INFO: Pod "pod-subpath-test-projected-89lw": Phase="Running", Reason="", readiness=false. Elapsed: 8.212499652s
Feb 20 19:27:20.089: INFO: Pod "pod-subpath-test-projected-89lw": Phase="Running", Reason="", readiness=false. Elapsed: 10.294817783s
Feb 20 19:27:22.131: INFO: Pod "pod-subpath-test-projected-89lw": Phase="Running", Reason="", readiness=false. Elapsed: 12.33717974s
Feb 20 19:27:24.174: INFO: Pod "pod-subpath-test-projected-89lw": Phase="Running", Reason="", readiness=false. Elapsed: 14.379459249s
Feb 20 19:27:26.216: INFO: Pod "pod-subpath-test-projected-89lw": Phase="Running", Reason="", readiness=false. Elapsed: 16.421597065s
Feb 20 19:27:28.258: INFO: Pod "pod-subpath-test-projected-89lw": Phase="Running", Reason="", readiness=false. Elapsed: 18.463960629s
Feb 20 19:27:30.300: INFO: Pod "pod-subpath-test-projected-89lw": Phase="Running", Reason="", readiness=false. Elapsed: 20.50622403s
Feb 20 19:27:32.343: INFO: Pod "pod-subpath-test-projected-89lw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.548755948s
STEP: Saw pod success
Feb 20 19:27:32.343: INFO: Pod "pod-subpath-test-projected-89lw" satisfied condition "success or failure"
Feb 20 19:27:32.385: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-subpath-test-projected-89lw container test-container-subpath-projected-89lw: <nil>
STEP: delete the pod
Feb 20 19:27:32.478: INFO: Waiting for pod pod-subpath-test-projected-89lw to disappear
Feb 20 19:27:32.520: INFO: Pod pod-subpath-test-projected-89lw no longer exists
STEP: Deleting pod pod-subpath-test-projected-89lw
Feb 20 19:27:32.520: INFO: Deleting pod "pod-subpath-test-projected-89lw" in namespace "e2e-tests-subpath-bqb8c"
[AfterEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:27:32.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-bqb8c" for this suite.
Feb 20 19:27:38.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:27:39.482: INFO: namespace: e2e-tests-subpath-bqb8c, resource: bindings, ignored listing per whitelist
Feb 20 19:27:40.366: INFO: namespace e2e-tests-subpath-bqb8c deletion completed in 7.762134617s

• [SLOW TEST:32.484 seconds]
[sig-storage] Subpath
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:27:40.366: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-r55zc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 20 19:27:44.886: INFO: Successfully updated pod "labelsupdate97682b11-3545-11e9-997a-8a6f774fb32b"
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:27:46.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-r55zc" for this suite.
Feb 20 19:28:09.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:28:10.528: INFO: namespace: e2e-tests-downward-api-r55zc, resource: bindings, ignored listing per whitelist
Feb 20 19:28:10.780: INFO: namespace e2e-tests-downward-api-r55zc deletion completed in 23.75499854s

• [SLOW TEST:30.414 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:28:10.780: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-q67wt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 19:28:12.714: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a9a542ed-3545-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-projected-q67wt" to be "success or failure"
Feb 20 19:28:12.758: INFO: Pod "downwardapi-volume-a9a542ed-3545-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 43.422112ms
Feb 20 19:28:14.800: INFO: Pod "downwardapi-volume-a9a542ed-3545-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085876225s
STEP: Saw pod success
Feb 20 19:28:14.800: INFO: Pod "downwardapi-volume-a9a542ed-3545-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:28:14.842: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod downwardapi-volume-a9a542ed-3545-11e9-997a-8a6f774fb32b container client-container: <nil>
STEP: delete the pod
Feb 20 19:28:15.022: INFO: Waiting for pod downwardapi-volume-a9a542ed-3545-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:28:15.065: INFO: Pod downwardapi-volume-a9a542ed-3545-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:28:15.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-q67wt" for this suite.
Feb 20 19:28:21.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:28:21.575: INFO: namespace: e2e-tests-projected-q67wt, resource: bindings, ignored listing per whitelist
Feb 20 19:28:22.843: INFO: namespace e2e-tests-projected-q67wt deletion completed in 7.735180489s

• [SLOW TEST:12.063 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:28:22.843: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-p5z44
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Feb 20 19:28:24.705: INFO: Waiting up to 5m0s for pod "var-expansion-b0caee16-3545-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-var-expansion-p5z44" to be "success or failure"
Feb 20 19:28:24.746: INFO: Pod "var-expansion-b0caee16-3545-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.772737ms
Feb 20 19:28:26.789: INFO: Pod "var-expansion-b0caee16-3545-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084119252s
STEP: Saw pod success
Feb 20 19:28:26.789: INFO: Pod "var-expansion-b0caee16-3545-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:28:26.830: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod var-expansion-b0caee16-3545-11e9-997a-8a6f774fb32b container dapi-container: <nil>
STEP: delete the pod
Feb 20 19:28:26.924: INFO: Waiting for pod var-expansion-b0caee16-3545-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:28:26.966: INFO: Pod var-expansion-b0caee16-3545-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:28:26.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-p5z44" for this suite.
Feb 20 19:28:33.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:28:33.812: INFO: namespace: e2e-tests-var-expansion-p5z44, resource: bindings, ignored listing per whitelist
Feb 20 19:28:34.731: INFO: namespace e2e-tests-var-expansion-p5z44 deletion completed in 7.722341464s

• [SLOW TEST:11.888 seconds]
[k8s.io] Variable Expansion
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:28:34.732: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-tb2mb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Feb 20 19:28:36.467: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 20 19:28:36.552: INFO: Waiting for terminating namespaces to be deleted...
Feb 20 19:28:36.594: INFO: 
Logging pods the kubelet thinks is on node ip-10-250-29-201.eu-west-1.compute.internal before test
Feb 20 19:28:36.725: INFO: coredns-5f4748c5f-ln884 from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:28:36.725: INFO: 	Container coredns ready: true, restart count 0
Feb 20 19:28:36.725: INFO: addons-nginx-ingress-controller-6574bbbf6f-vvn47 from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:28:36.725: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 20 19:28:36.725: INFO: addons-kubernetes-dashboard-5f64f76bd-fghf5 from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:28:36.725: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb 20 19:28:36.725: INFO: calico-node-dp8b4 from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:28:36.725: INFO: 	Container calico-node ready: true, restart count 0
Feb 20 19:28:36.726: INFO: node-exporter-hr89s from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:28:36.726: INFO: 	Container node-exporter ready: true, restart count 0
Feb 20 19:28:36.726: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6498456576-7cql9 from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:28:36.726: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Feb 20 19:28:36.726: INFO: blackbox-exporter-64f6f7f998-4jrfr from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:28:36.726: INFO: 	Container blackbox-exporter ready: true, restart count 0
Feb 20 19:28:36.726: INFO: vpn-shoot-7c466dcf55-7l9tt from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:28:36.726: INFO: 	Container vpn-shoot ready: true, restart count 0
Feb 20 19:28:36.726: INFO: metrics-server-67d85b8585-xjbtx from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:28:36.726: INFO: 	Container metrics-server ready: true, restart count 0
Feb 20 19:28:36.726: INFO: addons-kube-lego-648f8c9f5c-72vfs from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:28:36.726: INFO: 	Container kube-lego ready: true, restart count 0
Feb 20 19:28:36.726: INFO: kube-proxy-95xsf from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:28:36.726: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 20 19:28:36.726: INFO: 
Logging pods the kubelet thinks is on node ip-10-250-8-15.eu-west-1.compute.internal before test
Feb 20 19:28:36.772: INFO: kube-proxy-q6jfv from kube-system started at 2019-02-20 17:54:44 +0000 UTC (1 container statuses recorded)
Feb 20 19:28:36.772: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 20 19:28:36.772: INFO: calico-node-vgnmn from kube-system started at 2019-02-20 17:54:44 +0000 UTC (1 container statuses recorded)
Feb 20 19:28:36.772: INFO: 	Container calico-node ready: true, restart count 0
Feb 20 19:28:36.772: INFO: node-exporter-jvhwp from kube-system started at 2019-02-20 17:54:44 +0000 UTC (1 container statuses recorded)
Feb 20 19:28:36.772: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node ip-10-250-29-201.eu-west-1.compute.internal
STEP: verifying the node has the label node ip-10-250-8-15.eu-west-1.compute.internal
Feb 20 19:28:37.111: INFO: Pod addons-kube-lego-648f8c9f5c-72vfs requesting resource cpu=20m on Node ip-10-250-29-201.eu-west-1.compute.internal
Feb 20 19:28:37.111: INFO: Pod addons-kubernetes-dashboard-5f64f76bd-fghf5 requesting resource cpu=50m on Node ip-10-250-29-201.eu-west-1.compute.internal
Feb 20 19:28:37.111: INFO: Pod addons-nginx-ingress-controller-6574bbbf6f-vvn47 requesting resource cpu=100m on Node ip-10-250-29-201.eu-west-1.compute.internal
Feb 20 19:28:37.111: INFO: Pod addons-nginx-ingress-nginx-ingress-k8s-backend-6498456576-7cql9 requesting resource cpu=0m on Node ip-10-250-29-201.eu-west-1.compute.internal
Feb 20 19:28:37.111: INFO: Pod blackbox-exporter-64f6f7f998-4jrfr requesting resource cpu=5m on Node ip-10-250-29-201.eu-west-1.compute.internal
Feb 20 19:28:37.111: INFO: Pod calico-node-dp8b4 requesting resource cpu=100m on Node ip-10-250-29-201.eu-west-1.compute.internal
Feb 20 19:28:37.111: INFO: Pod calico-node-vgnmn requesting resource cpu=100m on Node ip-10-250-8-15.eu-west-1.compute.internal
Feb 20 19:28:37.111: INFO: Pod coredns-5f4748c5f-ln884 requesting resource cpu=50m on Node ip-10-250-29-201.eu-west-1.compute.internal
Feb 20 19:28:37.111: INFO: Pod kube-proxy-95xsf requesting resource cpu=20m on Node ip-10-250-29-201.eu-west-1.compute.internal
Feb 20 19:28:37.111: INFO: Pod kube-proxy-q6jfv requesting resource cpu=20m on Node ip-10-250-8-15.eu-west-1.compute.internal
Feb 20 19:28:37.111: INFO: Pod metrics-server-67d85b8585-xjbtx requesting resource cpu=20m on Node ip-10-250-29-201.eu-west-1.compute.internal
Feb 20 19:28:37.111: INFO: Pod node-exporter-hr89s requesting resource cpu=5m on Node ip-10-250-29-201.eu-west-1.compute.internal
Feb 20 19:28:37.111: INFO: Pod node-exporter-jvhwp requesting resource cpu=5m on Node ip-10-250-8-15.eu-west-1.compute.internal
Feb 20 19:28:37.111: INFO: Pod vpn-shoot-7c466dcf55-7l9tt requesting resource cpu=50m on Node ip-10-250-29-201.eu-west-1.compute.internal
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b836ad40-3545-11e9-997a-8a6f774fb32b.1585292c581e8f37], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-tb2mb/filler-pod-b836ad40-3545-11e9-997a-8a6f774fb32b to ip-10-250-8-15.eu-west-1.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b836ad40-3545-11e9-997a-8a6f774fb32b.1585292c80dfb3f7], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b836ad40-3545-11e9-997a-8a6f774fb32b.1585292c836c2c5d], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b836ad40-3545-11e9-997a-8a6f774fb32b.1585292c8a672feb], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b83d765b-3545-11e9-997a-8a6f774fb32b.1585292c5aa12e8d], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-tb2mb/filler-pod-b83d765b-3545-11e9-997a-8a6f774fb32b to ip-10-250-29-201.eu-west-1.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b83d765b-3545-11e9-997a-8a6f774fb32b.1585292c8426fd9b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b83d765b-3545-11e9-997a-8a6f774fb32b.1585292c86ba926d], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b83d765b-3545-11e9-997a-8a6f774fb32b.1585292c8d95e403], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1585292ce0c8f5e9], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node ip-10-250-29-201.eu-west-1.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-250-8-15.eu-west-1.compute.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:28:40.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-tb2mb" for this suite.
Feb 20 19:28:46.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:28:47.295: INFO: namespace: e2e-tests-sched-pred-tb2mb, resource: bindings, ignored listing per whitelist
Feb 20 19:28:48.510: INFO: namespace e2e-tests-sched-pred-tb2mb deletion completed in 7.717897105s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:13.779 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:28:48.511: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jtp27
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-c00d61be-3545-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume configMaps
Feb 20 19:28:50.348: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c013ca94-3545-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-projected-jtp27" to be "success or failure"
Feb 20 19:28:50.390: INFO: Pod "pod-projected-configmaps-c013ca94-3545-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.448437ms
Feb 20 19:28:52.432: INFO: Pod "pod-projected-configmaps-c013ca94-3545-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084002s
STEP: Saw pod success
Feb 20 19:28:52.432: INFO: Pod "pod-projected-configmaps-c013ca94-3545-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:28:52.474: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-projected-configmaps-c013ca94-3545-11e9-997a-8a6f774fb32b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 19:28:52.566: INFO: Waiting for pod pod-projected-configmaps-c013ca94-3545-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:28:52.608: INFO: Pod pod-projected-configmaps-c013ca94-3545-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:28:52.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jtp27" for this suite.
Feb 20 19:28:58.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:28:59.556: INFO: namespace: e2e-tests-projected-jtp27, resource: bindings, ignored listing per whitelist
Feb 20 19:29:00.438: INFO: namespace e2e-tests-projected-jtp27 deletion completed in 7.787403194s

• [SLOW TEST:11.927 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:29:00.438: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-p9n58
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 20 19:29:02.213: INFO: Waiting up to 5m0s for pod "pod-c7264de0-3545-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-emptydir-p9n58" to be "success or failure"
Feb 20 19:29:02.257: INFO: Pod "pod-c7264de0-3545-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 43.072649ms
Feb 20 19:29:04.299: INFO: Pod "pod-c7264de0-3545-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085293076s
STEP: Saw pod success
Feb 20 19:29:04.299: INFO: Pod "pod-c7264de0-3545-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:29:04.340: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-c7264de0-3545-11e9-997a-8a6f774fb32b container test-container: <nil>
STEP: delete the pod
Feb 20 19:29:04.433: INFO: Waiting for pod pod-c7264de0-3545-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:29:04.475: INFO: Pod pod-c7264de0-3545-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:29:04.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-p9n58" for this suite.
Feb 20 19:29:10.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:29:11.322: INFO: namespace: e2e-tests-emptydir-p9n58, resource: bindings, ignored listing per whitelist
Feb 20 19:29:12.299: INFO: namespace e2e-tests-emptydir-p9n58 deletion completed in 7.780715217s

• [SLOW TEST:11.861 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:29:12.299: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-jl5wq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-jl5wq
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 20 19:29:14.071: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 20 19:29:36.834: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://100.96.1.219:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-jl5wq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 19:29:36.834: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 19:29:37.622: INFO: Found all expected endpoints: [netserver-0]
Feb 20 19:29:37.664: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://100.96.0.61:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-jl5wq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 19:29:37.664: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 19:29:38.342: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:29:38.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-jl5wq" for this suite.
Feb 20 19:30:00.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:30:01.878: INFO: namespace: e2e-tests-pod-network-test-jl5wq, resource: bindings, ignored listing per whitelist
Feb 20 19:30:02.368: INFO: namespace e2e-tests-pod-network-test-jl5wq deletion completed in 23.983461489s

• [SLOW TEST:50.069 seconds]
[sig-network] Networking
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:30:02.368: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-jgndl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 20 19:30:07.077: INFO: Successfully updated pod "pod-update-activedeadlineseconds-ec2b14ce-3545-11e9-997a-8a6f774fb32b"
Feb 20 19:30:07.077: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-ec2b14ce-3545-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-pods-jgndl" to be "terminated due to deadline exceeded"
Feb 20 19:30:07.118: INFO: Pod "pod-update-activedeadlineseconds-ec2b14ce-3545-11e9-997a-8a6f774fb32b": Phase="Running", Reason="", readiness=true. Elapsed: 41.528524ms
Feb 20 19:30:09.161: INFO: Pod "pod-update-activedeadlineseconds-ec2b14ce-3545-11e9-997a-8a6f774fb32b": Phase="Running", Reason="", readiness=true. Elapsed: 2.083992178s
Feb 20 19:30:11.207: INFO: Pod "pod-update-activedeadlineseconds-ec2b14ce-3545-11e9-997a-8a6f774fb32b": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.129844189s
Feb 20 19:30:11.207: INFO: Pod "pod-update-activedeadlineseconds-ec2b14ce-3545-11e9-997a-8a6f774fb32b" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:30:11.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-jgndl" for this suite.
Feb 20 19:30:17.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:30:17.849: INFO: namespace: e2e-tests-pods-jgndl, resource: bindings, ignored listing per whitelist
Feb 20 19:30:19.123: INFO: namespace e2e-tests-pods-jgndl deletion completed in 7.872531126s

• [SLOW TEST:16.755 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:30:19.124: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-n2nfl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: Gathering metrics
W0220 19:30:21.166942   29709 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 20 19:30:21.167: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:30:21.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-n2nfl" for this suite.
Feb 20 19:30:27.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:30:28.087: INFO: namespace: e2e-tests-gc-n2nfl, resource: bindings, ignored listing per whitelist
Feb 20 19:30:28.978: INFO: namespace e2e-tests-gc-n2nfl deletion completed in 7.768678728s

• [SLOW TEST:9.855 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:30:28.978: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-l84dx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 20 19:30:30.818: INFO: Waiting up to 5m0s for pod "pod-fbf62811-3545-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-emptydir-l84dx" to be "success or failure"
Feb 20 19:30:30.860: INFO: Pod "pod-fbf62811-3545-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.592305ms
Feb 20 19:30:32.903: INFO: Pod "pod-fbf62811-3545-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084866024s
STEP: Saw pod success
Feb 20 19:30:32.903: INFO: Pod "pod-fbf62811-3545-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:30:32.946: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-fbf62811-3545-11e9-997a-8a6f774fb32b container test-container: <nil>
STEP: delete the pod
Feb 20 19:30:33.040: INFO: Waiting for pod pod-fbf62811-3545-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:30:33.083: INFO: Pod pod-fbf62811-3545-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:30:33.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-l84dx" for this suite.
Feb 20 19:30:39.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:30:40.598: INFO: namespace: e2e-tests-emptydir-l84dx, resource: bindings, ignored listing per whitelist
Feb 20 19:30:40.850: INFO: namespace e2e-tests-emptydir-l84dx deletion completed in 7.724321758s

• [SLOW TEST:11.872 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:30:40.850: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-2b5v4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-02ffb6a0-3546-11e9-997a-8a6f774fb32b
Feb 20 19:30:42.667: INFO: Pod name my-hostname-basic-02ffb6a0-3546-11e9-997a-8a6f774fb32b: Found 1 pods out of 1
Feb 20 19:30:42.667: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-02ffb6a0-3546-11e9-997a-8a6f774fb32b" are running
Feb 20 19:30:44.752: INFO: Pod "my-hostname-basic-02ffb6a0-3546-11e9-997a-8a6f774fb32b-9crr9" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-20 19:30:42 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-20 19:30:42 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-02ffb6a0-3546-11e9-997a-8a6f774fb32b]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-20 19:30:42 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-02ffb6a0-3546-11e9-997a-8a6f774fb32b]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-20 19:30:42 +0000 UTC Reason: Message:}])
Feb 20 19:30:44.753: INFO: Trying to dial the pod
Feb 20 19:30:49.970: INFO: Controller my-hostname-basic-02ffb6a0-3546-11e9-997a-8a6f774fb32b: Got expected result from replica 1 [my-hostname-basic-02ffb6a0-3546-11e9-997a-8a6f774fb32b-9crr9]: "my-hostname-basic-02ffb6a0-3546-11e9-997a-8a6f774fb32b-9crr9", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:30:49.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-2b5v4" for this suite.
Feb 20 19:30:56.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:30:57.160: INFO: namespace: e2e-tests-replication-controller-2b5v4, resource: bindings, ignored listing per whitelist
Feb 20 19:30:57.791: INFO: namespace e2e-tests-replication-controller-2b5v4 deletion completed in 7.774205693s

• [SLOW TEST:16.940 seconds]
[sig-apps] ReplicationController
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:30:57.791: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-m247w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 19:30:59.613: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0d1ff238-3546-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-downward-api-m247w" to be "success or failure"
Feb 20 19:30:59.655: INFO: Pod "downwardapi-volume-0d1ff238-3546-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.777815ms
Feb 20 19:31:01.698: INFO: Pod "downwardapi-volume-0d1ff238-3546-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084249034s
STEP: Saw pod success
Feb 20 19:31:01.698: INFO: Pod "downwardapi-volume-0d1ff238-3546-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:31:01.740: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod downwardapi-volume-0d1ff238-3546-11e9-997a-8a6f774fb32b container client-container: <nil>
STEP: delete the pod
Feb 20 19:31:01.833: INFO: Waiting for pod downwardapi-volume-0d1ff238-3546-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:31:01.875: INFO: Pod downwardapi-volume-0d1ff238-3546-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:31:01.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-m247w" for this suite.
Feb 20 19:31:08.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:31:09.098: INFO: namespace: e2e-tests-downward-api-m247w, resource: bindings, ignored listing per whitelist
Feb 20 19:31:09.686: INFO: namespace e2e-tests-downward-api-m247w deletion completed in 7.768892111s

• [SLOW TEST:11.895 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:31:09.686: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-bhm8v
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Feb 20 19:31:11.367: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml --namespace=e2e-tests-kubectl-bhm8v run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb 20 19:31:16.127: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb 20 19:31:16.128: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:31:18.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bhm8v" for this suite.
Feb 20 19:31:26.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:31:27.008: INFO: namespace: e2e-tests-kubectl-bhm8v, resource: bindings, ignored listing per whitelist
Feb 20 19:31:28.065: INFO: namespace e2e-tests-kubectl-bhm8v deletion completed in 9.805758704s

• [SLOW TEST:18.379 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:31:28.065: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-52plj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-52plj
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 20 19:31:29.868: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 20 19:31:52.648: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.227:8080/dial?request=hostName&protocol=http&host=100.96.1.226&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-52plj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 19:31:52.648: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 19:31:53.321: INFO: Waiting for endpoints: map[]
Feb 20 19:31:53.364: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.227:8080/dial?request=hostName&protocol=http&host=100.96.0.62&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-52plj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 19:31:53.364: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
Feb 20 19:31:54.004: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:31:54.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-52plj" for this suite.
Feb 20 19:32:16.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:32:16.593: INFO: namespace: e2e-tests-pod-network-test-52plj, resource: bindings, ignored listing per whitelist
Feb 20 19:32:17.816: INFO: namespace e2e-tests-pod-network-test-52plj deletion completed in 23.769458087s

• [SLOW TEST:49.751 seconds]
[sig-network] Networking
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:32:17.817: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-rsl5j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 20 19:32:19.710: INFO: Waiting up to 5m0s for pod "pod-3cdd8066-3546-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-emptydir-rsl5j" to be "success or failure"
Feb 20 19:32:19.752: INFO: Pod "pod-3cdd8066-3546-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 42.488987ms
Feb 20 19:32:21.798: INFO: Pod "pod-3cdd8066-3546-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.088513053s
STEP: Saw pod success
Feb 20 19:32:21.798: INFO: Pod "pod-3cdd8066-3546-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:32:21.840: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-3cdd8066-3546-11e9-997a-8a6f774fb32b container test-container: <nil>
STEP: delete the pod
Feb 20 19:32:21.935: INFO: Waiting for pod pod-3cdd8066-3546-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:32:21.977: INFO: Pod pod-3cdd8066-3546-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:32:21.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rsl5j" for this suite.
Feb 20 19:32:28.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:32:28.390: INFO: namespace: e2e-tests-emptydir-rsl5j, resource: bindings, ignored listing per whitelist
Feb 20 19:32:29.781: INFO: namespace e2e-tests-emptydir-rsl5j deletion completed in 7.760965295s

• [SLOW TEST:11.965 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:32:29.782: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-np2hq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Feb 20 19:32:32.215: INFO: Waiting up to 5m0s for pod "pod-service-account-4451feeb-3546-11e9-997a-8a6f774fb32b-hnp4k" in namespace "e2e-tests-svcaccounts-np2hq" to be "success or failure"
Feb 20 19:32:32.256: INFO: Pod "pod-service-account-4451feeb-3546-11e9-997a-8a6f774fb32b-hnp4k": Phase="Pending", Reason="", readiness=false. Elapsed: 41.346087ms
Feb 20 19:32:34.299: INFO: Pod "pod-service-account-4451feeb-3546-11e9-997a-8a6f774fb32b-hnp4k": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.083682301s
STEP: Saw pod success
Feb 20 19:32:34.299: INFO: Pod "pod-service-account-4451feeb-3546-11e9-997a-8a6f774fb32b-hnp4k" satisfied condition "success or failure"
Feb 20 19:32:34.340: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-service-account-4451feeb-3546-11e9-997a-8a6f774fb32b-hnp4k container token-test: <nil>
STEP: delete the pod
Feb 20 19:32:34.435: INFO: Waiting for pod pod-service-account-4451feeb-3546-11e9-997a-8a6f774fb32b-hnp4k to disappear
Feb 20 19:32:34.477: INFO: Pod pod-service-account-4451feeb-3546-11e9-997a-8a6f774fb32b-hnp4k no longer exists
STEP: Creating a pod to test consume service account root CA
Feb 20 19:32:34.521: INFO: Waiting up to 5m0s for pod "pod-service-account-4451feeb-3546-11e9-997a-8a6f774fb32b-7vvrh" in namespace "e2e-tests-svcaccounts-np2hq" to be "success or failure"
Feb 20 19:32:34.564: INFO: Pod "pod-service-account-4451feeb-3546-11e9-997a-8a6f774fb32b-7vvrh": Phase="Pending", Reason="", readiness=false. Elapsed: 43.431351ms
Feb 20 19:32:36.606: INFO: Pod "pod-service-account-4451feeb-3546-11e9-997a-8a6f774fb32b-7vvrh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085522669s
STEP: Saw pod success
Feb 20 19:32:36.606: INFO: Pod "pod-service-account-4451feeb-3546-11e9-997a-8a6f774fb32b-7vvrh" satisfied condition "success or failure"
Feb 20 19:32:36.651: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-service-account-4451feeb-3546-11e9-997a-8a6f774fb32b-7vvrh container root-ca-test: <nil>
STEP: delete the pod
Feb 20 19:32:36.747: INFO: Waiting for pod pod-service-account-4451feeb-3546-11e9-997a-8a6f774fb32b-7vvrh to disappear
Feb 20 19:32:36.788: INFO: Pod pod-service-account-4451feeb-3546-11e9-997a-8a6f774fb32b-7vvrh no longer exists
STEP: Creating a pod to test consume service account namespace
Feb 20 19:32:36.832: INFO: Waiting up to 5m0s for pod "pod-service-account-4451feeb-3546-11e9-997a-8a6f774fb32b-rvdx9" in namespace "e2e-tests-svcaccounts-np2hq" to be "success or failure"
Feb 20 19:32:36.874: INFO: Pod "pod-service-account-4451feeb-3546-11e9-997a-8a6f774fb32b-rvdx9": Phase="Pending", Reason="", readiness=false. Elapsed: 41.87195ms
Feb 20 19:32:38.916: INFO: Pod "pod-service-account-4451feeb-3546-11e9-997a-8a6f774fb32b-rvdx9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084250828s
STEP: Saw pod success
Feb 20 19:32:38.917: INFO: Pod "pod-service-account-4451feeb-3546-11e9-997a-8a6f774fb32b-rvdx9" satisfied condition "success or failure"
Feb 20 19:32:38.958: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-service-account-4451feeb-3546-11e9-997a-8a6f774fb32b-rvdx9 container namespace-test: <nil>
STEP: delete the pod
Feb 20 19:32:39.053: INFO: Waiting for pod pod-service-account-4451feeb-3546-11e9-997a-8a6f774fb32b-rvdx9 to disappear
Feb 20 19:32:39.094: INFO: Pod pod-service-account-4451feeb-3546-11e9-997a-8a6f774fb32b-rvdx9 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:32:39.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-np2hq" for this suite.
Feb 20 19:32:45.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:32:45.948: INFO: namespace: e2e-tests-svcaccounts-np2hq, resource: bindings, ignored listing per whitelist
Feb 20 19:32:46.930: INFO: namespace e2e-tests-svcaccounts-np2hq deletion completed in 7.793015441s

• [SLOW TEST:17.148 seconds]
[sig-auth] ServiceAccounts
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:32:46.930: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-zmzkb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 20 19:32:48.886: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb 20 19:32:48.970: INFO: Number of nodes with available pods: 0
Feb 20 19:32:48.970: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb 20 19:32:49.141: INFO: Number of nodes with available pods: 0
Feb 20 19:32:49.141: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:32:50.184: INFO: Number of nodes with available pods: 1
Feb 20 19:32:50.184: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb 20 19:32:50.310: INFO: failed to update node due to resource version conflict
Feb 20 19:32:51.437: INFO: Number of nodes with available pods: 0
Feb 20 19:32:51.437: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb 20 19:32:51.522: INFO: Number of nodes with available pods: 0
Feb 20 19:32:51.522: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:32:52.567: INFO: Number of nodes with available pods: 0
Feb 20 19:32:52.567: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:32:53.564: INFO: Number of nodes with available pods: 0
Feb 20 19:32:53.564: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:32:54.565: INFO: Number of nodes with available pods: 0
Feb 20 19:32:54.565: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:32:55.567: INFO: Number of nodes with available pods: 0
Feb 20 19:32:55.567: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:32:56.567: INFO: Number of nodes with available pods: 0
Feb 20 19:32:56.567: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:32:57.564: INFO: Number of nodes with available pods: 0
Feb 20 19:32:57.564: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:32:58.569: INFO: Number of nodes with available pods: 0
Feb 20 19:32:58.569: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:32:59.564: INFO: Number of nodes with available pods: 0
Feb 20 19:32:59.564: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:00.564: INFO: Number of nodes with available pods: 0
Feb 20 19:33:00.565: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:01.572: INFO: Number of nodes with available pods: 0
Feb 20 19:33:01.572: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:02.565: INFO: Number of nodes with available pods: 0
Feb 20 19:33:02.565: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:03.564: INFO: Number of nodes with available pods: 0
Feb 20 19:33:03.564: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:04.566: INFO: Number of nodes with available pods: 0
Feb 20 19:33:04.566: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:05.566: INFO: Number of nodes with available pods: 0
Feb 20 19:33:05.566: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:06.600: INFO: Number of nodes with available pods: 0
Feb 20 19:33:06.600: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:07.564: INFO: Number of nodes with available pods: 0
Feb 20 19:33:07.564: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:08.566: INFO: Number of nodes with available pods: 0
Feb 20 19:33:08.566: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:09.564: INFO: Number of nodes with available pods: 0
Feb 20 19:33:09.564: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:10.564: INFO: Number of nodes with available pods: 0
Feb 20 19:33:10.564: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:11.570: INFO: Number of nodes with available pods: 0
Feb 20 19:33:11.570: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:12.565: INFO: Number of nodes with available pods: 0
Feb 20 19:33:12.565: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:13.566: INFO: Number of nodes with available pods: 0
Feb 20 19:33:13.566: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:14.565: INFO: Number of nodes with available pods: 0
Feb 20 19:33:14.565: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:15.565: INFO: Number of nodes with available pods: 0
Feb 20 19:33:15.565: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:16.566: INFO: Number of nodes with available pods: 0
Feb 20 19:33:16.566: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:17.565: INFO: Number of nodes with available pods: 0
Feb 20 19:33:17.565: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:18.564: INFO: Number of nodes with available pods: 0
Feb 20 19:33:18.564: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:19.566: INFO: Number of nodes with available pods: 0
Feb 20 19:33:19.566: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:20.565: INFO: Number of nodes with available pods: 0
Feb 20 19:33:20.565: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:21.564: INFO: Number of nodes with available pods: 0
Feb 20 19:33:21.564: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:22.564: INFO: Number of nodes with available pods: 0
Feb 20 19:33:22.564: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:23.564: INFO: Number of nodes with available pods: 0
Feb 20 19:33:23.564: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:24.564: INFO: Number of nodes with available pods: 0
Feb 20 19:33:24.564: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:25.565: INFO: Number of nodes with available pods: 0
Feb 20 19:33:25.565: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:26.565: INFO: Number of nodes with available pods: 0
Feb 20 19:33:26.565: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:27.565: INFO: Number of nodes with available pods: 0
Feb 20 19:33:27.565: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:28.564: INFO: Number of nodes with available pods: 0
Feb 20 19:33:28.564: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:29.565: INFO: Number of nodes with available pods: 0
Feb 20 19:33:29.565: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:30.564: INFO: Number of nodes with available pods: 0
Feb 20 19:33:30.564: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:31.564: INFO: Number of nodes with available pods: 0
Feb 20 19:33:31.565: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:32.565: INFO: Number of nodes with available pods: 0
Feb 20 19:33:32.565: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:33.564: INFO: Number of nodes with available pods: 0
Feb 20 19:33:33.564: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:34.566: INFO: Number of nodes with available pods: 0
Feb 20 19:33:34.566: INFO: Node ip-10-250-29-201.eu-west-1.compute.internal is running more than one daemon pod
Feb 20 19:33:35.565: INFO: Number of nodes with available pods: 1
Feb 20 19:33:35.565: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-zmzkb, will wait for the garbage collector to delete the pods
Feb 20 19:33:35.783: INFO: Deleting {extensions DaemonSet} daemon-set took: 43.111378ms
Feb 20 19:33:35.884: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.198763ms
Feb 20 19:34:13.526: INFO: Number of nodes with available pods: 0
Feb 20 19:34:13.526: INFO: Number of running nodes: 0, number of available pods: 0
Feb 20 19:34:13.568: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-zmzkb/daemonsets","resourceVersion":"18545"},"items":null}

Feb 20 19:34:13.611: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-zmzkb/pods","resourceVersion":"18545"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:34:13.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-zmzkb" for this suite.
Feb 20 19:34:19.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:34:20.694: INFO: namespace: e2e-tests-daemonsets-zmzkb, resource: bindings, ignored listing per whitelist
Feb 20 19:34:21.616: INFO: namespace e2e-tests-daemonsets-zmzkb deletion completed in 7.789682547s

• [SLOW TEST:94.686 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:34:21.616: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-54gn4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0220 19:35:03.671788   29709 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 20 19:35:03.671: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:35:03.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-54gn4" for this suite.
Feb 20 19:35:09.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:35:10.311: INFO: namespace: e2e-tests-gc-54gn4, resource: bindings, ignored listing per whitelist
Feb 20 19:35:11.483: INFO: namespace e2e-tests-gc-54gn4 deletion completed in 7.767673894s

• [SLOW TEST:49.866 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:35:11.483: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-tp5k9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:35:13.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-tp5k9" for this suite.
Feb 20 19:35:35.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:35:36.184: INFO: namespace: e2e-tests-pods-tp5k9, resource: bindings, ignored listing per whitelist
Feb 20 19:35:37.126: INFO: namespace e2e-tests-pods-tp5k9 deletion completed in 23.815974068s

• [SLOW TEST:25.643 seconds]
[k8s.io] [sig-node] Pods Extended
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:35:37.127: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-tv7vk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-tv7vk/configmap-test-b399b0fc-3546-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume configMaps
Feb 20 19:35:38.956: INFO: Waiting up to 5m0s for pod "pod-configmaps-b3a02477-3546-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-configmap-tv7vk" to be "success or failure"
Feb 20 19:35:38.997: INFO: Pod "pod-configmaps-b3a02477-3546-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.428864ms
Feb 20 19:35:41.044: INFO: Pod "pod-configmaps-b3a02477-3546-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.088009107s
STEP: Saw pod success
Feb 20 19:35:41.044: INFO: Pod "pod-configmaps-b3a02477-3546-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:35:41.087: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-configmaps-b3a02477-3546-11e9-997a-8a6f774fb32b container env-test: <nil>
STEP: delete the pod
Feb 20 19:35:41.182: INFO: Waiting for pod pod-configmaps-b3a02477-3546-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:35:41.225: INFO: Pod pod-configmaps-b3a02477-3546-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:35:41.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tv7vk" for this suite.
Feb 20 19:35:47.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:35:47.563: INFO: namespace: e2e-tests-configmap-tv7vk, resource: bindings, ignored listing per whitelist
Feb 20 19:35:49.025: INFO: namespace e2e-tests-configmap-tv7vk deletion completed in 7.756629756s

• [SLOW TEST:11.898 seconds]
[sig-api-machinery] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:35:49.025: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-w2bvs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-bab1be1f-3546-11e9-997a-8a6f774fb32b
STEP: Creating a pod to test consume configMaps
Feb 20 19:35:50.856: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bab82deb-3546-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-projected-w2bvs" to be "success or failure"
Feb 20 19:35:50.897: INFO: Pod "pod-projected-configmaps-bab82deb-3546-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.729442ms
Feb 20 19:35:52.940: INFO: Pod "pod-projected-configmaps-bab82deb-3546-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084749977s
STEP: Saw pod success
Feb 20 19:35:52.940: INFO: Pod "pod-projected-configmaps-bab82deb-3546-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:35:52.982: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod pod-projected-configmaps-bab82deb-3546-11e9-997a-8a6f774fb32b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 19:35:53.074: INFO: Waiting for pod pod-projected-configmaps-bab82deb-3546-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:35:53.115: INFO: Pod pod-projected-configmaps-bab82deb-3546-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:35:53.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w2bvs" for this suite.
Feb 20 19:35:59.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:35:59.743: INFO: namespace: e2e-tests-projected-w2bvs, resource: bindings, ignored listing per whitelist
Feb 20 19:36:00.926: INFO: namespace e2e-tests-projected-w2bvs deletion completed in 7.76838752s

• [SLOW TEST:11.902 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:36:00.927: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-wstv4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-wstv4
Feb 20 19:36:04.891: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-wstv4
STEP: checking the pod's current state and verifying that restartCount is present
Feb 20 19:36:04.933: INFO: Initial restart count of pod liveness-exec is 0
Feb 20 19:36:58.108: INFO: Restart count of pod e2e-tests-container-probe-wstv4/liveness-exec is now 1 (53.174555911s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:36:58.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-wstv4" for this suite.
Feb 20 19:37:04.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:37:05.462: INFO: namespace: e2e-tests-container-probe-wstv4, resource: bindings, ignored listing per whitelist
Feb 20 19:37:05.968: INFO: namespace e2e-tests-container-probe-wstv4 deletion completed in 7.772781723s

• [SLOW TEST:65.041 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:37:05.968: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-9rf2r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Feb 20 19:37:07.666: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml api-versions'
Feb 20 19:37:08.182: INFO: stderr: ""
Feb 20 19:37:08.182: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:37:08.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9rf2r" for this suite.
Feb 20 19:37:14.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:37:14.618: INFO: namespace: e2e-tests-kubectl-9rf2r, resource: bindings, ignored listing per whitelist
Feb 20 19:37:15.992: INFO: namespace e2e-tests-kubectl-9rf2r deletion completed in 7.764757354s

• [SLOW TEST:10.024 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:37:15.992: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-pdrmg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Feb 20 19:37:17.774: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 20 19:37:17.858: INFO: Waiting for terminating namespaces to be deleted...
Feb 20 19:37:17.900: INFO: 
Logging pods the kubelet thinks is on node ip-10-250-29-201.eu-west-1.compute.internal before test
Feb 20 19:37:18.014: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6498456576-7cql9 from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:37:18.014: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Feb 20 19:37:18.014: INFO: blackbox-exporter-64f6f7f998-4jrfr from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:37:18.014: INFO: 	Container blackbox-exporter ready: true, restart count 0
Feb 20 19:37:18.014: INFO: vpn-shoot-7c466dcf55-7l9tt from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:37:18.014: INFO: 	Container vpn-shoot ready: true, restart count 0
Feb 20 19:37:18.014: INFO: metrics-server-67d85b8585-xjbtx from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:37:18.014: INFO: 	Container metrics-server ready: true, restart count 0
Feb 20 19:37:18.014: INFO: addons-kube-lego-648f8c9f5c-72vfs from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:37:18.014: INFO: 	Container kube-lego ready: true, restart count 0
Feb 20 19:37:18.014: INFO: kube-proxy-95xsf from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:37:18.014: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 20 19:37:18.014: INFO: addons-kubernetes-dashboard-5f64f76bd-fghf5 from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:37:18.014: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb 20 19:37:18.014: INFO: calico-node-dp8b4 from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:37:18.014: INFO: 	Container calico-node ready: true, restart count 0
Feb 20 19:37:18.014: INFO: node-exporter-hr89s from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:37:18.014: INFO: 	Container node-exporter ready: true, restart count 0
Feb 20 19:37:18.014: INFO: coredns-5f4748c5f-ln884 from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:37:18.014: INFO: 	Container coredns ready: true, restart count 0
Feb 20 19:37:18.014: INFO: addons-nginx-ingress-controller-6574bbbf6f-vvn47 from kube-system started at 2019-02-20 17:54:43 +0000 UTC (1 container statuses recorded)
Feb 20 19:37:18.014: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 20 19:37:18.014: INFO: 
Logging pods the kubelet thinks is on node ip-10-250-8-15.eu-west-1.compute.internal before test
Feb 20 19:37:18.062: INFO: kube-proxy-q6jfv from kube-system started at 2019-02-20 17:54:44 +0000 UTC (1 container statuses recorded)
Feb 20 19:37:18.062: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 20 19:37:18.062: INFO: calico-node-vgnmn from kube-system started at 2019-02-20 17:54:44 +0000 UTC (1 container statuses recorded)
Feb 20 19:37:18.062: INFO: 	Container calico-node ready: true, restart count 0
Feb 20 19:37:18.062: INFO: node-exporter-jvhwp from kube-system started at 2019-02-20 17:54:44 +0000 UTC (1 container statuses recorded)
Feb 20 19:37:18.062: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.158529a5ad8bfdd8], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:37:19.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-pdrmg" for this suite.
Feb 20 19:37:25.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:37:26.570: INFO: namespace: e2e-tests-sched-pred-pdrmg, resource: bindings, ignored listing per whitelist
Feb 20 19:37:27.115: INFO: namespace e2e-tests-sched-pred-pdrmg deletion completed in 7.731954207s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:11.123 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:37:27.115: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fmp72
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 20 19:37:28.911: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f52a235a-3546-11e9-997a-8a6f774fb32b" in namespace "e2e-tests-projected-fmp72" to be "success or failure"
Feb 20 19:37:28.952: INFO: Pod "downwardapi-volume-f52a235a-3546-11e9-997a-8a6f774fb32b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.650788ms
Feb 20 19:37:30.995: INFO: Pod "downwardapi-volume-f52a235a-3546-11e9-997a-8a6f774fb32b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.084240863s
STEP: Saw pod success
Feb 20 19:37:30.995: INFO: Pod "downwardapi-volume-f52a235a-3546-11e9-997a-8a6f774fb32b" satisfied condition "success or failure"
Feb 20 19:37:31.037: INFO: Trying to get logs from node ip-10-250-8-15.eu-west-1.compute.internal pod downwardapi-volume-f52a235a-3546-11e9-997a-8a6f774fb32b container client-container: <nil>
STEP: delete the pod
Feb 20 19:37:31.131: INFO: Waiting for pod downwardapi-volume-f52a235a-3546-11e9-997a-8a6f774fb32b to disappear
Feb 20 19:37:31.172: INFO: Pod downwardapi-volume-f52a235a-3546-11e9-997a-8a6f774fb32b no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:37:31.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fmp72" for this suite.
Feb 20 19:37:37.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:37:37.756: INFO: namespace: e2e-tests-projected-fmp72, resource: bindings, ignored listing per whitelist
Feb 20 19:37:38.973: INFO: namespace e2e-tests-projected-fmp72 deletion completed in 7.758434321s

• [SLOW TEST:11.858 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:37:38.973: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-5zl2z
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Feb 20 19:37:40.666: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb 20 19:37:40.666: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-5zl2z'
Feb 20 19:37:41.556: INFO: stderr: ""
Feb 20 19:37:41.556: INFO: stdout: "service/redis-slave created\n"
Feb 20 19:37:41.556: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb 20 19:37:41.556: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-5zl2z'
Feb 20 19:37:42.159: INFO: stderr: ""
Feb 20 19:37:42.159: INFO: stdout: "service/redis-master created\n"
Feb 20 19:37:42.159: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb 20 19:37:42.159: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-5zl2z'
Feb 20 19:37:42.733: INFO: stderr: ""
Feb 20 19:37:42.733: INFO: stdout: "service/frontend created\n"
Feb 20 19:37:42.733: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb 20 19:37:42.733: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-5zl2z'
Feb 20 19:37:43.385: INFO: stderr: ""
Feb 20 19:37:43.385: INFO: stdout: "deployment.extensions/frontend created\n"
Feb 20 19:37:43.386: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 20 19:37:43.386: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-5zl2z'
Feb 20 19:37:44.010: INFO: stderr: ""
Feb 20 19:37:44.010: INFO: stdout: "deployment.extensions/redis-master created\n"
Feb 20 19:37:44.010: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb 20 19:37:44.010: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-5zl2z'
Feb 20 19:37:44.627: INFO: stderr: ""
Feb 20 19:37:44.627: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Feb 20 19:37:44.627: INFO: Waiting for all frontend pods to be Running.
Feb 20 19:38:09.681: INFO: Waiting for frontend to serve content.
Feb 20 19:38:09.811: INFO: Trying to add a new entry to the guestbook.
Feb 20 19:38:09.943: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Feb 20 19:38:10.075: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5zl2z'
Feb 20 19:38:10.383: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 19:38:10.384: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb 20 19:38:10.384: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5zl2z'
Feb 20 19:38:10.668: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 19:38:10.668: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 20 19:38:10.668: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5zl2z'
Feb 20 19:38:10.970: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 19:38:10.970: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 20 19:38:10.970: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5zl2z'
Feb 20 19:38:11.279: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 19:38:11.279: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 20 19:38:11.280: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5zl2z'
Feb 20 19:38:11.598: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 19:38:11.598: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 20 19:38:11.599: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5zl2z'
Feb 20 19:38:11.986: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 19:38:11.986: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:38:11.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5zl2z" for this suite.
Feb 20 19:38:58.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:38:58.829: INFO: namespace: e2e-tests-kubectl-5zl2z, resource: bindings, ignored listing per whitelist
Feb 20 19:38:59.795: INFO: namespace e2e-tests-kubectl-5zl2z deletion completed in 47.766738081s

• [SLOW TEST:80.822 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:38:59.795: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-6h6px
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 20 19:39:01.501: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-6h6px'
Feb 20 19:39:01.936: INFO: stderr: ""
Feb 20 19:39:01.936: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 20 19:39:02.978: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 19:39:02.978: INFO: Found 0 / 1
Feb 20 19:39:03.979: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 19:39:03.979: INFO: Found 1 / 1
Feb 20 19:39:03.979: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb 20 19:39:04.021: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 19:39:04.021: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 20 19:39:04.021: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-aws-916gq.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml patch pod redis-master-2jcqk --namespace=e2e-tests-kubectl-6h6px -p {"metadata":{"annotations":{"x":"y"}}}'
Feb 20 19:39:04.358: INFO: stderr: ""
Feb 20 19:39:04.358: INFO: stdout: "pod/redis-master-2jcqk patched\n"
STEP: checking annotations
Feb 20 19:39:04.401: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 19:39:04.401: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:39:04.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6h6px" for this suite.
Feb 20 19:39:26.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:39:28.069: INFO: namespace: e2e-tests-kubectl-6h6px, resource: bindings, ignored listing per whitelist
Feb 20 19:39:28.250: INFO: namespace e2e-tests-kubectl-6h6px deletion completed in 23.806188549s

• [SLOW TEST:28.455 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:39:28.250: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-x5hdl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 20 19:39:32.825: INFO: Successfully updated pod "annotationupdate3d586ff0-3547-11e9-997a-8a6f774fb32b"
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:39:34.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x5hdl" for this suite.
Feb 20 19:39:57.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:39:57.224: INFO: namespace: e2e-tests-projected-x5hdl, resource: bindings, ignored listing per whitelist
Feb 20 19:39:58.954: INFO: namespace e2e-tests-projected-x5hdl deletion completed in 23.989495634s

• [SLOW TEST:30.704 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 20 19:39:58.954: INFO: >>> kubeConfig: /tmp/build/418d26f1/git-kubernetes_publish_conf_test_results-master_master/scripts/aws_kubeconfig.yaml
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-c86r2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb 20 19:40:02.987: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-4fb52fe8-3547-11e9-997a-8a6f774fb32b,GenerateName:,Namespace:e2e-tests-events-c86r2,SelfLink:/api/v1/namespaces/e2e-tests-events-c86r2/pods/send-events-4fb52fe8-3547-11e9-997a-8a6f774fb32b,UID:4fb815ca-3547-11e9-936d-1e925ead141b,ResourceVersion:19624,Generation:0,CreationTimestamp:2019-02-20 19:40:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 773534100,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.249/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wdzmh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wdzmh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-wdzmh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-250-8-15.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010dcc00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010dcc20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:40:00 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:40:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:40:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-20 19:40:00 +0000 UTC  }],Message:,Reason:,HostIP:10.250.8.15,PodIP:100.96.1.249,StartTime:2019-02-20 19:40:00 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-02-20 19:40:01 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://fa4cdef8bcec6fde214c3c6746f909e61e880496cdb58e7b0a3837b733450574}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Feb 20 19:40:05.030: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb 20 19:40:07.072: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 20 19:40:07.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-c86r2" for this suite.
Feb 20 19:40:45.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 19:40:45.834: INFO: namespace: e2e-tests-events-c86r2, resource: bindings, ignored listing per whitelist
Feb 20 19:40:46.927: INFO: namespace e2e-tests-events-c86r2 deletion completed in 39.76854625s

• [SLOW TEST:47.973 seconds]
[k8s.io] [sig-node] Events
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSFeb 20 19:40:46.927: INFO: Running AfterSuite actions on all node
Feb 20 19:40:46.927: INFO: Running AfterSuite actions on node 1
Feb 20 19:40:46.927: INFO: Skipping dumping logs from cluster

Ran 187 of 2011 Specs in 5585.453 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Flaked | 0 Pending | 1824 Skipped PASS

Ginkgo ran 1 suite in 1h33m6.665370137s
Test Suite Passed

I0112 04:12:12.797145      18 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-921671513
I0112 04:12:12.798035      18 e2e.go:224] Starting e2e run "3c5d0511-1620-11e9-8fb7-aa4233c46d55" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1547266331 - Will randomize all specs
Will run 201 of 1946 specs

Jan 12 04:12:12.981: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
Jan 12 04:12:12.984: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jan 12 04:12:13.001: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jan 12 04:12:13.029: INFO: The status of Pod configure-calico-tsst7 is Succeeded, skipping waiting
Jan 12 04:12:13.029: INFO: 15 / 16 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jan 12 04:12:13.029: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Jan 12 04:12:13.029: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jan 12 04:12:13.035: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Jan 12 04:12:13.035: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'kube-discovery' (0 seconds elapsed)
Jan 12 04:12:13.035: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Jan 12 04:12:13.035: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kubectl' (0 seconds elapsed)
Jan 12 04:12:13.035: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'service-proxy' (0 seconds elapsed)
Jan 12 04:12:13.035: INFO: e2e test version: v1.13.0
Jan 12 04:12:13.037: INFO: kube-apiserver version: v1.12.3
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:12:13.037: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename svcaccounts
Jan 12 04:12:13.091: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Jan 12 04:12:13.097: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-hrpnw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Jan 12 04:12:13.750: INFO: created pod pod-service-account-defaultsa
Jan 12 04:12:13.750: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jan 12 04:12:13.755: INFO: created pod pod-service-account-mountsa
Jan 12 04:12:13.755: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jan 12 04:12:13.778: INFO: created pod pod-service-account-nomountsa
Jan 12 04:12:13.778: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jan 12 04:12:13.790: INFO: created pod pod-service-account-defaultsa-mountspec
Jan 12 04:12:13.790: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jan 12 04:12:13.797: INFO: created pod pod-service-account-mountsa-mountspec
Jan 12 04:12:13.797: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jan 12 04:12:13.809: INFO: created pod pod-service-account-nomountsa-mountspec
Jan 12 04:12:13.809: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jan 12 04:12:13.822: INFO: created pod pod-service-account-defaultsa-nomountspec
Jan 12 04:12:13.822: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jan 12 04:12:13.852: INFO: created pod pod-service-account-mountsa-nomountspec
Jan 12 04:12:13.852: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jan 12 04:12:13.880: INFO: created pod pod-service-account-nomountsa-nomountspec
Jan 12 04:12:13.880: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:12:13.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-hrpnw" for this suite.
Jan 12 04:12:35.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:12:35.964: INFO: namespace: e2e-tests-svcaccounts-hrpnw, resource: bindings, ignored listing per whitelist
Jan 12 04:12:36.034: INFO: namespace e2e-tests-svcaccounts-hrpnw deletion completed in 22.147073194s

• [SLOW TEST:22.997 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:12:36.034: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-wd2sp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 12 04:12:36.279: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4ae2959b-1620-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-downward-api-wd2sp" to be "success or failure"
Jan 12 04:12:36.284: INFO: Pod "downwardapi-volume-4ae2959b-1620-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 5.334897ms
Jan 12 04:12:38.287: INFO: Pod "downwardapi-volume-4ae2959b-1620-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008776319s
STEP: Saw pod success
Jan 12 04:12:38.287: INFO: Pod "downwardapi-volume-4ae2959b-1620-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:12:38.290: INFO: Trying to get logs from node c76-1-41 pod downwardapi-volume-4ae2959b-1620-11e9-8fb7-aa4233c46d55 container client-container: <nil>
STEP: delete the pod
Jan 12 04:12:38.307: INFO: Waiting for pod downwardapi-volume-4ae2959b-1620-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:12:38.333: INFO: Pod downwardapi-volume-4ae2959b-1620-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:12:38.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wd2sp" for this suite.
Jan 12 04:12:44.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:12:44.465: INFO: namespace: e2e-tests-downward-api-wd2sp, resource: bindings, ignored listing per whitelist
Jan 12 04:12:44.496: INFO: namespace e2e-tests-downward-api-wd2sp deletion completed in 6.157867739s

• [SLOW TEST:8.462 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:12:44.496: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-kfx2b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-kfx2b
Jan 12 04:12:46.670: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-kfx2b
STEP: checking the pod's current state and verifying that restartCount is present
Jan 12 04:12:46.673: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:16:47.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-kfx2b" for this suite.
Jan 12 04:16:53.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:16:53.605: INFO: namespace: e2e-tests-container-probe-kfx2b, resource: bindings, ignored listing per whitelist
Jan 12 04:16:53.657: INFO: namespace e2e-tests-container-probe-kfx2b deletion completed in 6.093243012s

• [SLOW TEST:249.160 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:16:53.657: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-lf9qq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 12 04:16:53.842: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jan 12 04:16:53.849: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:16:53.852: INFO: Number of nodes with available pods: 0
Jan 12 04:16:53.852: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:16:54.855: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:16:54.878: INFO: Number of nodes with available pods: 0
Jan 12 04:16:54.878: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:16:55.862: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:16:55.870: INFO: Number of nodes with available pods: 0
Jan 12 04:16:55.870: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:16:56.863: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:16:56.872: INFO: Number of nodes with available pods: 1
Jan 12 04:16:56.872: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jan 12 04:16:56.912: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:16:56.916: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:16:57.925: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:16:57.940: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:16:58.924: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:16:58.933: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:16:59.924: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:16:59.938: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:00.924: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:00.933: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:01.924: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:01.935: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:02.924: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:02.933: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:03.920: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:03.924: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:04.924: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:04.935: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:05.921: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:05.925: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:06.924: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:06.934: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:07.920: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:07.924: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:08.922: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:08.929: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:09.926: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:09.934: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:10.922: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:10.927: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:11.919: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:11.922: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:12.924: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:12.932: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:13.924: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:13.932: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:14.924: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:14.932: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:15.924: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:15.941: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:16.923: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:16.932: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:17.924: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:17.933: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:18.923: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:18.932: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:19.925: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:19.932: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:20.924: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:20.931: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:21.921: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:21.924: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:22.924: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:22.931: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:23.925: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:23.934: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:24.924: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:24.933: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:25.925: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:25.933: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:26.924: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:26.931: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:27.921: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:27.927: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:28.920: INFO: Wrong image for pod: daemon-set-phzbx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 12 04:17:28.920: INFO: Pod daemon-set-phzbx is not available
Jan 12 04:17:28.923: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:29.919: INFO: Pod daemon-set-rcfgd is not available
Jan 12 04:17:29.922: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Jan 12 04:17:29.924: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:29.926: INFO: Number of nodes with available pods: 0
Jan 12 04:17:29.926: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:17:30.929: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:30.932: INFO: Number of nodes with available pods: 0
Jan 12 04:17:30.932: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:17:31.931: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 04:17:31.934: INFO: Number of nodes with available pods: 1
Jan 12 04:17:31.934: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-lf9qq, will wait for the garbage collector to delete the pods
Jan 12 04:17:32.033: INFO: Deleting DaemonSet.extensions daemon-set took: 16.900338ms
Jan 12 04:17:32.133: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.500578ms
Jan 12 04:17:36.038: INFO: Number of nodes with available pods: 0
Jan 12 04:17:36.038: INFO: Number of running nodes: 0, number of available pods: 0
Jan 12 04:17:36.041: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-lf9qq/daemonsets","resourceVersion":"131541"},"items":null}

Jan 12 04:17:36.044: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-lf9qq/pods","resourceVersion":"131541"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:17:36.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-lf9qq" for this suite.
Jan 12 04:17:42.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:17:42.106: INFO: namespace: e2e-tests-daemonsets-lf9qq, resource: bindings, ignored listing per whitelist
Jan 12 04:17:42.141: INFO: namespace e2e-tests-daemonsets-lf9qq deletion completed in 6.084847901s

• [SLOW TEST:48.484 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:17:42.141: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-2xdk7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0112 04:17:43.365174      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 12 04:17:43.365: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:17:43.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-2xdk7" for this suite.
Jan 12 04:17:49.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:17:49.475: INFO: namespace: e2e-tests-gc-2xdk7, resource: bindings, ignored listing per whitelist
Jan 12 04:17:49.535: INFO: namespace e2e-tests-gc-2xdk7 deletion completed in 6.165913839s

• [SLOW TEST:7.395 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:17:49.535: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-dvzqz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Jan 12 04:17:49.715: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Jan 12 04:17:49.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 create -f - --namespace=e2e-tests-kubectl-dvzqz'
Jan 12 04:17:50.403: INFO: stderr: ""
Jan 12 04:17:50.403: INFO: stdout: "service/redis-slave created\n"
Jan 12 04:17:50.403: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Jan 12 04:17:50.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 create -f - --namespace=e2e-tests-kubectl-dvzqz'
Jan 12 04:17:50.770: INFO: stderr: ""
Jan 12 04:17:50.770: INFO: stdout: "service/redis-master created\n"
Jan 12 04:17:50.770: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jan 12 04:17:50.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 create -f - --namespace=e2e-tests-kubectl-dvzqz'
Jan 12 04:17:51.079: INFO: stderr: ""
Jan 12 04:17:51.079: INFO: stdout: "service/frontend created\n"
Jan 12 04:17:51.080: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Jan 12 04:17:51.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 create -f - --namespace=e2e-tests-kubectl-dvzqz'
Jan 12 04:17:51.400: INFO: stderr: ""
Jan 12 04:17:51.400: INFO: stdout: "deployment.extensions/frontend created\n"
Jan 12 04:17:51.400: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jan 12 04:17:51.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 create -f - --namespace=e2e-tests-kubectl-dvzqz'
Jan 12 04:17:51.677: INFO: stderr: ""
Jan 12 04:17:51.677: INFO: stdout: "deployment.extensions/redis-master created\n"
Jan 12 04:17:51.677: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Jan 12 04:17:51.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 create -f - --namespace=e2e-tests-kubectl-dvzqz'
Jan 12 04:17:51.910: INFO: stderr: ""
Jan 12 04:17:51.910: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Jan 12 04:17:51.910: INFO: Waiting for all frontend pods to be Running.
Jan 12 04:17:56.989: INFO: Waiting for frontend to serve content.
Jan 12 04:17:57.033: INFO: Trying to add a new entry to the guestbook.
Jan 12 04:17:57.053: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Jan 12 04:17:57.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dvzqz'
Jan 12 04:17:57.167: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 12 04:17:57.167: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Jan 12 04:17:57.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dvzqz'
Jan 12 04:17:57.365: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 12 04:17:57.365: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan 12 04:17:57.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dvzqz'
Jan 12 04:17:57.600: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 12 04:17:57.600: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan 12 04:17:57.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dvzqz'
Jan 12 04:17:57.719: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 12 04:17:57.719: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan 12 04:17:57.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dvzqz'
Jan 12 04:17:57.945: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 12 04:17:57.945: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan 12 04:17:57.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dvzqz'
Jan 12 04:17:58.015: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 12 04:17:58.015: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:17:58.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dvzqz" for this suite.
Jan 12 04:18:36.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:18:36.072: INFO: namespace: e2e-tests-kubectl-dvzqz, resource: bindings, ignored listing per whitelist
Jan 12 04:18:36.177: INFO: namespace e2e-tests-kubectl-dvzqz deletion completed in 38.157517953s

• [SLOW TEST:46.641 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:18:36.177: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5n7hn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-2180f5e3-1621-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume secrets
Jan 12 04:18:36.346: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-218174c2-1621-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-projected-5n7hn" to be "success or failure"
Jan 12 04:18:36.349: INFO: Pod "pod-projected-secrets-218174c2-1621-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.800905ms
Jan 12 04:18:38.356: INFO: Pod "pod-projected-secrets-218174c2-1621-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009867001s
STEP: Saw pod success
Jan 12 04:18:38.356: INFO: Pod "pod-projected-secrets-218174c2-1621-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:18:38.363: INFO: Trying to get logs from node c76-1-41 pod pod-projected-secrets-218174c2-1621-11e9-8fb7-aa4233c46d55 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 12 04:18:38.409: INFO: Waiting for pod pod-projected-secrets-218174c2-1621-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:18:38.429: INFO: Pod pod-projected-secrets-218174c2-1621-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:18:38.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5n7hn" for this suite.
Jan 12 04:18:44.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:18:44.490: INFO: namespace: e2e-tests-projected-5n7hn, resource: bindings, ignored listing per whitelist
Jan 12 04:18:44.549: INFO: namespace e2e-tests-projected-5n7hn deletion completed in 6.116295182s

• [SLOW TEST:8.372 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:18:44.549: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-m6z4d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 12 04:18:49.259: INFO: Successfully updated pod "annotationupdate267dad1f-1621-11e9-8fb7-aa4233c46d55"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:18:51.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-m6z4d" for this suite.
Jan 12 04:19:13.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:19:13.346: INFO: namespace: e2e-tests-projected-m6z4d, resource: bindings, ignored listing per whitelist
Jan 12 04:19:13.408: INFO: namespace e2e-tests-projected-m6z4d deletion completed in 22.091139044s

• [SLOW TEST:28.859 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:19:13.408: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-lvn5k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 12 04:19:13.591: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Jan 12 04:19:13.597: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-lvn5k/daemonsets","resourceVersion":"132089"},"items":null}

Jan 12 04:19:13.599: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-lvn5k/pods","resourceVersion":"132089"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:19:13.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-lvn5k" for this suite.
Jan 12 04:19:19.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:19:19.670: INFO: namespace: e2e-tests-daemonsets-lvn5k, resource: bindings, ignored listing per whitelist
Jan 12 04:19:19.702: INFO: namespace e2e-tests-daemonsets-lvn5k deletion completed in 6.094538382s

S [SKIPPING] [6.294 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Jan 12 04:19:13.591: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:19:19.702: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-skpdc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-3b794e7d-1621-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume configMaps
Jan 12 04:19:19.953: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3b7a0602-1621-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-projected-skpdc" to be "success or failure"
Jan 12 04:19:19.956: INFO: Pod "pod-projected-configmaps-3b7a0602-1621-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.906616ms
Jan 12 04:19:21.959: INFO: Pod "pod-projected-configmaps-3b7a0602-1621-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00566132s
STEP: Saw pod success
Jan 12 04:19:21.959: INFO: Pod "pod-projected-configmaps-3b7a0602-1621-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:19:21.961: INFO: Trying to get logs from node c76-1-41 pod pod-projected-configmaps-3b7a0602-1621-11e9-8fb7-aa4233c46d55 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 12 04:19:21.976: INFO: Waiting for pod pod-projected-configmaps-3b7a0602-1621-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:19:21.979: INFO: Pod pod-projected-configmaps-3b7a0602-1621-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:19:21.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-skpdc" for this suite.
Jan 12 04:19:27.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:19:28.060: INFO: namespace: e2e-tests-projected-skpdc, resource: bindings, ignored listing per whitelist
Jan 12 04:19:28.067: INFO: namespace e2e-tests-projected-skpdc deletion completed in 6.085140601s

• [SLOW TEST:8.365 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:19:28.067: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-sdflq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 12 04:19:28.272: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"407132fc-1621-11e9-b7e1-000c294e6ffe", Controller:(*bool)(0xc00118454a), BlockOwnerDeletion:(*bool)(0xc00118454b)}}
Jan 12 04:19:28.278: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"406ee9c1-1621-11e9-b7e1-000c294e6ffe", Controller:(*bool)(0xc001184726), BlockOwnerDeletion:(*bool)(0xc001184727)}}
Jan 12 04:19:28.283: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"406ff37d-1621-11e9-b7e1-000c294e6ffe", Controller:(*bool)(0xc0010a3de2), BlockOwnerDeletion:(*bool)(0xc0010a3de3)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:19:33.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-sdflq" for this suite.
Jan 12 04:19:39.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:19:39.401: INFO: namespace: e2e-tests-gc-sdflq, resource: bindings, ignored listing per whitelist
Jan 12 04:19:39.430: INFO: namespace e2e-tests-gc-sdflq deletion completed in 6.125491491s

• [SLOW TEST:11.363 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:19:39.430: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-x92s9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-686sg in namespace e2e-tests-proxy-x92s9
I0112 04:19:39.612243      18 runners.go:184] Created replication controller with name: proxy-service-686sg, namespace: e2e-tests-proxy-x92s9, replica count: 1
I0112 04:19:40.664105      18 runners.go:184] proxy-service-686sg Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0112 04:19:41.664659      18 runners.go:184] proxy-service-686sg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0112 04:19:42.665284      18 runners.go:184] proxy-service-686sg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0112 04:19:43.666143      18 runners.go:184] proxy-service-686sg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0112 04:19:44.666632      18 runners.go:184] proxy-service-686sg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0112 04:19:45.667059      18 runners.go:184] proxy-service-686sg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0112 04:19:46.667629      18 runners.go:184] proxy-service-686sg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0112 04:19:47.668337      18 runners.go:184] proxy-service-686sg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0112 04:19:48.670003      18 runners.go:184] proxy-service-686sg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0112 04:19:49.670758      18 runners.go:184] proxy-service-686sg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0112 04:19:50.673721      18 runners.go:184] proxy-service-686sg Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 12 04:19:50.680: INFO: setup took 11.085064083s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jan 12 04:19:50.709: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:162/proxy/: bar (200; 27.659245ms)
Jan 12 04:19:50.712: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/rewri... (200; 31.927519ms)
Jan 12 04:19:50.715: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname2/proxy/: bar (200; 34.30792ms)
Jan 12 04:19:50.716: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:160/proxy/: foo (200; 33.97039ms)
Jan 12 04:19:50.716: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:160/proxy/: foo (200; 35.562298ms)
Jan 12 04:19:50.716: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname1/proxy/: foo (200; 34.670086ms)
Jan 12 04:19:50.719: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:162/proxy/: bar (200; 37.207233ms)
Jan 12 04:19:50.721: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/... (200; 39.885336ms)
Jan 12 04:19:50.722: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/rewriteme"... (200; 42.085096ms)
Jan 12 04:19:50.754: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname1/proxy/: foo (200; 72.790936ms)
Jan 12 04:19:50.758: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:460/proxy/: tls baz (200; 77.70475ms)
Jan 12 04:19:50.758: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname2/proxy/: bar (200; 76.406772ms)
Jan 12 04:19:50.758: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname1/proxy/: tls baz (200; 76.258544ms)
Jan 12 04:19:50.760: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/... (200; 78.456962ms)
Jan 12 04:19:50.760: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname2/proxy/: tls qux (200; 78.301136ms)
Jan 12 04:19:50.760: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:462/proxy/: tls qux (200; 79.095104ms)
Jan 12 04:19:50.766: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:162/proxy/: bar (200; 4.995333ms)
Jan 12 04:19:50.767: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:462/proxy/: tls qux (200; 6.441138ms)
Jan 12 04:19:50.767: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:460/proxy/: tls baz (200; 6.455473ms)
Jan 12 04:19:50.768: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:160/proxy/: foo (200; 6.677476ms)
Jan 12 04:19:50.770: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/rewriteme"... (200; 9.517083ms)
Jan 12 04:19:50.771: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname2/proxy/: bar (200; 10.193865ms)
Jan 12 04:19:50.771: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname1/proxy/: foo (200; 9.870751ms)
Jan 12 04:19:50.771: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/rewri... (200; 10.287997ms)
Jan 12 04:19:50.771: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:162/proxy/: bar (200; 10.29903ms)
Jan 12 04:19:50.771: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname1/proxy/: tls baz (200; 10.529358ms)
Jan 12 04:19:50.772: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname2/proxy/: bar (200; 11.626907ms)
Jan 12 04:19:50.794: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/... (200; 32.803826ms)
Jan 12 04:19:50.794: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname1/proxy/: foo (200; 33.061117ms)
Jan 12 04:19:50.795: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:160/proxy/: foo (200; 34.347879ms)
Jan 12 04:19:50.795: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/... (200; 34.462763ms)
Jan 12 04:19:50.796: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname2/proxy/: tls qux (200; 35.092985ms)
Jan 12 04:19:50.804: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/... (200; 7.904897ms)
Jan 12 04:19:50.804: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:162/proxy/: bar (200; 8.057622ms)
Jan 12 04:19:50.804: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/rewriteme"... (200; 7.857167ms)
Jan 12 04:19:50.807: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:160/proxy/: foo (200; 10.199582ms)
Jan 12 04:19:50.807: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:462/proxy/: tls qux (200; 10.302523ms)
Jan 12 04:19:50.807: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:460/proxy/: tls baz (200; 10.400509ms)
Jan 12 04:19:50.807: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname2/proxy/: tls qux (200; 10.362835ms)
Jan 12 04:19:50.807: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:160/proxy/: foo (200; 10.25863ms)
Jan 12 04:19:50.807: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/rewri... (200; 10.326101ms)
Jan 12 04:19:50.807: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:162/proxy/: bar (200; 10.328919ms)
Jan 12 04:19:50.807: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/... (200; 10.408696ms)
Jan 12 04:19:50.808: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname1/proxy/: foo (200; 11.965065ms)
Jan 12 04:19:50.808: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname2/proxy/: bar (200; 11.918128ms)
Jan 12 04:19:50.808: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname1/proxy/: tls baz (200; 11.961427ms)
Jan 12 04:19:50.808: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname2/proxy/: bar (200; 12.131171ms)
Jan 12 04:19:50.808: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname1/proxy/: foo (200; 12.289936ms)
Jan 12 04:19:50.818: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:160/proxy/: foo (200; 8.731945ms)
Jan 12 04:19:50.819: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:462/proxy/: tls qux (200; 9.020496ms)
Jan 12 04:19:50.819: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/rewriteme"... (200; 9.96726ms)
Jan 12 04:19:50.819: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname2/proxy/: bar (200; 9.394274ms)
Jan 12 04:19:50.819: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname2/proxy/: bar (200; 9.7417ms)
Jan 12 04:19:50.819: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:162/proxy/: bar (200; 9.186113ms)
Jan 12 04:19:50.819: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname1/proxy/: tls baz (200; 8.411604ms)
Jan 12 04:19:50.819: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/rewri... (200; 9.312159ms)
Jan 12 04:19:50.819: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:160/proxy/: foo (200; 9.713517ms)
Jan 12 04:19:50.819: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/... (200; 8.589178ms)
Jan 12 04:19:50.819: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname2/proxy/: tls qux (200; 8.314289ms)
Jan 12 04:19:50.819: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/... (200; 9.089904ms)
Jan 12 04:19:50.819: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname1/proxy/: foo (200; 8.448835ms)
Jan 12 04:19:50.819: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:460/proxy/: tls baz (200; 8.907845ms)
Jan 12 04:19:50.819: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname1/proxy/: foo (200; 8.818776ms)
Jan 12 04:19:50.821: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:162/proxy/: bar (200; 12.470503ms)
Jan 12 04:19:50.830: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:162/proxy/: bar (200; 7.895791ms)
Jan 12 04:19:50.830: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/rewri... (200; 7.702484ms)
Jan 12 04:19:50.830: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:160/proxy/: foo (200; 7.968377ms)
Jan 12 04:19:50.830: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:160/proxy/: foo (200; 8.00146ms)
Jan 12 04:19:50.830: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:162/proxy/: bar (200; 8.151884ms)
Jan 12 04:19:50.830: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:462/proxy/: tls qux (200; 7.940066ms)
Jan 12 04:19:50.832: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/rewriteme"... (200; 10.385572ms)
Jan 12 04:19:50.832: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/... (200; 10.648083ms)
Jan 12 04:19:50.833: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname2/proxy/: bar (200; 10.25678ms)
Jan 12 04:19:50.833: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname1/proxy/: foo (200; 11.133143ms)
Jan 12 04:19:50.833: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname2/proxy/: tls qux (200; 11.061107ms)
Jan 12 04:19:50.833: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname1/proxy/: foo (200; 11.32237ms)
Jan 12 04:19:50.833: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname2/proxy/: bar (200; 10.537592ms)
Jan 12 04:19:50.834: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:460/proxy/: tls baz (200; 12.197391ms)
Jan 12 04:19:50.834: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname1/proxy/: tls baz (200; 12.426493ms)
Jan 12 04:19:50.835: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/... (200; 13.242421ms)
Jan 12 04:19:50.842: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:162/proxy/: bar (200; 6.600612ms)
Jan 12 04:19:50.843: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/... (200; 7.557978ms)
Jan 12 04:19:50.843: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname2/proxy/: bar (200; 7.742882ms)
Jan 12 04:19:50.843: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/... (200; 8.034988ms)
Jan 12 04:19:50.843: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/rewriteme"... (200; 8.065696ms)
Jan 12 04:19:50.843: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:160/proxy/: foo (200; 8.019363ms)
Jan 12 04:19:50.844: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:460/proxy/: tls baz (200; 8.367365ms)
Jan 12 04:19:50.844: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:160/proxy/: foo (200; 8.330077ms)
Jan 12 04:19:50.844: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/rewri... (200; 8.412769ms)
Jan 12 04:19:50.844: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:462/proxy/: tls qux (200; 8.771187ms)
Jan 12 04:19:50.844: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname2/proxy/: tls qux (200; 8.993123ms)
Jan 12 04:19:50.846: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:162/proxy/: bar (200; 10.921453ms)
Jan 12 04:19:50.847: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname1/proxy/: foo (200; 11.538546ms)
Jan 12 04:19:50.847: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname2/proxy/: bar (200; 11.976088ms)
Jan 12 04:19:50.847: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname1/proxy/: foo (200; 12.025973ms)
Jan 12 04:19:50.847: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname1/proxy/: tls baz (200; 12.072726ms)
Jan 12 04:19:50.855: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/rewriteme"... (200; 7.466589ms)
Jan 12 04:19:50.855: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:460/proxy/: tls baz (200; 7.557324ms)
Jan 12 04:19:50.855: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/... (200; 7.614912ms)
Jan 12 04:19:50.855: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:162/proxy/: bar (200; 7.553073ms)
Jan 12 04:19:50.855: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:462/proxy/: tls qux (200; 8.022959ms)
Jan 12 04:19:50.856: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/rewri... (200; 8.490153ms)
Jan 12 04:19:50.856: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:160/proxy/: foo (200; 8.412433ms)
Jan 12 04:19:50.856: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:160/proxy/: foo (200; 8.769891ms)
Jan 12 04:19:50.856: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/... (200; 8.83901ms)
Jan 12 04:19:50.856: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname2/proxy/: bar (200; 8.815362ms)
Jan 12 04:19:50.857: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname2/proxy/: tls qux (200; 9.320893ms)
Jan 12 04:19:50.857: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname1/proxy/: tls baz (200; 9.360665ms)
Jan 12 04:19:50.858: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:162/proxy/: bar (200; 10.645414ms)
Jan 12 04:19:50.858: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname1/proxy/: foo (200; 10.639357ms)
Jan 12 04:19:50.858: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname1/proxy/: foo (200; 11.285834ms)
Jan 12 04:19:50.858: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname2/proxy/: bar (200; 11.187428ms)
Jan 12 04:19:50.866: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname1/proxy/: foo (200; 7.449407ms)
Jan 12 04:19:50.866: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname1/proxy/: tls baz (200; 7.408086ms)
Jan 12 04:19:50.866: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:160/proxy/: foo (200; 7.409358ms)
Jan 12 04:19:50.866: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/... (200; 7.43452ms)
Jan 12 04:19:50.866: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname2/proxy/: tls qux (200; 7.419689ms)
Jan 12 04:19:50.866: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:162/proxy/: bar (200; 7.481999ms)
Jan 12 04:19:50.866: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:162/proxy/: bar (200; 7.45136ms)
Jan 12 04:19:50.866: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/rewriteme"... (200; 7.422994ms)
Jan 12 04:19:50.866: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname2/proxy/: bar (200; 7.813275ms)
Jan 12 04:19:50.867: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname1/proxy/: foo (200; 7.916057ms)
Jan 12 04:19:50.867: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:462/proxy/: tls qux (200; 7.87798ms)
Jan 12 04:19:50.867: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname2/proxy/: bar (200; 8.197319ms)
Jan 12 04:19:50.867: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:160/proxy/: foo (200; 8.420064ms)
Jan 12 04:19:50.867: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/rewri... (200; 8.439005ms)
Jan 12 04:19:50.867: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/... (200; 8.507835ms)
Jan 12 04:19:50.868: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:460/proxy/: tls baz (200; 9.685822ms)
Jan 12 04:19:50.875: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:160/proxy/: foo (200; 6.82688ms)
Jan 12 04:19:50.875: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:160/proxy/: foo (200; 7.00942ms)
Jan 12 04:19:50.878: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname2/proxy/: bar (200; 9.519345ms)
Jan 12 04:19:50.878: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname1/proxy/: foo (200; 10.071462ms)
Jan 12 04:19:50.878: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname2/proxy/: tls qux (200; 10.000906ms)
Jan 12 04:19:50.878: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname2/proxy/: bar (200; 10.078048ms)
Jan 12 04:19:50.878: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname1/proxy/: tls baz (200; 10.043031ms)
Jan 12 04:19:50.879: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/... (200; 10.390569ms)
Jan 12 04:19:50.880: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:462/proxy/: tls qux (200; 11.094611ms)
Jan 12 04:19:50.880: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:162/proxy/: bar (200; 11.233686ms)
Jan 12 04:19:50.880: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/rewri... (200; 11.294602ms)
Jan 12 04:19:50.880: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:162/proxy/: bar (200; 11.340262ms)
Jan 12 04:19:50.880: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:460/proxy/: tls baz (200; 11.480568ms)
Jan 12 04:19:50.880: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/... (200; 11.477191ms)
Jan 12 04:19:50.880: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/rewriteme"... (200; 11.644766ms)
Jan 12 04:19:50.880: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname1/proxy/: foo (200; 11.520025ms)
Jan 12 04:19:50.887: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:162/proxy/: bar (200; 6.234865ms)
Jan 12 04:19:50.887: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/... (200; 6.472176ms)
Jan 12 04:19:50.887: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:460/proxy/: tls baz (200; 6.498992ms)
Jan 12 04:19:50.887: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:160/proxy/: foo (200; 6.926959ms)
Jan 12 04:19:50.887: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/... (200; 6.62942ms)
Jan 12 04:19:50.889: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:462/proxy/: tls qux (200; 9.1336ms)
Jan 12 04:19:50.889: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/rewriteme"... (200; 8.161843ms)
Jan 12 04:19:50.889: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:160/proxy/: foo (200; 8.909466ms)
Jan 12 04:19:50.890: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname2/proxy/: bar (200; 8.863422ms)
Jan 12 04:19:50.890: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname2/proxy/: tls qux (200; 9.180661ms)
Jan 12 04:19:50.891: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname1/proxy/: foo (200; 9.973517ms)
Jan 12 04:19:50.891: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/rewri... (200; 9.476686ms)
Jan 12 04:19:50.891: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname1/proxy/: tls baz (200; 9.892264ms)
Jan 12 04:19:50.891: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname2/proxy/: bar (200; 9.698188ms)
Jan 12 04:19:50.891: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:162/proxy/: bar (200; 10.034877ms)
Jan 12 04:19:50.893: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname1/proxy/: foo (200; 12.048506ms)
Jan 12 04:19:50.898: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:162/proxy/: bar (200; 5.608697ms)
Jan 12 04:19:50.898: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:160/proxy/: foo (200; 5.688629ms)
Jan 12 04:19:50.899: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:162/proxy/: bar (200; 6.023264ms)
Jan 12 04:19:50.899: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:460/proxy/: tls baz (200; 6.146765ms)
Jan 12 04:19:50.899: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:462/proxy/: tls qux (200; 6.102837ms)
Jan 12 04:19:50.899: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/... (200; 6.129265ms)
Jan 12 04:19:50.899: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/... (200; 6.17039ms)
Jan 12 04:19:50.899: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:160/proxy/: foo (200; 6.12205ms)
Jan 12 04:19:50.899: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/rewri... (200; 6.182848ms)
Jan 12 04:19:50.899: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/rewriteme"... (200; 6.550046ms)
Jan 12 04:19:50.902: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname2/proxy/: bar (200; 9.07484ms)
Jan 12 04:19:50.902: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname1/proxy/: tls baz (200; 9.194407ms)
Jan 12 04:19:50.902: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname1/proxy/: foo (200; 9.140349ms)
Jan 12 04:19:50.902: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname1/proxy/: foo (200; 9.087373ms)
Jan 12 04:19:50.902: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname2/proxy/: bar (200; 9.119724ms)
Jan 12 04:19:50.902: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname2/proxy/: tls qux (200; 9.543794ms)
Jan 12 04:19:50.909: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/rewriteme"... (200; 6.889428ms)
Jan 12 04:19:50.909: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/... (200; 6.939918ms)
Jan 12 04:19:50.909: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:162/proxy/: bar (200; 6.83076ms)
Jan 12 04:19:50.909: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:160/proxy/: foo (200; 6.8973ms)
Jan 12 04:19:50.909: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:460/proxy/: tls baz (200; 6.823547ms)
Jan 12 04:19:50.909: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/rewri... (200; 6.900177ms)
Jan 12 04:19:50.909: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:162/proxy/: bar (200; 6.882911ms)
Jan 12 04:19:50.909: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:462/proxy/: tls qux (200; 6.904209ms)
Jan 12 04:19:50.909: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/... (200; 6.863024ms)
Jan 12 04:19:50.910: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname1/proxy/: foo (200; 7.286327ms)
Jan 12 04:19:50.910: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname2/proxy/: tls qux (200; 7.392806ms)
Jan 12 04:19:50.910: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:160/proxy/: foo (200; 7.349707ms)
Jan 12 04:19:50.910: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname1/proxy/: foo (200; 7.444413ms)
Jan 12 04:19:50.910: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname1/proxy/: tls baz (200; 7.545597ms)
Jan 12 04:19:50.910: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname2/proxy/: bar (200; 7.458509ms)
Jan 12 04:19:50.911: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname2/proxy/: bar (200; 8.180606ms)
Jan 12 04:19:50.916: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:162/proxy/: bar (200; 5.385857ms)
Jan 12 04:19:50.916: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:160/proxy/: foo (200; 5.619729ms)
Jan 12 04:19:50.918: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:160/proxy/: foo (200; 6.768806ms)
Jan 12 04:19:50.918: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/rewriteme"... (200; 7.563914ms)
Jan 12 04:19:50.918: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname1/proxy/: foo (200; 7.337616ms)
Jan 12 04:19:50.918: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/... (200; 7.421851ms)
Jan 12 04:19:50.919: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:162/proxy/: bar (200; 8.313884ms)
Jan 12 04:19:50.919: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname2/proxy/: tls qux (200; 8.14458ms)
Jan 12 04:19:50.919: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/... (200; 8.210941ms)
Jan 12 04:19:50.919: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:462/proxy/: tls qux (200; 8.373102ms)
Jan 12 04:19:50.919: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/rewri... (200; 8.419774ms)
Jan 12 04:19:50.919: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname1/proxy/: foo (200; 8.317019ms)
Jan 12 04:19:50.919: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:460/proxy/: tls baz (200; 8.25968ms)
Jan 12 04:19:50.919: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname2/proxy/: bar (200; 8.536414ms)
Jan 12 04:19:50.919: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname1/proxy/: tls baz (200; 8.321184ms)
Jan 12 04:19:50.919: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname2/proxy/: bar (200; 8.584466ms)
Jan 12 04:19:50.924: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/rewriteme"... (200; 5.098501ms)
Jan 12 04:19:50.926: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:162/proxy/: bar (200; 6.124438ms)
Jan 12 04:19:50.926: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/... (200; 6.392817ms)
Jan 12 04:19:50.926: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/... (200; 6.483859ms)
Jan 12 04:19:50.927: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:162/proxy/: bar (200; 6.918872ms)
Jan 12 04:19:50.927: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/rewri... (200; 7.034918ms)
Jan 12 04:19:50.927: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:460/proxy/: tls baz (200; 6.812663ms)
Jan 12 04:19:50.927: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:160/proxy/: foo (200; 6.805515ms)
Jan 12 04:19:50.927: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:160/proxy/: foo (200; 6.813548ms)
Jan 12 04:19:50.927: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:462/proxy/: tls qux (200; 6.864159ms)
Jan 12 04:19:50.928: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname2/proxy/: bar (200; 8.504049ms)
Jan 12 04:19:50.928: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname1/proxy/: tls baz (200; 8.21612ms)
Jan 12 04:19:50.928: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname2/proxy/: bar (200; 8.691318ms)
Jan 12 04:19:50.928: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname1/proxy/: foo (200; 8.344917ms)
Jan 12 04:19:50.928: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname1/proxy/: foo (200; 8.333332ms)
Jan 12 04:19:50.928: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname2/proxy/: tls qux (200; 8.251462ms)
Jan 12 04:19:50.936: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname2/proxy/: tls qux (200; 6.824285ms)
Jan 12 04:19:50.936: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/... (200; 6.470391ms)
Jan 12 04:19:50.936: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/... (200; 7.407946ms)
Jan 12 04:19:50.936: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:162/proxy/: bar (200; 7.64904ms)
Jan 12 04:19:50.936: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:462/proxy/: tls qux (200; 6.561675ms)
Jan 12 04:19:50.936: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:460/proxy/: tls baz (200; 7.378896ms)
Jan 12 04:19:50.936: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:162/proxy/: bar (200; 6.591584ms)
Jan 12 04:19:50.936: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname1/proxy/: foo (200; 7.444382ms)
Jan 12 04:19:50.936: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/rewriteme"... (200; 6.986094ms)
Jan 12 04:19:50.936: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/rewri... (200; 6.666504ms)
Jan 12 04:19:50.936: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname1/proxy/: tls baz (200; 7.416861ms)
Jan 12 04:19:50.936: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:160/proxy/: foo (200; 6.756207ms)
Jan 12 04:19:50.937: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname2/proxy/: bar (200; 7.527068ms)
Jan 12 04:19:50.937: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname1/proxy/: foo (200; 8.70095ms)
Jan 12 04:19:50.937: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:160/proxy/: foo (200; 7.695173ms)
Jan 12 04:19:50.937: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname2/proxy/: bar (200; 7.818387ms)
Jan 12 04:19:50.949: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/... (200; 11.977507ms)
Jan 12 04:19:50.949: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:160/proxy/: foo (200; 11.842309ms)
Jan 12 04:19:50.949: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/... (200; 11.637222ms)
Jan 12 04:19:50.949: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:160/proxy/: foo (200; 11.980454ms)
Jan 12 04:19:50.949: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:162/proxy/: bar (200; 12.17213ms)
Jan 12 04:19:50.949: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:162/proxy/: bar (200; 11.816208ms)
Jan 12 04:19:50.949: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/rewriteme"... (200; 11.280493ms)
Jan 12 04:19:50.950: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:460/proxy/: tls baz (200; 12.182621ms)
Jan 12 04:19:50.950: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/rewri... (200; 11.677829ms)
Jan 12 04:19:50.950: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:462/proxy/: tls qux (200; 11.927391ms)
Jan 12 04:19:50.950: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname1/proxy/: foo (200; 12.237271ms)
Jan 12 04:19:50.951: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname2/proxy/: bar (200; 12.765679ms)
Jan 12 04:19:50.951: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname2/proxy/: bar (200; 12.865118ms)
Jan 12 04:19:50.951: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname2/proxy/: tls qux (200; 13.124733ms)
Jan 12 04:19:50.951: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname1/proxy/: tls baz (200; 13.534308ms)
Jan 12 04:19:50.951: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname1/proxy/: foo (200; 13.876848ms)
Jan 12 04:19:50.958: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:460/proxy/: tls baz (200; 6.391275ms)
Jan 12 04:19:50.959: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/rewriteme"... (200; 6.764665ms)
Jan 12 04:19:50.959: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:160/proxy/: foo (200; 6.770543ms)
Jan 12 04:19:50.959: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/... (200; 6.650458ms)
Jan 12 04:19:50.960: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname1/proxy/: foo (200; 8.331269ms)
Jan 12 04:19:50.960: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname1/proxy/: tls baz (200; 8.255891ms)
Jan 12 04:19:50.960: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:162/proxy/: bar (200; 7.845069ms)
Jan 12 04:19:50.960: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:162/proxy/: bar (200; 7.455411ms)
Jan 12 04:19:50.960: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:160/proxy/: foo (200; 7.635002ms)
Jan 12 04:19:50.960: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/... (200; 7.713296ms)
Jan 12 04:19:50.960: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/rewri... (200; 7.991675ms)
Jan 12 04:19:50.961: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname2/proxy/: bar (200; 8.845777ms)
Jan 12 04:19:50.961: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname2/proxy/: tls qux (200; 9.048653ms)
Jan 12 04:19:50.961: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:462/proxy/: tls qux (200; 8.526775ms)
Jan 12 04:19:50.961: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname1/proxy/: foo (200; 8.182902ms)
Jan 12 04:19:50.961: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname2/proxy/: bar (200; 8.818116ms)
Jan 12 04:19:50.967: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:162/proxy/: bar (200; 4.596434ms)
Jan 12 04:19:50.967: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/... (200; 6.131699ms)
Jan 12 04:19:50.967: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:160/proxy/: foo (200; 6.088088ms)
Jan 12 04:19:50.967: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:162/proxy/: bar (200; 5.78823ms)
Jan 12 04:19:50.967: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/rewri... (200; 4.776873ms)
Jan 12 04:19:50.967: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:462/proxy/: tls qux (200; 6.303317ms)
Jan 12 04:19:50.967: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/rewriteme"... (200; 5.091781ms)
Jan 12 04:19:50.968: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/... (200; 6.256019ms)
Jan 12 04:19:50.969: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname1/proxy/: foo (200; 7.179583ms)
Jan 12 04:19:50.969: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:460/proxy/: tls baz (200; 7.062404ms)
Jan 12 04:19:50.969: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:160/proxy/: foo (200; 7.892245ms)
Jan 12 04:19:50.970: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname1/proxy/: foo (200; 8.421247ms)
Jan 12 04:19:50.970: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname2/proxy/: bar (200; 7.925533ms)
Jan 12 04:19:50.970: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname1/proxy/: tls baz (200; 8.365199ms)
Jan 12 04:19:50.970: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname2/proxy/: bar (200; 7.854589ms)
Jan 12 04:19:50.970: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname2/proxy/: tls qux (200; 8.167778ms)
Jan 12 04:19:50.975: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/rewriteme"... (200; 4.778335ms)
Jan 12 04:19:50.977: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/... (200; 6.461881ms)
Jan 12 04:19:50.977: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:160/proxy/: foo (200; 6.640693ms)
Jan 12 04:19:50.977: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:162/proxy/: bar (200; 6.630525ms)
Jan 12 04:19:50.977: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/... (200; 6.561895ms)
Jan 12 04:19:50.979: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:160/proxy/: foo (200; 8.247734ms)
Jan 12 04:19:50.979: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/rewri... (200; 8.22552ms)
Jan 12 04:19:50.979: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:462/proxy/: tls qux (200; 8.354175ms)
Jan 12 04:19:50.979: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname2/proxy/: tls qux (200; 8.232717ms)
Jan 12 04:19:50.979: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:162/proxy/: bar (200; 8.427566ms)
Jan 12 04:19:50.980: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname2/proxy/: bar (200; 9.320819ms)
Jan 12 04:19:50.980: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname1/proxy/: foo (200; 9.307699ms)
Jan 12 04:19:50.980: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname1/proxy/: tls baz (200; 9.339883ms)
Jan 12 04:19:50.980: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname2/proxy/: bar (200; 9.375631ms)
Jan 12 04:19:50.980: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:460/proxy/: tls baz (200; 9.45439ms)
Jan 12 04:19:50.980: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname1/proxy/: foo (200; 9.982197ms)
Jan 12 04:19:50.988: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:1080/proxy/rewri... (200; 7.41489ms)
Jan 12 04:19:50.988: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:160/proxy/: foo (200; 7.475661ms)
Jan 12 04:19:50.988: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:160/proxy/: foo (200; 7.438041ms)
Jan 12 04:19:50.988: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:443/proxy/... (200; 7.457952ms)
Jan 12 04:19:50.988: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4/proxy/rewriteme"... (200; 7.668661ms)
Jan 12 04:19:50.989: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname2/proxy/: bar (200; 8.157164ms)
Jan 12 04:19:50.989: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:462/proxy/: tls qux (200; 8.331037ms)
Jan 12 04:19:50.989: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:1080/proxy/... (200; 8.328916ms)
Jan 12 04:19:50.989: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname1/proxy/: tls baz (200; 8.537225ms)
Jan 12 04:19:50.989: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/https:proxy-service-686sg:tlsportname2/proxy/: tls qux (200; 8.537367ms)
Jan 12 04:19:50.989: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/http:proxy-service-686sg-b5sb4:162/proxy/: bar (200; 8.657821ms)
Jan 12 04:19:50.989: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/proxy-service-686sg-b5sb4:162/proxy/: bar (200; 8.398565ms)
Jan 12 04:19:50.989: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-x92s9/pods/https:proxy-service-686sg-b5sb4:460/proxy/: tls baz (200; 8.713484ms)
Jan 12 04:19:50.989: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname1/proxy/: foo (200; 8.428857ms)
Jan 12 04:19:50.991: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/http:proxy-service-686sg:portname1/proxy/: foo (200; 10.20477ms)
Jan 12 04:19:50.991: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-x92s9/services/proxy-service-686sg:portname2/proxy/: bar (200; 10.160416ms)
STEP: deleting ReplicationController proxy-service-686sg in namespace e2e-tests-proxy-x92s9, will wait for the garbage collector to delete the pods
Jan 12 04:19:51.049: INFO: Deleting ReplicationController proxy-service-686sg took: 5.485029ms
Jan 12 04:19:51.150: INFO: Terminating ReplicationController proxy-service-686sg pods took: 100.697865ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:20:03.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-x92s9" for this suite.
Jan 12 04:20:09.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:20:09.602: INFO: namespace: e2e-tests-proxy-x92s9, resource: bindings, ignored listing per whitelist
Jan 12 04:20:09.641: INFO: namespace e2e-tests-proxy-x92s9 deletion completed in 6.08694163s

• [SLOW TEST:30.211 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:20:09.641: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-js5bl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Jan 12 04:20:09.801: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-921671513 proxy --unix-socket=/tmp/kubectl-proxy-unix524852452/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:20:09.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-js5bl" for this suite.
Jan 12 04:20:15.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:20:15.935: INFO: namespace: e2e-tests-kubectl-js5bl, resource: bindings, ignored listing per whitelist
Jan 12 04:20:15.954: INFO: namespace e2e-tests-kubectl-js5bl deletion completed in 6.094531375s

• [SLOW TEST:6.313 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:20:15.954: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-cgf2t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan 12 04:20:20.163: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 12 04:20:20.166: INFO: Pod pod-with-prestop-http-hook still exists
Jan 12 04:20:22.166: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 12 04:20:22.171: INFO: Pod pod-with-prestop-http-hook still exists
Jan 12 04:20:24.167: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 12 04:20:24.185: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:20:24.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-cgf2t" for this suite.
Jan 12 04:20:46.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:20:46.250: INFO: namespace: e2e-tests-container-lifecycle-hook-cgf2t, resource: bindings, ignored listing per whitelist
Jan 12 04:20:46.294: INFO: namespace e2e-tests-container-lifecycle-hook-cgf2t deletion completed in 22.097340958s

• [SLOW TEST:30.341 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:20:46.295: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-7wsbl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Jan 12 04:20:46.469: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-7wsbl" to be "success or failure"
Jan 12 04:20:46.476: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 6.768229ms
Jan 12 04:20:48.483: INFO: Pod "pod-host-path-test": Phase="Running", Reason="", readiness=false. Elapsed: 2.013928406s
Jan 12 04:20:50.486: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017557602s
STEP: Saw pod success
Jan 12 04:20:50.486: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jan 12 04:20:50.489: INFO: Trying to get logs from node c76-1-41 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jan 12 04:20:50.504: INFO: Waiting for pod pod-host-path-test to disappear
Jan 12 04:20:50.507: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:20:50.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-7wsbl" for this suite.
Jan 12 04:20:56.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:20:56.598: INFO: namespace: e2e-tests-hostpath-7wsbl, resource: bindings, ignored listing per whitelist
Jan 12 04:20:56.644: INFO: namespace e2e-tests-hostpath-7wsbl deletion completed in 6.133462579s

• [SLOW TEST:10.349 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:20:56.644: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-lxdx5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 12 04:20:56.831: INFO: Waiting up to 5m0s for pod "downwardapi-volume-753d93a6-1621-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-projected-lxdx5" to be "success or failure"
Jan 12 04:20:56.836: INFO: Pod "downwardapi-volume-753d93a6-1621-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 5.01183ms
Jan 12 04:20:58.844: INFO: Pod "downwardapi-volume-753d93a6-1621-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013120746s
STEP: Saw pod success
Jan 12 04:20:58.845: INFO: Pod "downwardapi-volume-753d93a6-1621-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:20:58.853: INFO: Trying to get logs from node c76-1-41 pod downwardapi-volume-753d93a6-1621-11e9-8fb7-aa4233c46d55 container client-container: <nil>
STEP: delete the pod
Jan 12 04:20:58.900: INFO: Waiting for pod downwardapi-volume-753d93a6-1621-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:20:58.903: INFO: Pod downwardapi-volume-753d93a6-1621-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:20:58.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lxdx5" for this suite.
Jan 12 04:21:04.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:21:05.056: INFO: namespace: e2e-tests-projected-lxdx5, resource: bindings, ignored listing per whitelist
Jan 12 04:21:05.066: INFO: namespace e2e-tests-projected-lxdx5 deletion completed in 6.160718204s

• [SLOW TEST:8.423 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:21:05.066: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-6p8vg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan 12 04:21:09.790: INFO: Successfully updated pod "pod-update-7a41c82b-1621-11e9-8fb7-aa4233c46d55"
STEP: verifying the updated pod is in kubernetes
Jan 12 04:21:09.819: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:21:09.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-6p8vg" for this suite.
Jan 12 04:21:31.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:21:31.881: INFO: namespace: e2e-tests-pods-6p8vg, resource: bindings, ignored listing per whitelist
Jan 12 04:21:31.929: INFO: namespace e2e-tests-pods-6p8vg deletion completed in 22.105919569s

• [SLOW TEST:26.863 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:21:31.929: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-zxzts
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Jan 12 04:21:34.120: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-8a4325c3-1621-11e9-8fb7-aa4233c46d55", GenerateName:"", Namespace:"e2e-tests-pods-zxzts", SelfLink:"/api/v1/namespaces/e2e-tests-pods-zxzts/pods/pod-submit-remove-8a4325c3-1621-11e9-8fb7-aa4233c46d55", UID:"8a437d16-1621-11e9-b7e1-000c294e6ffe", ResourceVersion:"132630", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63682863692, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"89905121"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-l9ktk", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001b52840), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-l9ktk", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001b34218), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"c76-1-41", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0001dca20), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001b34260)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001b34280)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001b34288), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682863692, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682863693, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682863693, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682863692, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.1.41", PodIP:"172.31.52.72", StartTime:(*v1.Time)(0xc0010bdf80), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc0010bdfa0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96", ContainerID:"docker://64ee5f7c1c380363b1bebda03902e75f3389ee766ba7a15f8904d843fb89260c"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Jan 12 04:21:39.144: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:21:39.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-zxzts" for this suite.
Jan 12 04:21:45.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:21:45.218: INFO: namespace: e2e-tests-pods-zxzts, resource: bindings, ignored listing per whitelist
Jan 12 04:21:45.264: INFO: namespace e2e-tests-pods-zxzts deletion completed in 6.101790745s

• [SLOW TEST:13.335 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:21:45.264: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-whvjw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jan 12 04:21:53.494: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-whvjw PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 12 04:21:53.494: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
Jan 12 04:21:53.613: INFO: Exec stderr: ""
Jan 12 04:21:53.614: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-whvjw PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 12 04:21:53.614: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
Jan 12 04:21:53.675: INFO: Exec stderr: ""
Jan 12 04:21:53.675: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-whvjw PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 12 04:21:53.675: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
Jan 12 04:21:53.737: INFO: Exec stderr: ""
Jan 12 04:21:53.737: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-whvjw PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 12 04:21:53.737: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
Jan 12 04:21:53.798: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jan 12 04:21:53.798: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-whvjw PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 12 04:21:53.798: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
Jan 12 04:21:53.859: INFO: Exec stderr: ""
Jan 12 04:21:53.859: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-whvjw PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 12 04:21:53.859: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
Jan 12 04:21:53.920: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jan 12 04:21:53.920: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-whvjw PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 12 04:21:53.920: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
Jan 12 04:21:54.003: INFO: Exec stderr: ""
Jan 12 04:21:54.003: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-whvjw PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 12 04:21:54.003: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
Jan 12 04:21:54.087: INFO: Exec stderr: ""
Jan 12 04:21:54.087: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-whvjw PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 12 04:21:54.087: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
Jan 12 04:21:54.149: INFO: Exec stderr: ""
Jan 12 04:21:54.149: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-whvjw PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 12 04:21:54.149: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
Jan 12 04:21:54.215: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:21:54.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-whvjw" for this suite.
Jan 12 04:22:54.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:22:54.276: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-whvjw, resource: bindings, ignored listing per whitelist
Jan 12 04:22:54.310: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-whvjw deletion completed in 1m0.091303731s

• [SLOW TEST:69.045 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:22:54.310: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-v4mcw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 12 04:22:54.476: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bb5d71f7-1621-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-downward-api-v4mcw" to be "success or failure"
Jan 12 04:22:54.480: INFO: Pod "downwardapi-volume-bb5d71f7-1621-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039714ms
Jan 12 04:22:56.489: INFO: Pod "downwardapi-volume-bb5d71f7-1621-11e9-8fb7-aa4233c46d55": Phase="Running", Reason="", readiness=true. Elapsed: 2.012911812s
Jan 12 04:22:58.493: INFO: Pod "downwardapi-volume-bb5d71f7-1621-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016988994s
STEP: Saw pod success
Jan 12 04:22:58.493: INFO: Pod "downwardapi-volume-bb5d71f7-1621-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:22:58.496: INFO: Trying to get logs from node c76-1-41 pod downwardapi-volume-bb5d71f7-1621-11e9-8fb7-aa4233c46d55 container client-container: <nil>
STEP: delete the pod
Jan 12 04:22:58.510: INFO: Waiting for pod downwardapi-volume-bb5d71f7-1621-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:22:58.513: INFO: Pod downwardapi-volume-bb5d71f7-1621-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:22:58.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-v4mcw" for this suite.
Jan 12 04:23:04.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:23:04.622: INFO: namespace: e2e-tests-downward-api-v4mcw, resource: bindings, ignored listing per whitelist
Jan 12 04:23:04.622: INFO: namespace e2e-tests-downward-api-v4mcw deletion completed in 6.106029026s

• [SLOW TEST:10.313 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:23:04.622: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-ddsll
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 12 04:23:04.827: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c188d7d8-1621-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-projected-ddsll" to be "success or failure"
Jan 12 04:23:04.833: INFO: Pod "downwardapi-volume-c188d7d8-1621-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 5.506339ms
Jan 12 04:23:06.836: INFO: Pod "downwardapi-volume-c188d7d8-1621-11e9-8fb7-aa4233c46d55": Phase="Running", Reason="", readiness=true. Elapsed: 2.009163457s
Jan 12 04:23:08.842: INFO: Pod "downwardapi-volume-c188d7d8-1621-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014643338s
STEP: Saw pod success
Jan 12 04:23:08.842: INFO: Pod "downwardapi-volume-c188d7d8-1621-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:23:08.846: INFO: Trying to get logs from node c76-1-41 pod downwardapi-volume-c188d7d8-1621-11e9-8fb7-aa4233c46d55 container client-container: <nil>
STEP: delete the pod
Jan 12 04:23:08.866: INFO: Waiting for pod downwardapi-volume-c188d7d8-1621-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:23:08.868: INFO: Pod downwardapi-volume-c188d7d8-1621-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:23:08.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ddsll" for this suite.
Jan 12 04:23:14.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:23:14.955: INFO: namespace: e2e-tests-projected-ddsll, resource: bindings, ignored listing per whitelist
Jan 12 04:23:14.999: INFO: namespace e2e-tests-projected-ddsll deletion completed in 6.12757179s

• [SLOW TEST:10.377 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:23:14.999: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-b5jzs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 12 04:23:17.711: INFO: Successfully updated pod "labelsupdatec7b1c94f-1621-11e9-8fb7-aa4233c46d55"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:23:21.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-b5jzs" for this suite.
Jan 12 04:23:43.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:23:43.878: INFO: namespace: e2e-tests-downward-api-b5jzs, resource: bindings, ignored listing per whitelist
Jan 12 04:23:43.898: INFO: namespace e2e-tests-downward-api-b5jzs deletion completed in 22.14118874s

• [SLOW TEST:28.898 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:23:43.898: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-c9rm6
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-d8eb7526-1621-11e9-8fb7-aa4233c46d55
STEP: Creating configMap with name cm-test-opt-upd-d8eb755d-1621-11e9-8fb7-aa4233c46d55
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-d8eb7526-1621-11e9-8fb7-aa4233c46d55
STEP: Updating configmap cm-test-opt-upd-d8eb755d-1621-11e9-8fb7-aa4233c46d55
STEP: Creating configMap with name cm-test-opt-create-d8eb756b-1621-11e9-8fb7-aa4233c46d55
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:23:48.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-c9rm6" for this suite.
Jan 12 04:24:10.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:24:10.304: INFO: namespace: e2e-tests-projected-c9rm6, resource: bindings, ignored listing per whitelist
Jan 12 04:24:10.312: INFO: namespace e2e-tests-projected-c9rm6 deletion completed in 22.117808914s

• [SLOW TEST:26.414 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:24:10.312: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-zmv5r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-e8a9f099-1621-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume configMaps
Jan 12 04:24:10.479: INFO: Waiting up to 5m0s for pod "pod-configmaps-e8aa64b7-1621-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-configmap-zmv5r" to be "success or failure"
Jan 12 04:24:10.487: INFO: Pod "pod-configmaps-e8aa64b7-1621-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 8.296239ms
Jan 12 04:24:12.490: INFO: Pod "pod-configmaps-e8aa64b7-1621-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011036632s
STEP: Saw pod success
Jan 12 04:24:12.490: INFO: Pod "pod-configmaps-e8aa64b7-1621-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:24:12.499: INFO: Trying to get logs from node c76-1-41 pod pod-configmaps-e8aa64b7-1621-11e9-8fb7-aa4233c46d55 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 12 04:24:12.524: INFO: Waiting for pod pod-configmaps-e8aa64b7-1621-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:24:12.530: INFO: Pod pod-configmaps-e8aa64b7-1621-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:24:12.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zmv5r" for this suite.
Jan 12 04:24:18.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:24:18.576: INFO: namespace: e2e-tests-configmap-zmv5r, resource: bindings, ignored listing per whitelist
Jan 12 04:24:18.636: INFO: namespace e2e-tests-configmap-zmv5r deletion completed in 6.102286565s

• [SLOW TEST:8.324 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:24:18.636: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-p4b4p
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-eda0b081-1621-11e9-8fb7-aa4233c46d55
STEP: Creating secret with name s-test-opt-upd-eda0b0fb-1621-11e9-8fb7-aa4233c46d55
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-eda0b081-1621-11e9-8fb7-aa4233c46d55
STEP: Updating secret s-test-opt-upd-eda0b0fb-1621-11e9-8fb7-aa4233c46d55
STEP: Creating secret with name s-test-opt-create-eda0b128-1621-11e9-8fb7-aa4233c46d55
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:25:52.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-p4b4p" for this suite.
Jan 12 04:26:14.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:26:14.124: INFO: namespace: e2e-tests-secrets-p4b4p, resource: bindings, ignored listing per whitelist
Jan 12 04:26:14.159: INFO: namespace e2e-tests-secrets-p4b4p deletion completed in 22.095702724s

• [SLOW TEST:115.523 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:26:14.159: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-mzcrt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-327b4a3e-1622-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume secrets
Jan 12 04:26:14.330: INFO: Waiting up to 5m0s for pod "pod-secrets-327caf16-1622-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-secrets-mzcrt" to be "success or failure"
Jan 12 04:26:14.334: INFO: Pod "pod-secrets-327caf16-1622-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 4.042297ms
Jan 12 04:26:16.340: INFO: Pod "pod-secrets-327caf16-1622-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01036137s
Jan 12 04:26:18.345: INFO: Pod "pod-secrets-327caf16-1622-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015042102s
STEP: Saw pod success
Jan 12 04:26:18.345: INFO: Pod "pod-secrets-327caf16-1622-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:26:18.349: INFO: Trying to get logs from node c76-1-41 pod pod-secrets-327caf16-1622-11e9-8fb7-aa4233c46d55 container secret-volume-test: <nil>
STEP: delete the pod
Jan 12 04:26:18.370: INFO: Waiting for pod pod-secrets-327caf16-1622-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:26:18.373: INFO: Pod pod-secrets-327caf16-1622-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:26:18.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-mzcrt" for this suite.
Jan 12 04:26:24.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:26:24.507: INFO: namespace: e2e-tests-secrets-mzcrt, resource: bindings, ignored listing per whitelist
Jan 12 04:26:24.535: INFO: namespace e2e-tests-secrets-mzcrt deletion completed in 6.158765697s

• [SLOW TEST:10.376 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:26:24.535: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-bp4ww
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jan 12 04:26:24.704: INFO: namespace e2e-tests-kubectl-bp4ww
Jan 12 04:26:24.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 create -f - --namespace=e2e-tests-kubectl-bp4ww'
Jan 12 04:26:25.064: INFO: stderr: ""
Jan 12 04:26:25.064: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 12 04:26:26.067: INFO: Selector matched 1 pods for map[app:redis]
Jan 12 04:26:26.067: INFO: Found 0 / 1
Jan 12 04:26:27.069: INFO: Selector matched 1 pods for map[app:redis]
Jan 12 04:26:27.069: INFO: Found 1 / 1
Jan 12 04:26:27.069: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 12 04:26:27.075: INFO: Selector matched 1 pods for map[app:redis]
Jan 12 04:26:27.075: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 12 04:26:27.075: INFO: wait on redis-master startup in e2e-tests-kubectl-bp4ww 
Jan 12 04:26:27.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 logs redis-master-t569w redis-master --namespace=e2e-tests-kubectl-bp4ww'
Jan 12 04:26:27.215: INFO: stderr: ""
Jan 12 04:26:27.215: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 12 Jan 04:26:26.394 # Server started, Redis version 3.2.12\n1:M 12 Jan 04:26:26.394 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 12 Jan 04:26:26.394 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Jan 12 04:26:27.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-bp4ww'
Jan 12 04:26:27.311: INFO: stderr: ""
Jan 12 04:26:27.311: INFO: stdout: "service/rm2 exposed\n"
Jan 12 04:26:27.314: INFO: Service rm2 in namespace e2e-tests-kubectl-bp4ww found.
STEP: exposing service
Jan 12 04:26:29.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-bp4ww'
Jan 12 04:26:29.444: INFO: stderr: ""
Jan 12 04:26:29.444: INFO: stdout: "service/rm3 exposed\n"
Jan 12 04:26:29.452: INFO: Service rm3 in namespace e2e-tests-kubectl-bp4ww found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:26:31.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bp4ww" for this suite.
Jan 12 04:26:53.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:26:53.573: INFO: namespace: e2e-tests-kubectl-bp4ww, resource: bindings, ignored listing per whitelist
Jan 12 04:26:53.608: INFO: namespace e2e-tests-kubectl-bp4ww deletion completed in 22.131479429s

• [SLOW TEST:29.073 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:26:53.608: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-2t6mb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 12 04:26:53.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-2t6mb'
Jan 12 04:26:53.840: INFO: stderr: ""
Jan 12 04:26:53.840: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Jan 12 04:26:53.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-2t6mb'
Jan 12 04:27:03.536: INFO: stderr: ""
Jan 12 04:27:03.536: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:27:03.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2t6mb" for this suite.
Jan 12 04:27:09.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:27:09.599: INFO: namespace: e2e-tests-kubectl-2t6mb, resource: bindings, ignored listing per whitelist
Jan 12 04:27:09.632: INFO: namespace e2e-tests-kubectl-2t6mb deletion completed in 6.091320452s

• [SLOW TEST:16.024 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:27:09.633: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-ppc2s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jan 12 04:27:09.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 create -f - --namespace=e2e-tests-kubectl-ppc2s'
Jan 12 04:27:10.038: INFO: stderr: ""
Jan 12 04:27:10.038: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 12 04:27:10.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ppc2s'
Jan 12 04:27:10.156: INFO: stderr: ""
Jan 12 04:27:10.157: INFO: stdout: "update-demo-nautilus-ctnc7 update-demo-nautilus-xj4dw "
Jan 12 04:27:10.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-nautilus-ctnc7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ppc2s'
Jan 12 04:27:10.240: INFO: stderr: ""
Jan 12 04:27:10.240: INFO: stdout: ""
Jan 12 04:27:10.240: INFO: update-demo-nautilus-ctnc7 is created but not running
Jan 12 04:27:15.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ppc2s'
Jan 12 04:27:15.325: INFO: stderr: ""
Jan 12 04:27:15.325: INFO: stdout: "update-demo-nautilus-ctnc7 update-demo-nautilus-xj4dw "
Jan 12 04:27:15.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-nautilus-ctnc7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ppc2s'
Jan 12 04:27:15.395: INFO: stderr: ""
Jan 12 04:27:15.395: INFO: stdout: "true"
Jan 12 04:27:15.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-nautilus-ctnc7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ppc2s'
Jan 12 04:27:15.462: INFO: stderr: ""
Jan 12 04:27:15.462: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 12 04:27:15.462: INFO: validating pod update-demo-nautilus-ctnc7
Jan 12 04:27:15.469: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 12 04:27:15.469: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 12 04:27:15.469: INFO: update-demo-nautilus-ctnc7 is verified up and running
Jan 12 04:27:15.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-nautilus-xj4dw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ppc2s'
Jan 12 04:27:15.564: INFO: stderr: ""
Jan 12 04:27:15.564: INFO: stdout: "true"
Jan 12 04:27:15.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-nautilus-xj4dw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ppc2s'
Jan 12 04:27:15.643: INFO: stderr: ""
Jan 12 04:27:15.643: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 12 04:27:15.643: INFO: validating pod update-demo-nautilus-xj4dw
Jan 12 04:27:15.648: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 12 04:27:15.648: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 12 04:27:15.648: INFO: update-demo-nautilus-xj4dw is verified up and running
STEP: scaling down the replication controller
Jan 12 04:27:15.649: INFO: scanned /root for discovery docs: <nil>
Jan 12 04:27:15.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-ppc2s'
Jan 12 04:27:16.748: INFO: stderr: ""
Jan 12 04:27:16.748: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 12 04:27:16.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ppc2s'
Jan 12 04:27:16.857: INFO: stderr: ""
Jan 12 04:27:16.857: INFO: stdout: "update-demo-nautilus-ctnc7 update-demo-nautilus-xj4dw "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jan 12 04:27:21.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ppc2s'
Jan 12 04:27:21.968: INFO: stderr: ""
Jan 12 04:27:21.968: INFO: stdout: "update-demo-nautilus-ctnc7 "
Jan 12 04:27:21.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-nautilus-ctnc7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ppc2s'
Jan 12 04:27:22.036: INFO: stderr: ""
Jan 12 04:27:22.036: INFO: stdout: "true"
Jan 12 04:27:22.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-nautilus-ctnc7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ppc2s'
Jan 12 04:27:22.104: INFO: stderr: ""
Jan 12 04:27:22.104: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 12 04:27:22.104: INFO: validating pod update-demo-nautilus-ctnc7
Jan 12 04:27:22.107: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 12 04:27:22.107: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 12 04:27:22.107: INFO: update-demo-nautilus-ctnc7 is verified up and running
STEP: scaling up the replication controller
Jan 12 04:27:22.108: INFO: scanned /root for discovery docs: <nil>
Jan 12 04:27:22.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-ppc2s'
Jan 12 04:27:23.206: INFO: stderr: ""
Jan 12 04:27:23.206: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 12 04:27:23.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ppc2s'
Jan 12 04:27:23.281: INFO: stderr: ""
Jan 12 04:27:23.281: INFO: stdout: "update-demo-nautilus-ctnc7 update-demo-nautilus-ssrc7 "
Jan 12 04:27:23.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-nautilus-ctnc7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ppc2s'
Jan 12 04:27:23.350: INFO: stderr: ""
Jan 12 04:27:23.350: INFO: stdout: "true"
Jan 12 04:27:23.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-nautilus-ctnc7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ppc2s'
Jan 12 04:27:23.416: INFO: stderr: ""
Jan 12 04:27:23.416: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 12 04:27:23.416: INFO: validating pod update-demo-nautilus-ctnc7
Jan 12 04:27:23.419: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 12 04:27:23.419: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 12 04:27:23.419: INFO: update-demo-nautilus-ctnc7 is verified up and running
Jan 12 04:27:23.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-nautilus-ssrc7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ppc2s'
Jan 12 04:27:23.500: INFO: stderr: ""
Jan 12 04:27:23.500: INFO: stdout: ""
Jan 12 04:27:23.500: INFO: update-demo-nautilus-ssrc7 is created but not running
Jan 12 04:27:28.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ppc2s'
Jan 12 04:27:28.615: INFO: stderr: ""
Jan 12 04:27:28.616: INFO: stdout: "update-demo-nautilus-ctnc7 update-demo-nautilus-ssrc7 "
Jan 12 04:27:28.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-nautilus-ctnc7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ppc2s'
Jan 12 04:27:28.697: INFO: stderr: ""
Jan 12 04:27:28.697: INFO: stdout: "true"
Jan 12 04:27:28.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-nautilus-ctnc7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ppc2s'
Jan 12 04:27:28.759: INFO: stderr: ""
Jan 12 04:27:28.759: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 12 04:27:28.759: INFO: validating pod update-demo-nautilus-ctnc7
Jan 12 04:27:28.763: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 12 04:27:28.763: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 12 04:27:28.763: INFO: update-demo-nautilus-ctnc7 is verified up and running
Jan 12 04:27:28.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-nautilus-ssrc7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ppc2s'
Jan 12 04:27:28.827: INFO: stderr: ""
Jan 12 04:27:28.827: INFO: stdout: "true"
Jan 12 04:27:28.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-nautilus-ssrc7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ppc2s'
Jan 12 04:27:28.890: INFO: stderr: ""
Jan 12 04:27:28.890: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 12 04:27:28.890: INFO: validating pod update-demo-nautilus-ssrc7
Jan 12 04:27:28.895: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 12 04:27:28.895: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 12 04:27:28.895: INFO: update-demo-nautilus-ssrc7 is verified up and running
STEP: using delete to clean up resources
Jan 12 04:27:28.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ppc2s'
Jan 12 04:27:28.981: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 12 04:27:28.981: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 12 04:27:28.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-ppc2s'
Jan 12 04:27:29.075: INFO: stderr: "No resources found.\n"
Jan 12 04:27:29.075: INFO: stdout: ""
Jan 12 04:27:29.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods -l name=update-demo --namespace=e2e-tests-kubectl-ppc2s -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 12 04:27:29.153: INFO: stderr: ""
Jan 12 04:27:29.153: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:27:29.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ppc2s" for this suite.
Jan 12 04:27:35.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:27:35.214: INFO: namespace: e2e-tests-kubectl-ppc2s, resource: bindings, ignored listing per whitelist
Jan 12 04:27:35.271: INFO: namespace e2e-tests-kubectl-ppc2s deletion completed in 6.111921299s

• [SLOW TEST:25.638 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:27:35.271: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-45ldr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-62d4c393-1622-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume configMaps
Jan 12 04:27:35.442: INFO: Waiting up to 5m0s for pod "pod-configmaps-62d5444f-1622-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-configmap-45ldr" to be "success or failure"
Jan 12 04:27:35.446: INFO: Pod "pod-configmaps-62d5444f-1622-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 3.306635ms
Jan 12 04:27:37.448: INFO: Pod "pod-configmaps-62d5444f-1622-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00592957s
STEP: Saw pod success
Jan 12 04:27:37.449: INFO: Pod "pod-configmaps-62d5444f-1622-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:27:37.451: INFO: Trying to get logs from node c76-1-41 pod pod-configmaps-62d5444f-1622-11e9-8fb7-aa4233c46d55 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 12 04:27:37.476: INFO: Waiting for pod pod-configmaps-62d5444f-1622-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:27:37.479: INFO: Pod pod-configmaps-62d5444f-1622-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:27:37.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-45ldr" for this suite.
Jan 12 04:27:43.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:27:43.585: INFO: namespace: e2e-tests-configmap-45ldr, resource: bindings, ignored listing per whitelist
Jan 12 04:27:43.622: INFO: namespace e2e-tests-configmap-45ldr deletion completed in 6.138641273s

• [SLOW TEST:8.351 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:27:43.622: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-sr5km
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 12 04:27:43.795: INFO: (0) /api/v1/nodes/c76-1-41:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 8.169717ms)
Jan 12 04:27:43.800: INFO: (1) /api/v1/nodes/c76-1-41:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 4.978007ms)
Jan 12 04:27:43.803: INFO: (2) /api/v1/nodes/c76-1-41:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.206107ms)
Jan 12 04:27:43.806: INFO: (3) /api/v1/nodes/c76-1-41:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.307827ms)
Jan 12 04:27:43.810: INFO: (4) /api/v1/nodes/c76-1-41:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.379763ms)
Jan 12 04:27:43.813: INFO: (5) /api/v1/nodes/c76-1-41:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.398277ms)
Jan 12 04:27:43.817: INFO: (6) /api/v1/nodes/c76-1-41:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.357494ms)
Jan 12 04:27:43.820: INFO: (7) /api/v1/nodes/c76-1-41:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.860327ms)
Jan 12 04:27:43.824: INFO: (8) /api/v1/nodes/c76-1-41:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.396516ms)
Jan 12 04:27:43.829: INFO: (9) /api/v1/nodes/c76-1-41:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 5.135702ms)
Jan 12 04:27:43.833: INFO: (10) /api/v1/nodes/c76-1-41:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.695174ms)
Jan 12 04:27:43.836: INFO: (11) /api/v1/nodes/c76-1-41:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.569413ms)
Jan 12 04:27:43.840: INFO: (12) /api/v1/nodes/c76-1-41:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.814111ms)
Jan 12 04:27:43.844: INFO: (13) /api/v1/nodes/c76-1-41:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.536723ms)
Jan 12 04:27:43.847: INFO: (14) /api/v1/nodes/c76-1-41:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.094249ms)
Jan 12 04:27:43.851: INFO: (15) /api/v1/nodes/c76-1-41:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.691507ms)
Jan 12 04:27:43.854: INFO: (16) /api/v1/nodes/c76-1-41:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.01787ms)
Jan 12 04:27:43.857: INFO: (17) /api/v1/nodes/c76-1-41:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.344603ms)
Jan 12 04:27:43.860: INFO: (18) /api/v1/nodes/c76-1-41:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.023091ms)
Jan 12 04:27:43.863: INFO: (19) /api/v1/nodes/c76-1-41:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.034937ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:27:43.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-sr5km" for this suite.
Jan 12 04:27:49.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:27:49.945: INFO: namespace: e2e-tests-proxy-sr5km, resource: bindings, ignored listing per whitelist
Jan 12 04:27:49.982: INFO: namespace e2e-tests-proxy-sr5km deletion completed in 6.116326655s

• [SLOW TEST:6.361 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:27:49.982: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-ntmcm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 12 04:27:50.168: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jan 12 04:27:55.175: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 12 04:27:55.175: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 12 04:27:55.214: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-ntmcm,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ntmcm/deployments/test-cleanup-deployment,UID:6e9b8798-1622-11e9-b7e1-000c294e6ffe,ResourceVersion:133851,Generation:1,CreationTimestamp:2019-01-12 04:27:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Jan 12 04:27:55.225: INFO: New ReplicaSet "test-cleanup-deployment-755f6b95cc" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc,GenerateName:,Namespace:e2e-tests-deployment-ntmcm,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ntmcm/replicasets/test-cleanup-deployment-755f6b95cc,UID:6e9ed330-1622-11e9-b7e1-000c294e6ffe,ResourceVersion:133853,Generation:1,CreationTimestamp:2019-01-12 04:27:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 6e9b8798-1622-11e9-b7e1-000c294e6ffe 0xc000cfdba7 0xc000cfdba8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 12 04:27:55.225: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Jan 12 04:27:55.225: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-ntmcm,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ntmcm/replicasets/test-cleanup-controller,UID:6b9aa7a5-1622-11e9-b7e1-000c294e6ffe,ResourceVersion:133852,Generation:1,CreationTimestamp:2019-01-12 04:27:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 6e9b8798-1622-11e9-b7e1-000c294e6ffe 0xc000cfd987 0xc000cfd988}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 12 04:27:55.239: INFO: Pod "test-cleanup-controller-mmrg5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-mmrg5,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-ntmcm,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ntmcm/pods/test-cleanup-controller-mmrg5,UID:6b9dc33f-1622-11e9-b7e1-000c294e6ffe,ResourceVersion:133845,Generation:0,CreationTimestamp:2019-01-12 04:27:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 6b9aa7a5-1622-11e9-b7e1-000c294e6ffe 0xc0009c1327 0xc0009c1328}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qfk6g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfk6g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qfk6g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0009c13a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0009c13c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:27:50 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:27:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:27:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:27:50 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:172.31.52.96,StartTime:2019-01-12 04:27:50 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-12 04:27:51 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://29b22fabf857522d1aac6e9735035919fc39add3fcabd32989264cefbd59bc26}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:27:55.239: INFO: Pod "test-cleanup-deployment-755f6b95cc-dvmxz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc-dvmxz,GenerateName:test-cleanup-deployment-755f6b95cc-,Namespace:e2e-tests-deployment-ntmcm,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ntmcm/pods/test-cleanup-deployment-755f6b95cc-dvmxz,UID:6e9f99e0-1622-11e9-b7e1-000c294e6ffe,ResourceVersion:133858,Generation:0,CreationTimestamp:2019-01-12 04:27:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-755f6b95cc 6e9ed330-1622-11e9-b7e1-000c294e6ffe 0xc0009c1497 0xc0009c1498}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qfk6g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qfk6g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-qfk6g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0009c1510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0009c1530}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:27:55 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:27:55.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-ntmcm" for this suite.
Jan 12 04:28:01.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:28:01.304: INFO: namespace: e2e-tests-deployment-ntmcm, resource: bindings, ignored listing per whitelist
Jan 12 04:28:01.351: INFO: namespace e2e-tests-deployment-ntmcm deletion completed in 6.105751345s

• [SLOW TEST:11.368 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:28:01.351: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-spc4m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 12 04:28:01.525: INFO: Waiting up to 5m0s for pod "downwardapi-volume-72607555-1622-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-downward-api-spc4m" to be "success or failure"
Jan 12 04:28:01.544: INFO: Pod "downwardapi-volume-72607555-1622-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 10.233841ms
Jan 12 04:28:03.548: INFO: Pod "downwardapi-volume-72607555-1622-11e9-8fb7-aa4233c46d55": Phase="Running", Reason="", readiness=true. Elapsed: 2.014589488s
Jan 12 04:28:05.553: INFO: Pod "downwardapi-volume-72607555-1622-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019226001s
STEP: Saw pod success
Jan 12 04:28:05.553: INFO: Pod "downwardapi-volume-72607555-1622-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:28:05.556: INFO: Trying to get logs from node c76-1-41 pod downwardapi-volume-72607555-1622-11e9-8fb7-aa4233c46d55 container client-container: <nil>
STEP: delete the pod
Jan 12 04:28:05.591: INFO: Waiting for pod downwardapi-volume-72607555-1622-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:28:05.593: INFO: Pod downwardapi-volume-72607555-1622-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:28:05.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-spc4m" for this suite.
Jan 12 04:28:11.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:28:11.656: INFO: namespace: e2e-tests-downward-api-spc4m, resource: bindings, ignored listing per whitelist
Jan 12 04:28:11.687: INFO: namespace e2e-tests-downward-api-spc4m deletion completed in 6.090686339s

• [SLOW TEST:10.336 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:28:11.687: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-86szt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-7889c1b0-1622-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume secrets
Jan 12 04:28:11.866: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-788a86f2-1622-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-projected-86szt" to be "success or failure"
Jan 12 04:28:11.869: INFO: Pod "pod-projected-secrets-788a86f2-1622-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 3.330607ms
Jan 12 04:28:13.873: INFO: Pod "pod-projected-secrets-788a86f2-1622-11e9-8fb7-aa4233c46d55": Phase="Running", Reason="", readiness=true. Elapsed: 2.007652183s
Jan 12 04:28:15.877: INFO: Pod "pod-projected-secrets-788a86f2-1622-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010857162s
STEP: Saw pod success
Jan 12 04:28:15.877: INFO: Pod "pod-projected-secrets-788a86f2-1622-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:28:15.879: INFO: Trying to get logs from node c76-1-41 pod pod-projected-secrets-788a86f2-1622-11e9-8fb7-aa4233c46d55 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 12 04:28:15.893: INFO: Waiting for pod pod-projected-secrets-788a86f2-1622-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:28:15.896: INFO: Pod pod-projected-secrets-788a86f2-1622-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:28:15.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-86szt" for this suite.
Jan 12 04:28:21.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:28:21.950: INFO: namespace: e2e-tests-projected-86szt, resource: bindings, ignored listing per whitelist
Jan 12 04:28:22.017: INFO: namespace e2e-tests-projected-86szt deletion completed in 6.117485767s

• [SLOW TEST:10.329 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:28:22.017: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-6lc9w
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-6lc9w
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-6lc9w
STEP: Deleting pre-stop pod
Jan 12 04:28:33.239: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:28:33.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-6lc9w" for this suite.
Jan 12 04:29:11.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:29:11.346: INFO: namespace: e2e-tests-prestop-6lc9w, resource: bindings, ignored listing per whitelist
Jan 12 04:29:11.358: INFO: namespace e2e-tests-prestop-6lc9w deletion completed in 38.103406751s

• [SLOW TEST:49.342 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:29:11.358: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-hqxg5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-hqxg5
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 12 04:29:11.525: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 12 04:29:29.574: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.31.52.74:8080/dial?request=hostName&protocol=http&host=172.31.52.84&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-hqxg5 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 12 04:29:29.574: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
Jan 12 04:29:29.645: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:29:29.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-hqxg5" for this suite.
Jan 12 04:29:51.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:29:51.710: INFO: namespace: e2e-tests-pod-network-test-hqxg5, resource: bindings, ignored listing per whitelist
Jan 12 04:29:51.735: INFO: namespace e2e-tests-pod-network-test-hqxg5 deletion completed in 22.087289783s

• [SLOW TEST:40.377 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:29:51.735: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-24wjt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 12 04:29:51.890: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:29:54.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-24wjt" for this suite.
Jan 12 04:30:34.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:30:34.111: INFO: namespace: e2e-tests-pods-24wjt, resource: bindings, ignored listing per whitelist
Jan 12 04:30:34.126: INFO: namespace e2e-tests-pods-24wjt deletion completed in 40.104932775s

• [SLOW TEST:42.391 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:30:34.127: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-gxxpc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 12 04:30:38.837: INFO: Successfully updated pod "labelsupdatecd6f4def-1622-11e9-8fb7-aa4233c46d55"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:30:40.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gxxpc" for this suite.
Jan 12 04:31:02.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:31:02.964: INFO: namespace: e2e-tests-projected-gxxpc, resource: bindings, ignored listing per whitelist
Jan 12 04:31:02.970: INFO: namespace e2e-tests-projected-gxxpc deletion completed in 22.110124816s

• [SLOW TEST:28.844 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:31:02.971: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bkvq4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-dea0d826-1622-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume configMaps
Jan 12 04:31:03.139: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-dea150d7-1622-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-projected-bkvq4" to be "success or failure"
Jan 12 04:31:03.141: INFO: Pod "pod-projected-configmaps-dea150d7-1622-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.677344ms
Jan 12 04:31:05.150: INFO: Pod "pod-projected-configmaps-dea150d7-1622-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011396765s
STEP: Saw pod success
Jan 12 04:31:05.150: INFO: Pod "pod-projected-configmaps-dea150d7-1622-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:31:05.152: INFO: Trying to get logs from node c76-1-41 pod pod-projected-configmaps-dea150d7-1622-11e9-8fb7-aa4233c46d55 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 12 04:31:05.179: INFO: Waiting for pod pod-projected-configmaps-dea150d7-1622-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:31:05.190: INFO: Pod pod-projected-configmaps-dea150d7-1622-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:31:05.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bkvq4" for this suite.
Jan 12 04:31:11.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:31:11.256: INFO: namespace: e2e-tests-projected-bkvq4, resource: bindings, ignored listing per whitelist
Jan 12 04:31:11.281: INFO: namespace e2e-tests-projected-bkvq4 deletion completed in 6.08714407s

• [SLOW TEST:8.310 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:31:11.281: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-zqt49
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 12 04:31:13.523: INFO: Waiting up to 5m0s for pod "client-envvars-e4cf2e08-1622-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-pods-zqt49" to be "success or failure"
Jan 12 04:31:13.553: INFO: Pod "client-envvars-e4cf2e08-1622-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 29.402087ms
Jan 12 04:31:15.556: INFO: Pod "client-envvars-e4cf2e08-1622-11e9-8fb7-aa4233c46d55": Phase="Running", Reason="", readiness=true. Elapsed: 2.032739178s
Jan 12 04:31:17.559: INFO: Pod "client-envvars-e4cf2e08-1622-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03542759s
STEP: Saw pod success
Jan 12 04:31:17.559: INFO: Pod "client-envvars-e4cf2e08-1622-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:31:17.561: INFO: Trying to get logs from node c76-1-41 pod client-envvars-e4cf2e08-1622-11e9-8fb7-aa4233c46d55 container env3cont: <nil>
STEP: delete the pod
Jan 12 04:31:17.631: INFO: Waiting for pod client-envvars-e4cf2e08-1622-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:31:17.634: INFO: Pod client-envvars-e4cf2e08-1622-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:31:17.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-zqt49" for this suite.
Jan 12 04:32:07.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:32:07.675: INFO: namespace: e2e-tests-pods-zqt49, resource: bindings, ignored listing per whitelist
Jan 12 04:32:07.734: INFO: namespace e2e-tests-pods-zqt49 deletion completed in 50.095778304s

• [SLOW TEST:56.453 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:32:07.734: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-9hfjk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Jan 12 04:32:07.900: INFO: Waiting up to 5m0s for pod "var-expansion-053b1fbf-1623-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-var-expansion-9hfjk" to be "success or failure"
Jan 12 04:32:07.905: INFO: Pod "var-expansion-053b1fbf-1623-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 5.409934ms
Jan 12 04:32:09.909: INFO: Pod "var-expansion-053b1fbf-1623-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009486098s
STEP: Saw pod success
Jan 12 04:32:09.909: INFO: Pod "var-expansion-053b1fbf-1623-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:32:09.913: INFO: Trying to get logs from node c76-1-41 pod var-expansion-053b1fbf-1623-11e9-8fb7-aa4233c46d55 container dapi-container: <nil>
STEP: delete the pod
Jan 12 04:32:09.940: INFO: Waiting for pod var-expansion-053b1fbf-1623-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:32:09.945: INFO: Pod var-expansion-053b1fbf-1623-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:32:09.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-9hfjk" for this suite.
Jan 12 04:32:15.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:32:15.992: INFO: namespace: e2e-tests-var-expansion-9hfjk, resource: bindings, ignored listing per whitelist
Jan 12 04:32:16.050: INFO: namespace e2e-tests-var-expansion-9hfjk deletion completed in 6.100106637s

• [SLOW TEST:8.316 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:32:16.050: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-tz25j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-tz25j
Jan 12 04:32:18.253: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-tz25j
STEP: checking the pod's current state and verifying that restartCount is present
Jan 12 04:32:18.261: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:36:19.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-tz25j" for this suite.
Jan 12 04:36:25.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:36:25.120: INFO: namespace: e2e-tests-container-probe-tz25j, resource: bindings, ignored listing per whitelist
Jan 12 04:36:25.179: INFO: namespace e2e-tests-container-probe-tz25j deletion completed in 6.093569312s

• [SLOW TEST:249.129 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:36:25.179: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-g82r6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jan 12 04:36:25.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 create -f - --namespace=e2e-tests-kubectl-g82r6'
Jan 12 04:36:25.923: INFO: stderr: ""
Jan 12 04:36:25.927: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 12 04:36:25.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-g82r6'
Jan 12 04:36:26.035: INFO: stderr: ""
Jan 12 04:36:26.035: INFO: stdout: "update-demo-nautilus-459j2 update-demo-nautilus-xtjlh "
Jan 12 04:36:26.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-nautilus-459j2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g82r6'
Jan 12 04:36:26.113: INFO: stderr: ""
Jan 12 04:36:26.113: INFO: stdout: ""
Jan 12 04:36:26.113: INFO: update-demo-nautilus-459j2 is created but not running
Jan 12 04:36:31.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-g82r6'
Jan 12 04:36:31.229: INFO: stderr: ""
Jan 12 04:36:31.229: INFO: stdout: "update-demo-nautilus-459j2 update-demo-nautilus-xtjlh "
Jan 12 04:36:31.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-nautilus-459j2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g82r6'
Jan 12 04:36:31.295: INFO: stderr: ""
Jan 12 04:36:31.295: INFO: stdout: "true"
Jan 12 04:36:31.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-nautilus-459j2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g82r6'
Jan 12 04:36:31.362: INFO: stderr: ""
Jan 12 04:36:31.362: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 12 04:36:31.362: INFO: validating pod update-demo-nautilus-459j2
Jan 12 04:36:31.368: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 12 04:36:31.368: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 12 04:36:31.368: INFO: update-demo-nautilus-459j2 is verified up and running
Jan 12 04:36:31.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-nautilus-xtjlh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g82r6'
Jan 12 04:36:31.432: INFO: stderr: ""
Jan 12 04:36:31.432: INFO: stdout: "true"
Jan 12 04:36:31.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-nautilus-xtjlh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g82r6'
Jan 12 04:36:31.498: INFO: stderr: ""
Jan 12 04:36:31.498: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 12 04:36:31.498: INFO: validating pod update-demo-nautilus-xtjlh
Jan 12 04:36:31.515: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 12 04:36:31.515: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 12 04:36:31.515: INFO: update-demo-nautilus-xtjlh is verified up and running
STEP: using delete to clean up resources
Jan 12 04:36:31.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-g82r6'
Jan 12 04:36:31.607: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 12 04:36:31.607: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 12 04:36:31.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-g82r6'
Jan 12 04:36:31.745: INFO: stderr: "No resources found.\n"
Jan 12 04:36:31.745: INFO: stdout: ""
Jan 12 04:36:31.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods -l name=update-demo --namespace=e2e-tests-kubectl-g82r6 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 12 04:36:31.824: INFO: stderr: ""
Jan 12 04:36:31.824: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:36:31.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-g82r6" for this suite.
Jan 12 04:36:53.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:36:53.939: INFO: namespace: e2e-tests-kubectl-g82r6, resource: bindings, ignored listing per whitelist
Jan 12 04:36:54.029: INFO: namespace e2e-tests-kubectl-g82r6 deletion completed in 22.192063019s

• [SLOW TEST:28.850 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:36:54.029: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qgvj5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-afe0c6cc-1623-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume configMaps
Jan 12 04:36:54.202: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-afe14e24-1623-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-projected-qgvj5" to be "success or failure"
Jan 12 04:36:54.204: INFO: Pod "pod-projected-configmaps-afe14e24-1623-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.273425ms
Jan 12 04:36:56.207: INFO: Pod "pod-projected-configmaps-afe14e24-1623-11e9-8fb7-aa4233c46d55": Phase="Running", Reason="", readiness=true. Elapsed: 2.005251255s
Jan 12 04:36:58.210: INFO: Pod "pod-projected-configmaps-afe14e24-1623-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008725075s
STEP: Saw pod success
Jan 12 04:36:58.210: INFO: Pod "pod-projected-configmaps-afe14e24-1623-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:36:58.213: INFO: Trying to get logs from node c76-1-41 pod pod-projected-configmaps-afe14e24-1623-11e9-8fb7-aa4233c46d55 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 12 04:36:58.237: INFO: Waiting for pod pod-projected-configmaps-afe14e24-1623-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:36:58.239: INFO: Pod pod-projected-configmaps-afe14e24-1623-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:36:58.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qgvj5" for this suite.
Jan 12 04:37:04.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:37:04.311: INFO: namespace: e2e-tests-projected-qgvj5, resource: bindings, ignored listing per whitelist
Jan 12 04:37:04.344: INFO: namespace e2e-tests-projected-qgvj5 deletion completed in 6.102145696s

• [SLOW TEST:10.315 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:37:04.344: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-mdjw2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan 12 04:37:04.519: INFO: Waiting up to 5m0s for pod "pod-b607b409-1623-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-emptydir-mdjw2" to be "success or failure"
Jan 12 04:37:04.523: INFO: Pod "pod-b607b409-1623-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 4.187495ms
Jan 12 04:37:06.526: INFO: Pod "pod-b607b409-1623-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007318344s
Jan 12 04:37:08.534: INFO: Pod "pod-b607b409-1623-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014625383s
STEP: Saw pod success
Jan 12 04:37:08.535: INFO: Pod "pod-b607b409-1623-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:37:08.541: INFO: Trying to get logs from node c76-1-41 pod pod-b607b409-1623-11e9-8fb7-aa4233c46d55 container test-container: <nil>
STEP: delete the pod
Jan 12 04:37:08.567: INFO: Waiting for pod pod-b607b409-1623-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:37:08.574: INFO: Pod pod-b607b409-1623-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:37:08.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mdjw2" for this suite.
Jan 12 04:37:14.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:37:14.639: INFO: namespace: e2e-tests-emptydir-mdjw2, resource: bindings, ignored listing per whitelist
Jan 12 04:37:14.695: INFO: namespace e2e-tests-emptydir-mdjw2 deletion completed in 6.116795359s

• [SLOW TEST:10.351 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:37:14.696: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-9pz75
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 12 04:37:14.864: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:37:16.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-9pz75" for this suite.
Jan 12 04:38:06.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:38:06.954: INFO: namespace: e2e-tests-pods-9pz75, resource: bindings, ignored listing per whitelist
Jan 12 04:38:07.022: INFO: namespace e2e-tests-pods-9pz75 deletion completed in 50.114620252s

• [SLOW TEST:52.326 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:38:07.022: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-4ngpf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0112 04:38:37.723769      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 12 04:38:37.723: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:38:37.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-4ngpf" for this suite.
Jan 12 04:38:43.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:38:43.811: INFO: namespace: e2e-tests-gc-4ngpf, resource: bindings, ignored listing per whitelist
Jan 12 04:38:43.817: INFO: namespace e2e-tests-gc-4ngpf deletion completed in 6.089837999s

• [SLOW TEST:36.795 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:38:43.817: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-xrz87
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Jan 12 04:38:48.003: INFO: Pod pod-hostip-f15135c3-1623-11e9-8fb7-aa4233c46d55 has hostIP: 192.168.1.41
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:38:48.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xrz87" for this suite.
Jan 12 04:39:10.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:39:10.058: INFO: namespace: e2e-tests-pods-xrz87, resource: bindings, ignored listing per whitelist
Jan 12 04:39:10.145: INFO: namespace e2e-tests-pods-xrz87 deletion completed in 22.135671548s

• [SLOW TEST:26.328 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:39:10.145: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-vzsxv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Jan 12 04:39:10.329: INFO: Waiting up to 5m0s for pod "var-expansion-0104c24b-1624-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-var-expansion-vzsxv" to be "success or failure"
Jan 12 04:39:10.343: INFO: Pod "var-expansion-0104c24b-1624-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 13.998837ms
Jan 12 04:39:12.346: INFO: Pod "var-expansion-0104c24b-1624-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017479198s
Jan 12 04:39:14.350: INFO: Pod "var-expansion-0104c24b-1624-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020606956s
STEP: Saw pod success
Jan 12 04:39:14.350: INFO: Pod "var-expansion-0104c24b-1624-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:39:14.352: INFO: Trying to get logs from node c76-1-41 pod var-expansion-0104c24b-1624-11e9-8fb7-aa4233c46d55 container dapi-container: <nil>
STEP: delete the pod
Jan 12 04:39:14.368: INFO: Waiting for pod var-expansion-0104c24b-1624-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:39:14.371: INFO: Pod var-expansion-0104c24b-1624-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:39:14.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-vzsxv" for this suite.
Jan 12 04:39:20.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:39:20.431: INFO: namespace: e2e-tests-var-expansion-vzsxv, resource: bindings, ignored listing per whitelist
Jan 12 04:39:20.476: INFO: namespace e2e-tests-var-expansion-vzsxv deletion completed in 6.102362305s

• [SLOW TEST:10.331 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:39:20.476: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-ncvgz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-072a9a0d-1624-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume configMaps
Jan 12 04:39:20.647: INFO: Waiting up to 5m0s for pod "pod-configmaps-072b2077-1624-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-configmap-ncvgz" to be "success or failure"
Jan 12 04:39:20.650: INFO: Pod "pod-configmaps-072b2077-1624-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 3.388221ms
Jan 12 04:39:22.658: INFO: Pod "pod-configmaps-072b2077-1624-11e9-8fb7-aa4233c46d55": Phase="Running", Reason="", readiness=true. Elapsed: 2.011184229s
Jan 12 04:39:24.663: INFO: Pod "pod-configmaps-072b2077-1624-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015505106s
STEP: Saw pod success
Jan 12 04:39:24.663: INFO: Pod "pod-configmaps-072b2077-1624-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:39:24.667: INFO: Trying to get logs from node c76-1-41 pod pod-configmaps-072b2077-1624-11e9-8fb7-aa4233c46d55 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 12 04:39:24.683: INFO: Waiting for pod pod-configmaps-072b2077-1624-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:39:24.685: INFO: Pod pod-configmaps-072b2077-1624-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:39:24.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ncvgz" for this suite.
Jan 12 04:39:30.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:39:30.778: INFO: namespace: e2e-tests-configmap-ncvgz, resource: bindings, ignored listing per whitelist
Jan 12 04:39:30.797: INFO: namespace e2e-tests-configmap-ncvgz deletion completed in 6.108596773s

• [SLOW TEST:10.321 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:39:30.797: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-runtime-cwcs5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:39:53.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-cwcs5" for this suite.
Jan 12 04:39:59.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:39:59.388: INFO: namespace: e2e-tests-container-runtime-cwcs5, resource: bindings, ignored listing per whitelist
Jan 12 04:39:59.432: INFO: namespace e2e-tests-container-runtime-cwcs5 deletion completed in 6.136063101s

• [SLOW TEST:28.635 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:39:59.432: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-52qsw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 12 04:39:59.593: INFO: Creating ReplicaSet my-hostname-basic-1e62cc8e-1624-11e9-8fb7-aa4233c46d55
Jan 12 04:39:59.599: INFO: Pod name my-hostname-basic-1e62cc8e-1624-11e9-8fb7-aa4233c46d55: Found 0 pods out of 1
Jan 12 04:40:04.604: INFO: Pod name my-hostname-basic-1e62cc8e-1624-11e9-8fb7-aa4233c46d55: Found 1 pods out of 1
Jan 12 04:40:04.604: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-1e62cc8e-1624-11e9-8fb7-aa4233c46d55" is running
Jan 12 04:40:04.607: INFO: Pod "my-hostname-basic-1e62cc8e-1624-11e9-8fb7-aa4233c46d55-5kc2c" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-12 04:39:59 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-12 04:40:01 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-12 04:40:01 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-12 04:39:59 +0000 UTC Reason: Message:}])
Jan 12 04:40:04.608: INFO: Trying to dial the pod
Jan 12 04:40:09.638: INFO: Controller my-hostname-basic-1e62cc8e-1624-11e9-8fb7-aa4233c46d55: Got expected result from replica 1 [my-hostname-basic-1e62cc8e-1624-11e9-8fb7-aa4233c46d55-5kc2c]: "my-hostname-basic-1e62cc8e-1624-11e9-8fb7-aa4233c46d55-5kc2c", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:40:09.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-52qsw" for this suite.
Jan 12 04:40:15.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:40:15.713: INFO: namespace: e2e-tests-replicaset-52qsw, resource: bindings, ignored listing per whitelist
Jan 12 04:40:15.739: INFO: namespace e2e-tests-replicaset-52qsw deletion completed in 6.09012175s

• [SLOW TEST:16.307 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:40:15.739: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-g984r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 12 04:40:15.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-g984r'
Jan 12 04:40:15.970: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan 12 04:40:15.970: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Jan 12 04:40:15.976: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Jan 12 04:40:15.985: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Jan 12 04:40:15.989: INFO: scanned /root for discovery docs: <nil>
Jan 12 04:40:15.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-g984r'
Jan 12 04:40:31.825: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan 12 04:40:31.826: INFO: stdout: "Created e2e-test-nginx-rc-83ac2555f1fb2489f3f86837f3680860\nScaling up e2e-test-nginx-rc-83ac2555f1fb2489f3f86837f3680860 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-83ac2555f1fb2489f3f86837f3680860 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-83ac2555f1fb2489f3f86837f3680860 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Jan 12 04:40:31.826: INFO: stdout: "Created e2e-test-nginx-rc-83ac2555f1fb2489f3f86837f3680860\nScaling up e2e-test-nginx-rc-83ac2555f1fb2489f3f86837f3680860 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-83ac2555f1fb2489f3f86837f3680860 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-83ac2555f1fb2489f3f86837f3680860 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Jan 12 04:40:31.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-g984r'
Jan 12 04:40:31.903: INFO: stderr: ""
Jan 12 04:40:31.903: INFO: stdout: "e2e-test-nginx-rc-83ac2555f1fb2489f3f86837f3680860-4c5dv e2e-test-nginx-rc-ldk8h "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Jan 12 04:40:36.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-g984r'
Jan 12 04:40:37.010: INFO: stderr: ""
Jan 12 04:40:37.010: INFO: stdout: "e2e-test-nginx-rc-83ac2555f1fb2489f3f86837f3680860-4c5dv "
Jan 12 04:40:37.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods e2e-test-nginx-rc-83ac2555f1fb2489f3f86837f3680860-4c5dv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g984r'
Jan 12 04:40:37.087: INFO: stderr: ""
Jan 12 04:40:37.087: INFO: stdout: "true"
Jan 12 04:40:37.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods e2e-test-nginx-rc-83ac2555f1fb2489f3f86837f3680860-4c5dv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g984r'
Jan 12 04:40:37.191: INFO: stderr: ""
Jan 12 04:40:37.191: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Jan 12 04:40:37.191: INFO: e2e-test-nginx-rc-83ac2555f1fb2489f3f86837f3680860-4c5dv is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Jan 12 04:40:37.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-g984r'
Jan 12 04:40:37.330: INFO: stderr: ""
Jan 12 04:40:37.330: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:40:37.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-g984r" for this suite.
Jan 12 04:40:59.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:40:59.420: INFO: namespace: e2e-tests-kubectl-g984r, resource: bindings, ignored listing per whitelist
Jan 12 04:40:59.454: INFO: namespace e2e-tests-kubectl-g984r deletion completed in 22.120624223s

• [SLOW TEST:43.715 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:40:59.454: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-z2698
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-z2698
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-z2698
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-z2698
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-z2698
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-z2698
Jan 12 04:41:03.664: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-z2698, name: ss-0, uid: 44383f53-1624-11e9-b7e1-000c294e6ffe, status phase: Failed. Waiting for statefulset controller to delete.
Jan 12 04:41:03.667: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-z2698, name: ss-0, uid: 44383f53-1624-11e9-b7e1-000c294e6ffe, status phase: Failed. Waiting for statefulset controller to delete.
Jan 12 04:41:03.694: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-z2698
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-z2698
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-z2698 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 12 04:41:07.753: INFO: Deleting all statefulset in ns e2e-tests-statefulset-z2698
Jan 12 04:41:07.761: INFO: Scaling statefulset ss to 0
Jan 12 04:41:17.786: INFO: Waiting for statefulset status.replicas updated to 0
Jan 12 04:41:17.790: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:41:17.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-z2698" for this suite.
Jan 12 04:41:23.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:41:23.886: INFO: namespace: e2e-tests-statefulset-z2698, resource: bindings, ignored listing per whitelist
Jan 12 04:41:23.923: INFO: namespace e2e-tests-statefulset-z2698 deletion completed in 6.10886879s

• [SLOW TEST:24.469 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:41:23.923: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-kxh77
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-50be490a-1624-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume configMaps
Jan 12 04:41:24.088: INFO: Waiting up to 5m0s for pod "pod-configmaps-50beb520-1624-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-configmap-kxh77" to be "success or failure"
Jan 12 04:41:24.091: INFO: Pod "pod-configmaps-50beb520-1624-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 3.186284ms
Jan 12 04:41:26.097: INFO: Pod "pod-configmaps-50beb520-1624-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008510462s
Jan 12 04:41:28.102: INFO: Pod "pod-configmaps-50beb520-1624-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013542983s
STEP: Saw pod success
Jan 12 04:41:28.102: INFO: Pod "pod-configmaps-50beb520-1624-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:41:28.106: INFO: Trying to get logs from node c76-1-41 pod pod-configmaps-50beb520-1624-11e9-8fb7-aa4233c46d55 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 12 04:41:28.145: INFO: Waiting for pod pod-configmaps-50beb520-1624-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:41:28.148: INFO: Pod pod-configmaps-50beb520-1624-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:41:28.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kxh77" for this suite.
Jan 12 04:41:34.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:41:34.209: INFO: namespace: e2e-tests-configmap-kxh77, resource: bindings, ignored listing per whitelist
Jan 12 04:41:34.257: INFO: namespace e2e-tests-configmap-kxh77 deletion completed in 6.10103119s

• [SLOW TEST:10.334 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:41:34.257: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-dqqwm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:41:36.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-dqqwm" for this suite.
Jan 12 04:42:26.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:42:26.586: INFO: namespace: e2e-tests-kubelet-test-dqqwm, resource: bindings, ignored listing per whitelist
Jan 12 04:42:26.594: INFO: namespace e2e-tests-kubelet-test-dqqwm deletion completed in 50.111522479s

• [SLOW TEST:52.338 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:42:26.595: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wqn6b
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan 12 04:42:26.779: INFO: Waiting up to 5m0s for pod "pod-761c1bb6-1624-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-emptydir-wqn6b" to be "success or failure"
Jan 12 04:42:26.783: INFO: Pod "pod-761c1bb6-1624-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 3.661922ms
Jan 12 04:42:28.789: INFO: Pod "pod-761c1bb6-1624-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009394394s
STEP: Saw pod success
Jan 12 04:42:28.789: INFO: Pod "pod-761c1bb6-1624-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:42:28.794: INFO: Trying to get logs from node c76-1-41 pod pod-761c1bb6-1624-11e9-8fb7-aa4233c46d55 container test-container: <nil>
STEP: delete the pod
Jan 12 04:42:28.827: INFO: Waiting for pod pod-761c1bb6-1624-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:42:28.830: INFO: Pod pod-761c1bb6-1624-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:42:28.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wqn6b" for this suite.
Jan 12 04:42:34.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:42:34.899: INFO: namespace: e2e-tests-emptydir-wqn6b, resource: bindings, ignored listing per whitelist
Jan 12 04:42:34.919: INFO: namespace e2e-tests-emptydir-wqn6b deletion completed in 6.08457633s

• [SLOW TEST:8.324 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:42:34.919: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-xdmb5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 12 04:42:35.134: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7b17763f-1624-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-projected-xdmb5" to be "success or failure"
Jan 12 04:42:35.137: INFO: Pod "downwardapi-volume-7b17763f-1624-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.741507ms
Jan 12 04:42:37.145: INFO: Pod "downwardapi-volume-7b17763f-1624-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011292848s
Jan 12 04:42:39.153: INFO: Pod "downwardapi-volume-7b17763f-1624-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019146204s
STEP: Saw pod success
Jan 12 04:42:39.153: INFO: Pod "downwardapi-volume-7b17763f-1624-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:42:39.160: INFO: Trying to get logs from node c76-1-41 pod downwardapi-volume-7b17763f-1624-11e9-8fb7-aa4233c46d55 container client-container: <nil>
STEP: delete the pod
Jan 12 04:42:39.204: INFO: Waiting for pod downwardapi-volume-7b17763f-1624-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:42:39.207: INFO: Pod downwardapi-volume-7b17763f-1624-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:42:39.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xdmb5" for this suite.
Jan 12 04:42:45.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:42:45.305: INFO: namespace: e2e-tests-projected-xdmb5, resource: bindings, ignored listing per whitelist
Jan 12 04:42:45.318: INFO: namespace e2e-tests-projected-xdmb5 deletion completed in 6.107324674s

• [SLOW TEST:10.398 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:42:45.318: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-257zv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 12 04:42:45.522: INFO: Waiting up to 5m0s for pod "downwardapi-volume-81487c7b-1624-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-projected-257zv" to be "success or failure"
Jan 12 04:42:45.524: INFO: Pod "downwardapi-volume-81487c7b-1624-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.289918ms
Jan 12 04:42:47.528: INFO: Pod "downwardapi-volume-81487c7b-1624-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005794497s
Jan 12 04:42:49.537: INFO: Pod "downwardapi-volume-81487c7b-1624-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015105536s
STEP: Saw pod success
Jan 12 04:42:49.537: INFO: Pod "downwardapi-volume-81487c7b-1624-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:42:49.541: INFO: Trying to get logs from node c76-1-41 pod downwardapi-volume-81487c7b-1624-11e9-8fb7-aa4233c46d55 container client-container: <nil>
STEP: delete the pod
Jan 12 04:42:49.571: INFO: Waiting for pod downwardapi-volume-81487c7b-1624-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:42:49.577: INFO: Pod downwardapi-volume-81487c7b-1624-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:42:49.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-257zv" for this suite.
Jan 12 04:42:55.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:42:55.646: INFO: namespace: e2e-tests-projected-257zv, resource: bindings, ignored listing per whitelist
Jan 12 04:42:55.666: INFO: namespace e2e-tests-projected-257zv deletion completed in 6.08507647s

• [SLOW TEST:10.349 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:42:55.667: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-l96v4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 12 04:42:55.848: INFO: Waiting up to 5m0s for pod "downwardapi-volume-876e0ce9-1624-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-downward-api-l96v4" to be "success or failure"
Jan 12 04:42:55.855: INFO: Pod "downwardapi-volume-876e0ce9-1624-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 6.885058ms
Jan 12 04:42:57.863: INFO: Pod "downwardapi-volume-876e0ce9-1624-11e9-8fb7-aa4233c46d55": Phase="Running", Reason="", readiness=true. Elapsed: 2.014968353s
Jan 12 04:42:59.867: INFO: Pod "downwardapi-volume-876e0ce9-1624-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018461217s
STEP: Saw pod success
Jan 12 04:42:59.867: INFO: Pod "downwardapi-volume-876e0ce9-1624-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:42:59.869: INFO: Trying to get logs from node c76-1-41 pod downwardapi-volume-876e0ce9-1624-11e9-8fb7-aa4233c46d55 container client-container: <nil>
STEP: delete the pod
Jan 12 04:42:59.883: INFO: Waiting for pod downwardapi-volume-876e0ce9-1624-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:42:59.885: INFO: Pod downwardapi-volume-876e0ce9-1624-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:42:59.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-l96v4" for this suite.
Jan 12 04:43:05.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:43:06.012: INFO: namespace: e2e-tests-downward-api-l96v4, resource: bindings, ignored listing per whitelist
Jan 12 04:43:06.018: INFO: namespace e2e-tests-downward-api-l96v4 deletion completed in 6.128627894s

• [SLOW TEST:10.351 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:43:06.018: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-vcdss
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jan 12 04:43:06.204: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-vcdss,SelfLink:/api/v1/namespaces/e2e-tests-watch-vcdss/configmaps/e2e-watch-test-configmap-a,UID:8d9c37d9-1624-11e9-b7e1-000c294e6ffe,ResourceVersion:136725,Generation:0,CreationTimestamp:2019-01-12 04:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 12 04:43:06.205: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-vcdss,SelfLink:/api/v1/namespaces/e2e-tests-watch-vcdss/configmaps/e2e-watch-test-configmap-a,UID:8d9c37d9-1624-11e9-b7e1-000c294e6ffe,ResourceVersion:136725,Generation:0,CreationTimestamp:2019-01-12 04:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jan 12 04:43:16.219: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-vcdss,SelfLink:/api/v1/namespaces/e2e-tests-watch-vcdss/configmaps/e2e-watch-test-configmap-a,UID:8d9c37d9-1624-11e9-b7e1-000c294e6ffe,ResourceVersion:136739,Generation:0,CreationTimestamp:2019-01-12 04:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan 12 04:43:16.220: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-vcdss,SelfLink:/api/v1/namespaces/e2e-tests-watch-vcdss/configmaps/e2e-watch-test-configmap-a,UID:8d9c37d9-1624-11e9-b7e1-000c294e6ffe,ResourceVersion:136739,Generation:0,CreationTimestamp:2019-01-12 04:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jan 12 04:43:26.231: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-vcdss,SelfLink:/api/v1/namespaces/e2e-tests-watch-vcdss/configmaps/e2e-watch-test-configmap-a,UID:8d9c37d9-1624-11e9-b7e1-000c294e6ffe,ResourceVersion:136753,Generation:0,CreationTimestamp:2019-01-12 04:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 12 04:43:26.231: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-vcdss,SelfLink:/api/v1/namespaces/e2e-tests-watch-vcdss/configmaps/e2e-watch-test-configmap-a,UID:8d9c37d9-1624-11e9-b7e1-000c294e6ffe,ResourceVersion:136753,Generation:0,CreationTimestamp:2019-01-12 04:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jan 12 04:43:36.246: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-vcdss,SelfLink:/api/v1/namespaces/e2e-tests-watch-vcdss/configmaps/e2e-watch-test-configmap-a,UID:8d9c37d9-1624-11e9-b7e1-000c294e6ffe,ResourceVersion:136767,Generation:0,CreationTimestamp:2019-01-12 04:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 12 04:43:36.246: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-vcdss,SelfLink:/api/v1/namespaces/e2e-tests-watch-vcdss/configmaps/e2e-watch-test-configmap-a,UID:8d9c37d9-1624-11e9-b7e1-000c294e6ffe,ResourceVersion:136767,Generation:0,CreationTimestamp:2019-01-12 04:43:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jan 12 04:43:46.265: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-vcdss,SelfLink:/api/v1/namespaces/e2e-tests-watch-vcdss/configmaps/e2e-watch-test-configmap-b,UID:a57b48b4-1624-11e9-b7e1-000c294e6ffe,ResourceVersion:136820,Generation:0,CreationTimestamp:2019-01-12 04:43:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 12 04:43:46.265: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-vcdss,SelfLink:/api/v1/namespaces/e2e-tests-watch-vcdss/configmaps/e2e-watch-test-configmap-b,UID:a57b48b4-1624-11e9-b7e1-000c294e6ffe,ResourceVersion:136820,Generation:0,CreationTimestamp:2019-01-12 04:43:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jan 12 04:43:56.270: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-vcdss,SelfLink:/api/v1/namespaces/e2e-tests-watch-vcdss/configmaps/e2e-watch-test-configmap-b,UID:a57b48b4-1624-11e9-b7e1-000c294e6ffe,ResourceVersion:136834,Generation:0,CreationTimestamp:2019-01-12 04:43:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 12 04:43:56.270: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-vcdss,SelfLink:/api/v1/namespaces/e2e-tests-watch-vcdss/configmaps/e2e-watch-test-configmap-b,UID:a57b48b4-1624-11e9-b7e1-000c294e6ffe,ResourceVersion:136834,Generation:0,CreationTimestamp:2019-01-12 04:43:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:44:06.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-vcdss" for this suite.
Jan 12 04:44:12.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:44:12.357: INFO: namespace: e2e-tests-watch-vcdss, resource: bindings, ignored listing per whitelist
Jan 12 04:44:12.391: INFO: namespace e2e-tests-watch-vcdss deletion completed in 6.115851277s

• [SLOW TEST:66.373 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:44:12.391: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-jwkj5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:44:12.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-jwkj5" for this suite.
Jan 12 04:44:18.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:44:18.661: INFO: namespace: e2e-tests-services-jwkj5, resource: bindings, ignored listing per whitelist
Jan 12 04:44:18.667: INFO: namespace e2e-tests-services-jwkj5 deletion completed in 6.109358763s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.276 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:44:18.667: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-9fpmd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 12 04:44:21.409: INFO: Successfully updated pod "annotationupdateb8e6c6b7-1624-11e9-8fb7-aa4233c46d55"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:44:23.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9fpmd" for this suite.
Jan 12 04:44:45.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:44:45.547: INFO: namespace: e2e-tests-downward-api-9fpmd, resource: bindings, ignored listing per whitelist
Jan 12 04:44:45.610: INFO: namespace e2e-tests-downward-api-9fpmd deletion completed in 22.114363803s

• [SLOW TEST:26.943 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:44:45.610: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-sflzs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0112 04:45:25.803093      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 12 04:45:25.803: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:45:25.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-sflzs" for this suite.
Jan 12 04:45:31.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:45:31.859: INFO: namespace: e2e-tests-gc-sflzs, resource: bindings, ignored listing per whitelist
Jan 12 04:45:32.187: INFO: namespace e2e-tests-gc-sflzs deletion completed in 6.378543403s

• [SLOW TEST:46.577 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:45:32.187: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-skdfs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:45:32.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-skdfs" for this suite.
Jan 12 04:45:38.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:45:38.768: INFO: namespace: e2e-tests-kubelet-test-skdfs, resource: bindings, ignored listing per whitelist
Jan 12 04:45:38.787: INFO: namespace e2e-tests-kubelet-test-skdfs deletion completed in 6.130424475s

• [SLOW TEST:6.600 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:45:38.787: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-9zqwk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 12 04:45:38.979: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e8aa946d-1624-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-projected-9zqwk" to be "success or failure"
Jan 12 04:45:38.988: INFO: Pod "downwardapi-volume-e8aa946d-1624-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 8.432605ms
Jan 12 04:45:40.998: INFO: Pod "downwardapi-volume-e8aa946d-1624-11e9-8fb7-aa4233c46d55": Phase="Running", Reason="", readiness=true. Elapsed: 2.018729324s
Jan 12 04:45:43.004: INFO: Pod "downwardapi-volume-e8aa946d-1624-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024302686s
STEP: Saw pod success
Jan 12 04:45:43.004: INFO: Pod "downwardapi-volume-e8aa946d-1624-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:45:43.008: INFO: Trying to get logs from node c76-1-41 pod downwardapi-volume-e8aa946d-1624-11e9-8fb7-aa4233c46d55 container client-container: <nil>
STEP: delete the pod
Jan 12 04:45:43.046: INFO: Waiting for pod downwardapi-volume-e8aa946d-1624-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:45:43.049: INFO: Pod downwardapi-volume-e8aa946d-1624-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:45:43.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9zqwk" for this suite.
Jan 12 04:45:49.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:45:49.145: INFO: namespace: e2e-tests-projected-9zqwk, resource: bindings, ignored listing per whitelist
Jan 12 04:45:49.150: INFO: namespace e2e-tests-projected-9zqwk deletion completed in 6.098449668s

• [SLOW TEST:10.363 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:45:49.150: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-r5h2s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 12 04:45:49.360: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eedbe733-1624-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-downward-api-r5h2s" to be "success or failure"
Jan 12 04:45:49.363: INFO: Pod "downwardapi-volume-eedbe733-1624-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 3.306123ms
Jan 12 04:45:51.372: INFO: Pod "downwardapi-volume-eedbe733-1624-11e9-8fb7-aa4233c46d55": Phase="Running", Reason="", readiness=true. Elapsed: 2.01223004s
Jan 12 04:45:53.381: INFO: Pod "downwardapi-volume-eedbe733-1624-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020748038s
STEP: Saw pod success
Jan 12 04:45:53.381: INFO: Pod "downwardapi-volume-eedbe733-1624-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:45:53.387: INFO: Trying to get logs from node c76-1-41 pod downwardapi-volume-eedbe733-1624-11e9-8fb7-aa4233c46d55 container client-container: <nil>
STEP: delete the pod
Jan 12 04:45:53.420: INFO: Waiting for pod downwardapi-volume-eedbe733-1624-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:45:53.424: INFO: Pod downwardapi-volume-eedbe733-1624-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:45:53.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-r5h2s" for this suite.
Jan 12 04:45:59.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:45:59.502: INFO: namespace: e2e-tests-downward-api-r5h2s, resource: bindings, ignored listing per whitelist
Jan 12 04:45:59.550: INFO: namespace e2e-tests-downward-api-r5h2s deletion completed in 6.110446929s

• [SLOW TEST:10.399 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:45:59.550: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-ftwdw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 12 04:45:59.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 version --client'
Jan 12 04:45:59.774: INFO: stderr: ""
Jan 12 04:45:59.774: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Jan 12 04:45:59.775: INFO: Not supported for server versions before "1.13.0"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:45:59.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ftwdw" for this suite.
Jan 12 04:46:05.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:46:05.874: INFO: namespace: e2e-tests-kubectl-ftwdw, resource: bindings, ignored listing per whitelist
Jan 12 04:46:05.881: INFO: namespace e2e-tests-kubectl-ftwdw deletion completed in 6.101354394s

S [SKIPPING] [6.332 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance] [It]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

    Jan 12 04:45:59.775: Not supported for server versions before "1.13.0"

    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:46:05.882: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-r8t7s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:46:06.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-r8t7s" for this suite.
Jan 12 04:46:28.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:46:28.155: INFO: namespace: e2e-tests-pods-r8t7s, resource: bindings, ignored listing per whitelist
Jan 12 04:46:28.194: INFO: namespace e2e-tests-pods-r8t7s deletion completed in 22.109262842s

• [SLOW TEST:22.312 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:46:28.194: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-s75x7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-s75x7
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 12 04:46:28.357: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 12 04:46:48.463: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.31.52.69:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-s75x7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 12 04:46:48.463: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
Jan 12 04:46:48.564: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:46:48.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-s75x7" for this suite.
Jan 12 04:47:10.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:47:10.608: INFO: namespace: e2e-tests-pod-network-test-s75x7, resource: bindings, ignored listing per whitelist
Jan 12 04:47:10.673: INFO: namespace e2e-tests-pod-network-test-s75x7 deletion completed in 22.105359287s

• [SLOW TEST:42.479 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:47:10.673: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-65rxc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-65rxc/configmap-test-1f6cd649-1625-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume configMaps
Jan 12 04:47:10.847: INFO: Waiting up to 5m0s for pod "pod-configmaps-1f6d7eb2-1625-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-configmap-65rxc" to be "success or failure"
Jan 12 04:47:10.851: INFO: Pod "pod-configmaps-1f6d7eb2-1625-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 3.952848ms
Jan 12 04:47:12.854: INFO: Pod "pod-configmaps-1f6d7eb2-1625-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007300883s
STEP: Saw pod success
Jan 12 04:47:12.854: INFO: Pod "pod-configmaps-1f6d7eb2-1625-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:47:12.856: INFO: Trying to get logs from node c76-1-41 pod pod-configmaps-1f6d7eb2-1625-11e9-8fb7-aa4233c46d55 container env-test: <nil>
STEP: delete the pod
Jan 12 04:47:12.903: INFO: Waiting for pod pod-configmaps-1f6d7eb2-1625-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:47:12.905: INFO: Pod pod-configmaps-1f6d7eb2-1625-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:47:12.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-65rxc" for this suite.
Jan 12 04:47:18.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:47:18.994: INFO: namespace: e2e-tests-configmap-65rxc, resource: bindings, ignored listing per whitelist
Jan 12 04:47:19.006: INFO: namespace e2e-tests-configmap-65rxc deletion completed in 6.097904797s

• [SLOW TEST:8.334 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:47:19.006: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-bwzd2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan 12 04:47:19.213: INFO: Waiting up to 5m0s for pod "pod-2469015d-1625-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-emptydir-bwzd2" to be "success or failure"
Jan 12 04:47:19.219: INFO: Pod "pod-2469015d-1625-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 5.964954ms
Jan 12 04:47:21.223: INFO: Pod "pod-2469015d-1625-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009680525s
STEP: Saw pod success
Jan 12 04:47:21.223: INFO: Pod "pod-2469015d-1625-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:47:21.226: INFO: Trying to get logs from node c76-1-41 pod pod-2469015d-1625-11e9-8fb7-aa4233c46d55 container test-container: <nil>
STEP: delete the pod
Jan 12 04:47:21.243: INFO: Waiting for pod pod-2469015d-1625-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:47:21.245: INFO: Pod pod-2469015d-1625-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:47:21.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bwzd2" for this suite.
Jan 12 04:47:27.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:47:27.338: INFO: namespace: e2e-tests-emptydir-bwzd2, resource: bindings, ignored listing per whitelist
Jan 12 04:47:27.357: INFO: namespace e2e-tests-emptydir-bwzd2 deletion completed in 6.107299119s

• [SLOW TEST:8.350 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:47:27.357: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-cm2tg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-295ff23b-1625-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume secrets
Jan 12 04:47:27.536: INFO: Waiting up to 5m0s for pod "pod-secrets-29607f72-1625-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-secrets-cm2tg" to be "success or failure"
Jan 12 04:47:27.538: INFO: Pod "pod-secrets-29607f72-1625-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.388132ms
Jan 12 04:47:29.543: INFO: Pod "pod-secrets-29607f72-1625-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007364451s
STEP: Saw pod success
Jan 12 04:47:29.543: INFO: Pod "pod-secrets-29607f72-1625-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:47:29.547: INFO: Trying to get logs from node c76-1-41 pod pod-secrets-29607f72-1625-11e9-8fb7-aa4233c46d55 container secret-volume-test: <nil>
STEP: delete the pod
Jan 12 04:47:29.576: INFO: Waiting for pod pod-secrets-29607f72-1625-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:47:29.579: INFO: Pod pod-secrets-29607f72-1625-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:47:29.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-cm2tg" for this suite.
Jan 12 04:47:35.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:47:35.620: INFO: namespace: e2e-tests-secrets-cm2tg, resource: bindings, ignored listing per whitelist
Jan 12 04:47:35.672: INFO: namespace e2e-tests-secrets-cm2tg deletion completed in 6.090260806s

• [SLOW TEST:8.315 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:47:35.672: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-gtj4v
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 12 04:47:55.852: INFO: Container started at 2019-01-12 04:47:37 +0000 UTC, pod became ready at 2019-01-12 04:47:54 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:47:55.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-gtj4v" for this suite.
Jan 12 04:48:17.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:48:17.934: INFO: namespace: e2e-tests-container-probe-gtj4v, resource: bindings, ignored listing per whitelist
Jan 12 04:48:17.976: INFO: namespace e2e-tests-container-probe-gtj4v deletion completed in 22.114427665s

• [SLOW TEST:42.304 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:48:17.976: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-p426j
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 12 04:48:18.144: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:48:19.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-p426j" for this suite.
Jan 12 04:48:25.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:48:25.342: INFO: namespace: e2e-tests-custom-resource-definition-p426j, resource: bindings, ignored listing per whitelist
Jan 12 04:48:25.363: INFO: namespace e2e-tests-custom-resource-definition-p426j deletion completed in 6.152823421s

• [SLOW TEST:7.387 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:48:25.363: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-sc6zn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Jan 12 04:48:25.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 --namespace=e2e-tests-kubectl-sc6zn run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Jan 12 04:48:27.788: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Jan 12 04:48:27.789: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:48:29.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sc6zn" for this suite.
Jan 12 04:48:35.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:48:35.871: INFO: namespace: e2e-tests-kubectl-sc6zn, resource: bindings, ignored listing per whitelist
Jan 12 04:48:35.901: INFO: namespace e2e-tests-kubectl-sc6zn deletion completed in 6.105001225s

• [SLOW TEST:10.538 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:48:35.901: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-tvvj5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 12 04:48:36.069: INFO: Waiting up to 5m0s for pod "downward-api-5239bf10-1625-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-downward-api-tvvj5" to be "success or failure"
Jan 12 04:48:36.072: INFO: Pod "downward-api-5239bf10-1625-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.74721ms
Jan 12 04:48:38.076: INFO: Pod "downward-api-5239bf10-1625-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006192421s
STEP: Saw pod success
Jan 12 04:48:38.076: INFO: Pod "downward-api-5239bf10-1625-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:48:38.078: INFO: Trying to get logs from node c76-1-41 pod downward-api-5239bf10-1625-11e9-8fb7-aa4233c46d55 container dapi-container: <nil>
STEP: delete the pod
Jan 12 04:48:38.096: INFO: Waiting for pod downward-api-5239bf10-1625-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:48:38.099: INFO: Pod downward-api-5239bf10-1625-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:48:38.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tvvj5" for this suite.
Jan 12 04:48:44.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:48:44.217: INFO: namespace: e2e-tests-downward-api-tvvj5, resource: bindings, ignored listing per whitelist
Jan 12 04:48:44.234: INFO: namespace e2e-tests-downward-api-tvvj5 deletion completed in 6.124604722s

• [SLOW TEST:8.333 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:48:44.234: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-4mgv4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 12 04:48:44.412: INFO: Waiting up to 5m0s for pod "downward-api-5731e254-1625-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-downward-api-4mgv4" to be "success or failure"
Jan 12 04:48:44.429: INFO: Pod "downward-api-5731e254-1625-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 16.929168ms
Jan 12 04:48:46.433: INFO: Pod "downward-api-5731e254-1625-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020340591s
STEP: Saw pod success
Jan 12 04:48:46.433: INFO: Pod "downward-api-5731e254-1625-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:48:46.435: INFO: Trying to get logs from node c76-1-41 pod downward-api-5731e254-1625-11e9-8fb7-aa4233c46d55 container dapi-container: <nil>
STEP: delete the pod
Jan 12 04:48:46.458: INFO: Waiting for pod downward-api-5731e254-1625-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:48:46.461: INFO: Pod downward-api-5731e254-1625-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:48:46.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4mgv4" for this suite.
Jan 12 04:48:52.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:48:52.531: INFO: namespace: e2e-tests-downward-api-4mgv4, resource: bindings, ignored listing per whitelist
Jan 12 04:48:52.561: INFO: namespace e2e-tests-downward-api-4mgv4 deletion completed in 6.094160607s

• [SLOW TEST:8.326 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:48:52.561: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-zls9c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jan 12 04:48:52.742: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-zls9c,SelfLink:/api/v1/namespaces/e2e-tests-watch-zls9c/configmaps/e2e-watch-test-resource-version,UID:5c270488-1625-11e9-b7e1-000c294e6ffe,ResourceVersion:138105,Generation:0,CreationTimestamp:2019-01-12 04:48:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 12 04:48:52.742: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-zls9c,SelfLink:/api/v1/namespaces/e2e-tests-watch-zls9c/configmaps/e2e-watch-test-resource-version,UID:5c270488-1625-11e9-b7e1-000c294e6ffe,ResourceVersion:138106,Generation:0,CreationTimestamp:2019-01-12 04:48:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:48:52.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-zls9c" for this suite.
Jan 12 04:48:58.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:48:58.838: INFO: namespace: e2e-tests-watch-zls9c, resource: bindings, ignored listing per whitelist
Jan 12 04:48:58.875: INFO: namespace e2e-tests-watch-zls9c deletion completed in 6.129265532s

• [SLOW TEST:6.314 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:48:58.875: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-f8rwn
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-5fec3437-1625-11e9-8fb7-aa4233c46d55
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-5fec3437-1625-11e9-8fb7-aa4233c46d55
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:50:07.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-f8rwn" for this suite.
Jan 12 04:50:29.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:50:29.796: INFO: namespace: e2e-tests-configmap-f8rwn, resource: bindings, ignored listing per whitelist
Jan 12 04:50:29.825: INFO: namespace e2e-tests-configmap-f8rwn deletion completed in 22.103463601s

• [SLOW TEST:90.950 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:50:29.825: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-mslz7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jan 12 04:50:29.986: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 12 04:50:29.994: INFO: Waiting for terminating namespaces to be deleted...
Jan 12 04:50:29.997: INFO: 
Logging pods the kubelet thinks is on node c76-1-41 before test
Jan 12 04:50:30.002: INFO: kubectl-cp4p5 from kube-system started at 2019-01-11 10:32:24 +0000 UTC (1 container statuses recorded)
Jan 12 04:50:30.002: INFO: 	Container kubectl ready: true, restart count 2
Jan 12 04:50:30.002: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-12 04:12:07 +0000 UTC (3 container statuses recorded)
Jan 12 04:50:30.002: INFO: 	Container cleanup ready: true, restart count 0
Jan 12 04:50:30.002: INFO: 	Container forwarder ready: true, restart count 0
Jan 12 04:50:30.002: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 12 04:50:30.002: INFO: sonobuoy-e2e-job-f2515c1fd49f447c from heptio-sonobuoy started at 2019-01-12 04:12:09 +0000 UTC (2 container statuses recorded)
Jan 12 04:50:30.002: INFO: 	Container e2e ready: true, restart count 0
Jan 12 04:50:30.002: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 12 04:50:30.002: INFO: kube-proxy-k8t9z from kube-system started at 2019-01-11 10:32:24 +0000 UTC (1 container statuses recorded)
Jan 12 04:50:30.002: INFO: 	Container kube-proxy ready: true, restart count 2
Jan 12 04:50:30.002: INFO: kube-controller-6dd888b6-2gdzh from kube-system started at 2019-01-12 01:48:43 +0000 UTC (1 container statuses recorded)
Jan 12 04:50:30.002: INFO: 	Container kube-controller ready: true, restart count 0
Jan 12 04:50:30.002: INFO: calico-node-47p2l from kube-system started at 2019-01-11 10:32:24 +0000 UTC (1 container statuses recorded)
Jan 12 04:50:30.002: INFO: 	Container calico-node ready: true, restart count 2
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-975c6e2b-1625-11e9-8fb7-aa4233c46d55 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-975c6e2b-1625-11e9-8fb7-aa4233c46d55 off the node c76-1-41
STEP: verifying the node doesn't have the label kubernetes.io/e2e-975c6e2b-1625-11e9-8fb7-aa4233c46d55
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:50:34.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-mslz7" for this suite.
Jan 12 04:50:44.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:50:44.241: INFO: namespace: e2e-tests-sched-pred-mslz7, resource: bindings, ignored listing per whitelist
Jan 12 04:50:44.243: INFO: namespace e2e-tests-sched-pred-mslz7 deletion completed in 10.104915561s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:14.418 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:50:44.243: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rdq9w
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-9eb9e477-1625-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume secrets
Jan 12 04:50:44.454: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9ebaaa7f-1625-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-projected-rdq9w" to be "success or failure"
Jan 12 04:50:44.458: INFO: Pod "pod-projected-secrets-9ebaaa7f-1625-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 3.41779ms
Jan 12 04:50:46.466: INFO: Pod "pod-projected-secrets-9ebaaa7f-1625-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011557518s
Jan 12 04:50:48.470: INFO: Pod "pod-projected-secrets-9ebaaa7f-1625-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015557322s
STEP: Saw pod success
Jan 12 04:50:48.470: INFO: Pod "pod-projected-secrets-9ebaaa7f-1625-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:50:48.473: INFO: Trying to get logs from node c76-1-41 pod pod-projected-secrets-9ebaaa7f-1625-11e9-8fb7-aa4233c46d55 container secret-volume-test: <nil>
STEP: delete the pod
Jan 12 04:50:48.500: INFO: Waiting for pod pod-projected-secrets-9ebaaa7f-1625-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:50:48.506: INFO: Pod pod-projected-secrets-9ebaaa7f-1625-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:50:48.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rdq9w" for this suite.
Jan 12 04:50:54.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:50:54.600: INFO: namespace: e2e-tests-projected-rdq9w, resource: bindings, ignored listing per whitelist
Jan 12 04:50:54.602: INFO: namespace e2e-tests-projected-rdq9w deletion completed in 6.090730818s

• [SLOW TEST:10.359 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:50:54.602: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-gq9w5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-gq9w5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-gq9w5 to expose endpoints map[]
Jan 12 04:50:54.807: INFO: Get endpoints failed (3.975499ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Jan 12 04:50:55.814: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-gq9w5 exposes endpoints map[] (1.010947707s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-gq9w5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-gq9w5 to expose endpoints map[pod1:[100]]
Jan 12 04:50:58.889: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-gq9w5 exposes endpoints map[pod1:[100]] (3.059367884s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-gq9w5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-gq9w5 to expose endpoints map[pod1:[100] pod2:[101]]
Jan 12 04:51:00.941: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-gq9w5 exposes endpoints map[pod1:[100] pod2:[101]] (2.041560779s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-gq9w5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-gq9w5 to expose endpoints map[pod2:[101]]
Jan 12 04:51:01.971: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-gq9w5 exposes endpoints map[pod2:[101]] (1.021912775s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-gq9w5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-gq9w5 to expose endpoints map[]
Jan 12 04:51:01.982: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-gq9w5 exposes endpoints map[] (5.678121ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:51:02.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-gq9w5" for this suite.
Jan 12 04:51:30.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:51:30.138: INFO: namespace: e2e-tests-services-gq9w5, resource: bindings, ignored listing per whitelist
Jan 12 04:51:30.160: INFO: namespace e2e-tests-services-gq9w5 deletion completed in 28.156165739s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:35.558 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:51:30.160: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-mgz44
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:51:32.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-mgz44" for this suite.
Jan 12 04:51:38.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:51:38.465: INFO: namespace: e2e-tests-emptydir-wrapper-mgz44, resource: bindings, ignored listing per whitelist
Jan 12 04:51:38.479: INFO: namespace e2e-tests-emptydir-wrapper-mgz44 deletion completed in 6.098388799s

• [SLOW TEST:8.319 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:51:38.480: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-ds6vg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Jan 12 04:51:38.633: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-921671513 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:51:38.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ds6vg" for this suite.
Jan 12 04:51:44.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:51:44.736: INFO: namespace: e2e-tests-kubectl-ds6vg, resource: bindings, ignored listing per whitelist
Jan 12 04:51:44.810: INFO: namespace e2e-tests-kubectl-ds6vg deletion completed in 6.117731969s

• [SLOW TEST:6.331 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:51:44.810: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-4gb24
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan 12 04:51:45.020: INFO: Waiting up to 5m0s for pod "pod-c2d94387-1625-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-emptydir-4gb24" to be "success or failure"
Jan 12 04:51:45.026: INFO: Pod "pod-c2d94387-1625-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 5.566708ms
Jan 12 04:51:47.029: INFO: Pod "pod-c2d94387-1625-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009077947s
STEP: Saw pod success
Jan 12 04:51:47.029: INFO: Pod "pod-c2d94387-1625-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:51:47.032: INFO: Trying to get logs from node c76-1-41 pod pod-c2d94387-1625-11e9-8fb7-aa4233c46d55 container test-container: <nil>
STEP: delete the pod
Jan 12 04:51:47.049: INFO: Waiting for pod pod-c2d94387-1625-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:51:47.052: INFO: Pod pod-c2d94387-1625-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:51:47.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4gb24" for this suite.
Jan 12 04:51:53.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:51:53.150: INFO: namespace: e2e-tests-emptydir-4gb24, resource: bindings, ignored listing per whitelist
Jan 12 04:51:53.171: INFO: namespace e2e-tests-emptydir-4gb24 deletion completed in 6.113603839s

• [SLOW TEST:8.361 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:51:53.171: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-lrb4k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan 12 04:51:55.868: INFO: Successfully updated pod "pod-update-activedeadlineseconds-c7cdfb6c-1625-11e9-8fb7-aa4233c46d55"
Jan 12 04:51:55.868: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-c7cdfb6c-1625-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-pods-lrb4k" to be "terminated due to deadline exceeded"
Jan 12 04:51:55.871: INFO: Pod "pod-update-activedeadlineseconds-c7cdfb6c-1625-11e9-8fb7-aa4233c46d55": Phase="Running", Reason="", readiness=true. Elapsed: 3.228361ms
Jan 12 04:51:57.875: INFO: Pod "pod-update-activedeadlineseconds-c7cdfb6c-1625-11e9-8fb7-aa4233c46d55": Phase="Running", Reason="", readiness=true. Elapsed: 2.006879868s
Jan 12 04:51:59.879: INFO: Pod "pod-update-activedeadlineseconds-c7cdfb6c-1625-11e9-8fb7-aa4233c46d55": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.010923901s
Jan 12 04:51:59.879: INFO: Pod "pod-update-activedeadlineseconds-c7cdfb6c-1625-11e9-8fb7-aa4233c46d55" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:51:59.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-lrb4k" for this suite.
Jan 12 04:52:05.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:52:05.919: INFO: namespace: e2e-tests-pods-lrb4k, resource: bindings, ignored listing per whitelist
Jan 12 04:52:05.982: INFO: namespace e2e-tests-pods-lrb4k deletion completed in 6.098481588s

• [SLOW TEST:12.812 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:52:05.983: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-rfwjq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Jan 12 04:52:06.156: INFO: Waiting up to 5m0s for pod "client-containers-cf71dfc8-1625-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-containers-rfwjq" to be "success or failure"
Jan 12 04:52:06.169: INFO: Pod "client-containers-cf71dfc8-1625-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 13.638364ms
Jan 12 04:52:08.175: INFO: Pod "client-containers-cf71dfc8-1625-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018774567s
Jan 12 04:52:10.178: INFO: Pod "client-containers-cf71dfc8-1625-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022693405s
STEP: Saw pod success
Jan 12 04:52:10.179: INFO: Pod "client-containers-cf71dfc8-1625-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:52:10.181: INFO: Trying to get logs from node c76-1-41 pod client-containers-cf71dfc8-1625-11e9-8fb7-aa4233c46d55 container test-container: <nil>
STEP: delete the pod
Jan 12 04:52:10.210: INFO: Waiting for pod client-containers-cf71dfc8-1625-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:52:10.212: INFO: Pod client-containers-cf71dfc8-1625-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:52:10.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-rfwjq" for this suite.
Jan 12 04:52:16.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:52:16.279: INFO: namespace: e2e-tests-containers-rfwjq, resource: bindings, ignored listing per whitelist
Jan 12 04:52:16.297: INFO: namespace e2e-tests-containers-rfwjq deletion completed in 6.081528286s

• [SLOW TEST:10.314 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:52:16.297: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-mhhkc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-mhhkc
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-mhhkc
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-mhhkc
Jan 12 04:52:16.493: INFO: Found 0 stateful pods, waiting for 1
Jan 12 04:52:26.502: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jan 12 04:52:26.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 exec --namespace=e2e-tests-statefulset-mhhkc ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 12 04:52:26.698: INFO: stderr: ""
Jan 12 04:52:26.698: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 12 04:52:26.698: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 12 04:52:26.701: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan 12 04:52:36.706: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 12 04:52:36.706: INFO: Waiting for statefulset status.replicas updated to 0
Jan 12 04:52:36.735: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Jan 12 04:52:36.735: INFO: ss-0  c76-1-41  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:16 +0000 UTC  }]
Jan 12 04:52:36.735: INFO: ss-1            Pending         []
Jan 12 04:52:36.735: INFO: 
Jan 12 04:52:36.735: INFO: StatefulSet ss has not reached scale 3, at 2
Jan 12 04:52:37.738: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.990302337s
Jan 12 04:52:38.743: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.986020333s
Jan 12 04:52:39.747: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.982018716s
Jan 12 04:52:40.760: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.97807614s
Jan 12 04:52:41.764: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.965184381s
Jan 12 04:52:42.778: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.960694488s
Jan 12 04:52:43.782: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.946669037s
Jan 12 04:52:44.787: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.941931163s
Jan 12 04:52:45.793: INFO: Verifying statefulset ss doesn't scale past 3 for another 937.513027ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-mhhkc
Jan 12 04:52:46.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 exec --namespace=e2e-tests-statefulset-mhhkc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 12 04:52:46.983: INFO: stderr: ""
Jan 12 04:52:46.983: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 12 04:52:46.983: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 12 04:52:46.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 exec --namespace=e2e-tests-statefulset-mhhkc ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 12 04:52:47.145: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jan 12 04:52:47.145: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 12 04:52:47.145: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 12 04:52:47.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 exec --namespace=e2e-tests-statefulset-mhhkc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 12 04:52:47.273: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jan 12 04:52:47.273: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 12 04:52:47.273: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 12 04:52:47.276: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Jan 12 04:52:57.280: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 12 04:52:57.280: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 12 04:52:57.280: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jan 12 04:52:57.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 exec --namespace=e2e-tests-statefulset-mhhkc ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 12 04:52:57.439: INFO: stderr: ""
Jan 12 04:52:57.439: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 12 04:52:57.439: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 12 04:52:57.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 exec --namespace=e2e-tests-statefulset-mhhkc ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 12 04:52:57.591: INFO: stderr: ""
Jan 12 04:52:57.591: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 12 04:52:57.592: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 12 04:52:57.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 exec --namespace=e2e-tests-statefulset-mhhkc ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 12 04:52:58.033: INFO: stderr: ""
Jan 12 04:52:58.033: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 12 04:52:58.033: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 12 04:52:58.033: INFO: Waiting for statefulset status.replicas updated to 0
Jan 12 04:52:58.035: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Jan 12 04:53:08.042: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 12 04:53:08.042: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 12 04:53:08.042: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 12 04:53:08.056: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Jan 12 04:53:08.056: INFO: ss-0  c76-1-41  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:16 +0000 UTC  }]
Jan 12 04:53:08.056: INFO: ss-1  c76-1-41  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:36 +0000 UTC  }]
Jan 12 04:53:08.056: INFO: ss-2  c76-1-41  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:36 +0000 UTC  }]
Jan 12 04:53:08.056: INFO: 
Jan 12 04:53:08.056: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 12 04:53:09.062: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Jan 12 04:53:09.062: INFO: ss-0  c76-1-41  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:16 +0000 UTC  }]
Jan 12 04:53:09.062: INFO: ss-1  c76-1-41  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:36 +0000 UTC  }]
Jan 12 04:53:09.062: INFO: ss-2  c76-1-41  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:36 +0000 UTC  }]
Jan 12 04:53:09.062: INFO: 
Jan 12 04:53:09.062: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 12 04:53:10.068: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Jan 12 04:53:10.068: INFO: ss-0  c76-1-41  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:16 +0000 UTC  }]
Jan 12 04:53:10.068: INFO: 
Jan 12 04:53:10.068: INFO: StatefulSet ss has not reached scale 0, at 1
Jan 12 04:53:11.073: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Jan 12 04:53:11.073: INFO: ss-0  c76-1-41  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:16 +0000 UTC  }]
Jan 12 04:53:11.073: INFO: 
Jan 12 04:53:11.073: INFO: StatefulSet ss has not reached scale 0, at 1
Jan 12 04:53:12.084: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Jan 12 04:53:12.084: INFO: ss-0  c76-1-41  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:16 +0000 UTC  }]
Jan 12 04:53:12.084: INFO: 
Jan 12 04:53:12.084: INFO: StatefulSet ss has not reached scale 0, at 1
Jan 12 04:53:13.089: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Jan 12 04:53:13.089: INFO: ss-0  c76-1-41  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:52:16 +0000 UTC  }]
Jan 12 04:53:13.089: INFO: 
Jan 12 04:53:13.089: INFO: StatefulSet ss has not reached scale 0, at 1
Jan 12 04:53:14.094: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.958273758s
Jan 12 04:53:15.104: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.952116168s
Jan 12 04:53:16.107: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.944099538s
Jan 12 04:53:17.111: INFO: Verifying statefulset ss doesn't scale past 0 for another 940.698249ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-mhhkc
Jan 12 04:53:18.117: INFO: Scaling statefulset ss to 0
Jan 12 04:53:18.134: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 12 04:53:18.138: INFO: Deleting all statefulset in ns e2e-tests-statefulset-mhhkc
Jan 12 04:53:18.143: INFO: Scaling statefulset ss to 0
Jan 12 04:53:18.154: INFO: Waiting for statefulset status.replicas updated to 0
Jan 12 04:53:18.156: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:53:18.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-mhhkc" for this suite.
Jan 12 04:53:24.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:53:24.245: INFO: namespace: e2e-tests-statefulset-mhhkc, resource: bindings, ignored listing per whitelist
Jan 12 04:53:24.273: INFO: namespace e2e-tests-statefulset-mhhkc deletion completed in 6.101678913s

• [SLOW TEST:67.976 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:53:24.273: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-cndb2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Jan 12 04:53:24.441: INFO: Waiting up to 5m0s for pod "client-containers-fe1bf270-1625-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-containers-cndb2" to be "success or failure"
Jan 12 04:53:24.446: INFO: Pod "client-containers-fe1bf270-1625-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 4.56507ms
Jan 12 04:53:26.449: INFO: Pod "client-containers-fe1bf270-1625-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007597613s
STEP: Saw pod success
Jan 12 04:53:26.449: INFO: Pod "client-containers-fe1bf270-1625-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:53:26.452: INFO: Trying to get logs from node c76-1-41 pod client-containers-fe1bf270-1625-11e9-8fb7-aa4233c46d55 container test-container: <nil>
STEP: delete the pod
Jan 12 04:53:26.475: INFO: Waiting for pod client-containers-fe1bf270-1625-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:53:26.491: INFO: Pod client-containers-fe1bf270-1625-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:53:26.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-cndb2" for this suite.
Jan 12 04:53:32.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:53:32.528: INFO: namespace: e2e-tests-containers-cndb2, resource: bindings, ignored listing per whitelist
Jan 12 04:53:32.602: INFO: namespace e2e-tests-containers-cndb2 deletion completed in 6.105488541s

• [SLOW TEST:8.329 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:53:32.602: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-g4cfr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 12 04:53:32.777: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0312c4bb-1626-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-projected-g4cfr" to be "success or failure"
Jan 12 04:53:32.782: INFO: Pod "downwardapi-volume-0312c4bb-1626-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 5.29434ms
Jan 12 04:53:34.790: INFO: Pod "downwardapi-volume-0312c4bb-1626-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012827164s
STEP: Saw pod success
Jan 12 04:53:34.790: INFO: Pod "downwardapi-volume-0312c4bb-1626-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:53:34.797: INFO: Trying to get logs from node c76-1-41 pod downwardapi-volume-0312c4bb-1626-11e9-8fb7-aa4233c46d55 container client-container: <nil>
STEP: delete the pod
Jan 12 04:53:34.834: INFO: Waiting for pod downwardapi-volume-0312c4bb-1626-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:53:34.840: INFO: Pod downwardapi-volume-0312c4bb-1626-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:53:34.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-g4cfr" for this suite.
Jan 12 04:53:40.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:53:40.921: INFO: namespace: e2e-tests-projected-g4cfr, resource: bindings, ignored listing per whitelist
Jan 12 04:53:40.939: INFO: namespace e2e-tests-projected-g4cfr deletion completed in 6.094648532s

• [SLOW TEST:8.337 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:53:40.939: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-jxvxw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-0809b455-1626-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume configMaps
Jan 12 04:53:41.102: INFO: Waiting up to 5m0s for pod "pod-configmaps-080a28af-1626-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-configmap-jxvxw" to be "success or failure"
Jan 12 04:53:41.104: INFO: Pod "pod-configmaps-080a28af-1626-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.60445ms
Jan 12 04:53:43.108: INFO: Pod "pod-configmaps-080a28af-1626-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006160364s
STEP: Saw pod success
Jan 12 04:53:43.108: INFO: Pod "pod-configmaps-080a28af-1626-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:53:43.111: INFO: Trying to get logs from node c76-1-41 pod pod-configmaps-080a28af-1626-11e9-8fb7-aa4233c46d55 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 12 04:53:43.165: INFO: Waiting for pod pod-configmaps-080a28af-1626-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:53:43.169: INFO: Pod pod-configmaps-080a28af-1626-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:53:43.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jxvxw" for this suite.
Jan 12 04:53:49.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:53:49.240: INFO: namespace: e2e-tests-configmap-jxvxw, resource: bindings, ignored listing per whitelist
Jan 12 04:53:49.282: INFO: namespace e2e-tests-configmap-jxvxw deletion completed in 6.109788887s

• [SLOW TEST:8.343 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:53:49.282: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-7lp2t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 12 04:53:49.441: INFO: Creating deployment "nginx-deployment"
Jan 12 04:53:49.445: INFO: Waiting for observed generation 1
Jan 12 04:53:51.452: INFO: Waiting for all required pods to come up
Jan 12 04:53:51.455: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Jan 12 04:53:59.479: INFO: Waiting for deployment "nginx-deployment" to complete
Jan 12 04:53:59.499: INFO: Updating deployment "nginx-deployment" with a non-existent image
Jan 12 04:53:59.529: INFO: Updating deployment nginx-deployment
Jan 12 04:53:59.529: INFO: Waiting for observed generation 2
Jan 12 04:54:01.557: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jan 12 04:54:01.560: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jan 12 04:54:01.577: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan 12 04:54:01.587: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jan 12 04:54:01.587: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jan 12 04:54:01.590: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan 12 04:54:01.595: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Jan 12 04:54:01.595: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Jan 12 04:54:01.620: INFO: Updating deployment nginx-deployment
Jan 12 04:54:01.620: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Jan 12 04:54:01.642: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jan 12 04:54:03.662: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 12 04:54:03.667: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7lp2t/deployments/nginx-deployment,UID:0d030d14-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139550,Generation:3,CreationTimestamp:2019-01-12 04:53:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-01-12 04:54:01 +0000 UTC 2019-01-12 04:54:01 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-01-12 04:54:01 +0000 UTC 2019-01-12 04:53:49 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Jan 12 04:54:03.671: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7lp2t/replicasets/nginx-deployment-7dc8f79789,UID:130776dd-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139544,Generation:3,CreationTimestamp:2019-01-12 04:53:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 0d030d14-1626-11e9-b7e1-000c294e6ffe 0xc001c6b3f7 0xc001c6b3f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 12 04:54:03.671: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Jan 12 04:54:03.672: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7lp2t/replicasets/nginx-deployment-7f9675fb8b,UID:0d04830c-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139543,Generation:3,CreationTimestamp:2019-01-12 04:53:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 0d030d14-1626-11e9-b7e1-000c294e6ffe 0xc001c6b7e7 0xc001c6b7e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Jan 12 04:54:03.684: INFO: Pod "nginx-deployment-7dc8f79789-2ccnz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-2ccnz,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7dc8f79789-2ccnz,UID:144d0e9f-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139530,Generation:0,CreationTimestamp:2019-01-12 04:54:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 130776dd-1626-11e9-b7e1-000c294e6ffe 0xc002100c97 0xc002100c98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002100ea0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002101040}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.685: INFO: Pod "nginx-deployment-7dc8f79789-8hxnv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-8hxnv,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7dc8f79789-8hxnv,UID:144fc144-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139536,Generation:0,CreationTimestamp:2019-01-12 04:54:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 130776dd-1626-11e9-b7e1-000c294e6ffe 0xc0021010b0 0xc0021010b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002101130} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002101150}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.685: INFO: Pod "nginx-deployment-7dc8f79789-dj4lk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-dj4lk,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7dc8f79789-dj4lk,UID:144d3287-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139538,Generation:0,CreationTimestamp:2019-01-12 04:54:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 130776dd-1626-11e9-b7e1-000c294e6ffe 0xc0021011c0 0xc0021011c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002101240} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002101260}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.685: INFO: Pod "nginx-deployment-7dc8f79789-fp8bk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-fp8bk,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7dc8f79789-fp8bk,UID:1448a027-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139571,Generation:0,CreationTimestamp:2019-01-12 04:54:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 130776dd-1626-11e9-b7e1-000c294e6ffe 0xc0021012d0 0xc0021012d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002101350} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002101370}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:,StartTime:2019-01-12 04:54:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.685: INFO: Pod "nginx-deployment-7dc8f79789-gpcjk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-gpcjk,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7dc8f79789-gpcjk,UID:144cf2a2-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139531,Generation:0,CreationTimestamp:2019-01-12 04:54:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 130776dd-1626-11e9-b7e1-000c294e6ffe 0xc002101480 0xc002101481}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002101500} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002101520}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.685: INFO: Pod "nginx-deployment-7dc8f79789-mrz7c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-mrz7c,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7dc8f79789-mrz7c,UID:131c8eae-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139460,Generation:0,CreationTimestamp:2019-01-12 04:53:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 130776dd-1626-11e9-b7e1-000c294e6ffe 0xc002101590 0xc002101591}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002101610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002101630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:59 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:,StartTime:2019-01-12 04:53:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.685: INFO: Pod "nginx-deployment-7dc8f79789-p4hcw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-p4hcw,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7dc8f79789-p4hcw,UID:144ab3db-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139574,Generation:0,CreationTimestamp:2019-01-12 04:54:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 130776dd-1626-11e9-b7e1-000c294e6ffe 0xc0021016f0 0xc0021016f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002101770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002101790}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:,StartTime:2019-01-12 04:54:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.686: INFO: Pod "nginx-deployment-7dc8f79789-qqd6n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-qqd6n,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7dc8f79789-qqd6n,UID:131d99b0-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139467,Generation:0,CreationTimestamp:2019-01-12 04:53:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 130776dd-1626-11e9-b7e1-000c294e6ffe 0xc002101850 0xc002101851}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021018d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021018f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:59 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:,StartTime:2019-01-12 04:53:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.686: INFO: Pod "nginx-deployment-7dc8f79789-r8hnz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-r8hnz,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7dc8f79789-r8hnz,UID:1309ef09-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139454,Generation:0,CreationTimestamp:2019-01-12 04:53:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 130776dd-1626-11e9-b7e1-000c294e6ffe 0xc0021019b0 0xc0021019b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002101a30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002101a50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:59 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:,StartTime:2019-01-12 04:53:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.686: INFO: Pod "nginx-deployment-7dc8f79789-vbjt8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-vbjt8,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7dc8f79789-vbjt8,UID:1308b71b-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139442,Generation:0,CreationTimestamp:2019-01-12 04:53:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 130776dd-1626-11e9-b7e1-000c294e6ffe 0xc002101b10 0xc002101b11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002101b90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002101bb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:59 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:,StartTime:2019-01-12 04:53:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.686: INFO: Pod "nginx-deployment-7dc8f79789-vh8z5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-vh8z5,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7dc8f79789-vh8z5,UID:144a4eaf-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139586,Generation:0,CreationTimestamp:2019-01-12 04:54:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 130776dd-1626-11e9-b7e1-000c294e6ffe 0xc002101c80 0xc002101c81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002101d00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002101d20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:,StartTime:2019-01-12 04:54:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.686: INFO: Pod "nginx-deployment-7dc8f79789-xwqw2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-xwqw2,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7dc8f79789-xwqw2,UID:130990e2-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139458,Generation:0,CreationTimestamp:2019-01-12 04:53:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 130776dd-1626-11e9-b7e1-000c294e6ffe 0xc002101e00 0xc002101e01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002101e80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002101ea0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:59 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:,StartTime:2019-01-12 04:53:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.686: INFO: Pod "nginx-deployment-7dc8f79789-zlqft" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-zlqft,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7dc8f79789-zlqft,UID:144d0016-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139537,Generation:0,CreationTimestamp:2019-01-12 04:54:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 130776dd-1626-11e9-b7e1-000c294e6ffe 0xc002101fe0 0xc002101fe1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020ea0d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020ea0f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.686: INFO: Pod "nginx-deployment-7f9675fb8b-4krkz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-4krkz,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7f9675fb8b-4krkz,UID:144592ee-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139568,Generation:0,CreationTimestamp:2019-01-12 04:54:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0d04830c-1626-11e9-b7e1-000c294e6ffe 0xc0020ea160 0xc0020ea161}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020ea290} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020ea2b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:,StartTime:2019-01-12 04:54:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.686: INFO: Pod "nginx-deployment-7f9675fb8b-4pbrl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-4pbrl,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7f9675fb8b-4pbrl,UID:144cdb4a-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139524,Generation:0,CreationTimestamp:2019-01-12 04:54:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0d04830c-1626-11e9-b7e1-000c294e6ffe 0xc0020ea367 0xc0020ea368}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020ea3e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020ea490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.687: INFO: Pod "nginx-deployment-7f9675fb8b-4qcv8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-4qcv8,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7f9675fb8b-4qcv8,UID:144a9149-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139604,Generation:0,CreationTimestamp:2019-01-12 04:54:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0d04830c-1626-11e9-b7e1-000c294e6ffe 0xc0020ea500 0xc0020ea501}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020ea570} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020ea590}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:,StartTime:2019-01-12 04:54:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.687: INFO: Pod "nginx-deployment-7f9675fb8b-772c4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-772c4,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7f9675fb8b-772c4,UID:0d08e082-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139393,Generation:0,CreationTimestamp:2019-01-12 04:53:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0d04830c-1626-11e9-b7e1-000c294e6ffe 0xc0020ea6a7 0xc0020ea6a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020ea720} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020ea740}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:49 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:172.31.52.115,StartTime:2019-01-12 04:53:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-12 04:53:55 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://c67a3524e1cfda786265f211d0fa7e4b48af0028f70ced036fb8397c3d4ec665}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.687: INFO: Pod "nginx-deployment-7f9675fb8b-7gnt9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-7gnt9,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7f9675fb8b-7gnt9,UID:144d00ce-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139534,Generation:0,CreationTimestamp:2019-01-12 04:54:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0d04830c-1626-11e9-b7e1-000c294e6ffe 0xc0020ea807 0xc0020ea808}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020ea880} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020ea8a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.688: INFO: Pod "nginx-deployment-7f9675fb8b-bjkx2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-bjkx2,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7f9675fb8b-bjkx2,UID:0d08ca65-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139381,Generation:0,CreationTimestamp:2019-01-12 04:53:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0d04830c-1626-11e9-b7e1-000c294e6ffe 0xc0020ea910 0xc0020ea911}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020ea980} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020ea9a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:49 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:172.31.52.104,StartTime:2019-01-12 04:53:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-12 04:53:54 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://e9574cbcd7fcac6b3bf52bc6194e7632fd84dd8d08cc623f6e527f5752c2d11c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.688: INFO: Pod "nginx-deployment-7f9675fb8b-d6x78" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-d6x78,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7f9675fb8b-d6x78,UID:0d068145-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139407,Generation:0,CreationTimestamp:2019-01-12 04:53:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0d04830c-1626-11e9-b7e1-000c294e6ffe 0xc0020eaa67 0xc0020eaa68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020eaae0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020eab00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:49 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:172.31.52.107,StartTime:2019-01-12 04:53:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-12 04:53:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://4f5de33a27026073b519f8157ff67a25749d86fd24d25e44d29ba462ada50a6f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.689: INFO: Pod "nginx-deployment-7f9675fb8b-dq42l" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-dq42l,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7f9675fb8b-dq42l,UID:0d0b4e94-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139384,Generation:0,CreationTimestamp:2019-01-12 04:53:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0d04830c-1626-11e9-b7e1-000c294e6ffe 0xc0020eabc7 0xc0020eabc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020eac40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020eac60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:49 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:172.31.52.118,StartTime:2019-01-12 04:53:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-12 04:53:55 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://756367689d878e4f6033701666b62c4b911f78301b7c8530e3bf494afed4827a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.689: INFO: Pod "nginx-deployment-7f9675fb8b-f8hsm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-f8hsm,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7f9675fb8b-f8hsm,UID:0d07a093-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139404,Generation:0,CreationTimestamp:2019-01-12 04:53:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0d04830c-1626-11e9-b7e1-000c294e6ffe 0xc0020ead27 0xc0020ead28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020eada0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020eadc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:49 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:172.31.52.108,StartTime:2019-01-12 04:53:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-12 04:53:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://5f76a4c68fd79a4054462640f0fd173c1ca76866ed24066b0f1d6143bfd66069}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.689: INFO: Pod "nginx-deployment-7f9675fb8b-j2hxk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-j2hxk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7f9675fb8b-j2hxk,UID:14487faa-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139569,Generation:0,CreationTimestamp:2019-01-12 04:54:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0d04830c-1626-11e9-b7e1-000c294e6ffe 0xc0020eae87 0xc0020eae88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020eaf00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020eaf20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:,StartTime:2019-01-12 04:54:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.689: INFO: Pod "nginx-deployment-7f9675fb8b-lx8zj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-lx8zj,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7f9675fb8b-lx8zj,UID:1448a059-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139573,Generation:0,CreationTimestamp:2019-01-12 04:54:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0d04830c-1626-11e9-b7e1-000c294e6ffe 0xc0020eafd7 0xc0020eafd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020eb050} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020eb070}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:,StartTime:2019-01-12 04:54:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.689: INFO: Pod "nginx-deployment-7f9675fb8b-pkbzj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-pkbzj,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7f9675fb8b-pkbzj,UID:0d08be4d-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139376,Generation:0,CreationTimestamp:2019-01-12 04:53:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0d04830c-1626-11e9-b7e1-000c294e6ffe 0xc0020eb127 0xc0020eb128}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020eb1a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020eb1c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:49 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:172.31.52.110,StartTime:2019-01-12 04:53:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-12 04:53:54 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://a80d1cfdd6253b5742e2b0f2f8e516192ae57dc678eb4746e810e7306dc83901}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.690: INFO: Pod "nginx-deployment-7f9675fb8b-qsczp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-qsczp,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7f9675fb8b-qsczp,UID:144a9854-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139525,Generation:0,CreationTimestamp:2019-01-12 04:54:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0d04830c-1626-11e9-b7e1-000c294e6ffe 0xc0020eb287 0xc0020eb288}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020eb300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020eb320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.690: INFO: Pod "nginx-deployment-7f9675fb8b-qx7dg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-qx7dg,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7f9675fb8b-qx7dg,UID:0d07f32d-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139396,Generation:0,CreationTimestamp:2019-01-12 04:53:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0d04830c-1626-11e9-b7e1-000c294e6ffe 0xc0020eb390 0xc0020eb391}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020eb400} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020eb420}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:49 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:172.31.52.102,StartTime:2019-01-12 04:53:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-12 04:53:54 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://a3d1589268f0ea6463ed73b663510952bf6b376d1a4e51ad87b887e89cd114c7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.690: INFO: Pod "nginx-deployment-7f9675fb8b-sxrgl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-sxrgl,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7f9675fb8b-sxrgl,UID:144d509c-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139533,Generation:0,CreationTimestamp:2019-01-12 04:54:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0d04830c-1626-11e9-b7e1-000c294e6ffe 0xc0020eb517 0xc0020eb518}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020eb590} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020eb5b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.690: INFO: Pod "nginx-deployment-7f9675fb8b-tzb45" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-tzb45,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7f9675fb8b-tzb45,UID:0d0b81fb-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139387,Generation:0,CreationTimestamp:2019-01-12 04:53:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0d04830c-1626-11e9-b7e1-000c294e6ffe 0xc0020eb630 0xc0020eb631}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020eb6a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020eb6c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:53:49 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:172.31.52.103,StartTime:2019-01-12 04:53:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-12 04:53:54 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://cd6f26cb4119ce4669d9976b6e7ed07124974ab014224051c0332b0fd05aaf28}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.690: INFO: Pod "nginx-deployment-7f9675fb8b-x7f29" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-x7f29,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7f9675fb8b-x7f29,UID:144a7f00-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139596,Generation:0,CreationTimestamp:2019-01-12 04:54:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0d04830c-1626-11e9-b7e1-000c294e6ffe 0xc0020eb787 0xc0020eb788}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020eb800} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020eb820}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:,StartTime:2019-01-12 04:54:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.690: INFO: Pod "nginx-deployment-7f9675fb8b-z6l4g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-z6l4g,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7f9675fb8b-z6l4g,UID:144cb7e4-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139528,Generation:0,CreationTimestamp:2019-01-12 04:54:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0d04830c-1626-11e9-b7e1-000c294e6ffe 0xc0020eb8d7 0xc0020eb8d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020eb950} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020eb970}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.690: INFO: Pod "nginx-deployment-7f9675fb8b-zb7cq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-zb7cq,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7f9675fb8b-zb7cq,UID:144aabb4-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139593,Generation:0,CreationTimestamp:2019-01-12 04:54:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0d04830c-1626-11e9-b7e1-000c294e6ffe 0xc0020eb9e0 0xc0020eb9e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020eba50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020eba80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:,StartTime:2019-01-12 04:54:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 12 04:54:03.690: INFO: Pod "nginx-deployment-7f9675fb8b-zqn57" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-zqn57,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-7lp2t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7lp2t/pods/nginx-deployment-7f9675fb8b-zqn57,UID:144d5c40-1626-11e9-b7e1-000c294e6ffe,ResourceVersion:139526,Generation:0,CreationTimestamp:2019-01-12 04:54:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0d04830c-1626-11e9-b7e1-000c294e6ffe 0xc0020ebb37 0xc0020ebb38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9v4xn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v4xn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9v4xn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020ebbb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020ebbd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:54:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:54:03.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-7lp2t" for this suite.
Jan 12 04:54:11.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:54:11.932: INFO: namespace: e2e-tests-deployment-7lp2t, resource: bindings, ignored listing per whitelist
Jan 12 04:54:12.019: INFO: namespace e2e-tests-deployment-7lp2t deletion completed in 8.325580752s

• [SLOW TEST:22.737 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:54:12.019: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-fxtk8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan 12 04:54:28.481: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 12 04:54:28.488: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 12 04:54:30.488: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 12 04:54:30.498: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 12 04:54:32.489: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 12 04:54:32.492: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 12 04:54:34.489: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 12 04:54:34.493: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 12 04:54:36.489: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 12 04:54:36.497: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 12 04:54:38.488: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 12 04:54:38.493: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 12 04:54:40.489: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 12 04:54:40.496: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 12 04:54:42.489: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 12 04:54:42.496: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 12 04:54:44.488: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 12 04:54:44.491: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 12 04:54:46.488: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 12 04:54:46.491: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:54:46.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-fxtk8" for this suite.
Jan 12 04:55:08.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:55:08.563: INFO: namespace: e2e-tests-container-lifecycle-hook-fxtk8, resource: bindings, ignored listing per whitelist
Jan 12 04:55:08.608: INFO: namespace e2e-tests-container-lifecycle-hook-fxtk8 deletion completed in 22.112266054s

• [SLOW TEST:56.589 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:55:08.608: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-jhdxj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-3c4bf341-1626-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume secrets
Jan 12 04:55:08.777: INFO: Waiting up to 5m0s for pod "pod-secrets-3c4c6aff-1626-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-secrets-jhdxj" to be "success or failure"
Jan 12 04:55:08.780: INFO: Pod "pod-secrets-3c4c6aff-1626-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 3.045991ms
Jan 12 04:55:10.783: INFO: Pod "pod-secrets-3c4c6aff-1626-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00600475s
STEP: Saw pod success
Jan 12 04:55:10.783: INFO: Pod "pod-secrets-3c4c6aff-1626-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:55:10.785: INFO: Trying to get logs from node c76-1-41 pod pod-secrets-3c4c6aff-1626-11e9-8fb7-aa4233c46d55 container secret-volume-test: <nil>
STEP: delete the pod
Jan 12 04:55:10.799: INFO: Waiting for pod pod-secrets-3c4c6aff-1626-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:55:10.802: INFO: Pod pod-secrets-3c4c6aff-1626-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:55:10.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-jhdxj" for this suite.
Jan 12 04:55:16.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:55:16.883: INFO: namespace: e2e-tests-secrets-jhdxj, resource: bindings, ignored listing per whitelist
Jan 12 04:55:16.903: INFO: namespace e2e-tests-secrets-jhdxj deletion completed in 6.096402827s

• [SLOW TEST:8.295 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:55:16.903: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-n77nw
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-413ee23f-1626-11e9-8fb7-aa4233c46d55
STEP: Creating secret with name s-test-opt-upd-413ee2ef-1626-11e9-8fb7-aa4233c46d55
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-413ee23f-1626-11e9-8fb7-aa4233c46d55
STEP: Updating secret s-test-opt-upd-413ee2ef-1626-11e9-8fb7-aa4233c46d55
STEP: Creating secret with name s-test-opt-create-413ee326-1626-11e9-8fb7-aa4233c46d55
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:55:23.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-n77nw" for this suite.
Jan 12 04:55:45.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:55:45.275: INFO: namespace: e2e-tests-projected-n77nw, resource: bindings, ignored listing per whitelist
Jan 12 04:55:45.344: INFO: namespace e2e-tests-projected-n77nw deletion completed in 22.114742295s

• [SLOW TEST:28.441 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:55:45.344: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-k5zd6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 12 04:55:45.524: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jan 12 04:55:45.533: INFO: Number of nodes with available pods: 0
Jan 12 04:55:45.533: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jan 12 04:55:45.556: INFO: Number of nodes with available pods: 0
Jan 12 04:55:45.556: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:55:46.559: INFO: Number of nodes with available pods: 0
Jan 12 04:55:46.559: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:55:47.560: INFO: Number of nodes with available pods: 1
Jan 12 04:55:47.560: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jan 12 04:55:47.592: INFO: Number of nodes with available pods: 1
Jan 12 04:55:47.592: INFO: Number of running nodes: 0, number of available pods: 1
Jan 12 04:55:48.599: INFO: Number of nodes with available pods: 0
Jan 12 04:55:48.599: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jan 12 04:55:48.616: INFO: Number of nodes with available pods: 0
Jan 12 04:55:48.616: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:55:49.620: INFO: Number of nodes with available pods: 0
Jan 12 04:55:49.620: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:55:50.624: INFO: Number of nodes with available pods: 0
Jan 12 04:55:50.624: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:55:51.619: INFO: Number of nodes with available pods: 0
Jan 12 04:55:51.619: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:55:52.623: INFO: Number of nodes with available pods: 0
Jan 12 04:55:52.623: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:55:53.621: INFO: Number of nodes with available pods: 0
Jan 12 04:55:53.621: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:55:54.620: INFO: Number of nodes with available pods: 0
Jan 12 04:55:54.620: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:55:55.620: INFO: Number of nodes with available pods: 0
Jan 12 04:55:55.620: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:55:56.624: INFO: Number of nodes with available pods: 0
Jan 12 04:55:56.624: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:55:57.620: INFO: Number of nodes with available pods: 0
Jan 12 04:55:57.620: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:55:58.620: INFO: Number of nodes with available pods: 0
Jan 12 04:55:58.620: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:55:59.620: INFO: Number of nodes with available pods: 0
Jan 12 04:55:59.620: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:00.624: INFO: Number of nodes with available pods: 0
Jan 12 04:56:00.624: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:01.621: INFO: Number of nodes with available pods: 0
Jan 12 04:56:01.621: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:02.621: INFO: Number of nodes with available pods: 0
Jan 12 04:56:02.621: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:03.621: INFO: Number of nodes with available pods: 0
Jan 12 04:56:03.621: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:04.621: INFO: Number of nodes with available pods: 0
Jan 12 04:56:04.621: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:05.620: INFO: Number of nodes with available pods: 0
Jan 12 04:56:05.620: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:06.623: INFO: Number of nodes with available pods: 0
Jan 12 04:56:06.623: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:07.620: INFO: Number of nodes with available pods: 0
Jan 12 04:56:07.620: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:08.625: INFO: Number of nodes with available pods: 0
Jan 12 04:56:08.625: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:09.624: INFO: Number of nodes with available pods: 0
Jan 12 04:56:09.625: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:10.624: INFO: Number of nodes with available pods: 0
Jan 12 04:56:10.624: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:11.621: INFO: Number of nodes with available pods: 0
Jan 12 04:56:11.621: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:12.624: INFO: Number of nodes with available pods: 0
Jan 12 04:56:12.625: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:13.621: INFO: Number of nodes with available pods: 0
Jan 12 04:56:13.621: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:14.619: INFO: Number of nodes with available pods: 0
Jan 12 04:56:14.619: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:15.624: INFO: Number of nodes with available pods: 0
Jan 12 04:56:15.624: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:16.623: INFO: Number of nodes with available pods: 0
Jan 12 04:56:16.623: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:17.624: INFO: Number of nodes with available pods: 0
Jan 12 04:56:17.624: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:18.624: INFO: Number of nodes with available pods: 0
Jan 12 04:56:18.624: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:19.625: INFO: Number of nodes with available pods: 0
Jan 12 04:56:19.625: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:20.624: INFO: Number of nodes with available pods: 0
Jan 12 04:56:20.624: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:21.623: INFO: Number of nodes with available pods: 0
Jan 12 04:56:21.623: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:22.624: INFO: Number of nodes with available pods: 0
Jan 12 04:56:22.624: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:23.619: INFO: Number of nodes with available pods: 0
Jan 12 04:56:23.619: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:24.619: INFO: Number of nodes with available pods: 0
Jan 12 04:56:24.619: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 04:56:25.622: INFO: Number of nodes with available pods: 1
Jan 12 04:56:25.622: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-k5zd6, will wait for the garbage collector to delete the pods
Jan 12 04:56:25.693: INFO: Deleting DaemonSet.extensions daemon-set took: 5.461726ms
Jan 12 04:56:25.793: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.395437ms
Jan 12 04:57:03.597: INFO: Number of nodes with available pods: 0
Jan 12 04:57:03.597: INFO: Number of running nodes: 0, number of available pods: 0
Jan 12 04:57:03.599: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-k5zd6/daemonsets","resourceVersion":"140385"},"items":null}

Jan 12 04:57:03.601: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-k5zd6/pods","resourceVersion":"140385"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:57:03.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-k5zd6" for this suite.
Jan 12 04:57:09.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:57:09.696: INFO: namespace: e2e-tests-daemonsets-k5zd6, resource: bindings, ignored listing per whitelist
Jan 12 04:57:09.701: INFO: namespace e2e-tests-daemonsets-k5zd6 deletion completed in 6.085969473s

• [SLOW TEST:84.357 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:57:09.701: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-dv9r9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:57:13.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-dv9r9" for this suite.
Jan 12 04:57:19.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:57:19.986: INFO: namespace: e2e-tests-kubelet-test-dv9r9, resource: bindings, ignored listing per whitelist
Jan 12 04:57:19.989: INFO: namespace e2e-tests-kubelet-test-dv9r9 deletion completed in 6.108104833s

• [SLOW TEST:10.288 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:57:19.989: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-qzfjz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-qzfjz/configmap-test-8a9b4552-1626-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume configMaps
Jan 12 04:57:20.160: INFO: Waiting up to 5m0s for pod "pod-configmaps-8a9bbec9-1626-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-configmap-qzfjz" to be "success or failure"
Jan 12 04:57:20.173: INFO: Pod "pod-configmaps-8a9bbec9-1626-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 13.358755ms
Jan 12 04:57:22.177: INFO: Pod "pod-configmaps-8a9bbec9-1626-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016783638s
STEP: Saw pod success
Jan 12 04:57:22.177: INFO: Pod "pod-configmaps-8a9bbec9-1626-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:57:22.179: INFO: Trying to get logs from node c76-1-41 pod pod-configmaps-8a9bbec9-1626-11e9-8fb7-aa4233c46d55 container env-test: <nil>
STEP: delete the pod
Jan 12 04:57:22.225: INFO: Waiting for pod pod-configmaps-8a9bbec9-1626-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:57:22.227: INFO: Pod pod-configmaps-8a9bbec9-1626-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:57:22.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qzfjz" for this suite.
Jan 12 04:57:28.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:57:28.308: INFO: namespace: e2e-tests-configmap-qzfjz, resource: bindings, ignored listing per whitelist
Jan 12 04:57:28.325: INFO: namespace e2e-tests-configmap-qzfjz deletion completed in 6.092965522s

• [SLOW TEST:8.335 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:57:28.325: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-jjh8c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 12 04:57:28.490: INFO: Waiting up to 5m0s for pod "downward-api-8f92d17b-1626-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-downward-api-jjh8c" to be "success or failure"
Jan 12 04:57:28.494: INFO: Pod "downward-api-8f92d17b-1626-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 4.161039ms
Jan 12 04:57:30.498: INFO: Pod "downward-api-8f92d17b-1626-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007362566s
STEP: Saw pod success
Jan 12 04:57:30.498: INFO: Pod "downward-api-8f92d17b-1626-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:57:30.500: INFO: Trying to get logs from node c76-1-41 pod downward-api-8f92d17b-1626-11e9-8fb7-aa4233c46d55 container dapi-container: <nil>
STEP: delete the pod
Jan 12 04:57:30.515: INFO: Waiting for pod downward-api-8f92d17b-1626-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:57:30.519: INFO: Pod downward-api-8f92d17b-1626-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:57:30.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jjh8c" for this suite.
Jan 12 04:57:36.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:57:36.602: INFO: namespace: e2e-tests-downward-api-jjh8c, resource: bindings, ignored listing per whitelist
Jan 12 04:57:36.628: INFO: namespace e2e-tests-downward-api-jjh8c deletion completed in 6.106322314s

• [SLOW TEST:8.303 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:57:36.629: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-9wngl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 12 04:57:36.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-9wngl'
Jan 12 04:57:36.891: INFO: stderr: ""
Jan 12 04:57:36.891: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Jan 12 04:57:41.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-9wngl -o json'
Jan 12 04:57:42.056: INFO: stderr: ""
Jan 12 04:57:42.056: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-01-12T04:57:36Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-9wngl\",\n        \"resourceVersion\": \"140582\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-9wngl/pods/e2e-test-nginx-pod\",\n        \"uid\": \"948ea846-1626-11e9-b7e1-000c294e6ffe\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-kx899\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"c76-1-41\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-kx899\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-kx899\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-12T04:57:36Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-12T04:57:38Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-12T04:57:38Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-12T04:57:36Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://4d9ff11a2355fc407bd28aab3f46457a58cdc1293050945fa584f05909bdd23c\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-01-12T04:57:38Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.1.41\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.31.52.98\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-01-12T04:57:36Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jan 12 04:57:42.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 replace -f - --namespace=e2e-tests-kubectl-9wngl'
Jan 12 04:57:42.395: INFO: stderr: ""
Jan 12 04:57:42.395: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Jan 12 04:57:42.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-9wngl'
Jan 12 04:57:53.555: INFO: stderr: ""
Jan 12 04:57:53.556: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:57:53.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9wngl" for this suite.
Jan 12 04:57:59.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:57:59.611: INFO: namespace: e2e-tests-kubectl-9wngl, resource: bindings, ignored listing per whitelist
Jan 12 04:57:59.648: INFO: namespace e2e-tests-kubectl-9wngl deletion completed in 6.088812621s

• [SLOW TEST:23.019 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:57:59.648: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-98cs4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-a2407793-1626-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume secrets
Jan 12 04:57:59.836: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a24124ff-1626-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-projected-98cs4" to be "success or failure"
Jan 12 04:57:59.842: INFO: Pod "pod-projected-secrets-a24124ff-1626-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 6.07873ms
Jan 12 04:58:01.854: INFO: Pod "pod-projected-secrets-a24124ff-1626-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017936825s
Jan 12 04:58:03.867: INFO: Pod "pod-projected-secrets-a24124ff-1626-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031034666s
STEP: Saw pod success
Jan 12 04:58:03.867: INFO: Pod "pod-projected-secrets-a24124ff-1626-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:58:03.869: INFO: Trying to get logs from node c76-1-41 pod pod-projected-secrets-a24124ff-1626-11e9-8fb7-aa4233c46d55 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 12 04:58:03.882: INFO: Waiting for pod pod-projected-secrets-a24124ff-1626-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:58:03.885: INFO: Pod pod-projected-secrets-a24124ff-1626-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:58:03.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-98cs4" for this suite.
Jan 12 04:58:09.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:58:09.932: INFO: namespace: e2e-tests-projected-98cs4, resource: bindings, ignored listing per whitelist
Jan 12 04:58:09.995: INFO: namespace e2e-tests-projected-98cs4 deletion completed in 6.107865585s

• [SLOW TEST:10.348 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:58:09.996: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-swtxq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-a86a25b3-1626-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume secrets
Jan 12 04:58:10.182: INFO: Waiting up to 5m0s for pod "pod-secrets-a86b2edc-1626-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-secrets-swtxq" to be "success or failure"
Jan 12 04:58:10.188: INFO: Pod "pod-secrets-a86b2edc-1626-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 5.781276ms
Jan 12 04:58:12.197: INFO: Pod "pod-secrets-a86b2edc-1626-11e9-8fb7-aa4233c46d55": Phase="Running", Reason="", readiness=true. Elapsed: 2.015348668s
Jan 12 04:58:14.205: INFO: Pod "pod-secrets-a86b2edc-1626-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023216938s
STEP: Saw pod success
Jan 12 04:58:14.205: INFO: Pod "pod-secrets-a86b2edc-1626-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:58:14.212: INFO: Trying to get logs from node c76-1-41 pod pod-secrets-a86b2edc-1626-11e9-8fb7-aa4233c46d55 container secret-volume-test: <nil>
STEP: delete the pod
Jan 12 04:58:14.248: INFO: Waiting for pod pod-secrets-a86b2edc-1626-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:58:14.253: INFO: Pod pod-secrets-a86b2edc-1626-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:58:14.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-swtxq" for this suite.
Jan 12 04:58:20.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:58:20.330: INFO: namespace: e2e-tests-secrets-swtxq, resource: bindings, ignored listing per whitelist
Jan 12 04:58:20.357: INFO: namespace e2e-tests-secrets-swtxq deletion completed in 6.099990503s

• [SLOW TEST:10.361 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:58:20.357: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-gbzzt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-gbzzt
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 12 04:58:20.518: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 12 04:58:42.625: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.31.52.64:8080/dial?request=hostName&protocol=udp&host=172.31.52.78&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-gbzzt PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 12 04:58:42.625: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
Jan 12 04:58:42.740: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:58:42.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-gbzzt" for this suite.
Jan 12 04:59:04.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:59:04.823: INFO: namespace: e2e-tests-pod-network-test-gbzzt, resource: bindings, ignored listing per whitelist
Jan 12 04:59:04.842: INFO: namespace e2e-tests-pod-network-test-gbzzt deletion completed in 22.099085964s

• [SLOW TEST:44.486 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:59:04.842: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-zwmjd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan 12 04:59:05.015: INFO: Waiting up to 5m0s for pod "pod-c91a20da-1626-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-emptydir-zwmjd" to be "success or failure"
Jan 12 04:59:05.019: INFO: Pod "pod-c91a20da-1626-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 4.296674ms
Jan 12 04:59:07.022: INFO: Pod "pod-c91a20da-1626-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007480252s
STEP: Saw pod success
Jan 12 04:59:07.022: INFO: Pod "pod-c91a20da-1626-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 04:59:07.025: INFO: Trying to get logs from node c76-1-41 pod pod-c91a20da-1626-11e9-8fb7-aa4233c46d55 container test-container: <nil>
STEP: delete the pod
Jan 12 04:59:07.070: INFO: Waiting for pod pod-c91a20da-1626-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 04:59:07.074: INFO: Pod pod-c91a20da-1626-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 04:59:07.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-zwmjd" for this suite.
Jan 12 04:59:13.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 04:59:13.191: INFO: namespace: e2e-tests-emptydir-zwmjd, resource: bindings, ignored listing per whitelist
Jan 12 04:59:13.195: INFO: namespace e2e-tests-emptydir-zwmjd deletion completed in 6.116271368s

• [SLOW TEST:8.352 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 04:59:13.195: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-mvxz5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-mvxz5
Jan 12 04:59:15.373: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-mvxz5
STEP: checking the pod's current state and verifying that restartCount is present
Jan 12 04:59:15.378: INFO: Initial restart count of pod liveness-http is 0
Jan 12 04:59:31.439: INFO: Restart count of pod e2e-tests-container-probe-mvxz5/liveness-http is now 1 (16.060043341s elapsed)
Jan 12 04:59:51.514: INFO: Restart count of pod e2e-tests-container-probe-mvxz5/liveness-http is now 2 (36.135992037s elapsed)
Jan 12 05:00:11.571: INFO: Restart count of pod e2e-tests-container-probe-mvxz5/liveness-http is now 3 (56.192651889s elapsed)
Jan 12 05:00:31.625: INFO: Restart count of pod e2e-tests-container-probe-mvxz5/liveness-http is now 4 (1m16.246546352s elapsed)
Jan 12 05:01:33.811: INFO: Restart count of pod e2e-tests-container-probe-mvxz5/liveness-http is now 5 (2m18.432803452s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:01:33.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-mvxz5" for this suite.
Jan 12 05:01:39.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:01:39.927: INFO: namespace: e2e-tests-container-probe-mvxz5, resource: bindings, ignored listing per whitelist
Jan 12 05:01:39.953: INFO: namespace e2e-tests-container-probe-mvxz5 deletion completed in 6.109908468s

• [SLOW TEST:146.759 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:01:39.954: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-rfph8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-s7xqv
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-zh4sg
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:01:46.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-rfph8" for this suite.
Jan 12 05:01:52.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:01:52.494: INFO: namespace: e2e-tests-namespaces-rfph8, resource: bindings, ignored listing per whitelist
Jan 12 05:01:52.533: INFO: namespace e2e-tests-namespaces-rfph8 deletion completed in 6.104150395s
STEP: Destroying namespace "e2e-tests-nsdeletetest-s7xqv" for this suite.
Jan 12 05:01:52.534: INFO: Namespace e2e-tests-nsdeletetest-s7xqv was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-zh4sg" for this suite.
Jan 12 05:01:58.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:01:58.610: INFO: namespace: e2e-tests-nsdeletetest-zh4sg, resource: bindings, ignored listing per whitelist
Jan 12 05:01:58.648: INFO: namespace e2e-tests-nsdeletetest-zh4sg deletion completed in 6.113451077s

• [SLOW TEST:18.694 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:01:58.648: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5wwlp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-30b2be3a-1627-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume configMaps
Jan 12 05:01:58.819: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-30b35290-1627-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-projected-5wwlp" to be "success or failure"
Jan 12 05:01:58.822: INFO: Pod "pod-projected-configmaps-30b35290-1627-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 3.206997ms
Jan 12 05:02:00.825: INFO: Pod "pod-projected-configmaps-30b35290-1627-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006573141s
STEP: Saw pod success
Jan 12 05:02:00.825: INFO: Pod "pod-projected-configmaps-30b35290-1627-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:02:00.828: INFO: Trying to get logs from node c76-1-41 pod pod-projected-configmaps-30b35290-1627-11e9-8fb7-aa4233c46d55 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 12 05:02:00.855: INFO: Waiting for pod pod-projected-configmaps-30b35290-1627-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:02:00.873: INFO: Pod pod-projected-configmaps-30b35290-1627-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:02:00.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5wwlp" for this suite.
Jan 12 05:02:06.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:02:06.937: INFO: namespace: e2e-tests-projected-5wwlp, resource: bindings, ignored listing per whitelist
Jan 12 05:02:06.981: INFO: namespace e2e-tests-projected-5wwlp deletion completed in 6.103847949s

• [SLOW TEST:8.332 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:02:06.981: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-z8hsx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-vs8h
STEP: Creating a pod to test atomic-volume-subpath
Jan 12 05:02:07.175: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-vs8h" in namespace "e2e-tests-subpath-z8hsx" to be "success or failure"
Jan 12 05:02:07.179: INFO: Pod "pod-subpath-test-projected-vs8h": Phase="Pending", Reason="", readiness=false. Elapsed: 3.431791ms
Jan 12 05:02:09.182: INFO: Pod "pod-subpath-test-projected-vs8h": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006864636s
Jan 12 05:02:11.191: INFO: Pod "pod-subpath-test-projected-vs8h": Phase="Running", Reason="", readiness=false. Elapsed: 4.015445518s
Jan 12 05:02:13.199: INFO: Pod "pod-subpath-test-projected-vs8h": Phase="Running", Reason="", readiness=false. Elapsed: 6.023775426s
Jan 12 05:02:15.207: INFO: Pod "pod-subpath-test-projected-vs8h": Phase="Running", Reason="", readiness=false. Elapsed: 8.031968523s
Jan 12 05:02:17.211: INFO: Pod "pod-subpath-test-projected-vs8h": Phase="Running", Reason="", readiness=false. Elapsed: 10.035785622s
Jan 12 05:02:19.220: INFO: Pod "pod-subpath-test-projected-vs8h": Phase="Running", Reason="", readiness=false. Elapsed: 12.044347047s
Jan 12 05:02:21.223: INFO: Pod "pod-subpath-test-projected-vs8h": Phase="Running", Reason="", readiness=false. Elapsed: 14.048030255s
Jan 12 05:02:23.233: INFO: Pod "pod-subpath-test-projected-vs8h": Phase="Running", Reason="", readiness=false. Elapsed: 16.057220083s
Jan 12 05:02:25.237: INFO: Pod "pod-subpath-test-projected-vs8h": Phase="Running", Reason="", readiness=false. Elapsed: 18.061271645s
Jan 12 05:02:27.240: INFO: Pod "pod-subpath-test-projected-vs8h": Phase="Running", Reason="", readiness=false. Elapsed: 20.064566402s
Jan 12 05:02:29.245: INFO: Pod "pod-subpath-test-projected-vs8h": Phase="Running", Reason="", readiness=false. Elapsed: 22.069881441s
Jan 12 05:02:31.250: INFO: Pod "pod-subpath-test-projected-vs8h": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.074838279s
STEP: Saw pod success
Jan 12 05:02:31.250: INFO: Pod "pod-subpath-test-projected-vs8h" satisfied condition "success or failure"
Jan 12 05:02:31.254: INFO: Trying to get logs from node c76-1-41 pod pod-subpath-test-projected-vs8h container test-container-subpath-projected-vs8h: <nil>
STEP: delete the pod
Jan 12 05:02:31.285: INFO: Waiting for pod pod-subpath-test-projected-vs8h to disappear
Jan 12 05:02:31.288: INFO: Pod pod-subpath-test-projected-vs8h no longer exists
STEP: Deleting pod pod-subpath-test-projected-vs8h
Jan 12 05:02:31.288: INFO: Deleting pod "pod-subpath-test-projected-vs8h" in namespace "e2e-tests-subpath-z8hsx"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:02:31.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-z8hsx" for this suite.
Jan 12 05:02:37.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:02:37.341: INFO: namespace: e2e-tests-subpath-z8hsx, resource: bindings, ignored listing per whitelist
Jan 12 05:02:37.383: INFO: namespace e2e-tests-subpath-z8hsx deletion completed in 6.087766885s

• [SLOW TEST:30.403 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:02:37.383: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-gcq8q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jan 12 05:02:37.542: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 12 05:02:37.548: INFO: Waiting for terminating namespaces to be deleted...
Jan 12 05:02:37.551: INFO: 
Logging pods the kubelet thinks is on node c76-1-41 before test
Jan 12 05:02:37.556: INFO: calico-node-47p2l from kube-system started at 2019-01-11 10:32:24 +0000 UTC (1 container statuses recorded)
Jan 12 05:02:37.556: INFO: 	Container calico-node ready: true, restart count 2
Jan 12 05:02:37.556: INFO: kubectl-cp4p5 from kube-system started at 2019-01-11 10:32:24 +0000 UTC (1 container statuses recorded)
Jan 12 05:02:37.556: INFO: 	Container kubectl ready: true, restart count 2
Jan 12 05:02:37.556: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-12 04:12:07 +0000 UTC (3 container statuses recorded)
Jan 12 05:02:37.556: INFO: 	Container cleanup ready: true, restart count 0
Jan 12 05:02:37.556: INFO: 	Container forwarder ready: true, restart count 0
Jan 12 05:02:37.556: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 12 05:02:37.556: INFO: sonobuoy-e2e-job-f2515c1fd49f447c from heptio-sonobuoy started at 2019-01-12 04:12:09 +0000 UTC (2 container statuses recorded)
Jan 12 05:02:37.556: INFO: 	Container e2e ready: true, restart count 0
Jan 12 05:02:37.556: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 12 05:02:37.556: INFO: kube-proxy-k8t9z from kube-system started at 2019-01-11 10:32:24 +0000 UTC (1 container statuses recorded)
Jan 12 05:02:37.556: INFO: 	Container kube-proxy ready: true, restart count 2
Jan 12 05:02:37.556: INFO: kube-controller-6dd888b6-2gdzh from kube-system started at 2019-01-12 01:48:43 +0000 UTC (1 container statuses recorded)
Jan 12 05:02:37.556: INFO: 	Container kube-controller ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node c76-1-41
Jan 12 05:02:37.576: INFO: Pod sonobuoy requesting resource cpu=0m on Node c76-1-41
Jan 12 05:02:37.576: INFO: Pod sonobuoy-e2e-job-f2515c1fd49f447c requesting resource cpu=0m on Node c76-1-41
Jan 12 05:02:37.576: INFO: Pod calico-node-47p2l requesting resource cpu=100m on Node c76-1-41
Jan 12 05:02:37.576: INFO: Pod kube-controller-6dd888b6-2gdzh requesting resource cpu=0m on Node c76-1-41
Jan 12 05:02:37.576: INFO: Pod kube-proxy-k8t9z requesting resource cpu=0m on Node c76-1-41
Jan 12 05:02:37.576: INFO: Pod kubectl-cp4p5 requesting resource cpu=100m on Node c76-1-41
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-47ce89f0-1627-11e9-8fb7-aa4233c46d55.157901486e759b60], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-gcq8q/filler-pod-47ce89f0-1627-11e9-8fb7-aa4233c46d55 to c76-1-41]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-47ce89f0-1627-11e9-8fb7-aa4233c46d55.15790148a468ddb3], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-47ce89f0-1627-11e9-8fb7-aa4233c46d55.15790148b10428fa], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-47ce89f0-1627-11e9-8fb7-aa4233c46d55.15790148b7f4fd4b], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15790148e6d2e00e], Reason = [FailedScheduling], Message = [0/2 nodes are available: 1 Insufficient cpu, 1 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node c76-1-41
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:02:40.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-gcq8q" for this suite.
Jan 12 05:02:46.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:02:46.711: INFO: namespace: e2e-tests-sched-pred-gcq8q, resource: bindings, ignored listing per whitelist
Jan 12 05:02:46.736: INFO: namespace e2e-tests-sched-pred-gcq8q deletion completed in 6.084011506s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.353 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:02:46.737: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-jg5cq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jan 12 05:02:46.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 create -f - --namespace=e2e-tests-kubectl-jg5cq'
Jan 12 05:02:47.297: INFO: stderr: ""
Jan 12 05:02:47.297: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 12 05:02:48.300: INFO: Selector matched 1 pods for map[app:redis]
Jan 12 05:02:48.300: INFO: Found 0 / 1
Jan 12 05:02:49.306: INFO: Selector matched 1 pods for map[app:redis]
Jan 12 05:02:49.306: INFO: Found 1 / 1
Jan 12 05:02:49.306: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jan 12 05:02:49.313: INFO: Selector matched 1 pods for map[app:redis]
Jan 12 05:02:49.314: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 12 05:02:49.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 patch pod redis-master-g28cv --namespace=e2e-tests-kubectl-jg5cq -p {"metadata":{"annotations":{"x":"y"}}}'
Jan 12 05:02:49.405: INFO: stderr: ""
Jan 12 05:02:49.405: INFO: stdout: "pod/redis-master-g28cv patched\n"
STEP: checking annotations
Jan 12 05:02:49.408: INFO: Selector matched 1 pods for map[app:redis]
Jan 12 05:02:49.408: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:02:49.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jg5cq" for this suite.
Jan 12 05:03:11.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:03:11.573: INFO: namespace: e2e-tests-kubectl-jg5cq, resource: bindings, ignored listing per whitelist
Jan 12 05:03:11.585: INFO: namespace e2e-tests-kubectl-jg5cq deletion completed in 22.172983764s

• [SLOW TEST:24.848 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:03:11.585: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-gnswq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-q5d2
STEP: Creating a pod to test atomic-volume-subpath
Jan 12 05:03:11.792: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-q5d2" in namespace "e2e-tests-subpath-gnswq" to be "success or failure"
Jan 12 05:03:11.795: INFO: Pod "pod-subpath-test-configmap-q5d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.493556ms
Jan 12 05:03:13.798: INFO: Pod "pod-subpath-test-configmap-q5d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005404851s
Jan 12 05:03:15.803: INFO: Pod "pod-subpath-test-configmap-q5d2": Phase="Running", Reason="", readiness=false. Elapsed: 4.010376694s
Jan 12 05:03:17.808: INFO: Pod "pod-subpath-test-configmap-q5d2": Phase="Running", Reason="", readiness=false. Elapsed: 6.01592705s
Jan 12 05:03:19.817: INFO: Pod "pod-subpath-test-configmap-q5d2": Phase="Running", Reason="", readiness=false. Elapsed: 8.024247721s
Jan 12 05:03:21.825: INFO: Pod "pod-subpath-test-configmap-q5d2": Phase="Running", Reason="", readiness=false. Elapsed: 10.032172552s
Jan 12 05:03:23.832: INFO: Pod "pod-subpath-test-configmap-q5d2": Phase="Running", Reason="", readiness=false. Elapsed: 12.039487688s
Jan 12 05:03:25.836: INFO: Pod "pod-subpath-test-configmap-q5d2": Phase="Running", Reason="", readiness=false. Elapsed: 14.044042047s
Jan 12 05:03:27.844: INFO: Pod "pod-subpath-test-configmap-q5d2": Phase="Running", Reason="", readiness=false. Elapsed: 16.051392522s
Jan 12 05:03:29.851: INFO: Pod "pod-subpath-test-configmap-q5d2": Phase="Running", Reason="", readiness=false. Elapsed: 18.059098702s
Jan 12 05:03:31.859: INFO: Pod "pod-subpath-test-configmap-q5d2": Phase="Running", Reason="", readiness=false. Elapsed: 20.066931013s
Jan 12 05:03:33.863: INFO: Pod "pod-subpath-test-configmap-q5d2": Phase="Running", Reason="", readiness=false. Elapsed: 22.070447857s
Jan 12 05:03:35.871: INFO: Pod "pod-subpath-test-configmap-q5d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.078467121s
STEP: Saw pod success
Jan 12 05:03:35.871: INFO: Pod "pod-subpath-test-configmap-q5d2" satisfied condition "success or failure"
Jan 12 05:03:35.877: INFO: Trying to get logs from node c76-1-41 pod pod-subpath-test-configmap-q5d2 container test-container-subpath-configmap-q5d2: <nil>
STEP: delete the pod
Jan 12 05:03:35.925: INFO: Waiting for pod pod-subpath-test-configmap-q5d2 to disappear
Jan 12 05:03:35.934: INFO: Pod pod-subpath-test-configmap-q5d2 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-q5d2
Jan 12 05:03:35.934: INFO: Deleting pod "pod-subpath-test-configmap-q5d2" in namespace "e2e-tests-subpath-gnswq"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:03:35.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-gnswq" for this suite.
Jan 12 05:03:41.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:03:41.988: INFO: namespace: e2e-tests-subpath-gnswq, resource: bindings, ignored listing per whitelist
Jan 12 05:03:42.055: INFO: namespace e2e-tests-subpath-gnswq deletion completed in 6.109790648s

• [SLOW TEST:30.470 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:03:42.055: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-hc5td
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jan 12 05:03:42.238: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-hc5td,SelfLink:/api/v1/namespaces/e2e-tests-watch-hc5td/configmaps/e2e-watch-test-watch-closed,UID:6e555298-1627-11e9-b7e1-000c294e6ffe,ResourceVersion:141678,Generation:0,CreationTimestamp:2019-01-12 05:03:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 12 05:03:42.239: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-hc5td,SelfLink:/api/v1/namespaces/e2e-tests-watch-hc5td/configmaps/e2e-watch-test-watch-closed,UID:6e555298-1627-11e9-b7e1-000c294e6ffe,ResourceVersion:141679,Generation:0,CreationTimestamp:2019-01-12 05:03:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jan 12 05:03:42.263: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-hc5td,SelfLink:/api/v1/namespaces/e2e-tests-watch-hc5td/configmaps/e2e-watch-test-watch-closed,UID:6e555298-1627-11e9-b7e1-000c294e6ffe,ResourceVersion:141680,Generation:0,CreationTimestamp:2019-01-12 05:03:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 12 05:03:42.263: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-hc5td,SelfLink:/api/v1/namespaces/e2e-tests-watch-hc5td/configmaps/e2e-watch-test-watch-closed,UID:6e555298-1627-11e9-b7e1-000c294e6ffe,ResourceVersion:141681,Generation:0,CreationTimestamp:2019-01-12 05:03:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:03:42.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-hc5td" for this suite.
Jan 12 05:03:48.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:03:48.354: INFO: namespace: e2e-tests-watch-hc5td, resource: bindings, ignored listing per whitelist
Jan 12 05:03:48.375: INFO: namespace e2e-tests-watch-hc5td deletion completed in 6.108036884s

• [SLOW TEST:6.320 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:03:48.375: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-d7vnv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan 12 05:03:48.553: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:03:48.555: INFO: Number of nodes with available pods: 0
Jan 12 05:03:48.555: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:03:49.560: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:03:49.563: INFO: Number of nodes with available pods: 0
Jan 12 05:03:49.563: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:03:50.566: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:03:50.573: INFO: Number of nodes with available pods: 1
Jan 12 05:03:50.573: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jan 12 05:03:50.603: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:03:50.606: INFO: Number of nodes with available pods: 0
Jan 12 05:03:50.606: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:03:51.610: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:03:51.612: INFO: Number of nodes with available pods: 0
Jan 12 05:03:51.612: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:03:52.611: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:03:52.615: INFO: Number of nodes with available pods: 0
Jan 12 05:03:52.615: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:03:53.611: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:03:53.614: INFO: Number of nodes with available pods: 0
Jan 12 05:03:53.614: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:03:54.610: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:03:54.612: INFO: Number of nodes with available pods: 0
Jan 12 05:03:54.612: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:03:55.610: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:03:55.612: INFO: Number of nodes with available pods: 0
Jan 12 05:03:55.612: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:03:56.611: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:03:56.614: INFO: Number of nodes with available pods: 0
Jan 12 05:03:56.614: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:03:57.610: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:03:57.613: INFO: Number of nodes with available pods: 0
Jan 12 05:03:57.613: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:03:58.617: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:03:58.624: INFO: Number of nodes with available pods: 0
Jan 12 05:03:58.624: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:03:59.612: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:03:59.615: INFO: Number of nodes with available pods: 0
Jan 12 05:03:59.616: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:00.616: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:00.625: INFO: Number of nodes with available pods: 0
Jan 12 05:04:00.625: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:01.611: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:01.614: INFO: Number of nodes with available pods: 0
Jan 12 05:04:01.614: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:02.616: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:02.622: INFO: Number of nodes with available pods: 0
Jan 12 05:04:02.622: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:03.611: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:03.614: INFO: Number of nodes with available pods: 0
Jan 12 05:04:03.614: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:04.612: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:04.616: INFO: Number of nodes with available pods: 0
Jan 12 05:04:04.616: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:05.615: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:05.623: INFO: Number of nodes with available pods: 0
Jan 12 05:04:05.623: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:06.616: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:06.623: INFO: Number of nodes with available pods: 0
Jan 12 05:04:06.623: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:07.611: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:07.615: INFO: Number of nodes with available pods: 0
Jan 12 05:04:07.615: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:08.610: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:08.613: INFO: Number of nodes with available pods: 0
Jan 12 05:04:08.613: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:09.611: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:09.614: INFO: Number of nodes with available pods: 0
Jan 12 05:04:09.614: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:10.615: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:10.622: INFO: Number of nodes with available pods: 0
Jan 12 05:04:10.622: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:11.611: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:11.615: INFO: Number of nodes with available pods: 0
Jan 12 05:04:11.615: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:12.615: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:12.622: INFO: Number of nodes with available pods: 0
Jan 12 05:04:12.622: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:13.611: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:13.614: INFO: Number of nodes with available pods: 0
Jan 12 05:04:13.615: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:14.615: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:14.622: INFO: Number of nodes with available pods: 0
Jan 12 05:04:14.622: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:15.609: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:15.612: INFO: Number of nodes with available pods: 0
Jan 12 05:04:15.612: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:16.611: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:16.614: INFO: Number of nodes with available pods: 0
Jan 12 05:04:16.614: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:17.610: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:17.613: INFO: Number of nodes with available pods: 0
Jan 12 05:04:17.613: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:18.616: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:18.623: INFO: Number of nodes with available pods: 0
Jan 12 05:04:18.623: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:19.610: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:19.613: INFO: Number of nodes with available pods: 0
Jan 12 05:04:19.613: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:20.615: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:20.623: INFO: Number of nodes with available pods: 0
Jan 12 05:04:20.623: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:21.612: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:21.616: INFO: Number of nodes with available pods: 0
Jan 12 05:04:21.616: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:22.612: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:22.615: INFO: Number of nodes with available pods: 0
Jan 12 05:04:22.615: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:23.611: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:23.615: INFO: Number of nodes with available pods: 0
Jan 12 05:04:23.615: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:24.610: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:24.613: INFO: Number of nodes with available pods: 0
Jan 12 05:04:24.614: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:25.610: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:25.613: INFO: Number of nodes with available pods: 0
Jan 12 05:04:25.613: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:26.614: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:26.619: INFO: Number of nodes with available pods: 0
Jan 12 05:04:26.620: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:27.611: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:27.614: INFO: Number of nodes with available pods: 0
Jan 12 05:04:27.614: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:28.616: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:28.623: INFO: Number of nodes with available pods: 0
Jan 12 05:04:28.624: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:29.616: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:29.622: INFO: Number of nodes with available pods: 0
Jan 12 05:04:29.622: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:30.616: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:30.623: INFO: Number of nodes with available pods: 0
Jan 12 05:04:30.623: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:31.612: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:31.616: INFO: Number of nodes with available pods: 0
Jan 12 05:04:31.616: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:32.616: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:32.623: INFO: Number of nodes with available pods: 0
Jan 12 05:04:32.623: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:33.609: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:33.612: INFO: Number of nodes with available pods: 0
Jan 12 05:04:33.612: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:34.610: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:34.613: INFO: Number of nodes with available pods: 0
Jan 12 05:04:34.613: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:04:35.610: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:04:35.614: INFO: Number of nodes with available pods: 1
Jan 12 05:04:35.614: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-d7vnv, will wait for the garbage collector to delete the pods
Jan 12 05:04:35.675: INFO: Deleting DaemonSet.extensions daemon-set took: 5.141414ms
Jan 12 05:04:35.775: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.683651ms
Jan 12 05:05:10.279: INFO: Number of nodes with available pods: 0
Jan 12 05:05:10.279: INFO: Number of running nodes: 0, number of available pods: 0
Jan 12 05:05:10.282: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-d7vnv/daemonsets","resourceVersion":"141901"},"items":null}

Jan 12 05:05:10.285: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-d7vnv/pods","resourceVersion":"141901"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:05:10.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-d7vnv" for this suite.
Jan 12 05:05:16.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:05:16.351: INFO: namespace: e2e-tests-daemonsets-d7vnv, resource: bindings, ignored listing per whitelist
Jan 12 05:05:16.380: INFO: namespace e2e-tests-daemonsets-d7vnv deletion completed in 6.082927352s

• [SLOW TEST:88.005 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:05:16.380: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-ggl5m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Jan 12 05:05:16.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 create -f - --namespace=e2e-tests-kubectl-ggl5m'
Jan 12 05:05:16.729: INFO: stderr: ""
Jan 12 05:05:16.729: INFO: stdout: "pod/pause created\n"
Jan 12 05:05:16.729: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jan 12 05:05:16.729: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-ggl5m" to be "running and ready"
Jan 12 05:05:16.732: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 3.110599ms
Jan 12 05:05:18.738: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.008292773s
Jan 12 05:05:18.738: INFO: Pod "pause" satisfied condition "running and ready"
Jan 12 05:05:18.738: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Jan 12 05:05:18.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-ggl5m'
Jan 12 05:05:18.844: INFO: stderr: ""
Jan 12 05:05:18.844: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jan 12 05:05:18.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pod pause -L testing-label --namespace=e2e-tests-kubectl-ggl5m'
Jan 12 05:05:18.945: INFO: stderr: ""
Jan 12 05:05:18.945: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jan 12 05:05:18.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 label pods pause testing-label- --namespace=e2e-tests-kubectl-ggl5m'
Jan 12 05:05:19.042: INFO: stderr: ""
Jan 12 05:05:19.042: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jan 12 05:05:19.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pod pause -L testing-label --namespace=e2e-tests-kubectl-ggl5m'
Jan 12 05:05:19.129: INFO: stderr: ""
Jan 12 05:05:19.129: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Jan 12 05:05:19.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ggl5m'
Jan 12 05:05:19.194: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 12 05:05:19.195: INFO: stdout: "pod \"pause\" force deleted\n"
Jan 12 05:05:19.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-ggl5m'
Jan 12 05:05:19.282: INFO: stderr: "No resources found.\n"
Jan 12 05:05:19.282: INFO: stdout: ""
Jan 12 05:05:19.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods -l name=pause --namespace=e2e-tests-kubectl-ggl5m -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 12 05:05:19.374: INFO: stderr: ""
Jan 12 05:05:19.374: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:05:19.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ggl5m" for this suite.
Jan 12 05:05:25.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:05:25.429: INFO: namespace: e2e-tests-kubectl-ggl5m, resource: bindings, ignored listing per whitelist
Jan 12 05:05:25.481: INFO: namespace e2e-tests-kubectl-ggl5m deletion completed in 6.103738737s

• [SLOW TEST:9.101 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:05:25.481: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-xv8kx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 12 05:05:25.654: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jan 12 05:05:30.663: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 12 05:05:30.663: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jan 12 05:05:32.669: INFO: Creating deployment "test-rollover-deployment"
Jan 12 05:05:32.682: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jan 12 05:05:34.694: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jan 12 05:05:34.706: INFO: Ensure that both replica sets have 1 created replica
Jan 12 05:05:34.712: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jan 12 05:05:34.720: INFO: Updating deployment test-rollover-deployment
Jan 12 05:05:34.720: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jan 12 05:05:36.749: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jan 12 05:05:36.755: INFO: Make sure deployment "test-rollover-deployment" is complete
Jan 12 05:05:36.761: INFO: all replica sets need to contain the pod-template-hash label
Jan 12 05:05:36.761: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682866332, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682866332, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682866334, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682866332, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 12 05:05:38.776: INFO: all replica sets need to contain the pod-template-hash label
Jan 12 05:05:38.777: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682866332, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682866332, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682866336, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682866332, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 12 05:05:40.767: INFO: all replica sets need to contain the pod-template-hash label
Jan 12 05:05:40.767: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682866332, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682866332, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682866336, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682866332, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 12 05:05:42.771: INFO: all replica sets need to contain the pod-template-hash label
Jan 12 05:05:42.771: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682866332, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682866332, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682866336, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682866332, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 12 05:05:44.780: INFO: all replica sets need to contain the pod-template-hash label
Jan 12 05:05:44.780: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682866332, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682866332, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682866336, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682866332, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 12 05:05:46.774: INFO: all replica sets need to contain the pod-template-hash label
Jan 12 05:05:46.774: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682866332, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682866332, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682866336, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682866332, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 12 05:05:48.777: INFO: 
Jan 12 05:05:48.778: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 12 05:05:48.797: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-xv8kx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xv8kx/deployments/test-rollover-deployment,UID:b02b6ef6-1627-11e9-b7e1-000c294e6ffe,ResourceVersion:142098,Generation:2,CreationTimestamp:2019-01-12 05:05:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-01-12 05:05:32 +0000 UTC 2019-01-12 05:05:32 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-01-12 05:05:46 +0000 UTC 2019-01-12 05:05:32 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan 12 05:05:48.801: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-xv8kx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xv8kx/replicasets/test-rollover-deployment-5b76ff8c4,UID:b16415ce-1627-11e9-b7e1-000c294e6ffe,ResourceVersion:142089,Generation:2,CreationTimestamp:2019-01-12 05:05:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment b02b6ef6-1627-11e9-b7e1-000c294e6ffe 0xc00114e600 0xc00114e601}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 12 05:05:48.801: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jan 12 05:05:48.802: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-xv8kx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xv8kx/replicasets/test-rollover-controller,UID:abfbd407-1627-11e9-b7e1-000c294e6ffe,ResourceVersion:142097,Generation:2,CreationTimestamp:2019-01-12 05:05:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment b02b6ef6-1627-11e9-b7e1-000c294e6ffe 0xc00114e427 0xc00114e428}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 12 05:05:48.802: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-xv8kx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xv8kx/replicasets/test-rollover-deployment-6975f4fb87,UID:b0322a14-1627-11e9-b7e1-000c294e6ffe,ResourceVersion:142051,Generation:2,CreationTimestamp:2019-01-12 05:05:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment b02b6ef6-1627-11e9-b7e1-000c294e6ffe 0xc00114e6f7 0xc00114e6f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 12 05:05:48.807: INFO: Pod "test-rollover-deployment-5b76ff8c4-q8ldb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-q8ldb,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-xv8kx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xv8kx/pods/test-rollover-deployment-5b76ff8c4-q8ldb,UID:b168c5ba-1627-11e9-b7e1-000c294e6ffe,ResourceVersion:142073,Generation:0,CreationTimestamp:2019-01-12 05:05:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 b16415ce-1627-11e9-b7e1-000c294e6ffe 0xc0010353c0 0xc0010353c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwnzt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwnzt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-nwnzt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001035440} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001035460}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 05:05:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 05:05:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 05:05:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 05:05:34 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:172.31.52.87,StartTime:2019-01-12 05:05:34 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-01-12 05:05:35 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://index.tenxcloud.com/tenx_containers/redis@sha256:9b5b1c1ec462abb4b89145a23a1fbf7eb3b2bb25927fc94e820f89a73029889f docker://9fbcb9eac2078d51d4cb1e18e83a0a149e9397d4d32a3f7852d697feb5204d35}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:05:48.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-xv8kx" for this suite.
Jan 12 05:05:54.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:05:54.899: INFO: namespace: e2e-tests-deployment-xv8kx, resource: bindings, ignored listing per whitelist
Jan 12 05:05:54.914: INFO: namespace e2e-tests-deployment-xv8kx deletion completed in 6.101848398s

• [SLOW TEST:29.433 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:05:54.914: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-q6cnh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 12 05:05:55.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-q6cnh'
Jan 12 05:05:55.177: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan 12 05:05:55.177: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Jan 12 05:05:57.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-q6cnh'
Jan 12 05:05:57.284: INFO: stderr: ""
Jan 12 05:05:57.284: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:05:57.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-q6cnh" for this suite.
Jan 12 05:06:13.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:06:13.344: INFO: namespace: e2e-tests-kubectl-q6cnh, resource: bindings, ignored listing per whitelist
Jan 12 05:06:13.391: INFO: namespace e2e-tests-kubectl-q6cnh deletion completed in 16.103122537s

• [SLOW TEST:18.477 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:06:13.392: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-dftwl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan 12 05:06:13.558: INFO: Waiting up to 5m0s for pod "pod-c889ea14-1627-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-emptydir-dftwl" to be "success or failure"
Jan 12 05:06:13.561: INFO: Pod "pod-c889ea14-1627-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 3.114006ms
Jan 12 05:06:15.565: INFO: Pod "pod-c889ea14-1627-11e9-8fb7-aa4233c46d55": Phase="Running", Reason="", readiness=true. Elapsed: 2.006662645s
Jan 12 05:06:17.571: INFO: Pod "pod-c889ea14-1627-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012708256s
STEP: Saw pod success
Jan 12 05:06:17.571: INFO: Pod "pod-c889ea14-1627-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:06:17.573: INFO: Trying to get logs from node c76-1-41 pod pod-c889ea14-1627-11e9-8fb7-aa4233c46d55 container test-container: <nil>
STEP: delete the pod
Jan 12 05:06:17.591: INFO: Waiting for pod pod-c889ea14-1627-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:06:17.593: INFO: Pod pod-c889ea14-1627-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:06:17.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dftwl" for this suite.
Jan 12 05:06:23.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:06:23.667: INFO: namespace: e2e-tests-emptydir-dftwl, resource: bindings, ignored listing per whitelist
Jan 12 05:06:23.704: INFO: namespace e2e-tests-emptydir-dftwl deletion completed in 6.108080078s

• [SLOW TEST:10.313 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:06:23.704: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-tnlff
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-tnlff
Jan 12 05:06:27.893: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-tnlff
STEP: checking the pod's current state and verifying that restartCount is present
Jan 12 05:06:27.897: INFO: Initial restart count of pod liveness-http is 0
Jan 12 05:06:51.971: INFO: Restart count of pod e2e-tests-container-probe-tnlff/liveness-http is now 1 (24.074349514s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:06:51.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-tnlff" for this suite.
Jan 12 05:06:58.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:06:58.086: INFO: namespace: e2e-tests-container-probe-tnlff, resource: bindings, ignored listing per whitelist
Jan 12 05:06:58.110: INFO: namespace e2e-tests-container-probe-tnlff deletion completed in 6.108816773s

• [SLOW TEST:34.406 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:06:58.111: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-bg2xs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan 12 05:07:02.375: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 12 05:07:02.386: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 12 05:07:04.387: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 12 05:07:04.391: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 12 05:07:06.387: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 12 05:07:06.395: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 12 05:07:08.387: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 12 05:07:08.397: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 12 05:07:10.387: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 12 05:07:10.396: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 12 05:07:12.387: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 12 05:07:12.390: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 12 05:07:14.387: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 12 05:07:14.396: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 12 05:07:16.387: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 12 05:07:16.396: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 12 05:07:18.388: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 12 05:07:18.396: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 12 05:07:20.387: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 12 05:07:20.399: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 12 05:07:22.388: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 12 05:07:22.395: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 12 05:07:24.387: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 12 05:07:24.392: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:07:24.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-bg2xs" for this suite.
Jan 12 05:07:46.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:07:46.492: INFO: namespace: e2e-tests-container-lifecycle-hook-bg2xs, resource: bindings, ignored listing per whitelist
Jan 12 05:07:46.525: INFO: namespace e2e-tests-container-lifecycle-hook-bg2xs deletion completed in 22.116341223s

• [SLOW TEST:48.415 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:07:46.526: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-6pdrb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Jan 12 05:07:46.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 api-versions'
Jan 12 05:07:46.820: INFO: stderr: ""
Jan 12 05:07:46.820: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:07:46.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6pdrb" for this suite.
Jan 12 05:07:52.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:07:52.928: INFO: namespace: e2e-tests-kubectl-6pdrb, resource: bindings, ignored listing per whitelist
Jan 12 05:07:52.938: INFO: namespace e2e-tests-kubectl-6pdrb deletion completed in 6.114189049s

• [SLOW TEST:6.412 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:07:52.938: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-rvl4k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Jan 12 05:07:53.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 create -f - --namespace=e2e-tests-kubectl-rvl4k'
Jan 12 05:07:53.314: INFO: stderr: ""
Jan 12 05:07:53.314: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 12 05:07:53.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rvl4k'
Jan 12 05:07:53.442: INFO: stderr: ""
Jan 12 05:07:53.442: INFO: stdout: "update-demo-nautilus-fnq6j update-demo-nautilus-klwws "
Jan 12 05:07:53.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-nautilus-fnq6j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rvl4k'
Jan 12 05:07:53.537: INFO: stderr: ""
Jan 12 05:07:53.537: INFO: stdout: ""
Jan 12 05:07:53.537: INFO: update-demo-nautilus-fnq6j is created but not running
Jan 12 05:07:58.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rvl4k'
Jan 12 05:07:58.668: INFO: stderr: ""
Jan 12 05:07:58.668: INFO: stdout: "update-demo-nautilus-fnq6j update-demo-nautilus-klwws "
Jan 12 05:07:58.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-nautilus-fnq6j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rvl4k'
Jan 12 05:07:58.729: INFO: stderr: ""
Jan 12 05:07:58.729: INFO: stdout: "true"
Jan 12 05:07:58.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-nautilus-fnq6j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rvl4k'
Jan 12 05:07:58.795: INFO: stderr: ""
Jan 12 05:07:58.795: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 12 05:07:58.795: INFO: validating pod update-demo-nautilus-fnq6j
Jan 12 05:07:58.801: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 12 05:07:58.801: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 12 05:07:58.801: INFO: update-demo-nautilus-fnq6j is verified up and running
Jan 12 05:07:58.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-nautilus-klwws -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rvl4k'
Jan 12 05:07:58.865: INFO: stderr: ""
Jan 12 05:07:58.865: INFO: stdout: "true"
Jan 12 05:07:58.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-nautilus-klwws -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rvl4k'
Jan 12 05:07:58.947: INFO: stderr: ""
Jan 12 05:07:58.947: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 12 05:07:58.947: INFO: validating pod update-demo-nautilus-klwws
Jan 12 05:07:58.954: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 12 05:07:58.954: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 12 05:07:58.954: INFO: update-demo-nautilus-klwws is verified up and running
STEP: rolling-update to new replication controller
Jan 12 05:07:58.955: INFO: scanned /root for discovery docs: <nil>
Jan 12 05:07:58.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-rvl4k'
Jan 12 05:08:21.453: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan 12 05:08:21.453: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 12 05:08:21.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rvl4k'
Jan 12 05:08:21.534: INFO: stderr: ""
Jan 12 05:08:21.534: INFO: stdout: "update-demo-kitten-prms7 update-demo-kitten-ws5m8 "
Jan 12 05:08:21.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-kitten-prms7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rvl4k'
Jan 12 05:08:21.596: INFO: stderr: ""
Jan 12 05:08:21.596: INFO: stdout: "true"
Jan 12 05:08:21.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-kitten-prms7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rvl4k'
Jan 12 05:08:21.661: INFO: stderr: ""
Jan 12 05:08:21.661: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan 12 05:08:21.661: INFO: validating pod update-demo-kitten-prms7
Jan 12 05:08:21.667: INFO: got data: {
  "image": "kitten.jpg"
}

Jan 12 05:08:21.667: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan 12 05:08:21.667: INFO: update-demo-kitten-prms7 is verified up and running
Jan 12 05:08:21.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-kitten-ws5m8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rvl4k'
Jan 12 05:08:21.732: INFO: stderr: ""
Jan 12 05:08:21.732: INFO: stdout: "true"
Jan 12 05:08:21.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods update-demo-kitten-ws5m8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rvl4k'
Jan 12 05:08:21.795: INFO: stderr: ""
Jan 12 05:08:21.795: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan 12 05:08:21.795: INFO: validating pod update-demo-kitten-ws5m8
Jan 12 05:08:21.801: INFO: got data: {
  "image": "kitten.jpg"
}

Jan 12 05:08:21.801: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan 12 05:08:21.801: INFO: update-demo-kitten-ws5m8 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:08:21.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rvl4k" for this suite.
Jan 12 05:08:43.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:08:43.905: INFO: namespace: e2e-tests-kubectl-rvl4k, resource: bindings, ignored listing per whitelist
Jan 12 05:08:43.926: INFO: namespace e2e-tests-kubectl-rvl4k deletion completed in 22.121178698s

• [SLOW TEST:50.988 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:08:43.926: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-75kq7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 12 05:08:44.104: INFO: (0) /api/v1/nodes/c76-1-41/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 7.484894ms)
Jan 12 05:08:44.110: INFO: (1) /api/v1/nodes/c76-1-41/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 5.565107ms)
Jan 12 05:08:44.115: INFO: (2) /api/v1/nodes/c76-1-41/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 5.3916ms)
Jan 12 05:08:44.120: INFO: (3) /api/v1/nodes/c76-1-41/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 4.775304ms)
Jan 12 05:08:44.125: INFO: (4) /api/v1/nodes/c76-1-41/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 4.726531ms)
Jan 12 05:08:44.130: INFO: (5) /api/v1/nodes/c76-1-41/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 5.305106ms)
Jan 12 05:08:44.136: INFO: (6) /api/v1/nodes/c76-1-41/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 5.378829ms)
Jan 12 05:08:44.139: INFO: (7) /api/v1/nodes/c76-1-41/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.371955ms)
Jan 12 05:08:44.143: INFO: (8) /api/v1/nodes/c76-1-41/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.291262ms)
Jan 12 05:08:44.146: INFO: (9) /api/v1/nodes/c76-1-41/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.235703ms)
Jan 12 05:08:44.149: INFO: (10) /api/v1/nodes/c76-1-41/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.042088ms)
Jan 12 05:08:44.152: INFO: (11) /api/v1/nodes/c76-1-41/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.385468ms)
Jan 12 05:08:44.156: INFO: (12) /api/v1/nodes/c76-1-41/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.429132ms)
Jan 12 05:08:44.160: INFO: (13) /api/v1/nodes/c76-1-41/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.594492ms)
Jan 12 05:08:44.163: INFO: (14) /api/v1/nodes/c76-1-41/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.229638ms)
Jan 12 05:08:44.166: INFO: (15) /api/v1/nodes/c76-1-41/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 3.362416ms)
Jan 12 05:08:44.169: INFO: (16) /api/v1/nodes/c76-1-41/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 2.769612ms)
Jan 12 05:08:44.172: INFO: (17) /api/v1/nodes/c76-1-41/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 2.766681ms)
Jan 12 05:08:44.175: INFO: (18) /api/v1/nodes/c76-1-41/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 2.991886ms)
Jan 12 05:08:44.178: INFO: (19) /api/v1/nodes/c76-1-41/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="boot.log-20190110.gz">boot.log-20190110.gz</a>
<a ... (200; 2.717959ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:08:44.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-75kq7" for this suite.
Jan 12 05:08:50.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:08:50.252: INFO: namespace: e2e-tests-proxy-75kq7, resource: bindings, ignored listing per whitelist
Jan 12 05:08:50.304: INFO: namespace e2e-tests-proxy-75kq7 deletion completed in 6.123733674s

• [SLOW TEST:6.378 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:08:50.304: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-cfcd4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-cfcd4
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Jan 12 05:08:50.490: INFO: Found 0 stateful pods, waiting for 3
Jan 12 05:09:00.499: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 12 05:09:00.499: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 12 05:09:00.499: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jan 12 05:09:00.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 exec --namespace=e2e-tests-statefulset-cfcd4 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 12 05:09:00.717: INFO: stderr: ""
Jan 12 05:09:00.717: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 12 05:09:00.717: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan 12 05:09:10.752: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jan 12 05:09:20.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 exec --namespace=e2e-tests-statefulset-cfcd4 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 12 05:09:20.932: INFO: stderr: ""
Jan 12 05:09:20.932: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 12 05:09:20.932: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 12 05:09:31.025: INFO: Waiting for StatefulSet e2e-tests-statefulset-cfcd4/ss2 to complete update
Jan 12 05:09:31.025: INFO: Waiting for Pod e2e-tests-statefulset-cfcd4/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 12 05:09:41.040: INFO: Waiting for StatefulSet e2e-tests-statefulset-cfcd4/ss2 to complete update
Jan 12 05:09:41.040: INFO: Waiting for Pod e2e-tests-statefulset-cfcd4/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Jan 12 05:09:51.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 exec --namespace=e2e-tests-statefulset-cfcd4 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 12 05:09:51.206: INFO: stderr: ""
Jan 12 05:09:51.206: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 12 05:09:51.206: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 12 05:10:01.243: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jan 12 05:10:11.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 exec --namespace=e2e-tests-statefulset-cfcd4 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 12 05:10:11.414: INFO: stderr: ""
Jan 12 05:10:11.414: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 12 05:10:11.414: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 12 05:10:21.445: INFO: Waiting for StatefulSet e2e-tests-statefulset-cfcd4/ss2 to complete update
Jan 12 05:10:21.445: INFO: Waiting for Pod e2e-tests-statefulset-cfcd4/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 12 05:10:31.460: INFO: Deleting all statefulset in ns e2e-tests-statefulset-cfcd4
Jan 12 05:10:31.465: INFO: Scaling statefulset ss2 to 0
Jan 12 05:11:01.489: INFO: Waiting for statefulset status.replicas updated to 0
Jan 12 05:11:01.498: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:11:01.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-cfcd4" for this suite.
Jan 12 05:11:07.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:11:07.556: INFO: namespace: e2e-tests-statefulset-cfcd4, resource: bindings, ignored listing per whitelist
Jan 12 05:11:07.627: INFO: namespace e2e-tests-statefulset-cfcd4 deletion completed in 6.097540772s

• [SLOW TEST:137.323 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:11:07.627: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-pgfc6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan 12 05:11:07.802: INFO: Waiting up to 5m0s for pod "pod-77eb92ec-1628-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-emptydir-pgfc6" to be "success or failure"
Jan 12 05:11:07.806: INFO: Pod "pod-77eb92ec-1628-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 3.945319ms
Jan 12 05:11:09.809: INFO: Pod "pod-77eb92ec-1628-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007326805s
STEP: Saw pod success
Jan 12 05:11:09.809: INFO: Pod "pod-77eb92ec-1628-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:11:09.812: INFO: Trying to get logs from node c76-1-41 pod pod-77eb92ec-1628-11e9-8fb7-aa4233c46d55 container test-container: <nil>
STEP: delete the pod
Jan 12 05:11:09.846: INFO: Waiting for pod pod-77eb92ec-1628-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:11:09.861: INFO: Pod pod-77eb92ec-1628-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:11:09.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pgfc6" for this suite.
Jan 12 05:11:15.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:11:15.969: INFO: namespace: e2e-tests-emptydir-pgfc6, resource: bindings, ignored listing per whitelist
Jan 12 05:11:15.986: INFO: namespace e2e-tests-emptydir-pgfc6 deletion completed in 6.118412176s

• [SLOW TEST:8.359 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:11:15.987: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-ngwv9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-7ce67b28-1628-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume configMaps
Jan 12 05:11:16.159: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7ce6fded-1628-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-projected-ngwv9" to be "success or failure"
Jan 12 05:11:16.172: INFO: Pod "pod-projected-configmaps-7ce6fded-1628-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 12.952361ms
Jan 12 05:11:18.175: INFO: Pod "pod-projected-configmaps-7ce6fded-1628-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015885206s
STEP: Saw pod success
Jan 12 05:11:18.175: INFO: Pod "pod-projected-configmaps-7ce6fded-1628-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:11:18.177: INFO: Trying to get logs from node c76-1-41 pod pod-projected-configmaps-7ce6fded-1628-11e9-8fb7-aa4233c46d55 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 12 05:11:18.195: INFO: Waiting for pod pod-projected-configmaps-7ce6fded-1628-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:11:18.198: INFO: Pod pod-projected-configmaps-7ce6fded-1628-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:11:18.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ngwv9" for this suite.
Jan 12 05:11:24.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:11:24.267: INFO: namespace: e2e-tests-projected-ngwv9, resource: bindings, ignored listing per whitelist
Jan 12 05:11:24.311: INFO: namespace e2e-tests-projected-ngwv9 deletion completed in 6.110205776s

• [SLOW TEST:8.325 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:11:24.312: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-g4z89
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-g4z89
I0112 05:11:24.477552      18 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-g4z89, replica count: 1
I0112 05:11:25.529619      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0112 05:11:26.530513      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 12 05:11:26.669: INFO: Created: latency-svc-x9sxt
Jan 12 05:11:26.714: INFO: Got endpoints: latency-svc-x9sxt [82.75529ms]
Jan 12 05:11:26.734: INFO: Created: latency-svc-gtfnp
Jan 12 05:11:26.740: INFO: Got endpoints: latency-svc-gtfnp [26.758772ms]
Jan 12 05:11:26.760: INFO: Created: latency-svc-pmpch
Jan 12 05:11:26.767: INFO: Got endpoints: latency-svc-pmpch [52.606165ms]
Jan 12 05:11:26.789: INFO: Created: latency-svc-s44tk
Jan 12 05:11:26.820: INFO: Got endpoints: latency-svc-s44tk [105.454753ms]
Jan 12 05:11:26.829: INFO: Created: latency-svc-nftpp
Jan 12 05:11:26.829: INFO: Got endpoints: latency-svc-nftpp [113.462124ms]
Jan 12 05:11:26.837: INFO: Created: latency-svc-wl7q8
Jan 12 05:11:26.859: INFO: Got endpoints: latency-svc-wl7q8 [144.496068ms]
Jan 12 05:11:26.890: INFO: Created: latency-svc-75qq2
Jan 12 05:11:26.899: INFO: Created: latency-svc-cjgsx
Jan 12 05:11:26.899: INFO: Got endpoints: latency-svc-75qq2 [184.198342ms]
Jan 12 05:11:26.925: INFO: Got endpoints: latency-svc-cjgsx [209.835234ms]
Jan 12 05:11:26.926: INFO: Created: latency-svc-j2x5t
Jan 12 05:11:26.942: INFO: Got endpoints: latency-svc-j2x5t [226.776315ms]
Jan 12 05:11:26.944: INFO: Created: latency-svc-5sz5p
Jan 12 05:11:26.949: INFO: Got endpoints: latency-svc-5sz5p [234.776154ms]
Jan 12 05:11:26.968: INFO: Created: latency-svc-cc4hk
Jan 12 05:11:26.986: INFO: Got endpoints: latency-svc-cc4hk [271.259935ms]
Jan 12 05:11:26.998: INFO: Created: latency-svc-j7x7c
Jan 12 05:11:27.004: INFO: Got endpoints: latency-svc-j7x7c [54.590098ms]
Jan 12 05:11:27.022: INFO: Created: latency-svc-p8l9z
Jan 12 05:11:27.035: INFO: Created: latency-svc-z4fb9
Jan 12 05:11:27.066: INFO: Got endpoints: latency-svc-z4fb9 [351.178041ms]
Jan 12 05:11:27.066: INFO: Got endpoints: latency-svc-p8l9z [351.225001ms]
Jan 12 05:11:27.099: INFO: Created: latency-svc-qgmqt
Jan 12 05:11:27.099: INFO: Got endpoints: latency-svc-qgmqt [384.299431ms]
Jan 12 05:11:27.115: INFO: Created: latency-svc-7mh7c
Jan 12 05:11:27.115: INFO: Got endpoints: latency-svc-7mh7c [399.52357ms]
Jan 12 05:11:27.127: INFO: Created: latency-svc-pdcfz
Jan 12 05:11:27.131: INFO: Got endpoints: latency-svc-pdcfz [416.888984ms]
Jan 12 05:11:27.149: INFO: Created: latency-svc-zchts
Jan 12 05:11:27.175: INFO: Got endpoints: latency-svc-zchts [434.357904ms]
Jan 12 05:11:27.178: INFO: Created: latency-svc-qjwmb
Jan 12 05:11:27.182: INFO: Got endpoints: latency-svc-qjwmb [415.044555ms]
Jan 12 05:11:27.215: INFO: Created: latency-svc-42bj4
Jan 12 05:11:27.224: INFO: Created: latency-svc-pfc2h
Jan 12 05:11:27.224: INFO: Got endpoints: latency-svc-42bj4 [404.644238ms]
Jan 12 05:11:27.232: INFO: Got endpoints: latency-svc-pfc2h [403.182018ms]
Jan 12 05:11:27.238: INFO: Created: latency-svc-xtzgs
Jan 12 05:11:27.260: INFO: Got endpoints: latency-svc-xtzgs [401.284852ms]
Jan 12 05:11:27.272: INFO: Created: latency-svc-plbj6
Jan 12 05:11:27.287: INFO: Got endpoints: latency-svc-plbj6 [388.18657ms]
Jan 12 05:11:27.298: INFO: Created: latency-svc-7bl82
Jan 12 05:11:27.303: INFO: Got endpoints: latency-svc-7bl82 [377.875243ms]
Jan 12 05:11:27.331: INFO: Created: latency-svc-n9qjp
Jan 12 05:11:27.368: INFO: Got endpoints: latency-svc-n9qjp [426.106569ms]
Jan 12 05:11:27.373: INFO: Created: latency-svc-z9hsx
Jan 12 05:11:27.381: INFO: Got endpoints: latency-svc-z9hsx [395.005787ms]
Jan 12 05:11:27.408: INFO: Created: latency-svc-njzb4
Jan 12 05:11:27.429: INFO: Got endpoints: latency-svc-njzb4 [425.223144ms]
Jan 12 05:11:27.434: INFO: Created: latency-svc-9c5r9
Jan 12 05:11:27.446: INFO: Got endpoints: latency-svc-9c5r9 [379.522104ms]
Jan 12 05:11:27.477: INFO: Created: latency-svc-t8c8p
Jan 12 05:11:27.487: INFO: Got endpoints: latency-svc-t8c8p [420.924949ms]
Jan 12 05:11:27.564: INFO: Created: latency-svc-bhdqf
Jan 12 05:11:27.574: INFO: Got endpoints: latency-svc-bhdqf [475.494203ms]
Jan 12 05:11:27.584: INFO: Created: latency-svc-2bp8l
Jan 12 05:11:27.597: INFO: Got endpoints: latency-svc-2bp8l [482.605213ms]
Jan 12 05:11:27.633: INFO: Created: latency-svc-grg7h
Jan 12 05:11:27.653: INFO: Got endpoints: latency-svc-grg7h [521.021756ms]
Jan 12 05:11:27.675: INFO: Created: latency-svc-xsth4
Jan 12 05:11:27.705: INFO: Got endpoints: latency-svc-xsth4 [530.011145ms]
Jan 12 05:11:27.717: INFO: Created: latency-svc-zxxsw
Jan 12 05:11:27.722: INFO: Got endpoints: latency-svc-zxxsw [539.788991ms]
Jan 12 05:11:27.733: INFO: Created: latency-svc-sw7l5
Jan 12 05:11:27.733: INFO: Got endpoints: latency-svc-sw7l5 [508.14417ms]
Jan 12 05:11:27.760: INFO: Created: latency-svc-vcs8b
Jan 12 05:11:27.769: INFO: Got endpoints: latency-svc-vcs8b [536.679555ms]
Jan 12 05:11:27.792: INFO: Created: latency-svc-ms7sn
Jan 12 05:11:27.800: INFO: Got endpoints: latency-svc-ms7sn [539.505333ms]
Jan 12 05:11:27.812: INFO: Created: latency-svc-8jk8m
Jan 12 05:11:27.832: INFO: Got endpoints: latency-svc-8jk8m [544.514649ms]
Jan 12 05:11:27.845: INFO: Created: latency-svc-5scbw
Jan 12 05:11:27.891: INFO: Got endpoints: latency-svc-5scbw [588.43788ms]
Jan 12 05:11:27.892: INFO: Created: latency-svc-2pvrv
Jan 12 05:11:27.892: INFO: Got endpoints: latency-svc-2pvrv [522.630264ms]
Jan 12 05:11:27.916: INFO: Created: latency-svc-lhkqz
Jan 12 05:11:27.916: INFO: Created: latency-svc-5q2pl
Jan 12 05:11:27.916: INFO: Got endpoints: latency-svc-5q2pl [535.041579ms]
Jan 12 05:11:27.940: INFO: Created: latency-svc-hcjxx
Jan 12 05:11:27.940: INFO: Got endpoints: latency-svc-lhkqz [510.972849ms]
Jan 12 05:11:27.964: INFO: Got endpoints: latency-svc-hcjxx [518.123924ms]
Jan 12 05:11:27.989: INFO: Created: latency-svc-lw6wq
Jan 12 05:11:28.231: INFO: Got endpoints: latency-svc-lw6wq [744.053494ms]
Jan 12 05:11:28.232: INFO: Created: latency-svc-dqvqw
Jan 12 05:11:28.232: INFO: Created: latency-svc-crj9p
Jan 12 05:11:28.232: INFO: Got endpoints: latency-svc-dqvqw [634.347249ms]
Jan 12 05:11:28.232: INFO: Got endpoints: latency-svc-crj9p [657.464159ms]
Jan 12 05:11:28.278: INFO: Created: latency-svc-s78qm
Jan 12 05:11:28.283: INFO: Got endpoints: latency-svc-s78qm [630.573235ms]
Jan 12 05:11:28.342: INFO: Created: latency-svc-t66zz
Jan 12 05:11:28.342: INFO: Got endpoints: latency-svc-t66zz [637.08987ms]
Jan 12 05:11:28.349: INFO: Created: latency-svc-x8f4x
Jan 12 05:11:28.357: INFO: Got endpoints: latency-svc-x8f4x [635.80329ms]
Jan 12 05:11:28.362: INFO: Created: latency-svc-df9kd
Jan 12 05:11:28.369: INFO: Created: latency-svc-7fwv2
Jan 12 05:11:28.369: INFO: Got endpoints: latency-svc-df9kd [636.176963ms]
Jan 12 05:11:28.404: INFO: Created: latency-svc-2t75j
Jan 12 05:11:28.482: INFO: Got endpoints: latency-svc-7fwv2 [713.623234ms]
Jan 12 05:11:28.483: INFO: Got endpoints: latency-svc-2t75j [682.881895ms]
Jan 12 05:11:28.513: INFO: Created: latency-svc-6rc5q
Jan 12 05:11:28.517: INFO: Got endpoints: latency-svc-6rc5q [685.303628ms]
Jan 12 05:11:28.554: INFO: Created: latency-svc-dn7v7
Jan 12 05:11:28.557: INFO: Got endpoints: latency-svc-dn7v7 [666.314319ms]
Jan 12 05:11:28.565: INFO: Created: latency-svc-s4zfk
Jan 12 05:11:28.583: INFO: Got endpoints: latency-svc-s4zfk [691.084363ms]
Jan 12 05:11:28.583: INFO: Created: latency-svc-zzgpc
Jan 12 05:11:28.590: INFO: Got endpoints: latency-svc-zzgpc [673.904071ms]
Jan 12 05:11:28.600: INFO: Created: latency-svc-t578s
Jan 12 05:11:28.638: INFO: Got endpoints: latency-svc-t578s [698.192233ms]
Jan 12 05:11:28.657: INFO: Created: latency-svc-hjff2
Jan 12 05:11:28.657: INFO: Got endpoints: latency-svc-hjff2 [693.432982ms]
Jan 12 05:11:28.688: INFO: Created: latency-svc-66nh6
Jan 12 05:11:28.700: INFO: Got endpoints: latency-svc-66nh6 [468.454948ms]
Jan 12 05:11:28.704: INFO: Created: latency-svc-rv6zc
Jan 12 05:11:28.745: INFO: Got endpoints: latency-svc-rv6zc [513.709324ms]
Jan 12 05:11:28.788: INFO: Created: latency-svc-lhhnj
Jan 12 05:11:28.847: INFO: Created: latency-svc-9d276
Jan 12 05:11:28.847: INFO: Got endpoints: latency-svc-lhhnj [615.449272ms]
Jan 12 05:11:28.874: INFO: Created: latency-svc-m9jcj
Jan 12 05:11:28.874: INFO: Got endpoints: latency-svc-9d276 [582.096398ms]
Jan 12 05:11:28.895: INFO: Created: latency-svc-vlmzt
Jan 12 05:11:28.897: INFO: Got endpoints: latency-svc-m9jcj [554.889008ms]
Jan 12 05:11:28.919: INFO: Created: latency-svc-msxzz
Jan 12 05:11:28.919: INFO: Got endpoints: latency-svc-msxzz [550.474309ms]
Jan 12 05:11:28.919: INFO: Got endpoints: latency-svc-vlmzt [561.887913ms]
Jan 12 05:11:28.982: INFO: Created: latency-svc-drk5l
Jan 12 05:11:28.982: INFO: Created: latency-svc-ksrj7
Jan 12 05:11:28.982: INFO: Created: latency-svc-8t884
Jan 12 05:11:28.982: INFO: Got endpoints: latency-svc-drk5l [464.896884ms]
Jan 12 05:11:28.982: INFO: Got endpoints: latency-svc-ksrj7 [500.195045ms]
Jan 12 05:11:28.983: INFO: Got endpoints: latency-svc-8t884 [499.625638ms]
Jan 12 05:11:28.995: INFO: Created: latency-svc-p8sq5
Jan 12 05:11:28.995: INFO: Got endpoints: latency-svc-p8sq5 [437.622246ms]
Jan 12 05:11:29.035: INFO: Created: latency-svc-2sdjh
Jan 12 05:11:29.040: INFO: Got endpoints: latency-svc-2sdjh [449.910707ms]
Jan 12 05:11:29.093: INFO: Created: latency-svc-zrk7v
Jan 12 05:11:29.093: INFO: Got endpoints: latency-svc-zrk7v [509.952048ms]
Jan 12 05:11:29.108: INFO: Created: latency-svc-95zvd
Jan 12 05:11:29.113: INFO: Got endpoints: latency-svc-95zvd [474.23405ms]
Jan 12 05:11:29.116: INFO: Created: latency-svc-nhxst
Jan 12 05:11:29.143: INFO: Got endpoints: latency-svc-nhxst [485.768604ms]
Jan 12 05:11:29.153: INFO: Created: latency-svc-9lqs4
Jan 12 05:11:29.153: INFO: Got endpoints: latency-svc-9lqs4 [453.736802ms]
Jan 12 05:11:29.163: INFO: Created: latency-svc-6zdvc
Jan 12 05:11:29.169: INFO: Got endpoints: latency-svc-6zdvc [423.741041ms]
Jan 12 05:11:29.212: INFO: Created: latency-svc-kd4x8
Jan 12 05:11:29.215: INFO: Got endpoints: latency-svc-kd4x8 [368.073127ms]
Jan 12 05:11:29.230: INFO: Created: latency-svc-p5tzc
Jan 12 05:11:29.239: INFO: Got endpoints: latency-svc-p5tzc [365.691569ms]
Jan 12 05:11:29.249: INFO: Created: latency-svc-q45qh
Jan 12 05:11:29.271: INFO: Got endpoints: latency-svc-q45qh [374.46653ms]
Jan 12 05:11:29.295: INFO: Created: latency-svc-mzqsr
Jan 12 05:11:29.295: INFO: Created: latency-svc-f5qn7
Jan 12 05:11:29.304: INFO: Got endpoints: latency-svc-f5qn7 [384.605079ms]
Jan 12 05:11:29.344: INFO: Got endpoints: latency-svc-mzqsr [424.311429ms]
Jan 12 05:11:29.362: INFO: Created: latency-svc-kzhqg
Jan 12 05:11:29.365: INFO: Got endpoints: latency-svc-kzhqg [382.91072ms]
Jan 12 05:11:29.380: INFO: Created: latency-svc-99cr7
Jan 12 05:11:29.387: INFO: Got endpoints: latency-svc-99cr7 [404.681371ms]
Jan 12 05:11:29.412: INFO: Created: latency-svc-57k2b
Jan 12 05:11:29.425: INFO: Got endpoints: latency-svc-57k2b [442.529114ms]
Jan 12 05:11:29.445: INFO: Created: latency-svc-s9dg9
Jan 12 05:11:29.456: INFO: Got endpoints: latency-svc-s9dg9 [461.244033ms]
Jan 12 05:11:29.457: INFO: Created: latency-svc-f4hzj
Jan 12 05:11:29.481: INFO: Got endpoints: latency-svc-f4hzj [440.685831ms]
Jan 12 05:11:29.534: INFO: Created: latency-svc-s24pl
Jan 12 05:11:29.547: INFO: Got endpoints: latency-svc-s24pl [454.214234ms]
Jan 12 05:11:29.588: INFO: Created: latency-svc-fnph7
Jan 12 05:11:29.592: INFO: Got endpoints: latency-svc-fnph7 [479.800605ms]
Jan 12 05:11:29.615: INFO: Created: latency-svc-5w5n4
Jan 12 05:11:29.621: INFO: Got endpoints: latency-svc-5w5n4 [477.65395ms]
Jan 12 05:11:29.639: INFO: Created: latency-svc-mjbh4
Jan 12 05:11:29.659: INFO: Got endpoints: latency-svc-mjbh4 [506.01758ms]
Jan 12 05:11:29.670: INFO: Created: latency-svc-4t9md
Jan 12 05:11:29.674: INFO: Created: latency-svc-2tdsv
Jan 12 05:11:29.693: INFO: Got endpoints: latency-svc-4t9md [524.095642ms]
Jan 12 05:11:29.751: INFO: Got endpoints: latency-svc-2tdsv [535.295017ms]
Jan 12 05:11:29.755: INFO: Created: latency-svc-pp7ls
Jan 12 05:11:29.790: INFO: Created: latency-svc-mnmhd
Jan 12 05:11:29.793: INFO: Got endpoints: latency-svc-pp7ls [554.054043ms]
Jan 12 05:11:29.802: INFO: Created: latency-svc-xp6qj
Jan 12 05:11:29.838: INFO: Created: latency-svc-trszd
Jan 12 05:11:29.838: INFO: Created: latency-svc-rgnld
Jan 12 05:11:29.841: INFO: Got endpoints: latency-svc-mnmhd [569.53852ms]
Jan 12 05:11:29.844: INFO: Created: latency-svc-w44xj
Jan 12 05:11:29.867: INFO: Created: latency-svc-m2lsx
Jan 12 05:11:29.878: INFO: Created: latency-svc-cxpfj
Jan 12 05:11:29.881: INFO: Created: latency-svc-v76tz
Jan 12 05:11:29.898: INFO: Got endpoints: latency-svc-xp6qj [594.365062ms]
Jan 12 05:11:29.914: INFO: Created: latency-svc-kwc66
Jan 12 05:11:29.951: INFO: Created: latency-svc-vrtnl
Jan 12 05:11:29.951: INFO: Created: latency-svc-td8gv
Jan 12 05:11:29.951: INFO: Got endpoints: latency-svc-rgnld [607.453701ms]
Jan 12 05:11:29.964: INFO: Created: latency-svc-rdjbn
Jan 12 05:11:29.969: INFO: Created: latency-svc-n2mms
Jan 12 05:11:29.982: INFO: Created: latency-svc-5t9l8
Jan 12 05:11:30.011: INFO: Created: latency-svc-m2dpz
Jan 12 05:11:30.034: INFO: Got endpoints: latency-svc-trszd [661.927003ms]
Jan 12 05:11:30.039: INFO: Created: latency-svc-5kg69
Jan 12 05:11:30.042: INFO: Got endpoints: latency-svc-w44xj [655.127366ms]
Jan 12 05:11:30.059: INFO: Created: latency-svc-t4wk4
Jan 12 05:11:30.131: INFO: Created: latency-svc-mpxwn
Jan 12 05:11:30.131: INFO: Created: latency-svc-h84zh
Jan 12 05:11:30.131: INFO: Got endpoints: latency-svc-m2lsx [706.162104ms]
Jan 12 05:11:30.156: INFO: Created: latency-svc-mkw8f
Jan 12 05:11:30.182: INFO: Got endpoints: latency-svc-cxpfj [725.665428ms]
Jan 12 05:11:30.183: INFO: Created: latency-svc-thr28
Jan 12 05:11:30.211: INFO: Got endpoints: latency-svc-v76tz [730.031204ms]
Jan 12 05:11:30.222: INFO: Created: latency-svc-dwrxx
Jan 12 05:11:30.230: INFO: Created: latency-svc-wsx7v
Jan 12 05:11:30.292: INFO: Got endpoints: latency-svc-kwc66 [745.103051ms]
Jan 12 05:11:30.294: INFO: Got endpoints: latency-svc-td8gv [701.388282ms]
Jan 12 05:11:30.311: INFO: Created: latency-svc-n8svs
Jan 12 05:11:30.316: INFO: Created: latency-svc-c6m49
Jan 12 05:11:30.340: INFO: Got endpoints: latency-svc-vrtnl [718.754293ms]
Jan 12 05:11:30.372: INFO: Created: latency-svc-5dj4h
Jan 12 05:11:30.392: INFO: Got endpoints: latency-svc-rdjbn [732.991429ms]
Jan 12 05:11:30.403: INFO: Created: latency-svc-jwfkd
Jan 12 05:11:30.442: INFO: Got endpoints: latency-svc-n2mms [748.309226ms]
Jan 12 05:11:30.460: INFO: Created: latency-svc-9v5m7
Jan 12 05:11:30.511: INFO: Got endpoints: latency-svc-5t9l8 [760.688005ms]
Jan 12 05:11:30.555: INFO: Created: latency-svc-lxtjd
Jan 12 05:11:30.555: INFO: Got endpoints: latency-svc-m2dpz [761.398147ms]
Jan 12 05:11:30.565: INFO: Created: latency-svc-mrf27
Jan 12 05:11:30.596: INFO: Got endpoints: latency-svc-5kg69 [754.49457ms]
Jan 12 05:11:30.610: INFO: Created: latency-svc-2mq8v
Jan 12 05:11:30.647: INFO: Got endpoints: latency-svc-t4wk4 [748.802786ms]
Jan 12 05:11:30.663: INFO: Created: latency-svc-wxwzt
Jan 12 05:11:30.690: INFO: Got endpoints: latency-svc-h84zh [738.891526ms]
Jan 12 05:11:30.701: INFO: Created: latency-svc-kmtpl
Jan 12 05:11:30.740: INFO: Got endpoints: latency-svc-mpxwn [706.354585ms]
Jan 12 05:11:30.779: INFO: Created: latency-svc-dkq6x
Jan 12 05:11:30.794: INFO: Got endpoints: latency-svc-mkw8f [751.179289ms]
Jan 12 05:11:30.818: INFO: Created: latency-svc-njjzn
Jan 12 05:11:30.841: INFO: Got endpoints: latency-svc-thr28 [710.018498ms]
Jan 12 05:11:30.856: INFO: Created: latency-svc-277r7
Jan 12 05:11:30.888: INFO: Got endpoints: latency-svc-dwrxx [706.31649ms]
Jan 12 05:11:30.941: INFO: Created: latency-svc-nhqhm
Jan 12 05:11:30.943: INFO: Got endpoints: latency-svc-wsx7v [731.908875ms]
Jan 12 05:11:30.956: INFO: Created: latency-svc-fj87d
Jan 12 05:11:31.007: INFO: Got endpoints: latency-svc-n8svs [714.384883ms]
Jan 12 05:11:31.048: INFO: Created: latency-svc-d4tw7
Jan 12 05:11:31.055: INFO: Got endpoints: latency-svc-c6m49 [760.792171ms]
Jan 12 05:11:31.071: INFO: Created: latency-svc-k272l
Jan 12 05:11:31.122: INFO: Got endpoints: latency-svc-5dj4h [781.76019ms]
Jan 12 05:11:31.156: INFO: Got endpoints: latency-svc-jwfkd [763.124654ms]
Jan 12 05:11:31.167: INFO: Created: latency-svc-tqt7d
Jan 12 05:11:31.177: INFO: Created: latency-svc-2cql9
Jan 12 05:11:31.192: INFO: Got endpoints: latency-svc-9v5m7 [749.729423ms]
Jan 12 05:11:31.226: INFO: Created: latency-svc-jxmll
Jan 12 05:11:31.250: INFO: Got endpoints: latency-svc-lxtjd [738.29948ms]
Jan 12 05:11:31.295: INFO: Created: latency-svc-spzrd
Jan 12 05:11:31.301: INFO: Got endpoints: latency-svc-mrf27 [746.317607ms]
Jan 12 05:11:31.339: INFO: Created: latency-svc-h9tfp
Jan 12 05:11:31.340: INFO: Got endpoints: latency-svc-2mq8v [744.117791ms]
Jan 12 05:11:31.398: INFO: Got endpoints: latency-svc-wxwzt [751.025317ms]
Jan 12 05:11:31.399: INFO: Created: latency-svc-kqz2z
Jan 12 05:11:31.429: INFO: Created: latency-svc-mtrs2
Jan 12 05:11:31.455: INFO: Got endpoints: latency-svc-kmtpl [764.601101ms]
Jan 12 05:11:31.484: INFO: Created: latency-svc-ncdq9
Jan 12 05:11:31.507: INFO: Got endpoints: latency-svc-dkq6x [767.14461ms]
Jan 12 05:11:31.535: INFO: Created: latency-svc-wd7c8
Jan 12 05:11:31.545: INFO: Got endpoints: latency-svc-njjzn [750.937398ms]
Jan 12 05:11:31.595: INFO: Created: latency-svc-7b7w9
Jan 12 05:11:31.595: INFO: Got endpoints: latency-svc-277r7 [753.792076ms]
Jan 12 05:11:31.614: INFO: Created: latency-svc-qjhgh
Jan 12 05:11:31.639: INFO: Got endpoints: latency-svc-nhqhm [750.825353ms]
Jan 12 05:11:31.655: INFO: Created: latency-svc-z79km
Jan 12 05:11:31.694: INFO: Got endpoints: latency-svc-fj87d [751.371041ms]
Jan 12 05:11:31.740: INFO: Created: latency-svc-86dht
Jan 12 05:11:31.745: INFO: Got endpoints: latency-svc-d4tw7 [738.855474ms]
Jan 12 05:11:31.762: INFO: Created: latency-svc-t5664
Jan 12 05:11:31.789: INFO: Got endpoints: latency-svc-k272l [734.475163ms]
Jan 12 05:11:31.826: INFO: Created: latency-svc-rjl94
Jan 12 05:11:31.844: INFO: Got endpoints: latency-svc-tqt7d [722.01455ms]
Jan 12 05:11:31.886: INFO: Created: latency-svc-z4hsr
Jan 12 05:11:31.891: INFO: Got endpoints: latency-svc-2cql9 [735.70153ms]
Jan 12 05:11:32.009: INFO: Got endpoints: latency-svc-spzrd [758.881114ms]
Jan 12 05:11:32.009: INFO: Got endpoints: latency-svc-jxmll [817.653223ms]
Jan 12 05:11:32.021: INFO: Created: latency-svc-7jvq7
Jan 12 05:11:32.078: INFO: Created: latency-svc-6mj7w
Jan 12 05:11:32.079: INFO: Got endpoints: latency-svc-h9tfp [777.236721ms]
Jan 12 05:11:32.116: INFO: Got endpoints: latency-svc-kqz2z [776.349692ms]
Jan 12 05:11:32.120: INFO: Created: latency-svc-j7hcb
Jan 12 05:11:32.133: INFO: Created: latency-svc-bj5zs
Jan 12 05:11:32.148: INFO: Got endpoints: latency-svc-mtrs2 [750.034761ms]
Jan 12 05:11:32.167: INFO: Created: latency-svc-hgrff
Jan 12 05:11:32.186: INFO: Created: latency-svc-6zts2
Jan 12 05:11:32.190: INFO: Got endpoints: latency-svc-ncdq9 [734.639915ms]
Jan 12 05:11:32.215: INFO: Created: latency-svc-hsjjt
Jan 12 05:11:32.254: INFO: Got endpoints: latency-svc-wd7c8 [747.078907ms]
Jan 12 05:11:32.285: INFO: Created: latency-svc-xs4sx
Jan 12 05:11:32.302: INFO: Got endpoints: latency-svc-7b7w9 [756.956243ms]
Jan 12 05:11:32.352: INFO: Created: latency-svc-kb86f
Jan 12 05:11:32.362: INFO: Got endpoints: latency-svc-qjhgh [766.344097ms]
Jan 12 05:11:32.385: INFO: Created: latency-svc-87t4t
Jan 12 05:11:32.390: INFO: Got endpoints: latency-svc-z79km [750.577011ms]
Jan 12 05:11:32.415: INFO: Created: latency-svc-c9ssl
Jan 12 05:11:32.439: INFO: Got endpoints: latency-svc-86dht [744.240498ms]
Jan 12 05:11:32.450: INFO: Created: latency-svc-9n4mc
Jan 12 05:11:32.492: INFO: Got endpoints: latency-svc-t5664 [746.027623ms]
Jan 12 05:11:32.521: INFO: Created: latency-svc-qj2t4
Jan 12 05:11:32.540: INFO: Got endpoints: latency-svc-rjl94 [750.705077ms]
Jan 12 05:11:32.554: INFO: Created: latency-svc-jmwd7
Jan 12 05:11:32.602: INFO: Got endpoints: latency-svc-z4hsr [757.992512ms]
Jan 12 05:11:32.663: INFO: Got endpoints: latency-svc-7jvq7 [771.94267ms]
Jan 12 05:11:32.663: INFO: Created: latency-svc-lzwgn
Jan 12 05:11:32.700: INFO: Created: latency-svc-qkntg
Jan 12 05:11:32.701: INFO: Got endpoints: latency-svc-6mj7w [691.804927ms]
Jan 12 05:11:32.766: INFO: Created: latency-svc-b4x2v
Jan 12 05:11:32.777: INFO: Got endpoints: latency-svc-j7hcb [767.36052ms]
Jan 12 05:11:32.794: INFO: Got endpoints: latency-svc-bj5zs [715.071581ms]
Jan 12 05:11:32.809: INFO: Created: latency-svc-2ntqj
Jan 12 05:11:32.840: INFO: Got endpoints: latency-svc-hgrff [723.619636ms]
Jan 12 05:11:32.840: INFO: Created: latency-svc-7h6rk
Jan 12 05:11:32.890: INFO: Got endpoints: latency-svc-6zts2 [741.970926ms]
Jan 12 05:11:32.906: INFO: Created: latency-svc-8n9qn
Jan 12 05:11:32.946: INFO: Got endpoints: latency-svc-hsjjt [756.578135ms]
Jan 12 05:11:32.950: INFO: Created: latency-svc-dbnrt
Jan 12 05:11:32.994: INFO: Got endpoints: latency-svc-xs4sx [739.324267ms]
Jan 12 05:11:33.004: INFO: Created: latency-svc-8n5v7
Jan 12 05:11:33.023: INFO: Created: latency-svc-tnbz5
Jan 12 05:11:33.058: INFO: Got endpoints: latency-svc-kb86f [755.957116ms]
Jan 12 05:11:33.078: INFO: Created: latency-svc-jjc57
Jan 12 05:11:33.100: INFO: Got endpoints: latency-svc-87t4t [738.892251ms]
Jan 12 05:11:33.141: INFO: Created: latency-svc-zs682
Jan 12 05:11:33.173: INFO: Got endpoints: latency-svc-c9ssl [782.580865ms]
Jan 12 05:11:33.218: INFO: Got endpoints: latency-svc-9n4mc [779.23571ms]
Jan 12 05:11:33.220: INFO: Created: latency-svc-p2bdf
Jan 12 05:11:33.242: INFO: Got endpoints: latency-svc-qj2t4 [750.577968ms]
Jan 12 05:11:33.243: INFO: Created: latency-svc-cxxsv
Jan 12 05:11:33.283: INFO: Created: latency-svc-td5x6
Jan 12 05:11:33.290: INFO: Got endpoints: latency-svc-jmwd7 [750.15312ms]
Jan 12 05:11:33.306: INFO: Created: latency-svc-5tccv
Jan 12 05:11:33.359: INFO: Got endpoints: latency-svc-lzwgn [756.803837ms]
Jan 12 05:11:33.396: INFO: Got endpoints: latency-svc-qkntg [732.929845ms]
Jan 12 05:11:33.397: INFO: Created: latency-svc-z2zhq
Jan 12 05:11:33.415: INFO: Created: latency-svc-chvcw
Jan 12 05:11:33.441: INFO: Got endpoints: latency-svc-b4x2v [740.810161ms]
Jan 12 05:11:33.479: INFO: Created: latency-svc-bfgh2
Jan 12 05:11:33.510: INFO: Got endpoints: latency-svc-2ntqj [733.809657ms]
Jan 12 05:11:33.541: INFO: Got endpoints: latency-svc-7h6rk [746.856256ms]
Jan 12 05:11:33.543: INFO: Created: latency-svc-g64pn
Jan 12 05:11:33.566: INFO: Created: latency-svc-j84m6
Jan 12 05:11:33.599: INFO: Got endpoints: latency-svc-8n9qn [759.004347ms]
Jan 12 05:11:33.614: INFO: Created: latency-svc-bgmwh
Jan 12 05:11:33.645: INFO: Got endpoints: latency-svc-dbnrt [754.465402ms]
Jan 12 05:11:33.680: INFO: Created: latency-svc-hwkcv
Jan 12 05:11:33.690: INFO: Got endpoints: latency-svc-8n5v7 [743.729369ms]
Jan 12 05:11:33.726: INFO: Created: latency-svc-49cfm
Jan 12 05:11:33.740: INFO: Got endpoints: latency-svc-tnbz5 [746.465974ms]
Jan 12 05:11:33.757: INFO: Created: latency-svc-f4jrb
Jan 12 05:11:33.796: INFO: Got endpoints: latency-svc-jjc57 [738.249692ms]
Jan 12 05:11:33.816: INFO: Created: latency-svc-fvwgc
Jan 12 05:11:33.846: INFO: Got endpoints: latency-svc-zs682 [745.288558ms]
Jan 12 05:11:33.868: INFO: Created: latency-svc-xq9ls
Jan 12 05:11:33.905: INFO: Got endpoints: latency-svc-p2bdf [732.738135ms]
Jan 12 05:11:33.938: INFO: Created: latency-svc-vtf4t
Jan 12 05:11:33.944: INFO: Got endpoints: latency-svc-cxxsv [726.454077ms]
Jan 12 05:11:34.015: INFO: Got endpoints: latency-svc-td5x6 [772.715828ms]
Jan 12 05:11:34.023: INFO: Created: latency-svc-8blc8
Jan 12 05:11:34.054: INFO: Got endpoints: latency-svc-5tccv [764.309407ms]
Jan 12 05:11:34.059: INFO: Created: latency-svc-j42lw
Jan 12 05:11:34.089: INFO: Created: latency-svc-ptsjh
Jan 12 05:11:34.110: INFO: Got endpoints: latency-svc-z2zhq [751.646666ms]
Jan 12 05:11:34.125: INFO: Created: latency-svc-7r9b8
Jan 12 05:11:34.142: INFO: Got endpoints: latency-svc-chvcw [745.813534ms]
Jan 12 05:11:34.165: INFO: Created: latency-svc-5r27d
Jan 12 05:11:34.200: INFO: Got endpoints: latency-svc-bfgh2 [758.327898ms]
Jan 12 05:11:34.240: INFO: Created: latency-svc-ww45j
Jan 12 05:11:34.264: INFO: Got endpoints: latency-svc-g64pn [753.910558ms]
Jan 12 05:11:34.279: INFO: Created: latency-svc-5k5kf
Jan 12 05:11:34.298: INFO: Got endpoints: latency-svc-j84m6 [757.583555ms]
Jan 12 05:11:34.335: INFO: Created: latency-svc-44qcp
Jan 12 05:11:34.352: INFO: Got endpoints: latency-svc-bgmwh [753.584728ms]
Jan 12 05:11:34.367: INFO: Created: latency-svc-zz42v
Jan 12 05:11:34.390: INFO: Got endpoints: latency-svc-hwkcv [744.82354ms]
Jan 12 05:11:34.402: INFO: Created: latency-svc-4vrjl
Jan 12 05:11:34.443: INFO: Got endpoints: latency-svc-49cfm [752.8454ms]
Jan 12 05:11:34.468: INFO: Created: latency-svc-xcpt9
Jan 12 05:11:34.489: INFO: Got endpoints: latency-svc-f4jrb [748.394967ms]
Jan 12 05:11:34.516: INFO: Created: latency-svc-mxx8m
Jan 12 05:11:34.539: INFO: Got endpoints: latency-svc-fvwgc [742.521868ms]
Jan 12 05:11:34.590: INFO: Got endpoints: latency-svc-xq9ls [743.932665ms]
Jan 12 05:11:34.639: INFO: Got endpoints: latency-svc-vtf4t [733.791889ms]
Jan 12 05:11:34.700: INFO: Got endpoints: latency-svc-8blc8 [755.54333ms]
Jan 12 05:11:34.743: INFO: Got endpoints: latency-svc-j42lw [727.642934ms]
Jan 12 05:11:34.792: INFO: Got endpoints: latency-svc-ptsjh [737.865178ms]
Jan 12 05:11:34.857: INFO: Got endpoints: latency-svc-7r9b8 [746.652015ms]
Jan 12 05:11:34.897: INFO: Got endpoints: latency-svc-5r27d [754.387752ms]
Jan 12 05:11:34.947: INFO: Got endpoints: latency-svc-ww45j [746.902943ms]
Jan 12 05:11:34.990: INFO: Got endpoints: latency-svc-5k5kf [725.45377ms]
Jan 12 05:11:35.059: INFO: Got endpoints: latency-svc-44qcp [760.903464ms]
Jan 12 05:11:35.112: INFO: Got endpoints: latency-svc-zz42v [759.914867ms]
Jan 12 05:11:35.139: INFO: Got endpoints: latency-svc-4vrjl [748.914616ms]
Jan 12 05:11:35.196: INFO: Got endpoints: latency-svc-xcpt9 [752.833365ms]
Jan 12 05:11:35.240: INFO: Got endpoints: latency-svc-mxx8m [751.799831ms]
Jan 12 05:11:35.241: INFO: Latencies: [26.758772ms 52.606165ms 54.590098ms 105.454753ms 113.462124ms 144.496068ms 184.198342ms 209.835234ms 226.776315ms 234.776154ms 271.259935ms 351.178041ms 351.225001ms 365.691569ms 368.073127ms 374.46653ms 377.875243ms 379.522104ms 382.91072ms 384.299431ms 384.605079ms 388.18657ms 395.005787ms 399.52357ms 401.284852ms 403.182018ms 404.644238ms 404.681371ms 415.044555ms 416.888984ms 420.924949ms 423.741041ms 424.311429ms 425.223144ms 426.106569ms 434.357904ms 437.622246ms 440.685831ms 442.529114ms 449.910707ms 453.736802ms 454.214234ms 461.244033ms 464.896884ms 468.454948ms 474.23405ms 475.494203ms 477.65395ms 479.800605ms 482.605213ms 485.768604ms 499.625638ms 500.195045ms 506.01758ms 508.14417ms 509.952048ms 510.972849ms 513.709324ms 518.123924ms 521.021756ms 522.630264ms 524.095642ms 530.011145ms 535.041579ms 535.295017ms 536.679555ms 539.505333ms 539.788991ms 544.514649ms 550.474309ms 554.054043ms 554.889008ms 561.887913ms 569.53852ms 582.096398ms 588.43788ms 594.365062ms 607.453701ms 615.449272ms 630.573235ms 634.347249ms 635.80329ms 636.176963ms 637.08987ms 655.127366ms 657.464159ms 661.927003ms 666.314319ms 673.904071ms 682.881895ms 685.303628ms 691.084363ms 691.804927ms 693.432982ms 698.192233ms 701.388282ms 706.162104ms 706.31649ms 706.354585ms 710.018498ms 713.623234ms 714.384883ms 715.071581ms 718.754293ms 722.01455ms 723.619636ms 725.45377ms 725.665428ms 726.454077ms 727.642934ms 730.031204ms 731.908875ms 732.738135ms 732.929845ms 732.991429ms 733.791889ms 733.809657ms 734.475163ms 734.639915ms 735.70153ms 737.865178ms 738.249692ms 738.29948ms 738.855474ms 738.891526ms 738.892251ms 739.324267ms 740.810161ms 741.970926ms 742.521868ms 743.729369ms 743.932665ms 744.053494ms 744.117791ms 744.240498ms 744.82354ms 745.103051ms 745.288558ms 745.813534ms 746.027623ms 746.317607ms 746.465974ms 746.652015ms 746.856256ms 746.902943ms 747.078907ms 748.309226ms 748.394967ms 748.802786ms 748.914616ms 749.729423ms 750.034761ms 750.15312ms 750.577011ms 750.577968ms 750.705077ms 750.825353ms 750.937398ms 751.025317ms 751.179289ms 751.371041ms 751.646666ms 751.799831ms 752.833365ms 752.8454ms 753.584728ms 753.792076ms 753.910558ms 754.387752ms 754.465402ms 754.49457ms 755.54333ms 755.957116ms 756.578135ms 756.803837ms 756.956243ms 757.583555ms 757.992512ms 758.327898ms 758.881114ms 759.004347ms 759.914867ms 760.688005ms 760.792171ms 760.903464ms 761.398147ms 763.124654ms 764.309407ms 764.601101ms 766.344097ms 767.14461ms 767.36052ms 771.94267ms 772.715828ms 776.349692ms 777.236721ms 779.23571ms 781.76019ms 782.580865ms 817.653223ms]
Jan 12 05:11:35.241: INFO: 50 %ile: 713.623234ms
Jan 12 05:11:35.241: INFO: 90 %ile: 759.004347ms
Jan 12 05:11:35.241: INFO: 99 %ile: 782.580865ms
Jan 12 05:11:35.241: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:11:35.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-g4z89" for this suite.
Jan 12 05:11:57.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:11:57.347: INFO: namespace: e2e-tests-svc-latency-g4z89, resource: bindings, ignored listing per whitelist
Jan 12 05:11:57.412: INFO: namespace e2e-tests-svc-latency-g4z89 deletion completed in 22.163526967s

• [SLOW TEST:33.100 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:11:57.412: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2x8g6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-9598523b-1628-11e9-8fb7-aa4233c46d55
STEP: Creating secret with name secret-projected-all-test-volume-95985221-1628-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test Check all projections for projected volume plugin
Jan 12 05:11:57.597: INFO: Waiting up to 5m0s for pod "projected-volume-959851d1-1628-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-projected-2x8g6" to be "success or failure"
Jan 12 05:11:57.602: INFO: Pod "projected-volume-959851d1-1628-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 4.722223ms
Jan 12 05:11:59.606: INFO: Pod "projected-volume-959851d1-1628-11e9-8fb7-aa4233c46d55": Phase="Running", Reason="", readiness=true. Elapsed: 2.008384837s
Jan 12 05:12:01.609: INFO: Pod "projected-volume-959851d1-1628-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011544037s
STEP: Saw pod success
Jan 12 05:12:01.609: INFO: Pod "projected-volume-959851d1-1628-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:12:01.612: INFO: Trying to get logs from node c76-1-41 pod projected-volume-959851d1-1628-11e9-8fb7-aa4233c46d55 container projected-all-volume-test: <nil>
STEP: delete the pod
Jan 12 05:12:01.675: INFO: Waiting for pod projected-volume-959851d1-1628-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:12:01.678: INFO: Pod projected-volume-959851d1-1628-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:12:01.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2x8g6" for this suite.
Jan 12 05:12:07.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:12:07.752: INFO: namespace: e2e-tests-projected-2x8g6, resource: bindings, ignored listing per whitelist
Jan 12 05:12:07.770: INFO: namespace e2e-tests-projected-2x8g6 deletion completed in 6.087915901s

• [SLOW TEST:10.358 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:12:07.770: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-rcbxq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 12 05:12:07.965: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9bc754bc-1628-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-downward-api-rcbxq" to be "success or failure"
Jan 12 05:12:07.970: INFO: Pod "downwardapi-volume-9bc754bc-1628-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 4.494182ms
Jan 12 05:12:09.973: INFO: Pod "downwardapi-volume-9bc754bc-1628-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007827506s
Jan 12 05:12:11.977: INFO: Pod "downwardapi-volume-9bc754bc-1628-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011227837s
STEP: Saw pod success
Jan 12 05:12:11.977: INFO: Pod "downwardapi-volume-9bc754bc-1628-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:12:11.979: INFO: Trying to get logs from node c76-1-41 pod downwardapi-volume-9bc754bc-1628-11e9-8fb7-aa4233c46d55 container client-container: <nil>
STEP: delete the pod
Jan 12 05:12:12.027: INFO: Waiting for pod downwardapi-volume-9bc754bc-1628-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:12:12.032: INFO: Pod downwardapi-volume-9bc754bc-1628-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:12:12.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rcbxq" for this suite.
Jan 12 05:12:18.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:12:18.106: INFO: namespace: e2e-tests-downward-api-rcbxq, resource: bindings, ignored listing per whitelist
Jan 12 05:12:18.144: INFO: namespace e2e-tests-downward-api-rcbxq deletion completed in 6.106797444s

• [SLOW TEST:10.374 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:12:18.144: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-p89vr
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-a1f31e6a-1628-11e9-8fb7-aa4233c46d55
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:12:22.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-p89vr" for this suite.
Jan 12 05:12:44.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:12:44.553: INFO: namespace: e2e-tests-configmap-p89vr, resource: bindings, ignored listing per whitelist
Jan 12 05:12:44.595: INFO: namespace e2e-tests-configmap-p89vr deletion completed in 22.216547094s

• [SLOW TEST:26.451 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:12:44.595: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-4r6vn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan 12 05:12:44.766: INFO: Waiting up to 5m0s for pod "pod-b1b78e7d-1628-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-emptydir-4r6vn" to be "success or failure"
Jan 12 05:12:44.781: INFO: Pod "pod-b1b78e7d-1628-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 15.541023ms
Jan 12 05:12:46.785: INFO: Pod "pod-b1b78e7d-1628-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019090422s
STEP: Saw pod success
Jan 12 05:12:46.785: INFO: Pod "pod-b1b78e7d-1628-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:12:46.788: INFO: Trying to get logs from node c76-1-41 pod pod-b1b78e7d-1628-11e9-8fb7-aa4233c46d55 container test-container: <nil>
STEP: delete the pod
Jan 12 05:12:46.815: INFO: Waiting for pod pod-b1b78e7d-1628-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:12:46.818: INFO: Pod pod-b1b78e7d-1628-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:12:46.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4r6vn" for this suite.
Jan 12 05:12:52.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:12:52.893: INFO: namespace: e2e-tests-emptydir-4r6vn, resource: bindings, ignored listing per whitelist
Jan 12 05:12:52.920: INFO: namespace e2e-tests-emptydir-4r6vn deletion completed in 6.097455115s

• [SLOW TEST:8.326 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:12:52.921: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rkjbz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 12 05:12:53.113: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b6b0dd43-1628-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-projected-rkjbz" to be "success or failure"
Jan 12 05:12:53.117: INFO: Pod "downwardapi-volume-b6b0dd43-1628-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 3.911061ms
Jan 12 05:12:55.125: INFO: Pod "downwardapi-volume-b6b0dd43-1628-11e9-8fb7-aa4233c46d55": Phase="Running", Reason="", readiness=true. Elapsed: 2.012297455s
Jan 12 05:12:57.135: INFO: Pod "downwardapi-volume-b6b0dd43-1628-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021556358s
STEP: Saw pod success
Jan 12 05:12:57.135: INFO: Pod "downwardapi-volume-b6b0dd43-1628-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:12:57.142: INFO: Trying to get logs from node c76-1-41 pod downwardapi-volume-b6b0dd43-1628-11e9-8fb7-aa4233c46d55 container client-container: <nil>
STEP: delete the pod
Jan 12 05:12:57.199: INFO: Waiting for pod downwardapi-volume-b6b0dd43-1628-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:12:57.201: INFO: Pod downwardapi-volume-b6b0dd43-1628-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:12:57.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rkjbz" for this suite.
Jan 12 05:13:03.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:13:03.301: INFO: namespace: e2e-tests-projected-rkjbz, resource: bindings, ignored listing per whitelist
Jan 12 05:13:03.318: INFO: namespace e2e-tests-projected-rkjbz deletion completed in 6.113514804s

• [SLOW TEST:10.398 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:13:03.319: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-84hrr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Jan 12 05:13:05.526: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-bce01476-1628-11e9-8fb7-aa4233c46d55,GenerateName:,Namespace:e2e-tests-events-84hrr,SelfLink:/api/v1/namespaces/e2e-tests-events-84hrr/pods/send-events-bce01476-1628-11e9-8fb7-aa4233c46d55,UID:bcdfe78f-1628-11e9-b7e1-000c294e6ffe,ResourceVersion:145212,Generation:0,CreationTimestamp:2019-01-12 05:13:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 481566074,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gm7tb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gm7tb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-gm7tb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f298c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f298e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 05:13:03 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 05:13:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 05:13:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 05:13:03 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:172.31.52.115,StartTime:2019-01-12 05:13:03 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-01-12 05:13:04 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://index.tenxcloud.com/tenx_containers/serve-hostname@sha256:5792caa151fd823f01e765c535bcdb0386e0e9c9a2b5687e4a613cecadfa3505 docker://6c20586e00e5fb3f2d7a21a64c04f904a4b28212441fbc21adbe087a783dbe6b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Jan 12 05:13:07.532: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Jan 12 05:13:09.536: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:13:09.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-84hrr" for this suite.
Jan 12 05:13:47.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:13:47.611: INFO: namespace: e2e-tests-events-84hrr, resource: bindings, ignored listing per whitelist
Jan 12 05:13:47.644: INFO: namespace e2e-tests-events-84hrr deletion completed in 38.089729997s

• [SLOW TEST:44.325 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:13:47.644: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-xtkrh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-nkhwb
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Jan 12 05:13:49.995: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-qdg6p
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:14:14.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-xtkrh" for this suite.
Jan 12 05:14:20.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:14:20.267: INFO: namespace: e2e-tests-namespaces-xtkrh, resource: bindings, ignored listing per whitelist
Jan 12 05:14:20.275: INFO: namespace e2e-tests-namespaces-xtkrh deletion completed in 6.123562363s
STEP: Destroying namespace "e2e-tests-nsdeletetest-nkhwb" for this suite.
Jan 12 05:14:20.277: INFO: Namespace e2e-tests-nsdeletetest-nkhwb was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-qdg6p" for this suite.
Jan 12 05:14:26.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:14:26.346: INFO: namespace: e2e-tests-nsdeletetest-qdg6p, resource: bindings, ignored listing per whitelist
Jan 12 05:14:26.372: INFO: namespace e2e-tests-nsdeletetest-qdg6p deletion completed in 6.094589035s

• [SLOW TEST:38.728 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:14:26.372: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-qqwt4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Jan 12 05:14:26.549: INFO: Pod name pod-release: Found 0 pods out of 1
Jan 12 05:14:31.554: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:14:32.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-qqwt4" for this suite.
Jan 12 05:14:38.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:14:38.675: INFO: namespace: e2e-tests-replication-controller-qqwt4, resource: bindings, ignored listing per whitelist
Jan 12 05:14:38.721: INFO: namespace e2e-tests-replication-controller-qqwt4 deletion completed in 6.132992848s

• [SLOW TEST:12.349 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:14:38.722: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rw8nq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-f5c0f37b-1628-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume configMaps
Jan 12 05:14:38.918: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f5c182d5-1628-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-projected-rw8nq" to be "success or failure"
Jan 12 05:14:38.922: INFO: Pod "pod-projected-configmaps-f5c182d5-1628-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 4.09484ms
Jan 12 05:14:40.926: INFO: Pod "pod-projected-configmaps-f5c182d5-1628-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007808148s
STEP: Saw pod success
Jan 12 05:14:40.926: INFO: Pod "pod-projected-configmaps-f5c182d5-1628-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:14:40.929: INFO: Trying to get logs from node c76-1-41 pod pod-projected-configmaps-f5c182d5-1628-11e9-8fb7-aa4233c46d55 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 12 05:14:40.956: INFO: Waiting for pod pod-projected-configmaps-f5c182d5-1628-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:14:40.958: INFO: Pod pod-projected-configmaps-f5c182d5-1628-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:14:40.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rw8nq" for this suite.
Jan 12 05:14:46.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:14:47.023: INFO: namespace: e2e-tests-projected-rw8nq, resource: bindings, ignored listing per whitelist
Jan 12 05:14:47.047: INFO: namespace e2e-tests-projected-rw8nq deletion completed in 6.085680344s

• [SLOW TEST:8.325 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:14:47.047: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-7kf8v
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-7kf8v
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7kf8v to expose endpoints map[]
Jan 12 05:14:47.225: INFO: Get endpoints failed (16.950813ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Jan 12 05:14:48.231: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7kf8v exposes endpoints map[] (1.02293727s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-7kf8v
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7kf8v to expose endpoints map[pod1:[80]]
Jan 12 05:14:50.276: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7kf8v exposes endpoints map[pod1:[80]] (2.023814149s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-7kf8v
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7kf8v to expose endpoints map[pod1:[80] pod2:[80]]
Jan 12 05:14:52.332: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7kf8v exposes endpoints map[pod2:[80] pod1:[80]] (2.050266131s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-7kf8v
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7kf8v to expose endpoints map[pod2:[80]]
Jan 12 05:14:53.363: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7kf8v exposes endpoints map[pod2:[80]] (1.021483749s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-7kf8v
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7kf8v to expose endpoints map[]
Jan 12 05:14:53.380: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7kf8v exposes endpoints map[] (6.895465ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:14:53.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-7kf8v" for this suite.
Jan 12 05:14:59.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:14:59.551: INFO: namespace: e2e-tests-services-7kf8v, resource: bindings, ignored listing per whitelist
Jan 12 05:14:59.585: INFO: namespace e2e-tests-services-7kf8v deletion completed in 6.1515981s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:12.539 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:14:59.585: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-s2lj8
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Jan 12 05:14:59.774: INFO: Waiting up to 5m0s for pod "pod-02300ac9-1629-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-emptydir-s2lj8" to be "success or failure"
Jan 12 05:14:59.787: INFO: Pod "pod-02300ac9-1629-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 12.936661ms
Jan 12 05:15:01.790: INFO: Pod "pod-02300ac9-1629-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015805827s
STEP: Saw pod success
Jan 12 05:15:01.790: INFO: Pod "pod-02300ac9-1629-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:15:01.792: INFO: Trying to get logs from node c76-1-41 pod pod-02300ac9-1629-11e9-8fb7-aa4233c46d55 container test-container: <nil>
STEP: delete the pod
Jan 12 05:15:01.847: INFO: Waiting for pod pod-02300ac9-1629-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:15:01.849: INFO: Pod pod-02300ac9-1629-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:15:01.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-s2lj8" for this suite.
Jan 12 05:15:07.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:15:07.913: INFO: namespace: e2e-tests-emptydir-s2lj8, resource: bindings, ignored listing per whitelist
Jan 12 05:15:07.945: INFO: namespace e2e-tests-emptydir-s2lj8 deletion completed in 6.091852502s

• [SLOW TEST:8.360 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:15:07.945: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-dg4tl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:15:15.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-dg4tl" for this suite.
Jan 12 05:15:37.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:15:37.191: INFO: namespace: e2e-tests-replication-controller-dg4tl, resource: bindings, ignored listing per whitelist
Jan 12 05:15:37.277: INFO: namespace e2e-tests-replication-controller-dg4tl deletion completed in 22.126627063s

• [SLOW TEST:29.332 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:15:37.277: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-7smlr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
STEP: Collecting events from namespace "e2e-tests-kubelet-test-7smlr".
STEP: Found 4 events.
Jan 12 05:16:39.479: INFO: At 2019-01-12 05:15:37 +0000 UTC - event for busybox-host-aliases3c6f5810-1620-11e9-8fb7-aa4233c46d55: {default-scheduler } Scheduled: Successfully assigned e2e-tests-kubelet-test-7smlr/busybox-host-aliases3c6f5810-1620-11e9-8fb7-aa4233c46d55 to c76-1-41
Jan 12 05:16:39.479: INFO: At 2019-01-12 05:15:38 +0000 UTC - event for busybox-host-aliases3c6f5810-1620-11e9-8fb7-aa4233c46d55: {kubelet c76-1-41} Pulled: Container image "docker.io/library/busybox:1.29" already present on machine
Jan 12 05:16:39.479: INFO: At 2019-01-12 05:15:38 +0000 UTC - event for busybox-host-aliases3c6f5810-1620-11e9-8fb7-aa4233c46d55: {kubelet c76-1-41} Created: Created container
Jan 12 05:16:39.479: INFO: At 2019-01-12 05:15:38 +0000 UTC - event for busybox-host-aliases3c6f5810-1620-11e9-8fb7-aa4233c46d55: {kubelet c76-1-41} Started: Started container
Jan 12 05:16:39.516: INFO: POD                                                       NODE      PHASE      GRACE  CONDITIONS
Jan 12 05:16:39.516: INFO: busybox-host-aliases3c6f5810-1620-11e9-8fb7-aa4233c46d55  c76-1-41  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 05:15:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 05:15:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 05:15:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 05:15:37 +0000 UTC  }]
Jan 12 05:16:39.516: INFO: sonobuoy                                                  c76-1-41  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:12:07 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:12:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:12:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:12:07 +0000 UTC  }]
Jan 12 05:16:39.516: INFO: sonobuoy-e2e-job-f2515c1fd49f447c                         c76-1-41  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:12:09 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:12:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:12:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 04:12:09 +0000 UTC  }]
Jan 12 05:16:39.516: INFO: calico-node-47p2l                                         c76-1-41  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:41:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:42:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:42:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-11 10:32:23 +0000 UTC  }]
Jan 12 05:16:39.516: INFO: calico-node-9mj47                                         c76-1-40  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:41:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:41:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:41:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-11 10:27:33 +0000 UTC  }]
Jan 12 05:16:39.516: INFO: configure-calico-tsst7                                    c76-1-40  Succeeded         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-11 10:27:33 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-11 10:27:39 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-11 10:27:39 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-11 10:27:33 +0000 UTC  }]
Jan 12 05:16:39.516: INFO: coredns-5f8bc8cbf5-8stsj                                  c76-1-40  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-11 10:28:50 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 02:29:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 02:29:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-11 10:28:50 +0000 UTC  }]
Jan 12 05:16:39.516: INFO: coredns-5f8bc8cbf5-r67rl                                  c76-1-40  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-11 10:32:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:41:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:41:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-11 10:32:32 +0000 UTC  }]
Jan 12 05:16:39.516: INFO: etcd-c76-1-40                                             c76-1-40  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:34:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:34:43 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:34:43 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:34:34 +0000 UTC  }]
Jan 12 05:16:39.516: INFO: kube-apiserver-c76-1-40                                   c76-1-40  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:34:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:34:43 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:34:43 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:34:34 +0000 UTC  }]
Jan 12 05:16:39.516: INFO: kube-controller-6dd888b6-2gdzh                            c76-1-41  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:48:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:48:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:48:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:48:43 +0000 UTC  }]
Jan 12 05:16:39.516: INFO: kube-controller-manager-c76-1-40                          c76-1-40  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:34:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:34:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:34:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:34:34 +0000 UTC  }]
Jan 12 05:16:39.516: INFO: kube-discovery-dhv7z                                      c76-1-40  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:41:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:41:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:41:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:41:17 +0000 UTC  }]
Jan 12 05:16:39.516: INFO: kube-dns-autoscaler-77cfb8c949-bllxk                      c76-1-40  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-11 10:27:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:41:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:41:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-11 10:27:33 +0000 UTC  }]
Jan 12 05:16:39.516: INFO: kube-proxy-5r9k5                                          c76-1-40  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-11 10:27:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:40:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:40:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-11 10:27:33 +0000 UTC  }]
Jan 12 05:16:39.516: INFO: kube-proxy-k8t9z                                          c76-1-41  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-11 10:32:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:40:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:40:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-11 10:32:23 +0000 UTC  }]
Jan 12 05:16:39.516: INFO: kube-scheduler-c76-1-40                                   c76-1-40  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-11 10:26:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:40:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:40:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-11 10:26:57 +0000 UTC  }]
Jan 12 05:16:39.516: INFO: kubectl-cp4p5                                             c76-1-41  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-11 10:32:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:40:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:40:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-11 10:32:23 +0000 UTC  }]
Jan 12 05:16:39.516: INFO: kubectl-z2zbp                                             c76-1-40  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-11 10:27:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:40:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 01:40:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-11 10:27:33 +0000 UTC  }]
Jan 12 05:16:39.516: INFO: 
Jan 12 05:16:39.541: INFO: 
Logging node info for node c76-1-40
Jan 12 05:16:39.543: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:c76-1-40,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/c76-1-40,UID:7401ad30-158b-11e9-8eb1-000c294e6ffe,ResourceVersion:145908,Generation:0,CreationTimestamp:2019-01-11 10:27:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/os: linux,kubernetes.io/hostname: c76-1-40,node-role.kubernetes.io/master: ,},Annotations:map[string]string{kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock,node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:NodeSpec{PodCIDR:172.31.0.0/24,DoNotUse_ExternalID:,ProviderID:,Unschedulable:false,Taints:[{node-role.kubernetes.io/master  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{cpu: {{4 0} {<nil>} 4 DecimalSI},ephemeral-storage: {{63318790144 0} {<nil>} 61834756Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{4123009024 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{4 0} {<nil>} 4 DecimalSI},ephemeral-storage: {{56986911036 0} {<nil>} 56986911036 DecimalSI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{4018151424 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2019-01-12 05:16:31 +0000 UTC 2019-01-11 10:27:03 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2019-01-12 05:16:31 +0000 UTC 2019-01-11 10:27:03 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-01-12 05:16:31 +0000 UTC 2019-01-11 10:27:03 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-01-12 05:16:31 +0000 UTC 2019-01-11 10:27:03 +0000 UTC KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-01-12 05:16:31 +0000 UTC 2019-01-11 10:28:50 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 192.168.1.40} {Hostname c76-1-40}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:5462046fd6564e269143595942c52d8b,SystemUUID:E99C4D56-8335-B49D-0A70-2098364E6FFE,BootID:75b5e5f9-c44e-4596-986f-18ebf26e92a7,KernelVersion:3.10.0-957.el7.x86_64,OSImage:CentOS Linux 7 (Core),ContainerRuntimeVersion:docker://17.3.2,KubeletVersion:v1.12.3,KubeProxyVersion:v1.12.3,OperatingSystem:linux,Architecture:amd64,},Images:[{[192.168.1.52/system_containers/hyperkube-amd64@sha256:a90d413c933bb465eefed80df373fa2af8468a6bfe0182082f652e68e7a3fb13 192.168.1.52/system_containers/hyperkube-amd64:v1.12.3] 709865716} {[192.168.1.52/system_containers/etcd@sha256:7b073bdab8c52dc23dfb3e2101597d30304437869ad8c0b425301e96a066c408 192.168.1.52/system_containers/etcd:3.2.24] 219655340} {[192.168.1.52/system_containers/kubectl-amd64@sha256:fd27ea38a1dc69008ecb87503813fa0bf355b0ce8ae2e596c9098993237c469a 192.168.1.52/system_containers/kubectl-amd64:v1.12.3] 166235497} {[192.168.1.52/system_containers/node@sha256:2f46157483904649f334da83e6b5e522bf20cbd3ea6ec9f43456673933021d5a 192.168.1.52/system_containers/node:v3.4.0] 75898396} {[192.168.1.52/system_containers/cni@sha256:61a410fd6512bd0747fa76798ed5c121c815d7aed94f12d02507b7406bf7ccf2 192.168.1.52/system_containers/cni:v3.4.0] 75430420} {[192.168.1.52/system_containers/agent@sha256:8844a2f97daae4dede402cfc1e719a1f7f82142690decc608c3b7e6679a2444c 192.168.1.52/system_containers/agent:v4.0.0] 68660084} {[192.168.1.52/system_containers/kube-controllers@sha256:7b549fa211f15a1b038c82cc7b11d4b3157db822aebd72c48f924620e9ec329c 192.168.1.52/system_containers/kube-controllers:v3.4.0] 56528665} {[192.168.1.52/system_containers/cluster-proportional-autoscaler-amd64@sha256:36359630278b119e7dd78f5437be1c667080108fa59ecba1b81cda3610dcf4d7 192.168.1.52/system_containers/cluster-proportional-autoscaler-amd64:1.2.0] 50253933} {[192.168.1.52/system_containers/coredns@sha256:a905b50f8ecddf67cd1ad92ef95f8547aea9fd1970359e00c16aa0ab1d517baa 192.168.1.52/system_containers/coredns:1.2.2] 39198271} {[192.168.1.52/system_containers/ctl@sha256:5e6685b93900eb5b79d93db0ac514f815c5bdd52c70da03bea4f7bc7debde2be 192.168.1.52/system_containers/ctl:v3.4.0] 35264750} {[192.168.1.52/system_containers/tde@sha256:e5bacdec54bf32e15955f88ff693fa5162b9eed97c7f1c79f5299e8cdde949a3 192.168.1.52/system_containers/tde:v4.0.0] 28785861} {[192.168.1.52/system_containers/kube-discovery-amd64@sha256:3af8edb8268f7303d15b47168228193e5be7c36e2e1e6efd1854cacf774cb5c8 192.168.1.52/system_containers/kube-discovery-amd64:v4.0.0] 15858550} {[192.168.1.52/system_containers/pause@sha256:fcaff905397ba63fd376d0c3019f1f1cb6e7506131389edbcb3d22719f1ae54d 192.168.1.52/system_containers/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
Jan 12 05:16:39.543: INFO: 
Logging kubelet events for node c76-1-40
Jan 12 05:16:39.545: INFO: 
Logging pods the kubelet thinks is on node c76-1-40
Jan 12 05:16:39.552: INFO: coredns-5f8bc8cbf5-r67rl started at 2019-01-11 10:32:32 +0000 UTC (0+1 container statuses recorded)
Jan 12 05:16:39.552: INFO: 	Container coredns ready: true, restart count 5
Jan 12 05:16:39.552: INFO: kube-controller-manager-c76-1-40 started at <nil> (0+0 container statuses recorded)
Jan 12 05:16:39.552: INFO: kube-scheduler-c76-1-40 started at <nil> (0+0 container statuses recorded)
Jan 12 05:16:39.552: INFO: etcd-c76-1-40 started at <nil> (0+0 container statuses recorded)
Jan 12 05:16:39.552: INFO: kube-proxy-5r9k5 started at 2019-01-11 10:27:33 +0000 UTC (0+1 container statuses recorded)
Jan 12 05:16:39.552: INFO: 	Container kube-proxy ready: true, restart count 2
Jan 12 05:16:39.552: INFO: calico-node-9mj47 started at 2019-01-11 10:27:33 +0000 UTC (1+1 container statuses recorded)
Jan 12 05:16:39.552: INFO: 	Init container install-cni ready: true, restart count 2
Jan 12 05:16:39.552: INFO: 	Container calico-node ready: true, restart count 2
Jan 12 05:16:39.552: INFO: kube-dns-autoscaler-77cfb8c949-bllxk started at 2019-01-11 10:27:33 +0000 UTC (0+1 container statuses recorded)
Jan 12 05:16:39.552: INFO: 	Container autoscaler ready: true, restart count 2
Jan 12 05:16:39.552: INFO: coredns-5f8bc8cbf5-8stsj started at 2019-01-11 10:28:50 +0000 UTC (0+1 container statuses recorded)
Jan 12 05:16:39.552: INFO: 	Container coredns ready: true, restart count 8
Jan 12 05:16:39.552: INFO: kube-apiserver-c76-1-40 started at <nil> (0+0 container statuses recorded)
Jan 12 05:16:39.552: INFO: kube-discovery-dhv7z started at 2019-01-12 01:41:17 +0000 UTC (0+1 container statuses recorded)
Jan 12 05:16:39.552: INFO: 	Container discovery ready: true, restart count 0
Jan 12 05:16:39.552: INFO: kubectl-z2zbp started at 2019-01-11 10:27:33 +0000 UTC (0+1 container statuses recorded)
Jan 12 05:16:39.552: INFO: 	Container kubectl ready: true, restart count 2
Jan 12 05:16:39.552: INFO: configure-calico-tsst7 started at 2019-01-11 10:27:33 +0000 UTC (0+1 container statuses recorded)
Jan 12 05:16:39.552: INFO: 	Container configure-calico ready: false, restart count 0
W0112 05:16:39.555535      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 12 05:16:39.571: INFO: 
Latency metrics for node c76-1-40
Jan 12 05:16:39.571: INFO: 
Logging node info for node c76-1-41
Jan 12 05:16:39.574: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:c76-1-41,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/c76-1-41,UID:2e7f7d60-158c-11e9-8eb1-000c294e6ffe,ResourceVersion:145915,Generation:0,CreationTimestamp:2019-01-11 10:32:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/os: linux,kubernetes.io/hostname: c76-1-41,},Annotations:map[string]string{kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock,node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:NodeSpec{PodCIDR:172.31.1.0/24,DoNotUse_ExternalID:,ProviderID:,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{cpu: {{4 0} {<nil>} 4 DecimalSI},ephemeral-storage: {{63318790144 0} {<nil>} 61834756Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{10464804864 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{4 0} {<nil>} 4 DecimalSI},ephemeral-storage: {{56986911036 0} {<nil>} 56986911036 DecimalSI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{10359947264 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2019-01-12 05:16:38 +0000 UTC 2019-01-11 10:32:24 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2019-01-12 05:16:38 +0000 UTC 2019-01-11 10:32:24 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-01-12 05:16:38 +0000 UTC 2019-01-11 10:32:24 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-01-12 05:16:38 +0000 UTC 2019-01-11 10:32:24 +0000 UTC KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-01-12 05:16:38 +0000 UTC 2019-01-11 10:33:34 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 192.168.1.41} {Hostname c76-1-41}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:5525b6edd57844c39a46324f54687a15,SystemUUID:564DE49B-C9A4-46EC-0CF9-607DB6F07600,BootID:29762b57-a009-4d43-96f2-4514732af44a,KernelVersion:3.10.0-957.el7.x86_64,OSImage:CentOS Linux 7 (Core),ContainerRuntimeVersion:docker://17.3.2,KubeletVersion:v1.12.3,KubeProxyVersion:v1.12.3,OperatingSystem:linux,Architecture:amd64,},Images:[{[192.168.1.52/system_containers/hyperkube-amd64@sha256:a90d413c933bb465eefed80df373fa2af8468a6bfe0182082f652e68e7a3fb13 192.168.1.52/system_containers/hyperkube-amd64:v1.12.3] 709865716} {[index.tenxcloud.com/tenx_containers/kube-conformance@sha256:f902946a54e0009b0128f2beba0df2ea122b199bb7762fcd34e787036e93475c index.tenxcloud.com/tenx_containers/kube-conformance:latest] 462484279} {[index.tenxcloud.com/tenx_containers/gb-frontend@sha256:6928fd2b434b77e638033dc0cceb90d9519ad00cbf9f22ce051b2fa17c4e0c86 gcr.io/google-samples/gb-frontend:v6 index.tenxcloud.com/tenx_containers/gb-frontend:v6] 373054764} {[index.tenxcloud.com/tenx_containers/jessie-dnsutils@sha256:07f9ed492626c1bc28aae3c0e8699fbb1159a43945e01b43cefdcc1998a805b9 gcr.io/kubernetes-e2e-test-images/jessie-dnsutils:1.0 index.tenxcloud.com/tenx_containers/jessie-dnsutils:1.0] 195633300} {[192.168.1.52/system_containers/kubectl-amd64@sha256:fd27ea38a1dc69008ecb87503813fa0bf355b0ce8ae2e596c9098993237c469a 192.168.1.52/system_containers/kubectl-amd64:v1.12.3] 166235497} {[nginx@sha256:b543f6d0983fbc25b9874e22f4fe257a567111da96fd1d8f1b44315f1236398c nginx:latest] 109154241} {[index.tenxcloud.com/tenx_containers/nginx-slim-amd64@sha256:6654db6d4028756062edac466454ee5c9cf9b20ef79e35a81e3c840031eb1e2b gcr.io/google-containers/nginx-slim:0.20 index.tenxcloud.com/tenx_containers/nginx-slim-amd64:0.20] 103565007} {[index.tenxcloud.com/tenx_containers/gb-redisslave@sha256:9ff2f9e5160bff9871d8c0fca0dd15b4b25954b322559699540ed9ac0ddfec7f gcr.io/google-samples/gb-redisslave:v3 index.tenxcloud.com/tenx_containers/gb-redisslave:v3] 98923658} {[192.168.1.52/system_containers/node@sha256:2f46157483904649f334da83e6b5e522bf20cbd3ea6ec9f43456673933021d5a 192.168.1.52/system_containers/node:v3.4.0] 75898396} {[192.168.1.52/system_containers/cni@sha256:61a410fd6512bd0747fa76798ed5c121c815d7aed94f12d02507b7406bf7ccf2 192.168.1.52/system_containers/cni:v3.4.0] 75430420} {[192.168.1.52/system_containers/agent@sha256:8844a2f97daae4dede402cfc1e719a1f7f82142690decc608c3b7e6679a2444c 192.168.1.52/system_containers/agent:v4.0.0] 68660084} {[192.168.1.52/system_containers/kube-controllers@sha256:7b549fa211f15a1b038c82cc7b11d4b3157db822aebd72c48f924620e9ec329c 192.168.1.52/system_containers/kube-controllers:v3.4.0] 56528665} {[index.tenxcloud.com/tenx_containers/namespace-deleter@sha256:1935280d17215d3e1d380fcc0efd6f7dfff5cb073538b05db7fcd41ba3ada88a index.tenxcloud.com/tenx_containers/namespace-deleter:v0.0.1] 43012728} {[192.168.1.52/system_containers/ctl@sha256:5e6685b93900eb5b79d93db0ac514f815c5bdd52c70da03bea4f7bc7debde2be 192.168.1.52/system_containers/ctl:v3.4.0] 35264750} {[index.tenxcloud.com/tenx_containers/sonobuoy@sha256:30f94f6446505251b44a43437290150273cd89d6dc3f5b8c71bb6f7c9cd7d23d index.tenxcloud.com/tenx_containers/sonobuoy:v0.13] 33389023} {[192.168.1.52/system_containers/tde@sha256:e5bacdec54bf32e15955f88ff693fa5162b9eed97c7f1c79f5299e8cdde949a3 192.168.1.52/system_containers/tde:v4.0.0] 28785861} {[index.tenxcloud.com/tenx_containers/nettest@sha256:d93ee599708eba703861aa6dee2fd3548249abfa05260bb5a691354c0a6f5e0c gcr.io/kubernetes-e2e-test-images/nettest:1.0 index.tenxcloud.com/tenx_containers/nettest:1.0] 27413498} {[nginx@sha256:385fbcf0f04621981df6c6f1abd896101eb61a439746ee2921b26abc78f45571 nginx:1.15-alpine] 17754400} {[nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 nginx:1.14-alpine] 17719601} {[index.tenxcloud.com/tenx_containers/scanner-forwarder@sha256:e5acebbbd78cf93d950abe002cecfe19db45abffec8bb8e50c09dc7163a52ad8 index.tenxcloud.com/tenx_containers/scanner-forwarder:v0.0.4] 10882452} {[index.tenxcloud.com/tenx_containers/dnsutils@sha256:f35617f790f43683c24a53f20c4ad4635cfb075a3cc52db80547bea03a57ef89 gcr.io/kubernetes-e2e-test-images/dnsutils:1.1 index.tenxcloud.com/tenx_containers/dnsutils:1.1] 9345437} {[index.tenxcloud.com/tenx_containers/hostexec@sha256:959c75dc7b8d77b7714871e1a99caec2f4c6bc5efd820a68b1477676ae52de0f gcr.io/kubernetes-e2e-test-images/hostexec:1.1 index.tenxcloud.com/tenx_containers/hostexec:1.1] 8467158} {[index.tenxcloud.com/tenx_containers/hostexec-amd64@sha256:aea5e0aec8f7b35e3271d30f304375846c5271bc369e86ead843bd30c276e60c gcr.io/kubernetes-e2e-test-images/hostexec:1.0 index.tenxcloud.com/tenx_containers/hostexec-amd64:1.0] 8351345} {[index.tenxcloud.com/tenx_containers/netexec@sha256:50de1d16ef5dd986e3ce3c7bbe3c6e5d85ba67eb29abd6e80605afa7c59e173e gcr.io/kubernetes-e2e-test-images/netexec:1.1 index.tenxcloud.com/tenx_containers/netexec:1.1] 6705349} {[index.tenxcloud.com/tenx_containers/redis@sha256:9b5b1c1ec462abb4b89145a23a1fbf7eb3b2bb25927fc94e820f89a73029889f gcr.io/kubernetes-e2e-test-images/redis:1.0 index.tenxcloud.com/tenx_containers/redis:1.0] 5901328} {[index.tenxcloud.com/tenx_containers/serve-hostname@sha256:5792caa151fd823f01e765c535bcdb0386e0e9c9a2b5687e4a613cecadfa3505 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 index.tenxcloud.com/tenx_containers/serve-hostname:1.1] 5851985} {[index.tenxcloud.com/tenx_containers/serve-hostname-amd64@sha256:bb8ec30897bcd57ab1bb73267d9cf13a8ca5dd88cc28b729c085fee834ba96c8 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.0 index.tenxcloud.com/tenx_containers/serve-hostname-amd64:1.0] 5470001} {[index.tenxcloud.com/tenx_containers/nautilus@sha256:2f8e5b5bc7ede351d03ae9a58c16cba7b37f4b17522c0345776576fca0559e8b gcr.io/kubernetes-e2e-test-images/nautilus:1.0 index.tenxcloud.com/tenx_containers/nautilus:1.0] 4753501} {[index.tenxcloud.com/tenx_containers/kitten@sha256:121b638ec01c7eeb320780b869ab1b797991e6ced43cb2a613139c7b798833d1 gcr.io/kubernetes-e2e-test-images/kitten:1.0 index.tenxcloud.com/tenx_containers/kitten:1.0] 4747037} {[index.tenxcloud.com/tenx_containers/test-webserver@sha256:ff6efa49e88f6c8307b922c2327b1ea3c23ca98c75a43986bd6c237523596d7b gcr.io/kubernetes-e2e-test-images/test-webserver:1.0 index.tenxcloud.com/tenx_containers/test-webserver:1.0] 4732240} {[index.tenxcloud.com/tenx_containers/porter-amd64@sha256:3c5fddee2d141df92fc99f06a835e2193cac444a0d0331d26384030281246b80 index.tenxcloud.com/tenx_containers/porter@sha256:3c5fddee2d141df92fc99f06a835e2193cac444a0d0331d26384030281246b80 gcr.io/kubernetes-e2e-test-images/porter:1.0 index.tenxcloud.com/tenx_containers/porter-amd64:1.0 index.tenxcloud.com/tenx_containers/porter:1.0] 4681408} {[index.tenxcloud.com/tenx_containers/liveness@sha256:1356c32eb0cc1e455dd0548f59c61582044c78ce5a7a00793133dec254f5e18f gcr.io/kubernetes-e2e-test-images/liveness:1.0 index.tenxcloud.com/tenx_containers/liveness:1.0] 4608721} {[index.tenxcloud.com/tenx_containers/entrypoint-tester@sha256:d9db86e396e77ef12b31e8cdb676a33c64c25194b0efcba9470ffdc293c9057a gcr.io/kubernetes-e2e-test-images/entrypoint-tester:1.0 index.tenxcloud.com/tenx_containers/entrypoint-tester:1.0] 2729534} {[index.tenxcloud.com/tenx_containers/mounttest@sha256:8ad000bb2d049adbbd20b889ce4f864d83056bd48ded75035516fac77b6bdee3 gcr.io/kubernetes-e2e-test-images/mounttest:1.0 index.tenxcloud.com/tenx_containers/mounttest:1.0] 1563521} {[index.tenxcloud.com/tenx_containers/mounttest-user-amd64@sha256:057dedcb5328948633813256e226841a99213f56817d1f7b0e020600dbd57179 index.tenxcloud.com/tenx_containers/mounttest-user@sha256:057dedcb5328948633813256e226841a99213f56817d1f7b0e020600dbd57179 gcr.io/kubernetes-e2e-test-images/mounttest-user:1.0 index.tenxcloud.com/tenx_containers/mounttest-user-amd64:1.0 index.tenxcloud.com/tenx_containers/mounttest-user:1.0] 1450451} {[busybox@sha256:7964ad52e396a6e045c39b5a44438424ac52e12e4d5a25d94895f2058cb863a0 busybox:latest] 1199417} {[busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796 busybox:1.29] 1154361} {[192.168.1.52/system_containers/pause@sha256:fcaff905397ba63fd376d0c3019f1f1cb6e7506131389edbcb3d22719f1ae54d index.tenxcloud.com/tenx_containers/pause@sha256:759c3f0f6493093a9043cc813092290af69029699ade0e3dbe024e968fcb7cca 192.168.1.52/system_containers/pause:3.1 index.tenxcloud.com/tenx_containers/pause:3.1 k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
Jan 12 05:16:39.574: INFO: 
Logging kubelet events for node c76-1-41
Jan 12 05:16:39.592: INFO: 
Logging pods the kubelet thinks is on node c76-1-41
Jan 12 05:16:39.597: INFO: kubectl-cp4p5 started at 2019-01-11 10:32:24 +0000 UTC (0+1 container statuses recorded)
Jan 12 05:16:39.597: INFO: 	Container kubectl ready: true, restart count 2
Jan 12 05:16:39.597: INFO: sonobuoy started at 2019-01-12 04:12:07 +0000 UTC (0+3 container statuses recorded)
Jan 12 05:16:39.597: INFO: 	Container cleanup ready: true, restart count 0
Jan 12 05:16:39.597: INFO: 	Container forwarder ready: true, restart count 0
Jan 12 05:16:39.597: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 12 05:16:39.597: INFO: sonobuoy-e2e-job-f2515c1fd49f447c started at 2019-01-12 04:12:09 +0000 UTC (0+2 container statuses recorded)
Jan 12 05:16:39.597: INFO: 	Container e2e ready: true, restart count 0
Jan 12 05:16:39.597: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 12 05:16:39.597: INFO: busybox-host-aliases3c6f5810-1620-11e9-8fb7-aa4233c46d55 started at 2019-01-12 05:15:37 +0000 UTC (0+1 container statuses recorded)
Jan 12 05:16:39.597: INFO: 	Container busybox-host-aliases3c6f5810-1620-11e9-8fb7-aa4233c46d55 ready: true, restart count 0
Jan 12 05:16:39.597: INFO: kube-proxy-k8t9z started at 2019-01-11 10:32:24 +0000 UTC (0+1 container statuses recorded)
Jan 12 05:16:39.597: INFO: 	Container kube-proxy ready: true, restart count 2
Jan 12 05:16:39.597: INFO: kube-controller-6dd888b6-2gdzh started at 2019-01-12 01:48:43 +0000 UTC (0+1 container statuses recorded)
Jan 12 05:16:39.597: INFO: 	Container kube-controller ready: true, restart count 0
Jan 12 05:16:39.597: INFO: calico-node-47p2l started at 2019-01-11 10:32:24 +0000 UTC (1+1 container statuses recorded)
Jan 12 05:16:39.597: INFO: 	Init container install-cni ready: true, restart count 2
Jan 12 05:16:39.597: INFO: 	Container calico-node ready: true, restart count 2
W0112 05:16:39.600083      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 12 05:16:39.780: INFO: 
Latency metrics for node c76-1-41
Jan 12 05:16:39.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-7smlr" for this suite.
Jan 12 05:17:23.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:17:23.841: INFO: namespace: e2e-tests-kubelet-test-7smlr, resource: bindings, ignored listing per whitelist
Jan 12 05:17:23.882: INFO: namespace e2e-tests-kubelet-test-7smlr deletion completed in 44.097950112s

• Failure [106.605 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance] [It]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

    Timed out after 60.001s.
    Expected
        <*errors.errorString | 0xc000e75fe0>: {
            s: "expected hosts file to contain entries from HostAliases. Got:\n# Kubernetes-managed hosts file.\n127.0.0.1\tlocalhost\n::1\tlocalhost ip6-localhost ip6-loopback\nfe00::0\tip6-localnet\nfe00::0\tip6-mcastprefix\nfe00::1\tip6-allnodes\nfe00::2\tip6-allrouters\n172.31.52.125\tbusybox-host-aliases3c6f5810-1620-11e9-8fb7-aa4233c46d55\n\n# Entries added by HostAliases.\n123.45.67.89\tfoo\n123.45.67.89\tbar\n",
        }
    to be nil

    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:183
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:17:23.882: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-6g9jh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 12 05:17:24.048: INFO: Waiting up to 5m0s for pod "downwardapi-volume-582e8f09-1629-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-downward-api-6g9jh" to be "success or failure"
Jan 12 05:17:24.065: INFO: Pod "downwardapi-volume-582e8f09-1629-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 16.364516ms
Jan 12 05:17:26.068: INFO: Pod "downwardapi-volume-582e8f09-1629-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019444209s
STEP: Saw pod success
Jan 12 05:17:26.068: INFO: Pod "downwardapi-volume-582e8f09-1629-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:17:26.071: INFO: Trying to get logs from node c76-1-41 pod downwardapi-volume-582e8f09-1629-11e9-8fb7-aa4233c46d55 container client-container: <nil>
STEP: delete the pod
Jan 12 05:17:26.086: INFO: Waiting for pod downwardapi-volume-582e8f09-1629-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:17:26.088: INFO: Pod downwardapi-volume-582e8f09-1629-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:17:26.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6g9jh" for this suite.
Jan 12 05:17:32.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:17:32.202: INFO: namespace: e2e-tests-downward-api-6g9jh, resource: bindings, ignored listing per whitelist
Jan 12 05:17:32.212: INFO: namespace e2e-tests-downward-api-6g9jh deletion completed in 6.11107447s

• [SLOW TEST:8.331 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:17:32.213: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8fczg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-5d260c85-1629-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume secrets
Jan 12 05:17:32.385: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5d2689f4-1629-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-projected-8fczg" to be "success or failure"
Jan 12 05:17:32.389: INFO: Pod "pod-projected-secrets-5d2689f4-1629-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 3.711998ms
Jan 12 05:17:34.393: INFO: Pod "pod-projected-secrets-5d2689f4-1629-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007321147s
STEP: Saw pod success
Jan 12 05:17:34.393: INFO: Pod "pod-projected-secrets-5d2689f4-1629-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:17:34.395: INFO: Trying to get logs from node c76-1-41 pod pod-projected-secrets-5d2689f4-1629-11e9-8fb7-aa4233c46d55 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 12 05:17:34.411: INFO: Waiting for pod pod-projected-secrets-5d2689f4-1629-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:17:34.414: INFO: Pod pod-projected-secrets-5d2689f4-1629-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:17:34.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8fczg" for this suite.
Jan 12 05:17:40.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:17:40.478: INFO: namespace: e2e-tests-projected-8fczg, resource: bindings, ignored listing per whitelist
Jan 12 05:17:40.523: INFO: namespace e2e-tests-projected-8fczg deletion completed in 6.106484197s

• [SLOW TEST:8.311 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:17:40.523: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-nj9kl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-fvfx
STEP: Creating a pod to test atomic-volume-subpath
Jan 12 05:17:40.695: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-fvfx" in namespace "e2e-tests-subpath-nj9kl" to be "success or failure"
Jan 12 05:17:40.698: INFO: Pod "pod-subpath-test-downwardapi-fvfx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.666794ms
Jan 12 05:17:42.701: INFO: Pod "pod-subpath-test-downwardapi-fvfx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006035318s
Jan 12 05:17:44.707: INFO: Pod "pod-subpath-test-downwardapi-fvfx": Phase="Running", Reason="", readiness=false. Elapsed: 4.011419999s
Jan 12 05:17:46.711: INFO: Pod "pod-subpath-test-downwardapi-fvfx": Phase="Running", Reason="", readiness=false. Elapsed: 6.01604536s
Jan 12 05:17:48.716: INFO: Pod "pod-subpath-test-downwardapi-fvfx": Phase="Running", Reason="", readiness=false. Elapsed: 8.02053183s
Jan 12 05:17:50.723: INFO: Pod "pod-subpath-test-downwardapi-fvfx": Phase="Running", Reason="", readiness=false. Elapsed: 10.02736882s
Jan 12 05:17:52.730: INFO: Pod "pod-subpath-test-downwardapi-fvfx": Phase="Running", Reason="", readiness=false. Elapsed: 12.034942386s
Jan 12 05:17:54.737: INFO: Pod "pod-subpath-test-downwardapi-fvfx": Phase="Running", Reason="", readiness=false. Elapsed: 14.041984242s
Jan 12 05:17:56.745: INFO: Pod "pod-subpath-test-downwardapi-fvfx": Phase="Running", Reason="", readiness=false. Elapsed: 16.049886847s
Jan 12 05:17:58.749: INFO: Pod "pod-subpath-test-downwardapi-fvfx": Phase="Running", Reason="", readiness=false. Elapsed: 18.054093351s
Jan 12 05:18:00.757: INFO: Pod "pod-subpath-test-downwardapi-fvfx": Phase="Running", Reason="", readiness=false. Elapsed: 20.062204955s
Jan 12 05:18:02.762: INFO: Pod "pod-subpath-test-downwardapi-fvfx": Phase="Running", Reason="", readiness=false. Elapsed: 22.06640951s
Jan 12 05:18:04.765: INFO: Pod "pod-subpath-test-downwardapi-fvfx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.069580897s
STEP: Saw pod success
Jan 12 05:18:04.765: INFO: Pod "pod-subpath-test-downwardapi-fvfx" satisfied condition "success or failure"
Jan 12 05:18:04.768: INFO: Trying to get logs from node c76-1-41 pod pod-subpath-test-downwardapi-fvfx container test-container-subpath-downwardapi-fvfx: <nil>
STEP: delete the pod
Jan 12 05:18:04.782: INFO: Waiting for pod pod-subpath-test-downwardapi-fvfx to disappear
Jan 12 05:18:04.785: INFO: Pod pod-subpath-test-downwardapi-fvfx no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-fvfx
Jan 12 05:18:04.785: INFO: Deleting pod "pod-subpath-test-downwardapi-fvfx" in namespace "e2e-tests-subpath-nj9kl"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:18:04.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-nj9kl" for this suite.
Jan 12 05:18:10.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:18:10.877: INFO: namespace: e2e-tests-subpath-nj9kl, resource: bindings, ignored listing per whitelist
Jan 12 05:18:10.907: INFO: namespace e2e-tests-subpath-nj9kl deletion completed in 6.115997499s

• [SLOW TEST:30.384 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:18:10.907: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-t59r7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 12 05:18:11.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 version'
Jan 12 05:18:11.130: INFO: stderr: ""
Jan 12 05:18:11.130: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.3\", GitCommit:\"1b9ab003f4ad0156395e173daaf6ccdf963e786e\", GitTreeState:\"clean\", BuildDate:\"2018-12-12T12:33:19Z\", GoVersion:\"go1.11\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:18:11.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-t59r7" for this suite.
Jan 12 05:18:17.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:18:17.216: INFO: namespace: e2e-tests-kubectl-t59r7, resource: bindings, ignored listing per whitelist
Jan 12 05:18:17.247: INFO: namespace e2e-tests-kubectl-t59r7 deletion completed in 6.114428948s

• [SLOW TEST:6.340 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:18:17.248: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-grflj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 12 05:18:17.413: INFO: Waiting up to 5m0s for pod "downward-api-77fd69d5-1629-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-downward-api-grflj" to be "success or failure"
Jan 12 05:18:17.416: INFO: Pod "downward-api-77fd69d5-1629-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.416466ms
Jan 12 05:18:19.419: INFO: Pod "downward-api-77fd69d5-1629-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005887649s
STEP: Saw pod success
Jan 12 05:18:19.419: INFO: Pod "downward-api-77fd69d5-1629-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:18:19.422: INFO: Trying to get logs from node c76-1-41 pod downward-api-77fd69d5-1629-11e9-8fb7-aa4233c46d55 container dapi-container: <nil>
STEP: delete the pod
Jan 12 05:18:19.438: INFO: Waiting for pod downward-api-77fd69d5-1629-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:18:19.440: INFO: Pod downward-api-77fd69d5-1629-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:18:19.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-grflj" for this suite.
Jan 12 05:18:25.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:18:25.550: INFO: namespace: e2e-tests-downward-api-grflj, resource: bindings, ignored listing per whitelist
Jan 12 05:18:25.561: INFO: namespace e2e-tests-downward-api-grflj deletion completed in 6.117202785s

• [SLOW TEST:8.313 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:18:25.561: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-x7bgl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-x7bgl.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-x7bgl.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-x7bgl.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-x7bgl.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-x7bgl.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-x7bgl.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 12 05:18:29.816: INFO: DNS probes using e2e-tests-dns-x7bgl/dns-test-7cf1dbad-1629-11e9-8fb7-aa4233c46d55 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:18:29.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-x7bgl" for this suite.
Jan 12 05:18:35.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:18:35.876: INFO: namespace: e2e-tests-dns-x7bgl, resource: bindings, ignored listing per whitelist
Jan 12 05:18:35.942: INFO: namespace e2e-tests-dns-x7bgl deletion completed in 6.108962212s

• [SLOW TEST:10.381 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:18:35.942: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-6wxpd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 12 05:18:36.102: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:18:39.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-6wxpd" for this suite.
Jan 12 05:19:01.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:19:01.999: INFO: namespace: e2e-tests-init-container-6wxpd, resource: bindings, ignored listing per whitelist
Jan 12 05:19:02.004: INFO: namespace e2e-tests-init-container-6wxpd deletion completed in 22.099275296s

• [SLOW TEST:26.062 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:19:02.004: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jxdtv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-92acf7dd-1629-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume configMaps
Jan 12 05:19:02.192: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-92ad6784-1629-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-projected-jxdtv" to be "success or failure"
Jan 12 05:19:02.199: INFO: Pod "pod-projected-configmaps-92ad6784-1629-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 7.820397ms
Jan 12 05:19:04.203: INFO: Pod "pod-projected-configmaps-92ad6784-1629-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011252181s
Jan 12 05:19:06.209: INFO: Pod "pod-projected-configmaps-92ad6784-1629-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017453884s
STEP: Saw pod success
Jan 12 05:19:06.209: INFO: Pod "pod-projected-configmaps-92ad6784-1629-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:19:06.214: INFO: Trying to get logs from node c76-1-41 pod pod-projected-configmaps-92ad6784-1629-11e9-8fb7-aa4233c46d55 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 12 05:19:06.255: INFO: Waiting for pod pod-projected-configmaps-92ad6784-1629-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:19:06.259: INFO: Pod pod-projected-configmaps-92ad6784-1629-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:19:06.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jxdtv" for this suite.
Jan 12 05:19:12.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:19:12.345: INFO: namespace: e2e-tests-projected-jxdtv, resource: bindings, ignored listing per whitelist
Jan 12 05:19:12.369: INFO: namespace e2e-tests-projected-jxdtv deletion completed in 6.105618554s

• [SLOW TEST:10.365 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:19:12.369: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-rgvwp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-rgvwp
Jan 12 05:19:16.558: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-rgvwp
STEP: checking the pod's current state and verifying that restartCount is present
Jan 12 05:19:16.565: INFO: Initial restart count of pod liveness-exec is 0
Jan 12 05:20:02.729: INFO: Restart count of pod e2e-tests-container-probe-rgvwp/liveness-exec is now 1 (46.163871197s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:20:02.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-rgvwp" for this suite.
Jan 12 05:20:08.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:20:08.832: INFO: namespace: e2e-tests-container-probe-rgvwp, resource: bindings, ignored listing per whitelist
Jan 12 05:20:08.841: INFO: namespace e2e-tests-container-probe-rgvwp deletion completed in 6.100946534s

• [SLOW TEST:56.472 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:20:08.841: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-cjqnd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 12 05:20:09.034: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ba83cabb-1629-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-projected-cjqnd" to be "success or failure"
Jan 12 05:20:09.038: INFO: Pod "downwardapi-volume-ba83cabb-1629-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 3.890423ms
Jan 12 05:20:11.041: INFO: Pod "downwardapi-volume-ba83cabb-1629-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007376633s
STEP: Saw pod success
Jan 12 05:20:11.041: INFO: Pod "downwardapi-volume-ba83cabb-1629-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:20:11.044: INFO: Trying to get logs from node c76-1-41 pod downwardapi-volume-ba83cabb-1629-11e9-8fb7-aa4233c46d55 container client-container: <nil>
STEP: delete the pod
Jan 12 05:20:11.059: INFO: Waiting for pod downwardapi-volume-ba83cabb-1629-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:20:11.062: INFO: Pod downwardapi-volume-ba83cabb-1629-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:20:11.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cjqnd" for this suite.
Jan 12 05:20:17.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:20:17.088: INFO: namespace: e2e-tests-projected-cjqnd, resource: bindings, ignored listing per whitelist
Jan 12 05:20:17.149: INFO: namespace e2e-tests-projected-cjqnd deletion completed in 6.083221561s

• [SLOW TEST:8.308 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:20:17.149: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-d4p29
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 12 05:20:17.319: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bf7572f0-1629-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-downward-api-d4p29" to be "success or failure"
Jan 12 05:20:17.321: INFO: Pod "downwardapi-volume-bf7572f0-1629-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.322887ms
Jan 12 05:20:19.325: INFO: Pod "downwardapi-volume-bf7572f0-1629-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005981394s
STEP: Saw pod success
Jan 12 05:20:19.325: INFO: Pod "downwardapi-volume-bf7572f0-1629-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:20:19.328: INFO: Trying to get logs from node c76-1-41 pod downwardapi-volume-bf7572f0-1629-11e9-8fb7-aa4233c46d55 container client-container: <nil>
STEP: delete the pod
Jan 12 05:20:19.357: INFO: Waiting for pod downwardapi-volume-bf7572f0-1629-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:20:19.360: INFO: Pod downwardapi-volume-bf7572f0-1629-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:20:19.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-d4p29" for this suite.
Jan 12 05:20:25.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:20:25.442: INFO: namespace: e2e-tests-downward-api-d4p29, resource: bindings, ignored listing per whitelist
Jan 12 05:20:25.479: INFO: namespace e2e-tests-downward-api-d4p29 deletion completed in 6.114508359s

• [SLOW TEST:8.330 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:20:25.479: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-bdcx5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-bdcx5/secret-test-c4711d9a-1629-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume secrets
Jan 12 05:20:25.681: INFO: Waiting up to 5m0s for pod "pod-configmaps-c471971b-1629-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-secrets-bdcx5" to be "success or failure"
Jan 12 05:20:25.684: INFO: Pod "pod-configmaps-c471971b-1629-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.243174ms
Jan 12 05:20:27.687: INFO: Pod "pod-configmaps-c471971b-1629-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005787599s
STEP: Saw pod success
Jan 12 05:20:27.687: INFO: Pod "pod-configmaps-c471971b-1629-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:20:27.690: INFO: Trying to get logs from node c76-1-41 pod pod-configmaps-c471971b-1629-11e9-8fb7-aa4233c46d55 container env-test: <nil>
STEP: delete the pod
Jan 12 05:20:27.707: INFO: Waiting for pod pod-configmaps-c471971b-1629-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:20:27.709: INFO: Pod pod-configmaps-c471971b-1629-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:20:27.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bdcx5" for this suite.
Jan 12 05:20:33.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:20:33.804: INFO: namespace: e2e-tests-secrets-bdcx5, resource: bindings, ignored listing per whitelist
Jan 12 05:20:33.809: INFO: namespace e2e-tests-secrets-bdcx5 deletion completed in 6.097432224s

• [SLOW TEST:8.331 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:20:33.810: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-jfn7b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-jfn7b
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-jfn7b
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-jfn7b
Jan 12 05:20:34.000: INFO: Found 0 stateful pods, waiting for 1
Jan 12 05:20:44.006: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jan 12 05:20:44.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 exec --namespace=e2e-tests-statefulset-jfn7b ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 12 05:20:44.169: INFO: stderr: ""
Jan 12 05:20:44.169: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 12 05:20:44.169: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 12 05:20:44.171: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan 12 05:20:54.179: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 12 05:20:54.179: INFO: Waiting for statefulset status.replicas updated to 0
Jan 12 05:20:54.206: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999348s
Jan 12 05:20:55.215: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.993176403s
Jan 12 05:20:56.220: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.984115442s
Jan 12 05:20:57.224: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.978801222s
Jan 12 05:20:58.233: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.974634304s
Jan 12 05:20:59.239: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.965198475s
Jan 12 05:21:00.248: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.960169322s
Jan 12 05:21:01.256: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.95171865s
Jan 12 05:21:02.262: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.943419731s
Jan 12 05:21:03.270: INFO: Verifying statefulset ss doesn't scale past 1 for another 937.088842ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-jfn7b
Jan 12 05:21:04.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 exec --namespace=e2e-tests-statefulset-jfn7b ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 12 05:21:04.552: INFO: stderr: ""
Jan 12 05:21:04.552: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 12 05:21:04.552: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 12 05:21:04.555: INFO: Found 1 stateful pods, waiting for 3
Jan 12 05:21:14.559: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 12 05:21:14.559: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 12 05:21:14.559: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jan 12 05:21:14.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 exec --namespace=e2e-tests-statefulset-jfn7b ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 12 05:21:14.791: INFO: stderr: ""
Jan 12 05:21:14.791: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 12 05:21:14.791: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 12 05:21:14.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 exec --namespace=e2e-tests-statefulset-jfn7b ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 12 05:21:14.912: INFO: stderr: ""
Jan 12 05:21:14.912: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 12 05:21:14.912: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 12 05:21:14.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 exec --namespace=e2e-tests-statefulset-jfn7b ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 12 05:21:15.034: INFO: stderr: ""
Jan 12 05:21:15.034: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 12 05:21:15.034: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 12 05:21:15.034: INFO: Waiting for statefulset status.replicas updated to 0
Jan 12 05:21:15.036: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Jan 12 05:21:25.052: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 12 05:21:25.053: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 12 05:21:25.053: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 12 05:21:25.075: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998815s
Jan 12 05:21:26.115: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993510569s
Jan 12 05:21:27.122: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.952270651s
Jan 12 05:21:28.128: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.9455089s
Jan 12 05:21:29.139: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.939488383s
Jan 12 05:21:30.148: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.928377993s
Jan 12 05:21:31.158: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.919578756s
Jan 12 05:21:32.168: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.908907711s
Jan 12 05:21:33.178: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.89944572s
Jan 12 05:21:34.187: INFO: Verifying statefulset ss doesn't scale past 3 for another 890.171568ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-jfn7b
Jan 12 05:21:35.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 exec --namespace=e2e-tests-statefulset-jfn7b ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 12 05:21:35.430: INFO: stderr: ""
Jan 12 05:21:35.430: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 12 05:21:35.430: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 12 05:21:35.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 exec --namespace=e2e-tests-statefulset-jfn7b ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 12 05:21:35.600: INFO: stderr: ""
Jan 12 05:21:35.600: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 12 05:21:35.600: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 12 05:21:35.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 exec --namespace=e2e-tests-statefulset-jfn7b ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 12 05:21:35.815: INFO: stderr: ""
Jan 12 05:21:35.815: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 12 05:21:35.815: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 12 05:21:35.815: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 12 05:21:55.847: INFO: Deleting all statefulset in ns e2e-tests-statefulset-jfn7b
Jan 12 05:21:55.851: INFO: Scaling statefulset ss to 0
Jan 12 05:21:55.859: INFO: Waiting for statefulset status.replicas updated to 0
Jan 12 05:21:55.862: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:21:55.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-jfn7b" for this suite.
Jan 12 05:22:01.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:22:01.924: INFO: namespace: e2e-tests-statefulset-jfn7b, resource: bindings, ignored listing per whitelist
Jan 12 05:22:01.963: INFO: namespace e2e-tests-statefulset-jfn7b deletion completed in 6.083605386s

• [SLOW TEST:88.153 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:22:01.963: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-jxcrf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0112 05:22:08.194512      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 12 05:22:08.194: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:22:08.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-jxcrf" for this suite.
Jan 12 05:22:14.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:22:14.329: INFO: namespace: e2e-tests-gc-jxcrf, resource: bindings, ignored listing per whitelist
Jan 12 05:22:14.354: INFO: namespace e2e-tests-gc-jxcrf deletion completed in 6.156262065s

• [SLOW TEST:12.392 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:22:14.354: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-xdhlf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Jan 12 05:22:14.599: INFO: Waiting up to 5m0s for pod "client-containers-055bf763-162a-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-containers-xdhlf" to be "success or failure"
Jan 12 05:22:14.623: INFO: Pod "client-containers-055bf763-162a-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 23.661755ms
Jan 12 05:22:16.630: INFO: Pod "client-containers-055bf763-162a-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031203553s
STEP: Saw pod success
Jan 12 05:22:16.631: INFO: Pod "client-containers-055bf763-162a-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:22:16.636: INFO: Trying to get logs from node c76-1-41 pod client-containers-055bf763-162a-11e9-8fb7-aa4233c46d55 container test-container: <nil>
STEP: delete the pod
Jan 12 05:22:16.671: INFO: Waiting for pod client-containers-055bf763-162a-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:22:16.675: INFO: Pod client-containers-055bf763-162a-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:22:16.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-xdhlf" for this suite.
Jan 12 05:22:22.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:22:22.783: INFO: namespace: e2e-tests-containers-xdhlf, resource: bindings, ignored listing per whitelist
Jan 12 05:22:22.793: INFO: namespace e2e-tests-containers-xdhlf deletion completed in 6.113844087s

• [SLOW TEST:8.439 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:22:22.793: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-hss46
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-0a58462c-162a-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume configMaps
Jan 12 05:22:22.959: INFO: Waiting up to 5m0s for pod "pod-configmaps-0a58b948-162a-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-configmap-hss46" to be "success or failure"
Jan 12 05:22:22.963: INFO: Pod "pod-configmaps-0a58b948-162a-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 3.679023ms
Jan 12 05:22:24.971: INFO: Pod "pod-configmaps-0a58b948-162a-11e9-8fb7-aa4233c46d55": Phase="Running", Reason="", readiness=true. Elapsed: 2.011341112s
Jan 12 05:22:26.981: INFO: Pod "pod-configmaps-0a58b948-162a-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02154696s
STEP: Saw pod success
Jan 12 05:22:26.981: INFO: Pod "pod-configmaps-0a58b948-162a-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:22:26.988: INFO: Trying to get logs from node c76-1-41 pod pod-configmaps-0a58b948-162a-11e9-8fb7-aa4233c46d55 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 12 05:22:27.037: INFO: Waiting for pod pod-configmaps-0a58b948-162a-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:22:27.042: INFO: Pod pod-configmaps-0a58b948-162a-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:22:27.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hss46" for this suite.
Jan 12 05:22:33.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:22:33.136: INFO: namespace: e2e-tests-configmap-hss46, resource: bindings, ignored listing per whitelist
Jan 12 05:22:33.152: INFO: namespace e2e-tests-configmap-hss46 deletion completed in 6.105992604s

• [SLOW TEST:10.359 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:22:33.152: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-d8lzc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan 12 05:22:33.356: INFO: Waiting up to 5m0s for pod "pod-10897723-162a-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-emptydir-d8lzc" to be "success or failure"
Jan 12 05:22:33.360: INFO: Pod "pod-10897723-162a-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 4.254575ms
Jan 12 05:22:35.367: INFO: Pod "pod-10897723-162a-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011556752s
Jan 12 05:22:37.371: INFO: Pod "pod-10897723-162a-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015110164s
STEP: Saw pod success
Jan 12 05:22:37.371: INFO: Pod "pod-10897723-162a-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:22:37.373: INFO: Trying to get logs from node c76-1-41 pod pod-10897723-162a-11e9-8fb7-aa4233c46d55 container test-container: <nil>
STEP: delete the pod
Jan 12 05:22:37.393: INFO: Waiting for pod pod-10897723-162a-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:22:37.397: INFO: Pod pod-10897723-162a-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:22:37.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-d8lzc" for this suite.
Jan 12 05:22:43.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:22:43.469: INFO: namespace: e2e-tests-emptydir-d8lzc, resource: bindings, ignored listing per whitelist
Jan 12 05:22:43.525: INFO: namespace e2e-tests-emptydir-d8lzc deletion completed in 6.125222631s

• [SLOW TEST:10.373 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:22:43.526: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-dprvc
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-16b52671-162a-11e9-8fb7-aa4233c46d55
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-16b52671-162a-11e9-8fb7-aa4233c46d55
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:22:47.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dprvc" for this suite.
Jan 12 05:23:09.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:23:09.821: INFO: namespace: e2e-tests-projected-dprvc, resource: bindings, ignored listing per whitelist
Jan 12 05:23:09.876: INFO: namespace e2e-tests-projected-dprvc deletion completed in 22.103040084s

• [SLOW TEST:26.350 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:23:09.876: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-9f2k6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0112 05:23:20.242741      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 12 05:23:20.242: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:23:20.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-9f2k6" for this suite.
Jan 12 05:23:26.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:23:26.460: INFO: namespace: e2e-tests-gc-9f2k6, resource: bindings, ignored listing per whitelist
Jan 12 05:23:26.495: INFO: namespace e2e-tests-gc-9f2k6 deletion completed in 6.246651272s

• [SLOW TEST:16.619 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:23:26.495: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-cpxkj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-305425f4-162a-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume secrets
Jan 12 05:23:26.686: INFO: Waiting up to 5m0s for pod "pod-secrets-30549dbb-162a-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-secrets-cpxkj" to be "success or failure"
Jan 12 05:23:26.688: INFO: Pod "pod-secrets-30549dbb-162a-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.540653ms
Jan 12 05:23:28.692: INFO: Pod "pod-secrets-30549dbb-162a-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006081203s
Jan 12 05:23:30.700: INFO: Pod "pod-secrets-30549dbb-162a-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01390286s
STEP: Saw pod success
Jan 12 05:23:30.700: INFO: Pod "pod-secrets-30549dbb-162a-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:23:30.707: INFO: Trying to get logs from node c76-1-41 pod pod-secrets-30549dbb-162a-11e9-8fb7-aa4233c46d55 container secret-volume-test: <nil>
STEP: delete the pod
Jan 12 05:23:30.745: INFO: Waiting for pod pod-secrets-30549dbb-162a-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:23:30.747: INFO: Pod pod-secrets-30549dbb-162a-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:23:30.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-cpxkj" for this suite.
Jan 12 05:23:36.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:23:36.870: INFO: namespace: e2e-tests-secrets-cpxkj, resource: bindings, ignored listing per whitelist
Jan 12 05:23:36.912: INFO: namespace e2e-tests-secrets-cpxkj deletion completed in 6.161279047s

• [SLOW TEST:10.417 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:23:36.913: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-k6tb2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 12 05:23:37.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-k6tb2'
Jan 12 05:23:37.308: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan 12 05:23:37.308: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Jan 12 05:23:37.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-k6tb2'
Jan 12 05:23:37.396: INFO: stderr: ""
Jan 12 05:23:37.396: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:23:37.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k6tb2" for this suite.
Jan 12 05:23:59.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:23:59.457: INFO: namespace: e2e-tests-kubectl-k6tb2, resource: bindings, ignored listing per whitelist
Jan 12 05:23:59.524: INFO: namespace e2e-tests-kubectl-k6tb2 deletion completed in 22.124517969s

• [SLOW TEST:22.611 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:23:59.524: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-9lqfw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:24:59.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-9lqfw" for this suite.
Jan 12 05:25:21.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:25:21.794: INFO: namespace: e2e-tests-container-probe-9lqfw, resource: bindings, ignored listing per whitelist
Jan 12 05:25:21.804: INFO: namespace e2e-tests-container-probe-9lqfw deletion completed in 22.101762889s

• [SLOW TEST:82.280 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:25:21.804: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-56s8j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 12 05:25:21.966: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jan 12 05:25:21.973: INFO: Pod name sample-pod: Found 0 pods out of 1
Jan 12 05:25:26.976: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 12 05:25:26.976: INFO: Creating deployment "test-rolling-update-deployment"
Jan 12 05:25:26.980: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jan 12 05:25:26.985: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jan 12 05:25:28.993: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jan 12 05:25:28.999: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682867526, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682867526, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682867527, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682867526, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 12 05:25:31.004: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 12 05:25:31.019: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-56s8j,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-56s8j/deployments/test-rolling-update-deployment,UID:7807f8c9-162a-11e9-b7e1-000c294e6ffe,ResourceVersion:148198,Generation:1,CreationTimestamp:2019-01-12 05:25:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-01-12 05:25:26 +0000 UTC 2019-01-12 05:25:26 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-01-12 05:25:29 +0000 UTC 2019-01-12 05:25:26 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan 12 05:25:31.023: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-56s8j,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-56s8j/replicasets/test-rolling-update-deployment-65b7695dcf,UID:7809ddb6-162a-11e9-b7e1-000c294e6ffe,ResourceVersion:148189,Generation:1,CreationTimestamp:2019-01-12 05:25:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 7807f8c9-162a-11e9-b7e1-000c294e6ffe 0xc001c2cdf7 0xc001c2cdf8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 12 05:25:31.023: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jan 12 05:25:31.024: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-56s8j,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-56s8j/replicasets/test-rolling-update-controller,UID:750b7127-162a-11e9-b7e1-000c294e6ffe,ResourceVersion:148197,Generation:2,CreationTimestamp:2019-01-12 05:25:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 7807f8c9-162a-11e9-b7e1-000c294e6ffe 0xc001c2cd37 0xc001c2cd38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 12 05:25:31.028: INFO: Pod "test-rolling-update-deployment-65b7695dcf-bffth" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-bffth,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-56s8j,SelfLink:/api/v1/namespaces/e2e-tests-deployment-56s8j/pods/test-rolling-update-deployment-65b7695dcf-bffth,UID:780a653a-162a-11e9-b7e1-000c294e6ffe,ResourceVersion:148188,Generation:0,CreationTimestamp:2019-01-12 05:25:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf 7809ddb6-162a-11e9-b7e1-000c294e6ffe 0xc001c2d6c7 0xc001c2d6c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9k2k2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9k2k2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-9k2k2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c2d740} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c2d760}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 05:25:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 05:25:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 05:25:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 05:25:26 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:172.31.52.127,StartTime:2019-01-12 05:25:27 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-01-12 05:25:28 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://index.tenxcloud.com/tenx_containers/redis@sha256:9b5b1c1ec462abb4b89145a23a1fbf7eb3b2bb25927fc94e820f89a73029889f docker://2c24df9f320d317ed4c4b2c9078a65319b8475c0b525ce4971a4b89c0f578b36}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:25:31.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-56s8j" for this suite.
Jan 12 05:25:37.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:25:37.126: INFO: namespace: e2e-tests-deployment-56s8j, resource: bindings, ignored listing per whitelist
Jan 12 05:25:37.130: INFO: namespace e2e-tests-deployment-56s8j deletion completed in 6.098547168s

• [SLOW TEST:15.326 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:25:37.130: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-rmndg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0112 05:25:47.458815      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 12 05:25:47.459: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:25:47.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-rmndg" for this suite.
Jan 12 05:25:53.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:25:53.537: INFO: namespace: e2e-tests-gc-rmndg, resource: bindings, ignored listing per whitelist
Jan 12 05:25:53.618: INFO: namespace e2e-tests-gc-rmndg deletion completed in 6.152309266s

• [SLOW TEST:16.488 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:25:53.618: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-cjrlg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan 12 05:25:53.844: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:25:53.847: INFO: Number of nodes with available pods: 0
Jan 12 05:25:53.847: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:25:54.851: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:25:54.853: INFO: Number of nodes with available pods: 0
Jan 12 05:25:54.853: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:25:55.857: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:25:55.865: INFO: Number of nodes with available pods: 1
Jan 12 05:25:55.865: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jan 12 05:25:55.892: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:25:55.895: INFO: Number of nodes with available pods: 0
Jan 12 05:25:55.895: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:25:56.899: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:25:56.902: INFO: Number of nodes with available pods: 0
Jan 12 05:25:56.902: INFO: Node c76-1-41 is running more than one daemon pod
Jan 12 05:25:57.907: INFO: DaemonSet pods can't tolerate node c76-1-40 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 12 05:25:57.914: INFO: Number of nodes with available pods: 1
Jan 12 05:25:57.914: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-cjrlg, will wait for the garbage collector to delete the pods
Jan 12 05:25:57.989: INFO: Deleting DaemonSet.extensions daemon-set took: 6.687432ms
Jan 12 05:25:58.090: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.665219ms
Jan 12 05:26:33.593: INFO: Number of nodes with available pods: 0
Jan 12 05:26:33.593: INFO: Number of running nodes: 0, number of available pods: 0
Jan 12 05:26:33.595: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-cjrlg/daemonsets","resourceVersion":"148448"},"items":null}

Jan 12 05:26:33.597: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-cjrlg/pods","resourceVersion":"148448"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:26:33.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-cjrlg" for this suite.
Jan 12 05:26:39.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:26:39.625: INFO: namespace: e2e-tests-daemonsets-cjrlg, resource: bindings, ignored listing per whitelist
Jan 12 05:26:39.692: INFO: namespace e2e-tests-daemonsets-cjrlg deletion completed in 6.086955094s

• [SLOW TEST:46.075 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:26:39.693: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-72vlp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 12 05:26:39.850: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:26:43.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-72vlp" for this suite.
Jan 12 05:26:49.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:26:49.460: INFO: namespace: e2e-tests-init-container-72vlp, resource: bindings, ignored listing per whitelist
Jan 12 05:26:49.490: INFO: namespace e2e-tests-init-container-72vlp deletion completed in 6.122474905s

• [SLOW TEST:9.798 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:26:49.491: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-j4hwc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-9dkr
STEP: Creating a pod to test atomic-volume-subpath
Jan 12 05:26:49.661: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-9dkr" in namespace "e2e-tests-subpath-j4hwc" to be "success or failure"
Jan 12 05:26:49.665: INFO: Pod "pod-subpath-test-secret-9dkr": Phase="Pending", Reason="", readiness=false. Elapsed: 3.590984ms
Jan 12 05:26:51.669: INFO: Pod "pod-subpath-test-secret-9dkr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00730124s
Jan 12 05:26:53.673: INFO: Pod "pod-subpath-test-secret-9dkr": Phase="Running", Reason="", readiness=false. Elapsed: 4.011409781s
Jan 12 05:26:55.677: INFO: Pod "pod-subpath-test-secret-9dkr": Phase="Running", Reason="", readiness=false. Elapsed: 6.015333283s
Jan 12 05:26:57.680: INFO: Pod "pod-subpath-test-secret-9dkr": Phase="Running", Reason="", readiness=false. Elapsed: 8.018639005s
Jan 12 05:26:59.685: INFO: Pod "pod-subpath-test-secret-9dkr": Phase="Running", Reason="", readiness=false. Elapsed: 10.023453907s
Jan 12 05:27:01.694: INFO: Pod "pod-subpath-test-secret-9dkr": Phase="Running", Reason="", readiness=false. Elapsed: 12.032112854s
Jan 12 05:27:03.708: INFO: Pod "pod-subpath-test-secret-9dkr": Phase="Running", Reason="", readiness=false. Elapsed: 14.046330141s
Jan 12 05:27:05.713: INFO: Pod "pod-subpath-test-secret-9dkr": Phase="Running", Reason="", readiness=false. Elapsed: 16.051796383s
Jan 12 05:27:07.721: INFO: Pod "pod-subpath-test-secret-9dkr": Phase="Running", Reason="", readiness=false. Elapsed: 18.059379185s
Jan 12 05:27:09.728: INFO: Pod "pod-subpath-test-secret-9dkr": Phase="Running", Reason="", readiness=false. Elapsed: 20.066963316s
Jan 12 05:27:11.733: INFO: Pod "pod-subpath-test-secret-9dkr": Phase="Running", Reason="", readiness=false. Elapsed: 22.071286619s
Jan 12 05:27:13.741: INFO: Pod "pod-subpath-test-secret-9dkr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.079605845s
STEP: Saw pod success
Jan 12 05:27:13.741: INFO: Pod "pod-subpath-test-secret-9dkr" satisfied condition "success or failure"
Jan 12 05:27:13.748: INFO: Trying to get logs from node c76-1-41 pod pod-subpath-test-secret-9dkr container test-container-subpath-secret-9dkr: <nil>
STEP: delete the pod
Jan 12 05:27:13.794: INFO: Waiting for pod pod-subpath-test-secret-9dkr to disappear
Jan 12 05:27:13.800: INFO: Pod pod-subpath-test-secret-9dkr no longer exists
STEP: Deleting pod pod-subpath-test-secret-9dkr
Jan 12 05:27:13.800: INFO: Deleting pod "pod-subpath-test-secret-9dkr" in namespace "e2e-tests-subpath-j4hwc"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:27:13.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-j4hwc" for this suite.
Jan 12 05:27:19.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:27:19.839: INFO: namespace: e2e-tests-subpath-j4hwc, resource: bindings, ignored listing per whitelist
Jan 12 05:27:19.903: INFO: namespace e2e-tests-subpath-j4hwc deletion completed in 6.096384861s

• [SLOW TEST:30.413 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:27:19.903: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-6vtdj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jan 12 05:27:20.085: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-6vtdj,SelfLink:/api/v1/namespaces/e2e-tests-watch-6vtdj/configmaps/e2e-watch-test-label-changed,UID:bb7099db-162a-11e9-b7e1-000c294e6ffe,ResourceVersion:148639,Generation:0,CreationTimestamp:2019-01-12 05:27:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 12 05:27:20.085: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-6vtdj,SelfLink:/api/v1/namespaces/e2e-tests-watch-6vtdj/configmaps/e2e-watch-test-label-changed,UID:bb7099db-162a-11e9-b7e1-000c294e6ffe,ResourceVersion:148640,Generation:0,CreationTimestamp:2019-01-12 05:27:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan 12 05:27:20.086: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-6vtdj,SelfLink:/api/v1/namespaces/e2e-tests-watch-6vtdj/configmaps/e2e-watch-test-label-changed,UID:bb7099db-162a-11e9-b7e1-000c294e6ffe,ResourceVersion:148641,Generation:0,CreationTimestamp:2019-01-12 05:27:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jan 12 05:27:30.115: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-6vtdj,SelfLink:/api/v1/namespaces/e2e-tests-watch-6vtdj/configmaps/e2e-watch-test-label-changed,UID:bb7099db-162a-11e9-b7e1-000c294e6ffe,ResourceVersion:148656,Generation:0,CreationTimestamp:2019-01-12 05:27:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 12 05:27:30.116: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-6vtdj,SelfLink:/api/v1/namespaces/e2e-tests-watch-6vtdj/configmaps/e2e-watch-test-label-changed,UID:bb7099db-162a-11e9-b7e1-000c294e6ffe,ResourceVersion:148657,Generation:0,CreationTimestamp:2019-01-12 05:27:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jan 12 05:27:30.116: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-6vtdj,SelfLink:/api/v1/namespaces/e2e-tests-watch-6vtdj/configmaps/e2e-watch-test-label-changed,UID:bb7099db-162a-11e9-b7e1-000c294e6ffe,ResourceVersion:148658,Generation:0,CreationTimestamp:2019-01-12 05:27:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:27:30.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-6vtdj" for this suite.
Jan 12 05:27:36.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:27:36.193: INFO: namespace: e2e-tests-watch-6vtdj, resource: bindings, ignored listing per whitelist
Jan 12 05:27:36.199: INFO: namespace e2e-tests-watch-6vtdj deletion completed in 6.080177039s

• [SLOW TEST:16.296 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:27:36.200: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-fssjq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 12 05:27:36.359: INFO: PodSpec: initContainers in spec.initContainers
Jan 12 05:28:18.068: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-c526bfbd-162a-11e9-8fb7-aa4233c46d55", GenerateName:"", Namespace:"e2e-tests-init-container-fssjq", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-fssjq/pods/pod-init-c526bfbd-162a-11e9-8fb7-aa4233c46d55", UID:"c526a673-162a-11e9-b7e1-000c294e6ffe", ResourceVersion:"148765", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63682867656, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"359933118"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-74h7v", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002856340), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-74h7v", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-74h7v", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-74h7v", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002bc42a8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"c76-1-41", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002076120), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002bc4650)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002bc46a0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002bc46a8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682867656, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682867656, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682867656, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682867656, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.1.41", PodIP:"172.31.52.104", StartTime:(*v1.Time)(0xc002c90100), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0028142a0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002814380)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://c17754f5ebda06733721b2e19f33e86bc166776a01913d499a1f5bac08dc381c"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002c90140), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002c90120), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:28:18.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-fssjq" for this suite.
Jan 12 05:28:40.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:28:40.197: INFO: namespace: e2e-tests-init-container-fssjq, resource: bindings, ignored listing per whitelist
Jan 12 05:28:40.227: INFO: namespace e2e-tests-init-container-fssjq deletion completed in 22.148393807s

• [SLOW TEST:64.027 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:28:40.227: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-pqj4w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jan 12 05:28:40.424: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 12 05:28:40.432: INFO: Waiting for terminating namespaces to be deleted...
Jan 12 05:28:40.447: INFO: 
Logging pods the kubelet thinks is on node c76-1-41 before test
Jan 12 05:28:40.454: INFO: kubectl-cp4p5 from kube-system started at 2019-01-11 10:32:24 +0000 UTC (1 container statuses recorded)
Jan 12 05:28:40.454: INFO: 	Container kubectl ready: true, restart count 2
Jan 12 05:28:40.454: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-12 04:12:07 +0000 UTC (3 container statuses recorded)
Jan 12 05:28:40.454: INFO: 	Container cleanup ready: true, restart count 0
Jan 12 05:28:40.454: INFO: 	Container forwarder ready: true, restart count 0
Jan 12 05:28:40.454: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 12 05:28:40.454: INFO: sonobuoy-e2e-job-f2515c1fd49f447c from heptio-sonobuoy started at 2019-01-12 04:12:09 +0000 UTC (2 container statuses recorded)
Jan 12 05:28:40.454: INFO: 	Container e2e ready: true, restart count 0
Jan 12 05:28:40.454: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 12 05:28:40.454: INFO: kube-proxy-k8t9z from kube-system started at 2019-01-11 10:32:24 +0000 UTC (1 container statuses recorded)
Jan 12 05:28:40.454: INFO: 	Container kube-proxy ready: true, restart count 2
Jan 12 05:28:40.454: INFO: kube-controller-6dd888b6-2gdzh from kube-system started at 2019-01-12 01:48:43 +0000 UTC (1 container statuses recorded)
Jan 12 05:28:40.454: INFO: 	Container kube-controller ready: true, restart count 0
Jan 12 05:28:40.454: INFO: calico-node-47p2l from kube-system started at 2019-01-11 10:32:24 +0000 UTC (1 container statuses recorded)
Jan 12 05:28:40.454: INFO: 	Container calico-node ready: true, restart count 2
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.157902b4532503ec], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:28:41.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-pqj4w" for this suite.
Jan 12 05:28:47.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:28:47.547: INFO: namespace: e2e-tests-sched-pred-pqj4w, resource: bindings, ignored listing per whitelist
Jan 12 05:28:47.613: INFO: namespace e2e-tests-sched-pred-pqj4w deletion completed in 6.09675859s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.386 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:28:47.613: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-8tp9g
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Jan 12 05:28:48.298: INFO: Waiting up to 5m0s for pod "pod-service-account-f00591fc-162a-11e9-8fb7-aa4233c46d55-lwb8q" in namespace "e2e-tests-svcaccounts-8tp9g" to be "success or failure"
Jan 12 05:28:48.304: INFO: Pod "pod-service-account-f00591fc-162a-11e9-8fb7-aa4233c46d55-lwb8q": Phase="Pending", Reason="", readiness=false. Elapsed: 6.418071ms
Jan 12 05:28:50.308: INFO: Pod "pod-service-account-f00591fc-162a-11e9-8fb7-aa4233c46d55-lwb8q": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010273727s
Jan 12 05:28:52.312: INFO: Pod "pod-service-account-f00591fc-162a-11e9-8fb7-aa4233c46d55-lwb8q": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013991879s
STEP: Saw pod success
Jan 12 05:28:52.312: INFO: Pod "pod-service-account-f00591fc-162a-11e9-8fb7-aa4233c46d55-lwb8q" satisfied condition "success or failure"
Jan 12 05:28:52.315: INFO: Trying to get logs from node c76-1-41 pod pod-service-account-f00591fc-162a-11e9-8fb7-aa4233c46d55-lwb8q container token-test: <nil>
STEP: delete the pod
Jan 12 05:28:52.334: INFO: Waiting for pod pod-service-account-f00591fc-162a-11e9-8fb7-aa4233c46d55-lwb8q to disappear
Jan 12 05:28:52.337: INFO: Pod pod-service-account-f00591fc-162a-11e9-8fb7-aa4233c46d55-lwb8q no longer exists
STEP: Creating a pod to test consume service account root CA
Jan 12 05:28:52.341: INFO: Waiting up to 5m0s for pod "pod-service-account-f00591fc-162a-11e9-8fb7-aa4233c46d55-czvjz" in namespace "e2e-tests-svcaccounts-8tp9g" to be "success or failure"
Jan 12 05:28:52.349: INFO: Pod "pod-service-account-f00591fc-162a-11e9-8fb7-aa4233c46d55-czvjz": Phase="Pending", Reason="", readiness=false. Elapsed: 7.569132ms
Jan 12 05:28:54.352: INFO: Pod "pod-service-account-f00591fc-162a-11e9-8fb7-aa4233c46d55-czvjz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010709825s
Jan 12 05:28:56.356: INFO: Pod "pod-service-account-f00591fc-162a-11e9-8fb7-aa4233c46d55-czvjz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014833729s
STEP: Saw pod success
Jan 12 05:28:56.356: INFO: Pod "pod-service-account-f00591fc-162a-11e9-8fb7-aa4233c46d55-czvjz" satisfied condition "success or failure"
Jan 12 05:28:56.359: INFO: Trying to get logs from node c76-1-41 pod pod-service-account-f00591fc-162a-11e9-8fb7-aa4233c46d55-czvjz container root-ca-test: <nil>
STEP: delete the pod
Jan 12 05:28:56.375: INFO: Waiting for pod pod-service-account-f00591fc-162a-11e9-8fb7-aa4233c46d55-czvjz to disappear
Jan 12 05:28:56.387: INFO: Pod pod-service-account-f00591fc-162a-11e9-8fb7-aa4233c46d55-czvjz no longer exists
STEP: Creating a pod to test consume service account namespace
Jan 12 05:28:56.391: INFO: Waiting up to 5m0s for pod "pod-service-account-f00591fc-162a-11e9-8fb7-aa4233c46d55-hrlhx" in namespace "e2e-tests-svcaccounts-8tp9g" to be "success or failure"
Jan 12 05:28:56.394: INFO: Pod "pod-service-account-f00591fc-162a-11e9-8fb7-aa4233c46d55-hrlhx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.767077ms
Jan 12 05:28:58.397: INFO: Pod "pod-service-account-f00591fc-162a-11e9-8fb7-aa4233c46d55-hrlhx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005812593s
Jan 12 05:29:00.405: INFO: Pod "pod-service-account-f00591fc-162a-11e9-8fb7-aa4233c46d55-hrlhx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013736922s
STEP: Saw pod success
Jan 12 05:29:00.405: INFO: Pod "pod-service-account-f00591fc-162a-11e9-8fb7-aa4233c46d55-hrlhx" satisfied condition "success or failure"
Jan 12 05:29:00.413: INFO: Trying to get logs from node c76-1-41 pod pod-service-account-f00591fc-162a-11e9-8fb7-aa4233c46d55-hrlhx container namespace-test: <nil>
STEP: delete the pod
Jan 12 05:29:00.473: INFO: Waiting for pod pod-service-account-f00591fc-162a-11e9-8fb7-aa4233c46d55-hrlhx to disappear
Jan 12 05:29:00.476: INFO: Pod pod-service-account-f00591fc-162a-11e9-8fb7-aa4233c46d55-hrlhx no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:29:00.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-8tp9g" for this suite.
Jan 12 05:29:06.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:29:06.544: INFO: namespace: e2e-tests-svcaccounts-8tp9g, resource: bindings, ignored listing per whitelist
Jan 12 05:29:06.577: INFO: namespace e2e-tests-svcaccounts-8tp9g deletion completed in 6.097930554s

• [SLOW TEST:18.964 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:29:06.577: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-td7bd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-td7bd
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 12 05:29:06.742: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 12 05:29:26.815: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 172.31.52.97 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-td7bd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 12 05:29:26.815: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
Jan 12 05:29:27.898: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:29:27.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-td7bd" for this suite.
Jan 12 05:29:49.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:29:49.963: INFO: namespace: e2e-tests-pod-network-test-td7bd, resource: bindings, ignored listing per whitelist
Jan 12 05:29:50.024: INFO: namespace e2e-tests-pod-network-test-td7bd deletion completed in 22.119438527s

• [SLOW TEST:43.447 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:29:50.024: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-7j2m7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Jan 12 05:29:50.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 create -f - --namespace=e2e-tests-kubectl-7j2m7'
Jan 12 05:29:50.525: INFO: stderr: ""
Jan 12 05:29:50.525: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Jan 12 05:29:51.529: INFO: Selector matched 1 pods for map[app:redis]
Jan 12 05:29:51.529: INFO: Found 0 / 1
Jan 12 05:29:52.535: INFO: Selector matched 1 pods for map[app:redis]
Jan 12 05:29:52.535: INFO: Found 1 / 1
Jan 12 05:29:52.536: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 12 05:29:52.543: INFO: Selector matched 1 pods for map[app:redis]
Jan 12 05:29:52.543: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Jan 12 05:29:52.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 logs redis-master-6c5bc redis-master --namespace=e2e-tests-kubectl-7j2m7'
Jan 12 05:29:52.635: INFO: stderr: ""
Jan 12 05:29:52.635: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 12 Jan 05:29:51.806 # Server started, Redis version 3.2.12\n1:M 12 Jan 05:29:51.806 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 12 Jan 05:29:51.807 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Jan 12 05:29:52.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 log redis-master-6c5bc redis-master --namespace=e2e-tests-kubectl-7j2m7 --tail=1'
Jan 12 05:29:52.705: INFO: stderr: ""
Jan 12 05:29:52.705: INFO: stdout: "1:M 12 Jan 05:29:51.807 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Jan 12 05:29:52.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 log redis-master-6c5bc redis-master --namespace=e2e-tests-kubectl-7j2m7 --limit-bytes=1'
Jan 12 05:29:52.779: INFO: stderr: ""
Jan 12 05:29:52.779: INFO: stdout: " "
STEP: exposing timestamps
Jan 12 05:29:52.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 log redis-master-6c5bc redis-master --namespace=e2e-tests-kubectl-7j2m7 --tail=1 --timestamps'
Jan 12 05:29:52.863: INFO: stderr: ""
Jan 12 05:29:52.863: INFO: stdout: "2019-01-12T05:29:51.807658902Z 1:M 12 Jan 05:29:51.807 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Jan 12 05:29:55.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 log redis-master-6c5bc redis-master --namespace=e2e-tests-kubectl-7j2m7 --since=1s'
Jan 12 05:29:55.525: INFO: stderr: ""
Jan 12 05:29:55.525: INFO: stdout: ""
Jan 12 05:29:55.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 log redis-master-6c5bc redis-master --namespace=e2e-tests-kubectl-7j2m7 --since=24h'
Jan 12 05:29:55.678: INFO: stderr: ""
Jan 12 05:29:55.678: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 12 Jan 05:29:51.806 # Server started, Redis version 3.2.12\n1:M 12 Jan 05:29:51.806 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 12 Jan 05:29:51.807 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Jan 12 05:29:55.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-7j2m7'
Jan 12 05:29:55.781: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 12 05:29:55.781: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Jan 12 05:29:55.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-7j2m7'
Jan 12 05:29:55.907: INFO: stderr: "No resources found.\n"
Jan 12 05:29:55.907: INFO: stdout: ""
Jan 12 05:29:55.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 get pods -l name=nginx --namespace=e2e-tests-kubectl-7j2m7 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 12 05:29:55.975: INFO: stderr: ""
Jan 12 05:29:55.975: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:29:55.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7j2m7" for this suite.
Jan 12 05:30:01.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:30:02.026: INFO: namespace: e2e-tests-kubectl-7j2m7, resource: bindings, ignored listing per whitelist
Jan 12 05:30:02.062: INFO: namespace e2e-tests-kubectl-7j2m7 deletion completed in 6.083694003s

• [SLOW TEST:12.038 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:30:02.063: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-942r9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-1c178aa4-162b-11e9-8fb7-aa4233c46d55
Jan 12 05:30:02.235: INFO: Pod name my-hostname-basic-1c178aa4-162b-11e9-8fb7-aa4233c46d55: Found 0 pods out of 1
Jan 12 05:30:07.240: INFO: Pod name my-hostname-basic-1c178aa4-162b-11e9-8fb7-aa4233c46d55: Found 1 pods out of 1
Jan 12 05:30:07.240: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-1c178aa4-162b-11e9-8fb7-aa4233c46d55" are running
Jan 12 05:30:07.243: INFO: Pod "my-hostname-basic-1c178aa4-162b-11e9-8fb7-aa4233c46d55-tcwcr" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-12 05:30:02 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-12 05:30:04 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-12 05:30:04 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-12 05:30:02 +0000 UTC Reason: Message:}])
Jan 12 05:30:07.243: INFO: Trying to dial the pod
Jan 12 05:30:12.263: INFO: Controller my-hostname-basic-1c178aa4-162b-11e9-8fb7-aa4233c46d55: Got expected result from replica 1 [my-hostname-basic-1c178aa4-162b-11e9-8fb7-aa4233c46d55-tcwcr]: "my-hostname-basic-1c178aa4-162b-11e9-8fb7-aa4233c46d55-tcwcr", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:30:12.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-942r9" for this suite.
Jan 12 05:30:18.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:30:18.341: INFO: namespace: e2e-tests-replication-controller-942r9, resource: bindings, ignored listing per whitelist
Jan 12 05:30:18.382: INFO: namespace e2e-tests-replication-controller-942r9 deletion completed in 6.112359857s

• [SLOW TEST:16.320 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:30:18.383: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-2hg6f
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-25d2ca7a-162b-11e9-8fb7-aa4233c46d55
STEP: Creating configMap with name cm-test-opt-upd-25d2caac-162b-11e9-8fb7-aa4233c46d55
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-25d2ca7a-162b-11e9-8fb7-aa4233c46d55
STEP: Updating configmap cm-test-opt-upd-25d2caac-162b-11e9-8fb7-aa4233c46d55
STEP: Creating configMap with name cm-test-opt-create-25d2cab9-162b-11e9-8fb7-aa4233c46d55
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:30:26.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2hg6f" for this suite.
Jan 12 05:30:48.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:30:48.796: INFO: namespace: e2e-tests-configmap-2hg6f, resource: bindings, ignored listing per whitelist
Jan 12 05:30:48.804: INFO: namespace e2e-tests-configmap-2hg6f deletion completed in 22.109486731s

• [SLOW TEST:30.421 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:30:48.804: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-6cw7n
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Jan 12 05:30:48.975: INFO: Waiting up to 5m0s for pod "pod-37f4800b-162b-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-emptydir-6cw7n" to be "success or failure"
Jan 12 05:30:48.980: INFO: Pod "pod-37f4800b-162b-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 4.524455ms
Jan 12 05:30:50.986: INFO: Pod "pod-37f4800b-162b-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01020818s
Jan 12 05:30:52.994: INFO: Pod "pod-37f4800b-162b-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018849088s
STEP: Saw pod success
Jan 12 05:30:52.994: INFO: Pod "pod-37f4800b-162b-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:30:53.001: INFO: Trying to get logs from node c76-1-41 pod pod-37f4800b-162b-11e9-8fb7-aa4233c46d55 container test-container: <nil>
STEP: delete the pod
Jan 12 05:30:53.045: INFO: Waiting for pod pod-37f4800b-162b-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:30:53.054: INFO: Pod pod-37f4800b-162b-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:30:53.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6cw7n" for this suite.
Jan 12 05:30:59.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:30:59.156: INFO: namespace: e2e-tests-emptydir-6cw7n, resource: bindings, ignored listing per whitelist
Jan 12 05:30:59.165: INFO: namespace e2e-tests-emptydir-6cw7n deletion completed in 6.105623357s

• [SLOW TEST:10.361 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:30:59.165: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-s7v8w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 12 05:30:59.322: INFO: Creating deployment "test-recreate-deployment"
Jan 12 05:30:59.331: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jan 12 05:30:59.336: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Jan 12 05:31:01.348: INFO: Waiting deployment "test-recreate-deployment" to complete
Jan 12 05:31:01.354: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jan 12 05:31:01.365: INFO: Updating deployment test-recreate-deployment
Jan 12 05:31:01.365: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 12 05:31:01.448: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-s7v8w,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-s7v8w/deployments/test-recreate-deployment,UID:3e1fda3a-162b-11e9-b7e1-000c294e6ffe,ResourceVersion:149493,Generation:2,CreationTimestamp:2019-01-12 05:30:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-01-12 05:31:01 +0000 UTC 2019-01-12 05:31:01 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-01-12 05:31:01 +0000 UTC 2019-01-12 05:30:59 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Jan 12 05:31:01.451: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-s7v8w,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-s7v8w/replicasets/test-recreate-deployment-7cf749666b,UID:3f5c05d7-162b-11e9-b7e1-000c294e6ffe,ResourceVersion:149492,Generation:1,CreationTimestamp:2019-01-12 05:31:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 3e1fda3a-162b-11e9-b7e1-000c294e6ffe 0xc0022c0cf7 0xc0022c0cf8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 12 05:31:01.451: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jan 12 05:31:01.451: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-s7v8w,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-s7v8w/replicasets/test-recreate-deployment-79f694ff59,UID:3e21cf86-162b-11e9-b7e1-000c294e6ffe,ResourceVersion:149481,Generation:2,CreationTimestamp:2019-01-12 05:30:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 3e1fda3a-162b-11e9-b7e1-000c294e6ffe 0xc0022c0c37 0xc0022c0c38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 12 05:31:01.453: INFO: Pod "test-recreate-deployment-7cf749666b-dggv9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-dggv9,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-s7v8w,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s7v8w/pods/test-recreate-deployment-7cf749666b-dggv9,UID:3f5c82ec-162b-11e9-b7e1-000c294e6ffe,ResourceVersion:149491,Generation:0,CreationTimestamp:2019-01-12 05:31:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b 3f5c05d7-162b-11e9-b7e1-000c294e6ffe 0xc0022c1d27 0xc0022c1d28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-stvrz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-stvrz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-stvrz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c76-1-41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022c1da0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022c1dc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 05:31:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 05:31:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-12 05:31:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-12 05:31:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.1.41,PodIP:,StartTime:2019-01-12 05:31:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:31:01.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-s7v8w" for this suite.
Jan 12 05:31:07.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:31:07.531: INFO: namespace: e2e-tests-deployment-s7v8w, resource: bindings, ignored listing per whitelist
Jan 12 05:31:07.552: INFO: namespace e2e-tests-deployment-s7v8w deletion completed in 6.095319719s

• [SLOW TEST:8.387 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:31:07.552: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-87hhs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Jan 12 05:31:07.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 cluster-info'
Jan 12 05:31:07.831: INFO: stderr: ""
Jan 12 05:31:07.832: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:31:07.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-87hhs" for this suite.
Jan 12 05:31:13.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:31:13.915: INFO: namespace: e2e-tests-kubectl-87hhs, resource: bindings, ignored listing per whitelist
Jan 12 05:31:13.947: INFO: namespace e2e-tests-kubectl-87hhs deletion completed in 6.110932205s

• [SLOW TEST:6.394 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:31:13.947: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-98dxk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan 12 05:31:14.126: INFO: Waiting up to 5m0s for pod "pod-46f10827-162b-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-emptydir-98dxk" to be "success or failure"
Jan 12 05:31:14.134: INFO: Pod "pod-46f10827-162b-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 7.754411ms
Jan 12 05:31:16.139: INFO: Pod "pod-46f10827-162b-11e9-8fb7-aa4233c46d55": Phase="Running", Reason="", readiness=true. Elapsed: 2.013195193s
Jan 12 05:31:18.142: INFO: Pod "pod-46f10827-162b-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016424177s
STEP: Saw pod success
Jan 12 05:31:18.142: INFO: Pod "pod-46f10827-162b-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:31:18.145: INFO: Trying to get logs from node c76-1-41 pod pod-46f10827-162b-11e9-8fb7-aa4233c46d55 container test-container: <nil>
STEP: delete the pod
Jan 12 05:31:18.160: INFO: Waiting for pod pod-46f10827-162b-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:31:18.162: INFO: Pod pod-46f10827-162b-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:31:18.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-98dxk" for this suite.
Jan 12 05:31:24.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:31:24.203: INFO: namespace: e2e-tests-emptydir-98dxk, resource: bindings, ignored listing per whitelist
Jan 12 05:31:24.324: INFO: namespace e2e-tests-emptydir-98dxk deletion completed in 6.158860303s

• [SLOW TEST:10.378 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:31:24.324: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-hjpw8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan 12 05:31:28.570: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 12 05:31:28.574: INFO: Pod pod-with-poststart-http-hook still exists
Jan 12 05:31:30.575: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 12 05:31:30.584: INFO: Pod pod-with-poststart-http-hook still exists
Jan 12 05:31:32.576: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 12 05:31:32.587: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:31:32.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-hjpw8" for this suite.
Jan 12 05:31:54.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:31:54.660: INFO: namespace: e2e-tests-container-lifecycle-hook-hjpw8, resource: bindings, ignored listing per whitelist
Jan 12 05:31:54.718: INFO: namespace e2e-tests-container-lifecycle-hook-hjpw8 deletion completed in 22.119279337s

• [SLOW TEST:30.393 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:31:54.718: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-q54tw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Jan 12 05:31:54.900: INFO: Waiting up to 5m0s for pod "var-expansion-5f400360-162b-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-var-expansion-q54tw" to be "success or failure"
Jan 12 05:31:54.902: INFO: Pod "var-expansion-5f400360-162b-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.347694ms
Jan 12 05:31:56.910: INFO: Pod "var-expansion-5f400360-162b-11e9-8fb7-aa4233c46d55": Phase="Running", Reason="", readiness=true. Elapsed: 2.009501199s
Jan 12 05:31:58.918: INFO: Pod "var-expansion-5f400360-162b-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017952159s
STEP: Saw pod success
Jan 12 05:31:58.918: INFO: Pod "var-expansion-5f400360-162b-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:31:58.925: INFO: Trying to get logs from node c76-1-41 pod var-expansion-5f400360-162b-11e9-8fb7-aa4233c46d55 container dapi-container: <nil>
STEP: delete the pod
Jan 12 05:31:58.958: INFO: Waiting for pod var-expansion-5f400360-162b-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:31:58.964: INFO: Pod var-expansion-5f400360-162b-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:31:58.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-q54tw" for this suite.
Jan 12 05:32:04.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:32:05.055: INFO: namespace: e2e-tests-var-expansion-q54tw, resource: bindings, ignored listing per whitelist
Jan 12 05:32:05.087: INFO: namespace e2e-tests-var-expansion-q54tw deletion completed in 6.120197694s

• [SLOW TEST:10.369 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:32:05.087: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-gn982
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 12 05:32:05.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-gn982'
Jan 12 05:32:05.324: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan 12 05:32:05.324: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Jan 12 05:32:05.329: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-87lcp]
Jan 12 05:32:05.329: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-87lcp" in namespace "e2e-tests-kubectl-gn982" to be "running and ready"
Jan 12 05:32:05.334: INFO: Pod "e2e-test-nginx-rc-87lcp": Phase="Pending", Reason="", readiness=false. Elapsed: 5.368159ms
Jan 12 05:32:07.341: INFO: Pod "e2e-test-nginx-rc-87lcp": Phase="Running", Reason="", readiness=true. Elapsed: 2.011924975s
Jan 12 05:32:07.341: INFO: Pod "e2e-test-nginx-rc-87lcp" satisfied condition "running and ready"
Jan 12 05:32:07.341: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-87lcp]
Jan 12 05:32:07.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-gn982'
Jan 12 05:32:07.480: INFO: stderr: ""
Jan 12 05:32:07.480: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Jan 12 05:32:07.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-gn982'
Jan 12 05:32:07.586: INFO: stderr: ""
Jan 12 05:32:07.586: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:32:07.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gn982" for this suite.
Jan 12 05:32:29.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:32:29.617: INFO: namespace: e2e-tests-kubectl-gn982, resource: bindings, ignored listing per whitelist
Jan 12 05:32:29.668: INFO: namespace e2e-tests-kubectl-gn982 deletion completed in 22.078937035s

• [SLOW TEST:24.581 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:32:29.668: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-58qdd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-741298a5-162b-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume secrets
Jan 12 05:32:29.847: INFO: Waiting up to 5m0s for pod "pod-secrets-74141e40-162b-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-secrets-58qdd" to be "success or failure"
Jan 12 05:32:29.851: INFO: Pod "pod-secrets-74141e40-162b-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 4.72152ms
Jan 12 05:32:31.857: INFO: Pod "pod-secrets-74141e40-162b-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010296419s
Jan 12 05:32:33.860: INFO: Pod "pod-secrets-74141e40-162b-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013710492s
STEP: Saw pod success
Jan 12 05:32:33.860: INFO: Pod "pod-secrets-74141e40-162b-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:32:33.863: INFO: Trying to get logs from node c76-1-41 pod pod-secrets-74141e40-162b-11e9-8fb7-aa4233c46d55 container secret-volume-test: <nil>
STEP: delete the pod
Jan 12 05:32:33.893: INFO: Waiting for pod pod-secrets-74141e40-162b-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:32:33.898: INFO: Pod pod-secrets-74141e40-162b-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:32:33.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-58qdd" for this suite.
Jan 12 05:32:39.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:32:39.997: INFO: namespace: e2e-tests-secrets-58qdd, resource: bindings, ignored listing per whitelist
Jan 12 05:32:40.029: INFO: namespace e2e-tests-secrets-58qdd deletion completed in 6.109035041s

• [SLOW TEST:10.361 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:32:40.029: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-t6pwj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-7a409d22-162b-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume configMaps
Jan 12 05:32:40.206: INFO: Waiting up to 5m0s for pod "pod-configmaps-7a411e0e-162b-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-configmap-t6pwj" to be "success or failure"
Jan 12 05:32:40.208: INFO: Pod "pod-configmaps-7a411e0e-162b-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.712411ms
Jan 12 05:32:42.211: INFO: Pod "pod-configmaps-7a411e0e-162b-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005381464s
STEP: Saw pod success
Jan 12 05:32:42.211: INFO: Pod "pod-configmaps-7a411e0e-162b-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:32:42.213: INFO: Trying to get logs from node c76-1-41 pod pod-configmaps-7a411e0e-162b-11e9-8fb7-aa4233c46d55 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 12 05:32:42.243: INFO: Waiting for pod pod-configmaps-7a411e0e-162b-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:32:42.246: INFO: Pod pod-configmaps-7a411e0e-162b-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:32:42.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-t6pwj" for this suite.
Jan 12 05:32:48.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:32:48.320: INFO: namespace: e2e-tests-configmap-t6pwj, resource: bindings, ignored listing per whitelist
Jan 12 05:32:48.340: INFO: namespace e2e-tests-configmap-t6pwj deletion completed in 6.089705031s

• [SLOW TEST:8.311 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:32:48.340: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-27rpg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Jan 12 05:32:48.512: INFO: Waiting up to 5m0s for pod "client-containers-7f33587f-162b-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-containers-27rpg" to be "success or failure"
Jan 12 05:32:48.515: INFO: Pod "client-containers-7f33587f-162b-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 3.25388ms
Jan 12 05:32:50.519: INFO: Pod "client-containers-7f33587f-162b-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006525951s
STEP: Saw pod success
Jan 12 05:32:50.519: INFO: Pod "client-containers-7f33587f-162b-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:32:50.521: INFO: Trying to get logs from node c76-1-41 pod client-containers-7f33587f-162b-11e9-8fb7-aa4233c46d55 container test-container: <nil>
STEP: delete the pod
Jan 12 05:32:50.545: INFO: Waiting for pod client-containers-7f33587f-162b-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:32:50.547: INFO: Pod client-containers-7f33587f-162b-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:32:50.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-27rpg" for this suite.
Jan 12 05:32:56.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:32:56.611: INFO: namespace: e2e-tests-containers-27rpg, resource: bindings, ignored listing per whitelist
Jan 12 05:32:56.659: INFO: namespace e2e-tests-containers-27rpg deletion completed in 6.10877706s

• [SLOW TEST:8.319 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:32:56.659: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-s7cjv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 12 05:32:56.834: INFO: Waiting up to 5m0s for pod "downwardapi-volume-842922a8-162b-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-downward-api-s7cjv" to be "success or failure"
Jan 12 05:32:56.838: INFO: Pod "downwardapi-volume-842922a8-162b-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 3.579601ms
Jan 12 05:32:58.842: INFO: Pod "downwardapi-volume-842922a8-162b-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00710287s
STEP: Saw pod success
Jan 12 05:32:58.842: INFO: Pod "downwardapi-volume-842922a8-162b-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:32:58.844: INFO: Trying to get logs from node c76-1-41 pod downwardapi-volume-842922a8-162b-11e9-8fb7-aa4233c46d55 container client-container: <nil>
STEP: delete the pod
Jan 12 05:32:58.859: INFO: Waiting for pod downwardapi-volume-842922a8-162b-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:32:58.861: INFO: Pod downwardapi-volume-842922a8-162b-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:32:58.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-s7cjv" for this suite.
Jan 12 05:33:04.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:33:04.923: INFO: namespace: e2e-tests-downward-api-s7cjv, resource: bindings, ignored listing per whitelist
Jan 12 05:33:04.966: INFO: namespace e2e-tests-downward-api-s7cjv deletion completed in 6.10166464s

• [SLOW TEST:8.307 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:33:04.966: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-bx9s9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan 12 05:33:05.148: INFO: Waiting up to 5m0s for pod "pod-891d0355-162b-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-emptydir-bx9s9" to be "success or failure"
Jan 12 05:33:05.156: INFO: Pod "pod-891d0355-162b-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 7.4895ms
Jan 12 05:33:07.160: INFO: Pod "pod-891d0355-162b-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011002444s
STEP: Saw pod success
Jan 12 05:33:07.160: INFO: Pod "pod-891d0355-162b-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:33:07.163: INFO: Trying to get logs from node c76-1-41 pod pod-891d0355-162b-11e9-8fb7-aa4233c46d55 container test-container: <nil>
STEP: delete the pod
Jan 12 05:33:07.192: INFO: Waiting for pod pod-891d0355-162b-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:33:07.195: INFO: Pod pod-891d0355-162b-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:33:07.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bx9s9" for this suite.
Jan 12 05:33:13.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:33:13.257: INFO: namespace: e2e-tests-emptydir-bx9s9, resource: bindings, ignored listing per whitelist
Jan 12 05:33:13.306: INFO: namespace e2e-tests-emptydir-bx9s9 deletion completed in 6.106755994s

• [SLOW TEST:8.340 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:33:13.306: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-k882n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 12 05:33:13.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-k882n'
Jan 12 05:33:13.560: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan 12 05:33:13.560: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Jan 12 05:33:15.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-921671513 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-k882n'
Jan 12 05:33:15.660: INFO: stderr: ""
Jan 12 05:33:15.660: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:33:15.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k882n" for this suite.
Jan 12 05:33:37.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:33:37.755: INFO: namespace: e2e-tests-kubectl-k882n, resource: bindings, ignored listing per whitelist
Jan 12 05:33:37.775: INFO: namespace e2e-tests-kubectl-k882n deletion completed in 22.11150325s

• [SLOW TEST:24.469 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:33:37.775: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-2plwz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-rj9b
STEP: Creating a pod to test atomic-volume-subpath
Jan 12 05:33:37.988: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-rj9b" in namespace "e2e-tests-subpath-2plwz" to be "success or failure"
Jan 12 05:33:37.994: INFO: Pod "pod-subpath-test-configmap-rj9b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.543717ms
Jan 12 05:33:40.008: INFO: Pod "pod-subpath-test-configmap-rj9b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019579165s
Jan 12 05:33:42.014: INFO: Pod "pod-subpath-test-configmap-rj9b": Phase="Running", Reason="", readiness=false. Elapsed: 4.025729661s
Jan 12 05:33:44.019: INFO: Pod "pod-subpath-test-configmap-rj9b": Phase="Running", Reason="", readiness=false. Elapsed: 6.031145841s
Jan 12 05:33:46.029: INFO: Pod "pod-subpath-test-configmap-rj9b": Phase="Running", Reason="", readiness=false. Elapsed: 8.04136085s
Jan 12 05:33:48.033: INFO: Pod "pod-subpath-test-configmap-rj9b": Phase="Running", Reason="", readiness=false. Elapsed: 10.045046462s
Jan 12 05:33:50.039: INFO: Pod "pod-subpath-test-configmap-rj9b": Phase="Running", Reason="", readiness=false. Elapsed: 12.050584797s
Jan 12 05:33:52.043: INFO: Pod "pod-subpath-test-configmap-rj9b": Phase="Running", Reason="", readiness=false. Elapsed: 14.054945421s
Jan 12 05:33:54.047: INFO: Pod "pod-subpath-test-configmap-rj9b": Phase="Running", Reason="", readiness=false. Elapsed: 16.058514103s
Jan 12 05:33:56.051: INFO: Pod "pod-subpath-test-configmap-rj9b": Phase="Running", Reason="", readiness=false. Elapsed: 18.06314476s
Jan 12 05:33:58.058: INFO: Pod "pod-subpath-test-configmap-rj9b": Phase="Running", Reason="", readiness=false. Elapsed: 20.070117269s
Jan 12 05:34:00.064: INFO: Pod "pod-subpath-test-configmap-rj9b": Phase="Running", Reason="", readiness=false. Elapsed: 22.075872581s
Jan 12 05:34:02.073: INFO: Pod "pod-subpath-test-configmap-rj9b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.084567448s
STEP: Saw pod success
Jan 12 05:34:02.073: INFO: Pod "pod-subpath-test-configmap-rj9b" satisfied condition "success or failure"
Jan 12 05:34:02.087: INFO: Trying to get logs from node c76-1-41 pod pod-subpath-test-configmap-rj9b container test-container-subpath-configmap-rj9b: <nil>
STEP: delete the pod
Jan 12 05:34:02.120: INFO: Waiting for pod pod-subpath-test-configmap-rj9b to disappear
Jan 12 05:34:02.125: INFO: Pod pod-subpath-test-configmap-rj9b no longer exists
STEP: Deleting pod pod-subpath-test-configmap-rj9b
Jan 12 05:34:02.125: INFO: Deleting pod "pod-subpath-test-configmap-rj9b" in namespace "e2e-tests-subpath-2plwz"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:34:02.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-2plwz" for this suite.
Jan 12 05:34:08.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:34:08.185: INFO: namespace: e2e-tests-subpath-2plwz, resource: bindings, ignored listing per whitelist
Jan 12 05:34:08.244: INFO: namespace e2e-tests-subpath-2plwz deletion completed in 6.100007559s

• [SLOW TEST:30.469 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:34:08.244: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-8st2z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan 12 05:34:08.411: INFO: Waiting up to 5m0s for pod "pod-aed3c9a1-162b-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-emptydir-8st2z" to be "success or failure"
Jan 12 05:34:08.425: INFO: Pod "pod-aed3c9a1-162b-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 13.052233ms
Jan 12 05:34:10.428: INFO: Pod "pod-aed3c9a1-162b-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01625879s
STEP: Saw pod success
Jan 12 05:34:10.428: INFO: Pod "pod-aed3c9a1-162b-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:34:10.430: INFO: Trying to get logs from node c76-1-41 pod pod-aed3c9a1-162b-11e9-8fb7-aa4233c46d55 container test-container: <nil>
STEP: delete the pod
Jan 12 05:34:10.491: INFO: Waiting for pod pod-aed3c9a1-162b-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:34:10.493: INFO: Pod pod-aed3c9a1-162b-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:34:10.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8st2z" for this suite.
Jan 12 05:34:16.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:34:16.612: INFO: namespace: e2e-tests-emptydir-8st2z, resource: bindings, ignored listing per whitelist
Jan 12 05:34:16.612: INFO: namespace e2e-tests-emptydir-8st2z deletion completed in 6.115512265s

• [SLOW TEST:8.369 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:34:16.613: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-m52wg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-m52wg
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Jan 12 05:34:16.792: INFO: Found 0 stateful pods, waiting for 3
Jan 12 05:34:26.797: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 12 05:34:26.797: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 12 05:34:26.797: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan 12 05:34:26.834: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jan 12 05:34:36.885: INFO: Updating stateful set ss2
Jan 12 05:34:36.895: INFO: Waiting for Pod e2e-tests-statefulset-m52wg/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Jan 12 05:34:47.024: INFO: Found 2 stateful pods, waiting for 3
Jan 12 05:34:57.035: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 12 05:34:57.035: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 12 05:34:57.035: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jan 12 05:34:57.073: INFO: Updating stateful set ss2
Jan 12 05:34:57.083: INFO: Waiting for Pod e2e-tests-statefulset-m52wg/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 12 05:35:07.124: INFO: Updating stateful set ss2
Jan 12 05:35:07.158: INFO: Waiting for StatefulSet e2e-tests-statefulset-m52wg/ss2 to complete update
Jan 12 05:35:07.158: INFO: Waiting for Pod e2e-tests-statefulset-m52wg/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 12 05:35:17.167: INFO: Waiting for StatefulSet e2e-tests-statefulset-m52wg/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 12 05:35:27.171: INFO: Deleting all statefulset in ns e2e-tests-statefulset-m52wg
Jan 12 05:35:27.175: INFO: Scaling statefulset ss2 to 0
Jan 12 05:35:47.207: INFO: Waiting for statefulset status.replicas updated to 0
Jan 12 05:35:47.211: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:35:47.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-m52wg" for this suite.
Jan 12 05:35:53.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:35:53.323: INFO: namespace: e2e-tests-statefulset-m52wg, resource: bindings, ignored listing per whitelist
Jan 12 05:35:53.350: INFO: namespace e2e-tests-statefulset-m52wg deletion completed in 6.113989638s

• [SLOW TEST:96.737 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:35:53.350: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-7lt6f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 12 05:35:53.510: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:35:56.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-7lt6f" for this suite.
Jan 12 05:36:02.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:36:02.966: INFO: namespace: e2e-tests-init-container-7lt6f, resource: bindings, ignored listing per whitelist
Jan 12 05:36:02.989: INFO: namespace e2e-tests-init-container-7lt6f deletion completed in 6.14937853s

• [SLOW TEST:9.639 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:36:02.989: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-cwlnt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Jan 12 05:36:14.209: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:36:15.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-cwlnt" for this suite.
Jan 12 05:36:37.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:36:37.304: INFO: namespace: e2e-tests-replicaset-cwlnt, resource: bindings, ignored listing per whitelist
Jan 12 05:36:37.325: INFO: namespace e2e-tests-replicaset-cwlnt deletion completed in 22.083581409s

• [SLOW TEST:34.336 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:36:37.325: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-48dr7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-22wlm
STEP: Creating secret with name secret-test-07b3148f-162c-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume secrets
Jan 12 05:36:37.671: INFO: Waiting up to 5m0s for pod "pod-secrets-07cada1e-162c-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-secrets-48dr7" to be "success or failure"
Jan 12 05:36:37.675: INFO: Pod "pod-secrets-07cada1e-162c-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 3.925068ms
Jan 12 05:36:39.679: INFO: Pod "pod-secrets-07cada1e-162c-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007274749s
STEP: Saw pod success
Jan 12 05:36:39.679: INFO: Pod "pod-secrets-07cada1e-162c-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:36:39.681: INFO: Trying to get logs from node c76-1-41 pod pod-secrets-07cada1e-162c-11e9-8fb7-aa4233c46d55 container secret-volume-test: <nil>
STEP: delete the pod
Jan 12 05:36:39.696: INFO: Waiting for pod pod-secrets-07cada1e-162c-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:36:39.699: INFO: Pod pod-secrets-07cada1e-162c-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:36:39.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-48dr7" for this suite.
Jan 12 05:36:45.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:36:45.763: INFO: namespace: e2e-tests-secrets-48dr7, resource: bindings, ignored listing per whitelist
Jan 12 05:36:45.807: INFO: namespace e2e-tests-secrets-48dr7 deletion completed in 6.105635854s
STEP: Destroying namespace "e2e-tests-secret-namespace-22wlm" for this suite.
Jan 12 05:36:51.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:36:51.847: INFO: namespace: e2e-tests-secret-namespace-22wlm, resource: bindings, ignored listing per whitelist
Jan 12 05:36:51.913: INFO: namespace e2e-tests-secret-namespace-22wlm deletion completed in 6.105744504s

• [SLOW TEST:14.588 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:36:51.913: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jsn6g
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-10618a5b-162c-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume secrets
Jan 12 05:36:52.089: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-106292c8-162c-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-projected-jsn6g" to be "success or failure"
Jan 12 05:36:52.096: INFO: Pod "pod-projected-secrets-106292c8-162c-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 6.491854ms
Jan 12 05:36:54.108: INFO: Pod "pod-projected-secrets-106292c8-162c-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01909792s
STEP: Saw pod success
Jan 12 05:36:54.109: INFO: Pod "pod-projected-secrets-106292c8-162c-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:36:54.115: INFO: Trying to get logs from node c76-1-41 pod pod-projected-secrets-106292c8-162c-11e9-8fb7-aa4233c46d55 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 12 05:36:54.149: INFO: Waiting for pod pod-projected-secrets-106292c8-162c-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:36:54.154: INFO: Pod pod-projected-secrets-106292c8-162c-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:36:54.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jsn6g" for this suite.
Jan 12 05:37:00.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:37:00.264: INFO: namespace: e2e-tests-projected-jsn6g, resource: bindings, ignored listing per whitelist
Jan 12 05:37:00.274: INFO: namespace e2e-tests-projected-jsn6g deletion completed in 6.115148915s

• [SLOW TEST:8.360 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:37:00.274: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-4clwr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Jan 12 05:37:00.634: INFO: Pod name wrapped-volume-race-1577571c-162c-11e9-8fb7-aa4233c46d55: Found 3 pods out of 5
Jan 12 05:37:05.639: INFO: Pod name wrapped-volume-race-1577571c-162c-11e9-8fb7-aa4233c46d55: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-1577571c-162c-11e9-8fb7-aa4233c46d55 in namespace e2e-tests-emptydir-wrapper-4clwr, will wait for the garbage collector to delete the pods
Jan 12 05:37:17.723: INFO: Deleting ReplicationController wrapped-volume-race-1577571c-162c-11e9-8fb7-aa4233c46d55 took: 5.921212ms
Jan 12 05:37:17.823: INFO: Terminating ReplicationController wrapped-volume-race-1577571c-162c-11e9-8fb7-aa4233c46d55 pods took: 100.774477ms
STEP: Creating RC which spawns configmap-volume pods
Jan 12 05:37:53.642: INFO: Pod name wrapped-volume-race-3511db9a-162c-11e9-8fb7-aa4233c46d55: Found 0 pods out of 5
Jan 12 05:37:58.647: INFO: Pod name wrapped-volume-race-3511db9a-162c-11e9-8fb7-aa4233c46d55: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-3511db9a-162c-11e9-8fb7-aa4233c46d55 in namespace e2e-tests-emptydir-wrapper-4clwr, will wait for the garbage collector to delete the pods
Jan 12 05:38:10.747: INFO: Deleting ReplicationController wrapped-volume-race-3511db9a-162c-11e9-8fb7-aa4233c46d55 took: 7.556097ms
Jan 12 05:38:10.848: INFO: Terminating ReplicationController wrapped-volume-race-3511db9a-162c-11e9-8fb7-aa4233c46d55 pods took: 100.390721ms
STEP: Creating RC which spawns configmap-volume pods
Jan 12 05:38:53.675: INFO: Pod name wrapped-volume-race-58d8d661-162c-11e9-8fb7-aa4233c46d55: Found 0 pods out of 5
Jan 12 05:38:58.680: INFO: Pod name wrapped-volume-race-58d8d661-162c-11e9-8fb7-aa4233c46d55: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-58d8d661-162c-11e9-8fb7-aa4233c46d55 in namespace e2e-tests-emptydir-wrapper-4clwr, will wait for the garbage collector to delete the pods
Jan 12 05:39:10.770: INFO: Deleting ReplicationController wrapped-volume-race-58d8d661-162c-11e9-8fb7-aa4233c46d55 took: 6.400151ms
Jan 12 05:39:10.871: INFO: Terminating ReplicationController wrapped-volume-race-58d8d661-162c-11e9-8fb7-aa4233c46d55 pods took: 101.613695ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:39:54.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-4clwr" for this suite.
Jan 12 05:40:00.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:40:00.796: INFO: namespace: e2e-tests-emptydir-wrapper-4clwr, resource: bindings, ignored listing per whitelist
Jan 12 05:40:00.893: INFO: namespace e2e-tests-emptydir-wrapper-4clwr deletion completed in 6.116212187s

• [SLOW TEST:180.619 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:40:00.893: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-c6zbg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-c6zbg A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-c6zbg;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-c6zbg A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-c6zbg.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-c6zbg.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-c6zbg.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-c6zbg.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-c6zbg.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-c6zbg.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-c6zbg.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-c6zbg.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 101.4.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.4.101_udp@PTR;check="$$(dig +tcp +noall +answer +search 101.4.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.4.101_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-c6zbg A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-c6zbg;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-c6zbg A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-c6zbg.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-c6zbg.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-c6zbg.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-c6zbg.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-c6zbg.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-c6zbg.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-c6zbg.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-c6zbg.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 101.4.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.4.101_udp@PTR;check="$$(dig +tcp +noall +answer +search 101.4.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.4.101_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 12 05:40:05.170: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:05.192: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:05.199: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:05.207: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:05.263: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:05.267: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:05.270: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-c6zbg from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:05.273: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:05.276: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:05.279: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:05.283: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:05.286: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:05.305: INFO: Lookups using e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55 failed for: [wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-c6zbg jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg jessie_udp@dns-test-service.e2e-tests-dns-c6zbg.svc jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc]

Jan 12 05:40:10.313: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:10.319: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:10.338: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:10.345: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:10.377: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:10.380: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:10.383: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-c6zbg from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:10.385: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:10.388: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:10.391: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:10.396: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:10.413: INFO: Lookups using e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55 failed for: [wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-c6zbg jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg jessie_udp@dns-test-service.e2e-tests-dns-c6zbg.svc jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc]

Jan 12 05:40:15.318: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:15.329: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:15.338: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:15.346: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:15.368: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:15.371: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:15.374: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-c6zbg from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:15.377: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:15.380: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:15.383: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:15.391: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:15.409: INFO: Lookups using e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55 failed for: [wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-c6zbg jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg jessie_udp@dns-test-service.e2e-tests-dns-c6zbg.svc jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc]

Jan 12 05:40:20.325: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:20.338: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:20.350: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:20.360: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:20.390: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:20.393: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:20.396: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-c6zbg from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:20.399: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:20.402: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:20.406: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:20.412: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:20.432: INFO: Lookups using e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55 failed for: [wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-c6zbg jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg jessie_udp@dns-test-service.e2e-tests-dns-c6zbg.svc jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc]

Jan 12 05:40:25.325: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:25.339: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:25.350: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:25.365: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:25.387: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:25.390: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:25.392: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-c6zbg from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:25.395: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:25.397: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:25.400: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:25.405: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:25.423: INFO: Lookups using e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55 failed for: [wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-c6zbg jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg jessie_udp@dns-test-service.e2e-tests-dns-c6zbg.svc jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc]

Jan 12 05:40:30.324: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:30.342: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:30.356: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:30.365: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:30.391: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:30.394: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:30.397: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-c6zbg from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:30.401: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:30.404: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:30.407: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:30.413: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc from pod e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55: the server could not find the requested resource (get pods dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55)
Jan 12 05:40:30.430: INFO: Lookups using e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55 failed for: [wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg wheezy_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-c6zbg jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg jessie_udp@dns-test-service.e2e-tests-dns-c6zbg.svc jessie_tcp@dns-test-service.e2e-tests-dns-c6zbg.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-c6zbg.svc]

Jan 12 05:40:35.457: INFO: DNS probes using e2e-tests-dns-c6zbg/dns-test-810ce566-162c-11e9-8fb7-aa4233c46d55 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:40:35.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-c6zbg" for this suite.
Jan 12 05:40:41.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:40:41.676: INFO: namespace: e2e-tests-dns-c6zbg, resource: bindings, ignored listing per whitelist
Jan 12 05:40:41.698: INFO: namespace e2e-tests-dns-c6zbg deletion completed in 6.125714106s

• [SLOW TEST:40.805 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:40:41.698: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-p6gmv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 12 05:40:41.875: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9958b44c-162c-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-projected-p6gmv" to be "success or failure"
Jan 12 05:40:41.889: INFO: Pod "downwardapi-volume-9958b44c-162c-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 13.56868ms
Jan 12 05:40:43.892: INFO: Pod "downwardapi-volume-9958b44c-162c-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016768587s
Jan 12 05:40:45.896: INFO: Pod "downwardapi-volume-9958b44c-162c-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020163688s
STEP: Saw pod success
Jan 12 05:40:45.896: INFO: Pod "downwardapi-volume-9958b44c-162c-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:40:45.898: INFO: Trying to get logs from node c76-1-41 pod downwardapi-volume-9958b44c-162c-11e9-8fb7-aa4233c46d55 container client-container: <nil>
STEP: delete the pod
Jan 12 05:40:45.925: INFO: Waiting for pod downwardapi-volume-9958b44c-162c-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:40:45.941: INFO: Pod downwardapi-volume-9958b44c-162c-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:40:45.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p6gmv" for this suite.
Jan 12 05:40:51.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:40:52.029: INFO: namespace: e2e-tests-projected-p6gmv, resource: bindings, ignored listing per whitelist
Jan 12 05:40:52.055: INFO: namespace e2e-tests-projected-p6gmv deletion completed in 6.109269829s

• [SLOW TEST:10.357 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:40:52.055: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-5gctf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:40:56.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-5gctf" for this suite.
Jan 12 05:41:52.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:41:52.345: INFO: namespace: e2e-tests-kubelet-test-5gctf, resource: bindings, ignored listing per whitelist
Jan 12 05:41:52.391: INFO: namespace e2e-tests-kubelet-test-5gctf deletion completed in 56.12444289s

• [SLOW TEST:60.337 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:41:52.392: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-9hc6r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-c37cbb8e-162c-11e9-8fb7-aa4233c46d55
STEP: Creating a pod to test consume secrets
Jan 12 05:41:52.585: INFO: Waiting up to 5m0s for pod "pod-secrets-c37e9e99-162c-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-secrets-9hc6r" to be "success or failure"
Jan 12 05:41:52.592: INFO: Pod "pod-secrets-c37e9e99-162c-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 6.841049ms
Jan 12 05:41:54.595: INFO: Pod "pod-secrets-c37e9e99-162c-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010481684s
STEP: Saw pod success
Jan 12 05:41:54.596: INFO: Pod "pod-secrets-c37e9e99-162c-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:41:54.611: INFO: Trying to get logs from node c76-1-41 pod pod-secrets-c37e9e99-162c-11e9-8fb7-aa4233c46d55 container secret-env-test: <nil>
STEP: delete the pod
Jan 12 05:41:54.632: INFO: Waiting for pod pod-secrets-c37e9e99-162c-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:41:54.635: INFO: Pod pod-secrets-c37e9e99-162c-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:41:54.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9hc6r" for this suite.
Jan 12 05:42:00.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:42:00.700: INFO: namespace: e2e-tests-secrets-9hc6r, resource: bindings, ignored listing per whitelist
Jan 12 05:42:00.739: INFO: namespace e2e-tests-secrets-9hc6r deletion completed in 6.099318383s

• [SLOW TEST:8.348 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 12 05:42:00.739: INFO: >>> kubeConfig: /tmp/kubeconfig-921671513
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-9xhbm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 12 05:42:00.927: INFO: Waiting up to 5m0s for pod "downward-api-c8774baa-162c-11e9-8fb7-aa4233c46d55" in namespace "e2e-tests-downward-api-9xhbm" to be "success or failure"
Jan 12 05:42:00.930: INFO: Pod "downward-api-c8774baa-162c-11e9-8fb7-aa4233c46d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.690522ms
Jan 12 05:42:02.933: INFO: Pod "downward-api-c8774baa-162c-11e9-8fb7-aa4233c46d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006249515s
STEP: Saw pod success
Jan 12 05:42:02.934: INFO: Pod "downward-api-c8774baa-162c-11e9-8fb7-aa4233c46d55" satisfied condition "success or failure"
Jan 12 05:42:02.936: INFO: Trying to get logs from node c76-1-41 pod downward-api-c8774baa-162c-11e9-8fb7-aa4233c46d55 container dapi-container: <nil>
STEP: delete the pod
Jan 12 05:42:02.951: INFO: Waiting for pod downward-api-c8774baa-162c-11e9-8fb7-aa4233c46d55 to disappear
Jan 12 05:42:02.954: INFO: Pod downward-api-c8774baa-162c-11e9-8fb7-aa4233c46d55 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 12 05:42:02.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9xhbm" for this suite.
Jan 12 05:42:08.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 12 05:42:09.040: INFO: namespace: e2e-tests-downward-api-9xhbm, resource: bindings, ignored listing per whitelist
Jan 12 05:42:09.070: INFO: namespace e2e-tests-downward-api-9xhbm deletion completed in 6.11196635s

• [SLOW TEST:8.330 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSJan 12 05:42:09.070: INFO: Running AfterSuite actions on all nodes
Jan 12 05:42:09.070: INFO: Running AfterSuite actions on node 1
Jan 12 05:42:09.070: INFO: Skipping dumping logs from cluster


Summarizing 1 Failure:

[Fail] [k8s.io] Kubelet when scheduling a busybox Pod with hostAliases [It] should write entries to /etc/hosts [NodeConformance] [Conformance] 
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:183

Ran 199 of 1946 Specs in 5396.089 seconds
FAIL! -- 198 Passed | 1 Failed | 0 Pending | 1747 Skipped --- FAIL: TestE2E (5396.28s)
FAIL

Ginkgo ran 1 suite in 1h29m57.417973407s
Test Suite Failed

Jan  8 09:12:55.414: INFO: Overriding default scale value of zero to 1
Jan  8 09:12:55.414: INFO: Overriding default milliseconds value of zero to 5000
I0108 09:12:56.076586      16 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-272738442
I0108 09:12:56.076771      16 e2e.go:304] Starting e2e run "9568e46c-1325-11e9-bc05-0a580af40202" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1546938775 - Will randomize all specs
Will run 188 of 1814 specs

Jan  8 09:12:56.244: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
Jan  8 09:12:56.248: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jan  8 09:12:56.260: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jan  8 09:12:56.286: INFO: 13 / 13 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jan  8 09:12:56.286: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Jan  8 09:12:56.286: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jan  8 09:12:56.292: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds' (0 seconds elapsed)
Jan  8 09:12:56.292: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Jan  8 09:12:56.292: INFO: e2e test version: v1.12.1
Jan  8 09:12:56.293: INFO: kube-apiserver version: v1.12.3+2.0.6.el7
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:12:56.294: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename svcaccounts
Jan  8 09:12:56.350: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Jan  8 09:12:56.863: INFO: Waiting up to 5m0s for pod "pod-service-account-9657fd78-1325-11e9-bc05-0a580af40202-h7kxw" in namespace "e2e-tests-svcaccounts-2trbr" to be "success or failure"
Jan  8 09:12:56.866: INFO: Pod "pod-service-account-9657fd78-1325-11e9-bc05-0a580af40202-h7kxw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.814213ms
Jan  8 09:12:58.869: INFO: Pod "pod-service-account-9657fd78-1325-11e9-bc05-0a580af40202-h7kxw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005732232s
Jan  8 09:13:00.875: INFO: Pod "pod-service-account-9657fd78-1325-11e9-bc05-0a580af40202-h7kxw": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011827728s
Jan  8 09:13:02.879: INFO: Pod "pod-service-account-9657fd78-1325-11e9-bc05-0a580af40202-h7kxw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015452615s
STEP: Saw pod success
Jan  8 09:13:02.879: INFO: Pod "pod-service-account-9657fd78-1325-11e9-bc05-0a580af40202-h7kxw" satisfied condition "success or failure"
Jan  8 09:13:02.881: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-service-account-9657fd78-1325-11e9-bc05-0a580af40202-h7kxw container token-test: <nil>
STEP: delete the pod
Jan  8 09:13:02.917: INFO: Waiting for pod pod-service-account-9657fd78-1325-11e9-bc05-0a580af40202-h7kxw to disappear
Jan  8 09:13:02.925: INFO: Pod pod-service-account-9657fd78-1325-11e9-bc05-0a580af40202-h7kxw no longer exists
STEP: Creating a pod to test consume service account root CA
Jan  8 09:13:02.928: INFO: Waiting up to 5m0s for pod "pod-service-account-9657fd78-1325-11e9-bc05-0a580af40202-7sk97" in namespace "e2e-tests-svcaccounts-2trbr" to be "success or failure"
Jan  8 09:13:02.932: INFO: Pod "pod-service-account-9657fd78-1325-11e9-bc05-0a580af40202-7sk97": Phase="Pending", Reason="", readiness=false. Elapsed: 3.80893ms
Jan  8 09:13:04.936: INFO: Pod "pod-service-account-9657fd78-1325-11e9-bc05-0a580af40202-7sk97": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007909637s
Jan  8 09:13:06.940: INFO: Pod "pod-service-account-9657fd78-1325-11e9-bc05-0a580af40202-7sk97": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011390806s
STEP: Saw pod success
Jan  8 09:13:06.940: INFO: Pod "pod-service-account-9657fd78-1325-11e9-bc05-0a580af40202-7sk97" satisfied condition "success or failure"
Jan  8 09:13:06.942: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-service-account-9657fd78-1325-11e9-bc05-0a580af40202-7sk97 container root-ca-test: <nil>
STEP: delete the pod
Jan  8 09:13:06.966: INFO: Waiting for pod pod-service-account-9657fd78-1325-11e9-bc05-0a580af40202-7sk97 to disappear
Jan  8 09:13:06.969: INFO: Pod pod-service-account-9657fd78-1325-11e9-bc05-0a580af40202-7sk97 no longer exists
STEP: Creating a pod to test consume service account namespace
Jan  8 09:13:06.974: INFO: Waiting up to 5m0s for pod "pod-service-account-9657fd78-1325-11e9-bc05-0a580af40202-7jqgv" in namespace "e2e-tests-svcaccounts-2trbr" to be "success or failure"
Jan  8 09:13:06.977: INFO: Pod "pod-service-account-9657fd78-1325-11e9-bc05-0a580af40202-7jqgv": Phase="Pending", Reason="", readiness=false. Elapsed: 3.487238ms
Jan  8 09:13:08.980: INFO: Pod "pod-service-account-9657fd78-1325-11e9-bc05-0a580af40202-7jqgv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006103558s
STEP: Saw pod success
Jan  8 09:13:08.980: INFO: Pod "pod-service-account-9657fd78-1325-11e9-bc05-0a580af40202-7jqgv" satisfied condition "success or failure"
Jan  8 09:13:08.983: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-service-account-9657fd78-1325-11e9-bc05-0a580af40202-7jqgv container namespace-test: <nil>
STEP: delete the pod
Jan  8 09:13:08.998: INFO: Waiting for pod pod-service-account-9657fd78-1325-11e9-bc05-0a580af40202-7jqgv to disappear
Jan  8 09:13:09.001: INFO: Pod pod-service-account-9657fd78-1325-11e9-bc05-0a580af40202-7jqgv no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:13:09.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-2trbr" for this suite.
Jan  8 09:13:15.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:13:15.052: INFO: namespace: e2e-tests-svcaccounts-2trbr, resource: bindings, ignored listing per whitelist
Jan  8 09:13:15.090: INFO: namespace e2e-tests-svcaccounts-2trbr deletion completed in 6.086470781s

â€¢ [SLOW TEST:18.796 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:13:15.090: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan  8 09:13:15.162: INFO: Waiting up to 5m0s for pod "downward-api-a1401ac4-1325-11e9-bc05-0a580af40202" in namespace "e2e-tests-downward-api-sr4xp" to be "success or failure"
Jan  8 09:13:15.164: INFO: Pod "downward-api-a1401ac4-1325-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.477527ms
Jan  8 09:13:17.168: INFO: Pod "downward-api-a1401ac4-1325-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006174906s
Jan  8 09:13:19.172: INFO: Pod "downward-api-a1401ac4-1325-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00991102s
Jan  8 09:13:21.175: INFO: Pod "downward-api-a1401ac4-1325-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013051023s
STEP: Saw pod success
Jan  8 09:13:21.175: INFO: Pod "downward-api-a1401ac4-1325-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:13:21.177: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod downward-api-a1401ac4-1325-11e9-bc05-0a580af40202 container dapi-container: <nil>
STEP: delete the pod
Jan  8 09:13:21.206: INFO: Waiting for pod downward-api-a1401ac4-1325-11e9-bc05-0a580af40202 to disappear
Jan  8 09:13:21.209: INFO: Pod downward-api-a1401ac4-1325-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:13:21.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-sr4xp" for this suite.
Jan  8 09:13:27.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:13:27.259: INFO: namespace: e2e-tests-downward-api-sr4xp, resource: bindings, ignored listing per whitelist
Jan  8 09:13:27.318: INFO: namespace e2e-tests-downward-api-sr4xp deletion completed in 6.106312868s

â€¢ [SLOW TEST:12.228 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:13:27.318: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-d44q4 A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-d44q4;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-d44q4 A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-d44q4;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-d44q4.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-d44q4.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-d44q4.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-d44q4.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-d44q4.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-d44q4.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-d44q4.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-d44q4.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-d44q4.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-d44q4.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-d44q4.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-d44q4.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-d44q4.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 212.176.96.10.in-addr.arpa. PTR)" && echo OK > /results/10.96.176.212_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 212.176.96.10.in-addr.arpa. PTR)" && echo OK > /results/10.96.176.212_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-d44q4 A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-d44q4;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-d44q4 A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-d44q4;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-d44q4.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-d44q4.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-d44q4.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-d44q4.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-d44q4.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-d44q4.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-d44q4.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-d44q4.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-d44q4.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-d44q4.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-d44q4.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-d44q4.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-d44q4.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 212.176.96.10.in-addr.arpa. PTR)" && echo OK > /results/10.96.176.212_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 212.176.96.10.in-addr.arpa. PTR)" && echo OK > /results/10.96.176.212_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan  8 09:13:57.491: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-d44q4/dns-test-a8960907-1325-11e9-bc05-0a580af40202: the server could not find the requested resource (get pods dns-test-a8960907-1325-11e9-bc05-0a580af40202)
Jan  8 09:13:57.495: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-d44q4/dns-test-a8960907-1325-11e9-bc05-0a580af40202: the server could not find the requested resource (get pods dns-test-a8960907-1325-11e9-bc05-0a580af40202)
Jan  8 09:13:57.499: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-d44q4 from pod e2e-tests-dns-d44q4/dns-test-a8960907-1325-11e9-bc05-0a580af40202: the server could not find the requested resource (get pods dns-test-a8960907-1325-11e9-bc05-0a580af40202)
Jan  8 09:13:57.502: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-d44q4 from pod e2e-tests-dns-d44q4/dns-test-a8960907-1325-11e9-bc05-0a580af40202: the server could not find the requested resource (get pods dns-test-a8960907-1325-11e9-bc05-0a580af40202)
Jan  8 09:13:57.506: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-d44q4.svc from pod e2e-tests-dns-d44q4/dns-test-a8960907-1325-11e9-bc05-0a580af40202: the server could not find the requested resource (get pods dns-test-a8960907-1325-11e9-bc05-0a580af40202)
Jan  8 09:13:57.510: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-d44q4.svc from pod e2e-tests-dns-d44q4/dns-test-a8960907-1325-11e9-bc05-0a580af40202: the server could not find the requested resource (get pods dns-test-a8960907-1325-11e9-bc05-0a580af40202)
Jan  8 09:13:57.513: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-d44q4.svc from pod e2e-tests-dns-d44q4/dns-test-a8960907-1325-11e9-bc05-0a580af40202: the server could not find the requested resource (get pods dns-test-a8960907-1325-11e9-bc05-0a580af40202)
Jan  8 09:13:57.516: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-d44q4.svc from pod e2e-tests-dns-d44q4/dns-test-a8960907-1325-11e9-bc05-0a580af40202: the server could not find the requested resource (get pods dns-test-a8960907-1325-11e9-bc05-0a580af40202)
Jan  8 09:13:57.538: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-d44q4/dns-test-a8960907-1325-11e9-bc05-0a580af40202: the server could not find the requested resource (get pods dns-test-a8960907-1325-11e9-bc05-0a580af40202)
Jan  8 09:13:57.541: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-d44q4/dns-test-a8960907-1325-11e9-bc05-0a580af40202: the server could not find the requested resource (get pods dns-test-a8960907-1325-11e9-bc05-0a580af40202)
Jan  8 09:13:57.544: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-d44q4 from pod e2e-tests-dns-d44q4/dns-test-a8960907-1325-11e9-bc05-0a580af40202: the server could not find the requested resource (get pods dns-test-a8960907-1325-11e9-bc05-0a580af40202)
Jan  8 09:13:57.547: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-d44q4 from pod e2e-tests-dns-d44q4/dns-test-a8960907-1325-11e9-bc05-0a580af40202: the server could not find the requested resource (get pods dns-test-a8960907-1325-11e9-bc05-0a580af40202)
Jan  8 09:13:57.550: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-d44q4.svc from pod e2e-tests-dns-d44q4/dns-test-a8960907-1325-11e9-bc05-0a580af40202: the server could not find the requested resource (get pods dns-test-a8960907-1325-11e9-bc05-0a580af40202)
Jan  8 09:13:57.553: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-d44q4.svc from pod e2e-tests-dns-d44q4/dns-test-a8960907-1325-11e9-bc05-0a580af40202: the server could not find the requested resource (get pods dns-test-a8960907-1325-11e9-bc05-0a580af40202)
Jan  8 09:13:57.556: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-d44q4.svc from pod e2e-tests-dns-d44q4/dns-test-a8960907-1325-11e9-bc05-0a580af40202: the server could not find the requested resource (get pods dns-test-a8960907-1325-11e9-bc05-0a580af40202)
Jan  8 09:13:57.559: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-d44q4.svc from pod e2e-tests-dns-d44q4/dns-test-a8960907-1325-11e9-bc05-0a580af40202: the server could not find the requested resource (get pods dns-test-a8960907-1325-11e9-bc05-0a580af40202)
Jan  8 09:13:57.578: INFO: Lookups using e2e-tests-dns-d44q4/dns-test-a8960907-1325-11e9-bc05-0a580af40202 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-d44q4 wheezy_tcp@dns-test-service.e2e-tests-dns-d44q4 wheezy_udp@dns-test-service.e2e-tests-dns-d44q4.svc wheezy_tcp@dns-test-service.e2e-tests-dns-d44q4.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-d44q4.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-d44q4.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-d44q4 jessie_tcp@dns-test-service.e2e-tests-dns-d44q4 jessie_udp@dns-test-service.e2e-tests-dns-d44q4.svc jessie_tcp@dns-test-service.e2e-tests-dns-d44q4.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-d44q4.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-d44q4.svc]

Jan  8 09:14:07.587: INFO: DNS probes using e2e-tests-dns-d44q4/dns-test-a8960907-1325-11e9-bc05-0a580af40202 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:14:07.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-d44q4" for this suite.
Jan  8 09:14:13.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:14:13.680: INFO: namespace: e2e-tests-dns-d44q4, resource: bindings, ignored listing per whitelist
Jan  8 09:14:13.743: INFO: namespace e2e-tests-dns-d44q4 deletion completed in 6.081747481s

â€¢ [SLOW TEST:46.425 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:14:13.744: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Jan  8 09:14:13.813: INFO: Waiting up to 5m0s for pod "pod-c435bae4-1325-11e9-bc05-0a580af40202" in namespace "e2e-tests-emptydir-jfz7m" to be "success or failure"
Jan  8 09:14:13.815: INFO: Pod "pod-c435bae4-1325-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.203564ms
Jan  8 09:14:15.818: INFO: Pod "pod-c435bae4-1325-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005159213s
Jan  8 09:14:17.821: INFO: Pod "pod-c435bae4-1325-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008554368s
Jan  8 09:14:19.825: INFO: Pod "pod-c435bae4-1325-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011815477s
STEP: Saw pod success
Jan  8 09:14:19.825: INFO: Pod "pod-c435bae4-1325-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:14:19.827: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod pod-c435bae4-1325-11e9-bc05-0a580af40202 container test-container: <nil>
STEP: delete the pod
Jan  8 09:14:19.842: INFO: Waiting for pod pod-c435bae4-1325-11e9-bc05-0a580af40202 to disappear
Jan  8 09:14:19.844: INFO: Pod pod-c435bae4-1325-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:14:19.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jfz7m" for this suite.
Jan  8 09:14:25.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:14:25.922: INFO: namespace: e2e-tests-emptydir-jfz7m, resource: bindings, ignored listing per whitelist
Jan  8 09:14:25.948: INFO: namespace e2e-tests-emptydir-jfz7m deletion completed in 6.100675644s

â€¢ [SLOW TEST:12.205 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:14:25.948: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan  8 09:14:26.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-wl752'
Jan  8 09:14:26.250: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan  8 09:14:26.250: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Jan  8 09:14:26.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-wl752'
Jan  8 09:14:26.342: INFO: stderr: ""
Jan  8 09:14:26.342: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:14:26.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wl752" for this suite.
Jan  8 09:14:48.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:14:48.433: INFO: namespace: e2e-tests-kubectl-wl752, resource: bindings, ignored listing per whitelist
Jan  8 09:14:48.439: INFO: namespace e2e-tests-kubectl-wl752 deletion completed in 22.092919821s

â€¢ [SLOW TEST:22.491 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:14:48.439: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  8 09:14:48.514: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jan  8 09:14:48.522: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:14:48.525: INFO: Number of nodes with available pods: 0
Jan  8 09:14:48.525: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:14:49.530: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:14:49.533: INFO: Number of nodes with available pods: 0
Jan  8 09:14:49.533: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:14:50.529: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:14:50.532: INFO: Number of nodes with available pods: 0
Jan  8 09:14:50.532: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:14:51.529: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:14:51.532: INFO: Number of nodes with available pods: 0
Jan  8 09:14:51.532: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:14:52.529: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:14:52.532: INFO: Number of nodes with available pods: 0
Jan  8 09:14:52.532: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:14:53.529: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:14:53.532: INFO: Number of nodes with available pods: 1
Jan  8 09:14:53.532: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:14:54.534: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:14:54.538: INFO: Number of nodes with available pods: 2
Jan  8 09:14:54.538: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jan  8 09:14:54.574: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:14:54.574: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:14:54.578: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:14:55.583: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:14:55.583: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:14:55.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:14:56.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:14:56.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:14:56.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:14:57.583: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:14:57.583: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:14:57.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:14:58.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:14:58.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:14:58.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:14:59.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:14:59.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:14:59.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:00.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:00.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:00.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:01.583: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:01.583: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:01.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:02.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:02.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:02.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:03.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:03.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:03.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:04.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:04.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:04.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:05.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:05.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:05.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:06.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:06.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:06.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:07.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:07.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:07.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:08.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:08.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:08.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:09.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:09.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:09.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:10.581: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:10.581: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:10.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:11.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:11.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:11.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:12.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:12.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:12.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:13.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:13.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:13.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:14.583: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:14.583: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:14.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:15.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:15.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:15.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:16.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:16.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:16.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:17.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:17.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:17.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:18.583: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:18.583: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:18.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:19.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:19.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:19.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:20.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:20.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:20.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:21.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:21.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:21.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:22.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:22.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:22.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:23.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:23.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:23.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:24.583: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:24.583: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:24.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:25.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:25.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:25.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:26.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:26.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:26.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:27.582: INFO: Wrong image for pod: daemon-set-c47kp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:27.582: INFO: Pod daemon-set-c47kp is not available
Jan  8 09:15:27.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:27.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:28.582: INFO: Pod daemon-set-68h6p is not available
Jan  8 09:15:28.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:28.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:29.582: INFO: Pod daemon-set-68h6p is not available
Jan  8 09:15:29.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:29.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:30.581: INFO: Pod daemon-set-68h6p is not available
Jan  8 09:15:30.581: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:30.584: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:31.582: INFO: Pod daemon-set-68h6p is not available
Jan  8 09:15:31.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:31.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:32.582: INFO: Pod daemon-set-68h6p is not available
Jan  8 09:15:32.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:32.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:33.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:33.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:34.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:34.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:35.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:35.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:36.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:36.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:37.583: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:37.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:38.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:38.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:39.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:39.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:40.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:40.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:41.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:41.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:42.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:42.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:43.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:43.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:44.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:44.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:45.583: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:45.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:46.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:46.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:47.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:47.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:48.583: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:48.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:49.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:49.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:50.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:50.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:51.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:51.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:52.583: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:52.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:53.583: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:53.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:54.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:54.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:55.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:55.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:56.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:56.584: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:57.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:57.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:58.583: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:58.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:15:59.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:15:59.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:16:00.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:16:00.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:16:01.583: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:16:01.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:16:02.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:16:02.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:16:03.582: INFO: Wrong image for pod: daemon-set-t956j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  8 09:16:03.582: INFO: Pod daemon-set-t956j is not available
Jan  8 09:16:03.585: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:16:04.582: INFO: Pod daemon-set-z5sch is not available
Jan  8 09:16:04.586: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Jan  8 09:16:04.589: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:16:04.591: INFO: Number of nodes with available pods: 1
Jan  8 09:16:04.591: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:16:05.596: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:16:05.598: INFO: Number of nodes with available pods: 1
Jan  8 09:16:05.598: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:16:06.595: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:16:06.598: INFO: Number of nodes with available pods: 1
Jan  8 09:16:06.598: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:16:07.596: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:16:07.599: INFO: Number of nodes with available pods: 1
Jan  8 09:16:07.599: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:16:08.598: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:16:08.607: INFO: Number of nodes with available pods: 1
Jan  8 09:16:08.607: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:16:09.595: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:16:09.598: INFO: Number of nodes with available pods: 2
Jan  8 09:16:09.598: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-kbzv4, will wait for the garbage collector to delete the pods
Jan  8 09:16:09.670: INFO: Deleting {extensions DaemonSet} daemon-set took: 6.029593ms
Jan  8 09:16:09.770: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.163147ms
Jan  8 09:16:17.473: INFO: Number of nodes with available pods: 0
Jan  8 09:16:17.473: INFO: Number of running nodes: 0, number of available pods: 0
Jan  8 09:16:17.475: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-kbzv4/daemonsets","resourceVersion":"1995"},"items":null}

Jan  8 09:16:17.478: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-kbzv4/pods","resourceVersion":"1995"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:16:17.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-kbzv4" for this suite.
Jan  8 09:16:23.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:16:23.569: INFO: namespace: e2e-tests-daemonsets-kbzv4, resource: bindings, ignored listing per whitelist
Jan  8 09:16:23.577: INFO: namespace e2e-tests-daemonsets-kbzv4 deletion completed in 6.0863311s

â€¢ [SLOW TEST:95.137 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:16:23.577: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-11996b96-1326-11e9-bc05-0a580af40202
STEP: Creating secret with name s-test-opt-upd-11996bcb-1326-11e9-bc05-0a580af40202
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-11996b96-1326-11e9-bc05-0a580af40202
STEP: Updating secret s-test-opt-upd-11996bcb-1326-11e9-bc05-0a580af40202
STEP: Creating secret with name s-test-opt-create-11996be0-1326-11e9-bc05-0a580af40202
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:16:29.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nc7jg" for this suite.
Jan  8 09:16:51.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:16:51.802: INFO: namespace: e2e-tests-projected-nc7jg, resource: bindings, ignored listing per whitelist
Jan  8 09:16:51.833: INFO: namespace e2e-tests-projected-nc7jg deletion completed in 22.092521201s

â€¢ [SLOW TEST:28.256 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:16:51.833: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jan  8 09:16:51.921: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-4x2jc,SelfLink:/api/v1/namespaces/e2e-tests-watch-4x2jc/configmaps/e2e-watch-test-watch-closed,UID:2271dec2-1326-11e9-a60a-02001701fa35,ResourceVersion:2129,Generation:0,CreationTimestamp:2019-01-08 09:16:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan  8 09:16:51.921: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-4x2jc,SelfLink:/api/v1/namespaces/e2e-tests-watch-4x2jc/configmaps/e2e-watch-test-watch-closed,UID:2271dec2-1326-11e9-a60a-02001701fa35,ResourceVersion:2130,Generation:0,CreationTimestamp:2019-01-08 09:16:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jan  8 09:16:51.933: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-4x2jc,SelfLink:/api/v1/namespaces/e2e-tests-watch-4x2jc/configmaps/e2e-watch-test-watch-closed,UID:2271dec2-1326-11e9-a60a-02001701fa35,ResourceVersion:2131,Generation:0,CreationTimestamp:2019-01-08 09:16:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan  8 09:16:51.933: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-4x2jc,SelfLink:/api/v1/namespaces/e2e-tests-watch-4x2jc/configmaps/e2e-watch-test-watch-closed,UID:2271dec2-1326-11e9-a60a-02001701fa35,ResourceVersion:2132,Generation:0,CreationTimestamp:2019-01-08 09:16:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:16:51.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-4x2jc" for this suite.
Jan  8 09:16:57.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:16:58.004: INFO: namespace: e2e-tests-watch-4x2jc, resource: bindings, ignored listing per whitelist
Jan  8 09:16:58.032: INFO: namespace e2e-tests-watch-4x2jc deletion completed in 6.096296635s

â€¢ [SLOW TEST:6.199 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:16:58.033: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Jan  8 09:16:58.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 api-versions'
Jan  8 09:16:58.185: INFO: stderr: ""
Jan  8 09:16:58.185: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:16:58.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-678np" for this suite.
Jan  8 09:17:04.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:17:04.209: INFO: namespace: e2e-tests-kubectl-678np, resource: bindings, ignored listing per whitelist
Jan  8 09:17:04.278: INFO: namespace e2e-tests-kubectl-678np deletion completed in 6.089831384s

â€¢ [SLOW TEST:6.246 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:17:04.278: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-29dc225d-1326-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume secrets
Jan  8 09:17:04.357: INFO: Waiting up to 5m0s for pod "pod-secrets-29dc9864-1326-11e9-bc05-0a580af40202" in namespace "e2e-tests-secrets-j8sc5" to be "success or failure"
Jan  8 09:17:04.360: INFO: Pod "pod-secrets-29dc9864-1326-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.675945ms
Jan  8 09:17:06.364: INFO: Pod "pod-secrets-29dc9864-1326-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006699674s
STEP: Saw pod success
Jan  8 09:17:06.364: INFO: Pod "pod-secrets-29dc9864-1326-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:17:06.366: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-secrets-29dc9864-1326-11e9-bc05-0a580af40202 container secret-volume-test: <nil>
STEP: delete the pod
Jan  8 09:17:06.382: INFO: Waiting for pod pod-secrets-29dc9864-1326-11e9-bc05-0a580af40202 to disappear
Jan  8 09:17:06.385: INFO: Pod pod-secrets-29dc9864-1326-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:17:06.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-j8sc5" for this suite.
Jan  8 09:17:12.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:17:12.445: INFO: namespace: e2e-tests-secrets-j8sc5, resource: bindings, ignored listing per whitelist
Jan  8 09:17:12.478: INFO: namespace e2e-tests-secrets-j8sc5 deletion completed in 6.090500641s

â€¢ [SLOW TEST:8.200 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:17:12.479: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-2ebf399e-1326-11e9-bc05-0a580af40202
STEP: Creating configMap with name cm-test-opt-upd-2ebf39d0-1326-11e9-bc05-0a580af40202
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-2ebf399e-1326-11e9-bc05-0a580af40202
STEP: Updating configmap cm-test-opt-upd-2ebf39d0-1326-11e9-bc05-0a580af40202
STEP: Creating configMap with name cm-test-opt-create-2ebf39e1-1326-11e9-bc05-0a580af40202
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:18:30.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nqtlq" for this suite.
Jan  8 09:18:52.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:18:53.015: INFO: namespace: e2e-tests-projected-nqtlq, resource: bindings, ignored listing per whitelist
Jan  8 09:18:53.057: INFO: namespace e2e-tests-projected-nqtlq deletion completed in 22.094234117s

â€¢ [SLOW TEST:100.578 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:18:53.057: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan  8 09:18:53.138: INFO: Waiting up to 5m0s for pod "downward-api-6ab2ff9f-1326-11e9-bc05-0a580af40202" in namespace "e2e-tests-downward-api-qbqtw" to be "success or failure"
Jan  8 09:18:53.141: INFO: Pod "downward-api-6ab2ff9f-1326-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.152609ms
Jan  8 09:18:55.145: INFO: Pod "downward-api-6ab2ff9f-1326-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006758265s
Jan  8 09:18:57.148: INFO: Pod "downward-api-6ab2ff9f-1326-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010605507s
Jan  8 09:18:59.152: INFO: Pod "downward-api-6ab2ff9f-1326-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013964119s
STEP: Saw pod success
Jan  8 09:18:59.152: INFO: Pod "downward-api-6ab2ff9f-1326-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:18:59.155: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod downward-api-6ab2ff9f-1326-11e9-bc05-0a580af40202 container dapi-container: <nil>
STEP: delete the pod
Jan  8 09:18:59.173: INFO: Waiting for pod downward-api-6ab2ff9f-1326-11e9-bc05-0a580af40202 to disappear
Jan  8 09:18:59.176: INFO: Pod downward-api-6ab2ff9f-1326-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:18:59.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qbqtw" for this suite.
Jan  8 09:19:05.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:19:05.208: INFO: namespace: e2e-tests-downward-api-qbqtw, resource: bindings, ignored listing per whitelist
Jan  8 09:19:05.288: INFO: namespace e2e-tests-downward-api-qbqtw deletion completed in 6.108281494s

â€¢ [SLOW TEST:12.231 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:19:05.288: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-71ff53d5-1326-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume configMaps
Jan  8 09:19:05.386: INFO: Waiting up to 5m0s for pod "pod-configmaps-71ffeafb-1326-11e9-bc05-0a580af40202" in namespace "e2e-tests-configmap-h9szl" to be "success or failure"
Jan  8 09:19:05.402: INFO: Pod "pod-configmaps-71ffeafb-1326-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 16.520315ms
Jan  8 09:19:07.406: INFO: Pod "pod-configmaps-71ffeafb-1326-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02072259s
STEP: Saw pod success
Jan  8 09:19:07.406: INFO: Pod "pod-configmaps-71ffeafb-1326-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:19:07.409: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod pod-configmaps-71ffeafb-1326-11e9-bc05-0a580af40202 container configmap-volume-test: <nil>
STEP: delete the pod
Jan  8 09:19:07.428: INFO: Waiting for pod pod-configmaps-71ffeafb-1326-11e9-bc05-0a580af40202 to disappear
Jan  8 09:19:07.431: INFO: Pod pod-configmaps-71ffeafb-1326-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:19:07.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-h9szl" for this suite.
Jan  8 09:19:13.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:19:13.547: INFO: namespace: e2e-tests-configmap-h9szl, resource: bindings, ignored listing per whitelist
Jan  8 09:19:13.572: INFO: namespace e2e-tests-configmap-h9szl deletion completed in 6.137836828s

â€¢ [SLOW TEST:8.284 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:19:13.572: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:19:19.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-qfvkg" for this suite.
Jan  8 09:19:25.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:19:25.771: INFO: namespace: e2e-tests-namespaces-qfvkg, resource: bindings, ignored listing per whitelist
Jan  8 09:19:25.837: INFO: namespace e2e-tests-namespaces-qfvkg deletion completed in 6.101283658s
STEP: Destroying namespace "e2e-tests-nsdeletetest-w2mt9" for this suite.
Jan  8 09:19:25.840: INFO: Namespace e2e-tests-nsdeletetest-w2mt9 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-wpd75" for this suite.
Jan  8 09:19:31.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:19:31.891: INFO: namespace: e2e-tests-nsdeletetest-wpd75, resource: bindings, ignored listing per whitelist
Jan  8 09:19:31.961: INFO: namespace e2e-tests-nsdeletetest-wpd75 deletion completed in 6.120546276s

â€¢ [SLOW TEST:18.389 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:19:31.961: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-81e429cb-1326-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume secrets
Jan  8 09:19:32.050: INFO: Waiting up to 5m0s for pod "pod-secrets-81e4a68a-1326-11e9-bc05-0a580af40202" in namespace "e2e-tests-secrets-6jwcb" to be "success or failure"
Jan  8 09:19:32.055: INFO: Pod "pod-secrets-81e4a68a-1326-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.798121ms
Jan  8 09:19:34.059: INFO: Pod "pod-secrets-81e4a68a-1326-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008311297s
STEP: Saw pod success
Jan  8 09:19:34.059: INFO: Pod "pod-secrets-81e4a68a-1326-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:19:34.061: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-secrets-81e4a68a-1326-11e9-bc05-0a580af40202 container secret-volume-test: <nil>
STEP: delete the pod
Jan  8 09:19:34.079: INFO: Waiting for pod pod-secrets-81e4a68a-1326-11e9-bc05-0a580af40202 to disappear
Jan  8 09:19:34.081: INFO: Pod pod-secrets-81e4a68a-1326-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:19:34.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6jwcb" for this suite.
Jan  8 09:19:40.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:19:40.135: INFO: namespace: e2e-tests-secrets-6jwcb, resource: bindings, ignored listing per whitelist
Jan  8 09:19:40.188: INFO: namespace e2e-tests-secrets-6jwcb deletion completed in 6.102812131s

â€¢ [SLOW TEST:8.227 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:19:40.188: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Jan  8 09:19:46.292: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:19:46.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-ss9dx" for this suite.
Jan  8 09:19:52.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:19:52.390: INFO: namespace: e2e-tests-gc-ss9dx, resource: bindings, ignored listing per whitelist
Jan  8 09:19:52.395: INFO: namespace e2e-tests-gc-ss9dx deletion completed in 6.099334083s

â€¢ [SLOW TEST:12.207 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:19:52.395: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-6jh7l
Jan  8 09:19:54.483: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-6jh7l
STEP: checking the pod's current state and verifying that restartCount is present
Jan  8 09:19:54.485: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:23:54.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-6jh7l" for this suite.
Jan  8 09:24:00.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:24:01.032: INFO: namespace: e2e-tests-container-probe-6jh7l, resource: bindings, ignored listing per whitelist
Jan  8 09:24:01.067: INFO: namespace e2e-tests-container-probe-6jh7l deletion completed in 6.104027264s

â€¢ [SLOW TEST:248.672 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:24:01.068: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Jan  8 09:24:01.144: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan  8 09:24:01.151: INFO: Waiting for terminating namespaces to be deleted...
Jan  8 09:24:01.154: INFO: 
Logging pods the kubelet thinks is on node oltf-408483-kube-worker1 before test
Jan  8 09:24:01.160: INFO: kube-flannel-ds-ktvvw from kube-system started at 2019-01-08 09:06:18 +0000 UTC (1 container statuses recorded)
Jan  8 09:24:01.160: INFO: 	Container kube-flannel ready: true, restart count 0
Jan  8 09:24:01.160: INFO: kube-proxy-hx5gw from kube-system started at 2019-01-08 09:06:18 +0000 UTC (1 container statuses recorded)
Jan  8 09:24:01.160: INFO: 	Container kube-proxy ready: true, restart count 0
Jan  8 09:24:01.160: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-08 09:12:14 +0000 UTC (1 container statuses recorded)
Jan  8 09:24:01.160: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan  8 09:24:01.160: INFO: sonobuoy-systemd-logs-daemon-set-e6ac5c1d15cd4528-rfbv9 from heptio-sonobuoy started at 2019-01-08 09:12:20 +0000 UTC (2 container statuses recorded)
Jan  8 09:24:01.160: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan  8 09:24:01.160: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan  8 09:24:01.160: INFO: 
Logging pods the kubelet thinks is on node oltf-408483-kube-worker2 before test
Jan  8 09:24:01.165: INFO: kube-flannel-ds-6df6t from kube-system started at 2019-01-08 09:07:03 +0000 UTC (1 container statuses recorded)
Jan  8 09:24:01.165: INFO: 	Container kube-flannel ready: true, restart count 0
Jan  8 09:24:01.165: INFO: kube-proxy-4wjhs from kube-system started at 2019-01-08 09:07:03 +0000 UTC (1 container statuses recorded)
Jan  8 09:24:01.165: INFO: 	Container kube-proxy ready: true, restart count 0
Jan  8 09:24:01.165: INFO: sonobuoy-e2e-job-95203627594e4c77 from heptio-sonobuoy started at 2019-01-08 09:12:20 +0000 UTC (2 container statuses recorded)
Jan  8 09:24:01.165: INFO: 	Container e2e ready: true, restart count 0
Jan  8 09:24:01.165: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan  8 09:24:01.165: INFO: sonobuoy-systemd-logs-daemon-set-e6ac5c1d15cd4528-tjn6w from heptio-sonobuoy started at 2019-01-08 09:12:20 +0000 UTC (2 container statuses recorded)
Jan  8 09:24:01.165: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan  8 09:24:01.165: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1577d539c8c459ff], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:24:02.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-ptgjj" for this suite.
Jan  8 09:24:08.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:24:08.258: INFO: namespace: e2e-tests-sched-pred-ptgjj, resource: bindings, ignored listing per whitelist
Jan  8 09:24:08.291: INFO: namespace e2e-tests-sched-pred-ptgjj deletion completed in 6.101058143s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

â€¢ [SLOW TEST:7.224 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:24:08.292: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Jan  8 09:24:08.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 create -f - --namespace=e2e-tests-kubectl-kjxm4'
Jan  8 09:24:08.623: INFO: stderr: ""
Jan  8 09:24:08.623: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Jan  8 09:24:09.627: INFO: Selector matched 1 pods for map[app:redis]
Jan  8 09:24:09.627: INFO: Found 0 / 1
Jan  8 09:24:10.627: INFO: Selector matched 1 pods for map[app:redis]
Jan  8 09:24:10.627: INFO: Found 1 / 1
Jan  8 09:24:10.627: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan  8 09:24:10.630: INFO: Selector matched 1 pods for map[app:redis]
Jan  8 09:24:10.630: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Jan  8 09:24:10.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 logs redis-master-gnt99 redis-master --namespace=e2e-tests-kubectl-kjxm4'
Jan  8 09:24:10.732: INFO: stderr: ""
Jan  8 09:24:10.732: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 08 Jan 09:24:09.564 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 08 Jan 09:24:09.565 # Server started, Redis version 3.2.12\n1:M 08 Jan 09:24:09.565 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 08 Jan 09:24:09.565 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Jan  8 09:24:10.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 log redis-master-gnt99 redis-master --namespace=e2e-tests-kubectl-kjxm4 --tail=1'
Jan  8 09:24:10.837: INFO: stderr: ""
Jan  8 09:24:10.837: INFO: stdout: "1:M 08 Jan 09:24:09.565 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Jan  8 09:24:10.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 log redis-master-gnt99 redis-master --namespace=e2e-tests-kubectl-kjxm4 --limit-bytes=1'
Jan  8 09:24:10.939: INFO: stderr: ""
Jan  8 09:24:10.939: INFO: stdout: " "
STEP: exposing timestamps
Jan  8 09:24:10.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 log redis-master-gnt99 redis-master --namespace=e2e-tests-kubectl-kjxm4 --tail=1 --timestamps'
Jan  8 09:24:11.036: INFO: stderr: ""
Jan  8 09:24:11.036: INFO: stdout: "2019-01-08T09:24:09.565709346Z 1:M 08 Jan 09:24:09.565 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Jan  8 09:24:13.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 log redis-master-gnt99 redis-master --namespace=e2e-tests-kubectl-kjxm4 --since=1s'
Jan  8 09:24:13.638: INFO: stderr: ""
Jan  8 09:24:13.638: INFO: stdout: ""
Jan  8 09:24:13.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 log redis-master-gnt99 redis-master --namespace=e2e-tests-kubectl-kjxm4 --since=24h'
Jan  8 09:24:13.735: INFO: stderr: ""
Jan  8 09:24:13.735: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 08 Jan 09:24:09.564 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 08 Jan 09:24:09.565 # Server started, Redis version 3.2.12\n1:M 08 Jan 09:24:09.565 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 08 Jan 09:24:09.565 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Jan  8 09:24:13.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-kjxm4'
Jan  8 09:24:13.826: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  8 09:24:13.826: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Jan  8 09:24:13.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-kjxm4'
Jan  8 09:24:13.932: INFO: stderr: "No resources found.\n"
Jan  8 09:24:13.932: INFO: stdout: ""
Jan  8 09:24:13.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods -l name=nginx --namespace=e2e-tests-kubectl-kjxm4 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan  8 09:24:14.016: INFO: stderr: ""
Jan  8 09:24:14.016: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:24:14.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kjxm4" for this suite.
Jan  8 09:24:20.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:24:20.043: INFO: namespace: e2e-tests-kubectl-kjxm4, resource: bindings, ignored listing per whitelist
Jan  8 09:24:20.122: INFO: namespace e2e-tests-kubectl-kjxm4 deletion completed in 6.102369329s

â€¢ [SLOW TEST:11.830 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:24:20.123: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-k4lkc/configmap-test-2da5a0ba-1327-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume configMaps
Jan  8 09:24:20.208: INFO: Waiting up to 5m0s for pod "pod-configmaps-2da6227b-1327-11e9-bc05-0a580af40202" in namespace "e2e-tests-configmap-k4lkc" to be "success or failure"
Jan  8 09:24:20.211: INFO: Pod "pod-configmaps-2da6227b-1327-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.923646ms
Jan  8 09:24:22.215: INFO: Pod "pod-configmaps-2da6227b-1327-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00662344s
STEP: Saw pod success
Jan  8 09:24:22.215: INFO: Pod "pod-configmaps-2da6227b-1327-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:24:22.218: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod pod-configmaps-2da6227b-1327-11e9-bc05-0a580af40202 container env-test: <nil>
STEP: delete the pod
Jan  8 09:24:22.236: INFO: Waiting for pod pod-configmaps-2da6227b-1327-11e9-bc05-0a580af40202 to disappear
Jan  8 09:24:22.239: INFO: Pod pod-configmaps-2da6227b-1327-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:24:22.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-k4lkc" for this suite.
Jan  8 09:24:28.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:24:28.307: INFO: namespace: e2e-tests-configmap-k4lkc, resource: bindings, ignored listing per whitelist
Jan  8 09:24:28.343: INFO: namespace e2e-tests-configmap-k4lkc deletion completed in 6.101240444s

â€¢ [SLOW TEST:8.221 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:24:28.344: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-328bac39-1327-11e9-bc05-0a580af40202
STEP: Creating configMap with name cm-test-opt-upd-328bac92-1327-11e9-bc05-0a580af40202
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-328bac39-1327-11e9-bc05-0a580af40202
STEP: Updating configmap cm-test-opt-upd-328bac92-1327-11e9-bc05-0a580af40202
STEP: Creating configMap with name cm-test-opt-create-328baca9-1327-11e9-bc05-0a580af40202
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:25:46.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-w9brl" for this suite.
Jan  8 09:26:08.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:26:08.900: INFO: namespace: e2e-tests-configmap-w9brl, resource: bindings, ignored listing per whitelist
Jan  8 09:26:08.944: INFO: namespace e2e-tests-configmap-w9brl deletion completed in 22.099926643s

â€¢ [SLOW TEST:100.601 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:26:08.945: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:26:09.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-2hhxh" for this suite.
Jan  8 09:26:15.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:26:15.119: INFO: namespace: e2e-tests-services-2hhxh, resource: bindings, ignored listing per whitelist
Jan  8 09:26:15.129: INFO: namespace e2e-tests-services-2hhxh deletion completed in 6.102788629s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

â€¢ [SLOW TEST:6.184 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:26:15.129: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  8 09:26:15.206: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jan  8 09:26:20.210: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan  8 09:26:20.210: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jan  8 09:26:22.214: INFO: Creating deployment "test-rollover-deployment"
Jan  8 09:26:22.222: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jan  8 09:26:24.229: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jan  8 09:26:24.235: INFO: Ensure that both replica sets have 1 created replica
Jan  8 09:26:24.241: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jan  8 09:26:24.248: INFO: Updating deployment test-rollover-deployment
Jan  8 09:26:24.248: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jan  8 09:26:26.255: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jan  8 09:26:26.261: INFO: Make sure deployment "test-rollover-deployment" is complete
Jan  8 09:26:26.267: INFO: all replica sets need to contain the pod-template-hash label
Jan  8 09:26:26.267: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682536382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682536382, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682536386, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682536382, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan  8 09:26:28.274: INFO: all replica sets need to contain the pod-template-hash label
Jan  8 09:26:28.274: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682536382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682536382, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682536386, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682536382, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan  8 09:26:30.274: INFO: all replica sets need to contain the pod-template-hash label
Jan  8 09:26:30.274: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682536382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682536382, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682536386, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682536382, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan  8 09:26:32.274: INFO: all replica sets need to contain the pod-template-hash label
Jan  8 09:26:32.274: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682536382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682536382, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682536386, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682536382, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan  8 09:26:34.274: INFO: all replica sets need to contain the pod-template-hash label
Jan  8 09:26:34.274: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682536382, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682536382, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682536386, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682536382, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan  8 09:26:36.273: INFO: 
Jan  8 09:26:36.273: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan  8 09:26:36.282: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-xhx5q,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xhx5q/deployments/test-rollover-deployment,UID:765fee63-1327-11e9-a60a-02001701fa35,ResourceVersion:3509,Generation:2,CreationTimestamp:2019-01-08 09:26:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-01-08 09:26:22 +0000 UTC 2019-01-08 09:26:22 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-01-08 09:26:36 +0000 UTC 2019-01-08 09:26:22 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan  8 09:26:36.285: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-xhx5q,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xhx5q/replicasets/test-rollover-deployment-5b76ff8c4,UID:77964e67-1327-11e9-a60a-02001701fa35,ResourceVersion:3500,Generation:2,CreationTimestamp:2019-01-08 09:26:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 765fee63-1327-11e9-a60a-02001701fa35 0xc421aa0777 0xc421aa0778}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan  8 09:26:36.285: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jan  8 09:26:36.285: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-xhx5q,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xhx5q/replicasets/test-rollover-controller,UID:7231568d-1327-11e9-a60a-02001701fa35,ResourceVersion:3508,Generation:2,CreationTimestamp:2019-01-08 09:26:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 765fee63-1327-11e9-a60a-02001701fa35 0xc421aa06c7 0xc421aa06c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan  8 09:26:36.286: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-xhx5q,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xhx5q/replicasets/test-rollover-deployment-6975f4fb87,UID:7663c003-1327-11e9-a60a-02001701fa35,ResourceVersion:3473,Generation:2,CreationTimestamp:2019-01-08 09:26:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 765fee63-1327-11e9-a60a-02001701fa35 0xc421aa0827 0xc421aa0828}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan  8 09:26:36.289: INFO: Pod "test-rollover-deployment-5b76ff8c4-9lsxt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-9lsxt,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-xhx5q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xhx5q/pods/test-rollover-deployment-5b76ff8c4-9lsxt,UID:779aade4-1327-11e9-a60a-02001701fa35,ResourceVersion:3483,Generation:0,CreationTimestamp:2019-01-08 09:26:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 77964e67-1327-11e9-a60a-02001701fa35 0xc421aa12e0 0xc421aa12e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4hlr5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4hlr5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-4hlr5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421aa1340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421aa1360}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:26:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:26:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:26:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:26:24 +0000 UTC  }],Message:,Reason:,HostIP:100.100.242.163,PodIP:10.244.2.18,StartTime:2019-01-08 09:26:24 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-01-08 09:26:25 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://3bcc552b4963893236709c3012957437b270f161d6ef98b405fe9cc435b58095}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:26:36.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-xhx5q" for this suite.
Jan  8 09:26:42.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:26:42.347: INFO: namespace: e2e-tests-deployment-xhx5q, resource: bindings, ignored listing per whitelist
Jan  8 09:26:42.404: INFO: namespace e2e-tests-deployment-xhx5q deletion completed in 6.11087572s

â€¢ [SLOW TEST:27.275 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:26:42.405: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan  8 09:26:54.535: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  8 09:26:54.538: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  8 09:26:56.538: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  8 09:26:56.542: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  8 09:26:58.538: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  8 09:26:58.542: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  8 09:27:00.538: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  8 09:27:00.542: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  8 09:27:02.538: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  8 09:27:02.541: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  8 09:27:04.538: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  8 09:27:04.542: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  8 09:27:06.538: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  8 09:27:06.542: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  8 09:27:08.538: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  8 09:27:08.542: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  8 09:27:10.538: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  8 09:27:10.542: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  8 09:27:12.538: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  8 09:27:12.541: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  8 09:27:14.538: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  8 09:27:14.542: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:27:14.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-wp2rw" for this suite.
Jan  8 09:27:36.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:27:36.588: INFO: namespace: e2e-tests-container-lifecycle-hook-wp2rw, resource: bindings, ignored listing per whitelist
Jan  8 09:27:36.651: INFO: namespace e2e-tests-container-lifecycle-hook-wp2rw deletion completed in 22.105838139s

â€¢ [SLOW TEST:54.246 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:27:36.652: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  8 09:27:36.733: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a2c96ea7-1327-11e9-bc05-0a580af40202" in namespace "e2e-tests-projected-qm2zd" to be "success or failure"
Jan  8 09:27:36.736: INFO: Pod "downwardapi-volume-a2c96ea7-1327-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.641334ms
Jan  8 09:27:38.739: INFO: Pod "downwardapi-volume-a2c96ea7-1327-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006439369s
STEP: Saw pod success
Jan  8 09:27:38.739: INFO: Pod "downwardapi-volume-a2c96ea7-1327-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:27:38.742: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod downwardapi-volume-a2c96ea7-1327-11e9-bc05-0a580af40202 container client-container: <nil>
STEP: delete the pod
Jan  8 09:27:38.763: INFO: Waiting for pod downwardapi-volume-a2c96ea7-1327-11e9-bc05-0a580af40202 to disappear
Jan  8 09:27:38.766: INFO: Pod downwardapi-volume-a2c96ea7-1327-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:27:38.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qm2zd" for this suite.
Jan  8 09:27:44.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:27:44.793: INFO: namespace: e2e-tests-projected-qm2zd, resource: bindings, ignored listing per whitelist
Jan  8 09:27:44.874: INFO: namespace e2e-tests-projected-qm2zd deletion completed in 6.104767091s

â€¢ [SLOW TEST:8.223 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:27:44.875: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Jan  8 09:27:44.947: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-qh5sh" to be "success or failure"
Jan  8 09:27:44.950: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.427735ms
Jan  8 09:27:46.953: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005886903s
STEP: Saw pod success
Jan  8 09:27:46.953: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jan  8 09:27:46.956: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jan  8 09:27:46.973: INFO: Waiting for pod pod-host-path-test to disappear
Jan  8 09:27:46.976: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:27:46.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-qh5sh" for this suite.
Jan  8 09:27:52.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:27:53.012: INFO: namespace: e2e-tests-hostpath-qh5sh, resource: bindings, ignored listing per whitelist
Jan  8 09:27:53.078: INFO: namespace e2e-tests-hostpath-qh5sh deletion completed in 6.098439282s

â€¢ [SLOW TEST:8.203 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:27:53.078: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-ac93b7c9-1327-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume configMaps
Jan  8 09:27:53.162: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ac944715-1327-11e9-bc05-0a580af40202" in namespace "e2e-tests-projected-28q2g" to be "success or failure"
Jan  8 09:27:53.165: INFO: Pod "pod-projected-configmaps-ac944715-1327-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.088266ms
Jan  8 09:27:55.169: INFO: Pod "pod-projected-configmaps-ac944715-1327-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006869051s
STEP: Saw pod success
Jan  8 09:27:55.169: INFO: Pod "pod-projected-configmaps-ac944715-1327-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:27:55.172: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-projected-configmaps-ac944715-1327-11e9-bc05-0a580af40202 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan  8 09:27:55.189: INFO: Waiting for pod pod-projected-configmaps-ac944715-1327-11e9-bc05-0a580af40202 to disappear
Jan  8 09:27:55.192: INFO: Pod pod-projected-configmaps-ac944715-1327-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:27:55.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-28q2g" for this suite.
Jan  8 09:28:01.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:28:01.223: INFO: namespace: e2e-tests-projected-28q2g, resource: bindings, ignored listing per whitelist
Jan  8 09:28:01.292: INFO: namespace e2e-tests-projected-28q2g deletion completed in 6.097331088s

â€¢ [SLOW TEST:8.214 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:28:01.292: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan  8 09:28:01.367: INFO: Waiting up to 5m0s for pod "pod-b1781079-1327-11e9-bc05-0a580af40202" in namespace "e2e-tests-emptydir-cdmk8" to be "success or failure"
Jan  8 09:28:01.369: INFO: Pod "pod-b1781079-1327-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.627346ms
Jan  8 09:28:03.373: INFO: Pod "pod-b1781079-1327-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006497964s
Jan  8 09:28:05.376: INFO: Pod "pod-b1781079-1327-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009807646s
Jan  8 09:28:07.380: INFO: Pod "pod-b1781079-1327-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013871626s
STEP: Saw pod success
Jan  8 09:28:07.381: INFO: Pod "pod-b1781079-1327-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:28:07.383: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod pod-b1781079-1327-11e9-bc05-0a580af40202 container test-container: <nil>
STEP: delete the pod
Jan  8 09:28:07.403: INFO: Waiting for pod pod-b1781079-1327-11e9-bc05-0a580af40202 to disappear
Jan  8 09:28:07.406: INFO: Pod pod-b1781079-1327-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:28:07.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cdmk8" for this suite.
Jan  8 09:28:13.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:28:13.507: INFO: namespace: e2e-tests-emptydir-cdmk8, resource: bindings, ignored listing per whitelist
Jan  8 09:28:13.512: INFO: namespace e2e-tests-emptydir-cdmk8 deletion completed in 6.100828012s

â€¢ [SLOW TEST:12.220 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:28:13.512: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  8 09:28:13.594: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b8c1c7f9-1327-11e9-bc05-0a580af40202" in namespace "e2e-tests-projected-bwzgp" to be "success or failure"
Jan  8 09:28:13.600: INFO: Pod "downwardapi-volume-b8c1c7f9-1327-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 5.389184ms
Jan  8 09:28:15.604: INFO: Pod "downwardapi-volume-b8c1c7f9-1327-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009313832s
STEP: Saw pod success
Jan  8 09:28:15.604: INFO: Pod "downwardapi-volume-b8c1c7f9-1327-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:28:15.607: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod downwardapi-volume-b8c1c7f9-1327-11e9-bc05-0a580af40202 container client-container: <nil>
STEP: delete the pod
Jan  8 09:28:15.625: INFO: Waiting for pod downwardapi-volume-b8c1c7f9-1327-11e9-bc05-0a580af40202 to disappear
Jan  8 09:28:15.628: INFO: Pod downwardapi-volume-b8c1c7f9-1327-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:28:15.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bwzgp" for this suite.
Jan  8 09:28:21.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:28:21.712: INFO: namespace: e2e-tests-projected-bwzgp, resource: bindings, ignored listing per whitelist
Jan  8 09:28:21.734: INFO: namespace e2e-tests-projected-bwzgp deletion completed in 6.1032901s

â€¢ [SLOW TEST:8.222 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:28:21.734: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-bda74498-1327-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume configMaps
Jan  8 09:28:21.811: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bda7cf9b-1327-11e9-bc05-0a580af40202" in namespace "e2e-tests-projected-ds9g9" to be "success or failure"
Jan  8 09:28:21.814: INFO: Pod "pod-projected-configmaps-bda7cf9b-1327-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.723002ms
Jan  8 09:28:23.818: INFO: Pod "pod-projected-configmaps-bda7cf9b-1327-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006685781s
STEP: Saw pod success
Jan  8 09:28:23.818: INFO: Pod "pod-projected-configmaps-bda7cf9b-1327-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:28:23.820: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod pod-projected-configmaps-bda7cf9b-1327-11e9-bc05-0a580af40202 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan  8 09:28:23.837: INFO: Waiting for pod pod-projected-configmaps-bda7cf9b-1327-11e9-bc05-0a580af40202 to disappear
Jan  8 09:28:23.840: INFO: Pod pod-projected-configmaps-bda7cf9b-1327-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:28:23.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ds9g9" for this suite.
Jan  8 09:28:29.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:28:29.894: INFO: namespace: e2e-tests-projected-ds9g9, resource: bindings, ignored listing per whitelist
Jan  8 09:28:29.964: INFO: namespace e2e-tests-projected-ds9g9 deletion completed in 6.119700923s

â€¢ [SLOW TEST:8.229 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:28:29.964: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Jan  8 09:28:30.046: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-272738442 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:28:30.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7jptr" for this suite.
Jan  8 09:28:36.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:28:36.183: INFO: namespace: e2e-tests-kubectl-7jptr, resource: bindings, ignored listing per whitelist
Jan  8 09:28:36.230: INFO: namespace e2e-tests-kubectl-7jptr deletion completed in 6.101298657s

â€¢ [SLOW TEST:6.267 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:28:36.231: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Jan  8 09:28:38.319: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-c64bae55-1327-11e9-bc05-0a580af40202,GenerateName:,Namespace:e2e-tests-events-vtskb,SelfLink:/api/v1/namespaces/e2e-tests-events-vtskb/pods/send-events-c64bae55-1327-11e9-bc05-0a580af40202,UID:c64c3429-1327-11e9-a60a-02001701fa35,ResourceVersion:3943,Generation:0,CreationTimestamp:2019-01-08 09:28:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 301172101,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s5bl8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s5bl8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-s5bl8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422423270} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422423290}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:28:36 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:28:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:28:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:28:36 +0000 UTC  }],Message:,Reason:,HostIP:100.100.242.162,PodIP:10.244.1.32,StartTime:2019-01-08 09:28:36 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-01-08 09:28:37 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://b35ca0d687ef8dabad1fc395a1b42d03a609168542b81a5278b7a62f09126ee1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Jan  8 09:28:40.323: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Jan  8 09:28:42.327: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:28:42.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-vtskb" for this suite.
Jan  8 09:29:20.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:29:20.412: INFO: namespace: e2e-tests-events-vtskb, resource: bindings, ignored listing per whitelist
Jan  8 09:29:20.438: INFO: namespace e2e-tests-events-vtskb deletion completed in 38.101452167s

â€¢ [SLOW TEST:44.207 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:29:20.438: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan  8 09:29:20.512: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:29:28.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-57txt" for this suite.
Jan  8 09:29:50.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:29:50.668: INFO: namespace: e2e-tests-init-container-57txt, resource: bindings, ignored listing per whitelist
Jan  8 09:29:50.722: INFO: namespace e2e-tests-init-container-57txt deletion completed in 22.099265815s

â€¢ [SLOW TEST:30.284 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:29:50.722: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  8 09:29:50.842: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"f2b61131-1327-11e9-a60a-02001701fa35", Controller:(*bool)(0xc421c8b642), BlockOwnerDeletion:(*bool)(0xc421c8b643)}}
Jan  8 09:29:50.849: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"f2b422bc-1327-11e9-a60a-02001701fa35", Controller:(*bool)(0xc421c8b9a2), BlockOwnerDeletion:(*bool)(0xc421c8b9a3)}}
Jan  8 09:29:50.854: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"f2b5688d-1327-11e9-a60a-02001701fa35", Controller:(*bool)(0xc4202674ce), BlockOwnerDeletion:(*bool)(0xc4202674cf)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:29:55.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-f7s9w" for this suite.
Jan  8 09:30:01.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:30:01.934: INFO: namespace: e2e-tests-gc-f7s9w, resource: bindings, ignored listing per whitelist
Jan  8 09:30:01.966: INFO: namespace e2e-tests-gc-f7s9w deletion completed in 6.100360562s

â€¢ [SLOW TEST:11.244 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:30:01.966: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  8 09:30:02.054: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Jan  8 09:30:02.060: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-jqtgf/daemonsets","resourceVersion":"4159"},"items":null}

Jan  8 09:30:02.063: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-jqtgf/pods","resourceVersion":"4159"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:30:02.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-jqtgf" for this suite.
Jan  8 09:30:08.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:30:08.171: INFO: namespace: e2e-tests-daemonsets-jqtgf, resource: bindings, ignored listing per whitelist
Jan  8 09:30:08.175: INFO: namespace e2e-tests-daemonsets-jqtgf deletion completed in 6.098991486s

S [SKIPPING] [6.209 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Jan  8 09:30:02.054: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:30:08.176: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jan  8 09:30:08.267: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-n9xw9,SelfLink:/api/v1/namespaces/e2e-tests-watch-n9xw9/configmaps/e2e-watch-test-resource-version,UID:fd196189-1327-11e9-a60a-02001701fa35,ResourceVersion:4180,Generation:0,CreationTimestamp:2019-01-08 09:30:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan  8 09:30:08.267: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-n9xw9,SelfLink:/api/v1/namespaces/e2e-tests-watch-n9xw9/configmaps/e2e-watch-test-resource-version,UID:fd196189-1327-11e9-a60a-02001701fa35,ResourceVersion:4181,Generation:0,CreationTimestamp:2019-01-08 09:30:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:30:08.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-n9xw9" for this suite.
Jan  8 09:30:14.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:30:14.326: INFO: namespace: e2e-tests-watch-n9xw9, resource: bindings, ignored listing per whitelist
Jan  8 09:30:14.379: INFO: namespace e2e-tests-watch-n9xw9 deletion completed in 6.109105115s

â€¢ [SLOW TEST:6.204 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:30:14.380: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Jan  8 09:30:54.491: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:30:54.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-g4xjw" for this suite.
Jan  8 09:31:00.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:31:00.536: INFO: namespace: e2e-tests-gc-g4xjw, resource: bindings, ignored listing per whitelist
Jan  8 09:31:00.595: INFO: namespace e2e-tests-gc-g4xjw deletion completed in 6.100841825s

â€¢ [SLOW TEST:46.216 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:31:00.595: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-1c5907bc-1328-11e9-bc05-0a580af40202
STEP: Creating secret with name secret-projected-all-test-volume-1c5907ac-1328-11e9-bc05-0a580af40202
STEP: Creating a pod to test Check all projections for projected volume plugin
Jan  8 09:31:00.686: INFO: Waiting up to 5m0s for pod "projected-volume-1c590781-1328-11e9-bc05-0a580af40202" in namespace "e2e-tests-projected-6llzn" to be "success or failure"
Jan  8 09:31:00.690: INFO: Pod "projected-volume-1c590781-1328-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.730979ms
Jan  8 09:31:02.694: INFO: Pod "projected-volume-1c590781-1328-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007559269s
STEP: Saw pod success
Jan  8 09:31:02.694: INFO: Pod "projected-volume-1c590781-1328-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:31:02.697: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod projected-volume-1c590781-1328-11e9-bc05-0a580af40202 container projected-all-volume-test: <nil>
STEP: delete the pod
Jan  8 09:31:02.715: INFO: Waiting for pod projected-volume-1c590781-1328-11e9-bc05-0a580af40202 to disappear
Jan  8 09:31:02.717: INFO: Pod projected-volume-1c590781-1328-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:31:02.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6llzn" for this suite.
Jan  8 09:31:08.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:31:08.812: INFO: namespace: e2e-tests-projected-6llzn, resource: bindings, ignored listing per whitelist
Jan  8 09:31:08.822: INFO: namespace e2e-tests-projected-6llzn deletion completed in 6.101273136s

â€¢ [SLOW TEST:8.227 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:31:08.823: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan  8 09:31:08.898: INFO: Waiting up to 5m0s for pod "pod-213f2c3f-1328-11e9-bc05-0a580af40202" in namespace "e2e-tests-emptydir-5kwtr" to be "success or failure"
Jan  8 09:31:08.904: INFO: Pod "pod-213f2c3f-1328-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 6.024219ms
Jan  8 09:31:10.907: INFO: Pod "pod-213f2c3f-1328-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008995674s
STEP: Saw pod success
Jan  8 09:31:10.907: INFO: Pod "pod-213f2c3f-1328-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:31:10.909: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-213f2c3f-1328-11e9-bc05-0a580af40202 container test-container: <nil>
STEP: delete the pod
Jan  8 09:31:10.928: INFO: Waiting for pod pod-213f2c3f-1328-11e9-bc05-0a580af40202 to disappear
Jan  8 09:31:10.932: INFO: Pod pod-213f2c3f-1328-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:31:10.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5kwtr" for this suite.
Jan  8 09:31:16.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:31:17.001: INFO: namespace: e2e-tests-emptydir-5kwtr, resource: bindings, ignored listing per whitelist
Jan  8 09:31:17.037: INFO: namespace e2e-tests-emptydir-5kwtr deletion completed in 6.1009136s

â€¢ [SLOW TEST:8.214 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:31:17.037: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  8 09:31:17.118: INFO: Waiting up to 5m0s for pod "downwardapi-volume-26258630-1328-11e9-bc05-0a580af40202" in namespace "e2e-tests-projected-qk8m7" to be "success or failure"
Jan  8 09:31:17.121: INFO: Pod "downwardapi-volume-26258630-1328-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.818912ms
Jan  8 09:31:19.125: INFO: Pod "downwardapi-volume-26258630-1328-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006357644s
STEP: Saw pod success
Jan  8 09:31:19.125: INFO: Pod "downwardapi-volume-26258630-1328-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:31:19.127: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod downwardapi-volume-26258630-1328-11e9-bc05-0a580af40202 container client-container: <nil>
STEP: delete the pod
Jan  8 09:31:19.144: INFO: Waiting for pod downwardapi-volume-26258630-1328-11e9-bc05-0a580af40202 to disappear
Jan  8 09:31:19.147: INFO: Pod downwardapi-volume-26258630-1328-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:31:19.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qk8m7" for this suite.
Jan  8 09:31:25.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:31:25.181: INFO: namespace: e2e-tests-projected-qk8m7, resource: bindings, ignored listing per whitelist
Jan  8 09:31:25.254: INFO: namespace e2e-tests-projected-qk8m7 deletion completed in 6.103073248s

â€¢ [SLOW TEST:8.217 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:31:25.254: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-2b0c3d09-1328-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume secrets
Jan  8 09:31:25.387: INFO: Waiting up to 5m0s for pod "pod-secrets-2b132be5-1328-11e9-bc05-0a580af40202" in namespace "e2e-tests-secrets-8z5jx" to be "success or failure"
Jan  8 09:31:25.390: INFO: Pod "pod-secrets-2b132be5-1328-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.374714ms
Jan  8 09:31:27.394: INFO: Pod "pod-secrets-2b132be5-1328-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006990015s
STEP: Saw pod success
Jan  8 09:31:27.394: INFO: Pod "pod-secrets-2b132be5-1328-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:31:27.397: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-secrets-2b132be5-1328-11e9-bc05-0a580af40202 container secret-volume-test: <nil>
STEP: delete the pod
Jan  8 09:31:27.418: INFO: Waiting for pod pod-secrets-2b132be5-1328-11e9-bc05-0a580af40202 to disappear
Jan  8 09:31:27.421: INFO: Pod pod-secrets-2b132be5-1328-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:31:27.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8z5jx" for this suite.
Jan  8 09:31:33.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:31:33.524: INFO: namespace: e2e-tests-secrets-8z5jx, resource: bindings, ignored listing per whitelist
Jan  8 09:31:33.524: INFO: namespace e2e-tests-secrets-8z5jx deletion completed in 6.099003307s
STEP: Destroying namespace "e2e-tests-secret-namespace-hwjvw" for this suite.
Jan  8 09:31:39.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:31:39.561: INFO: namespace: e2e-tests-secret-namespace-hwjvw, resource: bindings, ignored listing per whitelist
Jan  8 09:31:39.627: INFO: namespace e2e-tests-secret-namespace-hwjvw deletion completed in 6.103704395s

â€¢ [SLOW TEST:14.374 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:31:39.628: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-nppsl
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nppsl to expose endpoints map[]
Jan  8 09:31:39.724: INFO: Get endpoints failed (4.708599ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Jan  8 09:31:40.728: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nppsl exposes endpoints map[] (1.008178002s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-nppsl
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nppsl to expose endpoints map[pod1:[100]]
Jan  8 09:31:44.767: INFO: Unexpected endpoints: found map[], expected map[pod1:[100]] (4.03231325s elapsed, will retry)
Jan  8 09:31:46.779: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nppsl exposes endpoints map[pod1:[100]] (6.045102899s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-nppsl
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nppsl to expose endpoints map[pod1:[100] pod2:[101]]
Jan  8 09:31:48.811: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nppsl exposes endpoints map[pod1:[100] pod2:[101]] (2.027140182s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-nppsl
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nppsl to expose endpoints map[pod2:[101]]
Jan  8 09:31:48.825: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nppsl exposes endpoints map[pod2:[101]] (8.779122ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-nppsl
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nppsl to expose endpoints map[]
Jan  8 09:31:49.836: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nppsl exposes endpoints map[] (1.006087946s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:31:49.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-nppsl" for this suite.
Jan  8 09:32:11.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:32:11.924: INFO: namespace: e2e-tests-services-nppsl, resource: bindings, ignored listing per whitelist
Jan  8 09:32:11.978: INFO: namespace e2e-tests-services-nppsl deletion completed in 22.110868235s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

â€¢ [SLOW TEST:32.351 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:32:11.979: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  8 09:32:12.068: INFO: Waiting up to 5m0s for pod "downwardapi-volume-46e6120c-1328-11e9-bc05-0a580af40202" in namespace "e2e-tests-downward-api-67rhz" to be "success or failure"
Jan  8 09:32:12.071: INFO: Pod "downwardapi-volume-46e6120c-1328-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.935021ms
Jan  8 09:32:14.075: INFO: Pod "downwardapi-volume-46e6120c-1328-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007049902s
STEP: Saw pod success
Jan  8 09:32:14.075: INFO: Pod "downwardapi-volume-46e6120c-1328-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:32:14.078: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod downwardapi-volume-46e6120c-1328-11e9-bc05-0a580af40202 container client-container: <nil>
STEP: delete the pod
Jan  8 09:32:14.095: INFO: Waiting for pod downwardapi-volume-46e6120c-1328-11e9-bc05-0a580af40202 to disappear
Jan  8 09:32:14.097: INFO: Pod downwardapi-volume-46e6120c-1328-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:32:14.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-67rhz" for this suite.
Jan  8 09:32:20.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:32:20.129: INFO: namespace: e2e-tests-downward-api-67rhz, resource: bindings, ignored listing per whitelist
Jan  8 09:32:20.199: INFO: namespace e2e-tests-downward-api-67rhz deletion completed in 6.098075701s

â€¢ [SLOW TEST:8.220 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:32:20.199: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:32:20.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-nz29c" for this suite.
Jan  8 09:32:42.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:32:42.351: INFO: namespace: e2e-tests-pods-nz29c, resource: bindings, ignored listing per whitelist
Jan  8 09:32:42.388: INFO: namespace e2e-tests-pods-nz29c deletion completed in 22.102716349s

â€¢ [SLOW TEST:22.188 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:32:42.388: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan  8 09:32:42.469: INFO: Waiting up to 5m0s for pod "downward-api-59050b5e-1328-11e9-bc05-0a580af40202" in namespace "e2e-tests-downward-api-mbmtm" to be "success or failure"
Jan  8 09:32:42.472: INFO: Pod "downward-api-59050b5e-1328-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.92185ms
Jan  8 09:32:44.476: INFO: Pod "downward-api-59050b5e-1328-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007032524s
STEP: Saw pod success
Jan  8 09:32:44.476: INFO: Pod "downward-api-59050b5e-1328-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:32:44.479: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod downward-api-59050b5e-1328-11e9-bc05-0a580af40202 container dapi-container: <nil>
STEP: delete the pod
Jan  8 09:32:44.498: INFO: Waiting for pod downward-api-59050b5e-1328-11e9-bc05-0a580af40202 to disappear
Jan  8 09:32:44.500: INFO: Pod downward-api-59050b5e-1328-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:32:44.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mbmtm" for this suite.
Jan  8 09:32:50.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:32:50.556: INFO: namespace: e2e-tests-downward-api-mbmtm, resource: bindings, ignored listing per whitelist
Jan  8 09:32:50.604: INFO: namespace e2e-tests-downward-api-mbmtm deletion completed in 6.100408438s

â€¢ [SLOW TEST:8.217 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:32:50.605: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan  8 09:32:50.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-dlh54'
Jan  8 09:32:50.905: INFO: stderr: ""
Jan  8 09:32:50.905: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Jan  8 09:32:50.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-dlh54'
Jan  8 09:32:57.436: INFO: stderr: ""
Jan  8 09:32:57.436: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:32:57.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dlh54" for this suite.
Jan  8 09:33:03.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:33:03.524: INFO: namespace: e2e-tests-kubectl-dlh54, resource: bindings, ignored listing per whitelist
Jan  8 09:33:03.541: INFO: namespace e2e-tests-kubectl-dlh54 deletion completed in 6.101244295s

â€¢ [SLOW TEST:12.936 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:33:03.542: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-ncg59
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-ncg59
STEP: Deleting pre-stop pod
Jan  8 09:33:18.655: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:33:18.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-ncg59" for this suite.
Jan  8 09:34:04.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:34:04.749: INFO: namespace: e2e-tests-prestop-ncg59, resource: bindings, ignored listing per whitelist
Jan  8 09:34:04.765: INFO: namespace e2e-tests-prestop-ncg59 deletion completed in 46.099350297s

â€¢ [SLOW TEST:61.223 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:34:04.765: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  8 09:34:04.846: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8a1ec602-1328-11e9-bc05-0a580af40202" in namespace "e2e-tests-downward-api-9khgg" to be "success or failure"
Jan  8 09:34:04.850: INFO: Pod "downwardapi-volume-8a1ec602-1328-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.691493ms
Jan  8 09:34:06.853: INFO: Pod "downwardapi-volume-8a1ec602-1328-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00709015s
STEP: Saw pod success
Jan  8 09:34:06.853: INFO: Pod "downwardapi-volume-8a1ec602-1328-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:34:06.856: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod downwardapi-volume-8a1ec602-1328-11e9-bc05-0a580af40202 container client-container: <nil>
STEP: delete the pod
Jan  8 09:34:06.872: INFO: Waiting for pod downwardapi-volume-8a1ec602-1328-11e9-bc05-0a580af40202 to disappear
Jan  8 09:34:06.875: INFO: Pod downwardapi-volume-8a1ec602-1328-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:34:06.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9khgg" for this suite.
Jan  8 09:34:12.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:34:12.946: INFO: namespace: e2e-tests-downward-api-9khgg, resource: bindings, ignored listing per whitelist
Jan  8 09:34:12.977: INFO: namespace e2e-tests-downward-api-9khgg deletion completed in 6.09802275s

â€¢ [SLOW TEST:8.212 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:34:12.977: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-8f04f1c8-1328-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume secrets
Jan  8 09:34:13.070: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8f057cfc-1328-11e9-bc05-0a580af40202" in namespace "e2e-tests-projected-68hlj" to be "success or failure"
Jan  8 09:34:13.074: INFO: Pod "pod-projected-secrets-8f057cfc-1328-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.52677ms
Jan  8 09:34:15.078: INFO: Pod "pod-projected-secrets-8f057cfc-1328-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008181266s
STEP: Saw pod success
Jan  8 09:34:15.078: INFO: Pod "pod-projected-secrets-8f057cfc-1328-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:34:15.080: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-projected-secrets-8f057cfc-1328-11e9-bc05-0a580af40202 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan  8 09:34:15.098: INFO: Waiting for pod pod-projected-secrets-8f057cfc-1328-11e9-bc05-0a580af40202 to disappear
Jan  8 09:34:15.101: INFO: Pod pod-projected-secrets-8f057cfc-1328-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:34:15.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-68hlj" for this suite.
Jan  8 09:34:21.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:34:21.171: INFO: namespace: e2e-tests-projected-68hlj, resource: bindings, ignored listing per whitelist
Jan  8 09:34:21.205: INFO: namespace e2e-tests-projected-68hlj deletion completed in 6.100044822s

â€¢ [SLOW TEST:8.228 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:34:21.205: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-xxmz6
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Jan  8 09:34:21.298: INFO: Found 0 stateful pods, waiting for 3
Jan  8 09:34:31.303: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan  8 09:34:31.303: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan  8 09:34:31.303: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jan  8 09:34:31.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 exec --namespace=e2e-tests-statefulset-xxmz6 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  8 09:34:31.496: INFO: stderr: ""
Jan  8 09:34:31.496: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  8 09:34:31.496: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan  8 09:34:41.527: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jan  8 09:34:51.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 exec --namespace=e2e-tests-statefulset-xxmz6 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  8 09:34:51.727: INFO: stderr: ""
Jan  8 09:34:51.727: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  8 09:34:51.727: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  8 09:35:01.748: INFO: Waiting for StatefulSet e2e-tests-statefulset-xxmz6/ss2 to complete update
Jan  8 09:35:01.748: INFO: Waiting for Pod e2e-tests-statefulset-xxmz6/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan  8 09:35:01.748: INFO: Waiting for Pod e2e-tests-statefulset-xxmz6/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan  8 09:35:01.748: INFO: Waiting for Pod e2e-tests-statefulset-xxmz6/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan  8 09:35:11.755: INFO: Waiting for StatefulSet e2e-tests-statefulset-xxmz6/ss2 to complete update
Jan  8 09:35:11.755: INFO: Waiting for Pod e2e-tests-statefulset-xxmz6/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan  8 09:35:11.755: INFO: Waiting for Pod e2e-tests-statefulset-xxmz6/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan  8 09:35:21.755: INFO: Waiting for StatefulSet e2e-tests-statefulset-xxmz6/ss2 to complete update
Jan  8 09:35:21.755: INFO: Waiting for Pod e2e-tests-statefulset-xxmz6/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Jan  8 09:35:31.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 exec --namespace=e2e-tests-statefulset-xxmz6 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  8 09:35:31.941: INFO: stderr: ""
Jan  8 09:35:31.941: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  8 09:35:31.941: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  8 09:35:41.974: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jan  8 09:35:51.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 exec --namespace=e2e-tests-statefulset-xxmz6 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  8 09:35:52.174: INFO: stderr: ""
Jan  8 09:35:52.174: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  8 09:35:52.174: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  8 09:36:12.194: INFO: Waiting for StatefulSet e2e-tests-statefulset-xxmz6/ss2 to complete update
Jan  8 09:36:12.194: INFO: Waiting for Pod e2e-tests-statefulset-xxmz6/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan  8 09:36:22.201: INFO: Deleting all statefulset in ns e2e-tests-statefulset-xxmz6
Jan  8 09:36:22.204: INFO: Scaling statefulset ss2 to 0
Jan  8 09:36:42.218: INFO: Waiting for statefulset status.replicas updated to 0
Jan  8 09:36:42.221: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:36:42.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-xxmz6" for this suite.
Jan  8 09:36:48.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:36:48.320: INFO: namespace: e2e-tests-statefulset-xxmz6, resource: bindings, ignored listing per whitelist
Jan  8 09:36:48.364: INFO: namespace e2e-tests-statefulset-xxmz6 deletion completed in 6.126504687s

â€¢ [SLOW TEST:147.160 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:36:48.365: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  8 09:36:50.473: INFO: Waiting up to 5m0s for pod "client-envvars-ecd791bf-1328-11e9-bc05-0a580af40202" in namespace "e2e-tests-pods-h9zsr" to be "success or failure"
Jan  8 09:36:50.477: INFO: Pod "client-envvars-ecd791bf-1328-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.634049ms
Jan  8 09:36:52.481: INFO: Pod "client-envvars-ecd791bf-1328-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00809882s
STEP: Saw pod success
Jan  8 09:36:52.481: INFO: Pod "client-envvars-ecd791bf-1328-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:36:52.483: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod client-envvars-ecd791bf-1328-11e9-bc05-0a580af40202 container env3cont: <nil>
STEP: delete the pod
Jan  8 09:36:52.502: INFO: Waiting for pod client-envvars-ecd791bf-1328-11e9-bc05-0a580af40202 to disappear
Jan  8 09:36:52.505: INFO: Pod client-envvars-ecd791bf-1328-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:36:52.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-h9zsr" for this suite.
Jan  8 09:37:30.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:37:30.538: INFO: namespace: e2e-tests-pods-h9zsr, resource: bindings, ignored listing per whitelist
Jan  8 09:37:30.611: INFO: namespace e2e-tests-pods-h9zsr deletion completed in 38.102151251s

â€¢ [SLOW TEST:42.247 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:37:30.612: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan  8 09:37:30.693: INFO: Waiting up to 5m0s for pod "pod-04d089bf-1329-11e9-bc05-0a580af40202" in namespace "e2e-tests-emptydir-5pkgv" to be "success or failure"
Jan  8 09:37:30.696: INFO: Pod "pod-04d089bf-1329-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.064896ms
Jan  8 09:37:32.700: INFO: Pod "pod-04d089bf-1329-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006985725s
STEP: Saw pod success
Jan  8 09:37:32.700: INFO: Pod "pod-04d089bf-1329-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:37:32.702: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-04d089bf-1329-11e9-bc05-0a580af40202 container test-container: <nil>
STEP: delete the pod
Jan  8 09:37:32.723: INFO: Waiting for pod pod-04d089bf-1329-11e9-bc05-0a580af40202 to disappear
Jan  8 09:37:32.727: INFO: Pod pod-04d089bf-1329-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:37:32.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5pkgv" for this suite.
Jan  8 09:37:38.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:37:38.761: INFO: namespace: e2e-tests-emptydir-5pkgv, resource: bindings, ignored listing per whitelist
Jan  8 09:37:38.833: INFO: namespace e2e-tests-emptydir-5pkgv deletion completed in 6.103063277s

â€¢ [SLOW TEST:8.222 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:37:38.834: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jan  8 09:37:38.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 create -f - --namespace=e2e-tests-kubectl-6lrjs'
Jan  8 09:37:39.075: INFO: stderr: ""
Jan  8 09:37:39.075: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan  8 09:37:40.079: INFO: Selector matched 1 pods for map[app:redis]
Jan  8 09:37:40.079: INFO: Found 1 / 1
Jan  8 09:37:40.079: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jan  8 09:37:40.082: INFO: Selector matched 1 pods for map[app:redis]
Jan  8 09:37:40.082: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan  8 09:37:40.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 patch pod redis-master-dpwsl --namespace=e2e-tests-kubectl-6lrjs -p {"metadata":{"annotations":{"x":"y"}}}'
Jan  8 09:37:40.175: INFO: stderr: ""
Jan  8 09:37:40.175: INFO: stdout: "pod/redis-master-dpwsl patched\n"
STEP: checking annotations
Jan  8 09:37:40.178: INFO: Selector matched 1 pods for map[app:redis]
Jan  8 09:37:40.178: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:37:40.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6lrjs" for this suite.
Jan  8 09:38:02.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:38:02.222: INFO: namespace: e2e-tests-kubectl-6lrjs, resource: bindings, ignored listing per whitelist
Jan  8 09:38:02.283: INFO: namespace e2e-tests-kubectl-6lrjs deletion completed in 22.10180573s

â€¢ [SLOW TEST:23.449 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:38:02.283: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  8 09:38:02.366: INFO: Waiting up to 5m0s for pod "downwardapi-volume-17b15c22-1329-11e9-bc05-0a580af40202" in namespace "e2e-tests-downward-api-cjxv6" to be "success or failure"
Jan  8 09:38:02.370: INFO: Pod "downwardapi-volume-17b15c22-1329-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.686495ms
Jan  8 09:38:04.374: INFO: Pod "downwardapi-volume-17b15c22-1329-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007559714s
STEP: Saw pod success
Jan  8 09:38:04.374: INFO: Pod "downwardapi-volume-17b15c22-1329-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:38:04.376: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod downwardapi-volume-17b15c22-1329-11e9-bc05-0a580af40202 container client-container: <nil>
STEP: delete the pod
Jan  8 09:38:04.394: INFO: Waiting for pod downwardapi-volume-17b15c22-1329-11e9-bc05-0a580af40202 to disappear
Jan  8 09:38:04.398: INFO: Pod downwardapi-volume-17b15c22-1329-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:38:04.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cjxv6" for this suite.
Jan  8 09:38:10.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:38:10.448: INFO: namespace: e2e-tests-downward-api-cjxv6, resource: bindings, ignored listing per whitelist
Jan  8 09:38:10.502: INFO: namespace e2e-tests-downward-api-cjxv6 deletion completed in 6.100820927s

â€¢ [SLOW TEST:8.219 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:38:10.502: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Jan  8 09:38:11.664: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:38:11.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-v8fcr" for this suite.
Jan  8 09:38:17.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:38:17.714: INFO: namespace: e2e-tests-gc-v8fcr, resource: bindings, ignored listing per whitelist
Jan  8 09:38:17.768: INFO: namespace e2e-tests-gc-v8fcr deletion completed in 6.100268685s

â€¢ [SLOW TEST:7.266 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:38:17.768: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  8 09:38:17.851: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jan  8 09:38:22.855: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan  8 09:38:22.855: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan  8 09:38:22.873: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-rdhmt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rdhmt/deployments/test-cleanup-deployment,UID:23e98893-1329-11e9-a60a-02001701fa35,ResourceVersion:5958,Generation:1,CreationTimestamp:2019-01-08 09:38:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Jan  8 09:38:22.878: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Jan  8 09:38:22.878: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Jan  8 09:38:22.878: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-rdhmt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rdhmt/replicasets/test-cleanup-controller,UID:20ec5d12-1329-11e9-a60a-02001701fa35,ResourceVersion:5959,Generation:1,CreationTimestamp:2019-01-08 09:38:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 23e98893-1329-11e9-a60a-02001701fa35 0xc421f257bf 0xc421f257d0}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan  8 09:38:22.881: INFO: Pod "test-cleanup-controller-s9mpt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-s9mpt,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-rdhmt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rdhmt/pods/test-cleanup-controller-s9mpt,UID:20edb962-1329-11e9-a60a-02001701fa35,ResourceVersion:5952,Generation:0,CreationTimestamp:2019-01-08 09:38:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 20ec5d12-1329-11e9-a60a-02001701fa35 0xc421f25cff 0xc421f25d10}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j28qp {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j28qp,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j28qp true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f25d70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f25d90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:38:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:38:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:38:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:38:17 +0000 UTC  }],Message:,Reason:,HostIP:100.100.242.163,PodIP:10.244.2.52,StartTime:2019-01-08 09:38:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-08 09:38:18 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://277b8a25df2a1e9bdd5856d41cf9d0fc091423b2a0e06c444a60aab816369014}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:38:22.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-rdhmt" for this suite.
Jan  8 09:38:28.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:38:28.939: INFO: namespace: e2e-tests-deployment-rdhmt, resource: bindings, ignored listing per whitelist
Jan  8 09:38:28.991: INFO: namespace e2e-tests-deployment-rdhmt deletion completed in 6.105186405s

â€¢ [SLOW TEST:11.223 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:38:28.992: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Jan  8 09:38:29.073: INFO: Waiting up to 5m0s for pod "client-containers-279c63be-1329-11e9-bc05-0a580af40202" in namespace "e2e-tests-containers-gldhc" to be "success or failure"
Jan  8 09:38:29.076: INFO: Pod "client-containers-279c63be-1329-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.126423ms
Jan  8 09:38:31.080: INFO: Pod "client-containers-279c63be-1329-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006700932s
Jan  8 09:38:33.083: INFO: Pod "client-containers-279c63be-1329-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010289236s
Jan  8 09:38:35.087: INFO: Pod "client-containers-279c63be-1329-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014227788s
STEP: Saw pod success
Jan  8 09:38:35.087: INFO: Pod "client-containers-279c63be-1329-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:38:35.090: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod client-containers-279c63be-1329-11e9-bc05-0a580af40202 container test-container: <nil>
STEP: delete the pod
Jan  8 09:38:35.108: INFO: Waiting for pod client-containers-279c63be-1329-11e9-bc05-0a580af40202 to disappear
Jan  8 09:38:35.110: INFO: Pod client-containers-279c63be-1329-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:38:35.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-gldhc" for this suite.
Jan  8 09:38:41.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:38:41.141: INFO: namespace: e2e-tests-containers-gldhc, resource: bindings, ignored listing per whitelist
Jan  8 09:38:41.216: INFO: namespace e2e-tests-containers-gldhc deletion completed in 6.101988713s

â€¢ [SLOW TEST:12.224 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:38:41.216: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Jan  8 09:38:41.812: INFO: created pod pod-service-account-defaultsa
Jan  8 09:38:41.812: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jan  8 09:38:41.816: INFO: created pod pod-service-account-mountsa
Jan  8 09:38:41.816: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jan  8 09:38:41.824: INFO: created pod pod-service-account-nomountsa
Jan  8 09:38:41.824: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jan  8 09:38:41.837: INFO: created pod pod-service-account-defaultsa-mountspec
Jan  8 09:38:41.837: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jan  8 09:38:41.843: INFO: created pod pod-service-account-mountsa-mountspec
Jan  8 09:38:41.843: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jan  8 09:38:41.868: INFO: created pod pod-service-account-nomountsa-mountspec
Jan  8 09:38:41.868: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jan  8 09:38:41.879: INFO: created pod pod-service-account-defaultsa-nomountspec
Jan  8 09:38:41.879: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jan  8 09:38:41.888: INFO: created pod pod-service-account-mountsa-nomountspec
Jan  8 09:38:41.888: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jan  8 09:38:41.895: INFO: created pod pod-service-account-nomountsa-nomountspec
Jan  8 09:38:41.896: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:38:41.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-mtnjn" for this suite.
Jan  8 09:38:47.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:38:47.951: INFO: namespace: e2e-tests-svcaccounts-mtnjn, resource: bindings, ignored listing per whitelist
Jan  8 09:38:48.013: INFO: namespace e2e-tests-svcaccounts-mtnjn deletion completed in 6.108877149s

â€¢ [SLOW TEST:6.797 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:38:48.013: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan  8 09:38:50.620: INFO: Successfully updated pod "labelsupdate32f28cc4-1329-11e9-bc05-0a580af40202"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:38:54.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pzzvj" for this suite.
Jan  8 09:39:16.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:39:16.716: INFO: namespace: e2e-tests-downward-api-pzzvj, resource: bindings, ignored listing per whitelist
Jan  8 09:39:16.749: INFO: namespace e2e-tests-downward-api-pzzvj deletion completed in 22.100302966s

â€¢ [SLOW TEST:28.736 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:39:16.750: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan  8 09:39:24.864: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan  8 09:39:24.867: INFO: Pod pod-with-prestop-http-hook still exists
Jan  8 09:39:26.867: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan  8 09:39:26.871: INFO: Pod pod-with-prestop-http-hook still exists
Jan  8 09:39:28.867: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan  8 09:39:28.871: INFO: Pod pod-with-prestop-http-hook still exists
Jan  8 09:39:30.867: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan  8 09:39:30.871: INFO: Pod pod-with-prestop-http-hook still exists
Jan  8 09:39:32.867: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan  8 09:39:32.871: INFO: Pod pod-with-prestop-http-hook still exists
Jan  8 09:39:34.867: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan  8 09:39:34.872: INFO: Pod pod-with-prestop-http-hook still exists
Jan  8 09:39:36.867: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan  8 09:39:36.871: INFO: Pod pod-with-prestop-http-hook still exists
Jan  8 09:39:38.867: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan  8 09:39:38.871: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:39:38.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-kwwsx" for this suite.
Jan  8 09:40:00.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:40:00.945: INFO: namespace: e2e-tests-container-lifecycle-hook-kwwsx, resource: bindings, ignored listing per whitelist
Jan  8 09:40:00.982: INFO: namespace e2e-tests-container-lifecycle-hook-kwwsx deletion completed in 22.099673044s

â€¢ [SLOW TEST:44.233 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:40:00.983: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-5e717696-1329-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume secrets
Jan  8 09:40:01.069: INFO: Waiting up to 5m0s for pod "pod-secrets-5e7213f7-1329-11e9-bc05-0a580af40202" in namespace "e2e-tests-secrets-4kzlb" to be "success or failure"
Jan  8 09:40:01.072: INFO: Pod "pod-secrets-5e7213f7-1329-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.804346ms
Jan  8 09:40:03.075: INFO: Pod "pod-secrets-5e7213f7-1329-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006072597s
STEP: Saw pod success
Jan  8 09:40:03.075: INFO: Pod "pod-secrets-5e7213f7-1329-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:40:03.078: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod pod-secrets-5e7213f7-1329-11e9-bc05-0a580af40202 container secret-volume-test: <nil>
STEP: delete the pod
Jan  8 09:40:03.094: INFO: Waiting for pod pod-secrets-5e7213f7-1329-11e9-bc05-0a580af40202 to disappear
Jan  8 09:40:03.096: INFO: Pod pod-secrets-5e7213f7-1329-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:40:03.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4kzlb" for this suite.
Jan  8 09:40:09.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:40:09.170: INFO: namespace: e2e-tests-secrets-4kzlb, resource: bindings, ignored listing per whitelist
Jan  8 09:40:09.198: INFO: namespace e2e-tests-secrets-4kzlb deletion completed in 6.098225771s

â€¢ [SLOW TEST:8.215 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:40:09.198: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Jan  8 09:40:09.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 --namespace=e2e-tests-kubectl-2tst6 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Jan  8 09:40:11.315: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Jan  8 09:40:11.315: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:40:13.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2tst6" for this suite.
Jan  8 09:40:19.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:40:19.415: INFO: namespace: e2e-tests-kubectl-2tst6, resource: bindings, ignored listing per whitelist
Jan  8 09:40:19.425: INFO: namespace e2e-tests-kubectl-2tst6 deletion completed in 6.100408176s

â€¢ [SLOW TEST:10.227 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:40:19.426: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-55fhn
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-55fhn
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-55fhn
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-55fhn
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-55fhn
Jan  8 09:40:21.545: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-55fhn, name: ss-0, uid: 6980da41-1329-11e9-a60a-02001701fa35, status phase: Pending. Waiting for statefulset controller to delete.
Jan  8 09:40:27.424: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-55fhn, name: ss-0, uid: 6980da41-1329-11e9-a60a-02001701fa35, status phase: Failed. Waiting for statefulset controller to delete.
Jan  8 09:40:27.431: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-55fhn, name: ss-0, uid: 6980da41-1329-11e9-a60a-02001701fa35, status phase: Failed. Waiting for statefulset controller to delete.
Jan  8 09:40:27.436: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-55fhn
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-55fhn
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-55fhn and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan  8 09:40:29.465: INFO: Deleting all statefulset in ns e2e-tests-statefulset-55fhn
Jan  8 09:40:29.468: INFO: Scaling statefulset ss to 0
Jan  8 09:40:39.486: INFO: Waiting for statefulset status.replicas updated to 0
Jan  8 09:40:39.489: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:40:39.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-55fhn" for this suite.
Jan  8 09:40:45.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:40:45.543: INFO: namespace: e2e-tests-statefulset-55fhn, resource: bindings, ignored listing per whitelist
Jan  8 09:40:45.603: INFO: namespace e2e-tests-statefulset-55fhn deletion completed in 6.098254912s

â€¢ [SLOW TEST:26.178 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:40:45.603: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-t7dhg in namespace e2e-tests-proxy-xjsms
I0108 09:40:45.708167      16 runners.go:180] Created replication controller with name: proxy-service-t7dhg, namespace: e2e-tests-proxy-xjsms, replica count: 1
I0108 09:40:46.758586      16 runners.go:180] proxy-service-t7dhg Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0108 09:40:47.759060      16 runners.go:180] proxy-service-t7dhg Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0108 09:40:48.759278      16 runners.go:180] proxy-service-t7dhg Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0108 09:40:49.759497      16 runners.go:180] proxy-service-t7dhg Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0108 09:40:50.759733      16 runners.go:180] proxy-service-t7dhg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0108 09:40:51.759918      16 runners.go:180] proxy-service-t7dhg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0108 09:40:52.760207      16 runners.go:180] proxy-service-t7dhg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0108 09:40:53.760560      16 runners.go:180] proxy-service-t7dhg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0108 09:40:54.760883      16 runners.go:180] proxy-service-t7dhg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0108 09:40:55.761095      16 runners.go:180] proxy-service-t7dhg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0108 09:40:56.761467      16 runners.go:180] proxy-service-t7dhg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0108 09:40:57.761714      16 runners.go:180] proxy-service-t7dhg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0108 09:40:58.761930      16 runners.go:180] proxy-service-t7dhg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0108 09:40:59.762196      16 runners.go:180] proxy-service-t7dhg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0108 09:41:00.762417      16 runners.go:180] proxy-service-t7dhg Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan  8 09:41:00.765: INFO: setup took 15.085799708s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jan  8 09:41:00.777: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 11.906789ms)
Jan  8 09:41:00.777: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/... (200; 11.914007ms)
Jan  8 09:41:00.778: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/rewri... (200; 12.674004ms)
Jan  8 09:41:00.778: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 12.49467ms)
Jan  8 09:41:00.778: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/rewriteme"... (200; 12.736587ms)
Jan  8 09:41:00.778: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 12.595048ms)
Jan  8 09:41:00.780: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname2/proxy/: bar (200; 14.982041ms)
Jan  8 09:41:00.781: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 15.285823ms)
Jan  8 09:41:00.783: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname2/proxy/: bar (200; 17.37949ms)
Jan  8 09:41:00.783: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname1/proxy/: foo (200; 17.521027ms)
Jan  8 09:41:00.783: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname1/proxy/: foo (200; 17.660941ms)
Jan  8 09:41:00.784: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:462/proxy/: tls qux (200; 18.734921ms)
Jan  8 09:41:00.786: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/... (200; 20.145833ms)
Jan  8 09:41:00.789: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname1/proxy/: tls baz (200; 24.00098ms)
Jan  8 09:41:00.790: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname2/proxy/: tls qux (200; 24.87768ms)
Jan  8 09:41:00.791: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:460/proxy/: tls baz (200; 26.220301ms)
Jan  8 09:41:00.796: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 4.885678ms)
Jan  8 09:41:00.803: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 11.247869ms)
Jan  8 09:41:00.803: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:462/proxy/: tls qux (200; 11.357107ms)
Jan  8 09:41:00.803: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/... (200; 11.441994ms)
Jan  8 09:41:00.803: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/rewriteme"... (200; 11.652ms)
Jan  8 09:41:00.804: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname1/proxy/: tls baz (200; 11.967265ms)
Jan  8 09:41:00.805: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname2/proxy/: bar (200; 12.91464ms)
Jan  8 09:41:00.805: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname2/proxy/: tls qux (200; 13.170671ms)
Jan  8 09:41:00.805: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 13.223629ms)
Jan  8 09:41:00.805: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:460/proxy/: tls baz (200; 13.157699ms)
Jan  8 09:41:00.806: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname2/proxy/: bar (200; 14.076583ms)
Jan  8 09:41:00.806: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname1/proxy/: foo (200; 14.171633ms)
Jan  8 09:41:00.806: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/rewri... (200; 14.139113ms)
Jan  8 09:41:00.806: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname1/proxy/: foo (200; 14.123102ms)
Jan  8 09:41:00.806: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 14.229284ms)
Jan  8 09:41:00.807: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/... (200; 15.582441ms)
Jan  8 09:41:00.815: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/rewri... (200; 7.234508ms)
Jan  8 09:41:00.818: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/rewriteme"... (200; 10.428943ms)
Jan  8 09:41:00.818: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 10.202705ms)
Jan  8 09:41:00.818: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 11.112003ms)
Jan  8 09:41:00.819: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname1/proxy/: foo (200; 11.66242ms)
Jan  8 09:41:00.820: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/... (200; 11.967876ms)
Jan  8 09:41:00.820: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:460/proxy/: tls baz (200; 12.547158ms)
Jan  8 09:41:00.820: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname1/proxy/: tls baz (200; 12.226779ms)
Jan  8 09:41:00.821: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 12.678487ms)
Jan  8 09:41:00.821: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:462/proxy/: tls qux (200; 13.990738ms)
Jan  8 09:41:00.821: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname2/proxy/: bar (200; 13.464173ms)
Jan  8 09:41:00.822: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 14.379377ms)
Jan  8 09:41:00.822: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname2/proxy/: tls qux (200; 14.300573ms)
Jan  8 09:41:00.822: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/... (200; 14.402309ms)
Jan  8 09:41:00.822: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname1/proxy/: foo (200; 13.995554ms)
Jan  8 09:41:00.822: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname2/proxy/: bar (200; 14.11853ms)
Jan  8 09:41:00.832: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:460/proxy/: tls baz (200; 9.547667ms)
Jan  8 09:41:00.833: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/rewriteme"... (200; 10.909174ms)
Jan  8 09:41:00.833: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 10.883554ms)
Jan  8 09:41:00.833: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 11.070923ms)
Jan  8 09:41:00.833: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/... (200; 10.912046ms)
Jan  8 09:41:00.835: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 12.899302ms)
Jan  8 09:41:00.835: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/... (200; 13.23568ms)
Jan  8 09:41:00.836: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 13.400647ms)
Jan  8 09:41:00.836: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/rewri... (200; 13.682462ms)
Jan  8 09:41:00.836: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname2/proxy/: bar (200; 14.138853ms)
Jan  8 09:41:00.836: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname1/proxy/: foo (200; 14.192999ms)
Jan  8 09:41:00.837: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname1/proxy/: foo (200; 14.605529ms)
Jan  8 09:41:00.837: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:462/proxy/: tls qux (200; 14.947809ms)
Jan  8 09:41:00.837: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname1/proxy/: tls baz (200; 14.650341ms)
Jan  8 09:41:00.837: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname2/proxy/: tls qux (200; 14.973819ms)
Jan  8 09:41:00.837: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname2/proxy/: bar (200; 14.685297ms)
Jan  8 09:41:00.841: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:460/proxy/: tls baz (200; 4.026037ms)
Jan  8 09:41:00.843: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 5.369917ms)
Jan  8 09:41:00.843: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 5.397436ms)
Jan  8 09:41:00.848: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/rewri... (200; 10.717355ms)
Jan  8 09:41:00.848: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/... (200; 10.883427ms)
Jan  8 09:41:00.848: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 10.785702ms)
Jan  8 09:41:00.849: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 11.501715ms)
Jan  8 09:41:00.849: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/rewriteme"... (200; 11.296095ms)
Jan  8 09:41:00.852: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname1/proxy/: foo (200; 14.415141ms)
Jan  8 09:41:00.852: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname2/proxy/: bar (200; 14.55392ms)
Jan  8 09:41:00.853: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname2/proxy/: bar (200; 15.549304ms)
Jan  8 09:41:00.853: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname1/proxy/: tls baz (200; 15.511278ms)
Jan  8 09:41:00.853: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname1/proxy/: foo (200; 15.801452ms)
Jan  8 09:41:00.854: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/... (200; 16.043298ms)
Jan  8 09:41:00.854: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:462/proxy/: tls qux (200; 16.508293ms)
Jan  8 09:41:00.854: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname2/proxy/: tls qux (200; 16.332437ms)
Jan  8 09:41:00.858: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:460/proxy/: tls baz (200; 3.771266ms)
Jan  8 09:41:00.859: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/rewri... (200; 4.753146ms)
Jan  8 09:41:00.865: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/rewriteme"... (200; 10.441659ms)
Jan  8 09:41:00.865: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 10.475057ms)
Jan  8 09:41:00.865: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 10.356277ms)
Jan  8 09:41:00.865: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/... (200; 10.53605ms)
Jan  8 09:41:00.865: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 11.026117ms)
Jan  8 09:41:00.865: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:462/proxy/: tls qux (200; 10.819133ms)
Jan  8 09:41:00.865: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/... (200; 10.914202ms)
Jan  8 09:41:00.866: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 11.634052ms)
Jan  8 09:41:00.870: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname2/proxy/: tls qux (200; 15.877517ms)
Jan  8 09:41:00.870: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname1/proxy/: tls baz (200; 16.231476ms)
Jan  8 09:41:00.870: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname2/proxy/: bar (200; 16.022355ms)
Jan  8 09:41:00.870: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname2/proxy/: bar (200; 16.12854ms)
Jan  8 09:41:00.871: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname1/proxy/: foo (200; 16.527094ms)
Jan  8 09:41:00.871: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname1/proxy/: foo (200; 17.005633ms)
Jan  8 09:41:00.885: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname1/proxy/: foo (200; 13.455494ms)
Jan  8 09:41:00.885: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:462/proxy/: tls qux (200; 13.51491ms)
Jan  8 09:41:00.885: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 13.900102ms)
Jan  8 09:41:00.885: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 13.869762ms)
Jan  8 09:41:00.886: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:460/proxy/: tls baz (200; 14.287737ms)
Jan  8 09:41:00.886: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 14.72095ms)
Jan  8 09:41:00.887: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname1/proxy/: foo (200; 15.009486ms)
Jan  8 09:41:00.887: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 15.440593ms)
Jan  8 09:41:00.887: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/rewri... (200; 15.428708ms)
Jan  8 09:41:00.887: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname2/proxy/: bar (200; 15.532905ms)
Jan  8 09:41:00.888: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname1/proxy/: tls baz (200; 16.099807ms)
Jan  8 09:41:00.888: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/... (200; 15.979915ms)
Jan  8 09:41:00.888: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname2/proxy/: tls qux (200; 16.174531ms)
Jan  8 09:41:00.888: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/rewriteme"... (200; 16.924846ms)
Jan  8 09:41:00.888: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname2/proxy/: bar (200; 16.828574ms)
Jan  8 09:41:00.889: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/... (200; 17.076061ms)
Jan  8 09:41:00.899: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 9.749347ms)
Jan  8 09:41:00.899: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:460/proxy/: tls baz (200; 10.456582ms)
Jan  8 09:41:00.900: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 10.798874ms)
Jan  8 09:41:00.900: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 10.892615ms)
Jan  8 09:41:00.901: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/... (200; 11.486957ms)
Jan  8 09:41:00.901: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 11.56158ms)
Jan  8 09:41:00.901: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:462/proxy/: tls qux (200; 12.136407ms)
Jan  8 09:41:00.901: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/rewriteme"... (200; 12.007073ms)
Jan  8 09:41:00.901: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/... (200; 12.003863ms)
Jan  8 09:41:00.901: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/rewri... (200; 12.498488ms)
Jan  8 09:41:00.907: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname1/proxy/: tls baz (200; 18.14854ms)
Jan  8 09:41:00.907: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname1/proxy/: foo (200; 18.209514ms)
Jan  8 09:41:00.908: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname2/proxy/: bar (200; 18.882608ms)
Jan  8 09:41:00.908: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname2/proxy/: bar (200; 18.668369ms)
Jan  8 09:41:00.908: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname1/proxy/: foo (200; 18.694615ms)
Jan  8 09:41:00.908: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname2/proxy/: tls qux (200; 19.175512ms)
Jan  8 09:41:00.914: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 5.522538ms)
Jan  8 09:41:00.919: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 10.335378ms)
Jan  8 09:41:00.919: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 10.823629ms)
Jan  8 09:41:00.920: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/rewri... (200; 11.23044ms)
Jan  8 09:41:00.920: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:460/proxy/: tls baz (200; 11.406863ms)
Jan  8 09:41:00.920: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname2/proxy/: bar (200; 11.995757ms)
Jan  8 09:41:00.921: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname2/proxy/: bar (200; 12.588199ms)
Jan  8 09:41:00.923: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname1/proxy/: tls baz (200; 15.023847ms)
Jan  8 09:41:00.923: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:462/proxy/: tls qux (200; 14.902748ms)
Jan  8 09:41:00.924: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname1/proxy/: foo (200; 15.343745ms)
Jan  8 09:41:00.925: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/rewriteme"... (200; 16.529546ms)
Jan  8 09:41:00.925: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname1/proxy/: foo (200; 16.60705ms)
Jan  8 09:41:00.925: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname2/proxy/: tls qux (200; 16.529387ms)
Jan  8 09:41:00.925: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/... (200; 16.668999ms)
Jan  8 09:41:00.925: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/... (200; 16.909522ms)
Jan  8 09:41:00.926: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 17.311115ms)
Jan  8 09:41:00.936: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/... (200; 10.397505ms)
Jan  8 09:41:00.938: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/rewriteme"... (200; 11.809632ms)
Jan  8 09:41:00.941: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname2/proxy/: bar (200; 14.971716ms)
Jan  8 09:41:00.941: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 15.047016ms)
Jan  8 09:41:00.945: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:460/proxy/: tls baz (200; 19.019518ms)
Jan  8 09:41:00.946: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 19.684096ms)
Jan  8 09:41:00.946: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/rewri... (200; 19.555706ms)
Jan  8 09:41:00.946: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:462/proxy/: tls qux (200; 19.475633ms)
Jan  8 09:41:00.946: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 19.692613ms)
Jan  8 09:41:00.946: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/... (200; 19.601263ms)
Jan  8 09:41:00.946: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname2/proxy/: tls qux (200; 19.682846ms)
Jan  8 09:41:00.946: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname2/proxy/: bar (200; 19.853907ms)
Jan  8 09:41:00.946: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname1/proxy/: foo (200; 19.941364ms)
Jan  8 09:41:00.946: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname1/proxy/: foo (200; 19.961795ms)
Jan  8 09:41:00.946: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 19.660075ms)
Jan  8 09:41:00.946: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname1/proxy/: tls baz (200; 19.393478ms)
Jan  8 09:41:00.949: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 3.473579ms)
Jan  8 09:41:00.958: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 11.197539ms)
Jan  8 09:41:00.958: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:460/proxy/: tls baz (200; 11.086768ms)
Jan  8 09:41:00.958: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/rewriteme"... (200; 11.437044ms)
Jan  8 09:41:00.959: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 12.303706ms)
Jan  8 09:41:00.959: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname1/proxy/: foo (200; 12.819977ms)
Jan  8 09:41:00.959: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/rewri... (200; 12.40488ms)
Jan  8 09:41:00.959: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/... (200; 12.389833ms)
Jan  8 09:41:00.961: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname2/proxy/: bar (200; 14.209133ms)
Jan  8 09:41:00.961: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:462/proxy/: tls qux (200; 14.428809ms)
Jan  8 09:41:00.961: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname1/proxy/: foo (200; 14.855702ms)
Jan  8 09:41:00.961: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname2/proxy/: bar (200; 14.609697ms)
Jan  8 09:41:00.961: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname2/proxy/: tls qux (200; 14.604952ms)
Jan  8 09:41:00.961: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 15.502297ms)
Jan  8 09:41:00.962: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/... (200; 14.87478ms)
Jan  8 09:41:00.962: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname1/proxy/: tls baz (200; 15.104335ms)
Jan  8 09:41:00.968: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/rewriteme"... (200; 5.840852ms)
Jan  8 09:41:00.969: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/rewri... (200; 6.38448ms)
Jan  8 09:41:00.970: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/... (200; 7.609679ms)
Jan  8 09:41:00.974: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 11.881532ms)
Jan  8 09:41:00.975: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname1/proxy/: tls baz (200; 12.864691ms)
Jan  8 09:41:00.975: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 12.198419ms)
Jan  8 09:41:00.975: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 12.758787ms)
Jan  8 09:41:00.976: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname2/proxy/: tls qux (200; 13.606095ms)
Jan  8 09:41:00.976: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname2/proxy/: bar (200; 13.483627ms)
Jan  8 09:41:00.977: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:462/proxy/: tls qux (200; 13.99857ms)
Jan  8 09:41:00.977: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:460/proxy/: tls baz (200; 14.411966ms)
Jan  8 09:41:00.977: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname1/proxy/: foo (200; 13.965983ms)
Jan  8 09:41:00.977: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname1/proxy/: foo (200; 14.834196ms)
Jan  8 09:41:00.977: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/... (200; 14.862866ms)
Jan  8 09:41:00.977: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname2/proxy/: bar (200; 15.08859ms)
Jan  8 09:41:00.977: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 14.988259ms)
Jan  8 09:41:00.986: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 8.368389ms)
Jan  8 09:41:00.986: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 9.076866ms)
Jan  8 09:41:00.987: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 9.790856ms)
Jan  8 09:41:00.988: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/rewri... (200; 10.580736ms)
Jan  8 09:41:00.988: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/rewriteme"... (200; 10.912276ms)
Jan  8 09:41:00.988: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/... (200; 11.03311ms)
Jan  8 09:41:00.988: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 10.985771ms)
Jan  8 09:41:00.989: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:460/proxy/: tls baz (200; 11.659339ms)
Jan  8 09:41:00.990: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/... (200; 12.159227ms)
Jan  8 09:41:00.990: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname2/proxy/: tls qux (200; 12.18922ms)
Jan  8 09:41:00.990: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:462/proxy/: tls qux (200; 12.538657ms)
Jan  8 09:41:00.991: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname1/proxy/: foo (200; 14.133798ms)
Jan  8 09:41:00.992: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname2/proxy/: bar (200; 14.409653ms)
Jan  8 09:41:00.992: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname1/proxy/: tls baz (200; 14.620249ms)
Jan  8 09:41:00.992: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname1/proxy/: foo (200; 14.845939ms)
Jan  8 09:41:00.992: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname2/proxy/: bar (200; 14.875145ms)
Jan  8 09:41:01.002: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 9.240897ms)
Jan  8 09:41:01.003: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 9.675057ms)
Jan  8 09:41:01.004: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/rewri... (200; 10.81305ms)
Jan  8 09:41:01.004: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:462/proxy/: tls qux (200; 11.960914ms)
Jan  8 09:41:01.004: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 10.960234ms)
Jan  8 09:41:01.005: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 11.234507ms)
Jan  8 09:41:01.005: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/rewriteme"... (200; 11.692957ms)
Jan  8 09:41:01.005: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/... (200; 12.046181ms)
Jan  8 09:41:01.006: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname2/proxy/: bar (200; 12.741527ms)
Jan  8 09:41:01.006: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:460/proxy/: tls baz (200; 12.69576ms)
Jan  8 09:41:01.006: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname1/proxy/: tls baz (200; 13.077122ms)
Jan  8 09:41:01.006: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname1/proxy/: foo (200; 13.20557ms)
Jan  8 09:41:01.006: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/... (200; 12.703377ms)
Jan  8 09:41:01.006: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname2/proxy/: bar (200; 13.39675ms)
Jan  8 09:41:01.006: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname2/proxy/: tls qux (200; 13.155651ms)
Jan  8 09:41:01.006: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname1/proxy/: foo (200; 13.831463ms)
Jan  8 09:41:01.016: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 9.039146ms)
Jan  8 09:41:01.017: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 9.93467ms)
Jan  8 09:41:01.017: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 10.159252ms)
Jan  8 09:41:01.019: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:460/proxy/: tls baz (200; 11.978047ms)
Jan  8 09:41:01.019: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/rewri... (200; 12.334326ms)
Jan  8 09:41:01.019: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/rewriteme"... (200; 12.079133ms)
Jan  8 09:41:01.019: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:462/proxy/: tls qux (200; 12.8056ms)
Jan  8 09:41:01.019: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 12.776514ms)
Jan  8 09:41:01.020: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname2/proxy/: bar (200; 13.146467ms)
Jan  8 09:41:01.020: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname2/proxy/: tls qux (200; 13.178844ms)
Jan  8 09:41:01.020: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname1/proxy/: foo (200; 13.72663ms)
Jan  8 09:41:01.021: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname2/proxy/: bar (200; 14.204635ms)
Jan  8 09:41:01.021: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/... (200; 14.716268ms)
Jan  8 09:41:01.021: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/... (200; 14.564118ms)
Jan  8 09:41:01.022: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname1/proxy/: foo (200; 14.997252ms)
Jan  8 09:41:01.022: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname1/proxy/: tls baz (200; 14.907419ms)
Jan  8 09:41:01.027: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 5.017481ms)
Jan  8 09:41:01.027: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:460/proxy/: tls baz (200; 5.569743ms)
Jan  8 09:41:01.034: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 12.036539ms)
Jan  8 09:41:01.035: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 12.845878ms)
Jan  8 09:41:01.035: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/rewri... (200; 13.166182ms)
Jan  8 09:41:01.036: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/... (200; 14.386534ms)
Jan  8 09:41:01.037: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/... (200; 14.530286ms)
Jan  8 09:41:01.037: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 14.614084ms)
Jan  8 09:41:01.037: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/rewriteme"... (200; 15.061579ms)
Jan  8 09:41:01.037: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname2/proxy/: bar (200; 15.269786ms)
Jan  8 09:41:01.038: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:462/proxy/: tls qux (200; 15.994302ms)
Jan  8 09:41:01.038: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname2/proxy/: tls qux (200; 16.298534ms)
Jan  8 09:41:01.039: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname1/proxy/: tls baz (200; 16.749642ms)
Jan  8 09:41:01.039: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname1/proxy/: foo (200; 17.014757ms)
Jan  8 09:41:01.040: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname2/proxy/: bar (200; 17.713162ms)
Jan  8 09:41:01.041: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname1/proxy/: foo (200; 18.91758ms)
Jan  8 09:41:01.057: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname2/proxy/: bar (200; 15.602388ms)
Jan  8 09:41:01.057: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:460/proxy/: tls baz (200; 15.997753ms)
Jan  8 09:41:01.058: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/... (200; 16.106759ms)
Jan  8 09:41:01.058: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 16.488678ms)
Jan  8 09:41:01.059: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/... (200; 17.653816ms)
Jan  8 09:41:01.059: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname2/proxy/: tls qux (200; 17.937691ms)
Jan  8 09:41:01.059: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 18.148347ms)
Jan  8 09:41:01.060: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:462/proxy/: tls qux (200; 18.497456ms)
Jan  8 09:41:01.060: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 18.623081ms)
Jan  8 09:41:01.060: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname1/proxy/: tls baz (200; 18.506293ms)
Jan  8 09:41:01.060: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname2/proxy/: bar (200; 18.629665ms)
Jan  8 09:41:01.060: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/rewri... (200; 19.142032ms)
Jan  8 09:41:01.060: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname1/proxy/: foo (200; 18.814453ms)
Jan  8 09:41:01.061: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 18.949779ms)
Jan  8 09:41:01.061: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/rewriteme"... (200; 20.378462ms)
Jan  8 09:41:01.063: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname1/proxy/: foo (200; 21.856818ms)
Jan  8 09:41:01.067: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/... (200; 3.840347ms)
Jan  8 09:41:01.075: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/... (200; 11.565605ms)
Jan  8 09:41:01.075: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 12.416819ms)
Jan  8 09:41:01.076: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 12.996076ms)
Jan  8 09:41:01.076: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:460/proxy/: tls baz (200; 12.902638ms)
Jan  8 09:41:01.076: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 13.393576ms)
Jan  8 09:41:01.076: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 13.440904ms)
Jan  8 09:41:01.076: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/rewriteme"... (200; 13.360372ms)
Jan  8 09:41:01.076: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:462/proxy/: tls qux (200; 13.478174ms)
Jan  8 09:41:01.077: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/rewri... (200; 14.17081ms)
Jan  8 09:41:01.079: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname1/proxy/: tls baz (200; 16.148373ms)
Jan  8 09:41:01.080: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname1/proxy/: foo (200; 16.890756ms)
Jan  8 09:41:01.080: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname1/proxy/: foo (200; 17.30525ms)
Jan  8 09:41:01.081: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname2/proxy/: bar (200; 17.540372ms)
Jan  8 09:41:01.081: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname2/proxy/: tls qux (200; 17.748509ms)
Jan  8 09:41:01.081: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname2/proxy/: bar (200; 18.06557ms)
Jan  8 09:41:01.086: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:462/proxy/: tls qux (200; 4.604221ms)
Jan  8 09:41:01.093: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:460/proxy/: tls baz (200; 11.278676ms)
Jan  8 09:41:01.094: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname2/proxy/: bar (200; 12.303402ms)
Jan  8 09:41:01.094: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/rewriteme"... (200; 11.835118ms)
Jan  8 09:41:01.094: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname1/proxy/: foo (200; 12.540812ms)
Jan  8 09:41:01.094: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname2/proxy/: tls qux (200; 12.29687ms)
Jan  8 09:41:01.094: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 12.186869ms)
Jan  8 09:41:01.095: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname1/proxy/: tls baz (200; 13.259985ms)
Jan  8 09:41:01.095: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname1/proxy/: foo (200; 13.459605ms)
Jan  8 09:41:01.095: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 13.307521ms)
Jan  8 09:41:01.096: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 13.528252ms)
Jan  8 09:41:01.096: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/... (200; 13.642922ms)
Jan  8 09:41:01.096: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/... (200; 13.952271ms)
Jan  8 09:41:01.096: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname2/proxy/: bar (200; 14.1242ms)
Jan  8 09:41:01.096: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/rewri... (200; 13.819928ms)
Jan  8 09:41:01.096: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 14.171778ms)
Jan  8 09:41:01.109: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 12.714378ms)
Jan  8 09:41:01.109: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:462/proxy/: tls qux (200; 12.919434ms)
Jan  8 09:41:01.111: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk/proxy/rewriteme"... (200; 14.036683ms)
Jan  8 09:41:01.113: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:160/proxy/: foo (200; 16.54066ms)
Jan  8 09:41:01.113: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:1080/proxy/rewri... (200; 16.207127ms)
Jan  8 09:41:01.113: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:1080/proxy/... (200; 16.148794ms)
Jan  8 09:41:01.113: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname1/proxy/: foo (200; 17.189756ms)
Jan  8 09:41:01.113: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname2/proxy/: bar (200; 16.933261ms)
Jan  8 09:41:01.113: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname1/proxy/: tls baz (200; 17.064666ms)
Jan  8 09:41:01.113: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/http:proxy-service-t7dhg:portname2/proxy/: bar (200; 17.154796ms)
Jan  8 09:41:01.113: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/proxy-service-t7dhg:portname1/proxy/: foo (200; 17.046433ms)
Jan  8 09:41:01.113: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:443/proxy/... (200; 16.816936ms)
Jan  8 09:41:01.114: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/https:proxy-service-t7dhg-g24mk:460/proxy/: tls baz (200; 16.812986ms)
Jan  8 09:41:01.113: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xjsms/services/https:proxy-service-t7dhg:tlsportname2/proxy/: tls qux (200; 16.6859ms)
Jan  8 09:41:01.114: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/http:proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 16.927866ms)
Jan  8 09:41:01.114: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xjsms/pods/proxy-service-t7dhg-g24mk:162/proxy/: bar (200; 17.613467ms)
STEP: deleting { ReplicationController} proxy-service-t7dhg in namespace e2e-tests-proxy-xjsms, will wait for the garbage collector to delete the pods
Jan  8 09:41:01.173: INFO: Deleting { ReplicationController} proxy-service-t7dhg took: 6.118799ms
Jan  8 09:41:01.273: INFO: Terminating { ReplicationController} proxy-service-t7dhg pods took: 100.293991ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:41:13.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-xjsms" for this suite.
Jan  8 09:41:19.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:41:19.377: INFO: namespace: e2e-tests-proxy-xjsms, resource: bindings, ignored listing per whitelist
Jan  8 09:41:19.380: INFO: namespace e2e-tests-proxy-xjsms deletion completed in 6.102093861s

â€¢ [SLOW TEST:33.776 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:41:19.380: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Jan  8 09:41:19.466: INFO: Waiting up to 5m0s for pod "client-containers-8d2c565b-1329-11e9-bc05-0a580af40202" in namespace "e2e-tests-containers-q4pcf" to be "success or failure"
Jan  8 09:41:19.469: INFO: Pod "client-containers-8d2c565b-1329-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.029024ms
Jan  8 09:41:21.473: INFO: Pod "client-containers-8d2c565b-1329-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006992664s
STEP: Saw pod success
Jan  8 09:41:21.473: INFO: Pod "client-containers-8d2c565b-1329-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:41:21.476: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod client-containers-8d2c565b-1329-11e9-bc05-0a580af40202 container test-container: <nil>
STEP: delete the pod
Jan  8 09:41:21.493: INFO: Waiting for pod client-containers-8d2c565b-1329-11e9-bc05-0a580af40202 to disappear
Jan  8 09:41:21.497: INFO: Pod client-containers-8d2c565b-1329-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:41:21.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-q4pcf" for this suite.
Jan  8 09:41:27.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:41:27.538: INFO: namespace: e2e-tests-containers-q4pcf, resource: bindings, ignored listing per whitelist
Jan  8 09:41:27.603: INFO: namespace e2e-tests-containers-q4pcf deletion completed in 6.101555983s

â€¢ [SLOW TEST:8.223 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:41:27.603: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-92122960-1329-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume configMaps
Jan  8 09:41:27.686: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9212a434-1329-11e9-bc05-0a580af40202" in namespace "e2e-tests-projected-p598m" to be "success or failure"
Jan  8 09:41:27.689: INFO: Pod "pod-projected-configmaps-9212a434-1329-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.880091ms
Jan  8 09:41:29.694: INFO: Pod "pod-projected-configmaps-9212a434-1329-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008038534s
STEP: Saw pod success
Jan  8 09:41:29.694: INFO: Pod "pod-projected-configmaps-9212a434-1329-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:41:29.696: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod pod-projected-configmaps-9212a434-1329-11e9-bc05-0a580af40202 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan  8 09:41:29.713: INFO: Waiting for pod pod-projected-configmaps-9212a434-1329-11e9-bc05-0a580af40202 to disappear
Jan  8 09:41:29.716: INFO: Pod pod-projected-configmaps-9212a434-1329-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:41:29.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p598m" for this suite.
Jan  8 09:41:35.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:41:35.762: INFO: namespace: e2e-tests-projected-p598m, resource: bindings, ignored listing per whitelist
Jan  8 09:41:35.832: INFO: namespace e2e-tests-projected-p598m deletion completed in 6.112209813s

â€¢ [SLOW TEST:8.228 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:41:35.832: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Jan  8 09:41:35.907: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan  8 09:41:35.914: INFO: Waiting for terminating namespaces to be deleted...
Jan  8 09:41:35.917: INFO: 
Logging pods the kubelet thinks is on node oltf-408483-kube-worker1 before test
Jan  8 09:41:35.924: INFO: kube-proxy-hx5gw from kube-system started at 2019-01-08 09:06:18 +0000 UTC (1 container statuses recorded)
Jan  8 09:41:35.924: INFO: 	Container kube-proxy ready: true, restart count 0
Jan  8 09:41:35.924: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-08 09:12:14 +0000 UTC (1 container statuses recorded)
Jan  8 09:41:35.924: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan  8 09:41:35.924: INFO: sonobuoy-systemd-logs-daemon-set-e6ac5c1d15cd4528-rfbv9 from heptio-sonobuoy started at 2019-01-08 09:12:20 +0000 UTC (2 container statuses recorded)
Jan  8 09:41:35.924: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan  8 09:41:35.924: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan  8 09:41:35.924: INFO: kube-flannel-ds-ktvvw from kube-system started at 2019-01-08 09:06:18 +0000 UTC (1 container statuses recorded)
Jan  8 09:41:35.924: INFO: 	Container kube-flannel ready: true, restart count 0
Jan  8 09:41:35.924: INFO: 
Logging pods the kubelet thinks is on node oltf-408483-kube-worker2 before test
Jan  8 09:41:35.929: INFO: kube-proxy-4wjhs from kube-system started at 2019-01-08 09:07:03 +0000 UTC (1 container statuses recorded)
Jan  8 09:41:35.929: INFO: 	Container kube-proxy ready: true, restart count 0
Jan  8 09:41:35.929: INFO: sonobuoy-e2e-job-95203627594e4c77 from heptio-sonobuoy started at 2019-01-08 09:12:20 +0000 UTC (2 container statuses recorded)
Jan  8 09:41:35.929: INFO: 	Container e2e ready: true, restart count 0
Jan  8 09:41:35.929: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan  8 09:41:35.929: INFO: sonobuoy-systemd-logs-daemon-set-e6ac5c1d15cd4528-tjn6w from heptio-sonobuoy started at 2019-01-08 09:12:20 +0000 UTC (2 container statuses recorded)
Jan  8 09:41:35.929: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan  8 09:41:35.929: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan  8 09:41:35.929: INFO: kube-flannel-ds-6df6t from kube-system started at 2019-01-08 09:07:03 +0000 UTC (1 container statuses recorded)
Jan  8 09:41:35.929: INFO: 	Container kube-flannel ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node oltf-408483-kube-worker1
STEP: verifying the node has the label node oltf-408483-kube-worker2
Jan  8 09:41:35.976: INFO: Pod sonobuoy requesting resource cpu=0m on Node oltf-408483-kube-worker1
Jan  8 09:41:35.976: INFO: Pod sonobuoy-e2e-job-95203627594e4c77 requesting resource cpu=0m on Node oltf-408483-kube-worker2
Jan  8 09:41:35.976: INFO: Pod sonobuoy-systemd-logs-daemon-set-e6ac5c1d15cd4528-rfbv9 requesting resource cpu=0m on Node oltf-408483-kube-worker1
Jan  8 09:41:35.976: INFO: Pod sonobuoy-systemd-logs-daemon-set-e6ac5c1d15cd4528-tjn6w requesting resource cpu=0m on Node oltf-408483-kube-worker2
Jan  8 09:41:35.976: INFO: Pod kube-flannel-ds-6df6t requesting resource cpu=100m on Node oltf-408483-kube-worker2
Jan  8 09:41:35.976: INFO: Pod kube-flannel-ds-ktvvw requesting resource cpu=100m on Node oltf-408483-kube-worker1
Jan  8 09:41:35.976: INFO: Pod kube-proxy-4wjhs requesting resource cpu=0m on Node oltf-408483-kube-worker2
Jan  8 09:41:35.976: INFO: Pod kube-proxy-hx5gw requesting resource cpu=0m on Node oltf-408483-kube-worker1
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9704b9be-1329-11e9-bc05-0a580af40202.1577d62f60301ecd], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-29zsg/filler-pod-9704b9be-1329-11e9-bc05-0a580af40202 to oltf-408483-kube-worker1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9704b9be-1329-11e9-bc05-0a580af40202.1577d62f92c5ec6b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9704b9be-1329-11e9-bc05-0a580af40202.1577d62f958af4de], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9704b9be-1329-11e9-bc05-0a580af40202.1577d62f9bffe061], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9705b150-1329-11e9-bc05-0a580af40202.1577d62f609ff77a], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-29zsg/filler-pod-9705b150-1329-11e9-bc05-0a580af40202 to oltf-408483-kube-worker2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9705b150-1329-11e9-bc05-0a580af40202.1577d62f901a7bfa], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9705b150-1329-11e9-bc05-0a580af40202.1577d62f92a963f5], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9705b150-1329-11e9-bc05-0a580af40202.1577d62f98f490e9], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1577d62fd8630123], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node oltf-408483-kube-worker1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node oltf-408483-kube-worker2
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:41:39.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-29zsg" for this suite.
Jan  8 09:41:45.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:41:45.146: INFO: namespace: e2e-tests-sched-pred-29zsg, resource: bindings, ignored listing per whitelist
Jan  8 09:41:45.146: INFO: namespace e2e-tests-sched-pred-29zsg deletion completed in 6.101656031s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

â€¢ [SLOW TEST:9.315 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:41:45.147: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Jan  8 09:41:45.219: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan  8 09:41:45.226: INFO: Waiting for terminating namespaces to be deleted...
Jan  8 09:41:45.229: INFO: 
Logging pods the kubelet thinks is on node oltf-408483-kube-worker1 before test
Jan  8 09:41:45.234: INFO: kube-flannel-ds-ktvvw from kube-system started at 2019-01-08 09:06:18 +0000 UTC (1 container statuses recorded)
Jan  8 09:41:45.234: INFO: 	Container kube-flannel ready: true, restart count 0
Jan  8 09:41:45.234: INFO: kube-proxy-hx5gw from kube-system started at 2019-01-08 09:06:18 +0000 UTC (1 container statuses recorded)
Jan  8 09:41:45.234: INFO: 	Container kube-proxy ready: true, restart count 0
Jan  8 09:41:45.234: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-08 09:12:14 +0000 UTC (1 container statuses recorded)
Jan  8 09:41:45.234: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan  8 09:41:45.234: INFO: sonobuoy-systemd-logs-daemon-set-e6ac5c1d15cd4528-rfbv9 from heptio-sonobuoy started at 2019-01-08 09:12:20 +0000 UTC (2 container statuses recorded)
Jan  8 09:41:45.234: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan  8 09:41:45.234: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan  8 09:41:45.234: INFO: 
Logging pods the kubelet thinks is on node oltf-408483-kube-worker2 before test
Jan  8 09:41:45.239: INFO: kube-flannel-ds-6df6t from kube-system started at 2019-01-08 09:07:03 +0000 UTC (1 container statuses recorded)
Jan  8 09:41:45.239: INFO: 	Container kube-flannel ready: true, restart count 0
Jan  8 09:41:45.239: INFO: sonobuoy-systemd-logs-daemon-set-e6ac5c1d15cd4528-tjn6w from heptio-sonobuoy started at 2019-01-08 09:12:20 +0000 UTC (2 container statuses recorded)
Jan  8 09:41:45.239: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan  8 09:41:45.239: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan  8 09:41:45.239: INFO: kube-proxy-4wjhs from kube-system started at 2019-01-08 09:07:03 +0000 UTC (1 container statuses recorded)
Jan  8 09:41:45.239: INFO: 	Container kube-proxy ready: true, restart count 0
Jan  8 09:41:45.239: INFO: sonobuoy-e2e-job-95203627594e4c77 from heptio-sonobuoy started at 2019-01-08 09:12:20 +0000 UTC (2 container statuses recorded)
Jan  8 09:41:45.240: INFO: 	Container e2e ready: true, restart count 0
Jan  8 09:41:45.240: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-9dbecf4a-1329-11e9-bc05-0a580af40202 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-9dbecf4a-1329-11e9-bc05-0a580af40202 off the node oltf-408483-kube-worker1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-9dbecf4a-1329-11e9-bc05-0a580af40202
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:41:49.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-ztv9s" for this suite.
Jan  8 09:41:57.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:41:57.365: INFO: namespace: e2e-tests-sched-pred-ztv9s, resource: bindings, ignored listing per whitelist
Jan  8 09:41:57.428: INFO: namespace e2e-tests-sched-pred-ztv9s deletion completed in 8.107840394s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

â€¢ [SLOW TEST:12.282 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:41:57.428: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-zjhls
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan  8 09:41:57.502: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan  8 09:42:23.574: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.66:8080/dial?request=hostName&protocol=http&host=10.244.1.74&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-zjhls PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  8 09:42:23.574: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
Jan  8 09:42:23.667: INFO: Waiting for endpoints: map[]
Jan  8 09:42:23.671: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.66:8080/dial?request=hostName&protocol=http&host=10.244.2.65&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-zjhls PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  8 09:42:23.671: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
Jan  8 09:42:23.763: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:42:23.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-zjhls" for this suite.
Jan  8 09:42:45.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:42:45.789: INFO: namespace: e2e-tests-pod-network-test-zjhls, resource: bindings, ignored listing per whitelist
Jan  8 09:42:45.865: INFO: namespace e2e-tests-pod-network-test-zjhls deletion completed in 22.097836467s

â€¢ [SLOW TEST:48.437 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:42:45.865: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Jan  8 09:42:45.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 create -f - --namespace=e2e-tests-kubectl-tf7gc'
Jan  8 09:42:46.119: INFO: stderr: ""
Jan  8 09:42:46.119: INFO: stdout: "pod/pause created\n"
Jan  8 09:42:46.119: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jan  8 09:42:46.119: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-tf7gc" to be "running and ready"
Jan  8 09:42:46.128: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 9.008928ms
Jan  8 09:42:48.132: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.013231007s
Jan  8 09:42:48.132: INFO: Pod "pause" satisfied condition "running and ready"
Jan  8 09:42:48.132: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Jan  8 09:42:48.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-tf7gc'
Jan  8 09:42:48.225: INFO: stderr: ""
Jan  8 09:42:48.225: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jan  8 09:42:48.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pod pause -L testing-label --namespace=e2e-tests-kubectl-tf7gc'
Jan  8 09:42:48.309: INFO: stderr: ""
Jan  8 09:42:48.309: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jan  8 09:42:48.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 label pods pause testing-label- --namespace=e2e-tests-kubectl-tf7gc'
Jan  8 09:42:48.401: INFO: stderr: ""
Jan  8 09:42:48.401: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jan  8 09:42:48.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pod pause -L testing-label --namespace=e2e-tests-kubectl-tf7gc'
Jan  8 09:42:48.496: INFO: stderr: ""
Jan  8 09:42:48.496: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Jan  8 09:42:48.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-tf7gc'
Jan  8 09:42:48.588: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  8 09:42:48.588: INFO: stdout: "pod \"pause\" force deleted\n"
Jan  8 09:42:48.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-tf7gc'
Jan  8 09:42:48.714: INFO: stderr: "No resources found.\n"
Jan  8 09:42:48.714: INFO: stdout: ""
Jan  8 09:42:48.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods -l name=pause --namespace=e2e-tests-kubectl-tf7gc -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan  8 09:42:48.831: INFO: stderr: ""
Jan  8 09:42:48.831: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:42:48.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tf7gc" for this suite.
Jan  8 09:42:54.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:42:54.927: INFO: namespace: e2e-tests-kubectl-tf7gc, resource: bindings, ignored listing per whitelist
Jan  8 09:42:54.939: INFO: namespace e2e-tests-kubectl-tf7gc deletion completed in 6.102856438s

â€¢ [SLOW TEST:9.073 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:42:54.939: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-wcgpx
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-wcgpx to expose endpoints map[]
Jan  8 09:42:55.043: INFO: Get endpoints failed (3.096043ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Jan  8 09:42:56.048: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-wcgpx exposes endpoints map[] (1.007680645s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-wcgpx
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-wcgpx to expose endpoints map[pod1:[80]]
Jan  8 09:42:58.073: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-wcgpx exposes endpoints map[pod1:[80]] (2.019091891s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-wcgpx
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-wcgpx to expose endpoints map[pod2:[80] pod1:[80]]
Jan  8 09:43:00.114: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-wcgpx exposes endpoints map[pod1:[80] pod2:[80]] (2.031066795s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-wcgpx
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-wcgpx to expose endpoints map[pod2:[80]]
Jan  8 09:43:01.131: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-wcgpx exposes endpoints map[pod2:[80]] (1.012676428s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-wcgpx
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-wcgpx to expose endpoints map[]
Jan  8 09:43:02.141: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-wcgpx exposes endpoints map[] (1.005857496s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:43:02.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-wcgpx" for this suite.
Jan  8 09:43:08.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:43:08.281: INFO: namespace: e2e-tests-services-wcgpx, resource: bindings, ignored listing per whitelist
Jan  8 09:43:08.289: INFO: namespace e2e-tests-services-wcgpx deletion completed in 6.10203878s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

â€¢ [SLOW TEST:13.350 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:43:08.289: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  8 09:43:08.365: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jan  8 09:43:08.372: INFO: Pod name sample-pod: Found 0 pods out of 1
Jan  8 09:43:13.377: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan  8 09:43:13.377: INFO: Creating deployment "test-rolling-update-deployment"
Jan  8 09:43:13.381: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jan  8 09:43:13.387: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jan  8 09:43:15.395: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jan  8 09:43:15.399: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan  8 09:43:15.408: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-fs8hn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fs8hn/deployments/test-rolling-update-deployment,UID:d11307f4-1329-11e9-a60a-02001701fa35,ResourceVersion:7135,Generation:1,CreationTimestamp:2019-01-08 09:43:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-01-08 09:43:13 +0000 UTC 2019-01-08 09:43:13 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-01-08 09:43:15 +0000 UTC 2019-01-08 09:43:13 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan  8 09:43:15.412: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-fs8hn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fs8hn/replicasets/test-rolling-update-deployment-65b7695dcf,UID:d115c942-1329-11e9-a60a-02001701fa35,ResourceVersion:7126,Generation:1,CreationTimestamp:2019-01-08 09:43:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment d11307f4-1329-11e9-a60a-02001701fa35 0xc4226dd007 0xc4226dd008}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan  8 09:43:15.412: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jan  8 09:43:15.412: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-fs8hn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fs8hn/replicasets/test-rolling-update-controller,UID:ce164ca5-1329-11e9-a60a-02001701fa35,ResourceVersion:7134,Generation:2,CreationTimestamp:2019-01-08 09:43:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment d11307f4-1329-11e9-a60a-02001701fa35 0xc4226dced7 0xc4226dced8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan  8 09:43:15.415: INFO: Pod "test-rolling-update-deployment-65b7695dcf-7cczn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-7cczn,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-fs8hn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fs8hn/pods/test-rolling-update-deployment-65b7695dcf-7cczn,UID:d11665c1-1329-11e9-a60a-02001701fa35,ResourceVersion:7125,Generation:0,CreationTimestamp:2019-01-08 09:43:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf d115c942-1329-11e9-a60a-02001701fa35 0xc422628a17 0xc422628a18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zqpkb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zqpkb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-zqpkb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422628a90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422628ae0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:43:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:43:15 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:43:15 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:43:13 +0000 UTC  }],Message:,Reason:,HostIP:100.100.242.163,PodIP:10.244.2.70,StartTime:2019-01-08 09:43:13 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-01-08 09:43:14 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://f89fa00c9c8f07e0528aa232e6afe83248899cf04be1eb70d9253934e73dfdd5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:43:15.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-fs8hn" for this suite.
Jan  8 09:43:21.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:43:21.452: INFO: namespace: e2e-tests-deployment-fs8hn, resource: bindings, ignored listing per whitelist
Jan  8 09:43:21.523: INFO: namespace e2e-tests-deployment-fs8hn deletion completed in 6.103963646s

â€¢ [SLOW TEST:13.234 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:43:21.524: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jan  8 09:43:21.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 create -f - --namespace=e2e-tests-kubectl-h29hv'
Jan  8 09:43:21.940: INFO: stderr: ""
Jan  8 09:43:21.940: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan  8 09:43:21.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h29hv'
Jan  8 09:43:22.045: INFO: stderr: ""
Jan  8 09:43:22.045: INFO: stdout: "update-demo-nautilus-dl8jz update-demo-nautilus-jn6kq "
Jan  8 09:43:22.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-nautilus-dl8jz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h29hv'
Jan  8 09:43:22.138: INFO: stderr: ""
Jan  8 09:43:22.138: INFO: stdout: ""
Jan  8 09:43:22.138: INFO: update-demo-nautilus-dl8jz is created but not running
Jan  8 09:43:27.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h29hv'
Jan  8 09:43:27.228: INFO: stderr: ""
Jan  8 09:43:27.228: INFO: stdout: "update-demo-nautilus-dl8jz update-demo-nautilus-jn6kq "
Jan  8 09:43:27.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-nautilus-dl8jz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h29hv'
Jan  8 09:43:27.323: INFO: stderr: ""
Jan  8 09:43:27.323: INFO: stdout: "true"
Jan  8 09:43:27.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-nautilus-dl8jz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h29hv'
Jan  8 09:43:27.407: INFO: stderr: ""
Jan  8 09:43:27.407: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  8 09:43:27.407: INFO: validating pod update-demo-nautilus-dl8jz
Jan  8 09:43:27.411: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  8 09:43:27.411: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  8 09:43:27.411: INFO: update-demo-nautilus-dl8jz is verified up and running
Jan  8 09:43:27.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-nautilus-jn6kq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h29hv'
Jan  8 09:43:27.502: INFO: stderr: ""
Jan  8 09:43:27.502: INFO: stdout: "true"
Jan  8 09:43:27.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-nautilus-jn6kq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h29hv'
Jan  8 09:43:27.586: INFO: stderr: ""
Jan  8 09:43:27.586: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  8 09:43:27.586: INFO: validating pod update-demo-nautilus-jn6kq
Jan  8 09:43:27.591: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  8 09:43:27.591: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  8 09:43:27.591: INFO: update-demo-nautilus-jn6kq is verified up and running
STEP: scaling down the replication controller
Jan  8 09:43:27.593: INFO: scanned /root for discovery docs: <nil>
Jan  8 09:43:27.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-h29hv'
Jan  8 09:43:28.706: INFO: stderr: ""
Jan  8 09:43:28.706: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan  8 09:43:28.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h29hv'
Jan  8 09:43:28.797: INFO: stderr: ""
Jan  8 09:43:28.797: INFO: stdout: "update-demo-nautilus-dl8jz update-demo-nautilus-jn6kq "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jan  8 09:43:33.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h29hv'
Jan  8 09:43:33.886: INFO: stderr: ""
Jan  8 09:43:33.886: INFO: stdout: "update-demo-nautilus-jn6kq "
Jan  8 09:43:33.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-nautilus-jn6kq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h29hv'
Jan  8 09:43:33.971: INFO: stderr: ""
Jan  8 09:43:33.971: INFO: stdout: "true"
Jan  8 09:43:33.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-nautilus-jn6kq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h29hv'
Jan  8 09:43:34.056: INFO: stderr: ""
Jan  8 09:43:34.056: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  8 09:43:34.056: INFO: validating pod update-demo-nautilus-jn6kq
Jan  8 09:43:34.059: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  8 09:43:34.059: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  8 09:43:34.059: INFO: update-demo-nautilus-jn6kq is verified up and running
STEP: scaling up the replication controller
Jan  8 09:43:34.061: INFO: scanned /root for discovery docs: <nil>
Jan  8 09:43:34.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-h29hv'
Jan  8 09:43:35.171: INFO: stderr: ""
Jan  8 09:43:35.171: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan  8 09:43:35.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h29hv'
Jan  8 09:43:35.263: INFO: stderr: ""
Jan  8 09:43:35.263: INFO: stdout: "update-demo-nautilus-4wzm7 update-demo-nautilus-jn6kq "
Jan  8 09:43:35.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-nautilus-4wzm7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h29hv'
Jan  8 09:43:35.348: INFO: stderr: ""
Jan  8 09:43:35.348: INFO: stdout: ""
Jan  8 09:43:35.348: INFO: update-demo-nautilus-4wzm7 is created but not running
Jan  8 09:43:40.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h29hv'
Jan  8 09:43:40.444: INFO: stderr: ""
Jan  8 09:43:40.444: INFO: stdout: "update-demo-nautilus-4wzm7 update-demo-nautilus-jn6kq "
Jan  8 09:43:40.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-nautilus-4wzm7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h29hv'
Jan  8 09:43:40.527: INFO: stderr: ""
Jan  8 09:43:40.527: INFO: stdout: "true"
Jan  8 09:43:40.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-nautilus-4wzm7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h29hv'
Jan  8 09:43:40.610: INFO: stderr: ""
Jan  8 09:43:40.611: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  8 09:43:40.611: INFO: validating pod update-demo-nautilus-4wzm7
Jan  8 09:43:40.615: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  8 09:43:40.615: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  8 09:43:40.615: INFO: update-demo-nautilus-4wzm7 is verified up and running
Jan  8 09:43:40.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-nautilus-jn6kq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h29hv'
Jan  8 09:43:40.699: INFO: stderr: ""
Jan  8 09:43:40.699: INFO: stdout: "true"
Jan  8 09:43:40.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-nautilus-jn6kq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h29hv'
Jan  8 09:43:40.785: INFO: stderr: ""
Jan  8 09:43:40.785: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  8 09:43:40.785: INFO: validating pod update-demo-nautilus-jn6kq
Jan  8 09:43:40.789: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  8 09:43:40.789: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  8 09:43:40.789: INFO: update-demo-nautilus-jn6kq is verified up and running
STEP: using delete to clean up resources
Jan  8 09:43:40.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-h29hv'
Jan  8 09:43:40.878: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  8 09:43:40.878: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan  8 09:43:40.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-h29hv'
Jan  8 09:43:40.995: INFO: stderr: "No resources found.\n"
Jan  8 09:43:40.995: INFO: stdout: ""
Jan  8 09:43:40.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods -l name=update-demo --namespace=e2e-tests-kubectl-h29hv -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan  8 09:43:41.118: INFO: stderr: ""
Jan  8 09:43:41.118: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:43:41.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-h29hv" for this suite.
Jan  8 09:44:03.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:44:03.179: INFO: namespace: e2e-tests-kubectl-h29hv, resource: bindings, ignored listing per whitelist
Jan  8 09:44:03.219: INFO: namespace e2e-tests-kubectl-h29hv deletion completed in 22.096720835s

â€¢ [SLOW TEST:41.696 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:44:03.220: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  8 09:44:03.303: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eed412e6-1329-11e9-bc05-0a580af40202" in namespace "e2e-tests-projected-7g8sx" to be "success or failure"
Jan  8 09:44:03.306: INFO: Pod "downwardapi-volume-eed412e6-1329-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.035361ms
Jan  8 09:44:05.310: INFO: Pod "downwardapi-volume-eed412e6-1329-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007006866s
STEP: Saw pod success
Jan  8 09:44:05.310: INFO: Pod "downwardapi-volume-eed412e6-1329-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:44:05.313: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod downwardapi-volume-eed412e6-1329-11e9-bc05-0a580af40202 container client-container: <nil>
STEP: delete the pod
Jan  8 09:44:05.337: INFO: Waiting for pod downwardapi-volume-eed412e6-1329-11e9-bc05-0a580af40202 to disappear
Jan  8 09:44:05.340: INFO: Pod downwardapi-volume-eed412e6-1329-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:44:05.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7g8sx" for this suite.
Jan  8 09:44:11.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:44:11.527: INFO: namespace: e2e-tests-projected-7g8sx, resource: bindings, ignored listing per whitelist
Jan  8 09:44:11.564: INFO: namespace e2e-tests-projected-7g8sx deletion completed in 6.219903954s

â€¢ [SLOW TEST:8.344 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:44:11.564: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan  8 09:44:14.173: INFO: Successfully updated pod "annotationupdatef3cc6774-1329-11e9-bc05-0a580af40202"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:44:18.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x9nwp" for this suite.
Jan  8 09:44:40.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:44:40.243: INFO: namespace: e2e-tests-projected-x9nwp, resource: bindings, ignored listing per whitelist
Jan  8 09:44:40.307: INFO: namespace e2e-tests-projected-x9nwp deletion completed in 22.104493745s

â€¢ [SLOW TEST:28.743 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:44:40.308: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan  8 09:44:40.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-95ccf'
Jan  8 09:44:40.498: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan  8 09:44:40.499: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Jan  8 09:44:42.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-95ccf'
Jan  8 09:44:42.604: INFO: stderr: ""
Jan  8 09:44:42.604: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:44:42.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-95ccf" for this suite.
Jan  8 09:44:48.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:44:48.685: INFO: namespace: e2e-tests-kubectl-95ccf, resource: bindings, ignored listing per whitelist
Jan  8 09:44:48.709: INFO: namespace e2e-tests-kubectl-95ccf deletion completed in 6.100851098s

â€¢ [SLOW TEST:8.401 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:44:48.709: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Jan  8 09:44:48.777: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-272738442 proxy --unix-socket=/tmp/kubectl-proxy-unix673954913/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:44:48.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-s67bl" for this suite.
Jan  8 09:44:54.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:44:54.914: INFO: namespace: e2e-tests-kubectl-s67bl, resource: bindings, ignored listing per whitelist
Jan  8 09:44:54.947: INFO: namespace e2e-tests-kubectl-s67bl deletion completed in 6.101249085s

â€¢ [SLOW TEST:6.238 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:44:54.947: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  8 09:44:55.025: INFO: Creating deployment "test-recreate-deployment"
Jan  8 09:44:55.030: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jan  8 09:44:55.035: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Jan  8 09:44:57.041: INFO: Waiting deployment "test-recreate-deployment" to complete
Jan  8 09:44:57.044: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jan  8 09:44:57.052: INFO: Updating deployment test-recreate-deployment
Jan  8 09:44:57.052: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan  8 09:44:57.116: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-jsdqk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jsdqk/deployments/test-recreate-deployment,UID:0da94c36-132a-11e9-a60a-02001701fa35,ResourceVersion:7536,Generation:2,CreationTimestamp:2019-01-08 09:44:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-01-08 09:44:57 +0000 UTC 2019-01-08 09:44:57 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-01-08 09:44:57 +0000 UTC 2019-01-08 09:44:55 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Jan  8 09:44:57.119: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-jsdqk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jsdqk/replicasets/test-recreate-deployment-7cf749666b,UID:0ee2963c-132a-11e9-a60a-02001701fa35,ResourceVersion:7533,Generation:1,CreationTimestamp:2019-01-08 09:44:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 0da94c36-132a-11e9-a60a-02001701fa35 0xc422142567 0xc422142568}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan  8 09:44:57.119: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jan  8 09:44:57.120: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-jsdqk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jsdqk/replicasets/test-recreate-deployment-79f694ff59,UID:0daafdab-132a-11e9-a60a-02001701fa35,ResourceVersion:7524,Generation:2,CreationTimestamp:2019-01-08 09:44:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 0da94c36-132a-11e9-a60a-02001701fa35 0xc4221424a7 0xc4221424a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan  8 09:44:57.123: INFO: Pod "test-recreate-deployment-7cf749666b-ds2jg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-ds2jg,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-jsdqk,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jsdqk/pods/test-recreate-deployment-7cf749666b-ds2jg,UID:0ee34bea-132a-11e9-a60a-02001701fa35,ResourceVersion:7534,Generation:0,CreationTimestamp:2019-01-08 09:44:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b 0ee2963c-132a-11e9-a60a-02001701fa35 0xc422142f37 0xc422142f38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5r4b2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5r4b2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5r4b2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422142fa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422142fc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:44:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:44:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:44:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:44:57 +0000 UTC  }],Message:,Reason:,HostIP:100.100.242.163,PodIP:,StartTime:2019-01-08 09:44:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:44:57.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-jsdqk" for this suite.
Jan  8 09:45:03.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:45:03.215: INFO: namespace: e2e-tests-deployment-jsdqk, resource: bindings, ignored listing per whitelist
Jan  8 09:45:03.232: INFO: namespace e2e-tests-deployment-jsdqk deletion completed in 6.105538611s

â€¢ [SLOW TEST:8.285 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:45:03.232: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  8 09:45:03.311: INFO: Waiting up to 5m0s for pod "downwardapi-volume-12985681-132a-11e9-bc05-0a580af40202" in namespace "e2e-tests-projected-cf66w" to be "success or failure"
Jan  8 09:45:03.317: INFO: Pod "downwardapi-volume-12985681-132a-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 6.409942ms
Jan  8 09:45:05.322: INFO: Pod "downwardapi-volume-12985681-132a-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011093964s
STEP: Saw pod success
Jan  8 09:45:05.322: INFO: Pod "downwardapi-volume-12985681-132a-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:45:05.326: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod downwardapi-volume-12985681-132a-11e9-bc05-0a580af40202 container client-container: <nil>
STEP: delete the pod
Jan  8 09:45:05.345: INFO: Waiting for pod downwardapi-volume-12985681-132a-11e9-bc05-0a580af40202 to disappear
Jan  8 09:45:05.348: INFO: Pod downwardapi-volume-12985681-132a-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:45:05.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cf66w" for this suite.
Jan  8 09:45:11.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:45:11.385: INFO: namespace: e2e-tests-projected-cf66w, resource: bindings, ignored listing per whitelist
Jan  8 09:45:11.460: INFO: namespace e2e-tests-projected-cf66w deletion completed in 6.10766907s

â€¢ [SLOW TEST:8.228 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:45:11.460: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-4rnk7
Jan  8 09:45:17.558: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-4rnk7
STEP: checking the pod's current state and verifying that restartCount is present
Jan  8 09:45:17.561: INFO: Initial restart count of pod liveness-http is 0
Jan  8 09:45:33.594: INFO: Restart count of pod e2e-tests-container-probe-4rnk7/liveness-http is now 1 (16.032734633s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:45:33.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-4rnk7" for this suite.
Jan  8 09:45:39.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:45:39.653: INFO: namespace: e2e-tests-container-probe-4rnk7, resource: bindings, ignored listing per whitelist
Jan  8 09:45:39.706: INFO: namespace e2e-tests-container-probe-4rnk7 deletion completed in 6.099461499s

â€¢ [SLOW TEST:28.247 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:45:39.707: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan  8 09:45:39.784: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:45:43.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-954z8" for this suite.
Jan  8 09:45:49.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:45:49.271: INFO: namespace: e2e-tests-init-container-954z8, resource: bindings, ignored listing per whitelist
Jan  8 09:45:49.311: INFO: namespace e2e-tests-init-container-954z8 deletion completed in 6.105049133s

â€¢ [SLOW TEST:9.605 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:45:49.311: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-kxvx
STEP: Creating a pod to test atomic-volume-subpath
Jan  8 09:45:49.400: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-kxvx" in namespace "e2e-tests-subpath-5vnm4" to be "success or failure"
Jan  8 09:45:49.403: INFO: Pod "pod-subpath-test-projected-kxvx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.772488ms
Jan  8 09:45:51.406: INFO: Pod "pod-subpath-test-projected-kxvx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006241939s
Jan  8 09:45:53.410: INFO: Pod "pod-subpath-test-projected-kxvx": Phase="Running", Reason="", readiness=false. Elapsed: 4.010514246s
Jan  8 09:45:55.414: INFO: Pod "pod-subpath-test-projected-kxvx": Phase="Running", Reason="", readiness=false. Elapsed: 6.01464152s
Jan  8 09:45:57.418: INFO: Pod "pod-subpath-test-projected-kxvx": Phase="Running", Reason="", readiness=false. Elapsed: 8.017769936s
Jan  8 09:45:59.422: INFO: Pod "pod-subpath-test-projected-kxvx": Phase="Running", Reason="", readiness=false. Elapsed: 10.021780005s
Jan  8 09:46:01.425: INFO: Pod "pod-subpath-test-projected-kxvx": Phase="Running", Reason="", readiness=false. Elapsed: 12.024861621s
Jan  8 09:46:03.428: INFO: Pod "pod-subpath-test-projected-kxvx": Phase="Running", Reason="", readiness=false. Elapsed: 14.028555583s
Jan  8 09:46:05.432: INFO: Pod "pod-subpath-test-projected-kxvx": Phase="Running", Reason="", readiness=false. Elapsed: 16.032642939s
Jan  8 09:46:07.436: INFO: Pod "pod-subpath-test-projected-kxvx": Phase="Running", Reason="", readiness=false. Elapsed: 18.036564901s
Jan  8 09:46:09.440: INFO: Pod "pod-subpath-test-projected-kxvx": Phase="Running", Reason="", readiness=false. Elapsed: 20.04037775s
Jan  8 09:46:11.444: INFO: Pod "pod-subpath-test-projected-kxvx": Phase="Running", Reason="", readiness=false. Elapsed: 22.044338932s
Jan  8 09:46:13.448: INFO: Pod "pod-subpath-test-projected-kxvx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.048425475s
STEP: Saw pod success
Jan  8 09:46:13.448: INFO: Pod "pod-subpath-test-projected-kxvx" satisfied condition "success or failure"
Jan  8 09:46:13.451: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod pod-subpath-test-projected-kxvx container test-container-subpath-projected-kxvx: <nil>
STEP: delete the pod
Jan  8 09:46:13.470: INFO: Waiting for pod pod-subpath-test-projected-kxvx to disappear
Jan  8 09:46:13.472: INFO: Pod pod-subpath-test-projected-kxvx no longer exists
STEP: Deleting pod pod-subpath-test-projected-kxvx
Jan  8 09:46:13.472: INFO: Deleting pod "pod-subpath-test-projected-kxvx" in namespace "e2e-tests-subpath-5vnm4"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:46:13.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-5vnm4" for this suite.
Jan  8 09:46:19.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:46:19.513: INFO: namespace: e2e-tests-subpath-5vnm4, resource: bindings, ignored listing per whitelist
Jan  8 09:46:19.579: INFO: namespace e2e-tests-subpath-5vnm4 deletion completed in 6.100212675s

â€¢ [SLOW TEST:30.267 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:46:19.579: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  8 09:46:19.661: INFO: Waiting up to 5m0s for pod "downwardapi-volume-401a9a69-132a-11e9-bc05-0a580af40202" in namespace "e2e-tests-downward-api-2gf26" to be "success or failure"
Jan  8 09:46:19.664: INFO: Pod "downwardapi-volume-401a9a69-132a-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.163663ms
Jan  8 09:46:21.668: INFO: Pod "downwardapi-volume-401a9a69-132a-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006921712s
STEP: Saw pod success
Jan  8 09:46:21.668: INFO: Pod "downwardapi-volume-401a9a69-132a-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:46:21.670: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod downwardapi-volume-401a9a69-132a-11e9-bc05-0a580af40202 container client-container: <nil>
STEP: delete the pod
Jan  8 09:46:21.689: INFO: Waiting for pod downwardapi-volume-401a9a69-132a-11e9-bc05-0a580af40202 to disappear
Jan  8 09:46:21.691: INFO: Pod downwardapi-volume-401a9a69-132a-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:46:21.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2gf26" for this suite.
Jan  8 09:46:27.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:46:27.716: INFO: namespace: e2e-tests-downward-api-2gf26, resource: bindings, ignored listing per whitelist
Jan  8 09:46:27.794: INFO: namespace e2e-tests-downward-api-2gf26 deletion completed in 6.099046335s

â€¢ [SLOW TEST:8.215 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:46:27.794: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  8 09:46:27.871: INFO: Waiting up to 5m0s for pod "downwardapi-volume-44ff3bff-132a-11e9-bc05-0a580af40202" in namespace "e2e-tests-downward-api-4r8pq" to be "success or failure"
Jan  8 09:46:27.874: INFO: Pod "downwardapi-volume-44ff3bff-132a-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.813174ms
Jan  8 09:46:29.878: INFO: Pod "downwardapi-volume-44ff3bff-132a-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007051651s
STEP: Saw pod success
Jan  8 09:46:29.878: INFO: Pod "downwardapi-volume-44ff3bff-132a-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:46:29.881: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod downwardapi-volume-44ff3bff-132a-11e9-bc05-0a580af40202 container client-container: <nil>
STEP: delete the pod
Jan  8 09:46:29.899: INFO: Waiting for pod downwardapi-volume-44ff3bff-132a-11e9-bc05-0a580af40202 to disappear
Jan  8 09:46:29.907: INFO: Pod downwardapi-volume-44ff3bff-132a-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:46:29.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4r8pq" for this suite.
Jan  8 09:46:35.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:46:35.976: INFO: namespace: e2e-tests-downward-api-4r8pq, resource: bindings, ignored listing per whitelist
Jan  8 09:46:36.012: INFO: namespace e2e-tests-downward-api-4r8pq deletion completed in 6.101470415s

â€¢ [SLOW TEST:8.218 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:46:36.013: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan  8 09:46:36.106: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:46:36.109: INFO: Number of nodes with available pods: 0
Jan  8 09:46:36.109: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:46:37.113: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:46:37.116: INFO: Number of nodes with available pods: 0
Jan  8 09:46:37.116: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:46:38.113: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:46:38.116: INFO: Number of nodes with available pods: 2
Jan  8 09:46:38.116: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jan  8 09:46:38.133: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:46:38.137: INFO: Number of nodes with available pods: 1
Jan  8 09:46:38.137: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:46:39.141: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:46:39.147: INFO: Number of nodes with available pods: 1
Jan  8 09:46:39.147: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:46:40.142: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 09:46:40.145: INFO: Number of nodes with available pods: 2
Jan  8 09:46:40.145: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-6cgw8, will wait for the garbage collector to delete the pods
Jan  8 09:46:40.211: INFO: Deleting {extensions DaemonSet} daemon-set took: 7.372139ms
Jan  8 09:46:40.311: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.301773ms
Jan  8 09:47:23.314: INFO: Number of nodes with available pods: 0
Jan  8 09:47:23.314: INFO: Number of running nodes: 0, number of available pods: 0
Jan  8 09:47:23.316: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-6cgw8/daemonsets","resourceVersion":"8004"},"items":null}

Jan  8 09:47:23.319: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-6cgw8/pods","resourceVersion":"8004"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:47:23.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-6cgw8" for this suite.
Jan  8 09:47:29.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:47:29.422: INFO: namespace: e2e-tests-daemonsets-6cgw8, resource: bindings, ignored listing per whitelist
Jan  8 09:47:29.432: INFO: namespace e2e-tests-daemonsets-6cgw8 deletion completed in 6.100572014s

â€¢ [SLOW TEST:53.420 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:47:29.432: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Jan  8 09:48:00.047: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:48:00.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-l4xk9" for this suite.
Jan  8 09:48:06.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:48:06.144: INFO: namespace: e2e-tests-gc-l4xk9, resource: bindings, ignored listing per whitelist
Jan  8 09:48:06.151: INFO: namespace e2e-tests-gc-l4xk9 deletion completed in 6.100620019s

â€¢ [SLOW TEST:36.719 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:48:06.152: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-7fa04acc-132a-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume secrets
Jan  8 09:48:06.236: INFO: Waiting up to 5m0s for pod "pod-secrets-7fa0d4d4-132a-11e9-bc05-0a580af40202" in namespace "e2e-tests-secrets-76r5v" to be "success or failure"
Jan  8 09:48:06.240: INFO: Pod "pod-secrets-7fa0d4d4-132a-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.261812ms
Jan  8 09:48:08.243: INFO: Pod "pod-secrets-7fa0d4d4-132a-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006259219s
STEP: Saw pod success
Jan  8 09:48:08.243: INFO: Pod "pod-secrets-7fa0d4d4-132a-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:48:08.245: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-secrets-7fa0d4d4-132a-11e9-bc05-0a580af40202 container secret-env-test: <nil>
STEP: delete the pod
Jan  8 09:48:08.262: INFO: Waiting for pod pod-secrets-7fa0d4d4-132a-11e9-bc05-0a580af40202 to disappear
Jan  8 09:48:08.265: INFO: Pod pod-secrets-7fa0d4d4-132a-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:48:08.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-76r5v" for this suite.
Jan  8 09:48:14.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:48:14.333: INFO: namespace: e2e-tests-secrets-76r5v, resource: bindings, ignored listing per whitelist
Jan  8 09:48:14.366: INFO: namespace e2e-tests-secrets-76r5v deletion completed in 6.097610363s

â€¢ [SLOW TEST:8.215 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:48:14.367: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:49:14.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-jccqf" for this suite.
Jan  8 09:49:36.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:49:36.520: INFO: namespace: e2e-tests-container-probe-jccqf, resource: bindings, ignored listing per whitelist
Jan  8 09:49:36.549: INFO: namespace e2e-tests-container-probe-jccqf deletion completed in 22.098472298s

â€¢ [SLOW TEST:82.182 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:49:36.549: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan  8 09:49:36.642: INFO: Waiting up to 5m0s for pod "pod-b5837b4e-132a-11e9-bc05-0a580af40202" in namespace "e2e-tests-emptydir-zflls" to be "success or failure"
Jan  8 09:49:36.645: INFO: Pod "pod-b5837b4e-132a-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.738784ms
Jan  8 09:49:38.649: INFO: Pod "pod-b5837b4e-132a-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006294699s
Jan  8 09:49:40.652: INFO: Pod "pod-b5837b4e-132a-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010126058s
Jan  8 09:49:42.656: INFO: Pod "pod-b5837b4e-132a-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013959596s
STEP: Saw pod success
Jan  8 09:49:42.656: INFO: Pod "pod-b5837b4e-132a-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:49:42.659: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-b5837b4e-132a-11e9-bc05-0a580af40202 container test-container: <nil>
STEP: delete the pod
Jan  8 09:49:42.677: INFO: Waiting for pod pod-b5837b4e-132a-11e9-bc05-0a580af40202 to disappear
Jan  8 09:49:42.679: INFO: Pod pod-b5837b4e-132a-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:49:42.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-zflls" for this suite.
Jan  8 09:49:48.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:49:48.702: INFO: namespace: e2e-tests-emptydir-zflls, resource: bindings, ignored listing per whitelist
Jan  8 09:49:48.781: INFO: namespace e2e-tests-emptydir-zflls deletion completed in 6.097964429s

â€¢ [SLOW TEST:12.232 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:49:48.781: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  8 09:49:48.858: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:49:49.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-rxml8" for this suite.
Jan  8 09:49:55.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:49:56.028: INFO: namespace: e2e-tests-custom-resource-definition-rxml8, resource: bindings, ignored listing per whitelist
Jan  8 09:49:56.029: INFO: namespace e2e-tests-custom-resource-definition-rxml8 deletion completed in 6.101193332s

â€¢ [SLOW TEST:7.248 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:49:56.030: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-ppdr
STEP: Creating a pod to test atomic-volume-subpath
Jan  8 09:49:56.112: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-ppdr" in namespace "e2e-tests-subpath-8c7l6" to be "success or failure"
Jan  8 09:49:56.115: INFO: Pod "pod-subpath-test-configmap-ppdr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.855699ms
Jan  8 09:49:58.119: INFO: Pod "pod-subpath-test-configmap-ppdr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006855557s
Jan  8 09:50:00.123: INFO: Pod "pod-subpath-test-configmap-ppdr": Phase="Running", Reason="", readiness=false. Elapsed: 4.010787s
Jan  8 09:50:02.127: INFO: Pod "pod-subpath-test-configmap-ppdr": Phase="Running", Reason="", readiness=false. Elapsed: 6.014474315s
Jan  8 09:50:04.131: INFO: Pod "pod-subpath-test-configmap-ppdr": Phase="Running", Reason="", readiness=false. Elapsed: 8.018423928s
Jan  8 09:50:06.134: INFO: Pod "pod-subpath-test-configmap-ppdr": Phase="Running", Reason="", readiness=false. Elapsed: 10.022227039s
Jan  8 09:50:08.138: INFO: Pod "pod-subpath-test-configmap-ppdr": Phase="Running", Reason="", readiness=false. Elapsed: 12.026183995s
Jan  8 09:50:10.142: INFO: Pod "pod-subpath-test-configmap-ppdr": Phase="Running", Reason="", readiness=false. Elapsed: 14.029879468s
Jan  8 09:50:12.146: INFO: Pod "pod-subpath-test-configmap-ppdr": Phase="Running", Reason="", readiness=false. Elapsed: 16.033868384s
Jan  8 09:50:14.150: INFO: Pod "pod-subpath-test-configmap-ppdr": Phase="Running", Reason="", readiness=false. Elapsed: 18.037966382s
Jan  8 09:50:16.154: INFO: Pod "pod-subpath-test-configmap-ppdr": Phase="Running", Reason="", readiness=false. Elapsed: 20.041521645s
Jan  8 09:50:18.158: INFO: Pod "pod-subpath-test-configmap-ppdr": Phase="Running", Reason="", readiness=false. Elapsed: 22.045801155s
Jan  8 09:50:20.162: INFO: Pod "pod-subpath-test-configmap-ppdr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.049776598s
STEP: Saw pod success
Jan  8 09:50:20.162: INFO: Pod "pod-subpath-test-configmap-ppdr" satisfied condition "success or failure"
Jan  8 09:50:20.165: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod pod-subpath-test-configmap-ppdr container test-container-subpath-configmap-ppdr: <nil>
STEP: delete the pod
Jan  8 09:50:20.201: INFO: Waiting for pod pod-subpath-test-configmap-ppdr to disappear
Jan  8 09:50:20.207: INFO: Pod pod-subpath-test-configmap-ppdr no longer exists
STEP: Deleting pod pod-subpath-test-configmap-ppdr
Jan  8 09:50:20.207: INFO: Deleting pod "pod-subpath-test-configmap-ppdr" in namespace "e2e-tests-subpath-8c7l6"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:50:20.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-8c7l6" for this suite.
Jan  8 09:50:26.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:50:26.298: INFO: namespace: e2e-tests-subpath-8c7l6, resource: bindings, ignored listing per whitelist
Jan  8 09:50:26.320: INFO: namespace e2e-tests-subpath-8c7l6 deletion completed in 6.103826312s

â€¢ [SLOW TEST:30.291 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:50:26.321: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  8 09:50:26.404: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d32c9396-132a-11e9-bc05-0a580af40202" in namespace "e2e-tests-downward-api-64lrh" to be "success or failure"
Jan  8 09:50:26.406: INFO: Pod "downwardapi-volume-d32c9396-132a-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.695947ms
Jan  8 09:50:28.410: INFO: Pod "downwardapi-volume-d32c9396-132a-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006256258s
STEP: Saw pod success
Jan  8 09:50:28.410: INFO: Pod "downwardapi-volume-d32c9396-132a-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:50:28.412: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod downwardapi-volume-d32c9396-132a-11e9-bc05-0a580af40202 container client-container: <nil>
STEP: delete the pod
Jan  8 09:50:28.433: INFO: Waiting for pod downwardapi-volume-d32c9396-132a-11e9-bc05-0a580af40202 to disappear
Jan  8 09:50:28.435: INFO: Pod downwardapi-volume-d32c9396-132a-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:50:28.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-64lrh" for this suite.
Jan  8 09:50:34.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:50:34.506: INFO: namespace: e2e-tests-downward-api-64lrh, resource: bindings, ignored listing per whitelist
Jan  8 09:50:34.544: INFO: namespace e2e-tests-downward-api-64lrh deletion completed in 6.105129734s

â€¢ [SLOW TEST:8.224 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:50:34.544: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  8 09:50:34.624: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jan  8 09:50:34.632: INFO: Number of nodes with available pods: 0
Jan  8 09:50:34.632: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jan  8 09:50:34.652: INFO: Number of nodes with available pods: 0
Jan  8 09:50:34.652: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:50:35.656: INFO: Number of nodes with available pods: 0
Jan  8 09:50:35.656: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:50:36.656: INFO: Number of nodes with available pods: 1
Jan  8 09:50:36.656: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jan  8 09:50:36.673: INFO: Number of nodes with available pods: 1
Jan  8 09:50:36.673: INFO: Number of running nodes: 0, number of available pods: 1
Jan  8 09:50:37.676: INFO: Number of nodes with available pods: 0
Jan  8 09:50:37.676: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jan  8 09:50:37.688: INFO: Number of nodes with available pods: 0
Jan  8 09:50:37.688: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:50:38.694: INFO: Number of nodes with available pods: 0
Jan  8 09:50:38.694: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:50:39.691: INFO: Number of nodes with available pods: 0
Jan  8 09:50:39.691: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:50:40.691: INFO: Number of nodes with available pods: 0
Jan  8 09:50:40.691: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:50:41.691: INFO: Number of nodes with available pods: 0
Jan  8 09:50:41.691: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:50:42.692: INFO: Number of nodes with available pods: 0
Jan  8 09:50:42.692: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:50:43.691: INFO: Number of nodes with available pods: 0
Jan  8 09:50:43.691: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:50:44.691: INFO: Number of nodes with available pods: 0
Jan  8 09:50:44.691: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:50:45.691: INFO: Number of nodes with available pods: 0
Jan  8 09:50:45.691: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:50:46.691: INFO: Number of nodes with available pods: 0
Jan  8 09:50:46.691: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:50:47.691: INFO: Number of nodes with available pods: 0
Jan  8 09:50:47.691: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:50:48.692: INFO: Number of nodes with available pods: 0
Jan  8 09:50:48.692: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:50:49.691: INFO: Number of nodes with available pods: 0
Jan  8 09:50:49.691: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:50:50.691: INFO: Number of nodes with available pods: 0
Jan  8 09:50:50.691: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:50:51.691: INFO: Number of nodes with available pods: 0
Jan  8 09:50:51.691: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:50:52.691: INFO: Number of nodes with available pods: 0
Jan  8 09:50:52.691: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:50:53.692: INFO: Number of nodes with available pods: 0
Jan  8 09:50:53.692: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:50:54.692: INFO: Number of nodes with available pods: 0
Jan  8 09:50:54.692: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:50:55.691: INFO: Number of nodes with available pods: 0
Jan  8 09:50:55.691: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:50:56.691: INFO: Number of nodes with available pods: 0
Jan  8 09:50:56.692: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:50:57.691: INFO: Number of nodes with available pods: 0
Jan  8 09:50:57.692: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:50:58.692: INFO: Number of nodes with available pods: 0
Jan  8 09:50:58.692: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:50:59.692: INFO: Number of nodes with available pods: 0
Jan  8 09:50:59.692: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:51:00.692: INFO: Number of nodes with available pods: 0
Jan  8 09:51:00.692: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:51:01.691: INFO: Number of nodes with available pods: 0
Jan  8 09:51:01.691: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:51:02.691: INFO: Number of nodes with available pods: 0
Jan  8 09:51:02.691: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:51:03.691: INFO: Number of nodes with available pods: 0
Jan  8 09:51:03.691: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:51:04.691: INFO: Number of nodes with available pods: 0
Jan  8 09:51:04.691: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:51:05.691: INFO: Number of nodes with available pods: 0
Jan  8 09:51:05.692: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:51:06.692: INFO: Number of nodes with available pods: 0
Jan  8 09:51:06.692: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:51:07.691: INFO: Number of nodes with available pods: 0
Jan  8 09:51:07.691: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:51:08.691: INFO: Number of nodes with available pods: 0
Jan  8 09:51:08.691: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:51:09.691: INFO: Number of nodes with available pods: 0
Jan  8 09:51:09.691: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:51:10.691: INFO: Number of nodes with available pods: 0
Jan  8 09:51:10.691: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 09:51:11.693: INFO: Number of nodes with available pods: 1
Jan  8 09:51:11.693: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-htdds, will wait for the garbage collector to delete the pods
Jan  8 09:51:11.758: INFO: Deleting {extensions DaemonSet} daemon-set took: 6.103269ms
Jan  8 09:51:11.859: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.236884ms
Jan  8 09:51:47.461: INFO: Number of nodes with available pods: 0
Jan  8 09:51:47.461: INFO: Number of running nodes: 0, number of available pods: 0
Jan  8 09:51:47.464: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-htdds/daemonsets","resourceVersion":"8682"},"items":null}

Jan  8 09:51:47.467: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-htdds/pods","resourceVersion":"8682"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:51:47.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-htdds" for this suite.
Jan  8 09:51:53.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:51:53.528: INFO: namespace: e2e-tests-daemonsets-htdds, resource: bindings, ignored listing per whitelist
Jan  8 09:51:53.585: INFO: namespace e2e-tests-daemonsets-htdds deletion completed in 6.099190174s

â€¢ [SLOW TEST:79.041 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:51:53.586: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-072ffd20-132b-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume configMaps
Jan  8 09:51:53.671: INFO: Waiting up to 5m0s for pod "pod-configmaps-073084b9-132b-11e9-bc05-0a580af40202" in namespace "e2e-tests-configmap-6b2pg" to be "success or failure"
Jan  8 09:51:53.676: INFO: Pod "pod-configmaps-073084b9-132b-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.642028ms
Jan  8 09:51:55.679: INFO: Pod "pod-configmaps-073084b9-132b-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008389862s
STEP: Saw pod success
Jan  8 09:51:55.680: INFO: Pod "pod-configmaps-073084b9-132b-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:51:55.682: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod pod-configmaps-073084b9-132b-11e9-bc05-0a580af40202 container configmap-volume-test: <nil>
STEP: delete the pod
Jan  8 09:51:55.704: INFO: Waiting for pod pod-configmaps-073084b9-132b-11e9-bc05-0a580af40202 to disappear
Jan  8 09:51:55.712: INFO: Pod pod-configmaps-073084b9-132b-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:51:55.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6b2pg" for this suite.
Jan  8 09:52:01.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:52:01.763: INFO: namespace: e2e-tests-configmap-6b2pg, resource: bindings, ignored listing per whitelist
Jan  8 09:52:01.818: INFO: namespace e2e-tests-configmap-6b2pg deletion completed in 6.100483612s

â€¢ [SLOW TEST:8.232 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:52:01.818: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan  8 09:52:01.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-tfkp4'
Jan  8 09:52:01.986: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan  8 09:52:01.986: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Jan  8 09:52:01.990: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Jan  8 09:52:01.998: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Jan  8 09:52:02.012: INFO: scanned /root for discovery docs: <nil>
Jan  8 09:52:02.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-tfkp4'
Jan  8 09:52:17.785: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan  8 09:52:17.785: INFO: stdout: "Created e2e-test-nginx-rc-94f5858ea2dc6fc0d03f11c6daf492ee\nScaling up e2e-test-nginx-rc-94f5858ea2dc6fc0d03f11c6daf492ee from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-94f5858ea2dc6fc0d03f11c6daf492ee up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-94f5858ea2dc6fc0d03f11c6daf492ee to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Jan  8 09:52:17.785: INFO: stdout: "Created e2e-test-nginx-rc-94f5858ea2dc6fc0d03f11c6daf492ee\nScaling up e2e-test-nginx-rc-94f5858ea2dc6fc0d03f11c6daf492ee from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-94f5858ea2dc6fc0d03f11c6daf492ee up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-94f5858ea2dc6fc0d03f11c6daf492ee to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Jan  8 09:52:17.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-tfkp4'
Jan  8 09:52:17.874: INFO: stderr: ""
Jan  8 09:52:17.874: INFO: stdout: "e2e-test-nginx-rc-94f5858ea2dc6fc0d03f11c6daf492ee-4phn4 "
Jan  8 09:52:17.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods e2e-test-nginx-rc-94f5858ea2dc6fc0d03f11c6daf492ee-4phn4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tfkp4'
Jan  8 09:52:17.960: INFO: stderr: ""
Jan  8 09:52:17.960: INFO: stdout: "true"
Jan  8 09:52:17.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods e2e-test-nginx-rc-94f5858ea2dc6fc0d03f11c6daf492ee-4phn4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tfkp4'
Jan  8 09:52:18.047: INFO: stderr: ""
Jan  8 09:52:18.047: INFO: stdout: "nginx:1.14-alpine"
Jan  8 09:52:18.047: INFO: e2e-test-nginx-rc-94f5858ea2dc6fc0d03f11c6daf492ee-4phn4 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Jan  8 09:52:18.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-tfkp4'
Jan  8 09:52:18.143: INFO: stderr: ""
Jan  8 09:52:18.143: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:52:18.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tfkp4" for this suite.
Jan  8 09:52:24.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:52:24.184: INFO: namespace: e2e-tests-kubectl-tfkp4, resource: bindings, ignored listing per whitelist
Jan  8 09:52:24.251: INFO: namespace e2e-tests-kubectl-tfkp4 deletion completed in 6.102272498s

â€¢ [SLOW TEST:22.433 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:52:24.252: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-1977cbb3-132b-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume configMaps
Jan  8 09:52:24.341: INFO: Waiting up to 5m0s for pod "pod-configmaps-1978553c-132b-11e9-bc05-0a580af40202" in namespace "e2e-tests-configmap-5w92n" to be "success or failure"
Jan  8 09:52:24.344: INFO: Pod "pod-configmaps-1978553c-132b-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.879325ms
Jan  8 09:52:26.347: INFO: Pod "pod-configmaps-1978553c-132b-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006475474s
STEP: Saw pod success
Jan  8 09:52:26.347: INFO: Pod "pod-configmaps-1978553c-132b-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:52:26.350: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-configmaps-1978553c-132b-11e9-bc05-0a580af40202 container configmap-volume-test: <nil>
STEP: delete the pod
Jan  8 09:52:26.366: INFO: Waiting for pod pod-configmaps-1978553c-132b-11e9-bc05-0a580af40202 to disappear
Jan  8 09:52:26.369: INFO: Pod pod-configmaps-1978553c-132b-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:52:26.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5w92n" for this suite.
Jan  8 09:52:32.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:52:32.471: INFO: namespace: e2e-tests-configmap-5w92n, resource: bindings, ignored listing per whitelist
Jan  8 09:52:32.473: INFO: namespace e2e-tests-configmap-5w92n deletion completed in 6.100865263s

â€¢ [SLOW TEST:8.222 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:52:32.474: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-jf8fz
I0108 09:52:32.547262      16 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-jf8fz, replica count: 1
I0108 09:52:33.597700      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0108 09:52:34.598036      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan  8 09:52:34.712: INFO: Created: latency-svc-jhzwb
Jan  8 09:52:34.722: INFO: Got endpoints: latency-svc-jhzwb [23.852302ms]
Jan  8 09:52:34.739: INFO: Created: latency-svc-8kxld
Jan  8 09:52:34.744: INFO: Got endpoints: latency-svc-8kxld [22.3127ms]
Jan  8 09:52:34.755: INFO: Created: latency-svc-g96p6
Jan  8 09:52:34.761: INFO: Got endpoints: latency-svc-g96p6 [37.894246ms]
Jan  8 09:52:34.771: INFO: Created: latency-svc-75gfs
Jan  8 09:52:34.776: INFO: Got endpoints: latency-svc-75gfs [53.044824ms]
Jan  8 09:52:34.791: INFO: Created: latency-svc-bf5bj
Jan  8 09:52:34.797: INFO: Got endpoints: latency-svc-bf5bj [73.776528ms]
Jan  8 09:52:34.816: INFO: Created: latency-svc-zdnnx
Jan  8 09:52:34.819: INFO: Got endpoints: latency-svc-zdnnx [97.019406ms]
Jan  8 09:52:34.833: INFO: Created: latency-svc-m5bbf
Jan  8 09:52:34.835: INFO: Got endpoints: latency-svc-m5bbf [112.901315ms]
Jan  8 09:52:34.850: INFO: Created: latency-svc-mv5f7
Jan  8 09:52:34.850: INFO: Got endpoints: latency-svc-mv5f7 [127.379483ms]
Jan  8 09:52:34.860: INFO: Created: latency-svc-56gqk
Jan  8 09:52:34.866: INFO: Got endpoints: latency-svc-56gqk [142.85504ms]
Jan  8 09:52:34.879: INFO: Created: latency-svc-8rxqt
Jan  8 09:52:34.885: INFO: Got endpoints: latency-svc-8rxqt [161.639375ms]
Jan  8 09:52:34.899: INFO: Created: latency-svc-xfx29
Jan  8 09:52:34.904: INFO: Got endpoints: latency-svc-xfx29 [180.871282ms]
Jan  8 09:52:34.923: INFO: Created: latency-svc-7z24f
Jan  8 09:52:34.926: INFO: Got endpoints: latency-svc-7z24f [201.718766ms]
Jan  8 09:52:34.942: INFO: Created: latency-svc-l7bvp
Jan  8 09:52:34.963: INFO: Got endpoints: latency-svc-l7bvp [239.159205ms]
Jan  8 09:52:34.975: INFO: Created: latency-svc-h9gjh
Jan  8 09:52:34.996: INFO: Created: latency-svc-75vxf
Jan  8 09:52:34.998: INFO: Got endpoints: latency-svc-h9gjh [274.366342ms]
Jan  8 09:52:35.007: INFO: Got endpoints: latency-svc-75vxf [284.40151ms]
Jan  8 09:52:35.016: INFO: Created: latency-svc-vqxf7
Jan  8 09:52:35.024: INFO: Got endpoints: latency-svc-vqxf7 [301.914974ms]
Jan  8 09:52:35.037: INFO: Created: latency-svc-mwrtb
Jan  8 09:52:35.041: INFO: Got endpoints: latency-svc-mwrtb [296.351959ms]
Jan  8 09:52:35.054: INFO: Created: latency-svc-7f7wz
Jan  8 09:52:35.060: INFO: Got endpoints: latency-svc-7f7wz [298.155073ms]
Jan  8 09:52:35.073: INFO: Created: latency-svc-bc4vq
Jan  8 09:52:35.075: INFO: Got endpoints: latency-svc-bc4vq [298.728721ms]
Jan  8 09:52:35.082: INFO: Created: latency-svc-mfbwg
Jan  8 09:52:35.087: INFO: Got endpoints: latency-svc-mfbwg [290.3208ms]
Jan  8 09:52:35.098: INFO: Created: latency-svc-scmbj
Jan  8 09:52:35.103: INFO: Got endpoints: latency-svc-scmbj [283.876595ms]
Jan  8 09:52:35.123: INFO: Created: latency-svc-bxpc4
Jan  8 09:52:35.132: INFO: Got endpoints: latency-svc-bxpc4 [296.756859ms]
Jan  8 09:52:35.153: INFO: Created: latency-svc-vr2ng
Jan  8 09:52:35.156: INFO: Got endpoints: latency-svc-vr2ng [305.688347ms]
Jan  8 09:52:35.168: INFO: Created: latency-svc-jlm9x
Jan  8 09:52:35.172: INFO: Got endpoints: latency-svc-jlm9x [305.751067ms]
Jan  8 09:52:35.186: INFO: Created: latency-svc-flzzb
Jan  8 09:52:35.190: INFO: Got endpoints: latency-svc-flzzb [304.660548ms]
Jan  8 09:52:35.205: INFO: Created: latency-svc-6v27c
Jan  8 09:52:35.208: INFO: Got endpoints: latency-svc-6v27c [303.939787ms]
Jan  8 09:52:35.226: INFO: Created: latency-svc-dl4zh
Jan  8 09:52:35.230: INFO: Got endpoints: latency-svc-dl4zh [304.087762ms]
Jan  8 09:52:35.241: INFO: Created: latency-svc-llz47
Jan  8 09:52:35.246: INFO: Got endpoints: latency-svc-llz47 [283.182614ms]
Jan  8 09:52:35.273: INFO: Created: latency-svc-l7vk6
Jan  8 09:52:35.274: INFO: Got endpoints: latency-svc-l7vk6 [275.501984ms]
Jan  8 09:52:35.287: INFO: Created: latency-svc-cj9zd
Jan  8 09:52:35.290: INFO: Got endpoints: latency-svc-cj9zd [283.064668ms]
Jan  8 09:52:35.333: INFO: Created: latency-svc-m4z5s
Jan  8 09:52:35.333: INFO: Got endpoints: latency-svc-m4z5s [308.744382ms]
Jan  8 09:52:35.354: INFO: Created: latency-svc-btqn6
Jan  8 09:52:35.359: INFO: Got endpoints: latency-svc-btqn6 [318.361409ms]
Jan  8 09:52:35.376: INFO: Created: latency-svc-c75xk
Jan  8 09:52:35.381: INFO: Got endpoints: latency-svc-c75xk [321.741354ms]
Jan  8 09:52:35.392: INFO: Created: latency-svc-5gtqt
Jan  8 09:52:35.401: INFO: Got endpoints: latency-svc-5gtqt [325.950031ms]
Jan  8 09:52:35.406: INFO: Created: latency-svc-q4xnq
Jan  8 09:52:35.415: INFO: Got endpoints: latency-svc-q4xnq [327.898286ms]
Jan  8 09:52:35.425: INFO: Created: latency-svc-rnvlz
Jan  8 09:52:35.432: INFO: Got endpoints: latency-svc-rnvlz [328.258244ms]
Jan  8 09:52:35.449: INFO: Created: latency-svc-cqw7n
Jan  8 09:52:35.452: INFO: Got endpoints: latency-svc-cqw7n [319.48843ms]
Jan  8 09:52:35.471: INFO: Created: latency-svc-244m7
Jan  8 09:52:35.472: INFO: Got endpoints: latency-svc-244m7 [316.30451ms]
Jan  8 09:52:35.489: INFO: Created: latency-svc-nnndb
Jan  8 09:52:35.491: INFO: Got endpoints: latency-svc-nnndb [319.230662ms]
Jan  8 09:52:35.518: INFO: Created: latency-svc-4wsx7
Jan  8 09:52:35.520: INFO: Got endpoints: latency-svc-4wsx7 [330.477427ms]
Jan  8 09:52:35.532: INFO: Created: latency-svc-zkhb9
Jan  8 09:52:35.536: INFO: Got endpoints: latency-svc-zkhb9 [328.399466ms]
Jan  8 09:52:35.552: INFO: Created: latency-svc-hmcsb
Jan  8 09:52:35.554: INFO: Got endpoints: latency-svc-hmcsb [324.606652ms]
Jan  8 09:52:35.566: INFO: Created: latency-svc-7lw95
Jan  8 09:52:35.570: INFO: Got endpoints: latency-svc-7lw95 [323.204617ms]
Jan  8 09:52:35.581: INFO: Created: latency-svc-w9dzj
Jan  8 09:52:35.595: INFO: Got endpoints: latency-svc-w9dzj [320.799748ms]
Jan  8 09:52:35.600: INFO: Created: latency-svc-frv5c
Jan  8 09:52:35.604: INFO: Got endpoints: latency-svc-frv5c [313.467741ms]
Jan  8 09:52:35.618: INFO: Created: latency-svc-zbxp7
Jan  8 09:52:35.623: INFO: Got endpoints: latency-svc-zbxp7 [289.566814ms]
Jan  8 09:52:35.636: INFO: Created: latency-svc-7bzht
Jan  8 09:52:35.639: INFO: Got endpoints: latency-svc-7bzht [280.059212ms]
Jan  8 09:52:35.657: INFO: Created: latency-svc-2dfzp
Jan  8 09:52:35.661: INFO: Got endpoints: latency-svc-2dfzp [279.401501ms]
Jan  8 09:52:35.686: INFO: Created: latency-svc-8t8mc
Jan  8 09:52:35.692: INFO: Got endpoints: latency-svc-8t8mc [291.340349ms]
Jan  8 09:52:35.707: INFO: Created: latency-svc-h29k6
Jan  8 09:52:35.714: INFO: Got endpoints: latency-svc-h29k6 [299.281004ms]
Jan  8 09:52:35.723: INFO: Created: latency-svc-788gm
Jan  8 09:52:35.739: INFO: Created: latency-svc-7jz6v
Jan  8 09:52:35.758: INFO: Created: latency-svc-dggjf
Jan  8 09:52:35.765: INFO: Got endpoints: latency-svc-788gm [333.167812ms]
Jan  8 09:52:35.772: INFO: Created: latency-svc-7tg49
Jan  8 09:52:35.787: INFO: Created: latency-svc-pdrtr
Jan  8 09:52:35.801: INFO: Created: latency-svc-vp4k2
Jan  8 09:52:35.817: INFO: Got endpoints: latency-svc-7jz6v [365.427386ms]
Jan  8 09:52:35.819: INFO: Created: latency-svc-mlgqd
Jan  8 09:52:35.836: INFO: Created: latency-svc-tw8rr
Jan  8 09:52:35.852: INFO: Created: latency-svc-f4fxl
Jan  8 09:52:36.000: INFO: Created: latency-svc-bg5fd
Jan  8 09:52:36.001: INFO: Got endpoints: latency-svc-7tg49 [510.008484ms]
Jan  8 09:52:36.002: INFO: Got endpoints: latency-svc-dggjf [529.435345ms]
Jan  8 09:52:36.002: INFO: Got endpoints: latency-svc-pdrtr [481.045734ms]
Jan  8 09:52:36.014: INFO: Got endpoints: latency-svc-vp4k2 [477.396766ms]
Jan  8 09:52:36.022: INFO: Created: latency-svc-s7rqb
Jan  8 09:52:36.035: INFO: Created: latency-svc-f76pl
Jan  8 09:52:36.047: INFO: Created: latency-svc-2vsxz
Jan  8 09:52:36.062: INFO: Created: latency-svc-hxqjk
Jan  8 09:52:36.065: INFO: Got endpoints: latency-svc-mlgqd [510.643621ms]
Jan  8 09:52:36.076: INFO: Created: latency-svc-c8qlb
Jan  8 09:52:36.104: INFO: Created: latency-svc-s65ng
Jan  8 09:52:36.115: INFO: Created: latency-svc-5hvfc
Jan  8 09:52:36.117: INFO: Got endpoints: latency-svc-f4fxl [521.972929ms]
Jan  8 09:52:36.156: INFO: Created: latency-svc-bnpvp
Jan  8 09:52:36.166: INFO: Got endpoints: latency-svc-tw8rr [596.290525ms]
Jan  8 09:52:36.174: INFO: Created: latency-svc-7qw6v
Jan  8 09:52:36.189: INFO: Created: latency-svc-vchcs
Jan  8 09:52:36.204: INFO: Created: latency-svc-mddc4
Jan  8 09:52:36.223: INFO: Got endpoints: latency-svc-bg5fd [619.200028ms]
Jan  8 09:52:36.225: INFO: Created: latency-svc-8bddv
Jan  8 09:52:36.239: INFO: Created: latency-svc-hvwm8
Jan  8 09:52:36.259: INFO: Created: latency-svc-krs6r
Jan  8 09:52:36.266: INFO: Got endpoints: latency-svc-s7rqb [643.370215ms]
Jan  8 09:52:36.288: INFO: Created: latency-svc-cw2nd
Jan  8 09:52:36.296: INFO: Created: latency-svc-m568z
Jan  8 09:52:36.315: INFO: Got endpoints: latency-svc-f76pl [676.160613ms]
Jan  8 09:52:36.343: INFO: Created: latency-svc-6gdh9
Jan  8 09:52:36.365: INFO: Got endpoints: latency-svc-2vsxz [704.010042ms]
Jan  8 09:52:36.381: INFO: Created: latency-svc-vhcb6
Jan  8 09:52:36.415: INFO: Got endpoints: latency-svc-hxqjk [722.753359ms]
Jan  8 09:52:36.432: INFO: Created: latency-svc-qvhhd
Jan  8 09:52:36.465: INFO: Got endpoints: latency-svc-c8qlb [751.215829ms]
Jan  8 09:52:36.483: INFO: Created: latency-svc-mzqlc
Jan  8 09:52:36.515: INFO: Got endpoints: latency-svc-s65ng [750.221915ms]
Jan  8 09:52:36.533: INFO: Created: latency-svc-7r4jw
Jan  8 09:52:36.565: INFO: Got endpoints: latency-svc-5hvfc [747.669514ms]
Jan  8 09:52:36.583: INFO: Created: latency-svc-sbhkf
Jan  8 09:52:36.615: INFO: Got endpoints: latency-svc-bnpvp [613.791023ms]
Jan  8 09:52:36.633: INFO: Created: latency-svc-4swcv
Jan  8 09:52:36.664: INFO: Got endpoints: latency-svc-7qw6v [662.489025ms]
Jan  8 09:52:36.683: INFO: Created: latency-svc-h4lt9
Jan  8 09:52:36.715: INFO: Got endpoints: latency-svc-vchcs [713.247266ms]
Jan  8 09:52:36.732: INFO: Created: latency-svc-blk95
Jan  8 09:52:36.765: INFO: Got endpoints: latency-svc-mddc4 [751.000281ms]
Jan  8 09:52:36.782: INFO: Created: latency-svc-j9jbr
Jan  8 09:52:36.815: INFO: Got endpoints: latency-svc-8bddv [749.535605ms]
Jan  8 09:52:36.834: INFO: Created: latency-svc-zb5jw
Jan  8 09:52:36.868: INFO: Got endpoints: latency-svc-hvwm8 [751.140535ms]
Jan  8 09:52:36.903: INFO: Created: latency-svc-tdq74
Jan  8 09:52:36.915: INFO: Got endpoints: latency-svc-krs6r [748.629756ms]
Jan  8 09:52:36.930: INFO: Created: latency-svc-d8cds
Jan  8 09:52:36.965: INFO: Got endpoints: latency-svc-cw2nd [741.5772ms]
Jan  8 09:52:36.986: INFO: Created: latency-svc-xpzk6
Jan  8 09:52:37.015: INFO: Got endpoints: latency-svc-m568z [749.236864ms]
Jan  8 09:52:37.039: INFO: Created: latency-svc-j5nxb
Jan  8 09:52:37.065: INFO: Got endpoints: latency-svc-6gdh9 [749.506534ms]
Jan  8 09:52:37.083: INFO: Created: latency-svc-mkdwp
Jan  8 09:52:37.114: INFO: Got endpoints: latency-svc-vhcb6 [749.516523ms]
Jan  8 09:52:37.131: INFO: Created: latency-svc-pdwcn
Jan  8 09:52:37.168: INFO: Got endpoints: latency-svc-qvhhd [753.275984ms]
Jan  8 09:52:37.191: INFO: Created: latency-svc-nr2r6
Jan  8 09:52:37.216: INFO: Got endpoints: latency-svc-mzqlc [750.020828ms]
Jan  8 09:52:37.232: INFO: Created: latency-svc-8xqhl
Jan  8 09:52:37.264: INFO: Got endpoints: latency-svc-7r4jw [749.127315ms]
Jan  8 09:52:37.281: INFO: Created: latency-svc-pvlfb
Jan  8 09:52:37.314: INFO: Got endpoints: latency-svc-sbhkf [749.099801ms]
Jan  8 09:52:37.332: INFO: Created: latency-svc-mt4dm
Jan  8 09:52:37.365: INFO: Got endpoints: latency-svc-4swcv [749.573098ms]
Jan  8 09:52:37.380: INFO: Created: latency-svc-92sz7
Jan  8 09:52:37.414: INFO: Got endpoints: latency-svc-h4lt9 [750.068532ms]
Jan  8 09:52:37.431: INFO: Created: latency-svc-d8ndm
Jan  8 09:52:37.465: INFO: Got endpoints: latency-svc-blk95 [750.292174ms]
Jan  8 09:52:37.482: INFO: Created: latency-svc-4kb4r
Jan  8 09:52:37.514: INFO: Got endpoints: latency-svc-j9jbr [749.411114ms]
Jan  8 09:52:37.530: INFO: Created: latency-svc-2shz5
Jan  8 09:52:37.565: INFO: Got endpoints: latency-svc-zb5jw [750.388573ms]
Jan  8 09:52:37.582: INFO: Created: latency-svc-vnt2j
Jan  8 09:52:37.614: INFO: Got endpoints: latency-svc-tdq74 [746.415484ms]
Jan  8 09:52:37.631: INFO: Created: latency-svc-kkkxd
Jan  8 09:52:37.664: INFO: Got endpoints: latency-svc-d8cds [749.498501ms]
Jan  8 09:52:37.683: INFO: Created: latency-svc-j2z6k
Jan  8 09:52:37.716: INFO: Got endpoints: latency-svc-xpzk6 [750.793109ms]
Jan  8 09:52:37.735: INFO: Created: latency-svc-4sqw9
Jan  8 09:52:37.765: INFO: Got endpoints: latency-svc-j5nxb [749.38544ms]
Jan  8 09:52:37.782: INFO: Created: latency-svc-qcj4n
Jan  8 09:52:37.815: INFO: Got endpoints: latency-svc-mkdwp [749.700395ms]
Jan  8 09:52:37.840: INFO: Created: latency-svc-l8zpp
Jan  8 09:52:37.865: INFO: Got endpoints: latency-svc-pdwcn [750.216489ms]
Jan  8 09:52:37.883: INFO: Created: latency-svc-jr76h
Jan  8 09:52:37.925: INFO: Got endpoints: latency-svc-nr2r6 [757.091911ms]
Jan  8 09:52:37.963: INFO: Created: latency-svc-cgrc5
Jan  8 09:52:37.977: INFO: Got endpoints: latency-svc-8xqhl [761.645626ms]
Jan  8 09:52:37.997: INFO: Created: latency-svc-hvx9w
Jan  8 09:52:38.015: INFO: Got endpoints: latency-svc-pvlfb [750.488874ms]
Jan  8 09:52:38.032: INFO: Created: latency-svc-xm52t
Jan  8 09:52:38.068: INFO: Got endpoints: latency-svc-mt4dm [754.16299ms]
Jan  8 09:52:38.094: INFO: Created: latency-svc-c68ph
Jan  8 09:52:38.115: INFO: Got endpoints: latency-svc-92sz7 [749.920901ms]
Jan  8 09:52:38.131: INFO: Created: latency-svc-xqdgc
Jan  8 09:52:38.165: INFO: Got endpoints: latency-svc-d8ndm [750.668308ms]
Jan  8 09:52:38.188: INFO: Created: latency-svc-zm8cq
Jan  8 09:52:38.215: INFO: Got endpoints: latency-svc-4kb4r [749.981408ms]
Jan  8 09:52:38.233: INFO: Created: latency-svc-5qlst
Jan  8 09:52:38.264: INFO: Got endpoints: latency-svc-2shz5 [749.935516ms]
Jan  8 09:52:38.281: INFO: Created: latency-svc-2bzh8
Jan  8 09:52:38.316: INFO: Got endpoints: latency-svc-vnt2j [751.337091ms]
Jan  8 09:52:38.333: INFO: Created: latency-svc-s2jhl
Jan  8 09:52:38.365: INFO: Got endpoints: latency-svc-kkkxd [750.708776ms]
Jan  8 09:52:38.380: INFO: Created: latency-svc-mwnk7
Jan  8 09:52:38.415: INFO: Got endpoints: latency-svc-j2z6k [750.42209ms]
Jan  8 09:52:38.433: INFO: Created: latency-svc-dh68k
Jan  8 09:52:38.468: INFO: Got endpoints: latency-svc-4sqw9 [752.270866ms]
Jan  8 09:52:38.488: INFO: Created: latency-svc-w4dpj
Jan  8 09:52:38.515: INFO: Got endpoints: latency-svc-qcj4n [750.334314ms]
Jan  8 09:52:38.536: INFO: Created: latency-svc-xtbz7
Jan  8 09:52:38.565: INFO: Got endpoints: latency-svc-l8zpp [750.315618ms]
Jan  8 09:52:38.594: INFO: Created: latency-svc-ccgxl
Jan  8 09:52:38.615: INFO: Got endpoints: latency-svc-jr76h [750.188125ms]
Jan  8 09:52:38.635: INFO: Created: latency-svc-k97qg
Jan  8 09:52:38.665: INFO: Got endpoints: latency-svc-cgrc5 [739.282232ms]
Jan  8 09:52:38.690: INFO: Created: latency-svc-sb9rw
Jan  8 09:52:38.715: INFO: Got endpoints: latency-svc-hvx9w [737.727832ms]
Jan  8 09:52:38.738: INFO: Created: latency-svc-7mjlf
Jan  8 09:52:38.764: INFO: Got endpoints: latency-svc-xm52t [749.530377ms]
Jan  8 09:52:38.784: INFO: Created: latency-svc-kpp8c
Jan  8 09:52:38.816: INFO: Got endpoints: latency-svc-c68ph [747.44151ms]
Jan  8 09:52:38.835: INFO: Created: latency-svc-nzh8m
Jan  8 09:52:38.865: INFO: Got endpoints: latency-svc-xqdgc [749.871755ms]
Jan  8 09:52:38.885: INFO: Created: latency-svc-c2xw4
Jan  8 09:52:38.916: INFO: Got endpoints: latency-svc-zm8cq [750.366958ms]
Jan  8 09:52:38.939: INFO: Created: latency-svc-vwmhn
Jan  8 09:52:38.965: INFO: Got endpoints: latency-svc-5qlst [749.379107ms]
Jan  8 09:52:38.989: INFO: Created: latency-svc-blpfh
Jan  8 09:52:39.015: INFO: Got endpoints: latency-svc-2bzh8 [750.997982ms]
Jan  8 09:52:39.039: INFO: Created: latency-svc-6qghq
Jan  8 09:52:39.065: INFO: Got endpoints: latency-svc-s2jhl [748.311448ms]
Jan  8 09:52:39.103: INFO: Created: latency-svc-pnrr8
Jan  8 09:52:39.115: INFO: Got endpoints: latency-svc-mwnk7 [749.202602ms]
Jan  8 09:52:39.133: INFO: Created: latency-svc-frn4q
Jan  8 09:52:39.165: INFO: Got endpoints: latency-svc-dh68k [750.16867ms]
Jan  8 09:52:39.194: INFO: Created: latency-svc-kv52r
Jan  8 09:52:39.305: INFO: Got endpoints: latency-svc-w4dpj [836.976897ms]
Jan  8 09:52:39.309: INFO: Got endpoints: latency-svc-xtbz7 [793.698346ms]
Jan  8 09:52:39.322: INFO: Got endpoints: latency-svc-ccgxl [756.525477ms]
Jan  8 09:52:39.348: INFO: Created: latency-svc-896z6
Jan  8 09:52:39.364: INFO: Created: latency-svc-njdrf
Jan  8 09:52:39.368: INFO: Got endpoints: latency-svc-k97qg [753.034124ms]
Jan  8 09:52:39.379: INFO: Created: latency-svc-nt795
Jan  8 09:52:39.390: INFO: Created: latency-svc-z92dk
Jan  8 09:52:39.415: INFO: Got endpoints: latency-svc-sb9rw [750.09172ms]
Jan  8 09:52:39.431: INFO: Created: latency-svc-4c5k6
Jan  8 09:52:39.465: INFO: Got endpoints: latency-svc-7mjlf [749.762515ms]
Jan  8 09:52:39.482: INFO: Created: latency-svc-9hwtc
Jan  8 09:52:39.517: INFO: Got endpoints: latency-svc-kpp8c [752.182284ms]
Jan  8 09:52:39.535: INFO: Created: latency-svc-6c9tw
Jan  8 09:52:39.565: INFO: Got endpoints: latency-svc-nzh8m [749.126737ms]
Jan  8 09:52:39.583: INFO: Created: latency-svc-sw986
Jan  8 09:52:39.615: INFO: Got endpoints: latency-svc-c2xw4 [750.387002ms]
Jan  8 09:52:39.639: INFO: Created: latency-svc-ddzc2
Jan  8 09:52:39.665: INFO: Got endpoints: latency-svc-vwmhn [749.440483ms]
Jan  8 09:52:39.684: INFO: Created: latency-svc-4q5lc
Jan  8 09:52:39.715: INFO: Got endpoints: latency-svc-blpfh [749.912555ms]
Jan  8 09:52:39.734: INFO: Created: latency-svc-mk2v8
Jan  8 09:52:39.765: INFO: Got endpoints: latency-svc-6qghq [749.712971ms]
Jan  8 09:52:39.781: INFO: Created: latency-svc-7q978
Jan  8 09:52:39.815: INFO: Got endpoints: latency-svc-pnrr8 [749.745146ms]
Jan  8 09:52:39.837: INFO: Created: latency-svc-zpdw2
Jan  8 09:52:39.865: INFO: Got endpoints: latency-svc-frn4q [750.596045ms]
Jan  8 09:52:39.882: INFO: Created: latency-svc-ltzcb
Jan  8 09:52:39.916: INFO: Got endpoints: latency-svc-kv52r [750.632768ms]
Jan  8 09:52:39.952: INFO: Created: latency-svc-gq8vj
Jan  8 09:52:39.976: INFO: Got endpoints: latency-svc-896z6 [670.824151ms]
Jan  8 09:52:39.992: INFO: Created: latency-svc-5p8vm
Jan  8 09:52:40.015: INFO: Got endpoints: latency-svc-njdrf [706.077274ms]
Jan  8 09:52:40.032: INFO: Created: latency-svc-67p52
Jan  8 09:52:40.065: INFO: Got endpoints: latency-svc-nt795 [742.999253ms]
Jan  8 09:52:40.084: INFO: Created: latency-svc-pj45h
Jan  8 09:52:40.115: INFO: Got endpoints: latency-svc-z92dk [747.061484ms]
Jan  8 09:52:40.131: INFO: Created: latency-svc-5qj5n
Jan  8 09:52:40.166: INFO: Got endpoints: latency-svc-4c5k6 [751.279049ms]
Jan  8 09:52:40.183: INFO: Created: latency-svc-f95mm
Jan  8 09:52:40.214: INFO: Got endpoints: latency-svc-9hwtc [749.498942ms]
Jan  8 09:52:40.236: INFO: Created: latency-svc-znfrc
Jan  8 09:52:40.265: INFO: Got endpoints: latency-svc-6c9tw [748.901034ms]
Jan  8 09:52:40.300: INFO: Created: latency-svc-vrcb8
Jan  8 09:52:40.315: INFO: Got endpoints: latency-svc-sw986 [749.496321ms]
Jan  8 09:52:40.332: INFO: Created: latency-svc-tkqhk
Jan  8 09:52:40.364: INFO: Got endpoints: latency-svc-ddzc2 [749.297963ms]
Jan  8 09:52:40.386: INFO: Created: latency-svc-pgtkv
Jan  8 09:52:40.415: INFO: Got endpoints: latency-svc-4q5lc [750.10731ms]
Jan  8 09:52:40.432: INFO: Created: latency-svc-l5mkt
Jan  8 09:52:40.465: INFO: Got endpoints: latency-svc-mk2v8 [750.067935ms]
Jan  8 09:52:40.485: INFO: Created: latency-svc-ntbg2
Jan  8 09:52:40.515: INFO: Got endpoints: latency-svc-7q978 [749.704677ms]
Jan  8 09:52:40.532: INFO: Created: latency-svc-lxxvb
Jan  8 09:52:40.564: INFO: Got endpoints: latency-svc-zpdw2 [749.737373ms]
Jan  8 09:52:40.582: INFO: Created: latency-svc-mjs8s
Jan  8 09:52:40.616: INFO: Got endpoints: latency-svc-ltzcb [751.128951ms]
Jan  8 09:52:40.636: INFO: Created: latency-svc-x7xt4
Jan  8 09:52:40.665: INFO: Got endpoints: latency-svc-gq8vj [749.034785ms]
Jan  8 09:52:40.682: INFO: Created: latency-svc-k8fnm
Jan  8 09:52:40.715: INFO: Got endpoints: latency-svc-5p8vm [738.769489ms]
Jan  8 09:52:40.731: INFO: Created: latency-svc-2sg4s
Jan  8 09:52:40.765: INFO: Got endpoints: latency-svc-67p52 [750.304339ms]
Jan  8 09:52:40.783: INFO: Created: latency-svc-bcjln
Jan  8 09:52:40.815: INFO: Got endpoints: latency-svc-pj45h [749.927029ms]
Jan  8 09:52:40.833: INFO: Created: latency-svc-ctjr9
Jan  8 09:52:40.865: INFO: Got endpoints: latency-svc-5qj5n [749.908743ms]
Jan  8 09:52:40.881: INFO: Created: latency-svc-vmj7g
Jan  8 09:52:40.914: INFO: Got endpoints: latency-svc-f95mm [748.448756ms]
Jan  8 09:52:40.932: INFO: Created: latency-svc-m5tqg
Jan  8 09:52:40.965: INFO: Got endpoints: latency-svc-znfrc [750.996027ms]
Jan  8 09:52:40.983: INFO: Created: latency-svc-sfdnt
Jan  8 09:52:41.015: INFO: Got endpoints: latency-svc-vrcb8 [749.869603ms]
Jan  8 09:52:41.032: INFO: Created: latency-svc-4c89j
Jan  8 09:52:41.065: INFO: Got endpoints: latency-svc-tkqhk [750.068489ms]
Jan  8 09:52:41.081: INFO: Created: latency-svc-qp4kx
Jan  8 09:52:41.116: INFO: Got endpoints: latency-svc-pgtkv [751.738507ms]
Jan  8 09:52:41.133: INFO: Created: latency-svc-h4kf2
Jan  8 09:52:41.165: INFO: Got endpoints: latency-svc-l5mkt [749.699847ms]
Jan  8 09:52:41.183: INFO: Created: latency-svc-qgspn
Jan  8 09:52:41.214: INFO: Got endpoints: latency-svc-ntbg2 [749.364371ms]
Jan  8 09:52:41.237: INFO: Created: latency-svc-k7jcs
Jan  8 09:52:41.266: INFO: Got endpoints: latency-svc-lxxvb [750.893141ms]
Jan  8 09:52:41.286: INFO: Created: latency-svc-4rl2q
Jan  8 09:52:41.315: INFO: Got endpoints: latency-svc-mjs8s [750.644741ms]
Jan  8 09:52:41.333: INFO: Created: latency-svc-dvpbx
Jan  8 09:52:41.364: INFO: Got endpoints: latency-svc-x7xt4 [747.948868ms]
Jan  8 09:52:41.382: INFO: Created: latency-svc-tl52q
Jan  8 09:52:41.416: INFO: Got endpoints: latency-svc-k8fnm [751.1985ms]
Jan  8 09:52:41.461: INFO: Created: latency-svc-sbw8g
Jan  8 09:52:41.465: INFO: Got endpoints: latency-svc-2sg4s [749.939068ms]
Jan  8 09:52:41.482: INFO: Created: latency-svc-w8brp
Jan  8 09:52:41.514: INFO: Got endpoints: latency-svc-bcjln [749.079006ms]
Jan  8 09:52:41.531: INFO: Created: latency-svc-pd58n
Jan  8 09:52:41.566: INFO: Got endpoints: latency-svc-ctjr9 [750.902633ms]
Jan  8 09:52:41.581: INFO: Created: latency-svc-qfb5v
Jan  8 09:52:41.614: INFO: Got endpoints: latency-svc-vmj7g [749.141096ms]
Jan  8 09:52:41.631: INFO: Created: latency-svc-5627z
Jan  8 09:52:41.665: INFO: Got endpoints: latency-svc-m5tqg [750.519157ms]
Jan  8 09:52:41.681: INFO: Created: latency-svc-m285b
Jan  8 09:52:41.714: INFO: Got endpoints: latency-svc-sfdnt [748.86157ms]
Jan  8 09:52:41.730: INFO: Created: latency-svc-nvk8n
Jan  8 09:52:41.765: INFO: Got endpoints: latency-svc-4c89j [749.781982ms]
Jan  8 09:52:41.782: INFO: Created: latency-svc-4n7z8
Jan  8 09:52:41.814: INFO: Got endpoints: latency-svc-qp4kx [749.108796ms]
Jan  8 09:52:41.831: INFO: Created: latency-svc-4g8wb
Jan  8 09:52:41.865: INFO: Got endpoints: latency-svc-h4kf2 [748.772136ms]
Jan  8 09:52:41.883: INFO: Created: latency-svc-z5bkk
Jan  8 09:52:41.934: INFO: Got endpoints: latency-svc-qgspn [768.593068ms]
Jan  8 09:52:41.970: INFO: Got endpoints: latency-svc-k7jcs [755.432511ms]
Jan  8 09:52:41.972: INFO: Created: latency-svc-6dnl8
Jan  8 09:52:41.986: INFO: Created: latency-svc-ptl8m
Jan  8 09:52:42.016: INFO: Got endpoints: latency-svc-4rl2q [750.528409ms]
Jan  8 09:52:42.038: INFO: Created: latency-svc-ncxqf
Jan  8 09:52:42.065: INFO: Got endpoints: latency-svc-dvpbx [749.672438ms]
Jan  8 09:52:42.088: INFO: Created: latency-svc-tkcqb
Jan  8 09:52:42.115: INFO: Got endpoints: latency-svc-tl52q [750.170488ms]
Jan  8 09:52:42.132: INFO: Created: latency-svc-pktbb
Jan  8 09:52:42.165: INFO: Got endpoints: latency-svc-sbw8g [748.862326ms]
Jan  8 09:52:42.183: INFO: Created: latency-svc-vsk4k
Jan  8 09:52:42.217: INFO: Got endpoints: latency-svc-w8brp [752.186291ms]
Jan  8 09:52:42.232: INFO: Created: latency-svc-th8kw
Jan  8 09:52:42.266: INFO: Got endpoints: latency-svc-pd58n [751.422566ms]
Jan  8 09:52:42.293: INFO: Created: latency-svc-dtp7t
Jan  8 09:52:42.315: INFO: Got endpoints: latency-svc-qfb5v [749.557559ms]
Jan  8 09:52:42.332: INFO: Created: latency-svc-lq66s
Jan  8 09:52:42.365: INFO: Got endpoints: latency-svc-5627z [750.242544ms]
Jan  8 09:52:42.380: INFO: Created: latency-svc-fq6lw
Jan  8 09:52:42.415: INFO: Got endpoints: latency-svc-m285b [750.091694ms]
Jan  8 09:52:42.433: INFO: Created: latency-svc-xld95
Jan  8 09:52:42.465: INFO: Got endpoints: latency-svc-nvk8n [750.76576ms]
Jan  8 09:52:42.481: INFO: Created: latency-svc-2bsm7
Jan  8 09:52:42.515: INFO: Got endpoints: latency-svc-4n7z8 [749.494961ms]
Jan  8 09:52:42.535: INFO: Created: latency-svc-hzm4h
Jan  8 09:52:42.565: INFO: Got endpoints: latency-svc-4g8wb [750.888073ms]
Jan  8 09:52:42.615: INFO: Got endpoints: latency-svc-z5bkk [749.567336ms]
Jan  8 09:52:42.665: INFO: Got endpoints: latency-svc-6dnl8 [731.484923ms]
Jan  8 09:52:42.715: INFO: Got endpoints: latency-svc-ptl8m [745.341224ms]
Jan  8 09:52:42.765: INFO: Got endpoints: latency-svc-ncxqf [749.009405ms]
Jan  8 09:52:42.815: INFO: Got endpoints: latency-svc-tkcqb [750.021702ms]
Jan  8 09:52:42.865: INFO: Got endpoints: latency-svc-pktbb [750.672506ms]
Jan  8 09:52:42.916: INFO: Got endpoints: latency-svc-vsk4k [750.765347ms]
Jan  8 09:52:42.965: INFO: Got endpoints: latency-svc-th8kw [748.090323ms]
Jan  8 09:52:43.017: INFO: Got endpoints: latency-svc-dtp7t [751.031355ms]
Jan  8 09:52:43.064: INFO: Got endpoints: latency-svc-lq66s [749.141695ms]
Jan  8 09:52:43.115: INFO: Got endpoints: latency-svc-fq6lw [749.791278ms]
Jan  8 09:52:43.165: INFO: Got endpoints: latency-svc-xld95 [750.007428ms]
Jan  8 09:52:43.217: INFO: Got endpoints: latency-svc-2bsm7 [751.749687ms]
Jan  8 09:52:43.265: INFO: Got endpoints: latency-svc-hzm4h [750.369165ms]
Jan  8 09:52:43.265: INFO: Latencies: [22.3127ms 37.894246ms 53.044824ms 73.776528ms 97.019406ms 112.901315ms 127.379483ms 142.85504ms 161.639375ms 180.871282ms 201.718766ms 239.159205ms 274.366342ms 275.501984ms 279.401501ms 280.059212ms 283.064668ms 283.182614ms 283.876595ms 284.40151ms 289.566814ms 290.3208ms 291.340349ms 296.351959ms 296.756859ms 298.155073ms 298.728721ms 299.281004ms 301.914974ms 303.939787ms 304.087762ms 304.660548ms 305.688347ms 305.751067ms 308.744382ms 313.467741ms 316.30451ms 318.361409ms 319.230662ms 319.48843ms 320.799748ms 321.741354ms 323.204617ms 324.606652ms 325.950031ms 327.898286ms 328.258244ms 328.399466ms 330.477427ms 333.167812ms 365.427386ms 477.396766ms 481.045734ms 510.008484ms 510.643621ms 521.972929ms 529.435345ms 596.290525ms 613.791023ms 619.200028ms 643.370215ms 662.489025ms 670.824151ms 676.160613ms 704.010042ms 706.077274ms 713.247266ms 722.753359ms 731.484923ms 737.727832ms 738.769489ms 739.282232ms 741.5772ms 742.999253ms 745.341224ms 746.415484ms 747.061484ms 747.44151ms 747.669514ms 747.948868ms 748.090323ms 748.311448ms 748.448756ms 748.629756ms 748.772136ms 748.86157ms 748.862326ms 748.901034ms 749.009405ms 749.034785ms 749.079006ms 749.099801ms 749.108796ms 749.126737ms 749.127315ms 749.141096ms 749.141695ms 749.202602ms 749.236864ms 749.297963ms 749.364371ms 749.379107ms 749.38544ms 749.411114ms 749.440483ms 749.494961ms 749.496321ms 749.498501ms 749.498942ms 749.506534ms 749.516523ms 749.530377ms 749.535605ms 749.557559ms 749.567336ms 749.573098ms 749.672438ms 749.699847ms 749.700395ms 749.704677ms 749.712971ms 749.737373ms 749.745146ms 749.762515ms 749.781982ms 749.791278ms 749.869603ms 749.871755ms 749.908743ms 749.912555ms 749.920901ms 749.927029ms 749.935516ms 749.939068ms 749.981408ms 750.007428ms 750.020828ms 750.021702ms 750.067935ms 750.068489ms 750.068532ms 750.091694ms 750.09172ms 750.10731ms 750.16867ms 750.170488ms 750.188125ms 750.216489ms 750.221915ms 750.242544ms 750.292174ms 750.304339ms 750.315618ms 750.334314ms 750.366958ms 750.369165ms 750.387002ms 750.388573ms 750.42209ms 750.488874ms 750.519157ms 750.528409ms 750.596045ms 750.632768ms 750.644741ms 750.668308ms 750.672506ms 750.708776ms 750.765347ms 750.76576ms 750.793109ms 750.888073ms 750.893141ms 750.902633ms 750.996027ms 750.997982ms 751.000281ms 751.031355ms 751.128951ms 751.140535ms 751.1985ms 751.215829ms 751.279049ms 751.337091ms 751.422566ms 751.738507ms 751.749687ms 752.182284ms 752.186291ms 752.270866ms 753.034124ms 753.275984ms 754.16299ms 755.432511ms 756.525477ms 757.091911ms 761.645626ms 768.593068ms 793.698346ms 836.976897ms]
Jan  8 09:52:43.265: INFO: 50 %ile: 749.364371ms
Jan  8 09:52:43.265: INFO: 90 %ile: 751.1985ms
Jan  8 09:52:43.265: INFO: 99 %ile: 793.698346ms
Jan  8 09:52:43.265: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:52:43.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-jf8fz" for this suite.
Jan  8 09:52:55.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:52:55.365: INFO: namespace: e2e-tests-svc-latency-jf8fz, resource: bindings, ignored listing per whitelist
Jan  8 09:52:55.458: INFO: namespace e2e-tests-svc-latency-jf8fz deletion completed in 12.189081995s

â€¢ [SLOW TEST:22.985 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:52:55.459: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-n649
STEP: Creating a pod to test atomic-volume-subpath
Jan  8 09:52:55.555: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-n649" in namespace "e2e-tests-subpath-jzdxf" to be "success or failure"
Jan  8 09:52:55.561: INFO: Pod "pod-subpath-test-secret-n649": Phase="Pending", Reason="", readiness=false. Elapsed: 5.716214ms
Jan  8 09:52:57.564: INFO: Pod "pod-subpath-test-secret-n649": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009285135s
Jan  8 09:52:59.568: INFO: Pod "pod-subpath-test-secret-n649": Phase="Running", Reason="", readiness=false. Elapsed: 4.013332316s
Jan  8 09:53:01.573: INFO: Pod "pod-subpath-test-secret-n649": Phase="Running", Reason="", readiness=false. Elapsed: 6.017637258s
Jan  8 09:53:03.576: INFO: Pod "pod-subpath-test-secret-n649": Phase="Running", Reason="", readiness=false. Elapsed: 8.021307064s
Jan  8 09:53:05.580: INFO: Pod "pod-subpath-test-secret-n649": Phase="Running", Reason="", readiness=false. Elapsed: 10.025251811s
Jan  8 09:53:07.584: INFO: Pod "pod-subpath-test-secret-n649": Phase="Running", Reason="", readiness=false. Elapsed: 12.029123056s
Jan  8 09:53:09.588: INFO: Pod "pod-subpath-test-secret-n649": Phase="Running", Reason="", readiness=false. Elapsed: 14.032658214s
Jan  8 09:53:11.591: INFO: Pod "pod-subpath-test-secret-n649": Phase="Running", Reason="", readiness=false. Elapsed: 16.035785796s
Jan  8 09:53:13.595: INFO: Pod "pod-subpath-test-secret-n649": Phase="Running", Reason="", readiness=false. Elapsed: 18.039791483s
Jan  8 09:53:15.602: INFO: Pod "pod-subpath-test-secret-n649": Phase="Running", Reason="", readiness=false. Elapsed: 20.046956874s
Jan  8 09:53:17.606: INFO: Pod "pod-subpath-test-secret-n649": Phase="Running", Reason="", readiness=false. Elapsed: 22.050814056s
Jan  8 09:53:19.610: INFO: Pod "pod-subpath-test-secret-n649": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.054535124s
STEP: Saw pod success
Jan  8 09:53:19.610: INFO: Pod "pod-subpath-test-secret-n649" satisfied condition "success or failure"
Jan  8 09:53:19.613: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-subpath-test-secret-n649 container test-container-subpath-secret-n649: <nil>
STEP: delete the pod
Jan  8 09:53:19.630: INFO: Waiting for pod pod-subpath-test-secret-n649 to disappear
Jan  8 09:53:19.634: INFO: Pod pod-subpath-test-secret-n649 no longer exists
STEP: Deleting pod pod-subpath-test-secret-n649
Jan  8 09:53:19.634: INFO: Deleting pod "pod-subpath-test-secret-n649" in namespace "e2e-tests-subpath-jzdxf"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:53:19.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-jzdxf" for this suite.
Jan  8 09:53:25.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:53:25.689: INFO: namespace: e2e-tests-subpath-jzdxf, resource: bindings, ignored listing per whitelist
Jan  8 09:53:25.740: INFO: namespace e2e-tests-subpath-jzdxf deletion completed in 6.099146274s

â€¢ [SLOW TEST:30.281 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:53:25.741: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan  8 09:53:25.825: INFO: Waiting up to 5m0s for pod "pod-3e1dfbed-132b-11e9-bc05-0a580af40202" in namespace "e2e-tests-emptydir-5xqdf" to be "success or failure"
Jan  8 09:53:25.828: INFO: Pod "pod-3e1dfbed-132b-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.990201ms
Jan  8 09:53:27.831: INFO: Pod "pod-3e1dfbed-132b-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006830562s
STEP: Saw pod success
Jan  8 09:53:27.832: INFO: Pod "pod-3e1dfbed-132b-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:53:27.835: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod pod-3e1dfbed-132b-11e9-bc05-0a580af40202 container test-container: <nil>
STEP: delete the pod
Jan  8 09:53:27.853: INFO: Waiting for pod pod-3e1dfbed-132b-11e9-bc05-0a580af40202 to disappear
Jan  8 09:53:27.856: INFO: Pod pod-3e1dfbed-132b-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:53:27.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5xqdf" for this suite.
Jan  8 09:53:33.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:53:33.890: INFO: namespace: e2e-tests-emptydir-5xqdf, resource: bindings, ignored listing per whitelist
Jan  8 09:53:33.981: INFO: namespace e2e-tests-emptydir-5xqdf deletion completed in 6.120775047s

â€¢ [SLOW TEST:8.240 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:53:33.981: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan  8 09:53:34.060: INFO: Waiting up to 5m0s for pod "pod-4306ac13-132b-11e9-bc05-0a580af40202" in namespace "e2e-tests-emptydir-hr5qh" to be "success or failure"
Jan  8 09:53:34.064: INFO: Pod "pod-4306ac13-132b-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.147368ms
Jan  8 09:53:36.068: INFO: Pod "pod-4306ac13-132b-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008183919s
STEP: Saw pod success
Jan  8 09:53:36.068: INFO: Pod "pod-4306ac13-132b-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:53:36.071: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-4306ac13-132b-11e9-bc05-0a580af40202 container test-container: <nil>
STEP: delete the pod
Jan  8 09:53:36.088: INFO: Waiting for pod pod-4306ac13-132b-11e9-bc05-0a580af40202 to disappear
Jan  8 09:53:36.091: INFO: Pod pod-4306ac13-132b-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:53:36.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hr5qh" for this suite.
Jan  8 09:53:42.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:53:42.189: INFO: namespace: e2e-tests-emptydir-hr5qh, resource: bindings, ignored listing per whitelist
Jan  8 09:53:42.192: INFO: namespace e2e-tests-emptydir-hr5qh deletion completed in 6.096681976s

â€¢ [SLOW TEST:8.211 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:53:42.192: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  8 09:53:42.273: INFO: Waiting up to 5m0s for pod "downwardapi-volume-47ebe5af-132b-11e9-bc05-0a580af40202" in namespace "e2e-tests-projected-mk49c" to be "success or failure"
Jan  8 09:53:42.279: INFO: Pod "downwardapi-volume-47ebe5af-132b-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 5.839601ms
Jan  8 09:53:44.282: INFO: Pod "downwardapi-volume-47ebe5af-132b-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008925649s
STEP: Saw pod success
Jan  8 09:53:44.282: INFO: Pod "downwardapi-volume-47ebe5af-132b-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:53:44.285: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod downwardapi-volume-47ebe5af-132b-11e9-bc05-0a580af40202 container client-container: <nil>
STEP: delete the pod
Jan  8 09:53:44.302: INFO: Waiting for pod downwardapi-volume-47ebe5af-132b-11e9-bc05-0a580af40202 to disappear
Jan  8 09:53:44.305: INFO: Pod downwardapi-volume-47ebe5af-132b-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:53:44.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mk49c" for this suite.
Jan  8 09:53:50.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:53:50.387: INFO: namespace: e2e-tests-projected-mk49c, resource: bindings, ignored listing per whitelist
Jan  8 09:53:50.410: INFO: namespace e2e-tests-projected-mk49c deletion completed in 6.100502397s

â€¢ [SLOW TEST:8.218 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:53:50.410: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan  8 09:53:50.487: INFO: Waiting up to 5m0s for pod "pod-4cd154e4-132b-11e9-bc05-0a580af40202" in namespace "e2e-tests-emptydir-q6zcr" to be "success or failure"
Jan  8 09:53:50.493: INFO: Pod "pod-4cd154e4-132b-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 5.64766ms
Jan  8 09:53:52.497: INFO: Pod "pod-4cd154e4-132b-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009425534s
STEP: Saw pod success
Jan  8 09:53:52.497: INFO: Pod "pod-4cd154e4-132b-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:53:52.499: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-4cd154e4-132b-11e9-bc05-0a580af40202 container test-container: <nil>
STEP: delete the pod
Jan  8 09:53:52.516: INFO: Waiting for pod pod-4cd154e4-132b-11e9-bc05-0a580af40202 to disappear
Jan  8 09:53:52.519: INFO: Pod pod-4cd154e4-132b-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:53:52.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-q6zcr" for this suite.
Jan  8 09:53:58.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:53:58.544: INFO: namespace: e2e-tests-emptydir-q6zcr, resource: bindings, ignored listing per whitelist
Jan  8 09:53:58.625: INFO: namespace e2e-tests-emptydir-q6zcr deletion completed in 6.101559443s

â€¢ [SLOW TEST:8.215 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:53:58.626: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  8 09:53:58.709: INFO: (0) /api/v1/nodes/oltf-408483-kube-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 6.582352ms)
Jan  8 09:53:58.713: INFO: (1) /api/v1/nodes/oltf-408483-kube-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.958438ms)
Jan  8 09:53:58.718: INFO: (2) /api/v1/nodes/oltf-408483-kube-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.236ms)
Jan  8 09:53:58.722: INFO: (3) /api/v1/nodes/oltf-408483-kube-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.078922ms)
Jan  8 09:53:58.725: INFO: (4) /api/v1/nodes/oltf-408483-kube-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.629808ms)
Jan  8 09:53:58.729: INFO: (5) /api/v1/nodes/oltf-408483-kube-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.987048ms)
Jan  8 09:53:58.733: INFO: (6) /api/v1/nodes/oltf-408483-kube-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.478997ms)
Jan  8 09:53:58.737: INFO: (7) /api/v1/nodes/oltf-408483-kube-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.730892ms)
Jan  8 09:53:58.741: INFO: (8) /api/v1/nodes/oltf-408483-kube-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.726462ms)
Jan  8 09:53:58.744: INFO: (9) /api/v1/nodes/oltf-408483-kube-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.894767ms)
Jan  8 09:53:58.748: INFO: (10) /api/v1/nodes/oltf-408483-kube-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.987414ms)
Jan  8 09:53:58.752: INFO: (11) /api/v1/nodes/oltf-408483-kube-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.885015ms)
Jan  8 09:53:58.757: INFO: (12) /api/v1/nodes/oltf-408483-kube-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.192402ms)
Jan  8 09:53:58.760: INFO: (13) /api/v1/nodes/oltf-408483-kube-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.748212ms)
Jan  8 09:53:58.764: INFO: (14) /api/v1/nodes/oltf-408483-kube-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.828605ms)
Jan  8 09:53:58.768: INFO: (15) /api/v1/nodes/oltf-408483-kube-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.175648ms)
Jan  8 09:53:58.772: INFO: (16) /api/v1/nodes/oltf-408483-kube-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.98644ms)
Jan  8 09:53:58.777: INFO: (17) /api/v1/nodes/oltf-408483-kube-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.162698ms)
Jan  8 09:53:58.781: INFO: (18) /api/v1/nodes/oltf-408483-kube-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.132991ms)
Jan  8 09:53:58.785: INFO: (19) /api/v1/nodes/oltf-408483-kube-worker1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.806ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:53:58.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-lb5g4" for this suite.
Jan  8 09:54:04.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:54:04.874: INFO: namespace: e2e-tests-proxy-lb5g4, resource: bindings, ignored listing per whitelist
Jan  8 09:54:04.886: INFO: namespace e2e-tests-proxy-lb5g4 deletion completed in 6.097987324s

â€¢ [SLOW TEST:6.261 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:54:04.886: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan  8 09:54:07.489: INFO: Successfully updated pod "annotationupdate5571e888-132b-11e9-bc05-0a580af40202"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:54:11.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xl7p4" for this suite.
Jan  8 09:54:33.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:54:33.594: INFO: namespace: e2e-tests-downward-api-xl7p4, resource: bindings, ignored listing per whitelist
Jan  8 09:54:33.619: INFO: namespace e2e-tests-downward-api-xl7p4 deletion completed in 22.101356781s

â€¢ [SLOW TEST:28.733 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:54:33.619: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  8 09:54:33.703: INFO: Creating ReplicaSet my-hostname-basic-66946389-132b-11e9-bc05-0a580af40202
Jan  8 09:54:33.710: INFO: Pod name my-hostname-basic-66946389-132b-11e9-bc05-0a580af40202: Found 0 pods out of 1
Jan  8 09:54:38.714: INFO: Pod name my-hostname-basic-66946389-132b-11e9-bc05-0a580af40202: Found 1 pods out of 1
Jan  8 09:54:38.715: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-66946389-132b-11e9-bc05-0a580af40202" is running
Jan  8 09:54:38.717: INFO: Pod "my-hostname-basic-66946389-132b-11e9-bc05-0a580af40202-66q8s" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-08 09:54:33 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-08 09:54:35 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-08 09:54:35 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-08 09:54:33 +0000 UTC Reason: Message:}])
Jan  8 09:54:38.717: INFO: Trying to dial the pod
Jan  8 09:54:43.729: INFO: Controller my-hostname-basic-66946389-132b-11e9-bc05-0a580af40202: Got expected result from replica 1 [my-hostname-basic-66946389-132b-11e9-bc05-0a580af40202-66q8s]: "my-hostname-basic-66946389-132b-11e9-bc05-0a580af40202-66q8s", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:54:43.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-g6glj" for this suite.
Jan  8 09:54:49.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:54:49.791: INFO: namespace: e2e-tests-replicaset-g6glj, resource: bindings, ignored listing per whitelist
Jan  8 09:54:49.833: INFO: namespace e2e-tests-replicaset-g6glj deletion completed in 6.101098025s

â€¢ [SLOW TEST:16.214 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:54:49.834: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan  8 09:54:53.959: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan  8 09:54:53.962: INFO: Pod pod-with-poststart-http-hook still exists
Jan  8 09:54:55.962: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan  8 09:54:55.966: INFO: Pod pod-with-poststart-http-hook still exists
Jan  8 09:54:57.962: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan  8 09:54:57.965: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:54:57.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-dz56j" for this suite.
Jan  8 09:55:19.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:55:20.041: INFO: namespace: e2e-tests-container-lifecycle-hook-dz56j, resource: bindings, ignored listing per whitelist
Jan  8 09:55:20.071: INFO: namespace e2e-tests-container-lifecycle-hook-dz56j deletion completed in 22.101467417s

â€¢ [SLOW TEST:30.237 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:55:20.071: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-824334ca-132b-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume secrets
Jan  8 09:55:20.157: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8243c1ad-132b-11e9-bc05-0a580af40202" in namespace "e2e-tests-projected-q7n2c" to be "success or failure"
Jan  8 09:55:20.160: INFO: Pod "pod-projected-secrets-8243c1ad-132b-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.164307ms
Jan  8 09:55:22.164: INFO: Pod "pod-projected-secrets-8243c1ad-132b-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006751703s
STEP: Saw pod success
Jan  8 09:55:22.164: INFO: Pod "pod-projected-secrets-8243c1ad-132b-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:55:22.167: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod pod-projected-secrets-8243c1ad-132b-11e9-bc05-0a580af40202 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan  8 09:55:22.185: INFO: Waiting for pod pod-projected-secrets-8243c1ad-132b-11e9-bc05-0a580af40202 to disappear
Jan  8 09:55:22.188: INFO: Pod pod-projected-secrets-8243c1ad-132b-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:55:22.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-q7n2c" for this suite.
Jan  8 09:55:28.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:55:28.291: INFO: namespace: e2e-tests-projected-q7n2c, resource: bindings, ignored listing per whitelist
Jan  8 09:55:28.293: INFO: namespace e2e-tests-projected-q7n2c deletion completed in 6.101646655s

â€¢ [SLOW TEST:8.222 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:55:28.293: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-b5sfg
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan  8 09:55:28.365: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan  8 09:55:50.438: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.244.1.102:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-b5sfg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  8 09:55:50.438: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
Jan  8 09:55:50.533: INFO: Found all expected endpoints: [netserver-0]
Jan  8 09:55:50.536: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.244.2.96:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-b5sfg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  8 09:55:50.536: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
Jan  8 09:55:50.628: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:55:50.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-b5sfg" for this suite.
Jan  8 09:56:12.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:56:12.684: INFO: namespace: e2e-tests-pod-network-test-b5sfg, resource: bindings, ignored listing per whitelist
Jan  8 09:56:12.736: INFO: namespace e2e-tests-pod-network-test-b5sfg deletion completed in 22.103760534s

â€¢ [SLOW TEST:44.443 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:56:12.736: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-a1a7577c-132b-11e9-bc05-0a580af40202
Jan  8 09:56:12.820: INFO: Pod name my-hostname-basic-a1a7577c-132b-11e9-bc05-0a580af40202: Found 0 pods out of 1
Jan  8 09:56:17.824: INFO: Pod name my-hostname-basic-a1a7577c-132b-11e9-bc05-0a580af40202: Found 1 pods out of 1
Jan  8 09:56:17.824: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-a1a7577c-132b-11e9-bc05-0a580af40202" are running
Jan  8 09:56:17.827: INFO: Pod "my-hostname-basic-a1a7577c-132b-11e9-bc05-0a580af40202-nlq8g" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-08 09:56:12 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-08 09:56:14 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-08 09:56:14 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-08 09:56:12 +0000 UTC Reason: Message:}])
Jan  8 09:56:17.827: INFO: Trying to dial the pod
Jan  8 09:56:22.839: INFO: Controller my-hostname-basic-a1a7577c-132b-11e9-bc05-0a580af40202: Got expected result from replica 1 [my-hostname-basic-a1a7577c-132b-11e9-bc05-0a580af40202-nlq8g]: "my-hostname-basic-a1a7577c-132b-11e9-bc05-0a580af40202-nlq8g", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:56:22.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-w842j" for this suite.
Jan  8 09:56:28.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:56:28.872: INFO: namespace: e2e-tests-replication-controller-w842j, resource: bindings, ignored listing per whitelist
Jan  8 09:56:28.942: INFO: namespace e2e-tests-replication-controller-w842j deletion completed in 6.100083867s

â€¢ [SLOW TEST:16.206 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:56:28.943: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Jan  8 09:56:29.024: INFO: Waiting up to 5m0s for pod "var-expansion-ab502841-132b-11e9-bc05-0a580af40202" in namespace "e2e-tests-var-expansion-t56fk" to be "success or failure"
Jan  8 09:56:29.028: INFO: Pod "var-expansion-ab502841-132b-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.211381ms
Jan  8 09:56:31.032: INFO: Pod "var-expansion-ab502841-132b-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007072942s
STEP: Saw pod success
Jan  8 09:56:31.032: INFO: Pod "var-expansion-ab502841-132b-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:56:31.034: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod var-expansion-ab502841-132b-11e9-bc05-0a580af40202 container dapi-container: <nil>
STEP: delete the pod
Jan  8 09:56:31.051: INFO: Waiting for pod var-expansion-ab502841-132b-11e9-bc05-0a580af40202 to disappear
Jan  8 09:56:31.053: INFO: Pod var-expansion-ab502841-132b-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:56:31.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-t56fk" for this suite.
Jan  8 09:56:37.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:56:37.077: INFO: namespace: e2e-tests-var-expansion-t56fk, resource: bindings, ignored listing per whitelist
Jan  8 09:56:37.157: INFO: namespace e2e-tests-var-expansion-t56fk deletion completed in 6.099393189s

â€¢ [SLOW TEST:8.214 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:56:37.157: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-gwfdp
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-gwfdp
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-gwfdp
Jan  8 09:56:37.240: INFO: Found 0 stateful pods, waiting for 1
Jan  8 09:56:47.245: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jan  8 09:56:47.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 exec --namespace=e2e-tests-statefulset-gwfdp ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  8 09:56:47.440: INFO: stderr: ""
Jan  8 09:56:47.440: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  8 09:56:47.440: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  8 09:56:47.444: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan  8 09:56:57.449: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan  8 09:56:57.449: INFO: Waiting for statefulset status.replicas updated to 0
Jan  8 09:56:57.462: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Jan  8 09:56:57.462: INFO: ss-0  oltf-408483-kube-worker1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:37 +0000 UTC  }]
Jan  8 09:56:57.462: INFO: 
Jan  8 09:56:57.462: INFO: StatefulSet ss has not reached scale 3, at 1
Jan  8 09:56:58.467: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996502127s
Jan  8 09:56:59.472: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991781542s
Jan  8 09:57:00.476: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.986703133s
Jan  8 09:57:01.482: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.982571725s
Jan  8 09:57:02.486: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.976874974s
Jan  8 09:57:03.490: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972996647s
Jan  8 09:57:04.494: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.968789405s
Jan  8 09:57:05.499: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.964844565s
Jan  8 09:57:06.503: INFO: Verifying statefulset ss doesn't scale past 3 for another 960.444862ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-gwfdp
Jan  8 09:57:07.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 exec --namespace=e2e-tests-statefulset-gwfdp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  8 09:57:07.677: INFO: stderr: ""
Jan  8 09:57:07.677: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  8 09:57:07.677: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  8 09:57:07.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 exec --namespace=e2e-tests-statefulset-gwfdp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  8 09:57:07.850: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jan  8 09:57:07.850: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  8 09:57:07.850: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  8 09:57:07.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 exec --namespace=e2e-tests-statefulset-gwfdp ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  8 09:57:08.032: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jan  8 09:57:08.032: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  8 09:57:08.032: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  8 09:57:08.037: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Jan  8 09:57:18.041: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan  8 09:57:18.042: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan  8 09:57:18.042: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jan  8 09:57:18.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 exec --namespace=e2e-tests-statefulset-gwfdp ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  8 09:57:18.222: INFO: stderr: ""
Jan  8 09:57:18.222: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  8 09:57:18.222: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  8 09:57:18.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 exec --namespace=e2e-tests-statefulset-gwfdp ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  8 09:57:18.412: INFO: stderr: ""
Jan  8 09:57:18.412: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  8 09:57:18.412: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  8 09:57:18.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 exec --namespace=e2e-tests-statefulset-gwfdp ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  8 09:57:18.600: INFO: stderr: ""
Jan  8 09:57:18.600: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  8 09:57:18.600: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  8 09:57:18.600: INFO: Waiting for statefulset status.replicas updated to 0
Jan  8 09:57:18.604: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Jan  8 09:57:28.611: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan  8 09:57:28.611: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan  8 09:57:28.611: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan  8 09:57:28.622: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Jan  8 09:57:28.622: INFO: ss-0  oltf-408483-kube-worker1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:37 +0000 UTC  }]
Jan  8 09:57:28.622: INFO: ss-1  oltf-408483-kube-worker2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  }]
Jan  8 09:57:28.622: INFO: ss-2  oltf-408483-kube-worker1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  }]
Jan  8 09:57:28.622: INFO: 
Jan  8 09:57:28.622: INFO: StatefulSet ss has not reached scale 0, at 3
Jan  8 09:57:29.627: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Jan  8 09:57:29.627: INFO: ss-0  oltf-408483-kube-worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:37 +0000 UTC  }]
Jan  8 09:57:29.627: INFO: ss-1  oltf-408483-kube-worker2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  }]
Jan  8 09:57:29.627: INFO: ss-2  oltf-408483-kube-worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  }]
Jan  8 09:57:29.627: INFO: 
Jan  8 09:57:29.627: INFO: StatefulSet ss has not reached scale 0, at 3
Jan  8 09:57:30.631: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Jan  8 09:57:30.631: INFO: ss-0  oltf-408483-kube-worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:37 +0000 UTC  }]
Jan  8 09:57:30.631: INFO: ss-1  oltf-408483-kube-worker2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  }]
Jan  8 09:57:30.631: INFO: ss-2  oltf-408483-kube-worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  }]
Jan  8 09:57:30.631: INFO: 
Jan  8 09:57:30.631: INFO: StatefulSet ss has not reached scale 0, at 3
Jan  8 09:57:31.636: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Jan  8 09:57:31.636: INFO: ss-0  oltf-408483-kube-worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:37 +0000 UTC  }]
Jan  8 09:57:31.636: INFO: ss-1  oltf-408483-kube-worker2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  }]
Jan  8 09:57:31.636: INFO: ss-2  oltf-408483-kube-worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  }]
Jan  8 09:57:31.636: INFO: 
Jan  8 09:57:31.636: INFO: StatefulSet ss has not reached scale 0, at 3
Jan  8 09:57:32.641: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Jan  8 09:57:32.641: INFO: ss-0  oltf-408483-kube-worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:37 +0000 UTC  }]
Jan  8 09:57:32.641: INFO: ss-1  oltf-408483-kube-worker2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  }]
Jan  8 09:57:32.641: INFO: ss-2  oltf-408483-kube-worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  }]
Jan  8 09:57:32.641: INFO: 
Jan  8 09:57:32.641: INFO: StatefulSet ss has not reached scale 0, at 3
Jan  8 09:57:33.645: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Jan  8 09:57:33.645: INFO: ss-0  oltf-408483-kube-worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:37 +0000 UTC  }]
Jan  8 09:57:33.645: INFO: ss-2  oltf-408483-kube-worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  }]
Jan  8 09:57:33.646: INFO: 
Jan  8 09:57:33.646: INFO: StatefulSet ss has not reached scale 0, at 2
Jan  8 09:57:34.650: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Jan  8 09:57:34.650: INFO: ss-0  oltf-408483-kube-worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:37 +0000 UTC  }]
Jan  8 09:57:34.650: INFO: ss-2  oltf-408483-kube-worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  }]
Jan  8 09:57:34.650: INFO: 
Jan  8 09:57:34.650: INFO: StatefulSet ss has not reached scale 0, at 2
Jan  8 09:57:35.655: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Jan  8 09:57:35.655: INFO: ss-0  oltf-408483-kube-worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:37 +0000 UTC  }]
Jan  8 09:57:35.655: INFO: ss-2  oltf-408483-kube-worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  }]
Jan  8 09:57:35.655: INFO: 
Jan  8 09:57:35.655: INFO: StatefulSet ss has not reached scale 0, at 2
Jan  8 09:57:36.659: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Jan  8 09:57:36.659: INFO: ss-0  oltf-408483-kube-worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:37 +0000 UTC  }]
Jan  8 09:57:36.659: INFO: ss-2  oltf-408483-kube-worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:57:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 09:56:57 +0000 UTC  }]
Jan  8 09:57:36.659: INFO: 
Jan  8 09:57:36.659: INFO: StatefulSet ss has not reached scale 0, at 2
Jan  8 09:57:37.664: INFO: Verifying statefulset ss doesn't scale past 0 for another 958.989989ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-gwfdp
Jan  8 09:57:38.668: INFO: Scaling statefulset ss to 0
Jan  8 09:57:38.677: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan  8 09:57:38.680: INFO: Deleting all statefulset in ns e2e-tests-statefulset-gwfdp
Jan  8 09:57:38.683: INFO: Scaling statefulset ss to 0
Jan  8 09:57:38.692: INFO: Waiting for statefulset status.replicas updated to 0
Jan  8 09:57:38.695: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:57:38.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-gwfdp" for this suite.
Jan  8 09:57:44.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:57:44.793: INFO: namespace: e2e-tests-statefulset-gwfdp, resource: bindings, ignored listing per whitelist
Jan  8 09:57:44.813: INFO: namespace e2e-tests-statefulset-gwfdp deletion completed in 6.102505182s

â€¢ [SLOW TEST:67.655 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:57:44.813: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-d88a6989-132b-11e9-bc05-0a580af40202
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-d88a6989-132b-11e9-bc05-0a580af40202
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:57:48.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-smmg4" for this suite.
Jan  8 09:58:10.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:58:11.024: INFO: namespace: e2e-tests-projected-smmg4, resource: bindings, ignored listing per whitelist
Jan  8 09:58:11.059: INFO: namespace e2e-tests-projected-smmg4 deletion completed in 22.103117435s

â€¢ [SLOW TEST:26.246 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:58:11.059: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan  8 09:58:11.144: INFO: Waiting up to 5m0s for pod "pod-e82e4f55-132b-11e9-bc05-0a580af40202" in namespace "e2e-tests-emptydir-jwfk4" to be "success or failure"
Jan  8 09:58:11.147: INFO: Pod "pod-e82e4f55-132b-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.843412ms
Jan  8 09:58:13.150: INFO: Pod "pod-e82e4f55-132b-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006534496s
STEP: Saw pod success
Jan  8 09:58:13.150: INFO: Pod "pod-e82e4f55-132b-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:58:13.153: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-e82e4f55-132b-11e9-bc05-0a580af40202 container test-container: <nil>
STEP: delete the pod
Jan  8 09:58:13.172: INFO: Waiting for pod pod-e82e4f55-132b-11e9-bc05-0a580af40202 to disappear
Jan  8 09:58:13.175: INFO: Pod pod-e82e4f55-132b-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:58:13.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jwfk4" for this suite.
Jan  8 09:58:19.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:58:19.274: INFO: namespace: e2e-tests-emptydir-jwfk4, resource: bindings, ignored listing per whitelist
Jan  8 09:58:19.283: INFO: namespace e2e-tests-emptydir-jwfk4 deletion completed in 6.104553624s

â€¢ [SLOW TEST:8.225 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:58:19.284: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan  8 09:58:19.360: INFO: Waiting up to 5m0s for pod "downward-api-ed13ff4e-132b-11e9-bc05-0a580af40202" in namespace "e2e-tests-downward-api-jhvll" to be "success or failure"
Jan  8 09:58:19.363: INFO: Pod "downward-api-ed13ff4e-132b-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.797841ms
Jan  8 09:58:21.366: INFO: Pod "downward-api-ed13ff4e-132b-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006368426s
STEP: Saw pod success
Jan  8 09:58:21.366: INFO: Pod "downward-api-ed13ff4e-132b-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:58:21.369: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod downward-api-ed13ff4e-132b-11e9-bc05-0a580af40202 container dapi-container: <nil>
STEP: delete the pod
Jan  8 09:58:21.386: INFO: Waiting for pod downward-api-ed13ff4e-132b-11e9-bc05-0a580af40202 to disappear
Jan  8 09:58:21.388: INFO: Pod downward-api-ed13ff4e-132b-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:58:21.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jhvll" for this suite.
Jan  8 09:58:27.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:58:27.487: INFO: namespace: e2e-tests-downward-api-jhvll, resource: bindings, ignored listing per whitelist
Jan  8 09:58:27.492: INFO: namespace e2e-tests-downward-api-jhvll deletion completed in 6.100256901s

â€¢ [SLOW TEST:8.209 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:58:27.492: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-jnkgp/configmap-test-f1f97851-132b-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume configMaps
Jan  8 09:58:27.578: INFO: Waiting up to 5m0s for pod "pod-configmaps-f1fa1037-132b-11e9-bc05-0a580af40202" in namespace "e2e-tests-configmap-jnkgp" to be "success or failure"
Jan  8 09:58:27.581: INFO: Pod "pod-configmaps-f1fa1037-132b-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.609274ms
Jan  8 09:58:29.585: INFO: Pod "pod-configmaps-f1fa1037-132b-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00682241s
STEP: Saw pod success
Jan  8 09:58:29.585: INFO: Pod "pod-configmaps-f1fa1037-132b-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:58:29.588: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-configmaps-f1fa1037-132b-11e9-bc05-0a580af40202 container env-test: <nil>
STEP: delete the pod
Jan  8 09:58:29.605: INFO: Waiting for pod pod-configmaps-f1fa1037-132b-11e9-bc05-0a580af40202 to disappear
Jan  8 09:58:29.607: INFO: Pod pod-configmaps-f1fa1037-132b-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:58:29.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jnkgp" for this suite.
Jan  8 09:58:35.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:58:35.719: INFO: namespace: e2e-tests-configmap-jnkgp, resource: bindings, ignored listing per whitelist
Jan  8 09:58:35.725: INFO: namespace e2e-tests-configmap-jnkgp deletion completed in 6.113141847s

â€¢ [SLOW TEST:8.233 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:58:35.725: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Jan  8 09:58:35.805: INFO: Waiting up to 5m0s for pod "var-expansion-f6e167e7-132b-11e9-bc05-0a580af40202" in namespace "e2e-tests-var-expansion-5g5xz" to be "success or failure"
Jan  8 09:58:35.808: INFO: Pod "var-expansion-f6e167e7-132b-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.003171ms
Jan  8 09:58:37.812: INFO: Pod "var-expansion-f6e167e7-132b-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006676672s
STEP: Saw pod success
Jan  8 09:58:37.812: INFO: Pod "var-expansion-f6e167e7-132b-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:58:37.814: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod var-expansion-f6e167e7-132b-11e9-bc05-0a580af40202 container dapi-container: <nil>
STEP: delete the pod
Jan  8 09:58:37.832: INFO: Waiting for pod var-expansion-f6e167e7-132b-11e9-bc05-0a580af40202 to disappear
Jan  8 09:58:37.835: INFO: Pod var-expansion-f6e167e7-132b-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:58:37.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-5g5xz" for this suite.
Jan  8 09:58:43.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:58:43.933: INFO: namespace: e2e-tests-var-expansion-5g5xz, resource: bindings, ignored listing per whitelist
Jan  8 09:58:43.951: INFO: namespace e2e-tests-var-expansion-5g5xz deletion completed in 6.112036242s

â€¢ [SLOW TEST:8.225 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:58:43.951: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan  8 09:58:46.557: INFO: Successfully updated pod "pod-update-fbc8c4d8-132b-11e9-bc05-0a580af40202"
STEP: verifying the updated pod is in kubernetes
Jan  8 09:58:46.563: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:58:46.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-7jndh" for this suite.
Jan  8 09:59:08.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:59:08.599: INFO: namespace: e2e-tests-pods-7jndh, resource: bindings, ignored listing per whitelist
Jan  8 09:59:08.665: INFO: namespace e2e-tests-pods-7jndh deletion completed in 22.097695003s

â€¢ [SLOW TEST:24.714 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:59:08.665: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan  8 09:59:13.276: INFO: Successfully updated pod "pod-update-activedeadlineseconds-0a84da4f-132c-11e9-bc05-0a580af40202"
Jan  8 09:59:13.276: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-0a84da4f-132c-11e9-bc05-0a580af40202" in namespace "e2e-tests-pods-xbgfc" to be "terminated due to deadline exceeded"
Jan  8 09:59:13.279: INFO: Pod "pod-update-activedeadlineseconds-0a84da4f-132c-11e9-bc05-0a580af40202": Phase="Running", Reason="", readiness=true. Elapsed: 2.924769ms
Jan  8 09:59:15.283: INFO: Pod "pod-update-activedeadlineseconds-0a84da4f-132c-11e9-bc05-0a580af40202": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.006858749s
Jan  8 09:59:15.283: INFO: Pod "pod-update-activedeadlineseconds-0a84da4f-132c-11e9-bc05-0a580af40202" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:59:15.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xbgfc" for this suite.
Jan  8 09:59:21.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:59:21.378: INFO: namespace: e2e-tests-pods-xbgfc, resource: bindings, ignored listing per whitelist
Jan  8 09:59:21.392: INFO: namespace e2e-tests-pods-xbgfc deletion completed in 6.103113035s

â€¢ [SLOW TEST:12.727 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:59:21.392: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  8 09:59:21.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 version'
Jan  8 09:59:21.550: INFO: stderr: ""
Jan  8 09:59:21.550: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.3+2.0.6.el7\", GitCommit:\"7e7b7cdb9431f2f7634418cf636805c4769eba15\", GitTreeState:\"archive\", BuildDate:\"2019-01-07T23:14:18Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:59:21.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qc7cf" for this suite.
Jan  8 09:59:27.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:59:27.601: INFO: namespace: e2e-tests-kubectl-qc7cf, resource: bindings, ignored listing per whitelist
Jan  8 09:59:27.662: INFO: namespace e2e-tests-kubectl-qc7cf deletion completed in 6.107884268s

â€¢ [SLOW TEST:6.270 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:59:27.662: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-9nwml/secret-test-15d61299-132c-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume secrets
Jan  8 09:59:27.745: INFO: Waiting up to 5m0s for pod "pod-configmaps-15d69922-132c-11e9-bc05-0a580af40202" in namespace "e2e-tests-secrets-9nwml" to be "success or failure"
Jan  8 09:59:27.747: INFO: Pod "pod-configmaps-15d69922-132c-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.518345ms
Jan  8 09:59:29.751: INFO: Pod "pod-configmaps-15d69922-132c-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006255504s
STEP: Saw pod success
Jan  8 09:59:29.751: INFO: Pod "pod-configmaps-15d69922-132c-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 09:59:29.754: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-configmaps-15d69922-132c-11e9-bc05-0a580af40202 container env-test: <nil>
STEP: delete the pod
Jan  8 09:59:29.773: INFO: Waiting for pod pod-configmaps-15d69922-132c-11e9-bc05-0a580af40202 to disappear
Jan  8 09:59:29.776: INFO: Pod pod-configmaps-15d69922-132c-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 09:59:29.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9nwml" for this suite.
Jan  8 09:59:35.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 09:59:35.835: INFO: namespace: e2e-tests-secrets-9nwml, resource: bindings, ignored listing per whitelist
Jan  8 09:59:35.883: INFO: namespace e2e-tests-secrets-9nwml deletion completed in 6.100450895s

â€¢ [SLOW TEST:8.221 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 09:59:35.883: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-s7s56
Jan  8 09:59:37.976: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-s7s56
STEP: checking the pod's current state and verifying that restartCount is present
Jan  8 09:59:37.979: INFO: Initial restart count of pod liveness-http is 0
Jan  8 09:59:52.008: INFO: Restart count of pod e2e-tests-container-probe-s7s56/liveness-http is now 1 (14.02948225s elapsed)
Jan  8 10:00:12.051: INFO: Restart count of pod e2e-tests-container-probe-s7s56/liveness-http is now 2 (34.07228355s elapsed)
Jan  8 10:00:32.088: INFO: Restart count of pod e2e-tests-container-probe-s7s56/liveness-http is now 3 (54.109739203s elapsed)
Jan  8 10:00:52.124: INFO: Restart count of pod e2e-tests-container-probe-s7s56/liveness-http is now 4 (1m14.145205931s elapsed)
Jan  8 10:02:06.264: INFO: Restart count of pod e2e-tests-container-probe-s7s56/liveness-http is now 5 (2m28.285218497s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:02:06.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-s7s56" for this suite.
Jan  8 10:02:12.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:02:12.303: INFO: namespace: e2e-tests-container-probe-s7s56, resource: bindings, ignored listing per whitelist
Jan  8 10:02:12.376: INFO: namespace e2e-tests-container-probe-s7s56 deletion completed in 6.099235973s

â€¢ [SLOW TEST:156.493 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:02:12.376: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-78049f13-132c-11e9-bc05-0a580af40202
STEP: Creating secret with name s-test-opt-upd-78049f49-132c-11e9-bc05-0a580af40202
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-78049f13-132c-11e9-bc05-0a580af40202
STEP: Updating secret s-test-opt-upd-78049f49-132c-11e9-bc05-0a580af40202
STEP: Creating secret with name s-test-opt-create-78049f5f-132c-11e9-bc05-0a580af40202
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:02:16.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-ssxwn" for this suite.
Jan  8 10:02:38.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:02:38.595: INFO: namespace: e2e-tests-secrets-ssxwn, resource: bindings, ignored listing per whitelist
Jan  8 10:02:38.652: INFO: namespace e2e-tests-secrets-ssxwn deletion completed in 22.097469772s

â€¢ [SLOW TEST:26.275 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:02:38.652: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-gwsv
STEP: Creating a pod to test atomic-volume-subpath
Jan  8 10:02:38.744: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-gwsv" in namespace "e2e-tests-subpath-9s6vp" to be "success or failure"
Jan  8 10:02:38.749: INFO: Pod "pod-subpath-test-downwardapi-gwsv": Phase="Pending", Reason="", readiness=false. Elapsed: 5.801474ms
Jan  8 10:02:40.753: INFO: Pod "pod-subpath-test-downwardapi-gwsv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008938566s
Jan  8 10:02:42.757: INFO: Pod "pod-subpath-test-downwardapi-gwsv": Phase="Running", Reason="", readiness=false. Elapsed: 4.012978612s
Jan  8 10:02:44.761: INFO: Pod "pod-subpath-test-downwardapi-gwsv": Phase="Running", Reason="", readiness=false. Elapsed: 6.017044875s
Jan  8 10:02:46.765: INFO: Pod "pod-subpath-test-downwardapi-gwsv": Phase="Running", Reason="", readiness=false. Elapsed: 8.021244726s
Jan  8 10:02:48.769: INFO: Pod "pod-subpath-test-downwardapi-gwsv": Phase="Running", Reason="", readiness=false. Elapsed: 10.025134108s
Jan  8 10:02:50.773: INFO: Pod "pod-subpath-test-downwardapi-gwsv": Phase="Running", Reason="", readiness=false. Elapsed: 12.02913329s
Jan  8 10:02:52.776: INFO: Pod "pod-subpath-test-downwardapi-gwsv": Phase="Running", Reason="", readiness=false. Elapsed: 14.032734986s
Jan  8 10:02:54.780: INFO: Pod "pod-subpath-test-downwardapi-gwsv": Phase="Running", Reason="", readiness=false. Elapsed: 16.036509865s
Jan  8 10:02:56.784: INFO: Pod "pod-subpath-test-downwardapi-gwsv": Phase="Running", Reason="", readiness=false. Elapsed: 18.040365092s
Jan  8 10:02:58.793: INFO: Pod "pod-subpath-test-downwardapi-gwsv": Phase="Running", Reason="", readiness=false. Elapsed: 20.0495444s
Jan  8 10:03:00.797: INFO: Pod "pod-subpath-test-downwardapi-gwsv": Phase="Running", Reason="", readiness=false. Elapsed: 22.053330531s
Jan  8 10:03:02.801: INFO: Pod "pod-subpath-test-downwardapi-gwsv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.056828127s
STEP: Saw pod success
Jan  8 10:03:02.801: INFO: Pod "pod-subpath-test-downwardapi-gwsv" satisfied condition "success or failure"
Jan  8 10:03:02.804: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-subpath-test-downwardapi-gwsv container test-container-subpath-downwardapi-gwsv: <nil>
STEP: delete the pod
Jan  8 10:03:02.820: INFO: Waiting for pod pod-subpath-test-downwardapi-gwsv to disappear
Jan  8 10:03:02.823: INFO: Pod pod-subpath-test-downwardapi-gwsv no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-gwsv
Jan  8 10:03:02.823: INFO: Deleting pod "pod-subpath-test-downwardapi-gwsv" in namespace "e2e-tests-subpath-9s6vp"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:03:02.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-9s6vp" for this suite.
Jan  8 10:03:08.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:03:08.873: INFO: namespace: e2e-tests-subpath-9s6vp, resource: bindings, ignored listing per whitelist
Jan  8 10:03:08.932: INFO: namespace e2e-tests-subpath-9s6vp deletion completed in 6.102990619s

â€¢ [SLOW TEST:30.280 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:03:08.932: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-99b9c6de-132c-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume secrets
Jan  8 10:03:09.018: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-99ba47d7-132c-11e9-bc05-0a580af40202" in namespace "e2e-tests-projected-zgt9s" to be "success or failure"
Jan  8 10:03:09.022: INFO: Pod "pod-projected-secrets-99ba47d7-132c-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.262281ms
Jan  8 10:03:11.026: INFO: Pod "pod-projected-secrets-99ba47d7-132c-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007115375s
STEP: Saw pod success
Jan  8 10:03:11.026: INFO: Pod "pod-projected-secrets-99ba47d7-132c-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:03:11.028: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-projected-secrets-99ba47d7-132c-11e9-bc05-0a580af40202 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan  8 10:03:11.045: INFO: Waiting for pod pod-projected-secrets-99ba47d7-132c-11e9-bc05-0a580af40202 to disappear
Jan  8 10:03:11.048: INFO: Pod pod-projected-secrets-99ba47d7-132c-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:03:11.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zgt9s" for this suite.
Jan  8 10:03:17.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:03:17.077: INFO: namespace: e2e-tests-projected-zgt9s, resource: bindings, ignored listing per whitelist
Jan  8 10:03:17.152: INFO: namespace e2e-tests-projected-zgt9s deletion completed in 6.10046365s

â€¢ [SLOW TEST:8.220 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:03:17.153: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jan  8 10:03:21.251: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-fdxsn PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  8 10:03:21.251: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
Jan  8 10:03:21.337: INFO: Exec stderr: ""
Jan  8 10:03:21.337: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-fdxsn PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  8 10:03:21.337: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
Jan  8 10:03:21.420: INFO: Exec stderr: ""
Jan  8 10:03:21.420: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-fdxsn PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  8 10:03:21.420: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
Jan  8 10:03:21.503: INFO: Exec stderr: ""
Jan  8 10:03:21.503: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-fdxsn PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  8 10:03:21.503: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
Jan  8 10:03:21.589: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jan  8 10:03:21.589: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-fdxsn PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  8 10:03:21.589: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
Jan  8 10:03:21.671: INFO: Exec stderr: ""
Jan  8 10:03:21.671: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-fdxsn PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  8 10:03:21.671: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
Jan  8 10:03:21.756: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jan  8 10:03:21.756: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-fdxsn PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  8 10:03:21.756: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
Jan  8 10:03:21.845: INFO: Exec stderr: ""
Jan  8 10:03:21.845: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-fdxsn PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  8 10:03:21.845: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
Jan  8 10:03:21.928: INFO: Exec stderr: ""
Jan  8 10:03:21.928: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-fdxsn PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  8 10:03:21.928: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
Jan  8 10:03:22.011: INFO: Exec stderr: ""
Jan  8 10:03:22.011: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-fdxsn PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  8 10:03:22.011: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
Jan  8 10:03:22.094: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:03:22.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-fdxsn" for this suite.
Jan  8 10:04:14.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:04:14.186: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-fdxsn, resource: bindings, ignored listing per whitelist
Jan  8 10:04:14.199: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-fdxsn deletion completed in 52.101323052s

â€¢ [SLOW TEST:57.046 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:04:14.200: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan  8 10:04:16.809: INFO: Successfully updated pod "labelsupdatec0a075ac-132c-11e9-bc05-0a580af40202"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:04:18.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6wgjh" for this suite.
Jan  8 10:04:40.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:04:40.903: INFO: namespace: e2e-tests-projected-6wgjh, resource: bindings, ignored listing per whitelist
Jan  8 10:04:40.932: INFO: namespace e2e-tests-projected-6wgjh deletion completed in 22.102336621s

â€¢ [SLOW TEST:26.732 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:04:40.932: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Jan  8 10:04:41.011: INFO: Waiting up to 5m0s for pod "client-containers-d08f49a0-132c-11e9-bc05-0a580af40202" in namespace "e2e-tests-containers-995jm" to be "success or failure"
Jan  8 10:04:41.015: INFO: Pod "client-containers-d08f49a0-132c-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.935569ms
Jan  8 10:04:43.019: INFO: Pod "client-containers-d08f49a0-132c-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007654185s
STEP: Saw pod success
Jan  8 10:04:43.019: INFO: Pod "client-containers-d08f49a0-132c-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:04:43.022: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod client-containers-d08f49a0-132c-11e9-bc05-0a580af40202 container test-container: <nil>
STEP: delete the pod
Jan  8 10:04:43.040: INFO: Waiting for pod client-containers-d08f49a0-132c-11e9-bc05-0a580af40202 to disappear
Jan  8 10:04:43.043: INFO: Pod client-containers-d08f49a0-132c-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:04:43.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-995jm" for this suite.
Jan  8 10:04:49.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:04:49.152: INFO: namespace: e2e-tests-containers-995jm, resource: bindings, ignored listing per whitelist
Jan  8 10:04:49.152: INFO: namespace e2e-tests-containers-995jm deletion completed in 6.105717442s

â€¢ [SLOW TEST:8.220 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:04:49.152: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan  8 10:04:49.223: INFO: PodSpec: initContainers in spec.initContainers
Jan  8 10:05:32.835: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-d5753ff7-132c-11e9-bc05-0a580af40202", GenerateName:"", Namespace:"e2e-tests-init-container-zj7pf", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-zj7pf/pods/pod-init-d5753ff7-132c-11e9-bc05-0a580af40202", UID:"d575cee4-132c-11e9-a60a-02001701fa35", ResourceVersion:"12408", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63682538689, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"time":"223069701", "name":"foo"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-gx4z7", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc4209f6100), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gx4z7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gx4z7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gx4z7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc4215a73f8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"oltf-408483-kube-worker2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421a3b980), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4215a77b0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4215a7880)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc4215a7888), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682538689, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682538689, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682538689, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682538689, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"100.100.242.163", PodIP:"10.244.2.107", StartTime:(*v1.Time)(0xc421819320), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc42181e770)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc42181e7e0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://1b02181c33990a53ab5836a2d7f5e490e0632392ac5bcae5db47690dd6d06437"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421819360), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421819340), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:05:32.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-zj7pf" for this suite.
Jan  8 10:05:54.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:05:54.868: INFO: namespace: e2e-tests-init-container-zj7pf, resource: bindings, ignored listing per whitelist
Jan  8 10:05:54.940: INFO: namespace e2e-tests-init-container-zj7pf deletion completed in 22.100568707s

â€¢ [SLOW TEST:65.788 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:05:54.940: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-fcaccb33-132c-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume secrets
Jan  8 10:05:55.028: INFO: Waiting up to 5m0s for pod "pod-secrets-fcad5e13-132c-11e9-bc05-0a580af40202" in namespace "e2e-tests-secrets-j9jh6" to be "success or failure"
Jan  8 10:05:55.031: INFO: Pod "pod-secrets-fcad5e13-132c-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.854868ms
Jan  8 10:05:57.035: INFO: Pod "pod-secrets-fcad5e13-132c-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007139066s
STEP: Saw pod success
Jan  8 10:05:57.035: INFO: Pod "pod-secrets-fcad5e13-132c-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:05:57.038: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-secrets-fcad5e13-132c-11e9-bc05-0a580af40202 container secret-volume-test: <nil>
STEP: delete the pod
Jan  8 10:05:57.055: INFO: Waiting for pod pod-secrets-fcad5e13-132c-11e9-bc05-0a580af40202 to disappear
Jan  8 10:05:57.058: INFO: Pod pod-secrets-fcad5e13-132c-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:05:57.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-j9jh6" for this suite.
Jan  8 10:06:03.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:06:03.166: INFO: namespace: e2e-tests-secrets-j9jh6, resource: bindings, ignored listing per whitelist
Jan  8 10:06:03.172: INFO: namespace e2e-tests-secrets-j9jh6 deletion completed in 6.110687991s

â€¢ [SLOW TEST:8.232 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:06:03.172: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-01938277-132d-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume secrets
Jan  8 10:06:03.251: INFO: Waiting up to 5m0s for pod "pod-secrets-019404a0-132d-11e9-bc05-0a580af40202" in namespace "e2e-tests-secrets-mn6hv" to be "success or failure"
Jan  8 10:06:03.254: INFO: Pod "pod-secrets-019404a0-132d-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.24964ms
Jan  8 10:06:05.260: INFO: Pod "pod-secrets-019404a0-132d-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008756897s
STEP: Saw pod success
Jan  8 10:06:05.260: INFO: Pod "pod-secrets-019404a0-132d-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:06:05.263: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod pod-secrets-019404a0-132d-11e9-bc05-0a580af40202 container secret-volume-test: <nil>
STEP: delete the pod
Jan  8 10:06:05.288: INFO: Waiting for pod pod-secrets-019404a0-132d-11e9-bc05-0a580af40202 to disappear
Jan  8 10:06:05.291: INFO: Pod pod-secrets-019404a0-132d-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:06:05.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-mn6hv" for this suite.
Jan  8 10:06:11.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:06:11.337: INFO: namespace: e2e-tests-secrets-mn6hv, resource: bindings, ignored listing per whitelist
Jan  8 10:06:11.398: INFO: namespace e2e-tests-secrets-mn6hv deletion completed in 6.103507991s

â€¢ [SLOW TEST:8.226 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:06:11.399: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Jan  8 10:06:11.476: INFO: Waiting up to 5m0s for pod "var-expansion-067b4e04-132d-11e9-bc05-0a580af40202" in namespace "e2e-tests-var-expansion-pd5bl" to be "success or failure"
Jan  8 10:06:11.479: INFO: Pod "var-expansion-067b4e04-132d-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.984121ms
Jan  8 10:06:13.483: INFO: Pod "var-expansion-067b4e04-132d-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006295716s
STEP: Saw pod success
Jan  8 10:06:13.483: INFO: Pod "var-expansion-067b4e04-132d-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:06:13.485: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod var-expansion-067b4e04-132d-11e9-bc05-0a580af40202 container dapi-container: <nil>
STEP: delete the pod
Jan  8 10:06:13.503: INFO: Waiting for pod var-expansion-067b4e04-132d-11e9-bc05-0a580af40202 to disappear
Jan  8 10:06:13.506: INFO: Pod var-expansion-067b4e04-132d-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:06:13.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-pd5bl" for this suite.
Jan  8 10:06:19.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:06:19.595: INFO: namespace: e2e-tests-var-expansion-pd5bl, resource: bindings, ignored listing per whitelist
Jan  8 10:06:19.608: INFO: namespace e2e-tests-var-expansion-pd5bl deletion completed in 6.09852918s

â€¢ [SLOW TEST:8.210 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:06:19.608: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jan  8 10:06:19.694: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fk44b,SelfLink:/api/v1/namespaces/e2e-tests-watch-fk44b/configmaps/e2e-watch-test-label-changed,UID:0b5fd053-132d-11e9-a60a-02001701fa35,ResourceVersion:12569,Generation:0,CreationTimestamp:2019-01-08 10:06:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan  8 10:06:19.694: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fk44b,SelfLink:/api/v1/namespaces/e2e-tests-watch-fk44b/configmaps/e2e-watch-test-label-changed,UID:0b5fd053-132d-11e9-a60a-02001701fa35,ResourceVersion:12570,Generation:0,CreationTimestamp:2019-01-08 10:06:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan  8 10:06:19.694: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fk44b,SelfLink:/api/v1/namespaces/e2e-tests-watch-fk44b/configmaps/e2e-watch-test-label-changed,UID:0b5fd053-132d-11e9-a60a-02001701fa35,ResourceVersion:12571,Generation:0,CreationTimestamp:2019-01-08 10:06:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jan  8 10:06:29.720: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fk44b,SelfLink:/api/v1/namespaces/e2e-tests-watch-fk44b/configmaps/e2e-watch-test-label-changed,UID:0b5fd053-132d-11e9-a60a-02001701fa35,ResourceVersion:12587,Generation:0,CreationTimestamp:2019-01-08 10:06:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan  8 10:06:29.720: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fk44b,SelfLink:/api/v1/namespaces/e2e-tests-watch-fk44b/configmaps/e2e-watch-test-label-changed,UID:0b5fd053-132d-11e9-a60a-02001701fa35,ResourceVersion:12588,Generation:0,CreationTimestamp:2019-01-08 10:06:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jan  8 10:06:29.720: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fk44b,SelfLink:/api/v1/namespaces/e2e-tests-watch-fk44b/configmaps/e2e-watch-test-label-changed,UID:0b5fd053-132d-11e9-a60a-02001701fa35,ResourceVersion:12589,Generation:0,CreationTimestamp:2019-01-08 10:06:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:06:29.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-fk44b" for this suite.
Jan  8 10:06:35.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:06:35.791: INFO: namespace: e2e-tests-watch-fk44b, resource: bindings, ignored listing per whitelist
Jan  8 10:06:35.824: INFO: namespace e2e-tests-watch-fk44b deletion completed in 6.10035688s

â€¢ [SLOW TEST:16.216 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:06:35.824: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jan  8 10:06:35.897: INFO: namespace e2e-tests-kubectl-84sfz
Jan  8 10:06:35.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 create -f - --namespace=e2e-tests-kubectl-84sfz'
Jan  8 10:06:36.209: INFO: stderr: ""
Jan  8 10:06:36.209: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan  8 10:06:37.213: INFO: Selector matched 1 pods for map[app:redis]
Jan  8 10:06:37.213: INFO: Found 0 / 1
Jan  8 10:06:38.213: INFO: Selector matched 1 pods for map[app:redis]
Jan  8 10:06:38.213: INFO: Found 1 / 1
Jan  8 10:06:38.213: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan  8 10:06:38.216: INFO: Selector matched 1 pods for map[app:redis]
Jan  8 10:06:38.216: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan  8 10:06:38.216: INFO: wait on redis-master startup in e2e-tests-kubectl-84sfz 
Jan  8 10:06:38.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 logs redis-master-sbcct redis-master --namespace=e2e-tests-kubectl-84sfz'
Jan  8 10:06:38.319: INFO: stderr: ""
Jan  8 10:06:38.319: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 08 Jan 10:06:37.144 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 08 Jan 10:06:37.144 # Server started, Redis version 3.2.12\n1:M 08 Jan 10:06:37.144 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 08 Jan 10:06:37.144 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Jan  8 10:06:38.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-84sfz'
Jan  8 10:06:38.424: INFO: stderr: ""
Jan  8 10:06:38.424: INFO: stdout: "service/rm2 exposed\n"
Jan  8 10:06:38.431: INFO: Service rm2 in namespace e2e-tests-kubectl-84sfz found.
STEP: exposing service
Jan  8 10:06:40.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-84sfz'
Jan  8 10:06:40.545: INFO: stderr: ""
Jan  8 10:06:40.545: INFO: stdout: "service/rm3 exposed\n"
Jan  8 10:06:40.549: INFO: Service rm3 in namespace e2e-tests-kubectl-84sfz found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:06:42.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-84sfz" for this suite.
Jan  8 10:07:04.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:07:04.650: INFO: namespace: e2e-tests-kubectl-84sfz, resource: bindings, ignored listing per whitelist
Jan  8 10:07:04.659: INFO: namespace e2e-tests-kubectl-84sfz deletion completed in 22.099781137s

â€¢ [SLOW TEST:28.835 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:07:04.660: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  8 10:07:04.746: INFO: Waiting up to 5m0s for pod "downwardapi-volume-263b7483-132d-11e9-bc05-0a580af40202" in namespace "e2e-tests-downward-api-fvrrs" to be "success or failure"
Jan  8 10:07:04.749: INFO: Pod "downwardapi-volume-263b7483-132d-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.014947ms
Jan  8 10:07:06.752: INFO: Pod "downwardapi-volume-263b7483-132d-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00639474s
STEP: Saw pod success
Jan  8 10:07:06.752: INFO: Pod "downwardapi-volume-263b7483-132d-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:07:06.755: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod downwardapi-volume-263b7483-132d-11e9-bc05-0a580af40202 container client-container: <nil>
STEP: delete the pod
Jan  8 10:07:06.773: INFO: Waiting for pod downwardapi-volume-263b7483-132d-11e9-bc05-0a580af40202 to disappear
Jan  8 10:07:06.775: INFO: Pod downwardapi-volume-263b7483-132d-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:07:06.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fvrrs" for this suite.
Jan  8 10:07:12.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:07:12.829: INFO: namespace: e2e-tests-downward-api-fvrrs, resource: bindings, ignored listing per whitelist
Jan  8 10:07:12.879: INFO: namespace e2e-tests-downward-api-fvrrs deletion completed in 6.100562111s

â€¢ [SLOW TEST:8.220 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:07:12.880: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  8 10:07:30.964: INFO: Container started at 2019-01-08 10:07:13 +0000 UTC, pod became ready at 2019-01-08 10:07:29 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:07:30.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-sbxvr" for this suite.
Jan  8 10:07:52.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:07:53.047: INFO: namespace: e2e-tests-container-probe-sbxvr, resource: bindings, ignored listing per whitelist
Jan  8 10:07:53.070: INFO: namespace e2e-tests-container-probe-sbxvr deletion completed in 22.101733706s

â€¢ [SLOW TEST:40.190 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:07:53.070: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-p9j5z
Jan  8 10:07:55.159: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-p9j5z
STEP: checking the pod's current state and verifying that restartCount is present
Jan  8 10:07:55.162: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:11:55.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-p9j5z" for this suite.
Jan  8 10:12:01.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:12:01.705: INFO: namespace: e2e-tests-container-probe-p9j5z, resource: bindings, ignored listing per whitelist
Jan  8 10:12:01.728: INFO: namespace e2e-tests-container-probe-p9j5z deletion completed in 6.104830852s

â€¢ [SLOW TEST:248.658 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:12:01.728: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jan  8 10:12:01.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 create -f - --namespace=e2e-tests-kubectl-fvb9p'
Jan  8 10:12:01.977: INFO: stderr: ""
Jan  8 10:12:01.977: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan  8 10:12:01.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fvb9p'
Jan  8 10:12:02.075: INFO: stderr: ""
Jan  8 10:12:02.075: INFO: stdout: "update-demo-nautilus-47jfq update-demo-nautilus-mmnnp "
Jan  8 10:12:02.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-nautilus-47jfq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fvb9p'
Jan  8 10:12:02.157: INFO: stderr: ""
Jan  8 10:12:02.157: INFO: stdout: ""
Jan  8 10:12:02.157: INFO: update-demo-nautilus-47jfq is created but not running
Jan  8 10:12:07.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fvb9p'
Jan  8 10:12:07.270: INFO: stderr: ""
Jan  8 10:12:07.270: INFO: stdout: "update-demo-nautilus-47jfq update-demo-nautilus-mmnnp "
Jan  8 10:12:07.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-nautilus-47jfq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fvb9p'
Jan  8 10:12:07.356: INFO: stderr: ""
Jan  8 10:12:07.356: INFO: stdout: "true"
Jan  8 10:12:07.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-nautilus-47jfq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fvb9p'
Jan  8 10:12:07.438: INFO: stderr: ""
Jan  8 10:12:07.438: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  8 10:12:07.438: INFO: validating pod update-demo-nautilus-47jfq
Jan  8 10:12:07.443: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  8 10:12:07.443: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  8 10:12:07.443: INFO: update-demo-nautilus-47jfq is verified up and running
Jan  8 10:12:07.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-nautilus-mmnnp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fvb9p'
Jan  8 10:12:07.529: INFO: stderr: ""
Jan  8 10:12:07.529: INFO: stdout: "true"
Jan  8 10:12:07.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-nautilus-mmnnp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fvb9p'
Jan  8 10:12:07.615: INFO: stderr: ""
Jan  8 10:12:07.615: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  8 10:12:07.615: INFO: validating pod update-demo-nautilus-mmnnp
Jan  8 10:12:07.621: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  8 10:12:07.621: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  8 10:12:07.621: INFO: update-demo-nautilus-mmnnp is verified up and running
STEP: using delete to clean up resources
Jan  8 10:12:07.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-fvb9p'
Jan  8 10:12:07.708: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  8 10:12:07.708: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan  8 10:12:07.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-fvb9p'
Jan  8 10:12:07.828: INFO: stderr: "No resources found.\n"
Jan  8 10:12:07.828: INFO: stdout: ""
Jan  8 10:12:07.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods -l name=update-demo --namespace=e2e-tests-kubectl-fvb9p -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan  8 10:12:07.938: INFO: stderr: ""
Jan  8 10:12:07.938: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:12:07.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fvb9p" for this suite.
Jan  8 10:12:13.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:12:14.036: INFO: namespace: e2e-tests-kubectl-fvb9p, resource: bindings, ignored listing per whitelist
Jan  8 10:12:14.042: INFO: namespace e2e-tests-kubectl-fvb9p deletion completed in 6.099523913s

â€¢ [SLOW TEST:12.313 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:12:14.042: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  8 10:12:14.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 version --client'
Jan  8 10:12:14.179: INFO: stderr: ""
Jan  8 10:12:14.179: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Jan  8 10:12:14.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 create -f - --namespace=e2e-tests-kubectl-gmww7'
Jan  8 10:12:14.346: INFO: stderr: ""
Jan  8 10:12:14.346: INFO: stdout: "replicationcontroller/redis-master created\n"
Jan  8 10:12:14.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 create -f - --namespace=e2e-tests-kubectl-gmww7'
Jan  8 10:12:14.537: INFO: stderr: ""
Jan  8 10:12:14.537: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan  8 10:12:15.542: INFO: Selector matched 1 pods for map[app:redis]
Jan  8 10:12:15.542: INFO: Found 0 / 1
Jan  8 10:12:16.541: INFO: Selector matched 1 pods for map[app:redis]
Jan  8 10:12:16.541: INFO: Found 1 / 1
Jan  8 10:12:16.541: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan  8 10:12:16.544: INFO: Selector matched 1 pods for map[app:redis]
Jan  8 10:12:16.544: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan  8 10:12:16.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 describe pod redis-master-jdzx7 --namespace=e2e-tests-kubectl-gmww7'
Jan  8 10:12:16.648: INFO: stderr: ""
Jan  8 10:12:16.648: INFO: stdout: "Name:               redis-master-jdzx7\nNamespace:          e2e-tests-kubectl-gmww7\nPriority:           0\nPriorityClassName:  <none>\nNode:               oltf-408483-kube-worker2/100.100.242.163\nStart Time:         Tue, 08 Jan 2019 10:12:14 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.244.2.112\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://9ab7dcdd0321c9106a881487c49955f34a1c2a04e0dc262c14567b4cc06e6262\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 08 Jan 2019 10:12:15 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-ckd7q (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-ckd7q:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-ckd7q\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                               Message\n  ----    ------     ----  ----                               -------\n  Normal  Scheduled  2s    default-scheduler                  Successfully assigned e2e-tests-kubectl-gmww7/redis-master-jdzx7 to oltf-408483-kube-worker2\n  Normal  Pulled     1s    kubelet, oltf-408483-kube-worker2  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, oltf-408483-kube-worker2  Created container\n  Normal  Started    1s    kubelet, oltf-408483-kube-worker2  Started container\n"
Jan  8 10:12:16.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 describe rc redis-master --namespace=e2e-tests-kubectl-gmww7'
Jan  8 10:12:16.754: INFO: stderr: ""
Jan  8 10:12:16.754: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-gmww7\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-jdzx7\n"
Jan  8 10:12:16.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 describe service redis-master --namespace=e2e-tests-kubectl-gmww7'
Jan  8 10:12:16.851: INFO: stderr: ""
Jan  8 10:12:16.851: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-gmww7\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.100.168.179\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.2.112:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jan  8 10:12:16.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 describe node oltf-408483-kube-master'
Jan  8 10:12:16.967: INFO: stderr: ""
Jan  8 10:12:16.967: INFO: stdout: "Name:               oltf-408483-kube-master\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=oltf-408483-kube-master\n                    node-role.kubernetes.io/master=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"de:5c:0d:dd:60:ac\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 100.100.242.160\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 08 Jan 2019 09:03:10 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Tue, 08 Jan 2019 10:12:07 +0000   Tue, 08 Jan 2019 09:03:10 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Tue, 08 Jan 2019 10:12:07 +0000   Tue, 08 Jan 2019 09:03:10 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 08 Jan 2019 10:12:07 +0000   Tue, 08 Jan 2019 09:03:10 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 08 Jan 2019 10:12:07 +0000   Tue, 08 Jan 2019 09:03:10 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 08 Jan 2019 10:12:07 +0000   Tue, 08 Jan 2019 09:04:00 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  100.100.242.160\n  Hostname:    oltf-408483-kube-master\nCapacity:\n cpu:                4\n ephemeral-storage:  40223552Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             14084884Ki\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  37070025462\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             13982484Ki\n pods:               110\nSystem Info:\n Machine ID:                 9d5499bb83384f399eb3639889deae5d\n System UUID:                9D5499BB-8338-4F39-9EB3-639889DEAE5D\n Boot ID:                    3b6006a3-48c0-4928-9d73-2b7a3d62bc39\n Kernel Version:             4.14.35-1844.2.0.el7uek.x86_64\n OS Image:                   Oracle Linux Server 7.6\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.3.1\n Kubelet Version:            v1.12.3+2.0.6.el7\n Kube-Proxy Version:         v1.12.3+2.0.6.el7\nPodCIDR:                     10.244.0.0/24\nNon-terminated Pods:         (10 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-e6ac5c1d15cd4528-mblhl    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                coredns-7cdcb9c958-7zmv9                                   100m (2%)     0 (0%)      70Mi (0%)        170Mi (1%)\n  kube-system                coredns-7cdcb9c958-j9lc8                                   100m (2%)     0 (0%)      70Mi (0%)        170Mi (1%)\n  kube-system                etcd-oltf-408483-kube-master                               0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-apiserver-oltf-408483-kube-master                     250m (6%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-controller-manager-oltf-408483-kube-master            200m (5%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-flannel-ds-kdfwt                                      100m (2%)     100m (2%)   100Mi (0%)       100Mi (0%)\n  kube-system                kube-proxy-gxt29                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-scheduler-oltf-408483-kube-master                     100m (2%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                kubernetes-dashboard-5f47c877c8-rx8zl                      0 (0%)        0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests    Limits\n  --------  --------    ------\n  cpu       850m (21%)  100m (2%)\n  memory    240Mi (1%)  440Mi (3%)\nEvents:     <none>\n"
Jan  8 10:12:16.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 describe namespace e2e-tests-kubectl-gmww7'
Jan  8 10:12:17.068: INFO: stderr: ""
Jan  8 10:12:17.068: INFO: stdout: "Name:         e2e-tests-kubectl-gmww7\nLabels:       e2e-framework=kubectl\n              e2e-run=9568e46c-1325-11e9-bc05-0a580af40202\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:12:17.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gmww7" for this suite.
Jan  8 10:12:39.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:12:39.121: INFO: namespace: e2e-tests-kubectl-gmww7, resource: bindings, ignored listing per whitelist
Jan  8 10:12:39.173: INFO: namespace e2e-tests-kubectl-gmww7 deletion completed in 22.10125025s

â€¢ [SLOW TEST:25.131 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:12:39.173: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-ed9e2c21-132d-11e9-bc05-0a580af40202
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-ed9e2c21-132d-11e9-bc05-0a580af40202
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:12:43.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nw4lj" for this suite.
Jan  8 10:13:05.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:13:05.394: INFO: namespace: e2e-tests-configmap-nw4lj, resource: bindings, ignored listing per whitelist
Jan  8 10:13:05.426: INFO: namespace e2e-tests-configmap-nw4lj deletion completed in 22.115382933s

â€¢ [SLOW TEST:26.252 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:13:05.426: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-vxz5c
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Jan  8 10:13:05.516: INFO: Found 0 stateful pods, waiting for 3
Jan  8 10:13:15.520: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan  8 10:13:15.521: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan  8 10:13:15.521: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan  8 10:13:15.558: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jan  8 10:13:25.597: INFO: Updating stateful set ss2
Jan  8 10:13:25.603: INFO: Waiting for Pod e2e-tests-statefulset-vxz5c/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Jan  8 10:13:35.654: INFO: Found 1 stateful pods, waiting for 3
Jan  8 10:13:45.659: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan  8 10:13:45.659: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan  8 10:13:45.659: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jan  8 10:13:45.686: INFO: Updating stateful set ss2
Jan  8 10:13:45.692: INFO: Waiting for Pod e2e-tests-statefulset-vxz5c/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan  8 10:13:55.700: INFO: Waiting for Pod e2e-tests-statefulset-vxz5c/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan  8 10:14:05.718: INFO: Updating stateful set ss2
Jan  8 10:14:05.726: INFO: Waiting for StatefulSet e2e-tests-statefulset-vxz5c/ss2 to complete update
Jan  8 10:14:05.726: INFO: Waiting for Pod e2e-tests-statefulset-vxz5c/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan  8 10:14:15.734: INFO: Deleting all statefulset in ns e2e-tests-statefulset-vxz5c
Jan  8 10:14:15.737: INFO: Scaling statefulset ss2 to 0
Jan  8 10:14:35.752: INFO: Waiting for statefulset status.replicas updated to 0
Jan  8 10:14:35.755: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:14:35.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-vxz5c" for this suite.
Jan  8 10:14:41.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:14:41.802: INFO: namespace: e2e-tests-statefulset-vxz5c, resource: bindings, ignored listing per whitelist
Jan  8 10:14:41.887: INFO: namespace e2e-tests-statefulset-vxz5c deletion completed in 6.113840351s

â€¢ [SLOW TEST:96.461 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:14:41.887: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  8 10:14:41.977: INFO: Waiting up to 5m0s for pod "downwardapi-volume-36c35c6d-132e-11e9-bc05-0a580af40202" in namespace "e2e-tests-projected-mhn4l" to be "success or failure"
Jan  8 10:14:41.983: INFO: Pod "downwardapi-volume-36c35c6d-132e-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 5.940057ms
Jan  8 10:14:43.987: INFO: Pod "downwardapi-volume-36c35c6d-132e-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00986256s
STEP: Saw pod success
Jan  8 10:14:43.987: INFO: Pod "downwardapi-volume-36c35c6d-132e-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:14:43.989: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod downwardapi-volume-36c35c6d-132e-11e9-bc05-0a580af40202 container client-container: <nil>
STEP: delete the pod
Jan  8 10:14:44.009: INFO: Waiting for pod downwardapi-volume-36c35c6d-132e-11e9-bc05-0a580af40202 to disappear
Jan  8 10:14:44.012: INFO: Pod downwardapi-volume-36c35c6d-132e-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:14:44.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mhn4l" for this suite.
Jan  8 10:14:50.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:14:50.040: INFO: namespace: e2e-tests-projected-mhn4l, resource: bindings, ignored listing per whitelist
Jan  8 10:14:50.116: INFO: namespace e2e-tests-projected-mhn4l deletion completed in 6.100415688s

â€¢ [SLOW TEST:8.229 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:14:50.116: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-3ba907c5-132e-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume configMaps
Jan  8 10:14:50.196: INFO: Waiting up to 5m0s for pod "pod-configmaps-3ba9941c-132e-11e9-bc05-0a580af40202" in namespace "e2e-tests-configmap-r7k7t" to be "success or failure"
Jan  8 10:14:50.199: INFO: Pod "pod-configmaps-3ba9941c-132e-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.779773ms
Jan  8 10:14:52.202: INFO: Pod "pod-configmaps-3ba9941c-132e-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006565309s
STEP: Saw pod success
Jan  8 10:14:52.202: INFO: Pod "pod-configmaps-3ba9941c-132e-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:14:52.205: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-configmaps-3ba9941c-132e-11e9-bc05-0a580af40202 container configmap-volume-test: <nil>
STEP: delete the pod
Jan  8 10:14:52.222: INFO: Waiting for pod pod-configmaps-3ba9941c-132e-11e9-bc05-0a580af40202 to disappear
Jan  8 10:14:52.225: INFO: Pod pod-configmaps-3ba9941c-132e-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:14:52.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-r7k7t" for this suite.
Jan  8 10:14:58.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:14:58.314: INFO: namespace: e2e-tests-configmap-r7k7t, resource: bindings, ignored listing per whitelist
Jan  8 10:14:58.327: INFO: namespace e2e-tests-configmap-r7k7t deletion completed in 6.098661071s

â€¢ [SLOW TEST:8.211 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:14:58.327: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-408f84b0-132e-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume secrets
Jan  8 10:14:58.418: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-40900122-132e-11e9-bc05-0a580af40202" in namespace "e2e-tests-projected-dt6mn" to be "success or failure"
Jan  8 10:14:58.421: INFO: Pod "pod-projected-secrets-40900122-132e-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.945416ms
Jan  8 10:15:00.425: INFO: Pod "pod-projected-secrets-40900122-132e-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00656999s
STEP: Saw pod success
Jan  8 10:15:00.425: INFO: Pod "pod-projected-secrets-40900122-132e-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:15:00.428: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod pod-projected-secrets-40900122-132e-11e9-bc05-0a580af40202 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan  8 10:15:00.444: INFO: Waiting for pod pod-projected-secrets-40900122-132e-11e9-bc05-0a580af40202 to disappear
Jan  8 10:15:00.447: INFO: Pod pod-projected-secrets-40900122-132e-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:15:00.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dt6mn" for this suite.
Jan  8 10:15:06.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:15:06.535: INFO: namespace: e2e-tests-projected-dt6mn, resource: bindings, ignored listing per whitelist
Jan  8 10:15:06.554: INFO: namespace e2e-tests-projected-dt6mn deletion completed in 6.103653918s

â€¢ [SLOW TEST:8.227 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:15:06.554: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Jan  8 10:15:16.693: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:15:16.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-qvdr8" for this suite.
Jan  8 10:15:22.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:15:22.783: INFO: namespace: e2e-tests-gc-qvdr8, resource: bindings, ignored listing per whitelist
Jan  8 10:15:22.799: INFO: namespace e2e-tests-gc-qvdr8 deletion completed in 6.101620014s

â€¢ [SLOW TEST:16.244 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:15:22.799: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  8 10:15:22.882: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4f24d1c2-132e-11e9-bc05-0a580af40202" in namespace "e2e-tests-downward-api-glcmm" to be "success or failure"
Jan  8 10:15:22.885: INFO: Pod "downwardapi-volume-4f24d1c2-132e-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.51011ms
Jan  8 10:15:24.889: INFO: Pod "downwardapi-volume-4f24d1c2-132e-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0069724s
STEP: Saw pod success
Jan  8 10:15:24.889: INFO: Pod "downwardapi-volume-4f24d1c2-132e-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:15:24.892: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod downwardapi-volume-4f24d1c2-132e-11e9-bc05-0a580af40202 container client-container: <nil>
STEP: delete the pod
Jan  8 10:15:24.908: INFO: Waiting for pod downwardapi-volume-4f24d1c2-132e-11e9-bc05-0a580af40202 to disappear
Jan  8 10:15:24.911: INFO: Pod downwardapi-volume-4f24d1c2-132e-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:15:24.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-glcmm" for this suite.
Jan  8 10:15:30.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:15:30.986: INFO: namespace: e2e-tests-downward-api-glcmm, resource: bindings, ignored listing per whitelist
Jan  8 10:15:31.023: INFO: namespace e2e-tests-downward-api-glcmm deletion completed in 6.108666033s

â€¢ [SLOW TEST:8.224 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:15:31.023: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-p46pr.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-p46pr.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-p46pr.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-p46pr.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-p46pr.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-p46pr.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan  8 10:15:43.190: INFO: DNS probes using e2e-tests-dns-p46pr/dns-test-540bbfcd-132e-11e9-bc05-0a580af40202 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:15:43.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-p46pr" for this suite.
Jan  8 10:15:49.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:15:49.298: INFO: namespace: e2e-tests-dns-p46pr, resource: bindings, ignored listing per whitelist
Jan  8 10:15:49.314: INFO: namespace e2e-tests-dns-p46pr deletion completed in 6.105477245s

â€¢ [SLOW TEST:18.291 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:15:49.314: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan  8 10:15:49.404: INFO: Waiting up to 5m0s for pod "pod-5ef3f72c-132e-11e9-bc05-0a580af40202" in namespace "e2e-tests-emptydir-l7cpj" to be "success or failure"
Jan  8 10:15:49.407: INFO: Pod "pod-5ef3f72c-132e-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.574102ms
Jan  8 10:15:51.411: INFO: Pod "pod-5ef3f72c-132e-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007133701s
STEP: Saw pod success
Jan  8 10:15:51.411: INFO: Pod "pod-5ef3f72c-132e-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:15:51.414: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-5ef3f72c-132e-11e9-bc05-0a580af40202 container test-container: <nil>
STEP: delete the pod
Jan  8 10:15:51.430: INFO: Waiting for pod pod-5ef3f72c-132e-11e9-bc05-0a580af40202 to disappear
Jan  8 10:15:51.432: INFO: Pod pod-5ef3f72c-132e-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:15:51.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-l7cpj" for this suite.
Jan  8 10:15:57.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:15:57.459: INFO: namespace: e2e-tests-emptydir-l7cpj, resource: bindings, ignored listing per whitelist
Jan  8 10:15:57.536: INFO: namespace e2e-tests-emptydir-l7cpj deletion completed in 6.100236744s

â€¢ [SLOW TEST:8.222 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:15:57.536: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-63d8541b-132e-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume secrets
Jan  8 10:15:57.615: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-63d8e9d7-132e-11e9-bc05-0a580af40202" in namespace "e2e-tests-projected-dk7w5" to be "success or failure"
Jan  8 10:15:57.618: INFO: Pod "pod-projected-secrets-63d8e9d7-132e-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.778826ms
Jan  8 10:15:59.623: INFO: Pod "pod-projected-secrets-63d8e9d7-132e-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007512437s
STEP: Saw pod success
Jan  8 10:15:59.623: INFO: Pod "pod-projected-secrets-63d8e9d7-132e-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:15:59.625: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod pod-projected-secrets-63d8e9d7-132e-11e9-bc05-0a580af40202 container secret-volume-test: <nil>
STEP: delete the pod
Jan  8 10:15:59.642: INFO: Waiting for pod pod-projected-secrets-63d8e9d7-132e-11e9-bc05-0a580af40202 to disappear
Jan  8 10:15:59.645: INFO: Pod pod-projected-secrets-63d8e9d7-132e-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:15:59.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dk7w5" for this suite.
Jan  8 10:16:05.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:16:05.750: INFO: namespace: e2e-tests-projected-dk7w5, resource: bindings, ignored listing per whitelist
Jan  8 10:16:05.753: INFO: namespace e2e-tests-projected-dk7w5 deletion completed in 6.104863012s

â€¢ [SLOW TEST:8.217 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:16:05.753: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Jan  8 10:16:05.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 cluster-info'
Jan  8 10:16:05.919: INFO: stderr: ""
Jan  8 10:16:05.919: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:16:05.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xfh2f" for this suite.
Jan  8 10:16:11.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:16:12.017: INFO: namespace: e2e-tests-kubectl-xfh2f, resource: bindings, ignored listing per whitelist
Jan  8 10:16:12.052: INFO: namespace e2e-tests-kubectl-xfh2f deletion completed in 6.128213701s

â€¢ [SLOW TEST:6.299 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:16:12.052: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-6c7f509a-132e-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume secrets
Jan  8 10:16:12.132: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6c7fe2b6-132e-11e9-bc05-0a580af40202" in namespace "e2e-tests-projected-mgglj" to be "success or failure"
Jan  8 10:16:12.138: INFO: Pod "pod-projected-secrets-6c7fe2b6-132e-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 5.755801ms
Jan  8 10:16:14.142: INFO: Pod "pod-projected-secrets-6c7fe2b6-132e-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009742774s
STEP: Saw pod success
Jan  8 10:16:14.142: INFO: Pod "pod-projected-secrets-6c7fe2b6-132e-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:16:14.145: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod pod-projected-secrets-6c7fe2b6-132e-11e9-bc05-0a580af40202 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan  8 10:16:14.165: INFO: Waiting for pod pod-projected-secrets-6c7fe2b6-132e-11e9-bc05-0a580af40202 to disappear
Jan  8 10:16:14.168: INFO: Pod pod-projected-secrets-6c7fe2b6-132e-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:16:14.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mgglj" for this suite.
Jan  8 10:16:20.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:16:20.227: INFO: namespace: e2e-tests-projected-mgglj, resource: bindings, ignored listing per whitelist
Jan  8 10:16:20.274: INFO: namespace e2e-tests-projected-mgglj deletion completed in 6.102936628s

â€¢ [SLOW TEST:8.222 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:16:20.275: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Jan  8 10:16:20.355: INFO: Waiting up to 5m0s for pod "client-containers-7166c6a3-132e-11e9-bc05-0a580af40202" in namespace "e2e-tests-containers-4w2fc" to be "success or failure"
Jan  8 10:16:20.359: INFO: Pod "client-containers-7166c6a3-132e-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.393081ms
Jan  8 10:16:22.363: INFO: Pod "client-containers-7166c6a3-132e-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007378819s
Jan  8 10:16:24.366: INFO: Pod "client-containers-7166c6a3-132e-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011220561s
Jan  8 10:16:26.370: INFO: Pod "client-containers-7166c6a3-132e-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014859734s
STEP: Saw pod success
Jan  8 10:16:26.370: INFO: Pod "client-containers-7166c6a3-132e-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:16:26.373: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod client-containers-7166c6a3-132e-11e9-bc05-0a580af40202 container test-container: <nil>
STEP: delete the pod
Jan  8 10:16:26.391: INFO: Waiting for pod client-containers-7166c6a3-132e-11e9-bc05-0a580af40202 to disappear
Jan  8 10:16:26.394: INFO: Pod client-containers-7166c6a3-132e-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:16:26.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-4w2fc" for this suite.
Jan  8 10:16:32.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:16:32.461: INFO: namespace: e2e-tests-containers-4w2fc, resource: bindings, ignored listing per whitelist
Jan  8 10:16:32.497: INFO: namespace e2e-tests-containers-4w2fc deletion completed in 6.098473289s

â€¢ [SLOW TEST:12.222 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:16:32.497: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Jan  8 10:16:32.579: INFO: Waiting up to 5m0s for pod "pod-78b00924-132e-11e9-bc05-0a580af40202" in namespace "e2e-tests-emptydir-n6xkj" to be "success or failure"
Jan  8 10:16:32.582: INFO: Pod "pod-78b00924-132e-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.521424ms
Jan  8 10:16:34.585: INFO: Pod "pod-78b00924-132e-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006201991s
STEP: Saw pod success
Jan  8 10:16:34.585: INFO: Pod "pod-78b00924-132e-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:16:34.588: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-78b00924-132e-11e9-bc05-0a580af40202 container test-container: <nil>
STEP: delete the pod
Jan  8 10:16:34.604: INFO: Waiting for pod pod-78b00924-132e-11e9-bc05-0a580af40202 to disappear
Jan  8 10:16:34.607: INFO: Pod pod-78b00924-132e-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:16:34.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-n6xkj" for this suite.
Jan  8 10:16:40.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:16:40.659: INFO: namespace: e2e-tests-emptydir-n6xkj, resource: bindings, ignored listing per whitelist
Jan  8 10:16:40.712: INFO: namespace e2e-tests-emptydir-n6xkj deletion completed in 6.099297284s

â€¢ [SLOW TEST:8.215 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:16:40.712: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-mg7l8
Jan  8 10:16:42.796: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-mg7l8
STEP: checking the pod's current state and verifying that restartCount is present
Jan  8 10:16:42.799: INFO: Initial restart count of pod liveness-exec is 0
Jan  8 10:17:28.888: INFO: Restart count of pod e2e-tests-container-probe-mg7l8/liveness-exec is now 1 (46.088535942s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:17:28.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-mg7l8" for this suite.
Jan  8 10:17:34.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:17:34.981: INFO: namespace: e2e-tests-container-probe-mg7l8, resource: bindings, ignored listing per whitelist
Jan  8 10:17:35.019: INFO: namespace e2e-tests-container-probe-mg7l8 deletion completed in 6.107753357s

â€¢ [SLOW TEST:54.307 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:17:35.020: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-9df5775c-132e-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume configMaps
Jan  8 10:17:35.113: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9df5ffd0-132e-11e9-bc05-0a580af40202" in namespace "e2e-tests-projected-ndn6p" to be "success or failure"
Jan  8 10:17:35.116: INFO: Pod "pod-projected-configmaps-9df5ffd0-132e-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.946805ms
Jan  8 10:17:37.120: INFO: Pod "pod-projected-configmaps-9df5ffd0-132e-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006625128s
STEP: Saw pod success
Jan  8 10:17:37.120: INFO: Pod "pod-projected-configmaps-9df5ffd0-132e-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:17:37.123: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-projected-configmaps-9df5ffd0-132e-11e9-bc05-0a580af40202 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan  8 10:17:37.141: INFO: Waiting for pod pod-projected-configmaps-9df5ffd0-132e-11e9-bc05-0a580af40202 to disappear
Jan  8 10:17:37.144: INFO: Pod pod-projected-configmaps-9df5ffd0-132e-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:17:37.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ndn6p" for this suite.
Jan  8 10:17:43.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:17:43.199: INFO: namespace: e2e-tests-projected-ndn6p, resource: bindings, ignored listing per whitelist
Jan  8 10:17:43.250: INFO: namespace e2e-tests-projected-ndn6p deletion completed in 6.101948203s

â€¢ [SLOW TEST:8.230 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:17:43.250: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-6b7t7
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-6b7t7
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-6b7t7
Jan  8 10:17:43.342: INFO: Found 0 stateful pods, waiting for 1
Jan  8 10:17:53.346: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jan  8 10:17:53.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 exec --namespace=e2e-tests-statefulset-6b7t7 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  8 10:17:53.537: INFO: stderr: ""
Jan  8 10:17:53.537: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  8 10:17:53.537: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  8 10:17:53.541: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan  8 10:18:03.545: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan  8 10:18:03.545: INFO: Waiting for statefulset status.replicas updated to 0
Jan  8 10:18:03.564: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999762s
Jan  8 10:18:04.569: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.992796738s
Jan  8 10:18:05.573: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.988232819s
Jan  8 10:18:06.577: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.984439481s
Jan  8 10:18:07.581: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.980170627s
Jan  8 10:18:08.585: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.97622145s
Jan  8 10:18:09.589: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.971960064s
Jan  8 10:18:10.593: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.968358659s
Jan  8 10:18:11.596: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.964247771s
Jan  8 10:18:12.600: INFO: Verifying statefulset ss doesn't scale past 1 for another 960.710541ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-6b7t7
Jan  8 10:18:13.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 exec --namespace=e2e-tests-statefulset-6b7t7 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  8 10:18:13.782: INFO: stderr: ""
Jan  8 10:18:13.783: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  8 10:18:13.783: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  8 10:18:13.786: INFO: Found 1 stateful pods, waiting for 3
Jan  8 10:18:23.790: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan  8 10:18:23.790: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan  8 10:18:23.790: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jan  8 10:18:23.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 exec --namespace=e2e-tests-statefulset-6b7t7 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  8 10:18:23.974: INFO: stderr: ""
Jan  8 10:18:23.974: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  8 10:18:23.974: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  8 10:18:23.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 exec --namespace=e2e-tests-statefulset-6b7t7 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  8 10:18:24.157: INFO: stderr: ""
Jan  8 10:18:24.157: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  8 10:18:24.157: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  8 10:18:24.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 exec --namespace=e2e-tests-statefulset-6b7t7 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  8 10:18:24.336: INFO: stderr: ""
Jan  8 10:18:24.336: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  8 10:18:24.336: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  8 10:18:24.336: INFO: Waiting for statefulset status.replicas updated to 0
Jan  8 10:18:24.339: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Jan  8 10:18:34.347: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan  8 10:18:34.347: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan  8 10:18:34.347: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan  8 10:18:34.358: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999744s
Jan  8 10:18:35.364: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996195093s
Jan  8 10:18:36.368: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990333307s
Jan  8 10:18:37.373: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.986273364s
Jan  8 10:18:38.377: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.981506796s
Jan  8 10:18:39.382: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.977127289s
Jan  8 10:18:40.386: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972520067s
Jan  8 10:18:41.391: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.96809442s
Jan  8 10:18:42.396: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.963428689s
Jan  8 10:18:43.399: INFO: Verifying statefulset ss doesn't scale past 3 for another 958.952548ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-6b7t7
Jan  8 10:18:44.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 exec --namespace=e2e-tests-statefulset-6b7t7 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  8 10:18:44.583: INFO: stderr: ""
Jan  8 10:18:44.583: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  8 10:18:44.583: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  8 10:18:44.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 exec --namespace=e2e-tests-statefulset-6b7t7 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  8 10:18:44.760: INFO: stderr: ""
Jan  8 10:18:44.760: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  8 10:18:44.760: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  8 10:18:44.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 exec --namespace=e2e-tests-statefulset-6b7t7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  8 10:18:44.938: INFO: stderr: ""
Jan  8 10:18:44.938: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  8 10:18:44.938: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  8 10:18:44.938: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan  8 10:19:04.955: INFO: Deleting all statefulset in ns e2e-tests-statefulset-6b7t7
Jan  8 10:19:04.958: INFO: Scaling statefulset ss to 0
Jan  8 10:19:04.968: INFO: Waiting for statefulset status.replicas updated to 0
Jan  8 10:19:04.971: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:19:04.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-6b7t7" for this suite.
Jan  8 10:19:11.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:19:11.033: INFO: namespace: e2e-tests-statefulset-6b7t7, resource: bindings, ignored listing per whitelist
Jan  8 10:19:11.092: INFO: namespace e2e-tests-statefulset-6b7t7 deletion completed in 6.102685965s

â€¢ [SLOW TEST:87.842 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:19:11.092: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan  8 10:19:15.203: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  8 10:19:15.206: INFO: Pod pod-with-prestop-exec-hook still exists
Jan  8 10:19:17.207: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  8 10:19:17.210: INFO: Pod pod-with-prestop-exec-hook still exists
Jan  8 10:19:19.207: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  8 10:19:19.210: INFO: Pod pod-with-prestop-exec-hook still exists
Jan  8 10:19:21.207: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  8 10:19:21.210: INFO: Pod pod-with-prestop-exec-hook still exists
Jan  8 10:19:23.207: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  8 10:19:23.210: INFO: Pod pod-with-prestop-exec-hook still exists
Jan  8 10:19:25.207: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  8 10:19:25.210: INFO: Pod pod-with-prestop-exec-hook still exists
Jan  8 10:19:27.207: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  8 10:19:27.210: INFO: Pod pod-with-prestop-exec-hook still exists
Jan  8 10:19:29.207: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  8 10:19:29.210: INFO: Pod pod-with-prestop-exec-hook still exists
Jan  8 10:19:31.207: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  8 10:19:31.210: INFO: Pod pod-with-prestop-exec-hook still exists
Jan  8 10:19:33.207: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  8 10:19:33.210: INFO: Pod pod-with-prestop-exec-hook still exists
Jan  8 10:19:35.207: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan  8 10:19:35.215: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:19:35.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-cnplr" for this suite.
Jan  8 10:19:57.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:19:57.299: INFO: namespace: e2e-tests-container-lifecycle-hook-cnplr, resource: bindings, ignored listing per whitelist
Jan  8 10:19:57.329: INFO: namespace e2e-tests-container-lifecycle-hook-cnplr deletion completed in 22.100455825s

â€¢ [SLOW TEST:46.237 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:19:57.329: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  8 10:19:57.409: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f2c69a65-132e-11e9-bc05-0a580af40202" in namespace "e2e-tests-projected-hz8n5" to be "success or failure"
Jan  8 10:19:57.414: INFO: Pod "downwardapi-volume-f2c69a65-132e-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.084237ms
Jan  8 10:19:59.417: INFO: Pod "downwardapi-volume-f2c69a65-132e-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007597195s
STEP: Saw pod success
Jan  8 10:19:59.417: INFO: Pod "downwardapi-volume-f2c69a65-132e-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:19:59.420: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod downwardapi-volume-f2c69a65-132e-11e9-bc05-0a580af40202 container client-container: <nil>
STEP: delete the pod
Jan  8 10:19:59.437: INFO: Waiting for pod downwardapi-volume-f2c69a65-132e-11e9-bc05-0a580af40202 to disappear
Jan  8 10:19:59.439: INFO: Pod downwardapi-volume-f2c69a65-132e-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:19:59.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hz8n5" for this suite.
Jan  8 10:20:05.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:20:05.539: INFO: namespace: e2e-tests-projected-hz8n5, resource: bindings, ignored listing per whitelist
Jan  8 10:20:05.544: INFO: namespace e2e-tests-projected-hz8n5 deletion completed in 6.10158583s

â€¢ [SLOW TEST:8.215 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:20:05.545: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-f7abde28-132e-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume configMaps
Jan  8 10:20:05.626: INFO: Waiting up to 5m0s for pod "pod-configmaps-f7ac60a2-132e-11e9-bc05-0a580af40202" in namespace "e2e-tests-configmap-lrfst" to be "success or failure"
Jan  8 10:20:05.629: INFO: Pod "pod-configmaps-f7ac60a2-132e-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.720557ms
Jan  8 10:20:07.632: INFO: Pod "pod-configmaps-f7ac60a2-132e-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006305519s
STEP: Saw pod success
Jan  8 10:20:07.633: INFO: Pod "pod-configmaps-f7ac60a2-132e-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:20:07.635: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod pod-configmaps-f7ac60a2-132e-11e9-bc05-0a580af40202 container configmap-volume-test: <nil>
STEP: delete the pod
Jan  8 10:20:07.654: INFO: Waiting for pod pod-configmaps-f7ac60a2-132e-11e9-bc05-0a580af40202 to disappear
Jan  8 10:20:07.657: INFO: Pod pod-configmaps-f7ac60a2-132e-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:20:07.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lrfst" for this suite.
Jan  8 10:20:13.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:20:13.714: INFO: namespace: e2e-tests-configmap-lrfst, resource: bindings, ignored listing per whitelist
Jan  8 10:20:13.760: INFO: namespace e2e-tests-configmap-lrfst deletion completed in 6.099895668s

â€¢ [SLOW TEST:8.216 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:20:13.761: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Jan  8 10:20:23.865: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:20:23.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-vhb88" for this suite.
Jan  8 10:20:29.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:20:29.934: INFO: namespace: e2e-tests-gc-vhb88, resource: bindings, ignored listing per whitelist
Jan  8 10:20:29.988: INFO: namespace e2e-tests-gc-vhb88 deletion completed in 6.119006975s

â€¢ [SLOW TEST:16.227 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:20:29.988: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-063e05d6-132f-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume configMaps
Jan  8 10:20:30.072: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-063e8a07-132f-11e9-bc05-0a580af40202" in namespace "e2e-tests-projected-h8d26" to be "success or failure"
Jan  8 10:20:30.075: INFO: Pod "pod-projected-configmaps-063e8a07-132f-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.035691ms
Jan  8 10:20:32.079: INFO: Pod "pod-projected-configmaps-063e8a07-132f-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006931379s
STEP: Saw pod success
Jan  8 10:20:32.079: INFO: Pod "pod-projected-configmaps-063e8a07-132f-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:20:32.082: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-projected-configmaps-063e8a07-132f-11e9-bc05-0a580af40202 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan  8 10:20:32.099: INFO: Waiting for pod pod-projected-configmaps-063e8a07-132f-11e9-bc05-0a580af40202 to disappear
Jan  8 10:20:32.101: INFO: Pod pod-projected-configmaps-063e8a07-132f-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:20:32.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h8d26" for this suite.
Jan  8 10:20:38.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:20:38.143: INFO: namespace: e2e-tests-projected-h8d26, resource: bindings, ignored listing per whitelist
Jan  8 10:20:38.204: INFO: namespace e2e-tests-projected-h8d26 deletion completed in 6.0994082s

â€¢ [SLOW TEST:8.217 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:20:38.205: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-0b239584-132f-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume configMaps
Jan  8 10:20:38.288: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0b24235a-132f-11e9-bc05-0a580af40202" in namespace "e2e-tests-projected-lp7dp" to be "success or failure"
Jan  8 10:20:38.291: INFO: Pod "pod-projected-configmaps-0b24235a-132f-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.74607ms
Jan  8 10:20:40.295: INFO: Pod "pod-projected-configmaps-0b24235a-132f-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007334863s
STEP: Saw pod success
Jan  8 10:20:40.295: INFO: Pod "pod-projected-configmaps-0b24235a-132f-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:20:40.298: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod pod-projected-configmaps-0b24235a-132f-11e9-bc05-0a580af40202 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan  8 10:20:40.317: INFO: Waiting for pod pod-projected-configmaps-0b24235a-132f-11e9-bc05-0a580af40202 to disappear
Jan  8 10:20:40.323: INFO: Pod pod-projected-configmaps-0b24235a-132f-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:20:40.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lp7dp" for this suite.
Jan  8 10:20:46.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:20:46.390: INFO: namespace: e2e-tests-projected-lp7dp, resource: bindings, ignored listing per whitelist
Jan  8 10:20:46.430: INFO: namespace e2e-tests-projected-lp7dp deletion completed in 6.103630137s

â€¢ [SLOW TEST:8.226 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:20:46.431: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-100b4cf0-132f-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume configMaps
Jan  8 10:20:46.517: INFO: Waiting up to 5m0s for pod "pod-configmaps-100bc34e-132f-11e9-bc05-0a580af40202" in namespace "e2e-tests-configmap-shbvz" to be "success or failure"
Jan  8 10:20:46.523: INFO: Pod "pod-configmaps-100bc34e-132f-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 5.417339ms
Jan  8 10:20:48.527: INFO: Pod "pod-configmaps-100bc34e-132f-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009450631s
STEP: Saw pod success
Jan  8 10:20:48.527: INFO: Pod "pod-configmaps-100bc34e-132f-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:20:48.529: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-configmaps-100bc34e-132f-11e9-bc05-0a580af40202 container configmap-volume-test: <nil>
STEP: delete the pod
Jan  8 10:20:48.546: INFO: Waiting for pod pod-configmaps-100bc34e-132f-11e9-bc05-0a580af40202 to disappear
Jan  8 10:20:48.549: INFO: Pod pod-configmaps-100bc34e-132f-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:20:48.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-shbvz" for this suite.
Jan  8 10:20:54.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:20:54.618: INFO: namespace: e2e-tests-configmap-shbvz, resource: bindings, ignored listing per whitelist
Jan  8 10:20:54.662: INFO: namespace e2e-tests-configmap-shbvz deletion completed in 6.108919966s

â€¢ [SLOW TEST:8.231 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:20:54.662: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  8 10:20:54.732: INFO: Creating deployment "nginx-deployment"
Jan  8 10:20:54.736: INFO: Waiting for observed generation 1
Jan  8 10:20:56.743: INFO: Waiting for all required pods to come up
Jan  8 10:20:56.749: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Jan  8 10:20:58.763: INFO: Waiting for deployment "nginx-deployment" to complete
Jan  8 10:20:58.769: INFO: Updating deployment "nginx-deployment" with a non-existent image
Jan  8 10:20:58.777: INFO: Updating deployment nginx-deployment
Jan  8 10:20:58.777: INFO: Waiting for observed generation 2
Jan  8 10:21:00.784: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jan  8 10:21:00.787: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jan  8 10:21:00.789: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan  8 10:21:00.797: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jan  8 10:21:00.797: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jan  8 10:21:00.800: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan  8 10:21:00.805: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Jan  8 10:21:00.805: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Jan  8 10:21:00.813: INFO: Updating deployment nginx-deployment
Jan  8 10:21:00.813: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Jan  8 10:21:00.820: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jan  8 10:21:00.833: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan  8 10:21:00.884: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-g8f2g/deployments/nginx-deployment,UID:14f279e4-132f-11e9-a60a-02001701fa35,ResourceVersion:15524,Generation:3,CreationTimestamp:2019-01-08 10:20:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2019-01-08 10:20:58 +0000 UTC 2019-01-08 10:20:54 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.} {Available False 2019-01-08 10:21:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Jan  8 10:21:00.906: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-g8f2g/replicasets/nginx-deployment-7dc8f79789,UID:175bcab4-132f-11e9-a60a-02001701fa35,ResourceVersion:15515,Generation:3,CreationTimestamp:2019-01-08 10:20:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 14f279e4-132f-11e9-a60a-02001701fa35 0xc422c913c7 0xc422c913c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan  8 10:21:00.906: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Jan  8 10:21:00.906: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-g8f2g/replicasets/nginx-deployment-7f9675fb8b,UID:14f3f049-132f-11e9-a60a-02001701fa35,ResourceVersion:15513,Generation:3,CreationTimestamp:2019-01-08 10:20:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 14f279e4-132f-11e9-a60a-02001701fa35 0xc422c91497 0xc422c91498}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Jan  8 10:21:00.937: INFO: Pod "nginx-deployment-7dc8f79789-7c6hj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-7c6hj,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7dc8f79789-7c6hj,UID:175d4457-132f-11e9-a60a-02001701fa35,ResourceVersion:15480,Generation:0,CreationTimestamp:2019-01-08 10:20:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 175bcab4-132f-11e9-a60a-02001701fa35 0xc4229fb0e7 0xc4229fb0e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4229fb150} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4229fb170}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:58 +0000 UTC  }],Message:,Reason:,HostIP:100.100.242.163,PodIP:,StartTime:2019-01-08 10:20:58 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.938: INFO: Pod "nginx-deployment-7dc8f79789-bdcdw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-bdcdw,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7dc8f79789-bdcdw,UID:189e5eb0-132f-11e9-a60a-02001701fa35,ResourceVersion:15557,Generation:0,CreationTimestamp:2019-01-08 10:21:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 175bcab4-132f-11e9-a60a-02001701fa35 0xc4229fb230 0xc4229fb231}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4229fb2b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4229fb2d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.938: INFO: Pod "nginx-deployment-7dc8f79789-c8j6x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-c8j6x,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7dc8f79789-c8j6x,UID:1896c0b3-132f-11e9-a60a-02001701fa35,ResourceVersion:15538,Generation:0,CreationTimestamp:2019-01-08 10:21:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 175bcab4-132f-11e9-a60a-02001701fa35 0xc4229fb327 0xc4229fb328}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4229fb390} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4229fb3c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.938: INFO: Pod "nginx-deployment-7dc8f79789-cnxtj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-cnxtj,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7dc8f79789-cnxtj,UID:189a1cdb-132f-11e9-a60a-02001701fa35,ResourceVersion:15553,Generation:0,CreationTimestamp:2019-01-08 10:21:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 175bcab4-132f-11e9-a60a-02001701fa35 0xc4229fb630 0xc4229fb631}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4229fb6a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4229fb6c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.938: INFO: Pod "nginx-deployment-7dc8f79789-fr9gt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-fr9gt,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7dc8f79789-fr9gt,UID:17652295-132f-11e9-a60a-02001701fa35,ResourceVersion:15496,Generation:0,CreationTimestamp:2019-01-08 10:20:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 175bcab4-132f-11e9-a60a-02001701fa35 0xc4229fbf00 0xc4229fbf01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4229fbf70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4229fbf90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:58 +0000 UTC  }],Message:,Reason:,HostIP:100.100.242.162,PodIP:,StartTime:2019-01-08 10:20:58 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.938: INFO: Pod "nginx-deployment-7dc8f79789-kdc5r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-kdc5r,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7dc8f79789-kdc5r,UID:189a42df-132f-11e9-a60a-02001701fa35,ResourceVersion:15559,Generation:0,CreationTimestamp:2019-01-08 10:21:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 175bcab4-132f-11e9-a60a-02001701fa35 0xc422830050 0xc422830051}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4228300c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4228300e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.939: INFO: Pod "nginx-deployment-7dc8f79789-mlfh7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-mlfh7,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7dc8f79789-mlfh7,UID:18945e5c-132f-11e9-a60a-02001701fa35,ResourceVersion:15530,Generation:0,CreationTimestamp:2019-01-08 10:21:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 175bcab4-132f-11e9-a60a-02001701fa35 0xc422830230 0xc422830231}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4228302a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4228302c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.939: INFO: Pod "nginx-deployment-7dc8f79789-nkptt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-nkptt,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7dc8f79789-nkptt,UID:1896995a-132f-11e9-a60a-02001701fa35,ResourceVersion:15539,Generation:0,CreationTimestamp:2019-01-08 10:21:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 175bcab4-132f-11e9-a60a-02001701fa35 0xc4228303a0 0xc4228303a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422830480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4228304b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.939: INFO: Pod "nginx-deployment-7dc8f79789-pjksw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-pjksw,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7dc8f79789-pjksw,UID:175c7b9a-132f-11e9-a60a-02001701fa35,ResourceVersion:15471,Generation:0,CreationTimestamp:2019-01-08 10:20:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 175bcab4-132f-11e9-a60a-02001701fa35 0xc422830590 0xc422830591}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422830600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422830620}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:58 +0000 UTC  }],Message:,Reason:,HostIP:100.100.242.163,PodIP:,StartTime:2019-01-08 10:20:58 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.939: INFO: Pod "nginx-deployment-7dc8f79789-rvxq4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-rvxq4,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7dc8f79789-rvxq4,UID:17662c47-132f-11e9-a60a-02001701fa35,ResourceVersion:15499,Generation:0,CreationTimestamp:2019-01-08 10:20:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 175bcab4-132f-11e9-a60a-02001701fa35 0xc422830770 0xc422830771}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4228307e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422830800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:58 +0000 UTC  }],Message:,Reason:,HostIP:100.100.242.163,PodIP:,StartTime:2019-01-08 10:20:58 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.939: INFO: Pod "nginx-deployment-7dc8f79789-shbpq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-shbpq,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7dc8f79789-shbpq,UID:189a3e54-132f-11e9-a60a-02001701fa35,ResourceVersion:15555,Generation:0,CreationTimestamp:2019-01-08 10:21:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 175bcab4-132f-11e9-a60a-02001701fa35 0xc422830970 0xc422830971}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4228309e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422830a00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.940: INFO: Pod "nginx-deployment-7dc8f79789-zqzkj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-zqzkj,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7dc8f79789-zqzkj,UID:175d3da0-132f-11e9-a60a-02001701fa35,ResourceVersion:15477,Generation:0,CreationTimestamp:2019-01-08 10:20:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 175bcab4-132f-11e9-a60a-02001701fa35 0xc422830bb0 0xc422830bb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422830c20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422830c40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:58 +0000 UTC  }],Message:,Reason:,HostIP:100.100.242.162,PodIP:,StartTime:2019-01-08 10:20:58 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.940: INFO: Pod "nginx-deployment-7dc8f79789-zzj8t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-zzj8t,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7dc8f79789-zzj8t,UID:189aa24d-132f-11e9-a60a-02001701fa35,ResourceVersion:15563,Generation:0,CreationTimestamp:2019-01-08 10:21:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 175bcab4-132f-11e9-a60a-02001701fa35 0xc422830d80 0xc422830d81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422830df0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422830e10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.940: INFO: Pod "nginx-deployment-7f9675fb8b-52j54" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-52j54,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7f9675fb8b-52j54,UID:14f8f5a0-132f-11e9-a60a-02001701fa35,ResourceVersion:15429,Generation:0,CreationTimestamp:2019-01-08 10:20:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 14f3f049-132f-11e9-a60a-02001701fa35 0xc422830e80 0xc422830e81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422830ee0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422830f00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:54 +0000 UTC  }],Message:,Reason:,HostIP:100.100.242.162,PodIP:10.244.1.154,StartTime:2019-01-08 10:20:54 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-08 10:20:56 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://069273df52c3c62880d0a8dc24dcc2e6b5ef87299dd810548ab3ce1d354ed2ed}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.940: INFO: Pod "nginx-deployment-7f9675fb8b-5bgb2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-5bgb2,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7f9675fb8b-5bgb2,UID:14fba841-132f-11e9-a60a-02001701fa35,ResourceVersion:15435,Generation:0,CreationTimestamp:2019-01-08 10:20:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 14f3f049-132f-11e9-a60a-02001701fa35 0xc422830fc7 0xc422830fc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422831030} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422831050}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:54 +0000 UTC  }],Message:,Reason:,HostIP:100.100.242.162,PodIP:10.244.1.156,StartTime:2019-01-08 10:20:54 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-08 10:20:56 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://cdfa9cdc61d06f51fb5a32ccf41d8767d344709264c0a1e8650cf5447d7146dd}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.940: INFO: Pod "nginx-deployment-7f9675fb8b-5fwdj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-5fwdj,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7f9675fb8b-5fwdj,UID:189af300-132f-11e9-a60a-02001701fa35,ResourceVersion:15565,Generation:0,CreationTimestamp:2019-01-08 10:21:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 14f3f049-132f-11e9-a60a-02001701fa35 0xc422831117 0xc422831118}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422831180} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4228311a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.941: INFO: Pod "nginx-deployment-7f9675fb8b-5p7gg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-5p7gg,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7f9675fb8b-5p7gg,UID:14f6eafb-132f-11e9-a60a-02001701fa35,ResourceVersion:15398,Generation:0,CreationTimestamp:2019-01-08 10:20:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 14f3f049-132f-11e9-a60a-02001701fa35 0xc422831210 0xc422831211}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422831270} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422831290}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:54 +0000 UTC  }],Message:,Reason:,HostIP:100.100.242.162,PodIP:10.244.1.153,StartTime:2019-01-08 10:20:54 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-08 10:20:55 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://58f9eec306aaf3b6d0fa0c7b75c2bfa4a74d5e810e4c95198abdbb88aff89bcd}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.941: INFO: Pod "nginx-deployment-7f9675fb8b-6dt24" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-6dt24,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7f9675fb8b-6dt24,UID:14f8de8e-132f-11e9-a60a-02001701fa35,ResourceVersion:15432,Generation:0,CreationTimestamp:2019-01-08 10:20:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 14f3f049-132f-11e9-a60a-02001701fa35 0xc422831367 0xc422831368}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4228313d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4228313f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:54 +0000 UTC  }],Message:,Reason:,HostIP:100.100.242.162,PodIP:10.244.1.155,StartTime:2019-01-08 10:20:54 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-08 10:20:56 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://dc661d6d05cb3af134fb10b944e12053d8608a9b9f795cb1779b23125c120cdd}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.941: INFO: Pod "nginx-deployment-7f9675fb8b-6x5mf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-6x5mf,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7f9675fb8b-6x5mf,UID:14f8b1f8-132f-11e9-a60a-02001701fa35,ResourceVersion:15447,Generation:0,CreationTimestamp:2019-01-08 10:20:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 14f3f049-132f-11e9-a60a-02001701fa35 0xc4228314c7 0xc4228314c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422831530} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422831550}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:54 +0000 UTC  }],Message:,Reason:,HostIP:100.100.242.163,PodIP:10.244.2.141,StartTime:2019-01-08 10:20:54 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-08 10:20:56 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://f136234b6924cbc1e86eecee10c7b1b4b54b9de5b7544d26d392ac775d53f8ae}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.941: INFO: Pod "nginx-deployment-7f9675fb8b-84tbm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-84tbm,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7f9675fb8b-84tbm,UID:189ac90d-132f-11e9-a60a-02001701fa35,ResourceVersion:15566,Generation:0,CreationTimestamp:2019-01-08 10:21:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 14f3f049-132f-11e9-a60a-02001701fa35 0xc4228319b7 0xc4228319b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422831e50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422831e70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.941: INFO: Pod "nginx-deployment-7f9675fb8b-9x776" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-9x776,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7f9675fb8b-9x776,UID:18964a29-132f-11e9-a60a-02001701fa35,ResourceVersion:15537,Generation:0,CreationTimestamp:2019-01-08 10:21:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 14f3f049-132f-11e9-a60a-02001701fa35 0xc422831ee0 0xc422831ee1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422831fd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422831ff0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.941: INFO: Pod "nginx-deployment-7f9675fb8b-bmw4s" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-bmw4s,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7f9675fb8b-bmw4s,UID:14f601de-132f-11e9-a60a-02001701fa35,ResourceVersion:15417,Generation:0,CreationTimestamp:2019-01-08 10:20:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 14f3f049-132f-11e9-a60a-02001701fa35 0xc4227f0480 0xc4227f0481}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4227f04e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4227f0500}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:56 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:54 +0000 UTC  }],Message:,Reason:,HostIP:100.100.242.163,PodIP:10.244.2.138,StartTime:2019-01-08 10:20:54 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-08 10:20:55 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://400695ff89efdbfe52056d3b9c63867cfdf069b7af5885a65a881d66c0497a49}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.942: INFO: Pod "nginx-deployment-7f9675fb8b-c6kng" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-c6kng,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7f9675fb8b-c6kng,UID:18975537-132f-11e9-a60a-02001701fa35,ResourceVersion:15536,Generation:0,CreationTimestamp:2019-01-08 10:21:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 14f3f049-132f-11e9-a60a-02001701fa35 0xc4227f0777 0xc4227f0778}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4227f07e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4227f0800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.942: INFO: Pod "nginx-deployment-7f9675fb8b-d86kl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-d86kl,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7f9675fb8b-d86kl,UID:189444d4-132f-11e9-a60a-02001701fa35,ResourceVersion:15533,Generation:0,CreationTimestamp:2019-01-08 10:21:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 14f3f049-132f-11e9-a60a-02001701fa35 0xc4227f08b0 0xc4227f08b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4227f0910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4227f0930}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.942: INFO: Pod "nginx-deployment-7f9675fb8b-j5m2c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-j5m2c,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7f9675fb8b-j5m2c,UID:189b15d6-132f-11e9-a60a-02001701fa35,ResourceVersion:15567,Generation:0,CreationTimestamp:2019-01-08 10:21:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 14f3f049-132f-11e9-a60a-02001701fa35 0xc4227f09b0 0xc4227f09b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4227f0a40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4227f0a60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.942: INFO: Pod "nginx-deployment-7f9675fb8b-m8g7j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-m8g7j,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7f9675fb8b-m8g7j,UID:1896f7ff-132f-11e9-a60a-02001701fa35,ResourceVersion:15540,Generation:0,CreationTimestamp:2019-01-08 10:21:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 14f3f049-132f-11e9-a60a-02001701fa35 0xc4227f0ad0 0xc4227f0ad1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4227f0ba0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4227f0bc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.942: INFO: Pod "nginx-deployment-7f9675fb8b-mgl94" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-mgl94,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7f9675fb8b-mgl94,UID:189af3e6-132f-11e9-a60a-02001701fa35,ResourceVersion:15560,Generation:0,CreationTimestamp:2019-01-08 10:21:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 14f3f049-132f-11e9-a60a-02001701fa35 0xc4227f0c30 0xc4227f0c31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4227f0c90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4227f0cb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.943: INFO: Pod "nginx-deployment-7f9675fb8b-nkxhp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-nkxhp,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7f9675fb8b-nkxhp,UID:14f6cfe6-132f-11e9-a60a-02001701fa35,ResourceVersion:15420,Generation:0,CreationTimestamp:2019-01-08 10:20:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 14f3f049-132f-11e9-a60a-02001701fa35 0xc4227f0e60 0xc4227f0e61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4227f0ec0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4227f0ee0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:56 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:54 +0000 UTC  }],Message:,Reason:,HostIP:100.100.242.163,PodIP:10.244.2.139,StartTime:2019-01-08 10:20:54 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-08 10:20:55 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://be8bac583fa4977703089086913bcf63cdd9ce0a97e3512ef40202daca408317}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.943: INFO: Pod "nginx-deployment-7f9675fb8b-qc44z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-qc44z,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7f9675fb8b-qc44z,UID:189442ae-132f-11e9-a60a-02001701fa35,ResourceVersion:15562,Generation:0,CreationTimestamp:2019-01-08 10:21:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 14f3f049-132f-11e9-a60a-02001701fa35 0xc4227f1077 0xc4227f1078}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4227f10e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4227f1100}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC  }],Message:,Reason:,HostIP:100.100.242.163,PodIP:,StartTime:2019-01-08 10:21:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.943: INFO: Pod "nginx-deployment-7f9675fb8b-t5cws" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-t5cws,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7f9675fb8b-t5cws,UID:14fbffd0-132f-11e9-a60a-02001701fa35,ResourceVersion:15441,Generation:0,CreationTimestamp:2019-01-08 10:20:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 14f3f049-132f-11e9-a60a-02001701fa35 0xc4227f1227 0xc4227f1228}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4227f1290} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4227f12b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:20:54 +0000 UTC  }],Message:,Reason:,HostIP:100.100.242.163,PodIP:10.244.2.140,StartTime:2019-01-08 10:20:54 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-08 10:20:56 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://9ccdaf1e0b91ce0979c108d904767b23e536d40a7ba9391d326d199c499aedcf}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.943: INFO: Pod "nginx-deployment-7f9675fb8b-vr5sh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-vr5sh,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7f9675fb8b-vr5sh,UID:18930f0f-132f-11e9-a60a-02001701fa35,ResourceVersion:15554,Generation:0,CreationTimestamp:2019-01-08 10:21:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 14f3f049-132f-11e9-a60a-02001701fa35 0xc4227f1387 0xc4227f1388}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4227f1460} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4227f1480}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC  }],Message:,Reason:,HostIP:100.100.242.162,PodIP:,StartTime:2019-01-08 10:21:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.944: INFO: Pod "nginx-deployment-7f9675fb8b-wzmt8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-wzmt8,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7f9675fb8b-wzmt8,UID:1896e123-132f-11e9-a60a-02001701fa35,ResourceVersion:15544,Generation:0,CreationTimestamp:2019-01-08 10:21:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 14f3f049-132f-11e9-a60a-02001701fa35 0xc4227f1537 0xc4227f1538}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4227f1610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4227f1630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  8 10:21:00.944: INFO: Pod "nginx-deployment-7f9675fb8b-znpnt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-znpnt,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-g8f2g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8f2g/pods/nginx-deployment-7f9675fb8b-znpnt,UID:189b14ec-132f-11e9-a60a-02001701fa35,ResourceVersion:15564,Generation:0,CreationTimestamp:2019-01-08 10:21:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 14f3f049-132f-11e9-a60a-02001701fa35 0xc4227f16a0 0xc4227f16a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4chh5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4chh5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4chh5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:oltf-408483-kube-worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4227f1700} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4227f1720}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-08 10:21:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:21:00.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-g8f2g" for this suite.
Jan  8 10:21:08.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:21:09.027: INFO: namespace: e2e-tests-deployment-g8f2g, resource: bindings, ignored listing per whitelist
Jan  8 10:21:09.064: INFO: namespace e2e-tests-deployment-g8f2g deletion completed in 8.114953813s

â€¢ [SLOW TEST:14.402 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:21:09.064: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan  8 10:21:09.145: INFO: Waiting up to 5m0s for pod "pod-1d887f71-132f-11e9-bc05-0a580af40202" in namespace "e2e-tests-emptydir-mr72f" to be "success or failure"
Jan  8 10:21:09.149: INFO: Pod "pod-1d887f71-132f-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.343762ms
Jan  8 10:21:11.152: INFO: Pod "pod-1d887f71-132f-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006691627s
STEP: Saw pod success
Jan  8 10:21:11.152: INFO: Pod "pod-1d887f71-132f-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:21:11.155: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-1d887f71-132f-11e9-bc05-0a580af40202 container test-container: <nil>
STEP: delete the pod
Jan  8 10:21:11.172: INFO: Waiting for pod pod-1d887f71-132f-11e9-bc05-0a580af40202 to disappear
Jan  8 10:21:11.175: INFO: Pod pod-1d887f71-132f-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:21:11.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mr72f" for this suite.
Jan  8 10:21:17.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:21:17.223: INFO: namespace: e2e-tests-emptydir-mr72f, resource: bindings, ignored listing per whitelist
Jan  8 10:21:17.284: INFO: namespace e2e-tests-emptydir-mr72f deletion completed in 6.105673466s

â€¢ [SLOW TEST:8.220 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:21:17.285: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-226e6230-132f-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume secrets
Jan  8 10:21:17.365: INFO: Waiting up to 5m0s for pod "pod-secrets-226ee6ee-132f-11e9-bc05-0a580af40202" in namespace "e2e-tests-secrets-cnhf2" to be "success or failure"
Jan  8 10:21:17.368: INFO: Pod "pod-secrets-226ee6ee-132f-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.719858ms
Jan  8 10:21:19.372: INFO: Pod "pod-secrets-226ee6ee-132f-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006408495s
STEP: Saw pod success
Jan  8 10:21:19.372: INFO: Pod "pod-secrets-226ee6ee-132f-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:21:19.375: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod pod-secrets-226ee6ee-132f-11e9-bc05-0a580af40202 container secret-volume-test: <nil>
STEP: delete the pod
Jan  8 10:21:19.392: INFO: Waiting for pod pod-secrets-226ee6ee-132f-11e9-bc05-0a580af40202 to disappear
Jan  8 10:21:19.394: INFO: Pod pod-secrets-226ee6ee-132f-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:21:19.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-cnhf2" for this suite.
Jan  8 10:21:25.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:21:25.441: INFO: namespace: e2e-tests-secrets-cnhf2, resource: bindings, ignored listing per whitelist
Jan  8 10:21:25.500: INFO: namespace e2e-tests-secrets-cnhf2 deletion completed in 6.101813273s

â€¢ [SLOW TEST:8.215 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:21:25.500: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-2755250f-132f-11e9-bc05-0a580af40202
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:21:27.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-g8bwm" for this suite.
Jan  8 10:21:49.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:21:49.637: INFO: namespace: e2e-tests-configmap-g8bwm, resource: bindings, ignored listing per whitelist
Jan  8 10:21:49.726: INFO: namespace e2e-tests-configmap-g8bwm deletion completed in 22.108629109s

â€¢ [SLOW TEST:24.226 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:21:49.726: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-qk8rq
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan  8 10:21:49.804: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan  8 10:22:09.868: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.159:8080/dial?request=hostName&protocol=udp&host=10.244.1.173&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-qk8rq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  8 10:22:09.868: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
Jan  8 10:22:09.961: INFO: Waiting for endpoints: map[]
Jan  8 10:22:09.964: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.159:8080/dial?request=hostName&protocol=udp&host=10.244.2.158&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-qk8rq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  8 10:22:09.964: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
Jan  8 10:22:10.054: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:22:10.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-qk8rq" for this suite.
Jan  8 10:22:32.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:22:32.129: INFO: namespace: e2e-tests-pod-network-test-qk8rq, resource: bindings, ignored listing per whitelist
Jan  8 10:22:32.167: INFO: namespace e2e-tests-pod-network-test-qk8rq deletion completed in 22.10818051s

â€¢ [SLOW TEST:42.441 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:22:32.167: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Jan  8 10:22:32.242: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Jan  8 10:22:32.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 create -f - --namespace=e2e-tests-kubectl-b2dk4'
Jan  8 10:22:32.562: INFO: stderr: ""
Jan  8 10:22:32.562: INFO: stdout: "service/redis-slave created\n"
Jan  8 10:22:32.562: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Jan  8 10:22:32.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 create -f - --namespace=e2e-tests-kubectl-b2dk4'
Jan  8 10:22:32.757: INFO: stderr: ""
Jan  8 10:22:32.757: INFO: stdout: "service/redis-master created\n"
Jan  8 10:22:32.757: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jan  8 10:22:32.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 create -f - --namespace=e2e-tests-kubectl-b2dk4'
Jan  8 10:22:32.940: INFO: stderr: ""
Jan  8 10:22:32.940: INFO: stdout: "service/frontend created\n"
Jan  8 10:22:32.940: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Jan  8 10:22:32.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 create -f - --namespace=e2e-tests-kubectl-b2dk4'
Jan  8 10:22:33.131: INFO: stderr: ""
Jan  8 10:22:33.131: INFO: stdout: "deployment.extensions/frontend created\n"
Jan  8 10:22:33.131: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jan  8 10:22:33.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 create -f - --namespace=e2e-tests-kubectl-b2dk4'
Jan  8 10:22:33.305: INFO: stderr: ""
Jan  8 10:22:33.305: INFO: stdout: "deployment.extensions/redis-master created\n"
Jan  8 10:22:33.305: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Jan  8 10:22:33.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 create -f - --namespace=e2e-tests-kubectl-b2dk4'
Jan  8 10:22:33.472: INFO: stderr: ""
Jan  8 10:22:33.472: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Jan  8 10:22:33.472: INFO: Waiting for all frontend pods to be Running.
Jan  8 10:22:58.524: INFO: Waiting for frontend to serve content.
Jan  8 10:22:58.538: INFO: Trying to add a new entry to the guestbook.
Jan  8 10:22:58.549: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Jan  8 10:22:58.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-b2dk4'
Jan  8 10:22:58.679: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  8 10:22:58.679: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Jan  8 10:22:58.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-b2dk4'
Jan  8 10:22:58.789: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  8 10:22:58.789: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan  8 10:22:58.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-b2dk4'
Jan  8 10:22:58.905: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  8 10:22:58.905: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan  8 10:22:58.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-b2dk4'
Jan  8 10:22:59.009: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  8 10:22:59.009: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan  8 10:22:59.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-b2dk4'
Jan  8 10:22:59.118: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  8 10:22:59.118: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan  8 10:22:59.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-b2dk4'
Jan  8 10:22:59.215: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  8 10:22:59.215: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:22:59.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b2dk4" for this suite.
Jan  8 10:23:39.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:23:39.244: INFO: namespace: e2e-tests-kubectl-b2dk4, resource: bindings, ignored listing per whitelist
Jan  8 10:23:39.327: INFO: namespace e2e-tests-kubectl-b2dk4 deletion completed in 40.107363571s

â€¢ [SLOW TEST:67.159 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:23:39.327: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jan  8 10:23:39.409: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-jg7z4,SelfLink:/api/v1/namespaces/e2e-tests-watch-jg7z4/configmaps/e2e-watch-test-configmap-a,UID:771994b6-132f-11e9-a60a-02001701fa35,ResourceVersion:16385,Generation:0,CreationTimestamp:2019-01-08 10:23:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan  8 10:23:39.409: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-jg7z4,SelfLink:/api/v1/namespaces/e2e-tests-watch-jg7z4/configmaps/e2e-watch-test-configmap-a,UID:771994b6-132f-11e9-a60a-02001701fa35,ResourceVersion:16385,Generation:0,CreationTimestamp:2019-01-08 10:23:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jan  8 10:23:49.417: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-jg7z4,SelfLink:/api/v1/namespaces/e2e-tests-watch-jg7z4/configmaps/e2e-watch-test-configmap-a,UID:771994b6-132f-11e9-a60a-02001701fa35,ResourceVersion:16400,Generation:0,CreationTimestamp:2019-01-08 10:23:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan  8 10:23:49.417: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-jg7z4,SelfLink:/api/v1/namespaces/e2e-tests-watch-jg7z4/configmaps/e2e-watch-test-configmap-a,UID:771994b6-132f-11e9-a60a-02001701fa35,ResourceVersion:16400,Generation:0,CreationTimestamp:2019-01-08 10:23:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jan  8 10:23:59.425: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-jg7z4,SelfLink:/api/v1/namespaces/e2e-tests-watch-jg7z4/configmaps/e2e-watch-test-configmap-a,UID:771994b6-132f-11e9-a60a-02001701fa35,ResourceVersion:16415,Generation:0,CreationTimestamp:2019-01-08 10:23:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan  8 10:23:59.425: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-jg7z4,SelfLink:/api/v1/namespaces/e2e-tests-watch-jg7z4/configmaps/e2e-watch-test-configmap-a,UID:771994b6-132f-11e9-a60a-02001701fa35,ResourceVersion:16415,Generation:0,CreationTimestamp:2019-01-08 10:23:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jan  8 10:24:09.432: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-jg7z4,SelfLink:/api/v1/namespaces/e2e-tests-watch-jg7z4/configmaps/e2e-watch-test-configmap-a,UID:771994b6-132f-11e9-a60a-02001701fa35,ResourceVersion:16430,Generation:0,CreationTimestamp:2019-01-08 10:23:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan  8 10:24:09.432: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-jg7z4,SelfLink:/api/v1/namespaces/e2e-tests-watch-jg7z4/configmaps/e2e-watch-test-configmap-a,UID:771994b6-132f-11e9-a60a-02001701fa35,ResourceVersion:16430,Generation:0,CreationTimestamp:2019-01-08 10:23:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jan  8 10:24:19.439: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-jg7z4,SelfLink:/api/v1/namespaces/e2e-tests-watch-jg7z4/configmaps/e2e-watch-test-configmap-b,UID:8ef53ef7-132f-11e9-a60a-02001701fa35,ResourceVersion:16445,Generation:0,CreationTimestamp:2019-01-08 10:24:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan  8 10:24:19.439: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-jg7z4,SelfLink:/api/v1/namespaces/e2e-tests-watch-jg7z4/configmaps/e2e-watch-test-configmap-b,UID:8ef53ef7-132f-11e9-a60a-02001701fa35,ResourceVersion:16445,Generation:0,CreationTimestamp:2019-01-08 10:24:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jan  8 10:24:29.446: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-jg7z4,SelfLink:/api/v1/namespaces/e2e-tests-watch-jg7z4/configmaps/e2e-watch-test-configmap-b,UID:8ef53ef7-132f-11e9-a60a-02001701fa35,ResourceVersion:16460,Generation:0,CreationTimestamp:2019-01-08 10:24:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan  8 10:24:29.446: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-jg7z4,SelfLink:/api/v1/namespaces/e2e-tests-watch-jg7z4/configmaps/e2e-watch-test-configmap-b,UID:8ef53ef7-132f-11e9-a60a-02001701fa35,ResourceVersion:16460,Generation:0,CreationTimestamp:2019-01-08 10:24:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:24:39.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-jg7z4" for this suite.
Jan  8 10:24:45.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:24:45.513: INFO: namespace: e2e-tests-watch-jg7z4, resource: bindings, ignored listing per whitelist
Jan  8 10:24:45.551: INFO: namespace e2e-tests-watch-jg7z4 deletion completed in 6.099977835s

â€¢ [SLOW TEST:66.224 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:24:45.551: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  8 10:24:45.637: INFO: (0) /api/v1/nodes/oltf-408483-kube-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 6.067773ms)
Jan  8 10:24:45.641: INFO: (1) /api/v1/nodes/oltf-408483-kube-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.00517ms)
Jan  8 10:24:45.645: INFO: (2) /api/v1/nodes/oltf-408483-kube-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.79776ms)
Jan  8 10:24:45.649: INFO: (3) /api/v1/nodes/oltf-408483-kube-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.98737ms)
Jan  8 10:24:45.653: INFO: (4) /api/v1/nodes/oltf-408483-kube-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.064123ms)
Jan  8 10:24:45.657: INFO: (5) /api/v1/nodes/oltf-408483-kube-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.898773ms)
Jan  8 10:24:45.661: INFO: (6) /api/v1/nodes/oltf-408483-kube-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.951862ms)
Jan  8 10:24:45.665: INFO: (7) /api/v1/nodes/oltf-408483-kube-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.272444ms)
Jan  8 10:24:45.669: INFO: (8) /api/v1/nodes/oltf-408483-kube-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.88172ms)
Jan  8 10:24:45.673: INFO: (9) /api/v1/nodes/oltf-408483-kube-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.129719ms)
Jan  8 10:24:45.677: INFO: (10) /api/v1/nodes/oltf-408483-kube-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.752157ms)
Jan  8 10:24:45.681: INFO: (11) /api/v1/nodes/oltf-408483-kube-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.975764ms)
Jan  8 10:24:45.685: INFO: (12) /api/v1/nodes/oltf-408483-kube-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.045832ms)
Jan  8 10:24:45.689: INFO: (13) /api/v1/nodes/oltf-408483-kube-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.869311ms)
Jan  8 10:24:45.693: INFO: (14) /api/v1/nodes/oltf-408483-kube-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.7063ms)
Jan  8 10:24:45.696: INFO: (15) /api/v1/nodes/oltf-408483-kube-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.908736ms)
Jan  8 10:24:45.700: INFO: (16) /api/v1/nodes/oltf-408483-kube-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.723211ms)
Jan  8 10:24:45.704: INFO: (17) /api/v1/nodes/oltf-408483-kube-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.851356ms)
Jan  8 10:24:45.708: INFO: (18) /api/v1/nodes/oltf-408483-kube-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.89238ms)
Jan  8 10:24:45.712: INFO: (19) /api/v1/nodes/oltf-408483-kube-worker1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.720734ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:24:45.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-v8t5w" for this suite.
Jan  8 10:24:51.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:24:51.792: INFO: namespace: e2e-tests-proxy-v8t5w, resource: bindings, ignored listing per whitelist
Jan  8 10:24:51.816: INFO: namespace e2e-tests-proxy-v8t5w deletion completed in 6.100359819s

â€¢ [SLOW TEST:6.265 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:24:51.816: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-sfsgw
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan  8 10:24:51.887: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan  8 10:25:13.963: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.244.1.178 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-sfsgw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  8 10:25:13.963: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
Jan  8 10:25:15.052: INFO: Found all expected endpoints: [netserver-0]
Jan  8 10:25:15.055: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.244.2.162 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-sfsgw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  8 10:25:15.055: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
Jan  8 10:25:16.145: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:25:16.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-sfsgw" for this suite.
Jan  8 10:25:38.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:25:38.199: INFO: namespace: e2e-tests-pod-network-test-sfsgw, resource: bindings, ignored listing per whitelist
Jan  8 10:25:38.251: INFO: namespace e2e-tests-pod-network-test-sfsgw deletion completed in 22.101180447s

â€¢ [SLOW TEST:46.435 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:25:38.251: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  8 10:25:38.331: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bdfb28a6-132f-11e9-bc05-0a580af40202" in namespace "e2e-tests-downward-api-m7ldv" to be "success or failure"
Jan  8 10:25:38.333: INFO: Pod "downwardapi-volume-bdfb28a6-132f-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.65957ms
Jan  8 10:25:40.337: INFO: Pod "downwardapi-volume-bdfb28a6-132f-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006235224s
STEP: Saw pod success
Jan  8 10:25:40.337: INFO: Pod "downwardapi-volume-bdfb28a6-132f-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:25:40.340: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod downwardapi-volume-bdfb28a6-132f-11e9-bc05-0a580af40202 container client-container: <nil>
STEP: delete the pod
Jan  8 10:25:40.358: INFO: Waiting for pod downwardapi-volume-bdfb28a6-132f-11e9-bc05-0a580af40202 to disappear
Jan  8 10:25:40.361: INFO: Pod downwardapi-volume-bdfb28a6-132f-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:25:40.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-m7ldv" for this suite.
Jan  8 10:25:46.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:25:46.422: INFO: namespace: e2e-tests-downward-api-m7ldv, resource: bindings, ignored listing per whitelist
Jan  8 10:25:46.464: INFO: namespace e2e-tests-downward-api-m7ldv deletion completed in 6.099262708s

â€¢ [SLOW TEST:8.213 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:25:46.464: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan  8 10:25:46.532: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:25:49.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-85j4q" for this suite.
Jan  8 10:25:55.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:25:55.494: INFO: namespace: e2e-tests-init-container-85j4q, resource: bindings, ignored listing per whitelist
Jan  8 10:25:55.537: INFO: namespace e2e-tests-init-container-85j4q deletion completed in 6.099499407s

â€¢ [SLOW TEST:9.074 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:25:55.537: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan  8 10:25:55.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-vrjdn'
Jan  8 10:25:55.711: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan  8 10:25:55.711: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Jan  8 10:25:59.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-vrjdn'
Jan  8 10:25:59.817: INFO: stderr: ""
Jan  8 10:25:59.817: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:25:59.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vrjdn" for this suite.
Jan  8 10:26:05.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:26:05.878: INFO: namespace: e2e-tests-kubectl-vrjdn, resource: bindings, ignored listing per whitelist
Jan  8 10:26:05.931: INFO: namespace e2e-tests-kubectl-vrjdn deletion completed in 6.109964382s

â€¢ [SLOW TEST:10.394 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:26:05.931: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-wq8q
STEP: Creating a pod to test atomic-volume-subpath
Jan  8 10:26:06.022: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-wq8q" in namespace "e2e-tests-subpath-mblrq" to be "success or failure"
Jan  8 10:26:06.025: INFO: Pod "pod-subpath-test-configmap-wq8q": Phase="Pending", Reason="", readiness=false. Elapsed: 2.946063ms
Jan  8 10:26:08.028: INFO: Pod "pod-subpath-test-configmap-wq8q": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006224228s
Jan  8 10:26:10.032: INFO: Pod "pod-subpath-test-configmap-wq8q": Phase="Running", Reason="", readiness=false. Elapsed: 4.010004434s
Jan  8 10:26:12.036: INFO: Pod "pod-subpath-test-configmap-wq8q": Phase="Running", Reason="", readiness=false. Elapsed: 6.013731471s
Jan  8 10:26:14.040: INFO: Pod "pod-subpath-test-configmap-wq8q": Phase="Running", Reason="", readiness=false. Elapsed: 8.017818928s
Jan  8 10:26:16.044: INFO: Pod "pod-subpath-test-configmap-wq8q": Phase="Running", Reason="", readiness=false. Elapsed: 10.022276003s
Jan  8 10:26:18.048: INFO: Pod "pod-subpath-test-configmap-wq8q": Phase="Running", Reason="", readiness=false. Elapsed: 12.026293171s
Jan  8 10:26:20.052: INFO: Pod "pod-subpath-test-configmap-wq8q": Phase="Running", Reason="", readiness=false. Elapsed: 14.030334674s
Jan  8 10:26:22.056: INFO: Pod "pod-subpath-test-configmap-wq8q": Phase="Running", Reason="", readiness=false. Elapsed: 16.034301091s
Jan  8 10:26:24.060: INFO: Pod "pod-subpath-test-configmap-wq8q": Phase="Running", Reason="", readiness=false. Elapsed: 18.038443218s
Jan  8 10:26:26.065: INFO: Pod "pod-subpath-test-configmap-wq8q": Phase="Running", Reason="", readiness=false. Elapsed: 20.042584995s
Jan  8 10:26:28.068: INFO: Pod "pod-subpath-test-configmap-wq8q": Phase="Running", Reason="", readiness=false. Elapsed: 22.046404285s
Jan  8 10:26:30.073: INFO: Pod "pod-subpath-test-configmap-wq8q": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.05064382s
STEP: Saw pod success
Jan  8 10:26:30.073: INFO: Pod "pod-subpath-test-configmap-wq8q" satisfied condition "success or failure"
Jan  8 10:26:30.076: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-subpath-test-configmap-wq8q container test-container-subpath-configmap-wq8q: <nil>
STEP: delete the pod
Jan  8 10:26:30.095: INFO: Waiting for pod pod-subpath-test-configmap-wq8q to disappear
Jan  8 10:26:30.098: INFO: Pod pod-subpath-test-configmap-wq8q no longer exists
STEP: Deleting pod pod-subpath-test-configmap-wq8q
Jan  8 10:26:30.098: INFO: Deleting pod "pod-subpath-test-configmap-wq8q" in namespace "e2e-tests-subpath-mblrq"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:26:30.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-mblrq" for this suite.
Jan  8 10:26:36.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:26:36.184: INFO: namespace: e2e-tests-subpath-mblrq, resource: bindings, ignored listing per whitelist
Jan  8 10:26:36.213: INFO: namespace e2e-tests-subpath-mblrq deletion completed in 6.108359541s

â€¢ [SLOW TEST:30.281 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:26:36.213: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Jan  8 10:26:36.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 create -f - --namespace=e2e-tests-kubectl-6mckr'
Jan  8 10:26:36.457: INFO: stderr: ""
Jan  8 10:26:36.457: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan  8 10:26:36.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6mckr'
Jan  8 10:26:36.555: INFO: stderr: ""
Jan  8 10:26:36.555: INFO: stdout: "update-demo-nautilus-9v96m update-demo-nautilus-z7xzx "
Jan  8 10:26:36.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-nautilus-9v96m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6mckr'
Jan  8 10:26:36.642: INFO: stderr: ""
Jan  8 10:26:36.642: INFO: stdout: ""
Jan  8 10:26:36.642: INFO: update-demo-nautilus-9v96m is created but not running
Jan  8 10:26:41.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6mckr'
Jan  8 10:26:41.746: INFO: stderr: ""
Jan  8 10:26:41.746: INFO: stdout: "update-demo-nautilus-9v96m update-demo-nautilus-z7xzx "
Jan  8 10:26:41.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-nautilus-9v96m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6mckr'
Jan  8 10:26:41.831: INFO: stderr: ""
Jan  8 10:26:41.831: INFO: stdout: "true"
Jan  8 10:26:41.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-nautilus-9v96m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6mckr'
Jan  8 10:26:41.925: INFO: stderr: ""
Jan  8 10:26:41.925: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  8 10:26:41.925: INFO: validating pod update-demo-nautilus-9v96m
Jan  8 10:26:41.940: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  8 10:26:41.940: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  8 10:26:41.940: INFO: update-demo-nautilus-9v96m is verified up and running
Jan  8 10:26:41.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-nautilus-z7xzx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6mckr'
Jan  8 10:26:42.024: INFO: stderr: ""
Jan  8 10:26:42.024: INFO: stdout: "true"
Jan  8 10:26:42.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-nautilus-z7xzx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6mckr'
Jan  8 10:26:42.108: INFO: stderr: ""
Jan  8 10:26:42.108: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  8 10:26:42.108: INFO: validating pod update-demo-nautilus-z7xzx
Jan  8 10:26:42.113: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  8 10:26:42.113: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  8 10:26:42.113: INFO: update-demo-nautilus-z7xzx is verified up and running
STEP: rolling-update to new replication controller
Jan  8 10:26:42.114: INFO: scanned /root for discovery docs: <nil>
Jan  8 10:26:42.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-6mckr'
Jan  8 10:27:07.487: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan  8 10:27:07.487: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan  8 10:27:07.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6mckr'
Jan  8 10:27:07.580: INFO: stderr: ""
Jan  8 10:27:07.580: INFO: stdout: "update-demo-kitten-62hhs update-demo-kitten-mq2wt "
Jan  8 10:27:07.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-kitten-62hhs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6mckr'
Jan  8 10:27:07.666: INFO: stderr: ""
Jan  8 10:27:07.666: INFO: stdout: "true"
Jan  8 10:27:07.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-kitten-62hhs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6mckr'
Jan  8 10:27:07.750: INFO: stderr: ""
Jan  8 10:27:07.750: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan  8 10:27:07.750: INFO: validating pod update-demo-kitten-62hhs
Jan  8 10:27:07.755: INFO: got data: {
  "image": "kitten.jpg"
}

Jan  8 10:27:07.755: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan  8 10:27:07.755: INFO: update-demo-kitten-62hhs is verified up and running
Jan  8 10:27:07.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-kitten-mq2wt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6mckr'
Jan  8 10:27:07.838: INFO: stderr: ""
Jan  8 10:27:07.838: INFO: stdout: "true"
Jan  8 10:27:07.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pods update-demo-kitten-mq2wt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6mckr'
Jan  8 10:27:07.925: INFO: stderr: ""
Jan  8 10:27:07.925: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan  8 10:27:07.925: INFO: validating pod update-demo-kitten-mq2wt
Jan  8 10:27:07.931: INFO: got data: {
  "image": "kitten.jpg"
}

Jan  8 10:27:07.931: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan  8 10:27:07.931: INFO: update-demo-kitten-mq2wt is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:27:07.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6mckr" for this suite.
Jan  8 10:27:29.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:27:30.043: INFO: namespace: e2e-tests-kubectl-6mckr, resource: bindings, ignored listing per whitelist
Jan  8 10:27:30.043: INFO: namespace e2e-tests-kubectl-6mckr deletion completed in 22.108131598s

â€¢ [SLOW TEST:53.831 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:27:30.044: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan  8 10:27:30.126: INFO: Waiting up to 5m0s for pod "pod-009dbd81-1330-11e9-bc05-0a580af40202" in namespace "e2e-tests-emptydir-stmcl" to be "success or failure"
Jan  8 10:27:30.130: INFO: Pod "pod-009dbd81-1330-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.090039ms
Jan  8 10:27:32.133: INFO: Pod "pod-009dbd81-1330-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006316494s
STEP: Saw pod success
Jan  8 10:27:32.133: INFO: Pod "pod-009dbd81-1330-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:27:32.136: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod pod-009dbd81-1330-11e9-bc05-0a580af40202 container test-container: <nil>
STEP: delete the pod
Jan  8 10:27:32.153: INFO: Waiting for pod pod-009dbd81-1330-11e9-bc05-0a580af40202 to disappear
Jan  8 10:27:32.155: INFO: Pod pod-009dbd81-1330-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:27:32.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-stmcl" for this suite.
Jan  8 10:27:38.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:27:38.228: INFO: namespace: e2e-tests-emptydir-stmcl, resource: bindings, ignored listing per whitelist
Jan  8 10:27:38.261: INFO: namespace e2e-tests-emptydir-stmcl deletion completed in 6.101604097s

â€¢ [SLOW TEST:8.217 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:27:38.261: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Jan  8 10:27:40.354: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-0582846d-1330-11e9-bc05-0a580af40202", GenerateName:"", Namespace:"e2e-tests-pods-knfsw", SelfLink:"/api/v1/namespaces/e2e-tests-pods-knfsw/pods/pod-submit-remove-0582846d-1330-11e9-bc05-0a580af40202", UID:"0583b5ff-1330-11e9-a60a-02001701fa35", ResourceVersion:"17114", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63682540058, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"330847486"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-nvp4f", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc4217c0840), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-nvp4f", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc420f0ca88), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"oltf-408483-kube-worker1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc4213db560), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc420f0cac0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc420f0cae0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc420f0cae8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682540058, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682540060, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682540060, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682540058, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"100.100.242.162", PodIP:"10.244.1.183", StartTime:(*v1.Time)(0xc4214d2180), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc4214d21a0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96", ContainerID:"docker://31e91d8c7b3f4f08917e8ccadbcbc2c10b4e28c69041c90ecf475c2e3af4e108"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Jan  8 10:27:45.367: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:27:45.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-knfsw" for this suite.
Jan  8 10:27:51.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:27:51.414: INFO: namespace: e2e-tests-pods-knfsw, resource: bindings, ignored listing per whitelist
Jan  8 10:27:51.478: INFO: namespace e2e-tests-pods-knfsw deletion completed in 6.103328572s

â€¢ [SLOW TEST:13.217 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:27:51.478: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan  8 10:27:51.561: INFO: Waiting up to 5m0s for pod "downward-api-0d6460bd-1330-11e9-bc05-0a580af40202" in namespace "e2e-tests-downward-api-j86cg" to be "success or failure"
Jan  8 10:27:51.566: INFO: Pod "downward-api-0d6460bd-1330-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.793994ms
Jan  8 10:27:53.570: INFO: Pod "downward-api-0d6460bd-1330-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008734527s
STEP: Saw pod success
Jan  8 10:27:53.570: INFO: Pod "downward-api-0d6460bd-1330-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:27:53.573: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod downward-api-0d6460bd-1330-11e9-bc05-0a580af40202 container dapi-container: <nil>
STEP: delete the pod
Jan  8 10:27:53.593: INFO: Waiting for pod downward-api-0d6460bd-1330-11e9-bc05-0a580af40202 to disappear
Jan  8 10:27:53.595: INFO: Pod downward-api-0d6460bd-1330-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:27:53.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-j86cg" for this suite.
Jan  8 10:27:59.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:27:59.681: INFO: namespace: e2e-tests-downward-api-j86cg, resource: bindings, ignored listing per whitelist
Jan  8 10:27:59.700: INFO: namespace e2e-tests-downward-api-j86cg deletion completed in 6.101372356s

â€¢ [SLOW TEST:8.223 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:27:59.701: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Jan  8 10:28:01.838: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:28:25.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-5hh28" for this suite.
Jan  8 10:28:31.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:28:31.957: INFO: namespace: e2e-tests-namespaces-5hh28, resource: bindings, ignored listing per whitelist
Jan  8 10:28:31.999: INFO: namespace e2e-tests-namespaces-5hh28 deletion completed in 6.104606022s
STEP: Destroying namespace "e2e-tests-nsdeletetest-w6z2g" for this suite.
Jan  8 10:28:32.002: INFO: Namespace e2e-tests-nsdeletetest-w6z2g was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-d9fwp" for this suite.
Jan  8 10:28:38.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:28:38.106: INFO: namespace: e2e-tests-nsdeletetest-d9fwp, resource: bindings, ignored listing per whitelist
Jan  8 10:28:38.114: INFO: namespace e2e-tests-nsdeletetest-d9fwp deletion completed in 6.111377292s

â€¢ [SLOW TEST:38.413 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:28:38.114: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan  8 10:28:38.212: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:28:38.214: INFO: Number of nodes with available pods: 0
Jan  8 10:28:38.214: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 10:28:39.219: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:28:39.222: INFO: Number of nodes with available pods: 0
Jan  8 10:28:39.222: INFO: Node oltf-408483-kube-worker1 is running more than one daemon pod
Jan  8 10:28:40.219: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:28:40.223: INFO: Number of nodes with available pods: 2
Jan  8 10:28:40.223: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jan  8 10:28:40.240: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:28:40.243: INFO: Number of nodes with available pods: 1
Jan  8 10:28:40.243: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:28:41.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:28:41.251: INFO: Number of nodes with available pods: 1
Jan  8 10:28:41.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:28:42.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:28:42.251: INFO: Number of nodes with available pods: 1
Jan  8 10:28:42.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:28:43.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:28:43.251: INFO: Number of nodes with available pods: 1
Jan  8 10:28:43.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:28:44.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:28:44.251: INFO: Number of nodes with available pods: 1
Jan  8 10:28:44.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:28:45.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:28:45.251: INFO: Number of nodes with available pods: 1
Jan  8 10:28:45.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:28:46.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:28:46.251: INFO: Number of nodes with available pods: 1
Jan  8 10:28:46.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:28:47.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:28:47.251: INFO: Number of nodes with available pods: 1
Jan  8 10:28:47.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:28:48.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:28:48.251: INFO: Number of nodes with available pods: 1
Jan  8 10:28:48.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:28:49.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:28:49.251: INFO: Number of nodes with available pods: 1
Jan  8 10:28:49.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:28:50.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:28:50.251: INFO: Number of nodes with available pods: 1
Jan  8 10:28:50.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:28:51.247: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:28:51.251: INFO: Number of nodes with available pods: 1
Jan  8 10:28:51.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:28:52.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:28:52.251: INFO: Number of nodes with available pods: 1
Jan  8 10:28:52.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:28:53.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:28:53.251: INFO: Number of nodes with available pods: 1
Jan  8 10:28:53.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:28:54.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:28:54.252: INFO: Number of nodes with available pods: 1
Jan  8 10:28:54.252: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:28:55.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:28:55.251: INFO: Number of nodes with available pods: 1
Jan  8 10:28:55.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:28:56.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:28:56.251: INFO: Number of nodes with available pods: 1
Jan  8 10:28:56.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:28:57.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:28:57.251: INFO: Number of nodes with available pods: 1
Jan  8 10:28:57.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:28:58.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:28:58.251: INFO: Number of nodes with available pods: 1
Jan  8 10:28:58.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:28:59.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:28:59.252: INFO: Number of nodes with available pods: 1
Jan  8 10:28:59.258: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:00.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:00.251: INFO: Number of nodes with available pods: 1
Jan  8 10:29:00.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:01.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:01.251: INFO: Number of nodes with available pods: 1
Jan  8 10:29:01.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:02.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:02.251: INFO: Number of nodes with available pods: 1
Jan  8 10:29:02.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:03.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:03.251: INFO: Number of nodes with available pods: 1
Jan  8 10:29:03.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:04.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:04.251: INFO: Number of nodes with available pods: 1
Jan  8 10:29:04.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:05.247: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:05.251: INFO: Number of nodes with available pods: 1
Jan  8 10:29:05.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:06.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:06.251: INFO: Number of nodes with available pods: 1
Jan  8 10:29:06.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:07.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:07.251: INFO: Number of nodes with available pods: 1
Jan  8 10:29:07.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:08.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:08.251: INFO: Number of nodes with available pods: 1
Jan  8 10:29:08.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:09.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:09.251: INFO: Number of nodes with available pods: 1
Jan  8 10:29:09.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:10.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:10.251: INFO: Number of nodes with available pods: 1
Jan  8 10:29:10.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:11.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:11.251: INFO: Number of nodes with available pods: 1
Jan  8 10:29:11.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:12.259: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:12.262: INFO: Number of nodes with available pods: 1
Jan  8 10:29:12.262: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:13.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:13.251: INFO: Number of nodes with available pods: 1
Jan  8 10:29:13.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:14.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:14.251: INFO: Number of nodes with available pods: 1
Jan  8 10:29:14.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:15.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:15.251: INFO: Number of nodes with available pods: 1
Jan  8 10:29:15.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:16.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:16.251: INFO: Number of nodes with available pods: 1
Jan  8 10:29:16.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:17.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:17.251: INFO: Number of nodes with available pods: 1
Jan  8 10:29:17.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:18.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:18.251: INFO: Number of nodes with available pods: 1
Jan  8 10:29:18.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:19.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:19.251: INFO: Number of nodes with available pods: 1
Jan  8 10:29:19.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:20.247: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:20.250: INFO: Number of nodes with available pods: 1
Jan  8 10:29:20.250: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:21.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:21.251: INFO: Number of nodes with available pods: 1
Jan  8 10:29:21.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:22.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:22.251: INFO: Number of nodes with available pods: 1
Jan  8 10:29:22.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:23.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:23.251: INFO: Number of nodes with available pods: 1
Jan  8 10:29:23.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:24.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:24.251: INFO: Number of nodes with available pods: 1
Jan  8 10:29:24.251: INFO: Node oltf-408483-kube-worker2 is running more than one daemon pod
Jan  8 10:29:25.248: INFO: DaemonSet pods can't tolerate node oltf-408483-kube-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan  8 10:29:25.251: INFO: Number of nodes with available pods: 2
Jan  8 10:29:25.251: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-rsxr7, will wait for the garbage collector to delete the pods
Jan  8 10:29:25.318: INFO: Deleting {extensions DaemonSet} daemon-set took: 9.802416ms
Jan  8 10:29:25.418: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.195971ms
Jan  8 10:30:03.322: INFO: Number of nodes with available pods: 0
Jan  8 10:30:03.322: INFO: Number of running nodes: 0, number of available pods: 0
Jan  8 10:30:03.324: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-rsxr7/daemonsets","resourceVersion":"17468"},"items":null}

Jan  8 10:30:03.327: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-rsxr7/pods","resourceVersion":"17468"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:30:03.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-rsxr7" for this suite.
Jan  8 10:30:09.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:30:09.369: INFO: namespace: e2e-tests-daemonsets-rsxr7, resource: bindings, ignored listing per whitelist
Jan  8 10:30:09.441: INFO: namespace e2e-tests-daemonsets-rsxr7 deletion completed in 6.100909344s

â€¢ [SLOW TEST:91.328 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:30:09.442: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  8 10:30:09.526: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5fa03ec3-1330-11e9-bc05-0a580af40202" in namespace "e2e-tests-projected-xfj8t" to be "success or failure"
Jan  8 10:30:09.531: INFO: Pod "downwardapi-volume-5fa03ec3-1330-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.7706ms
Jan  8 10:30:11.535: INFO: Pod "downwardapi-volume-5fa03ec3-1330-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008753865s
STEP: Saw pod success
Jan  8 10:30:11.535: INFO: Pod "downwardapi-volume-5fa03ec3-1330-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:30:11.538: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod downwardapi-volume-5fa03ec3-1330-11e9-bc05-0a580af40202 container client-container: <nil>
STEP: delete the pod
Jan  8 10:30:11.554: INFO: Waiting for pod downwardapi-volume-5fa03ec3-1330-11e9-bc05-0a580af40202 to disappear
Jan  8 10:30:11.557: INFO: Pod downwardapi-volume-5fa03ec3-1330-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:30:11.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xfj8t" for this suite.
Jan  8 10:30:17.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:30:17.644: INFO: namespace: e2e-tests-projected-xfj8t, resource: bindings, ignored listing per whitelist
Jan  8 10:30:17.662: INFO: namespace e2e-tests-projected-xfj8t deletion completed in 6.101623222s

â€¢ [SLOW TEST:8.220 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:30:17.662: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Jan  8 10:30:19.750: INFO: Pod pod-hostip-64855b46-1330-11e9-bc05-0a580af40202 has hostIP: 100.100.242.163
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:30:19.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-zqtmq" for this suite.
Jan  8 10:30:41.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:30:41.805: INFO: namespace: e2e-tests-pods-zqtmq, resource: bindings, ignored listing per whitelist
Jan  8 10:30:41.855: INFO: namespace e2e-tests-pods-zqtmq deletion completed in 22.100746994s

â€¢ [SLOW TEST:24.193 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:30:41.855: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan  8 10:30:41.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-nk567'
Jan  8 10:30:42.029: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan  8 10:30:42.030: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Jan  8 10:30:42.038: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-p7ql9]
Jan  8 10:30:42.038: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-p7ql9" in namespace "e2e-tests-kubectl-nk567" to be "running and ready"
Jan  8 10:30:42.046: INFO: Pod "e2e-test-nginx-rc-p7ql9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.33091ms
Jan  8 10:30:44.050: INFO: Pod "e2e-test-nginx-rc-p7ql9": Phase="Running", Reason="", readiness=true. Elapsed: 2.012139049s
Jan  8 10:30:44.050: INFO: Pod "e2e-test-nginx-rc-p7ql9" satisfied condition "running and ready"
Jan  8 10:30:44.050: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-p7ql9]
Jan  8 10:30:44.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-nk567'
Jan  8 10:30:44.163: INFO: stderr: ""
Jan  8 10:30:44.163: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Jan  8 10:30:44.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-nk567'
Jan  8 10:30:44.257: INFO: stderr: ""
Jan  8 10:30:44.257: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:30:44.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nk567" for this suite.
Jan  8 10:30:50.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:30:50.345: INFO: namespace: e2e-tests-kubectl-nk567, resource: bindings, ignored listing per whitelist
Jan  8 10:30:50.360: INFO: namespace e2e-tests-kubectl-nk567 deletion completed in 6.100064322s

â€¢ [SLOW TEST:8.505 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:30:50.361: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-78033ed6-1330-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume configMaps
Jan  8 10:30:50.444: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7803bf44-1330-11e9-bc05-0a580af40202" in namespace "e2e-tests-projected-kh54r" to be "success or failure"
Jan  8 10:30:50.449: INFO: Pod "pod-projected-configmaps-7803bf44-1330-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 5.217264ms
Jan  8 10:30:52.453: INFO: Pod "pod-projected-configmaps-7803bf44-1330-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008722226s
STEP: Saw pod success
Jan  8 10:30:52.453: INFO: Pod "pod-projected-configmaps-7803bf44-1330-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:30:52.456: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod pod-projected-configmaps-7803bf44-1330-11e9-bc05-0a580af40202 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan  8 10:30:52.475: INFO: Waiting for pod pod-projected-configmaps-7803bf44-1330-11e9-bc05-0a580af40202 to disappear
Jan  8 10:30:52.478: INFO: Pod pod-projected-configmaps-7803bf44-1330-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:30:52.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kh54r" for this suite.
Jan  8 10:30:58.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:30:58.576: INFO: namespace: e2e-tests-projected-kh54r, resource: bindings, ignored listing per whitelist
Jan  8 10:30:58.584: INFO: namespace e2e-tests-projected-kh54r deletion completed in 6.101603883s

â€¢ [SLOW TEST:8.223 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:30:58.584: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-7cea5fa6-1330-11e9-bc05-0a580af40202
STEP: Creating a pod to test consume configMaps
Jan  8 10:30:58.670: INFO: Waiting up to 5m0s for pod "pod-configmaps-7ceafbe9-1330-11e9-bc05-0a580af40202" in namespace "e2e-tests-configmap-ldj42" to be "success or failure"
Jan  8 10:30:58.674: INFO: Pod "pod-configmaps-7ceafbe9-1330-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.113132ms
Jan  8 10:31:00.677: INFO: Pod "pod-configmaps-7ceafbe9-1330-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006626572s
STEP: Saw pod success
Jan  8 10:31:00.677: INFO: Pod "pod-configmaps-7ceafbe9-1330-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:31:00.680: INFO: Trying to get logs from node oltf-408483-kube-worker1 pod pod-configmaps-7ceafbe9-1330-11e9-bc05-0a580af40202 container configmap-volume-test: <nil>
STEP: delete the pod
Jan  8 10:31:00.696: INFO: Waiting for pod pod-configmaps-7ceafbe9-1330-11e9-bc05-0a580af40202 to disappear
Jan  8 10:31:00.698: INFO: Pod pod-configmaps-7ceafbe9-1330-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:31:00.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ldj42" for this suite.
Jan  8 10:31:06.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:31:06.784: INFO: namespace: e2e-tests-configmap-ldj42, resource: bindings, ignored listing per whitelist
Jan  8 10:31:06.801: INFO: namespace e2e-tests-configmap-ldj42 deletion completed in 6.097891391s

â€¢ [SLOW TEST:8.217 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:31:06.801: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan  8 10:31:06.878: INFO: Waiting up to 5m0s for pod "pod-81cf7868-1330-11e9-bc05-0a580af40202" in namespace "e2e-tests-emptydir-lnxgk" to be "success or failure"
Jan  8 10:31:06.881: INFO: Pod "pod-81cf7868-1330-11e9-bc05-0a580af40202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.82458ms
Jan  8 10:31:08.885: INFO: Pod "pod-81cf7868-1330-11e9-bc05-0a580af40202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007176069s
STEP: Saw pod success
Jan  8 10:31:08.885: INFO: Pod "pod-81cf7868-1330-11e9-bc05-0a580af40202" satisfied condition "success or failure"
Jan  8 10:31:08.888: INFO: Trying to get logs from node oltf-408483-kube-worker2 pod pod-81cf7868-1330-11e9-bc05-0a580af40202 container test-container: <nil>
STEP: delete the pod
Jan  8 10:31:08.905: INFO: Waiting for pod pod-81cf7868-1330-11e9-bc05-0a580af40202 to disappear
Jan  8 10:31:08.908: INFO: Pod pod-81cf7868-1330-11e9-bc05-0a580af40202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:31:08.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lnxgk" for this suite.
Jan  8 10:31:14.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:31:14.960: INFO: namespace: e2e-tests-emptydir-lnxgk, resource: bindings, ignored listing per whitelist
Jan  8 10:31:15.015: INFO: namespace e2e-tests-emptydir-lnxgk deletion completed in 6.103671158s

â€¢ [SLOW TEST:8.215 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  8 10:31:15.016: INFO: >>> kubeConfig: /tmp/kubeconfig-272738442
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan  8 10:31:15.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-22kvm'
Jan  8 10:31:15.189: INFO: stderr: ""
Jan  8 10:31:15.189: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Jan  8 10:31:20.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-22kvm -o json'
Jan  8 10:31:20.328: INFO: stderr: ""
Jan  8 10:31:20.328: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-01-08T10:31:15Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-22kvm\",\n        \"resourceVersion\": \"17762\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-22kvm/pods/e2e-test-nginx-pod\",\n        \"uid\": \"86c2c811-1330-11e9-a60a-02001701fa35\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-7cgjw\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"oltf-408483-kube-worker1\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-7cgjw\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-7cgjw\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-08T10:31:15Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-08T10:31:16Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-08T10:31:16Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-08T10:31:15Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://eaceda9302ebbf81289e8a357ed2211620e78f654be45e2685fcb50a0aecdb20\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-01-08T10:31:16Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"100.100.242.162\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.1.191\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-01-08T10:31:15Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jan  8 10:31:20.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 replace -f - --namespace=e2e-tests-kubectl-22kvm'
Jan  8 10:31:20.492: INFO: stderr: ""
Jan  8 10:31:20.492: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Jan  8 10:31:20.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-272738442 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-22kvm'
Jan  8 10:31:22.050: INFO: stderr: ""
Jan  8 10:31:22.050: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  8 10:31:22.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-22kvm" for this suite.
Jan  8 10:31:28.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  8 10:31:28.094: INFO: namespace: e2e-tests-kubectl-22kvm, resource: bindings, ignored listing per whitelist
Jan  8 10:31:28.153: INFO: namespace e2e-tests-kubectl-22kvm deletion completed in 6.099566573s

â€¢ [SLOW TEST:13.138 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSJan  8 10:31:28.154: INFO: Running AfterSuite actions on all node
Jan  8 10:31:28.154: INFO: Running AfterSuite actions on node 1
Jan  8 10:31:28.154: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 4711.911 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h18m33.095195545s
Test Suite Passed

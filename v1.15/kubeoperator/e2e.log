I0927 05:46:11.194518      16 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-833349834
I0927 05:46:11.194640      16 e2e.go:241] Starting e2e run "fc2212a9-0052-47d8-8864-912a7dc63933" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1569563167 - Will randomize all specs
Will run 215 of 4413 specs

Sep 27 05:46:11.403: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
Sep 27 05:46:11.406: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Sep 27 05:46:11.421: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Sep 27 05:46:11.450: INFO: 18 / 18 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Sep 27 05:46:11.450: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Sep 27 05:46:11.450: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Sep 27 05:46:11.458: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-amd64' (0 seconds elapsed)
Sep 27 05:46:11.458: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'traefik-ingress-lb' (0 seconds elapsed)
Sep 27 05:46:11.458: INFO: e2e test version: v1.15.3
Sep 27 05:46:11.459: INFO: kube-apiserver version: v1.15.3
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:46:11.459: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename replication-controller
Sep 27 05:46:11.520: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Sep 27 05:46:11.532: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-666
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Sep 27 05:46:11.673: INFO: Pod name pod-release: Found 0 pods out of 1
Sep 27 05:46:16.677: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:46:17.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-666" for this suite.
Sep 27 05:46:23.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:46:24.038: INFO: namespace replication-controller-666 deletion completed in 6.339608195s

• [SLOW TEST:12.579 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:46:24.038: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3359
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-08faab59-73d3-4905-aa8d-38933b15143f
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:46:26.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3359" for this suite.
Sep 27 05:46:48.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:46:48.477: INFO: namespace configmap-3359 deletion completed in 22.089986032s

• [SLOW TEST:24.439 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:46:48.477: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7454
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7454.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7454.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7454.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7454.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 27 05:46:52.641: INFO: DNS probes using dns-test-ae140c52-8175-43b4-80bb-7f627eecd926 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7454.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7454.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7454.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7454.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 27 05:46:56.709: INFO: File wheezy_udp@dns-test-service-3.dns-7454.svc.cluster.local from pod  dns-7454/dns-test-8f5e689c-ef07-423d-a902-0042e4569919 contains '' instead of 'bar.example.com.'
Sep 27 05:46:56.712: INFO: Lookups using dns-7454/dns-test-8f5e689c-ef07-423d-a902-0042e4569919 failed for: [wheezy_udp@dns-test-service-3.dns-7454.svc.cluster.local]

Sep 27 05:47:01.718: INFO: DNS probes using dns-test-8f5e689c-ef07-423d-a902-0042e4569919 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7454.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-7454.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7454.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-7454.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 27 05:47:05.780: INFO: DNS probes using dns-test-eda38574-d7a1-4cde-a2e0-9ad11c0b051c succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:47:05.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7454" for this suite.
Sep 27 05:47:11.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:47:11.920: INFO: namespace dns-7454 deletion completed in 6.09050658s

• [SLOW TEST:23.443 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:47:11.920: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5835
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 05:47:12.059: INFO: Creating deployment "test-recreate-deployment"
Sep 27 05:47:12.065: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Sep 27 05:47:12.075: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Sep 27 05:47:14.081: INFO: Waiting deployment "test-recreate-deployment" to complete
Sep 27 05:47:14.083: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Sep 27 05:47:14.089: INFO: Updating deployment test-recreate-deployment
Sep 27 05:47:14.089: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Sep 27 05:47:14.194: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-5835,SelfLink:/apis/apps/v1/namespaces/deployment-5835/deployments/test-recreate-deployment,UID:29381378-a95b-44b8-9e74-7983b9658e1d,ResourceVersion:8708,Generation:2,CreationTimestamp:2019-09-27 05:47:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-09-27 05:47:14 +0000 UTC 2019-09-27 05:47:14 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-09-27 05:47:14 +0000 UTC 2019-09-27 05:47:12 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Sep 27 05:47:14.197: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-5835,SelfLink:/apis/apps/v1/namespaces/deployment-5835/replicasets/test-recreate-deployment-5c8c9cc69d,UID:9a007856-9958-42a5-a279-2ad87c4bf1dd,ResourceVersion:8707,Generation:1,CreationTimestamp:2019-09-27 05:47:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 29381378-a95b-44b8-9e74-7983b9658e1d 0xc002bed9a7 0xc002bed9a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 27 05:47:14.197: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Sep 27 05:47:14.197: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-5835,SelfLink:/apis/apps/v1/namespaces/deployment-5835/replicasets/test-recreate-deployment-6df85df6b9,UID:5b3750f0-fffa-47c3-8c24-63508fb3ad19,ResourceVersion:8697,Generation:2,CreationTimestamp:2019-09-27 05:47:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 29381378-a95b-44b8-9e74-7983b9658e1d 0xc002beda67 0xc002beda68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 27 05:47:14.199: INFO: Pod "test-recreate-deployment-5c8c9cc69d-6tc5f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-6tc5f,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-5835,SelfLink:/api/v1/namespaces/deployment-5835/pods/test-recreate-deployment-5c8c9cc69d-6tc5f,UID:fde3f434-ed96-4f6f-b01a-f021c8b7702a,ResourceVersion:8709,Generation:0,CreationTimestamp:2019-09-27 05:47:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d 9a007856-9958-42a5-a279-2ad87c4bf1dd 0xc002c04347 0xc002c04348}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-zkqnv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zkqnv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zkqnv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker3.dev-bj.kubeoperator.io,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 05:47:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 05:47:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 05:47:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 05:47:14 +0000 UTC  }],Message:,Reason:,HostIP:172.16.10.234,PodIP:,StartTime:2019-09-27 05:47:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:47:14.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5835" for this suite.
Sep 27 05:47:20.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:47:20.297: INFO: namespace deployment-5835 deletion completed in 6.093793351s

• [SLOW TEST:8.377 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:47:20.298: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3792
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep 27 05:47:20.442: INFO: Waiting up to 5m0s for pod "pod-fed96c72-5abc-4fee-b450-a2e9f41e5ec8" in namespace "emptydir-3792" to be "success or failure"
Sep 27 05:47:20.444: INFO: Pod "pod-fed96c72-5abc-4fee-b450-a2e9f41e5ec8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029545ms
Sep 27 05:47:22.448: INFO: Pod "pod-fed96c72-5abc-4fee-b450-a2e9f41e5ec8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00522029s
STEP: Saw pod success
Sep 27 05:47:22.448: INFO: Pod "pod-fed96c72-5abc-4fee-b450-a2e9f41e5ec8" satisfied condition "success or failure"
Sep 27 05:47:22.450: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-fed96c72-5abc-4fee-b450-a2e9f41e5ec8 container test-container: <nil>
STEP: delete the pod
Sep 27 05:47:22.466: INFO: Waiting for pod pod-fed96c72-5abc-4fee-b450-a2e9f41e5ec8 to disappear
Sep 27 05:47:22.468: INFO: Pod pod-fed96c72-5abc-4fee-b450-a2e9f41e5ec8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:47:22.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3792" for this suite.
Sep 27 05:47:28.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:47:28.552: INFO: namespace emptydir-3792 deletion completed in 6.078490626s

• [SLOW TEST:8.254 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:47:28.552: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5374
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:47:30.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5374" for this suite.
Sep 27 05:48:08.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:48:08.808: INFO: namespace kubelet-test-5374 deletion completed in 38.091361194s

• [SLOW TEST:40.256 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:48:08.809: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2323
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-8a2de59c-31bf-4ee5-874d-d991f212586a
STEP: Creating a pod to test consume secrets
Sep 27 05:48:08.971: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fcf6e16a-a077-4e06-b856-75cc78d04143" in namespace "projected-2323" to be "success or failure"
Sep 27 05:48:08.975: INFO: Pod "pod-projected-secrets-fcf6e16a-a077-4e06-b856-75cc78d04143": Phase="Pending", Reason="", readiness=false. Elapsed: 3.005609ms
Sep 27 05:48:10.977: INFO: Pod "pod-projected-secrets-fcf6e16a-a077-4e06-b856-75cc78d04143": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005980054s
STEP: Saw pod success
Sep 27 05:48:10.978: INFO: Pod "pod-projected-secrets-fcf6e16a-a077-4e06-b856-75cc78d04143" satisfied condition "success or failure"
Sep 27 05:48:10.979: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-projected-secrets-fcf6e16a-a077-4e06-b856-75cc78d04143 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 27 05:48:11.000: INFO: Waiting for pod pod-projected-secrets-fcf6e16a-a077-4e06-b856-75cc78d04143 to disappear
Sep 27 05:48:11.002: INFO: Pod pod-projected-secrets-fcf6e16a-a077-4e06-b856-75cc78d04143 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:48:11.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2323" for this suite.
Sep 27 05:48:17.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:48:17.085: INFO: namespace projected-2323 deletion completed in 6.078699066s

• [SLOW TEST:8.277 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:48:17.086: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9134
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 05:48:17.230: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3c59b340-981b-4202-985f-29e924411515" in namespace "projected-9134" to be "success or failure"
Sep 27 05:48:17.234: INFO: Pod "downwardapi-volume-3c59b340-981b-4202-985f-29e924411515": Phase="Pending", Reason="", readiness=false. Elapsed: 3.851657ms
Sep 27 05:48:19.236: INFO: Pod "downwardapi-volume-3c59b340-981b-4202-985f-29e924411515": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00652682s
STEP: Saw pod success
Sep 27 05:48:19.237: INFO: Pod "downwardapi-volume-3c59b340-981b-4202-985f-29e924411515" satisfied condition "success or failure"
Sep 27 05:48:19.238: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod downwardapi-volume-3c59b340-981b-4202-985f-29e924411515 container client-container: <nil>
STEP: delete the pod
Sep 27 05:48:19.255: INFO: Waiting for pod downwardapi-volume-3c59b340-981b-4202-985f-29e924411515 to disappear
Sep 27 05:48:19.257: INFO: Pod downwardapi-volume-3c59b340-981b-4202-985f-29e924411515 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:48:19.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9134" for this suite.
Sep 27 05:48:25.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:48:25.349: INFO: namespace projected-9134 deletion completed in 6.086290338s

• [SLOW TEST:8.264 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:48:25.350: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2692
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1293
STEP: creating an rc
Sep 27 05:48:25.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 create -f - --namespace=kubectl-2692'
Sep 27 05:48:26.441: INFO: stderr: ""
Sep 27 05:48:26.441: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Sep 27 05:48:27.444: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 05:48:27.444: INFO: Found 0 / 1
Sep 27 05:48:28.444: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 05:48:28.444: INFO: Found 1 / 1
Sep 27 05:48:28.444: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 27 05:48:28.446: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 05:48:28.447: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Sep 27 05:48:28.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 logs redis-master-bvxhg redis-master --namespace=kubectl-2692'
Sep 27 05:48:28.574: INFO: stderr: ""
Sep 27 05:48:28.574: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Sep 05:48:27.247 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Sep 05:48:27.247 # Server started, Redis version 3.2.12\n1:M 27 Sep 05:48:27.247 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Sep 05:48:27.247 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Sep 27 05:48:28.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 log redis-master-bvxhg redis-master --namespace=kubectl-2692 --tail=1'
Sep 27 05:48:28.680: INFO: stderr: ""
Sep 27 05:48:28.680: INFO: stdout: "1:M 27 Sep 05:48:27.247 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Sep 27 05:48:28.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 log redis-master-bvxhg redis-master --namespace=kubectl-2692 --limit-bytes=1'
Sep 27 05:48:28.773: INFO: stderr: ""
Sep 27 05:48:28.773: INFO: stdout: " "
STEP: exposing timestamps
Sep 27 05:48:28.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 log redis-master-bvxhg redis-master --namespace=kubectl-2692 --tail=1 --timestamps'
Sep 27 05:48:28.863: INFO: stderr: ""
Sep 27 05:48:28.863: INFO: stdout: "2019-09-27T05:48:27.250510757Z 1:M 27 Sep 05:48:27.247 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Sep 27 05:48:31.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 log redis-master-bvxhg redis-master --namespace=kubectl-2692 --since=1s'
Sep 27 05:48:31.450: INFO: stderr: ""
Sep 27 05:48:31.450: INFO: stdout: ""
Sep 27 05:48:31.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 log redis-master-bvxhg redis-master --namespace=kubectl-2692 --since=24h'
Sep 27 05:48:31.542: INFO: stderr: ""
Sep 27 05:48:31.542: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Sep 05:48:27.247 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Sep 05:48:27.247 # Server started, Redis version 3.2.12\n1:M 27 Sep 05:48:27.247 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Sep 05:48:27.247 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1299
STEP: using delete to clean up resources
Sep 27 05:48:31.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 delete --grace-period=0 --force -f - --namespace=kubectl-2692'
Sep 27 05:48:31.627: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 27 05:48:31.627: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Sep 27 05:48:31.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get rc,svc -l name=nginx --no-headers --namespace=kubectl-2692'
Sep 27 05:48:31.709: INFO: stderr: "No resources found.\n"
Sep 27 05:48:31.709: INFO: stdout: ""
Sep 27 05:48:31.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods -l name=nginx --namespace=kubectl-2692 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 27 05:48:31.784: INFO: stderr: ""
Sep 27 05:48:31.784: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:48:31.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2692" for this suite.
Sep 27 05:48:37.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:48:37.891: INFO: namespace kubectl-2692 deletion completed in 6.093538663s

• [SLOW TEST:12.542 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:48:37.892: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2827
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-bnpv
STEP: Creating a pod to test atomic-volume-subpath
Sep 27 05:48:38.043: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-bnpv" in namespace "subpath-2827" to be "success or failure"
Sep 27 05:48:38.046: INFO: Pod "pod-subpath-test-configmap-bnpv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.852711ms
Sep 27 05:48:40.049: INFO: Pod "pod-subpath-test-configmap-bnpv": Phase="Running", Reason="", readiness=true. Elapsed: 2.005910817s
Sep 27 05:48:42.054: INFO: Pod "pod-subpath-test-configmap-bnpv": Phase="Running", Reason="", readiness=true. Elapsed: 4.010812854s
Sep 27 05:48:44.057: INFO: Pod "pod-subpath-test-configmap-bnpv": Phase="Running", Reason="", readiness=true. Elapsed: 6.013694766s
Sep 27 05:48:46.061: INFO: Pod "pod-subpath-test-configmap-bnpv": Phase="Running", Reason="", readiness=true. Elapsed: 8.016986035s
Sep 27 05:48:48.063: INFO: Pod "pod-subpath-test-configmap-bnpv": Phase="Running", Reason="", readiness=true. Elapsed: 10.019596313s
Sep 27 05:48:50.066: INFO: Pod "pod-subpath-test-configmap-bnpv": Phase="Running", Reason="", readiness=true. Elapsed: 12.022281932s
Sep 27 05:48:52.069: INFO: Pod "pod-subpath-test-configmap-bnpv": Phase="Running", Reason="", readiness=true. Elapsed: 14.025524806s
Sep 27 05:48:54.072: INFO: Pod "pod-subpath-test-configmap-bnpv": Phase="Running", Reason="", readiness=true. Elapsed: 16.02816689s
Sep 27 05:48:56.075: INFO: Pod "pod-subpath-test-configmap-bnpv": Phase="Running", Reason="", readiness=true. Elapsed: 18.031513337s
Sep 27 05:48:58.078: INFO: Pod "pod-subpath-test-configmap-bnpv": Phase="Running", Reason="", readiness=true. Elapsed: 20.034539075s
Sep 27 05:49:00.081: INFO: Pod "pod-subpath-test-configmap-bnpv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.037369988s
STEP: Saw pod success
Sep 27 05:49:00.081: INFO: Pod "pod-subpath-test-configmap-bnpv" satisfied condition "success or failure"
Sep 27 05:49:00.083: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-subpath-test-configmap-bnpv container test-container-subpath-configmap-bnpv: <nil>
STEP: delete the pod
Sep 27 05:49:00.099: INFO: Waiting for pod pod-subpath-test-configmap-bnpv to disappear
Sep 27 05:49:00.101: INFO: Pod pod-subpath-test-configmap-bnpv no longer exists
STEP: Deleting pod pod-subpath-test-configmap-bnpv
Sep 27 05:49:00.101: INFO: Deleting pod "pod-subpath-test-configmap-bnpv" in namespace "subpath-2827"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:49:00.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2827" for this suite.
Sep 27 05:49:06.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:49:06.192: INFO: namespace subpath-2827 deletion completed in 6.084536378s

• [SLOW TEST:28.300 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:49:06.192: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-817
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-52371305-da0b-40bc-8951-ba7740d601db
STEP: Creating secret with name s-test-opt-upd-536a4cc6-af9e-4c42-be82-ec351edd76bf
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-52371305-da0b-40bc-8951-ba7740d601db
STEP: Updating secret s-test-opt-upd-536a4cc6-af9e-4c42-be82-ec351edd76bf
STEP: Creating secret with name s-test-opt-create-dacfa092-07d2-4414-a6d5-06a8fbc02405
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:49:10.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-817" for this suite.
Sep 27 05:49:32.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:49:32.524: INFO: namespace secrets-817 deletion completed in 22.08622432s

• [SLOW TEST:26.332 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:49:32.524: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-2067
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Sep 27 05:49:35.193: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2067 pod-service-account-a1a07d21-a56d-4204-b9a5-2126d68bc514 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Sep 27 05:49:35.495: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2067 pod-service-account-a1a07d21-a56d-4204-b9a5-2126d68bc514 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Sep 27 05:49:35.671: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2067 pod-service-account-a1a07d21-a56d-4204-b9a5-2126d68bc514 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:49:35.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2067" for this suite.
Sep 27 05:49:41.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:49:41.947: INFO: namespace svcaccounts-2067 deletion completed in 6.086549058s

• [SLOW TEST:9.423 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:49:41.947: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8646
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-45666cbd-144d-446c-843b-7027cc3c5007
STEP: Creating secret with name secret-projected-all-test-volume-335b680a-9f66-479f-9eac-a254a014c7eb
STEP: Creating a pod to test Check all projections for projected volume plugin
Sep 27 05:49:42.099: INFO: Waiting up to 5m0s for pod "projected-volume-f987b2d5-4775-44a8-beeb-38e790b7445e" in namespace "projected-8646" to be "success or failure"
Sep 27 05:49:42.102: INFO: Pod "projected-volume-f987b2d5-4775-44a8-beeb-38e790b7445e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.490725ms
Sep 27 05:49:44.105: INFO: Pod "projected-volume-f987b2d5-4775-44a8-beeb-38e790b7445e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00527201s
STEP: Saw pod success
Sep 27 05:49:44.105: INFO: Pod "projected-volume-f987b2d5-4775-44a8-beeb-38e790b7445e" satisfied condition "success or failure"
Sep 27 05:49:44.106: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod projected-volume-f987b2d5-4775-44a8-beeb-38e790b7445e container projected-all-volume-test: <nil>
STEP: delete the pod
Sep 27 05:49:44.126: INFO: Waiting for pod projected-volume-f987b2d5-4775-44a8-beeb-38e790b7445e to disappear
Sep 27 05:49:44.129: INFO: Pod projected-volume-f987b2d5-4775-44a8-beeb-38e790b7445e no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:49:44.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8646" for this suite.
Sep 27 05:49:50.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:49:50.238: INFO: namespace projected-8646 deletion completed in 6.104643549s

• [SLOW TEST:8.291 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:49:50.239: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-76
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-76/configmap-test-4a4437b1-9d79-47b0-8cd3-a0761ea11421
STEP: Creating a pod to test consume configMaps
Sep 27 05:49:50.390: INFO: Waiting up to 5m0s for pod "pod-configmaps-4c5edd43-2270-4abe-9369-cbecc9c33b22" in namespace "configmap-76" to be "success or failure"
Sep 27 05:49:50.396: INFO: Pod "pod-configmaps-4c5edd43-2270-4abe-9369-cbecc9c33b22": Phase="Pending", Reason="", readiness=false. Elapsed: 5.921056ms
Sep 27 05:49:52.400: INFO: Pod "pod-configmaps-4c5edd43-2270-4abe-9369-cbecc9c33b22": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009131997s
STEP: Saw pod success
Sep 27 05:49:52.400: INFO: Pod "pod-configmaps-4c5edd43-2270-4abe-9369-cbecc9c33b22" satisfied condition "success or failure"
Sep 27 05:49:52.402: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-configmaps-4c5edd43-2270-4abe-9369-cbecc9c33b22 container env-test: <nil>
STEP: delete the pod
Sep 27 05:49:52.420: INFO: Waiting for pod pod-configmaps-4c5edd43-2270-4abe-9369-cbecc9c33b22 to disappear
Sep 27 05:49:52.424: INFO: Pod pod-configmaps-4c5edd43-2270-4abe-9369-cbecc9c33b22 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:49:52.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-76" for this suite.
Sep 27 05:49:58.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:49:58.506: INFO: namespace configmap-76 deletion completed in 6.077994335s

• [SLOW TEST:8.268 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:49:58.507: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-726
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-f7930369-0c52-40b8-9b9c-e4b034de80bc
STEP: Creating a pod to test consume secrets
Sep 27 05:49:58.681: INFO: Waiting up to 5m0s for pod "pod-secrets-d9b1acea-7e1d-4d19-bac5-90029bd3e3b6" in namespace "secrets-726" to be "success or failure"
Sep 27 05:49:58.684: INFO: Pod "pod-secrets-d9b1acea-7e1d-4d19-bac5-90029bd3e3b6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.732875ms
Sep 27 05:50:00.687: INFO: Pod "pod-secrets-d9b1acea-7e1d-4d19-bac5-90029bd3e3b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006576711s
STEP: Saw pod success
Sep 27 05:50:00.687: INFO: Pod "pod-secrets-d9b1acea-7e1d-4d19-bac5-90029bd3e3b6" satisfied condition "success or failure"
Sep 27 05:50:00.689: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-secrets-d9b1acea-7e1d-4d19-bac5-90029bd3e3b6 container secret-volume-test: <nil>
STEP: delete the pod
Sep 27 05:50:00.709: INFO: Waiting for pod pod-secrets-d9b1acea-7e1d-4d19-bac5-90029bd3e3b6 to disappear
Sep 27 05:50:00.711: INFO: Pod pod-secrets-d9b1acea-7e1d-4d19-bac5-90029bd3e3b6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:50:00.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-726" for this suite.
Sep 27 05:50:06.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:50:06.809: INFO: namespace secrets-726 deletion completed in 6.093304582s

• [SLOW TEST:8.302 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:50:06.809: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9982
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 05:50:06.955: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a3c0728e-03f4-4e8c-b4a5-303f69255a13" in namespace "downward-api-9982" to be "success or failure"
Sep 27 05:50:06.962: INFO: Pod "downwardapi-volume-a3c0728e-03f4-4e8c-b4a5-303f69255a13": Phase="Pending", Reason="", readiness=false. Elapsed: 7.285014ms
Sep 27 05:50:08.965: INFO: Pod "downwardapi-volume-a3c0728e-03f4-4e8c-b4a5-303f69255a13": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010262132s
STEP: Saw pod success
Sep 27 05:50:08.965: INFO: Pod "downwardapi-volume-a3c0728e-03f4-4e8c-b4a5-303f69255a13" satisfied condition "success or failure"
Sep 27 05:50:08.967: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod downwardapi-volume-a3c0728e-03f4-4e8c-b4a5-303f69255a13 container client-container: <nil>
STEP: delete the pod
Sep 27 05:50:08.984: INFO: Waiting for pod downwardapi-volume-a3c0728e-03f4-4e8c-b4a5-303f69255a13 to disappear
Sep 27 05:50:08.985: INFO: Pod downwardapi-volume-a3c0728e-03f4-4e8c-b4a5-303f69255a13 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:50:08.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9982" for this suite.
Sep 27 05:50:15.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:50:15.071: INFO: namespace downward-api-9982 deletion completed in 6.081728187s

• [SLOW TEST:8.262 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:50:15.072: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7616
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-7c41b3a4-2e5b-4c8f-9993-b5a6017153cb in namespace container-probe-7616
Sep 27 05:50:17.222: INFO: Started pod busybox-7c41b3a4-2e5b-4c8f-9993-b5a6017153cb in namespace container-probe-7616
STEP: checking the pod's current state and verifying that restartCount is present
Sep 27 05:50:17.224: INFO: Initial restart count of pod busybox-7c41b3a4-2e5b-4c8f-9993-b5a6017153cb is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:54:17.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7616" for this suite.
Sep 27 05:54:23.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:54:23.735: INFO: namespace container-probe-7616 deletion completed in 6.113558599s

• [SLOW TEST:248.664 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:54:23.736: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8735
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-8735
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8735 to expose endpoints map[]
Sep 27 05:54:23.905: INFO: successfully validated that service multi-endpoint-test in namespace services-8735 exposes endpoints map[] (7.511512ms elapsed)
STEP: Creating pod pod1 in namespace services-8735
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8735 to expose endpoints map[pod1:[100]]
Sep 27 05:54:24.938: INFO: successfully validated that service multi-endpoint-test in namespace services-8735 exposes endpoints map[pod1:[100]] (1.021373862s elapsed)
STEP: Creating pod pod2 in namespace services-8735
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8735 to expose endpoints map[pod1:[100] pod2:[101]]
Sep 27 05:54:26.970: INFO: successfully validated that service multi-endpoint-test in namespace services-8735 exposes endpoints map[pod1:[100] pod2:[101]] (2.028136332s elapsed)
STEP: Deleting pod pod1 in namespace services-8735
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8735 to expose endpoints map[pod2:[101]]
Sep 27 05:54:27.988: INFO: successfully validated that service multi-endpoint-test in namespace services-8735 exposes endpoints map[pod2:[101]] (1.013934044s elapsed)
STEP: Deleting pod pod2 in namespace services-8735
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8735 to expose endpoints map[]
Sep 27 05:54:29.002: INFO: successfully validated that service multi-endpoint-test in namespace services-8735 exposes endpoints map[] (1.007926007s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:54:29.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8735" for this suite.
Sep 27 05:54:35.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:54:35.119: INFO: namespace services-8735 deletion completed in 6.085247441s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:11.383 seconds]
[sig-network] Services
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:54:35.119: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8753
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 05:54:35.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 create -f - --namespace=kubectl-8753'
Sep 27 05:54:35.606: INFO: stderr: ""
Sep 27 05:54:35.606: INFO: stdout: "replicationcontroller/redis-master created\n"
Sep 27 05:54:35.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 create -f - --namespace=kubectl-8753'
Sep 27 05:54:35.818: INFO: stderr: ""
Sep 27 05:54:35.818: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep 27 05:54:36.821: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 05:54:36.821: INFO: Found 0 / 1
Sep 27 05:54:37.821: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 05:54:37.821: INFO: Found 1 / 1
Sep 27 05:54:37.821: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 27 05:54:37.823: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 05:54:37.823: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 27 05:54:37.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 describe pod redis-master-d26hh --namespace=kubectl-8753'
Sep 27 05:54:37.914: INFO: stderr: ""
Sep 27 05:54:37.914: INFO: stdout: "Name:           redis-master-d26hh\nNamespace:      kubectl-8753\nNode:           worker3.dev-bj.kubeoperator.io/172.16.10.234\nStart Time:     Fri, 27 Sep 2019 05:54:35 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    <none>\nStatus:         Running\nIP:             172.20.5.27\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://99809de0a11b1b53e2c76d910400c803d4cc2e63d4ba8f3301921b6dceff1518\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker://sha256:e4423e943a205fe1d81768e60603c8f2c5821576bad0801c1e91b8ba586124a0\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 27 Sep 2019 05:54:36 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-xvdx4 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-xvdx4:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-xvdx4\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     <none>\nEvents:\n  Type    Reason     Age   From                                     Message\n  ----    ------     ----  ----                                     -------\n  Normal  Scheduled  2s    default-scheduler                        Successfully assigned kubectl-8753/redis-master-d26hh to worker3.dev-bj.kubeoperator.io\n  Normal  Pulled     1s    kubelet, worker3.dev-bj.kubeoperator.io  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, worker3.dev-bj.kubeoperator.io  Created container redis-master\n  Normal  Started    1s    kubelet, worker3.dev-bj.kubeoperator.io  Started container redis-master\n"
Sep 27 05:54:37.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 describe rc redis-master --namespace=kubectl-8753'
Sep 27 05:54:38.013: INFO: stderr: ""
Sep 27 05:54:38.013: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-8753\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-d26hh\n"
Sep 27 05:54:38.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 describe service redis-master --namespace=kubectl-8753'
Sep 27 05:54:38.106: INFO: stderr: ""
Sep 27 05:54:38.107: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-8753\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.68.127.140\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.20.5.27:6379\nSession Affinity:  None\nEvents:            <none>\n"
Sep 27 05:54:38.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 describe node master1.dev-bj.kubeoperator.io'
Sep 27 05:54:38.232: INFO: stderr: ""
Sep 27 05:54:38.232: INFO: stdout: "Name:               master1.dev-bj.kubeoperator.io\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=master1.dev-bj.kubeoperator.io\n                    kubernetes.io/os=linux\n                    kubernetes.io/role=master\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"46:62:20:d5:e8:a7\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 172.16.10.238\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 27 Sep 2019 03:39:55 +0000\nTaints:             node.kubernetes.io/unschedulable:NoSchedule\nUnschedulable:      true\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Fri, 27 Sep 2019 05:54:22 +0000   Fri, 27 Sep 2019 03:39:55 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Fri, 27 Sep 2019 05:54:22 +0000   Fri, 27 Sep 2019 03:39:55 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Fri, 27 Sep 2019 05:54:22 +0000   Fri, 27 Sep 2019 03:39:55 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Fri, 27 Sep 2019 05:54:22 +0000   Fri, 27 Sep 2019 03:39:55 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  172.16.10.238\n  Hostname:    master1.dev-bj.kubeoperator.io\nCapacity:\n cpu:                2\n ephemeral-storage:  49250820Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             8009572Ki\n pods:               110\nAllocatable:\n cpu:                1800m\n ephemeral-storage:  49359097846\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             7292772Ki\n pods:               110\nSystem Info:\n Machine ID:                 c84576f2eaeb411b9337801828375d22\n System UUID:                F7570142-B0CF-EB89-D464-14A01FEA1A08\n Boot ID:                    92758bce-f63e-4453-aaad-e6774ed024d9\n Kernel Version:             3.10.0-957.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.9\n Kubelet Version:            v1.15.3\n Kube-Proxy Version:         v1.15.3\nPodCIDR:                     172.20.0.0/24\nProviderID:                  vsphere://420157F7-CFB0-89EB-D464-14A01FEA1A08\nNon-terminated Pods:         (5 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                kube-flannel-ds-amd64-dn8ln                                100m (5%)     100m (5%)   50Mi (0%)        50Mi (0%)      132m\n  kube-system                traefik-ingress-lb-lfhpr                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         129m\n  monitoring                 f2c-prometheus-node-exporter-68qcp                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         129m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-7f0ec8e8c9ff47b9-fw964    0 (0%)        0 (0%)      0 (0%)           0 (0%)         8m33s\n  weave                      weave-scope-agent-wnscg                                    100m (5%)     0 (0%)      100Mi (1%)       0 (0%)         129m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                200m (11%)  100m (5%)\n  memory             150Mi (2%)  50Mi (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:\n  Type    Reason                   Age                  From                                        Message\n  ----    ------                   ----                 ----                                        -------\n  Normal  Starting                 134m                 kube-proxy, master1.dev-bj.kubeoperator.io  Starting kube-proxy.\n  Normal  Starting                 134m                 kubelet, master1.dev-bj.kubeoperator.io     Starting kubelet.\n  Normal  NodeHasSufficientMemory  134m (x2 over 134m)  kubelet, master1.dev-bj.kubeoperator.io     Node master1.dev-bj.kubeoperator.io status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    134m (x2 over 134m)  kubelet, master1.dev-bj.kubeoperator.io     Node master1.dev-bj.kubeoperator.io status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     134m (x2 over 134m)  kubelet, master1.dev-bj.kubeoperator.io     Node master1.dev-bj.kubeoperator.io status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  134m                 kubelet, master1.dev-bj.kubeoperator.io     Updated limits on kube reserved cgroup /system.slice/kubelet.service\n  Normal  NodeAllocatableEnforced  134m                 kubelet, master1.dev-bj.kubeoperator.io     Updated Node Allocatable limit across pods\n  Normal  NodeReady                134m                 kubelet, master1.dev-bj.kubeoperator.io     Node master1.dev-bj.kubeoperator.io status is now: NodeReady\n  Normal  Starting                 134m                 kube-proxy, master1.dev-bj.kubeoperator.io  Starting kube-proxy.\n  Normal  Starting                 134m                 kubelet, master1.dev-bj.kubeoperator.io     Starting kubelet.\n  Normal  NodeAllocatableEnforced  134m                 kubelet, master1.dev-bj.kubeoperator.io     Updated limits on kube reserved cgroup /system.slice/kubelet.service\n  Normal  NodeAllocatableEnforced  134m                 kubelet, master1.dev-bj.kubeoperator.io     Updated Node Allocatable limit across pods\n  Normal  NodeHasSufficientMemory  134m                 kubelet, master1.dev-bj.kubeoperator.io     Node master1.dev-bj.kubeoperator.io status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    134m                 kubelet, master1.dev-bj.kubeoperator.io     Node master1.dev-bj.kubeoperator.io status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     134m                 kubelet, master1.dev-bj.kubeoperator.io     Node master1.dev-bj.kubeoperator.io status is now: NodeHasSufficientPID\n  Normal  NodeNotSchedulable       134m                 kubelet, master1.dev-bj.kubeoperator.io     Node master1.dev-bj.kubeoperator.io status is now: NodeNotSchedulable\n"
Sep 27 05:54:38.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 describe namespace kubectl-8753'
Sep 27 05:54:38.319: INFO: stderr: ""
Sep 27 05:54:38.319: INFO: stdout: "Name:         kubectl-8753\nLabels:       e2e-framework=kubectl\n              e2e-run=fc2212a9-0052-47d8-8864-912a7dc63933\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:54:38.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8753" for this suite.
Sep 27 05:55:00.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:55:00.405: INFO: namespace kubectl-8753 deletion completed in 22.082040809s

• [SLOW TEST:25.286 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:55:00.405: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2151
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-cc6e6b19-cd40-473f-95dc-7a064412dbc8
STEP: Creating a pod to test consume secrets
Sep 27 05:55:00.553: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-89060cec-7f04-4da3-9018-9f55f1981e90" in namespace "projected-2151" to be "success or failure"
Sep 27 05:55:00.556: INFO: Pod "pod-projected-secrets-89060cec-7f04-4da3-9018-9f55f1981e90": Phase="Pending", Reason="", readiness=false. Elapsed: 2.298696ms
Sep 27 05:55:02.562: INFO: Pod "pod-projected-secrets-89060cec-7f04-4da3-9018-9f55f1981e90": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008965422s
STEP: Saw pod success
Sep 27 05:55:02.562: INFO: Pod "pod-projected-secrets-89060cec-7f04-4da3-9018-9f55f1981e90" satisfied condition "success or failure"
Sep 27 05:55:02.565: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-projected-secrets-89060cec-7f04-4da3-9018-9f55f1981e90 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 27 05:55:02.590: INFO: Waiting for pod pod-projected-secrets-89060cec-7f04-4da3-9018-9f55f1981e90 to disappear
Sep 27 05:55:02.602: INFO: Pod pod-projected-secrets-89060cec-7f04-4da3-9018-9f55f1981e90 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:55:02.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2151" for this suite.
Sep 27 05:55:08.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:55:08.705: INFO: namespace projected-2151 deletion completed in 6.096933953s

• [SLOW TEST:8.299 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:55:08.705: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5264
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-5264
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Sep 27 05:55:08.871: INFO: Found 0 stateful pods, waiting for 3
Sep 27 05:55:18.874: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 27 05:55:18.874: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 27 05:55:18.874: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Sep 27 05:55:18.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 exec --namespace=statefulset-5264 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 27 05:55:19.088: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 27 05:55:19.088: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 27 05:55:19.088: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep 27 05:55:29.119: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Sep 27 05:55:39.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 exec --namespace=statefulset-5264 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 27 05:55:39.323: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 27 05:55:39.323: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 27 05:55:39.323: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 27 05:55:49.343: INFO: Waiting for StatefulSet statefulset-5264/ss2 to complete update
Sep 27 05:55:49.343: INFO: Waiting for Pod statefulset-5264/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep 27 05:55:49.343: INFO: Waiting for Pod statefulset-5264/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep 27 05:55:49.343: INFO: Waiting for Pod statefulset-5264/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep 27 05:55:59.350: INFO: Waiting for StatefulSet statefulset-5264/ss2 to complete update
Sep 27 05:55:59.350: INFO: Waiting for Pod statefulset-5264/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Sep 27 05:56:09.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 exec --namespace=statefulset-5264 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 27 05:56:09.533: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 27 05:56:09.533: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 27 05:56:09.533: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 27 05:56:19.566: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Sep 27 05:56:29.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 exec --namespace=statefulset-5264 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 27 05:56:29.766: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 27 05:56:29.766: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 27 05:56:29.766: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 27 05:56:39.796: INFO: Waiting for StatefulSet statefulset-5264/ss2 to complete update
Sep 27 05:56:39.796: INFO: Waiting for Pod statefulset-5264/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Sep 27 05:56:39.796: INFO: Waiting for Pod statefulset-5264/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Sep 27 05:56:39.796: INFO: Waiting for Pod statefulset-5264/ss2-2 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Sep 27 05:56:49.803: INFO: Waiting for StatefulSet statefulset-5264/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep 27 05:56:59.806: INFO: Deleting all statefulset in ns statefulset-5264
Sep 27 05:56:59.809: INFO: Scaling statefulset ss2 to 0
Sep 27 05:57:19.822: INFO: Waiting for statefulset status.replicas updated to 0
Sep 27 05:57:19.825: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:57:19.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5264" for this suite.
Sep 27 05:57:25.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:57:25.935: INFO: namespace statefulset-5264 deletion completed in 6.092749624s

• [SLOW TEST:137.231 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:57:25.936: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2870
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Sep 27 05:57:26.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 cluster-info'
Sep 27 05:57:26.163: INFO: stderr: ""
Sep 27 05:57:26.163: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.68.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.68.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://10.68.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:57:26.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2870" for this suite.
Sep 27 05:57:32.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:57:32.246: INFO: namespace kubectl-2870 deletion completed in 6.077312396s

• [SLOW TEST:6.310 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:57:32.246: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1481
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Sep 27 05:57:32.393: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1481,SelfLink:/api/v1/namespaces/watch-1481/configmaps/e2e-watch-test-watch-closed,UID:8fd240e3-a780-426f-8040-3a2e063d04a1,ResourceVersion:10822,Generation:0,CreationTimestamp:2019-09-27 05:57:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 27 05:57:32.393: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1481,SelfLink:/api/v1/namespaces/watch-1481/configmaps/e2e-watch-test-watch-closed,UID:8fd240e3-a780-426f-8040-3a2e063d04a1,ResourceVersion:10823,Generation:0,CreationTimestamp:2019-09-27 05:57:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Sep 27 05:57:32.407: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1481,SelfLink:/api/v1/namespaces/watch-1481/configmaps/e2e-watch-test-watch-closed,UID:8fd240e3-a780-426f-8040-3a2e063d04a1,ResourceVersion:10824,Generation:0,CreationTimestamp:2019-09-27 05:57:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 27 05:57:32.407: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1481,SelfLink:/api/v1/namespaces/watch-1481/configmaps/e2e-watch-test-watch-closed,UID:8fd240e3-a780-426f-8040-3a2e063d04a1,ResourceVersion:10825,Generation:0,CreationTimestamp:2019-09-27 05:57:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:57:32.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1481" for this suite.
Sep 27 05:57:38.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:57:38.501: INFO: namespace watch-1481 deletion completed in 6.089184268s

• [SLOW TEST:6.255 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:57:38.501: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-467
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-306d35f4-a3a1-43d2-8287-87ffa20bd6dc
STEP: Creating a pod to test consume configMaps
Sep 27 05:57:38.650: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-57211888-b977-4d15-b2c5-e1c045f1ca62" in namespace "projected-467" to be "success or failure"
Sep 27 05:57:38.653: INFO: Pod "pod-projected-configmaps-57211888-b977-4d15-b2c5-e1c045f1ca62": Phase="Pending", Reason="", readiness=false. Elapsed: 3.182397ms
Sep 27 05:57:40.657: INFO: Pod "pod-projected-configmaps-57211888-b977-4d15-b2c5-e1c045f1ca62": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006575145s
STEP: Saw pod success
Sep 27 05:57:40.657: INFO: Pod "pod-projected-configmaps-57211888-b977-4d15-b2c5-e1c045f1ca62" satisfied condition "success or failure"
Sep 27 05:57:40.659: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-projected-configmaps-57211888-b977-4d15-b2c5-e1c045f1ca62 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 05:57:40.690: INFO: Waiting for pod pod-projected-configmaps-57211888-b977-4d15-b2c5-e1c045f1ca62 to disappear
Sep 27 05:57:40.692: INFO: Pod pod-projected-configmaps-57211888-b977-4d15-b2c5-e1c045f1ca62 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:57:40.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-467" for this suite.
Sep 27 05:57:46.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:57:46.780: INFO: namespace projected-467 deletion completed in 6.083689162s

• [SLOW TEST:8.280 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:57:46.781: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8609
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 05:57:46.916: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:57:47.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8609" for this suite.
Sep 27 05:57:53.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:57:54.061: INFO: namespace custom-resource-definition-8609 deletion completed in 6.085074415s

• [SLOW TEST:7.280 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:57:54.061: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-478
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 05:57:54.208: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1ce62372-771f-4490-903a-65b4a8c0b655" in namespace "downward-api-478" to be "success or failure"
Sep 27 05:57:54.210: INFO: Pod "downwardapi-volume-1ce62372-771f-4490-903a-65b4a8c0b655": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021245ms
Sep 27 05:57:56.213: INFO: Pod "downwardapi-volume-1ce62372-771f-4490-903a-65b4a8c0b655": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004999477s
STEP: Saw pod success
Sep 27 05:57:56.213: INFO: Pod "downwardapi-volume-1ce62372-771f-4490-903a-65b4a8c0b655" satisfied condition "success or failure"
Sep 27 05:57:56.215: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod downwardapi-volume-1ce62372-771f-4490-903a-65b4a8c0b655 container client-container: <nil>
STEP: delete the pod
Sep 27 05:57:56.234: INFO: Waiting for pod downwardapi-volume-1ce62372-771f-4490-903a-65b4a8c0b655 to disappear
Sep 27 05:57:56.236: INFO: Pod downwardapi-volume-1ce62372-771f-4490-903a-65b4a8c0b655 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:57:56.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-478" for this suite.
Sep 27 05:58:02.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:58:02.329: INFO: namespace downward-api-478 deletion completed in 6.089062888s

• [SLOW TEST:8.268 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:58:02.329: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4221
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 27 05:58:02.561: INFO: Number of nodes with available pods: 0
Sep 27 05:58:02.561: INFO: Node master1.dev-bj.kubeoperator.io is running more than one daemon pod
Sep 27 05:58:03.596: INFO: Number of nodes with available pods: 1
Sep 27 05:58:03.596: INFO: Node master1.dev-bj.kubeoperator.io is running more than one daemon pod
Sep 27 05:58:04.573: INFO: Number of nodes with available pods: 4
Sep 27 05:58:04.573: INFO: Node master2.dev-bj.kubeoperator.io is running more than one daemon pod
Sep 27 05:58:05.572: INFO: Number of nodes with available pods: 6
Sep 27 05:58:05.572: INFO: Number of running nodes: 6, number of available pods: 6
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Sep 27 05:58:05.590: INFO: Number of nodes with available pods: 6
Sep 27 05:58:05.590: INFO: Number of running nodes: 6, number of available pods: 6
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4221, will wait for the garbage collector to delete the pods
Sep 27 05:58:06.682: INFO: Deleting DaemonSet.extensions daemon-set took: 27.926131ms
Sep 27 05:58:06.982: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.245831ms
Sep 27 05:58:19.786: INFO: Number of nodes with available pods: 0
Sep 27 05:58:19.786: INFO: Number of running nodes: 0, number of available pods: 0
Sep 27 05:58:19.792: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4221/daemonsets","resourceVersion":"11112"},"items":null}

Sep 27 05:58:19.794: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4221/pods","resourceVersion":"11112"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:58:19.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4221" for this suite.
Sep 27 05:58:25.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:58:25.906: INFO: namespace daemonsets-4221 deletion completed in 6.095939032s

• [SLOW TEST:23.578 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:58:25.907: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-1485
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep 27 05:58:30.132: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 27 05:58:30.134: INFO: Pod pod-with-poststart-http-hook still exists
Sep 27 05:58:32.134: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 27 05:58:32.137: INFO: Pod pod-with-poststart-http-hook still exists
Sep 27 05:58:34.134: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 27 05:58:34.137: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:58:34.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1485" for this suite.
Sep 27 05:58:56.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:58:56.227: INFO: namespace container-lifecycle-hook-1485 deletion completed in 22.085187778s

• [SLOW TEST:30.320 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:58:56.227: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2488
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Sep 27 05:58:56.421: INFO: Waiting up to 5m0s for pod "pod-97489832-468b-4e9b-8581-6179410b78db" in namespace "emptydir-2488" to be "success or failure"
Sep 27 05:58:56.425: INFO: Pod "pod-97489832-468b-4e9b-8581-6179410b78db": Phase="Pending", Reason="", readiness=false. Elapsed: 4.530164ms
Sep 27 05:58:58.428: INFO: Pod "pod-97489832-468b-4e9b-8581-6179410b78db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007414039s
STEP: Saw pod success
Sep 27 05:58:58.428: INFO: Pod "pod-97489832-468b-4e9b-8581-6179410b78db" satisfied condition "success or failure"
Sep 27 05:58:58.430: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-97489832-468b-4e9b-8581-6179410b78db container test-container: <nil>
STEP: delete the pod
Sep 27 05:58:58.447: INFO: Waiting for pod pod-97489832-468b-4e9b-8581-6179410b78db to disappear
Sep 27 05:58:58.450: INFO: Pod pod-97489832-468b-4e9b-8581-6179410b78db no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:58:58.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2488" for this suite.
Sep 27 05:59:04.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:59:04.546: INFO: namespace emptydir-2488 deletion completed in 6.09097135s

• [SLOW TEST:8.319 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:59:04.547: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-6385
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 05:59:04.696: INFO: (0) /api/v1/nodes/worker1.dev-bj.kubeoperator.io/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.815089ms)
Sep 27 05:59:04.699: INFO: (1) /api/v1/nodes/worker1.dev-bj.kubeoperator.io/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.183903ms)
Sep 27 05:59:04.702: INFO: (2) /api/v1/nodes/worker1.dev-bj.kubeoperator.io/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.973439ms)
Sep 27 05:59:04.705: INFO: (3) /api/v1/nodes/worker1.dev-bj.kubeoperator.io/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.942781ms)
Sep 27 05:59:04.708: INFO: (4) /api/v1/nodes/worker1.dev-bj.kubeoperator.io/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.850339ms)
Sep 27 05:59:04.711: INFO: (5) /api/v1/nodes/worker1.dev-bj.kubeoperator.io/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.540706ms)
Sep 27 05:59:04.714: INFO: (6) /api/v1/nodes/worker1.dev-bj.kubeoperator.io/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.145791ms)
Sep 27 05:59:04.717: INFO: (7) /api/v1/nodes/worker1.dev-bj.kubeoperator.io/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.023871ms)
Sep 27 05:59:04.721: INFO: (8) /api/v1/nodes/worker1.dev-bj.kubeoperator.io/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.031124ms)
Sep 27 05:59:04.724: INFO: (9) /api/v1/nodes/worker1.dev-bj.kubeoperator.io/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.029163ms)
Sep 27 05:59:04.727: INFO: (10) /api/v1/nodes/worker1.dev-bj.kubeoperator.io/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.017463ms)
Sep 27 05:59:04.731: INFO: (11) /api/v1/nodes/worker1.dev-bj.kubeoperator.io/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.973932ms)
Sep 27 05:59:04.734: INFO: (12) /api/v1/nodes/worker1.dev-bj.kubeoperator.io/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.105455ms)
Sep 27 05:59:04.737: INFO: (13) /api/v1/nodes/worker1.dev-bj.kubeoperator.io/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.03615ms)
Sep 27 05:59:04.740: INFO: (14) /api/v1/nodes/worker1.dev-bj.kubeoperator.io/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.131836ms)
Sep 27 05:59:04.743: INFO: (15) /api/v1/nodes/worker1.dev-bj.kubeoperator.io/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.16699ms)
Sep 27 05:59:04.746: INFO: (16) /api/v1/nodes/worker1.dev-bj.kubeoperator.io/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.079785ms)
Sep 27 05:59:04.749: INFO: (17) /api/v1/nodes/worker1.dev-bj.kubeoperator.io/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.09732ms)
Sep 27 05:59:04.752: INFO: (18) /api/v1/nodes/worker1.dev-bj.kubeoperator.io/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.956552ms)
Sep 27 05:59:04.755: INFO: (19) /api/v1/nodes/worker1.dev-bj.kubeoperator.io/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.988343ms)
[AfterEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:59:04.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6385" for this suite.
Sep 27 05:59:10.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:59:10.850: INFO: namespace proxy-6385 deletion completed in 6.090267657s

• [SLOW TEST:6.303 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:59:10.850: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8021
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-0c1638ba-6c36-4da3-9dde-217f95583e0c
STEP: Creating a pod to test consume secrets
Sep 27 05:59:10.999: INFO: Waiting up to 5m0s for pod "pod-secrets-9bd454a5-664f-44a2-9432-0394b56382b8" in namespace "secrets-8021" to be "success or failure"
Sep 27 05:59:11.004: INFO: Pod "pod-secrets-9bd454a5-664f-44a2-9432-0394b56382b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.679038ms
Sep 27 05:59:13.007: INFO: Pod "pod-secrets-9bd454a5-664f-44a2-9432-0394b56382b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007951326s
STEP: Saw pod success
Sep 27 05:59:13.007: INFO: Pod "pod-secrets-9bd454a5-664f-44a2-9432-0394b56382b8" satisfied condition "success or failure"
Sep 27 05:59:13.010: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-secrets-9bd454a5-664f-44a2-9432-0394b56382b8 container secret-env-test: <nil>
STEP: delete the pod
Sep 27 05:59:13.026: INFO: Waiting for pod pod-secrets-9bd454a5-664f-44a2-9432-0394b56382b8 to disappear
Sep 27 05:59:13.028: INFO: Pod pod-secrets-9bd454a5-664f-44a2-9432-0394b56382b8 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 05:59:13.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8021" for this suite.
Sep 27 05:59:19.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 05:59:19.122: INFO: namespace secrets-8021 deletion completed in 6.089905466s

• [SLOW TEST:8.273 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 05:59:19.123: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-54
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-42de9565-e85a-42a4-95df-e872910130ea
STEP: Creating configMap with name cm-test-opt-upd-0e122df9-9c20-4b0d-8a7a-a07831cfc1fd
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-42de9565-e85a-42a4-95df-e872910130ea
STEP: Updating configmap cm-test-opt-upd-0e122df9-9c20-4b0d-8a7a-a07831cfc1fd
STEP: Creating configMap with name cm-test-opt-create-bb066d63-1dc4-47f7-9d35-878f2a5b4527
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:00:27.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-54" for this suite.
Sep 27 06:00:49.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:00:49.748: INFO: namespace projected-54 deletion completed in 22.103208274s

• [SLOW TEST:90.626 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:00:49.749: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8373
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-a9cc99f8-de49-43fa-8015-8cd864fc4827
STEP: Creating a pod to test consume secrets
Sep 27 06:00:49.954: INFO: Waiting up to 5m0s for pod "pod-secrets-97ad7062-2f7c-4cb6-b991-d1f54f2b1f6d" in namespace "secrets-8373" to be "success or failure"
Sep 27 06:00:49.960: INFO: Pod "pod-secrets-97ad7062-2f7c-4cb6-b991-d1f54f2b1f6d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.285945ms
Sep 27 06:00:51.964: INFO: Pod "pod-secrets-97ad7062-2f7c-4cb6-b991-d1f54f2b1f6d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010508247s
STEP: Saw pod success
Sep 27 06:00:51.964: INFO: Pod "pod-secrets-97ad7062-2f7c-4cb6-b991-d1f54f2b1f6d" satisfied condition "success or failure"
Sep 27 06:00:51.966: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-secrets-97ad7062-2f7c-4cb6-b991-d1f54f2b1f6d container secret-volume-test: <nil>
STEP: delete the pod
Sep 27 06:00:51.984: INFO: Waiting for pod pod-secrets-97ad7062-2f7c-4cb6-b991-d1f54f2b1f6d to disappear
Sep 27 06:00:51.987: INFO: Pod pod-secrets-97ad7062-2f7c-4cb6-b991-d1f54f2b1f6d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:00:51.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8373" for this suite.
Sep 27 06:00:58.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:00:58.076: INFO: namespace secrets-8373 deletion completed in 6.083399575s

• [SLOW TEST:8.328 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:00:58.076: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-1074
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Sep 27 06:00:58.219: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-1074" to be "success or failure"
Sep 27 06:00:58.222: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.991052ms
Sep 27 06:01:00.225: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00604904s
STEP: Saw pod success
Sep 27 06:01:00.225: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Sep 27 06:01:00.227: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Sep 27 06:01:00.250: INFO: Waiting for pod pod-host-path-test to disappear
Sep 27 06:01:00.253: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:01:00.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-1074" for this suite.
Sep 27 06:01:06.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:01:06.347: INFO: namespace hostpath-1074 deletion completed in 6.089614948s

• [SLOW TEST:8.271 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:01:06.348: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5640
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 06:01:06.491: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b981ff7c-d421-4ddb-9345-cbfb82988148" in namespace "projected-5640" to be "success or failure"
Sep 27 06:01:06.495: INFO: Pod "downwardapi-volume-b981ff7c-d421-4ddb-9345-cbfb82988148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.101457ms
Sep 27 06:01:08.498: INFO: Pod "downwardapi-volume-b981ff7c-d421-4ddb-9345-cbfb82988148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007084024s
STEP: Saw pod success
Sep 27 06:01:08.498: INFO: Pod "downwardapi-volume-b981ff7c-d421-4ddb-9345-cbfb82988148" satisfied condition "success or failure"
Sep 27 06:01:08.500: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod downwardapi-volume-b981ff7c-d421-4ddb-9345-cbfb82988148 container client-container: <nil>
STEP: delete the pod
Sep 27 06:01:08.520: INFO: Waiting for pod downwardapi-volume-b981ff7c-d421-4ddb-9345-cbfb82988148 to disappear
Sep 27 06:01:08.522: INFO: Pod downwardapi-volume-b981ff7c-d421-4ddb-9345-cbfb82988148 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:01:08.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5640" for this suite.
Sep 27 06:01:14.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:01:14.619: INFO: namespace projected-5640 deletion completed in 6.091527081s

• [SLOW TEST:8.271 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:01:14.619: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9061
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-cf1009b4-0ecb-4108-b108-1b2ec2ea734f
STEP: Creating a pod to test consume configMaps
Sep 27 06:01:14.772: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d4b631e5-2bbd-49fd-8056-5c5ee36b35dd" in namespace "projected-9061" to be "success or failure"
Sep 27 06:01:14.777: INFO: Pod "pod-projected-configmaps-d4b631e5-2bbd-49fd-8056-5c5ee36b35dd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.291478ms
Sep 27 06:01:16.780: INFO: Pod "pod-projected-configmaps-d4b631e5-2bbd-49fd-8056-5c5ee36b35dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008068557s
STEP: Saw pod success
Sep 27 06:01:16.780: INFO: Pod "pod-projected-configmaps-d4b631e5-2bbd-49fd-8056-5c5ee36b35dd" satisfied condition "success or failure"
Sep 27 06:01:16.783: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-projected-configmaps-d4b631e5-2bbd-49fd-8056-5c5ee36b35dd container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 06:01:16.799: INFO: Waiting for pod pod-projected-configmaps-d4b631e5-2bbd-49fd-8056-5c5ee36b35dd to disappear
Sep 27 06:01:16.801: INFO: Pod pod-projected-configmaps-d4b631e5-2bbd-49fd-8056-5c5ee36b35dd no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:01:16.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9061" for this suite.
Sep 27 06:01:22.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:01:22.895: INFO: namespace projected-9061 deletion completed in 6.089771745s

• [SLOW TEST:8.277 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:01:22.896: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-8560
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Sep 27 06:01:25.051: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-13fa1557-0e26-4f00-b287-a670cee345dd,GenerateName:,Namespace:events-8560,SelfLink:/api/v1/namespaces/events-8560/pods/send-events-13fa1557-0e26-4f00-b287-a670cee345dd,UID:bfe68f63-a871-4c87-8228-f4ab199818cf,ResourceVersion:11806,Generation:0,CreationTimestamp:2019-09-27 06:01:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 30464888,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mt6p8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mt6p8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-mt6p8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker3.dev-bj.kubeoperator.io,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:01:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:01:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:01:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:01:23 +0000 UTC  }],Message:,Reason:,HostIP:172.16.10.234,PodIP:172.20.5.44,StartTime:2019-09-27 06:01:23 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-09-27 06:01:23 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker://sha256:c6b8a28d5611cf83d297661ddd7f40672d286eafd7eb3852267e634e8eee0948 docker://f0d1b41b077888aff6eb84c92d128b9108548cb2bcad8e6981a285629fdd4240}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Sep 27 06:01:27.055: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Sep 27 06:01:29.058: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:01:29.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8560" for this suite.
Sep 27 06:02:15.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:02:15.152: INFO: namespace events-8560 deletion completed in 46.082185308s

• [SLOW TEST:52.257 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:02:15.152: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8157
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:02:17.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8157" for this suite.
Sep 27 06:03:07.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:03:07.406: INFO: namespace kubelet-test-8157 deletion completed in 50.083151024s

• [SLOW TEST:52.254 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:03:07.406: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1218
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Sep 27 06:03:07.610: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:03:09.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1218" for this suite.
Sep 27 06:03:15.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:03:15.807: INFO: namespace init-container-1218 deletion completed in 6.119947722s

• [SLOW TEST:8.401 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:03:15.807: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3589
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 06:03:15.972: INFO: Create a RollingUpdate DaemonSet
Sep 27 06:03:15.976: INFO: Check that daemon pods launch on every node of the cluster
Sep 27 06:03:15.982: INFO: Number of nodes with available pods: 0
Sep 27 06:03:15.982: INFO: Node master1.dev-bj.kubeoperator.io is running more than one daemon pod
Sep 27 06:03:16.991: INFO: Number of nodes with available pods: 0
Sep 27 06:03:16.991: INFO: Node master1.dev-bj.kubeoperator.io is running more than one daemon pod
Sep 27 06:03:17.990: INFO: Number of nodes with available pods: 6
Sep 27 06:03:17.990: INFO: Number of running nodes: 6, number of available pods: 6
Sep 27 06:03:17.990: INFO: Update the DaemonSet to trigger a rollout
Sep 27 06:03:17.997: INFO: Updating DaemonSet daemon-set
Sep 27 06:03:30.015: INFO: Roll back the DaemonSet before rollout is complete
Sep 27 06:03:30.022: INFO: Updating DaemonSet daemon-set
Sep 27 06:03:30.022: INFO: Make sure DaemonSet rollback is complete
Sep 27 06:03:30.025: INFO: Wrong image for pod: daemon-set-8qhf6. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 27 06:03:30.025: INFO: Pod daemon-set-8qhf6 is not available
Sep 27 06:03:31.033: INFO: Wrong image for pod: daemon-set-8qhf6. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 27 06:03:31.033: INFO: Pod daemon-set-8qhf6 is not available
Sep 27 06:03:32.037: INFO: Wrong image for pod: daemon-set-8qhf6. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 27 06:03:32.037: INFO: Pod daemon-set-8qhf6 is not available
Sep 27 06:03:33.034: INFO: Pod daemon-set-4mgj8 is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3589, will wait for the garbage collector to delete the pods
Sep 27 06:03:33.103: INFO: Deleting DaemonSet.extensions daemon-set took: 7.284091ms
Sep 27 06:03:33.403: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.174645ms
Sep 27 06:03:41.306: INFO: Number of nodes with available pods: 0
Sep 27 06:03:41.306: INFO: Number of running nodes: 0, number of available pods: 0
Sep 27 06:03:41.309: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3589/daemonsets","resourceVersion":"12288"},"items":null}

Sep 27 06:03:41.310: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3589/pods","resourceVersion":"12288"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:03:41.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3589" for this suite.
Sep 27 06:03:47.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:03:47.411: INFO: namespace daemonsets-3589 deletion completed in 6.084660958s

• [SLOW TEST:31.603 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:03:47.411: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-947
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Sep 27 06:03:47.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 create -f - --namespace=kubectl-947'
Sep 27 06:03:48.020: INFO: stderr: ""
Sep 27 06:03:48.020: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep 27 06:03:49.024: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 06:03:49.024: INFO: Found 0 / 1
Sep 27 06:03:50.023: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 06:03:50.023: INFO: Found 1 / 1
Sep 27 06:03:50.023: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Sep 27 06:03:50.025: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 06:03:50.025: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 27 06:03:50.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 patch pod redis-master-drh5d --namespace=kubectl-947 -p {"metadata":{"annotations":{"x":"y"}}}'
Sep 27 06:03:50.116: INFO: stderr: ""
Sep 27 06:03:50.116: INFO: stdout: "pod/redis-master-drh5d patched\n"
STEP: checking annotations
Sep 27 06:03:50.120: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 06:03:50.120: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:03:50.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-947" for this suite.
Sep 27 06:04:12.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:04:12.217: INFO: namespace kubectl-947 deletion completed in 22.091991404s

• [SLOW TEST:24.806 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:04:12.217: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-2200
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-2200, will wait for the garbage collector to delete the pods
Sep 27 06:04:14.424: INFO: Deleting Job.batch foo took: 7.136909ms
Sep 27 06:04:14.724: INFO: Terminating Job.batch foo pods took: 300.172896ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:04:51.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2200" for this suite.
Sep 27 06:04:57.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:04:57.419: INFO: namespace job-2200 deletion completed in 6.087763561s

• [SLOW TEST:45.202 seconds]
[sig-apps] Job
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:04:57.420: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6466
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 27 06:04:57.589: INFO: Number of nodes with available pods: 0
Sep 27 06:04:57.590: INFO: Node master1.dev-bj.kubeoperator.io is running more than one daemon pod
Sep 27 06:04:58.601: INFO: Number of nodes with available pods: 0
Sep 27 06:04:58.601: INFO: Node master1.dev-bj.kubeoperator.io is running more than one daemon pod
Sep 27 06:04:59.597: INFO: Number of nodes with available pods: 5
Sep 27 06:04:59.597: INFO: Node master2.dev-bj.kubeoperator.io is running more than one daemon pod
Sep 27 06:05:00.597: INFO: Number of nodes with available pods: 6
Sep 27 06:05:00.597: INFO: Number of running nodes: 6, number of available pods: 6
STEP: Stop a daemon pod, check that the daemon pod is revived.
Sep 27 06:05:00.620: INFO: Number of nodes with available pods: 5
Sep 27 06:05:00.620: INFO: Node worker1.dev-bj.kubeoperator.io is running more than one daemon pod
Sep 27 06:05:01.628: INFO: Number of nodes with available pods: 5
Sep 27 06:05:01.628: INFO: Node worker1.dev-bj.kubeoperator.io is running more than one daemon pod
Sep 27 06:05:02.628: INFO: Number of nodes with available pods: 5
Sep 27 06:05:02.628: INFO: Node worker1.dev-bj.kubeoperator.io is running more than one daemon pod
Sep 27 06:05:03.627: INFO: Number of nodes with available pods: 5
Sep 27 06:05:03.627: INFO: Node worker1.dev-bj.kubeoperator.io is running more than one daemon pod
Sep 27 06:05:04.632: INFO: Number of nodes with available pods: 6
Sep 27 06:05:04.632: INFO: Number of running nodes: 6, number of available pods: 6
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6466, will wait for the garbage collector to delete the pods
Sep 27 06:05:04.695: INFO: Deleting DaemonSet.extensions daemon-set took: 7.43612ms
Sep 27 06:05:04.995: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.196453ms
Sep 27 06:05:11.398: INFO: Number of nodes with available pods: 0
Sep 27 06:05:11.398: INFO: Number of running nodes: 0, number of available pods: 0
Sep 27 06:05:11.401: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6466/daemonsets","resourceVersion":"12726"},"items":null}

Sep 27 06:05:11.404: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6466/pods","resourceVersion":"12726"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:05:11.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6466" for this suite.
Sep 27 06:05:17.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:05:17.504: INFO: namespace daemonsets-6466 deletion completed in 6.083455793s

• [SLOW TEST:20.084 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:05:17.504: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-757
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1722
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 27 06:05:17.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-757'
Sep 27 06:05:17.781: INFO: stderr: ""
Sep 27 06:05:17.781: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Sep 27 06:05:22.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pod e2e-test-nginx-pod --namespace=kubectl-757 -o json'
Sep 27 06:05:22.911: INFO: stderr: ""
Sep 27 06:05:22.911: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-09-27T06:05:17Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-757\",\n        \"resourceVersion\": \"12802\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-757/pods/e2e-test-nginx-pod\",\n        \"uid\": \"c32dfe03-8f88-46ab-abbe-8fe5172019c8\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-xvjtb\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"worker3.dev-bj.kubeoperator.io\",\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"volumes\": [\n            {\n                \"name\": \"default-token-xvjtb\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-xvjtb\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-27T06:05:17Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-27T06:05:19Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-27T06:05:19Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-27T06:05:17Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://68be0c5e1718b35fbb06e9c4b0a14ea47cba4a51753f8625ce840d8271190423\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker://sha256:8a2fb25a19f5dc1528b7a3fabe8b3145ff57fe10e4f1edac6c718a3cf4aa4b73\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-09-27T06:05:18Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.16.10.234\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.20.5.52\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-09-27T06:05:17Z\"\n    }\n}\n"
STEP: replace the image in the pod
Sep 27 06:05:22.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 replace -f - --namespace=kubectl-757'
Sep 27 06:05:23.195: INFO: stderr: ""
Sep 27 06:05:23.195: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1727
Sep 27 06:05:23.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 delete pods e2e-test-nginx-pod --namespace=kubectl-757'
Sep 27 06:05:31.296: INFO: stderr: ""
Sep 27 06:05:31.296: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:05:31.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-757" for this suite.
Sep 27 06:05:37.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:05:37.382: INFO: namespace kubectl-757 deletion completed in 6.08039437s

• [SLOW TEST:19.878 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:05:37.383: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6399
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-e56dc54a-a2b3-40a7-9d0b-c38aae5572cf
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-e56dc54a-a2b3-40a7-9d0b-c38aae5572cf
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:05:43.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6399" for this suite.
Sep 27 06:06:05.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:06:05.684: INFO: namespace configmap-6399 deletion completed in 22.099206324s

• [SLOW TEST:28.301 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:06:05.684: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2927
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 06:06:05.830: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Sep 27 06:06:10.833: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 27 06:06:10.833: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Sep 27 06:06:10.851: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-2927,SelfLink:/apis/apps/v1/namespaces/deployment-2927/deployments/test-cleanup-deployment,UID:18271bfb-7a4c-4398-a3a7-7fb1ba0984bd,ResourceVersion:12977,Generation:1,CreationTimestamp:2019-09-27 06:06:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Sep 27 06:06:10.854: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Sep 27 06:06:10.854: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Sep 27 06:06:10.854: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-2927,SelfLink:/apis/apps/v1/namespaces/deployment-2927/replicasets/test-cleanup-controller,UID:21dc365a-c38b-4a3c-b7b9-95b12bdd6c10,ResourceVersion:12978,Generation:1,CreationTimestamp:2019-09-27 06:06:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 18271bfb-7a4c-4398-a3a7-7fb1ba0984bd 0xc003971857 0xc003971858}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep 27 06:06:10.857: INFO: Pod "test-cleanup-controller-67hb9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-67hb9,GenerateName:test-cleanup-controller-,Namespace:deployment-2927,SelfLink:/api/v1/namespaces/deployment-2927/pods/test-cleanup-controller-67hb9,UID:8683a5d6-7b06-41d3-814b-f32e9aefad9a,ResourceVersion:12964,Generation:0,CreationTimestamp:2019-09-27 06:06:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 21dc365a-c38b-4a3c-b7b9-95b12bdd6c10 0xc002cce867 0xc002cce868}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-khj2x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-khj2x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-khj2x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker3.dev-bj.kubeoperator.io,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:06:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:06:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:06:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:06:05 +0000 UTC  }],Message:,Reason:,HostIP:172.16.10.234,PodIP:172.20.5.54,StartTime:2019-09-27 06:06:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-27 06:06:06 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker://sha256:8a2fb25a19f5dc1528b7a3fabe8b3145ff57fe10e4f1edac6c718a3cf4aa4b73 docker://fc732b54d9e6deb04c2da0610b72d605981566d289555bd2776f30d9a3da65d6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:06:10.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2927" for this suite.
Sep 27 06:06:16.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:06:16.966: INFO: namespace deployment-2927 deletion completed in 6.101331535s

• [SLOW TEST:11.283 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:06:16.967: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-652
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Sep 27 06:06:17.111: INFO: Waiting up to 5m0s for pod "var-expansion-853c9ab5-a6f6-48e5-bed2-64d0ff5492e0" in namespace "var-expansion-652" to be "success or failure"
Sep 27 06:06:17.120: INFO: Pod "var-expansion-853c9ab5-a6f6-48e5-bed2-64d0ff5492e0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.510677ms
Sep 27 06:06:19.123: INFO: Pod "var-expansion-853c9ab5-a6f6-48e5-bed2-64d0ff5492e0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011534777s
STEP: Saw pod success
Sep 27 06:06:19.123: INFO: Pod "var-expansion-853c9ab5-a6f6-48e5-bed2-64d0ff5492e0" satisfied condition "success or failure"
Sep 27 06:06:19.125: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod var-expansion-853c9ab5-a6f6-48e5-bed2-64d0ff5492e0 container dapi-container: <nil>
STEP: delete the pod
Sep 27 06:06:19.144: INFO: Waiting for pod var-expansion-853c9ab5-a6f6-48e5-bed2-64d0ff5492e0 to disappear
Sep 27 06:06:19.146: INFO: Pod var-expansion-853c9ab5-a6f6-48e5-bed2-64d0ff5492e0 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:06:19.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-652" for this suite.
Sep 27 06:06:25.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:06:25.239: INFO: namespace var-expansion-652 deletion completed in 6.085423436s

• [SLOW TEST:8.272 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:06:25.239: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6190
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6190.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6190.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6190.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6190.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6190.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6190.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6190.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6190.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6190.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6190.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6190.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6190.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6190.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 12.123.68.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.68.123.12_udp@PTR;check="$$(dig +tcp +noall +answer +search 12.123.68.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.68.123.12_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6190.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6190.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6190.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6190.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6190.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6190.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6190.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6190.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6190.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6190.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6190.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6190.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6190.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 12.123.68.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.68.123.12_udp@PTR;check="$$(dig +tcp +noall +answer +search 12.123.68.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.68.123.12_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 27 06:06:27.433: INFO: Unable to read wheezy_udp@dns-test-service.dns-6190.svc.cluster.local from pod dns-6190/dns-test-174c6c54-625a-472a-a573-e66d00e887ca: the server could not find the requested resource (get pods dns-test-174c6c54-625a-472a-a573-e66d00e887ca)
Sep 27 06:06:27.435: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6190.svc.cluster.local from pod dns-6190/dns-test-174c6c54-625a-472a-a573-e66d00e887ca: the server could not find the requested resource (get pods dns-test-174c6c54-625a-472a-a573-e66d00e887ca)
Sep 27 06:06:27.437: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6190.svc.cluster.local from pod dns-6190/dns-test-174c6c54-625a-472a-a573-e66d00e887ca: the server could not find the requested resource (get pods dns-test-174c6c54-625a-472a-a573-e66d00e887ca)
Sep 27 06:06:27.440: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6190.svc.cluster.local from pod dns-6190/dns-test-174c6c54-625a-472a-a573-e66d00e887ca: the server could not find the requested resource (get pods dns-test-174c6c54-625a-472a-a573-e66d00e887ca)
Sep 27 06:06:27.456: INFO: Unable to read jessie_udp@dns-test-service.dns-6190.svc.cluster.local from pod dns-6190/dns-test-174c6c54-625a-472a-a573-e66d00e887ca: the server could not find the requested resource (get pods dns-test-174c6c54-625a-472a-a573-e66d00e887ca)
Sep 27 06:06:27.458: INFO: Unable to read jessie_tcp@dns-test-service.dns-6190.svc.cluster.local from pod dns-6190/dns-test-174c6c54-625a-472a-a573-e66d00e887ca: the server could not find the requested resource (get pods dns-test-174c6c54-625a-472a-a573-e66d00e887ca)
Sep 27 06:06:27.460: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6190.svc.cluster.local from pod dns-6190/dns-test-174c6c54-625a-472a-a573-e66d00e887ca: the server could not find the requested resource (get pods dns-test-174c6c54-625a-472a-a573-e66d00e887ca)
Sep 27 06:06:27.463: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6190.svc.cluster.local from pod dns-6190/dns-test-174c6c54-625a-472a-a573-e66d00e887ca: the server could not find the requested resource (get pods dns-test-174c6c54-625a-472a-a573-e66d00e887ca)
Sep 27 06:06:27.478: INFO: Lookups using dns-6190/dns-test-174c6c54-625a-472a-a573-e66d00e887ca failed for: [wheezy_udp@dns-test-service.dns-6190.svc.cluster.local wheezy_tcp@dns-test-service.dns-6190.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6190.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6190.svc.cluster.local jessie_udp@dns-test-service.dns-6190.svc.cluster.local jessie_tcp@dns-test-service.dns-6190.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6190.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6190.svc.cluster.local]

Sep 27 06:06:32.528: INFO: DNS probes using dns-6190/dns-test-174c6c54-625a-472a-a573-e66d00e887ca succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:06:32.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6190" for this suite.
Sep 27 06:06:38.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:06:38.724: INFO: namespace dns-6190 deletion completed in 6.097436859s

• [SLOW TEST:13.485 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:06:38.724: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7259
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 06:06:38.871: INFO: Waiting up to 5m0s for pod "downwardapi-volume-35141519-8324-4a97-bb9f-fa36ea258583" in namespace "downward-api-7259" to be "success or failure"
Sep 27 06:06:38.876: INFO: Pod "downwardapi-volume-35141519-8324-4a97-bb9f-fa36ea258583": Phase="Pending", Reason="", readiness=false. Elapsed: 5.567051ms
Sep 27 06:06:40.879: INFO: Pod "downwardapi-volume-35141519-8324-4a97-bb9f-fa36ea258583": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008554617s
STEP: Saw pod success
Sep 27 06:06:40.879: INFO: Pod "downwardapi-volume-35141519-8324-4a97-bb9f-fa36ea258583" satisfied condition "success or failure"
Sep 27 06:06:40.881: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod downwardapi-volume-35141519-8324-4a97-bb9f-fa36ea258583 container client-container: <nil>
STEP: delete the pod
Sep 27 06:06:40.898: INFO: Waiting for pod downwardapi-volume-35141519-8324-4a97-bb9f-fa36ea258583 to disappear
Sep 27 06:06:40.900: INFO: Pod downwardapi-volume-35141519-8324-4a97-bb9f-fa36ea258583 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:06:40.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7259" for this suite.
Sep 27 06:06:46.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:06:46.984: INFO: namespace downward-api-7259 deletion completed in 6.079793819s

• [SLOW TEST:8.260 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:06:46.985: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3429
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-8c16d274-b157-4bfb-92dd-a7c062bd851e
STEP: Creating a pod to test consume configMaps
Sep 27 06:06:47.144: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c9979f0f-c474-496a-a31c-aa07494d9ac9" in namespace "projected-3429" to be "success or failure"
Sep 27 06:06:47.148: INFO: Pod "pod-projected-configmaps-c9979f0f-c474-496a-a31c-aa07494d9ac9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.673909ms
Sep 27 06:06:49.150: INFO: Pod "pod-projected-configmaps-c9979f0f-c474-496a-a31c-aa07494d9ac9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006570098s
STEP: Saw pod success
Sep 27 06:06:49.150: INFO: Pod "pod-projected-configmaps-c9979f0f-c474-496a-a31c-aa07494d9ac9" satisfied condition "success or failure"
Sep 27 06:06:49.153: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-projected-configmaps-c9979f0f-c474-496a-a31c-aa07494d9ac9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 06:06:49.169: INFO: Waiting for pod pod-projected-configmaps-c9979f0f-c474-496a-a31c-aa07494d9ac9 to disappear
Sep 27 06:06:49.171: INFO: Pod pod-projected-configmaps-c9979f0f-c474-496a-a31c-aa07494d9ac9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:06:49.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3429" for this suite.
Sep 27 06:06:55.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:06:55.260: INFO: namespace projected-3429 deletion completed in 6.084408424s

• [SLOW TEST:8.275 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:06:55.260: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-7161
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Sep 27 06:06:55.396: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:06:58.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7161" for this suite.
Sep 27 06:07:20.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:07:20.521: INFO: namespace init-container-7161 deletion completed in 22.087728169s

• [SLOW TEST:25.261 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:07:20.522: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5879
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1686
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 27 06:07:20.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-5879'
Sep 27 06:07:20.766: INFO: stderr: ""
Sep 27 06:07:20.766: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1691
Sep 27 06:07:20.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 delete pods e2e-test-nginx-pod --namespace=kubectl-5879'
Sep 27 06:07:31.307: INFO: stderr: ""
Sep 27 06:07:31.307: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:07:31.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5879" for this suite.
Sep 27 06:07:37.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:07:37.393: INFO: namespace kubectl-5879 deletion completed in 6.081177977s

• [SLOW TEST:16.871 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:07:37.393: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-3236
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Sep 27 06:07:37.530: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:07:40.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3236" for this suite.
Sep 27 06:07:46.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:07:46.949: INFO: namespace init-container-3236 deletion completed in 6.086526843s

• [SLOW TEST:9.556 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:07:46.949: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5610
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-2e1d22c1-5571-4be9-a2fa-0295b978490f
STEP: Creating a pod to test consume configMaps
Sep 27 06:07:47.104: INFO: Waiting up to 5m0s for pod "pod-configmaps-e16b63fb-07e2-47be-b437-a8162e859012" in namespace "configmap-5610" to be "success or failure"
Sep 27 06:07:47.109: INFO: Pod "pod-configmaps-e16b63fb-07e2-47be-b437-a8162e859012": Phase="Pending", Reason="", readiness=false. Elapsed: 5.021479ms
Sep 27 06:07:49.113: INFO: Pod "pod-configmaps-e16b63fb-07e2-47be-b437-a8162e859012": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008438952s
STEP: Saw pod success
Sep 27 06:07:49.113: INFO: Pod "pod-configmaps-e16b63fb-07e2-47be-b437-a8162e859012" satisfied condition "success or failure"
Sep 27 06:07:49.115: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-configmaps-e16b63fb-07e2-47be-b437-a8162e859012 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 06:07:49.135: INFO: Waiting for pod pod-configmaps-e16b63fb-07e2-47be-b437-a8162e859012 to disappear
Sep 27 06:07:49.137: INFO: Pod pod-configmaps-e16b63fb-07e2-47be-b437-a8162e859012 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:07:49.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5610" for this suite.
Sep 27 06:07:55.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:07:55.225: INFO: namespace configmap-5610 deletion completed in 6.083759958s

• [SLOW TEST:8.277 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:07:55.226: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9319
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:07:57.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9319" for this suite.
Sep 27 06:08:43.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:08:43.475: INFO: namespace kubelet-test-9319 deletion completed in 46.080502304s

• [SLOW TEST:48.249 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:08:43.475: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6690
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-d4f621a3-0703-446d-98eb-a88af61b691a
STEP: Creating a pod to test consume configMaps
Sep 27 06:08:43.625: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8f650686-c7a7-41e6-b48d-5166ba7b8d9b" in namespace "projected-6690" to be "success or failure"
Sep 27 06:08:43.627: INFO: Pod "pod-projected-configmaps-8f650686-c7a7-41e6-b48d-5166ba7b8d9b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.85276ms
Sep 27 06:08:45.630: INFO: Pod "pod-projected-configmaps-8f650686-c7a7-41e6-b48d-5166ba7b8d9b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005513791s
STEP: Saw pod success
Sep 27 06:08:45.630: INFO: Pod "pod-projected-configmaps-8f650686-c7a7-41e6-b48d-5166ba7b8d9b" satisfied condition "success or failure"
Sep 27 06:08:45.632: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-projected-configmaps-8f650686-c7a7-41e6-b48d-5166ba7b8d9b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 06:08:45.650: INFO: Waiting for pod pod-projected-configmaps-8f650686-c7a7-41e6-b48d-5166ba7b8d9b to disappear
Sep 27 06:08:45.653: INFO: Pod pod-projected-configmaps-8f650686-c7a7-41e6-b48d-5166ba7b8d9b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:08:45.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6690" for this suite.
Sep 27 06:08:51.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:08:51.760: INFO: namespace projected-6690 deletion completed in 6.09932544s

• [SLOW TEST:8.285 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:08:51.760: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8792
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-92kk
STEP: Creating a pod to test atomic-volume-subpath
Sep 27 06:08:51.922: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-92kk" in namespace "subpath-8792" to be "success or failure"
Sep 27 06:08:51.925: INFO: Pod "pod-subpath-test-configmap-92kk": Phase="Pending", Reason="", readiness=false. Elapsed: 3.438166ms
Sep 27 06:08:53.928: INFO: Pod "pod-subpath-test-configmap-92kk": Phase="Running", Reason="", readiness=true. Elapsed: 2.00616486s
Sep 27 06:08:55.931: INFO: Pod "pod-subpath-test-configmap-92kk": Phase="Running", Reason="", readiness=true. Elapsed: 4.009123566s
Sep 27 06:08:57.934: INFO: Pod "pod-subpath-test-configmap-92kk": Phase="Running", Reason="", readiness=true. Elapsed: 6.011837799s
Sep 27 06:08:59.937: INFO: Pod "pod-subpath-test-configmap-92kk": Phase="Running", Reason="", readiness=true. Elapsed: 8.015000249s
Sep 27 06:09:01.940: INFO: Pod "pod-subpath-test-configmap-92kk": Phase="Running", Reason="", readiness=true. Elapsed: 10.018028895s
Sep 27 06:09:03.943: INFO: Pod "pod-subpath-test-configmap-92kk": Phase="Running", Reason="", readiness=true. Elapsed: 12.020839355s
Sep 27 06:09:05.946: INFO: Pod "pod-subpath-test-configmap-92kk": Phase="Running", Reason="", readiness=true. Elapsed: 14.023703291s
Sep 27 06:09:07.948: INFO: Pod "pod-subpath-test-configmap-92kk": Phase="Running", Reason="", readiness=true. Elapsed: 16.026380965s
Sep 27 06:09:09.951: INFO: Pod "pod-subpath-test-configmap-92kk": Phase="Running", Reason="", readiness=true. Elapsed: 18.029290685s
Sep 27 06:09:11.954: INFO: Pod "pod-subpath-test-configmap-92kk": Phase="Running", Reason="", readiness=true. Elapsed: 20.032222377s
Sep 27 06:09:13.957: INFO: Pod "pod-subpath-test-configmap-92kk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.034902477s
STEP: Saw pod success
Sep 27 06:09:13.957: INFO: Pod "pod-subpath-test-configmap-92kk" satisfied condition "success or failure"
Sep 27 06:09:13.959: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-subpath-test-configmap-92kk container test-container-subpath-configmap-92kk: <nil>
STEP: delete the pod
Sep 27 06:09:13.976: INFO: Waiting for pod pod-subpath-test-configmap-92kk to disappear
Sep 27 06:09:13.978: INFO: Pod pod-subpath-test-configmap-92kk no longer exists
STEP: Deleting pod pod-subpath-test-configmap-92kk
Sep 27 06:09:13.978: INFO: Deleting pod "pod-subpath-test-configmap-92kk" in namespace "subpath-8792"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:09:13.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8792" for this suite.
Sep 27 06:09:19.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:09:20.067: INFO: namespace subpath-8792 deletion completed in 6.08329722s

• [SLOW TEST:28.307 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:09:20.068: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7871
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 06:09:20.213: INFO: Waiting up to 5m0s for pod "downwardapi-volume-825eaa25-965b-480f-aa53-033b09ada816" in namespace "projected-7871" to be "success or failure"
Sep 27 06:09:20.216: INFO: Pod "downwardapi-volume-825eaa25-965b-480f-aa53-033b09ada816": Phase="Pending", Reason="", readiness=false. Elapsed: 2.599066ms
Sep 27 06:09:22.219: INFO: Pod "downwardapi-volume-825eaa25-965b-480f-aa53-033b09ada816": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005681451s
STEP: Saw pod success
Sep 27 06:09:22.219: INFO: Pod "downwardapi-volume-825eaa25-965b-480f-aa53-033b09ada816" satisfied condition "success or failure"
Sep 27 06:09:22.221: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod downwardapi-volume-825eaa25-965b-480f-aa53-033b09ada816 container client-container: <nil>
STEP: delete the pod
Sep 27 06:09:22.238: INFO: Waiting for pod downwardapi-volume-825eaa25-965b-480f-aa53-033b09ada816 to disappear
Sep 27 06:09:22.240: INFO: Pod downwardapi-volume-825eaa25-965b-480f-aa53-033b09ada816 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:09:22.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7871" for this suite.
Sep 27 06:09:28.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:09:28.330: INFO: namespace projected-7871 deletion completed in 6.085345757s

• [SLOW TEST:8.262 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:09:28.330: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-828
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 27 06:09:30.485: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:09:30.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-828" for this suite.
Sep 27 06:09:36.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:09:36.588: INFO: namespace container-runtime-828 deletion completed in 6.083141254s

• [SLOW TEST:8.258 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:09:36.588: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9484
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-th76
STEP: Creating a pod to test atomic-volume-subpath
Sep 27 06:09:36.740: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-th76" in namespace "subpath-9484" to be "success or failure"
Sep 27 06:09:36.746: INFO: Pod "pod-subpath-test-downwardapi-th76": Phase="Pending", Reason="", readiness=false. Elapsed: 5.588961ms
Sep 27 06:09:38.748: INFO: Pod "pod-subpath-test-downwardapi-th76": Phase="Running", Reason="", readiness=true. Elapsed: 2.008031192s
Sep 27 06:09:40.752: INFO: Pod "pod-subpath-test-downwardapi-th76": Phase="Running", Reason="", readiness=true. Elapsed: 4.011239425s
Sep 27 06:09:42.755: INFO: Pod "pod-subpath-test-downwardapi-th76": Phase="Running", Reason="", readiness=true. Elapsed: 6.014162052s
Sep 27 06:09:44.759: INFO: Pod "pod-subpath-test-downwardapi-th76": Phase="Running", Reason="", readiness=true. Elapsed: 8.018603087s
Sep 27 06:09:46.762: INFO: Pod "pod-subpath-test-downwardapi-th76": Phase="Running", Reason="", readiness=true. Elapsed: 10.021559309s
Sep 27 06:09:48.764: INFO: Pod "pod-subpath-test-downwardapi-th76": Phase="Running", Reason="", readiness=true. Elapsed: 12.023927619s
Sep 27 06:09:50.768: INFO: Pod "pod-subpath-test-downwardapi-th76": Phase="Running", Reason="", readiness=true. Elapsed: 14.027432721s
Sep 27 06:09:52.771: INFO: Pod "pod-subpath-test-downwardapi-th76": Phase="Running", Reason="", readiness=true. Elapsed: 16.030482375s
Sep 27 06:09:54.774: INFO: Pod "pod-subpath-test-downwardapi-th76": Phase="Running", Reason="", readiness=true. Elapsed: 18.033670257s
Sep 27 06:09:56.777: INFO: Pod "pod-subpath-test-downwardapi-th76": Phase="Running", Reason="", readiness=true. Elapsed: 20.036785081s
Sep 27 06:09:58.780: INFO: Pod "pod-subpath-test-downwardapi-th76": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.039105763s
STEP: Saw pod success
Sep 27 06:09:58.780: INFO: Pod "pod-subpath-test-downwardapi-th76" satisfied condition "success or failure"
Sep 27 06:09:58.781: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-subpath-test-downwardapi-th76 container test-container-subpath-downwardapi-th76: <nil>
STEP: delete the pod
Sep 27 06:09:58.801: INFO: Waiting for pod pod-subpath-test-downwardapi-th76 to disappear
Sep 27 06:09:58.803: INFO: Pod pod-subpath-test-downwardapi-th76 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-th76
Sep 27 06:09:58.803: INFO: Deleting pod "pod-subpath-test-downwardapi-th76" in namespace "subpath-9484"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:09:58.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9484" for this suite.
Sep 27 06:10:04.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:10:04.913: INFO: namespace subpath-9484 deletion completed in 6.102003789s

• [SLOW TEST:28.325 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:10:04.913: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1250
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-117947c9-a3d7-46a3-8258-d647ca8527eb
STEP: Creating a pod to test consume configMaps
Sep 27 06:10:05.069: INFO: Waiting up to 5m0s for pod "pod-configmaps-ff2f4370-93e4-4a24-849e-81c043f544fd" in namespace "configmap-1250" to be "success or failure"
Sep 27 06:10:05.072: INFO: Pod "pod-configmaps-ff2f4370-93e4-4a24-849e-81c043f544fd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.598875ms
Sep 27 06:10:07.075: INFO: Pod "pod-configmaps-ff2f4370-93e4-4a24-849e-81c043f544fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006755879s
STEP: Saw pod success
Sep 27 06:10:07.075: INFO: Pod "pod-configmaps-ff2f4370-93e4-4a24-849e-81c043f544fd" satisfied condition "success or failure"
Sep 27 06:10:07.078: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-configmaps-ff2f4370-93e4-4a24-849e-81c043f544fd container configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 06:10:07.097: INFO: Waiting for pod pod-configmaps-ff2f4370-93e4-4a24-849e-81c043f544fd to disappear
Sep 27 06:10:07.099: INFO: Pod pod-configmaps-ff2f4370-93e4-4a24-849e-81c043f544fd no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:10:07.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1250" for this suite.
Sep 27 06:10:13.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:10:13.185: INFO: namespace configmap-1250 deletion completed in 6.081999487s

• [SLOW TEST:8.272 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:10:13.186: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7019
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-57759ae0-b783-4cdd-998b-3e02325979e1
STEP: Creating a pod to test consume secrets
Sep 27 06:10:13.340: INFO: Waiting up to 5m0s for pod "pod-secrets-56469d21-775a-4288-b793-7bb8f344a605" in namespace "secrets-7019" to be "success or failure"
Sep 27 06:10:13.342: INFO: Pod "pod-secrets-56469d21-775a-4288-b793-7bb8f344a605": Phase="Pending", Reason="", readiness=false. Elapsed: 1.957861ms
Sep 27 06:10:15.345: INFO: Pod "pod-secrets-56469d21-775a-4288-b793-7bb8f344a605": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0049384s
STEP: Saw pod success
Sep 27 06:10:15.345: INFO: Pod "pod-secrets-56469d21-775a-4288-b793-7bb8f344a605" satisfied condition "success or failure"
Sep 27 06:10:15.347: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-secrets-56469d21-775a-4288-b793-7bb8f344a605 container secret-volume-test: <nil>
STEP: delete the pod
Sep 27 06:10:15.367: INFO: Waiting for pod pod-secrets-56469d21-775a-4288-b793-7bb8f344a605 to disappear
Sep 27 06:10:15.371: INFO: Pod pod-secrets-56469d21-775a-4288-b793-7bb8f344a605 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:10:15.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7019" for this suite.
Sep 27 06:10:21.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:10:21.456: INFO: namespace secrets-7019 deletion completed in 6.081101991s

• [SLOW TEST:8.271 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:10:21.457: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6211
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep 27 06:10:21.598: INFO: Waiting up to 5m0s for pod "pod-2bd8b4a3-5d55-4db4-b2e9-c4e30e022654" in namespace "emptydir-6211" to be "success or failure"
Sep 27 06:10:21.604: INFO: Pod "pod-2bd8b4a3-5d55-4db4-b2e9-c4e30e022654": Phase="Pending", Reason="", readiness=false. Elapsed: 5.677511ms
Sep 27 06:10:23.607: INFO: Pod "pod-2bd8b4a3-5d55-4db4-b2e9-c4e30e022654": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008517629s
STEP: Saw pod success
Sep 27 06:10:23.607: INFO: Pod "pod-2bd8b4a3-5d55-4db4-b2e9-c4e30e022654" satisfied condition "success or failure"
Sep 27 06:10:23.609: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-2bd8b4a3-5d55-4db4-b2e9-c4e30e022654 container test-container: <nil>
STEP: delete the pod
Sep 27 06:10:23.625: INFO: Waiting for pod pod-2bd8b4a3-5d55-4db4-b2e9-c4e30e022654 to disappear
Sep 27 06:10:23.627: INFO: Pod pod-2bd8b4a3-5d55-4db4-b2e9-c4e30e022654 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:10:23.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6211" for this suite.
Sep 27 06:10:29.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:10:29.741: INFO: namespace emptydir-6211 deletion completed in 6.109735532s

• [SLOW TEST:8.285 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:10:29.742: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5653
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep 27 06:10:32.416: INFO: Successfully updated pod "pod-update-105d687f-9d3c-4181-a097-5e862aed7655"
STEP: verifying the updated pod is in kubernetes
Sep 27 06:10:32.421: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:10:32.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5653" for this suite.
Sep 27 06:10:54.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:10:54.510: INFO: namespace pods-5653 deletion completed in 22.08419497s

• [SLOW TEST:24.768 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:10:54.510: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8155
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-5e39f516-dbce-452a-8bb6-9e97911fa218
STEP: Creating a pod to test consume secrets
Sep 27 06:10:54.669: INFO: Waiting up to 5m0s for pod "pod-secrets-e09924d2-4d98-445e-b7e0-0ad7049b68eb" in namespace "secrets-8155" to be "success or failure"
Sep 27 06:10:54.674: INFO: Pod "pod-secrets-e09924d2-4d98-445e-b7e0-0ad7049b68eb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.791372ms
Sep 27 06:10:56.677: INFO: Pod "pod-secrets-e09924d2-4d98-445e-b7e0-0ad7049b68eb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008184845s
STEP: Saw pod success
Sep 27 06:10:56.677: INFO: Pod "pod-secrets-e09924d2-4d98-445e-b7e0-0ad7049b68eb" satisfied condition "success or failure"
Sep 27 06:10:56.680: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-secrets-e09924d2-4d98-445e-b7e0-0ad7049b68eb container secret-volume-test: <nil>
STEP: delete the pod
Sep 27 06:10:56.702: INFO: Waiting for pod pod-secrets-e09924d2-4d98-445e-b7e0-0ad7049b68eb to disappear
Sep 27 06:10:56.704: INFO: Pod pod-secrets-e09924d2-4d98-445e-b7e0-0ad7049b68eb no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:10:56.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8155" for this suite.
Sep 27 06:11:02.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:11:02.798: INFO: namespace secrets-8155 deletion completed in 6.090403772s

• [SLOW TEST:8.289 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:11:02.799: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-1168
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Sep 27 06:11:02.939: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Sep 27 06:11:03.247: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Sep 27 06:11:07.034: INFO: Waited 1.722661831s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:11:07.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-1168" for this suite.
Sep 27 06:11:13.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:11:13.940: INFO: namespace aggregator-1168 deletion completed in 6.171558851s

• [SLOW TEST:11.141 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:11:13.940: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2441
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-c0d185a1-dea8-4bff-afca-bd20f8257360
STEP: Creating a pod to test consume configMaps
Sep 27 06:11:14.087: INFO: Waiting up to 5m0s for pod "pod-configmaps-59577d73-fe00-4092-a231-1cdc225de8ca" in namespace "configmap-2441" to be "success or failure"
Sep 27 06:11:14.094: INFO: Pod "pod-configmaps-59577d73-fe00-4092-a231-1cdc225de8ca": Phase="Pending", Reason="", readiness=false. Elapsed: 7.153997ms
Sep 27 06:11:16.097: INFO: Pod "pod-configmaps-59577d73-fe00-4092-a231-1cdc225de8ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01027369s
STEP: Saw pod success
Sep 27 06:11:16.097: INFO: Pod "pod-configmaps-59577d73-fe00-4092-a231-1cdc225de8ca" satisfied condition "success or failure"
Sep 27 06:11:16.099: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-configmaps-59577d73-fe00-4092-a231-1cdc225de8ca container configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 06:11:16.116: INFO: Waiting for pod pod-configmaps-59577d73-fe00-4092-a231-1cdc225de8ca to disappear
Sep 27 06:11:16.117: INFO: Pod pod-configmaps-59577d73-fe00-4092-a231-1cdc225de8ca no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:11:16.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2441" for this suite.
Sep 27 06:11:22.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:11:22.212: INFO: namespace configmap-2441 deletion completed in 6.090383631s

• [SLOW TEST:8.272 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:11:22.213: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-8094
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Sep 27 06:11:22.349: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 27 06:11:22.359: INFO: Waiting for terminating namespaces to be deleted...
Sep 27 06:11:22.361: INFO: 
Logging pods the kubelet thinks is on node worker1.dev-bj.kubeoperator.io before test
Sep 27 06:11:22.370: INFO: weave-scope-agent-fd4jr from weave started at 2019-09-27 03:45:13 +0000 UTC (1 container statuses recorded)
Sep 27 06:11:22.370: INFO: 	Container scope-agent ready: true, restart count 0
Sep 27 06:11:22.370: INFO: sonobuoy from sonobuoy started at 2019-09-27 05:46:03 +0000 UTC (1 container statuses recorded)
Sep 27 06:11:22.370: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 27 06:11:22.370: INFO: sonobuoy-e2e-job-4960befc9aee4574 from sonobuoy started at 2019-09-27 05:46:05 +0000 UTC (2 container statuses recorded)
Sep 27 06:11:22.370: INFO: 	Container e2e ready: true, restart count 0
Sep 27 06:11:22.370: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 27 06:11:22.370: INFO: sonobuoy-systemd-logs-daemon-set-7f0ec8e8c9ff47b9-2pvqs from sonobuoy started at 2019-09-27 05:46:06 +0000 UTC (2 container statuses recorded)
Sep 27 06:11:22.370: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 27 06:11:22.370: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 27 06:11:22.370: INFO: kube-flannel-ds-amd64-2tjkj from kube-system started at 2019-09-27 03:42:32 +0000 UTC (1 container statuses recorded)
Sep 27 06:11:22.370: INFO: 	Container kube-flannel ready: true, restart count 0
Sep 27 06:11:22.370: INFO: traefik-ingress-lb-5hr58 from kube-system started at 2019-09-27 03:44:43 +0000 UTC (1 container statuses recorded)
Sep 27 06:11:22.370: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Sep 27 06:11:22.370: INFO: weave-scope-app-7d78556c95-hlvsr from weave started at 2019-09-27 03:45:13 +0000 UTC (1 container statuses recorded)
Sep 27 06:11:22.370: INFO: 	Container app ready: true, restart count 0
Sep 27 06:11:22.370: INFO: f2c-prometheus-server-59b7445459-cdgrc from monitoring started at 2019-09-27 03:45:02 +0000 UTC (2 container statuses recorded)
Sep 27 06:11:22.370: INFO: 	Container prometheus-server ready: true, restart count 0
Sep 27 06:11:22.370: INFO: 	Container prometheus-server-configmap-reload ready: true, restart count 0
Sep 27 06:11:22.370: INFO: tiller-deploy-7cf9b9d4d9-2hhhb from kube-system started at 2019-09-27 03:44:15 +0000 UTC (1 container statuses recorded)
Sep 27 06:11:22.370: INFO: 	Container tiller ready: true, restart count 0
Sep 27 06:11:22.370: INFO: coredns-6647cfd5f7-5wgqm from kube-system started at 2019-09-27 03:44:35 +0000 UTC (1 container statuses recorded)
Sep 27 06:11:22.370: INFO: 	Container coredns ready: true, restart count 0
Sep 27 06:11:22.370: INFO: f2c-prometheus-node-exporter-9jg5c from monitoring started at 2019-09-27 03:45:00 +0000 UTC (1 container statuses recorded)
Sep 27 06:11:22.370: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Sep 27 06:11:22.370: INFO: 
Logging pods the kubelet thinks is on node worker2.dev-bj.kubeoperator.io before test
Sep 27 06:11:22.380: INFO: traefik-ingress-lb-cmrlj from kube-system started at 2019-09-27 03:44:43 +0000 UTC (1 container statuses recorded)
Sep 27 06:11:22.380: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Sep 27 06:11:22.380: INFO: f2c-grafana-6dd4b6bc5c-822q6 from monitoring started at 2019-09-27 03:45:09 +0000 UTC (1 container statuses recorded)
Sep 27 06:11:22.380: INFO: 	Container grafana ready: true, restart count 0
Sep 27 06:11:22.380: INFO: weave-scope-cluster-agent-6fdcc8f6dd-247hz from weave started at 2019-09-27 03:45:13 +0000 UTC (1 container statuses recorded)
Sep 27 06:11:22.380: INFO: 	Container scope-cluster-agent ready: true, restart count 0
Sep 27 06:11:22.380: INFO: kube-flannel-ds-amd64-ptljm from kube-system started at 2019-09-27 03:42:32 +0000 UTC (1 container statuses recorded)
Sep 27 06:11:22.380: INFO: 	Container kube-flannel ready: true, restart count 0
Sep 27 06:11:22.380: INFO: coredns-6647cfd5f7-m24g4 from kube-system started at 2019-09-27 03:44:35 +0000 UTC (1 container statuses recorded)
Sep 27 06:11:22.380: INFO: 	Container coredns ready: true, restart count 0
Sep 27 06:11:22.380: INFO: heapster-5646c79465-tpqxz from kube-system started at 2019-09-27 03:44:50 +0000 UTC (1 container statuses recorded)
Sep 27 06:11:22.380: INFO: 	Container heapster ready: true, restart count 0
Sep 27 06:11:22.380: INFO: f2c-prometheus-node-exporter-kgb24 from monitoring started at 2019-09-27 03:45:00 +0000 UTC (1 container statuses recorded)
Sep 27 06:11:22.380: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Sep 27 06:11:22.380: INFO: weave-scope-agent-rrlfg from weave started at 2019-09-27 03:45:13 +0000 UTC (1 container statuses recorded)
Sep 27 06:11:22.380: INFO: 	Container scope-agent ready: true, restart count 0
Sep 27 06:11:22.380: INFO: kube-registry-dh5pv from kube-system started at 2019-09-27 03:45:49 +0000 UTC (2 container statuses recorded)
Sep 27 06:11:22.380: INFO: 	Container registry ready: true, restart count 0
Sep 27 06:11:22.380: INFO: 	Container registry-ui ready: true, restart count 0
Sep 27 06:11:22.380: INFO: sonobuoy-systemd-logs-daemon-set-7f0ec8e8c9ff47b9-rg9hc from sonobuoy started at 2019-09-27 05:46:06 +0000 UTC (2 container statuses recorded)
Sep 27 06:11:22.380: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 27 06:11:22.380: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 27 06:11:22.380: INFO: 
Logging pods the kubelet thinks is on node worker3.dev-bj.kubeoperator.io before test
Sep 27 06:11:22.386: INFO: kube-flannel-ds-amd64-frff7 from kube-system started at 2019-09-27 03:42:32 +0000 UTC (1 container statuses recorded)
Sep 27 06:11:22.386: INFO: 	Container kube-flannel ready: true, restart count 0
Sep 27 06:11:22.386: INFO: traefik-ingress-lb-tst7r from kube-system started at 2019-09-27 03:44:43 +0000 UTC (1 container statuses recorded)
Sep 27 06:11:22.386: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Sep 27 06:11:22.386: INFO: f2c-prometheus-node-exporter-p2zc6 from monitoring started at 2019-09-27 03:45:01 +0000 UTC (1 container statuses recorded)
Sep 27 06:11:22.386: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Sep 27 06:11:22.386: INFO: f2c-prometheus-kube-state-metrics-5b66c65d69-b5znb from monitoring started at 2019-09-27 03:45:01 +0000 UTC (1 container statuses recorded)
Sep 27 06:11:22.386: INFO: 	Container prometheus-kube-state-metrics ready: true, restart count 0
Sep 27 06:11:22.386: INFO: sonobuoy-systemd-logs-daemon-set-7f0ec8e8c9ff47b9-j8dzb from sonobuoy started at 2019-09-27 05:46:06 +0000 UTC (2 container statuses recorded)
Sep 27 06:11:22.386: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 27 06:11:22.386: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 27 06:11:22.386: INFO: kubernetes-dashboard-5bc5db49-r7vvg from kube-system started at 2019-09-27 03:44:49 +0000 UTC (1 container statuses recorded)
Sep 27 06:11:22.386: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep 27 06:11:22.386: INFO: f2c-prometheus-alertmanager-65f9fd5bf5-8fc2f from monitoring started at 2019-09-27 03:45:02 +0000 UTC (2 container statuses recorded)
Sep 27 06:11:22.386: INFO: 	Container prometheus-alertmanager ready: true, restart count 0
Sep 27 06:11:22.386: INFO: 	Container prometheus-alertmanager-configmap-reload ready: true, restart count 0
Sep 27 06:11:22.386: INFO: weave-scope-agent-64k6h from weave started at 2019-09-27 03:45:13 +0000 UTC (1 container statuses recorded)
Sep 27 06:11:22.386: INFO: 	Container scope-agent ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node worker1.dev-bj.kubeoperator.io
STEP: verifying the node has the label node worker2.dev-bj.kubeoperator.io
STEP: verifying the node has the label node worker3.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod coredns-6647cfd5f7-5wgqm requesting resource cpu=100m on Node worker1.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod coredns-6647cfd5f7-m24g4 requesting resource cpu=100m on Node worker2.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod heapster-5646c79465-tpqxz requesting resource cpu=0m on Node worker2.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod kube-flannel-ds-amd64-2tjkj requesting resource cpu=100m on Node worker1.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod kube-flannel-ds-amd64-frff7 requesting resource cpu=100m on Node worker3.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod kube-flannel-ds-amd64-ptljm requesting resource cpu=100m on Node worker2.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod kube-registry-dh5pv requesting resource cpu=1000m on Node worker2.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod kubernetes-dashboard-5bc5db49-r7vvg requesting resource cpu=0m on Node worker3.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod tiller-deploy-7cf9b9d4d9-2hhhb requesting resource cpu=0m on Node worker1.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod traefik-ingress-lb-5hr58 requesting resource cpu=0m on Node worker1.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod traefik-ingress-lb-cmrlj requesting resource cpu=0m on Node worker2.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod traefik-ingress-lb-tst7r requesting resource cpu=0m on Node worker3.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod f2c-grafana-6dd4b6bc5c-822q6 requesting resource cpu=0m on Node worker2.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod f2c-prometheus-alertmanager-65f9fd5bf5-8fc2f requesting resource cpu=0m on Node worker3.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod f2c-prometheus-kube-state-metrics-5b66c65d69-b5znb requesting resource cpu=0m on Node worker3.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod f2c-prometheus-node-exporter-9jg5c requesting resource cpu=0m on Node worker1.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod f2c-prometheus-node-exporter-kgb24 requesting resource cpu=0m on Node worker2.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod f2c-prometheus-node-exporter-p2zc6 requesting resource cpu=0m on Node worker3.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod f2c-prometheus-server-59b7445459-cdgrc requesting resource cpu=0m on Node worker1.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod sonobuoy requesting resource cpu=0m on Node worker1.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod sonobuoy-e2e-job-4960befc9aee4574 requesting resource cpu=0m on Node worker1.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod sonobuoy-systemd-logs-daemon-set-7f0ec8e8c9ff47b9-2pvqs requesting resource cpu=0m on Node worker1.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod sonobuoy-systemd-logs-daemon-set-7f0ec8e8c9ff47b9-j8dzb requesting resource cpu=0m on Node worker3.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod sonobuoy-systemd-logs-daemon-set-7f0ec8e8c9ff47b9-rg9hc requesting resource cpu=0m on Node worker2.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod weave-scope-agent-64k6h requesting resource cpu=100m on Node worker3.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod weave-scope-agent-fd4jr requesting resource cpu=100m on Node worker1.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod weave-scope-agent-rrlfg requesting resource cpu=100m on Node worker2.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod weave-scope-app-7d78556c95-hlvsr requesting resource cpu=0m on Node worker1.dev-bj.kubeoperator.io
Sep 27 06:11:22.456: INFO: Pod weave-scope-cluster-agent-6fdcc8f6dd-247hz requesting resource cpu=100m on Node worker2.dev-bj.kubeoperator.io
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-30eddd5f-58e8-4d84-bb65-b30dfb03877a.15c836c3475ed548], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8094/filler-pod-30eddd5f-58e8-4d84-bb65-b30dfb03877a to worker2.dev-bj.kubeoperator.io]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-30eddd5f-58e8-4d84-bb65-b30dfb03877a.15c836c37bbd92d8], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-30eddd5f-58e8-4d84-bb65-b30dfb03877a.15c836c37de893f7], Reason = [Created], Message = [Created container filler-pod-30eddd5f-58e8-4d84-bb65-b30dfb03877a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-30eddd5f-58e8-4d84-bb65-b30dfb03877a.15c836c3850608cf], Reason = [Started], Message = [Started container filler-pod-30eddd5f-58e8-4d84-bb65-b30dfb03877a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3ee0b5b0-da3a-4e87-b42c-b18af770eb8a.15c836c347286c82], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8094/filler-pod-3ee0b5b0-da3a-4e87-b42c-b18af770eb8a to worker1.dev-bj.kubeoperator.io]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3ee0b5b0-da3a-4e87-b42c-b18af770eb8a.15c836c375ffc246], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3ee0b5b0-da3a-4e87-b42c-b18af770eb8a.15c836c378630334], Reason = [Created], Message = [Created container filler-pod-3ee0b5b0-da3a-4e87-b42c-b18af770eb8a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3ee0b5b0-da3a-4e87-b42c-b18af770eb8a.15c836c3814cc2a5], Reason = [Started], Message = [Started container filler-pod-3ee0b5b0-da3a-4e87-b42c-b18af770eb8a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-82a4fbad-7ec7-4999-ab31-0f5d4b81d763.15c836c347487f72], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8094/filler-pod-82a4fbad-7ec7-4999-ab31-0f5d4b81d763 to worker3.dev-bj.kubeoperator.io]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-82a4fbad-7ec7-4999-ab31-0f5d4b81d763.15c836c373a27e1f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-82a4fbad-7ec7-4999-ab31-0f5d4b81d763.15c836c376575f28], Reason = [Created], Message = [Created container filler-pod-82a4fbad-7ec7-4999-ab31-0f5d4b81d763]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-82a4fbad-7ec7-4999-ab31-0f5d4b81d763.15c836c37ec2417d], Reason = [Started], Message = [Started container filler-pod-82a4fbad-7ec7-4999-ab31-0f5d4b81d763]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15c836c43681c654], Reason = [FailedScheduling], Message = [0/6 nodes are available: 3 Insufficient cpu, 3 node(s) were unschedulable.]
STEP: removing the label node off the node worker1.dev-bj.kubeoperator.io
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node worker2.dev-bj.kubeoperator.io
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node worker3.dev-bj.kubeoperator.io
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:11:27.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8094" for this suite.
Sep 27 06:11:33.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:11:33.672: INFO: namespace sched-pred-8094 deletion completed in 6.113825985s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:11.459 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:11:33.672: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4612
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 06:11:33.829: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Sep 27 06:11:35.868: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:11:36.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4612" for this suite.
Sep 27 06:11:42.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:11:42.970: INFO: namespace replication-controller-4612 deletion completed in 6.087762519s

• [SLOW TEST:9.298 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:11:42.970: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-3208
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 06:11:43.118: INFO: (0) /api/v1/nodes/worker1.dev-bj.kubeoperator.io:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.994587ms)
Sep 27 06:11:43.122: INFO: (1) /api/v1/nodes/worker1.dev-bj.kubeoperator.io:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.662465ms)
Sep 27 06:11:43.126: INFO: (2) /api/v1/nodes/worker1.dev-bj.kubeoperator.io:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.237447ms)
Sep 27 06:11:43.129: INFO: (3) /api/v1/nodes/worker1.dev-bj.kubeoperator.io:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.104303ms)
Sep 27 06:11:43.132: INFO: (4) /api/v1/nodes/worker1.dev-bj.kubeoperator.io:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.350486ms)
Sep 27 06:11:43.136: INFO: (5) /api/v1/nodes/worker1.dev-bj.kubeoperator.io:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.705099ms)
Sep 27 06:11:43.139: INFO: (6) /api/v1/nodes/worker1.dev-bj.kubeoperator.io:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.105392ms)
Sep 27 06:11:43.143: INFO: (7) /api/v1/nodes/worker1.dev-bj.kubeoperator.io:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.335086ms)
Sep 27 06:11:43.146: INFO: (8) /api/v1/nodes/worker1.dev-bj.kubeoperator.io:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.519314ms)
Sep 27 06:11:43.150: INFO: (9) /api/v1/nodes/worker1.dev-bj.kubeoperator.io:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.656518ms)
Sep 27 06:11:43.155: INFO: (10) /api/v1/nodes/worker1.dev-bj.kubeoperator.io:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.187893ms)
Sep 27 06:11:43.159: INFO: (11) /api/v1/nodes/worker1.dev-bj.kubeoperator.io:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.622761ms)
Sep 27 06:11:43.162: INFO: (12) /api/v1/nodes/worker1.dev-bj.kubeoperator.io:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.660139ms)
Sep 27 06:11:43.166: INFO: (13) /api/v1/nodes/worker1.dev-bj.kubeoperator.io:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.247377ms)
Sep 27 06:11:43.169: INFO: (14) /api/v1/nodes/worker1.dev-bj.kubeoperator.io:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.26609ms)
Sep 27 06:11:43.172: INFO: (15) /api/v1/nodes/worker1.dev-bj.kubeoperator.io:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.395192ms)
Sep 27 06:11:43.175: INFO: (16) /api/v1/nodes/worker1.dev-bj.kubeoperator.io:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.136885ms)
Sep 27 06:11:43.179: INFO: (17) /api/v1/nodes/worker1.dev-bj.kubeoperator.io:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.356134ms)
Sep 27 06:11:43.182: INFO: (18) /api/v1/nodes/worker1.dev-bj.kubeoperator.io:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.191596ms)
Sep 27 06:11:43.185: INFO: (19) /api/v1/nodes/worker1.dev-bj.kubeoperator.io:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.301738ms)
[AfterEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:11:43.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3208" for this suite.
Sep 27 06:11:49.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:11:49.272: INFO: namespace proxy-3208 deletion completed in 6.082124794s

• [SLOW TEST:6.302 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:11:49.272: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-8181
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-8200
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7010
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:12:13.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8181" for this suite.
Sep 27 06:12:19.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:12:19.889: INFO: namespace namespaces-8181 deletion completed in 6.134504505s
STEP: Destroying namespace "nsdeletetest-8200" for this suite.
Sep 27 06:12:19.893: INFO: Namespace nsdeletetest-8200 was already deleted
STEP: Destroying namespace "nsdeletetest-7010" for this suite.
Sep 27 06:12:25.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:12:26.192: INFO: namespace nsdeletetest-7010 deletion completed in 6.298676944s

• [SLOW TEST:36.920 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:12:26.192: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8087
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1421
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 27 06:12:26.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-8087'
Sep 27 06:12:26.887: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 27 06:12:26.887: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1427
Sep 27 06:12:28.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 delete deployment e2e-test-nginx-deployment --namespace=kubectl-8087'
Sep 27 06:12:29.022: INFO: stderr: ""
Sep 27 06:12:29.022: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:12:29.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8087" for this suite.
Sep 27 06:14:31.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:14:31.153: INFO: namespace kubectl-8087 deletion completed in 2m2.118068255s

• [SLOW TEST:124.961 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:14:31.154: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-655
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Sep 27 06:14:31.331: INFO: Waiting up to 5m0s for pod "var-expansion-ba8c742e-f435-4d07-bbd6-e032016f8f97" in namespace "var-expansion-655" to be "success or failure"
Sep 27 06:14:31.342: INFO: Pod "var-expansion-ba8c742e-f435-4d07-bbd6-e032016f8f97": Phase="Pending", Reason="", readiness=false. Elapsed: 11.215396ms
Sep 27 06:14:33.345: INFO: Pod "var-expansion-ba8c742e-f435-4d07-bbd6-e032016f8f97": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01491191s
STEP: Saw pod success
Sep 27 06:14:33.345: INFO: Pod "var-expansion-ba8c742e-f435-4d07-bbd6-e032016f8f97" satisfied condition "success or failure"
Sep 27 06:14:33.349: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod var-expansion-ba8c742e-f435-4d07-bbd6-e032016f8f97 container dapi-container: <nil>
STEP: delete the pod
Sep 27 06:14:33.378: INFO: Waiting for pod var-expansion-ba8c742e-f435-4d07-bbd6-e032016f8f97 to disappear
Sep 27 06:14:33.381: INFO: Pod var-expansion-ba8c742e-f435-4d07-bbd6-e032016f8f97 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:14:33.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-655" for this suite.
Sep 27 06:14:39.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:14:39.481: INFO: namespace var-expansion-655 deletion completed in 6.095167707s

• [SLOW TEST:8.327 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:14:39.481: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-9477
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9347
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9704
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:14:45.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9477" for this suite.
Sep 27 06:14:51.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:14:52.027: INFO: namespace namespaces-9477 deletion completed in 6.089300199s
STEP: Destroying namespace "nsdeletetest-9347" for this suite.
Sep 27 06:14:52.029: INFO: Namespace nsdeletetest-9347 was already deleted
STEP: Destroying namespace "nsdeletetest-9704" for this suite.
Sep 27 06:14:58.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:14:58.134: INFO: namespace nsdeletetest-9704 deletion completed in 6.104486533s

• [SLOW TEST:18.653 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:14:58.134: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6976
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-6976
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6976 to expose endpoints map[]
Sep 27 06:14:58.310: INFO: successfully validated that service endpoint-test2 in namespace services-6976 exposes endpoints map[] (9.769372ms elapsed)
STEP: Creating pod pod1 in namespace services-6976
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6976 to expose endpoints map[pod1:[80]]
Sep 27 06:15:00.357: INFO: successfully validated that service endpoint-test2 in namespace services-6976 exposes endpoints map[pod1:[80]] (2.03655364s elapsed)
STEP: Creating pod pod2 in namespace services-6976
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6976 to expose endpoints map[pod1:[80] pod2:[80]]
Sep 27 06:15:02.422: INFO: successfully validated that service endpoint-test2 in namespace services-6976 exposes endpoints map[pod1:[80] pod2:[80]] (2.0596517s elapsed)
STEP: Deleting pod pod1 in namespace services-6976
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6976 to expose endpoints map[pod2:[80]]
Sep 27 06:15:02.455: INFO: successfully validated that service endpoint-test2 in namespace services-6976 exposes endpoints map[pod2:[80]] (16.077832ms elapsed)
STEP: Deleting pod pod2 in namespace services-6976
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6976 to expose endpoints map[]
Sep 27 06:15:03.485: INFO: successfully validated that service endpoint-test2 in namespace services-6976 exposes endpoints map[] (1.016424512s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:15:03.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6976" for this suite.
Sep 27 06:15:25.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:15:25.641: INFO: namespace services-6976 deletion completed in 22.110986179s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:27.507 seconds]
[sig-network] Services
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:15:25.641: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3257
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-84c8dcc6-7f92-4f28-a85e-48edd7ae222f
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:15:25.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3257" for this suite.
Sep 27 06:15:31.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:15:31.951: INFO: namespace secrets-3257 deletion completed in 6.085123524s

• [SLOW TEST:6.310 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:15:31.952: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4139
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-69b5952d-36bd-4b5f-8796-d389b39af1b9
STEP: Creating a pod to test consume configMaps
Sep 27 06:15:32.101: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c32e420b-89ab-47eb-be73-82161d4a98e4" in namespace "projected-4139" to be "success or failure"
Sep 27 06:15:32.106: INFO: Pod "pod-projected-configmaps-c32e420b-89ab-47eb-be73-82161d4a98e4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.936599ms
Sep 27 06:15:34.109: INFO: Pod "pod-projected-configmaps-c32e420b-89ab-47eb-be73-82161d4a98e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007953985s
STEP: Saw pod success
Sep 27 06:15:34.109: INFO: Pod "pod-projected-configmaps-c32e420b-89ab-47eb-be73-82161d4a98e4" satisfied condition "success or failure"
Sep 27 06:15:34.111: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-projected-configmaps-c32e420b-89ab-47eb-be73-82161d4a98e4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 06:15:34.127: INFO: Waiting for pod pod-projected-configmaps-c32e420b-89ab-47eb-be73-82161d4a98e4 to disappear
Sep 27 06:15:34.129: INFO: Pod pod-projected-configmaps-c32e420b-89ab-47eb-be73-82161d4a98e4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:15:34.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4139" for this suite.
Sep 27 06:15:40.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:15:40.222: INFO: namespace projected-4139 deletion completed in 6.089046913s

• [SLOW TEST:8.271 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:15:40.223: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1453
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1457
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 27 06:15:40.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-1453'
Sep 27 06:15:40.687: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 27 06:15:40.687: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Sep 27 06:15:40.706: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-csxp9]
Sep 27 06:15:40.706: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-csxp9" in namespace "kubectl-1453" to be "running and ready"
Sep 27 06:15:40.712: INFO: Pod "e2e-test-nginx-rc-csxp9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.758105ms
Sep 27 06:15:42.715: INFO: Pod "e2e-test-nginx-rc-csxp9": Phase="Running", Reason="", readiness=true. Elapsed: 2.008713321s
Sep 27 06:15:42.715: INFO: Pod "e2e-test-nginx-rc-csxp9" satisfied condition "running and ready"
Sep 27 06:15:42.715: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-csxp9]
Sep 27 06:15:42.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 logs rc/e2e-test-nginx-rc --namespace=kubectl-1453'
Sep 27 06:15:42.816: INFO: stderr: ""
Sep 27 06:15:42.816: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1462
Sep 27 06:15:42.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 delete rc e2e-test-nginx-rc --namespace=kubectl-1453'
Sep 27 06:15:42.898: INFO: stderr: ""
Sep 27 06:15:42.898: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:15:42.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1453" for this suite.
Sep 27 06:16:04.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:16:04.991: INFO: namespace kubectl-1453 deletion completed in 22.088147192s

• [SLOW TEST:24.769 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:16:04.992: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2593
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Sep 27 06:16:05.182: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-833349834 proxy --unix-socket=/tmp/kubectl-proxy-unix843341413/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:16:05.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2593" for this suite.
Sep 27 06:16:11.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:16:11.356: INFO: namespace kubectl-2593 deletion completed in 6.098841916s

• [SLOW TEST:6.365 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:16:11.357: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2490
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Sep 27 06:16:42.048: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:16:42.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0927 06:16:42.048441      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-2490" for this suite.
Sep 27 06:16:48.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:16:48.151: INFO: namespace gc-2490 deletion completed in 6.099166232s

• [SLOW TEST:36.795 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:16:48.152: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1067
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 06:16:48.307: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6086ec6b-ccf3-4135-aa92-25e1d2e50e6d" in namespace "projected-1067" to be "success or failure"
Sep 27 06:16:48.313: INFO: Pod "downwardapi-volume-6086ec6b-ccf3-4135-aa92-25e1d2e50e6d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.626786ms
Sep 27 06:16:50.317: INFO: Pod "downwardapi-volume-6086ec6b-ccf3-4135-aa92-25e1d2e50e6d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009535431s
STEP: Saw pod success
Sep 27 06:16:50.317: INFO: Pod "downwardapi-volume-6086ec6b-ccf3-4135-aa92-25e1d2e50e6d" satisfied condition "success or failure"
Sep 27 06:16:50.320: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod downwardapi-volume-6086ec6b-ccf3-4135-aa92-25e1d2e50e6d container client-container: <nil>
STEP: delete the pod
Sep 27 06:16:50.343: INFO: Waiting for pod downwardapi-volume-6086ec6b-ccf3-4135-aa92-25e1d2e50e6d to disappear
Sep 27 06:16:50.345: INFO: Pod downwardapi-volume-6086ec6b-ccf3-4135-aa92-25e1d2e50e6d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:16:50.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1067" for this suite.
Sep 27 06:16:56.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:16:56.461: INFO: namespace projected-1067 deletion completed in 6.111895975s

• [SLOW TEST:8.310 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:16:56.461: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7245
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-7245
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 27 06:16:56.601: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 27 06:17:16.690: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.20.5.89:8080/dial?request=hostName&protocol=http&host=172.20.5.88&port=8080&tries=1'] Namespace:pod-network-test-7245 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 06:17:16.690: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
Sep 27 06:17:16.821: INFO: Waiting for endpoints: map[]
Sep 27 06:17:16.826: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.20.5.89:8080/dial?request=hostName&protocol=http&host=172.20.3.21&port=8080&tries=1'] Namespace:pod-network-test-7245 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 06:17:16.826: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
Sep 27 06:17:16.925: INFO: Waiting for endpoints: map[]
Sep 27 06:17:16.929: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.20.5.89:8080/dial?request=hostName&protocol=http&host=172.20.4.14&port=8080&tries=1'] Namespace:pod-network-test-7245 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 06:17:16.929: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
Sep 27 06:17:17.027: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:17:17.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7245" for this suite.
Sep 27 06:17:39.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:17:39.115: INFO: namespace pod-network-test-7245 deletion completed in 22.08050176s

• [SLOW TEST:42.653 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:17:39.115: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5928
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 06:17:39.264: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:17:41.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5928" for this suite.
Sep 27 06:18:23.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:18:23.378: INFO: namespace pods-5928 deletion completed in 42.081969149s

• [SLOW TEST:44.263 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:18:23.378: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-5049
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Sep 27 06:18:23.522: INFO: Waiting up to 5m0s for pod "var-expansion-4b50fd42-68a9-4f14-869d-dab7c5a887d0" in namespace "var-expansion-5049" to be "success or failure"
Sep 27 06:18:23.525: INFO: Pod "var-expansion-4b50fd42-68a9-4f14-869d-dab7c5a887d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.873971ms
Sep 27 06:18:25.528: INFO: Pod "var-expansion-4b50fd42-68a9-4f14-869d-dab7c5a887d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005704787s
STEP: Saw pod success
Sep 27 06:18:25.528: INFO: Pod "var-expansion-4b50fd42-68a9-4f14-869d-dab7c5a887d0" satisfied condition "success or failure"
Sep 27 06:18:25.530: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod var-expansion-4b50fd42-68a9-4f14-869d-dab7c5a887d0 container dapi-container: <nil>
STEP: delete the pod
Sep 27 06:18:25.548: INFO: Waiting for pod var-expansion-4b50fd42-68a9-4f14-869d-dab7c5a887d0 to disappear
Sep 27 06:18:25.551: INFO: Pod var-expansion-4b50fd42-68a9-4f14-869d-dab7c5a887d0 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:18:25.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5049" for this suite.
Sep 27 06:18:31.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:18:31.639: INFO: namespace var-expansion-5049 deletion completed in 6.083559921s

• [SLOW TEST:8.261 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:18:31.639: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1154
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1154.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-1154.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1154.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1154.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-1154.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1154.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 27 06:18:33.841: INFO: DNS probes using dns-1154/dns-test-c16ccc73-f0c9-47f0-ad7b-e57b55632d9e succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:18:33.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1154" for this suite.
Sep 27 06:18:39.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:18:39.954: INFO: namespace dns-1154 deletion completed in 6.088243887s

• [SLOW TEST:8.315 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:18:39.954: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1370
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-h75v
STEP: Creating a pod to test atomic-volume-subpath
Sep 27 06:18:40.104: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-h75v" in namespace "subpath-1370" to be "success or failure"
Sep 27 06:18:40.106: INFO: Pod "pod-subpath-test-projected-h75v": Phase="Pending", Reason="", readiness=false. Elapsed: 2.244199ms
Sep 27 06:18:42.109: INFO: Pod "pod-subpath-test-projected-h75v": Phase="Running", Reason="", readiness=true. Elapsed: 2.005000854s
Sep 27 06:18:44.112: INFO: Pod "pod-subpath-test-projected-h75v": Phase="Running", Reason="", readiness=true. Elapsed: 4.007927377s
Sep 27 06:18:46.115: INFO: Pod "pod-subpath-test-projected-h75v": Phase="Running", Reason="", readiness=true. Elapsed: 6.010945735s
Sep 27 06:18:48.118: INFO: Pod "pod-subpath-test-projected-h75v": Phase="Running", Reason="", readiness=true. Elapsed: 8.013953163s
Sep 27 06:18:50.125: INFO: Pod "pod-subpath-test-projected-h75v": Phase="Running", Reason="", readiness=true. Elapsed: 10.021836195s
Sep 27 06:18:52.128: INFO: Pod "pod-subpath-test-projected-h75v": Phase="Running", Reason="", readiness=true. Elapsed: 12.024850432s
Sep 27 06:18:54.132: INFO: Pod "pod-subpath-test-projected-h75v": Phase="Running", Reason="", readiness=true. Elapsed: 14.027899797s
Sep 27 06:18:56.134: INFO: Pod "pod-subpath-test-projected-h75v": Phase="Running", Reason="", readiness=true. Elapsed: 16.030836589s
Sep 27 06:18:58.137: INFO: Pod "pod-subpath-test-projected-h75v": Phase="Running", Reason="", readiness=true. Elapsed: 18.033660152s
Sep 27 06:19:00.140: INFO: Pod "pod-subpath-test-projected-h75v": Phase="Running", Reason="", readiness=true. Elapsed: 20.036661948s
Sep 27 06:19:02.144: INFO: Pod "pod-subpath-test-projected-h75v": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.039993497s
STEP: Saw pod success
Sep 27 06:19:02.144: INFO: Pod "pod-subpath-test-projected-h75v" satisfied condition "success or failure"
Sep 27 06:19:02.146: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-subpath-test-projected-h75v container test-container-subpath-projected-h75v: <nil>
STEP: delete the pod
Sep 27 06:19:02.166: INFO: Waiting for pod pod-subpath-test-projected-h75v to disappear
Sep 27 06:19:02.170: INFO: Pod pod-subpath-test-projected-h75v no longer exists
STEP: Deleting pod pod-subpath-test-projected-h75v
Sep 27 06:19:02.170: INFO: Deleting pod "pod-subpath-test-projected-h75v" in namespace "subpath-1370"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:19:02.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1370" for this suite.
Sep 27 06:19:08.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:19:08.258: INFO: namespace subpath-1370 deletion completed in 6.082562801s

• [SLOW TEST:28.304 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:19:08.258: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4681
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-c59f6a05-0d50-4160-95df-e60ef2ba63e8
Sep 27 06:19:08.408: INFO: Pod name my-hostname-basic-c59f6a05-0d50-4160-95df-e60ef2ba63e8: Found 0 pods out of 1
Sep 27 06:19:13.412: INFO: Pod name my-hostname-basic-c59f6a05-0d50-4160-95df-e60ef2ba63e8: Found 1 pods out of 1
Sep 27 06:19:13.412: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-c59f6a05-0d50-4160-95df-e60ef2ba63e8" are running
Sep 27 06:19:13.414: INFO: Pod "my-hostname-basic-c59f6a05-0d50-4160-95df-e60ef2ba63e8-65l7n" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-27 06:19:08 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-27 06:19:10 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-27 06:19:10 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-27 06:19:08 +0000 UTC Reason: Message:}])
Sep 27 06:19:13.414: INFO: Trying to dial the pod
Sep 27 06:19:18.423: INFO: Controller my-hostname-basic-c59f6a05-0d50-4160-95df-e60ef2ba63e8: Got expected result from replica 1 [my-hostname-basic-c59f6a05-0d50-4160-95df-e60ef2ba63e8-65l7n]: "my-hostname-basic-c59f6a05-0d50-4160-95df-e60ef2ba63e8-65l7n", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:19:18.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4681" for this suite.
Sep 27 06:19:24.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:19:24.513: INFO: namespace replication-controller-4681 deletion completed in 6.085546899s

• [SLOW TEST:16.255 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:19:24.513: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3563
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep 27 06:19:24.658: INFO: Waiting up to 5m0s for pod "pod-1b1d5bc6-0e2f-4e3d-8b82-744214533731" in namespace "emptydir-3563" to be "success or failure"
Sep 27 06:19:24.663: INFO: Pod "pod-1b1d5bc6-0e2f-4e3d-8b82-744214533731": Phase="Pending", Reason="", readiness=false. Elapsed: 4.925969ms
Sep 27 06:19:26.666: INFO: Pod "pod-1b1d5bc6-0e2f-4e3d-8b82-744214533731": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008346823s
STEP: Saw pod success
Sep 27 06:19:26.666: INFO: Pod "pod-1b1d5bc6-0e2f-4e3d-8b82-744214533731" satisfied condition "success or failure"
Sep 27 06:19:26.670: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-1b1d5bc6-0e2f-4e3d-8b82-744214533731 container test-container: <nil>
STEP: delete the pod
Sep 27 06:19:26.691: INFO: Waiting for pod pod-1b1d5bc6-0e2f-4e3d-8b82-744214533731 to disappear
Sep 27 06:19:26.695: INFO: Pod pod-1b1d5bc6-0e2f-4e3d-8b82-744214533731 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:19:26.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3563" for this suite.
Sep 27 06:19:32.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:19:32.792: INFO: namespace emptydir-3563 deletion completed in 6.088891313s

• [SLOW TEST:8.279 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:19:32.792: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Sep 27 06:19:35.958: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:19:36.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4" for this suite.
Sep 27 06:19:58.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:19:59.070: INFO: namespace replicaset-4 deletion completed in 22.096088618s

• [SLOW TEST:26.278 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:19:59.070: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3438
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 06:19:59.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 version'
Sep 27 06:19:59.286: INFO: stderr: ""
Sep 27 06:19:59.286: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.3\", GitCommit:\"2d3c76f9091b6bec110a5e63777c332469e0cba2\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T11:13:54Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.3\", GitCommit:\"2d3c76f9091b6bec110a5e63777c332469e0cba2\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T11:05:50Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:19:59.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3438" for this suite.
Sep 27 06:20:05.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:20:05.387: INFO: namespace kubectl-3438 deletion completed in 6.093785398s

• [SLOW TEST:6.316 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:20:05.387: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-4666
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Sep 27 06:20:06.048: INFO: created pod pod-service-account-defaultsa
Sep 27 06:20:06.048: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Sep 27 06:20:06.054: INFO: created pod pod-service-account-mountsa
Sep 27 06:20:06.054: INFO: pod pod-service-account-mountsa service account token volume mount: true
Sep 27 06:20:06.064: INFO: created pod pod-service-account-nomountsa
Sep 27 06:20:06.064: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Sep 27 06:20:06.071: INFO: created pod pod-service-account-defaultsa-mountspec
Sep 27 06:20:06.071: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Sep 27 06:20:06.077: INFO: created pod pod-service-account-mountsa-mountspec
Sep 27 06:20:06.078: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Sep 27 06:20:06.086: INFO: created pod pod-service-account-nomountsa-mountspec
Sep 27 06:20:06.086: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Sep 27 06:20:06.093: INFO: created pod pod-service-account-defaultsa-nomountspec
Sep 27 06:20:06.093: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Sep 27 06:20:06.103: INFO: created pod pod-service-account-mountsa-nomountspec
Sep 27 06:20:06.103: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Sep 27 06:20:06.110: INFO: created pod pod-service-account-nomountsa-nomountspec
Sep 27 06:20:06.110: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:20:06.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4666" for this suite.
Sep 27 06:20:12.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:20:12.230: INFO: namespace svcaccounts-4666 deletion completed in 6.108934565s

• [SLOW TEST:6.843 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:20:12.230: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-99
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:20:16.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-99" for this suite.
Sep 27 06:20:22.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:20:22.487: INFO: namespace kubelet-test-99 deletion completed in 6.101139594s

• [SLOW TEST:10.256 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:20:22.487: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4516
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Sep 27 06:20:22.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 api-versions'
Sep 27 06:20:22.715: INFO: stderr: ""
Sep 27 06:20:22.715: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:20:22.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4516" for this suite.
Sep 27 06:20:28.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:20:28.809: INFO: namespace kubectl-4516 deletion completed in 6.088632952s

• [SLOW TEST:6.322 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:20:28.809: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9483
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 06:20:29.020: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Sep 27 06:20:29.037: INFO: Number of nodes with available pods: 0
Sep 27 06:20:29.037: INFO: Node master1.dev-bj.kubeoperator.io is running more than one daemon pod
Sep 27 06:20:30.050: INFO: Number of nodes with available pods: 0
Sep 27 06:20:30.050: INFO: Node master1.dev-bj.kubeoperator.io is running more than one daemon pod
Sep 27 06:20:31.045: INFO: Number of nodes with available pods: 6
Sep 27 06:20:31.045: INFO: Number of running nodes: 6, number of available pods: 6
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Sep 27 06:20:31.071: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:31.071: INFO: Wrong image for pod: daemon-set-9lbgw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:31.071: INFO: Wrong image for pod: daemon-set-b7lkw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:31.071: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:31.071: INFO: Wrong image for pod: daemon-set-jsknw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:31.071: INFO: Wrong image for pod: daemon-set-th9jm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:32.081: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:32.081: INFO: Wrong image for pod: daemon-set-9lbgw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:32.081: INFO: Wrong image for pod: daemon-set-b7lkw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:32.081: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:32.081: INFO: Wrong image for pod: daemon-set-jsknw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:32.081: INFO: Wrong image for pod: daemon-set-th9jm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:33.081: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:33.081: INFO: Wrong image for pod: daemon-set-9lbgw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:33.081: INFO: Wrong image for pod: daemon-set-b7lkw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:33.081: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:33.081: INFO: Wrong image for pod: daemon-set-jsknw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:33.081: INFO: Wrong image for pod: daemon-set-th9jm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:34.082: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:34.082: INFO: Wrong image for pod: daemon-set-9lbgw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:34.082: INFO: Wrong image for pod: daemon-set-b7lkw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:34.082: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:34.082: INFO: Wrong image for pod: daemon-set-jsknw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:34.082: INFO: Pod daemon-set-jsknw is not available
Sep 27 06:20:34.082: INFO: Wrong image for pod: daemon-set-th9jm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:35.081: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:35.081: INFO: Wrong image for pod: daemon-set-9lbgw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:35.081: INFO: Wrong image for pod: daemon-set-b7lkw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:35.081: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:35.081: INFO: Wrong image for pod: daemon-set-jsknw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:35.081: INFO: Pod daemon-set-jsknw is not available
Sep 27 06:20:35.081: INFO: Wrong image for pod: daemon-set-th9jm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:36.081: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:36.081: INFO: Wrong image for pod: daemon-set-9lbgw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:36.081: INFO: Wrong image for pod: daemon-set-b7lkw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:36.081: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:36.081: INFO: Wrong image for pod: daemon-set-jsknw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:36.081: INFO: Pod daemon-set-jsknw is not available
Sep 27 06:20:36.081: INFO: Wrong image for pod: daemon-set-th9jm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:37.082: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:37.082: INFO: Wrong image for pod: daemon-set-9lbgw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:37.082: INFO: Wrong image for pod: daemon-set-b7lkw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:37.082: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:37.082: INFO: Wrong image for pod: daemon-set-jsknw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:37.082: INFO: Pod daemon-set-jsknw is not available
Sep 27 06:20:37.082: INFO: Wrong image for pod: daemon-set-th9jm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:38.081: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:38.081: INFO: Wrong image for pod: daemon-set-9lbgw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:38.081: INFO: Wrong image for pod: daemon-set-b7lkw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:38.081: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:38.081: INFO: Wrong image for pod: daemon-set-jsknw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:38.081: INFO: Pod daemon-set-jsknw is not available
Sep 27 06:20:38.081: INFO: Wrong image for pod: daemon-set-th9jm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:39.082: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:39.082: INFO: Wrong image for pod: daemon-set-9lbgw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:39.082: INFO: Wrong image for pod: daemon-set-b7lkw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:39.082: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:39.082: INFO: Wrong image for pod: daemon-set-jsknw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:39.082: INFO: Pod daemon-set-jsknw is not available
Sep 27 06:20:39.082: INFO: Wrong image for pod: daemon-set-th9jm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:40.081: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:40.081: INFO: Wrong image for pod: daemon-set-9lbgw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:40.081: INFO: Wrong image for pod: daemon-set-b7lkw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:40.081: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:40.081: INFO: Wrong image for pod: daemon-set-jsknw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:40.081: INFO: Pod daemon-set-jsknw is not available
Sep 27 06:20:40.081: INFO: Wrong image for pod: daemon-set-th9jm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:41.081: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:41.081: INFO: Wrong image for pod: daemon-set-9lbgw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:41.081: INFO: Wrong image for pod: daemon-set-b7lkw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:41.081: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:41.081: INFO: Wrong image for pod: daemon-set-jsknw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:41.081: INFO: Pod daemon-set-jsknw is not available
Sep 27 06:20:41.081: INFO: Wrong image for pod: daemon-set-th9jm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:42.081: INFO: Pod daemon-set-46lds is not available
Sep 27 06:20:42.081: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:42.081: INFO: Wrong image for pod: daemon-set-9lbgw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:42.081: INFO: Wrong image for pod: daemon-set-b7lkw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:42.081: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:42.081: INFO: Wrong image for pod: daemon-set-th9jm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:43.082: INFO: Pod daemon-set-46lds is not available
Sep 27 06:20:43.082: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:43.082: INFO: Wrong image for pod: daemon-set-9lbgw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:43.082: INFO: Wrong image for pod: daemon-set-b7lkw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:43.082: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:43.082: INFO: Wrong image for pod: daemon-set-th9jm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:44.081: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:44.081: INFO: Wrong image for pod: daemon-set-9lbgw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:44.081: INFO: Wrong image for pod: daemon-set-b7lkw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:44.081: INFO: Pod daemon-set-b7lkw is not available
Sep 27 06:20:44.081: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:44.081: INFO: Wrong image for pod: daemon-set-th9jm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:45.081: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:45.081: INFO: Wrong image for pod: daemon-set-9lbgw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:45.081: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:45.081: INFO: Pod daemon-set-n2kxj is not available
Sep 27 06:20:45.081: INFO: Wrong image for pod: daemon-set-th9jm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:46.081: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:46.081: INFO: Wrong image for pod: daemon-set-9lbgw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:46.081: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:46.081: INFO: Wrong image for pod: daemon-set-th9jm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:47.084: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:47.084: INFO: Wrong image for pod: daemon-set-9lbgw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:47.084: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:47.084: INFO: Wrong image for pod: daemon-set-th9jm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:47.084: INFO: Pod daemon-set-th9jm is not available
Sep 27 06:20:48.082: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:48.082: INFO: Wrong image for pod: daemon-set-9lbgw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:48.082: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:48.082: INFO: Wrong image for pod: daemon-set-th9jm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:48.082: INFO: Pod daemon-set-th9jm is not available
Sep 27 06:20:49.082: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:49.082: INFO: Wrong image for pod: daemon-set-9lbgw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:49.082: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:49.082: INFO: Wrong image for pod: daemon-set-th9jm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:49.082: INFO: Pod daemon-set-th9jm is not available
Sep 27 06:20:50.082: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:50.082: INFO: Wrong image for pod: daemon-set-9lbgw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:50.082: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:50.082: INFO: Wrong image for pod: daemon-set-th9jm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:50.082: INFO: Pod daemon-set-th9jm is not available
Sep 27 06:20:51.081: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:51.081: INFO: Wrong image for pod: daemon-set-9lbgw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:51.081: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:51.081: INFO: Wrong image for pod: daemon-set-th9jm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:51.081: INFO: Pod daemon-set-th9jm is not available
Sep 27 06:20:52.083: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:52.083: INFO: Wrong image for pod: daemon-set-9lbgw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:52.083: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:52.083: INFO: Wrong image for pod: daemon-set-th9jm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:52.083: INFO: Pod daemon-set-th9jm is not available
Sep 27 06:20:53.082: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:53.082: INFO: Wrong image for pod: daemon-set-9lbgw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:53.082: INFO: Pod daemon-set-9zb7p is not available
Sep 27 06:20:53.082: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:54.081: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:54.081: INFO: Wrong image for pod: daemon-set-9lbgw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:54.081: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:55.081: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:55.081: INFO: Wrong image for pod: daemon-set-9lbgw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:55.081: INFO: Pod daemon-set-9lbgw is not available
Sep 27 06:20:55.081: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:56.083: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:56.083: INFO: Pod daemon-set-fvbvm is not available
Sep 27 06:20:56.083: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:57.081: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:57.081: INFO: Pod daemon-set-fvbvm is not available
Sep 27 06:20:57.081: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:58.083: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:58.083: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:59.081: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:59.081: INFO: Wrong image for pod: daemon-set-jpj28. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:20:59.081: INFO: Pod daemon-set-jpj28 is not available
Sep 27 06:21:00.081: INFO: Pod daemon-set-4stw2 is not available
Sep 27 06:21:00.081: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:21:01.082: INFO: Pod daemon-set-4stw2 is not available
Sep 27 06:21:01.083: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:21:02.082: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:21:03.081: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:21:04.081: INFO: Wrong image for pod: daemon-set-5f9vv. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 06:21:04.081: INFO: Pod daemon-set-5f9vv is not available
Sep 27 06:21:05.085: INFO: Pod daemon-set-r9d7l is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Sep 27 06:21:05.102: INFO: Number of nodes with available pods: 5
Sep 27 06:21:05.102: INFO: Node master2.dev-bj.kubeoperator.io is running more than one daemon pod
Sep 27 06:21:06.111: INFO: Number of nodes with available pods: 5
Sep 27 06:21:06.112: INFO: Node master2.dev-bj.kubeoperator.io is running more than one daemon pod
Sep 27 06:21:07.110: INFO: Number of nodes with available pods: 6
Sep 27 06:21:07.110: INFO: Number of running nodes: 6, number of available pods: 6
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9483, will wait for the garbage collector to delete the pods
Sep 27 06:21:07.195: INFO: Deleting DaemonSet.extensions daemon-set took: 7.805155ms
Sep 27 06:21:07.495: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.177399ms
Sep 27 06:21:19.999: INFO: Number of nodes with available pods: 0
Sep 27 06:21:19.999: INFO: Number of running nodes: 0, number of available pods: 0
Sep 27 06:21:20.002: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9483/daemonsets","resourceVersion":"16715"},"items":null}

Sep 27 06:21:20.004: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9483/pods","resourceVersion":"16715"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:21:20.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9483" for this suite.
Sep 27 06:21:26.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:21:26.111: INFO: namespace daemonsets-9483 deletion completed in 6.088289583s

• [SLOW TEST:57.301 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:21:26.111: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7245
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 06:21:26.274: INFO: Waiting up to 5m0s for pod "downwardapi-volume-13a841d0-f793-48fa-8bb1-d50878f9f2df" in namespace "downward-api-7245" to be "success or failure"
Sep 27 06:21:26.276: INFO: Pod "downwardapi-volume-13a841d0-f793-48fa-8bb1-d50878f9f2df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.220385ms
Sep 27 06:21:28.279: INFO: Pod "downwardapi-volume-13a841d0-f793-48fa-8bb1-d50878f9f2df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004862343s
STEP: Saw pod success
Sep 27 06:21:28.279: INFO: Pod "downwardapi-volume-13a841d0-f793-48fa-8bb1-d50878f9f2df" satisfied condition "success or failure"
Sep 27 06:21:28.280: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod downwardapi-volume-13a841d0-f793-48fa-8bb1-d50878f9f2df container client-container: <nil>
STEP: delete the pod
Sep 27 06:21:28.299: INFO: Waiting for pod downwardapi-volume-13a841d0-f793-48fa-8bb1-d50878f9f2df to disappear
Sep 27 06:21:28.301: INFO: Pod downwardapi-volume-13a841d0-f793-48fa-8bb1-d50878f9f2df no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:21:28.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7245" for this suite.
Sep 27 06:21:34.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:21:34.391: INFO: namespace downward-api-7245 deletion completed in 6.084634999s

• [SLOW TEST:8.280 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:21:34.391: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4257
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Sep 27 06:21:40.554: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W0927 06:21:40.554916      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 27 06:21:40.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4257" for this suite.
Sep 27 06:21:46.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:21:46.645: INFO: namespace gc-4257 deletion completed in 6.085358191s

• [SLOW TEST:12.254 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:21:46.645: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1208
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 06:21:46.813: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Sep 27 06:21:46.822: INFO: Number of nodes with available pods: 0
Sep 27 06:21:46.822: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Sep 27 06:21:46.845: INFO: Number of nodes with available pods: 0
Sep 27 06:21:46.845: INFO: Node worker1.dev-bj.kubeoperator.io is running more than one daemon pod
Sep 27 06:21:47.848: INFO: Number of nodes with available pods: 0
Sep 27 06:21:47.848: INFO: Node worker1.dev-bj.kubeoperator.io is running more than one daemon pod
Sep 27 06:21:48.849: INFO: Number of nodes with available pods: 1
Sep 27 06:21:48.849: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Sep 27 06:21:48.866: INFO: Number of nodes with available pods: 1
Sep 27 06:21:48.866: INFO: Number of running nodes: 0, number of available pods: 1
Sep 27 06:21:49.869: INFO: Number of nodes with available pods: 0
Sep 27 06:21:49.869: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Sep 27 06:21:49.877: INFO: Number of nodes with available pods: 0
Sep 27 06:21:49.877: INFO: Node worker1.dev-bj.kubeoperator.io is running more than one daemon pod
Sep 27 06:21:50.880: INFO: Number of nodes with available pods: 0
Sep 27 06:21:50.880: INFO: Node worker1.dev-bj.kubeoperator.io is running more than one daemon pod
Sep 27 06:21:51.879: INFO: Number of nodes with available pods: 0
Sep 27 06:21:51.880: INFO: Node worker1.dev-bj.kubeoperator.io is running more than one daemon pod
Sep 27 06:21:52.880: INFO: Number of nodes with available pods: 0
Sep 27 06:21:52.880: INFO: Node worker1.dev-bj.kubeoperator.io is running more than one daemon pod
Sep 27 06:21:53.880: INFO: Number of nodes with available pods: 1
Sep 27 06:21:53.880: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1208, will wait for the garbage collector to delete the pods
Sep 27 06:21:53.944: INFO: Deleting DaemonSet.extensions daemon-set took: 7.267071ms
Sep 27 06:21:54.044: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.274905ms
Sep 27 06:22:00.047: INFO: Number of nodes with available pods: 0
Sep 27 06:22:00.047: INFO: Number of running nodes: 0, number of available pods: 0
Sep 27 06:22:00.049: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1208/daemonsets","resourceVersion":"17174"},"items":null}

Sep 27 06:22:00.053: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1208/pods","resourceVersion":"17174"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:22:00.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1208" for this suite.
Sep 27 06:22:06.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:22:06.175: INFO: namespace daemonsets-1208 deletion completed in 6.092839274s

• [SLOW TEST:19.530 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:22:06.176: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6772
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Sep 27 06:22:06.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 --namespace=kubectl-6772 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Sep 27 06:22:07.403: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Sep 27 06:22:07.403: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:22:09.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6772" for this suite.
Sep 27 06:22:15.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:22:15.495: INFO: namespace kubectl-6772 deletion completed in 6.082160468s

• [SLOW TEST:9.320 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:22:15.496: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6685
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep 27 06:22:15.646: INFO: Waiting up to 5m0s for pod "downward-api-c3dad811-ca2f-4c06-906e-85882e28b8ed" in namespace "downward-api-6685" to be "success or failure"
Sep 27 06:22:15.648: INFO: Pod "downward-api-c3dad811-ca2f-4c06-906e-85882e28b8ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.312277ms
Sep 27 06:22:17.652: INFO: Pod "downward-api-c3dad811-ca2f-4c06-906e-85882e28b8ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005648767s
STEP: Saw pod success
Sep 27 06:22:17.652: INFO: Pod "downward-api-c3dad811-ca2f-4c06-906e-85882e28b8ed" satisfied condition "success or failure"
Sep 27 06:22:17.654: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod downward-api-c3dad811-ca2f-4c06-906e-85882e28b8ed container dapi-container: <nil>
STEP: delete the pod
Sep 27 06:22:17.674: INFO: Waiting for pod downward-api-c3dad811-ca2f-4c06-906e-85882e28b8ed to disappear
Sep 27 06:22:17.677: INFO: Pod downward-api-c3dad811-ca2f-4c06-906e-85882e28b8ed no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:22:17.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6685" for this suite.
Sep 27 06:22:23.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:22:23.781: INFO: namespace downward-api-6685 deletion completed in 6.10039376s

• [SLOW TEST:8.286 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:22:23.781: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-697
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 27 06:22:25.954: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:22:25.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-697" for this suite.
Sep 27 06:22:32.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:22:32.200: INFO: namespace container-runtime-697 deletion completed in 6.199421516s

• [SLOW TEST:8.419 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:22:32.200: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2485
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Sep 27 06:22:42.550: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:22:42.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0927 06:22:42.550048      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-2485" for this suite.
Sep 27 06:22:48.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:22:48.637: INFO: namespace gc-2485 deletion completed in 6.082689992s

• [SLOW TEST:16.437 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:22:48.638: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-4463
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 27 06:22:50.801: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:22:50.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4463" for this suite.
Sep 27 06:22:56.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:22:56.904: INFO: namespace container-runtime-4463 deletion completed in 6.085536124s

• [SLOW TEST:8.266 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:22:56.904: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2305
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-73a842ce-f4ce-4638-8c35-54c8d37aa3f5
STEP: Creating a pod to test consume secrets
Sep 27 06:22:57.053: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8cbf6950-3223-4dcf-a6aa-1f120794a89a" in namespace "projected-2305" to be "success or failure"
Sep 27 06:22:57.058: INFO: Pod "pod-projected-secrets-8cbf6950-3223-4dcf-a6aa-1f120794a89a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.226113ms
Sep 27 06:22:59.061: INFO: Pod "pod-projected-secrets-8cbf6950-3223-4dcf-a6aa-1f120794a89a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007508093s
STEP: Saw pod success
Sep 27 06:22:59.061: INFO: Pod "pod-projected-secrets-8cbf6950-3223-4dcf-a6aa-1f120794a89a" satisfied condition "success or failure"
Sep 27 06:22:59.063: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-projected-secrets-8cbf6950-3223-4dcf-a6aa-1f120794a89a container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 27 06:22:59.079: INFO: Waiting for pod pod-projected-secrets-8cbf6950-3223-4dcf-a6aa-1f120794a89a to disappear
Sep 27 06:22:59.082: INFO: Pod pod-projected-secrets-8cbf6950-3223-4dcf-a6aa-1f120794a89a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:22:59.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2305" for this suite.
Sep 27 06:23:05.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:23:05.264: INFO: namespace projected-2305 deletion completed in 6.177753477s

• [SLOW TEST:8.360 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:23:05.264: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6670
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Sep 27 06:23:05.460: INFO: namespace kubectl-6670
Sep 27 06:23:05.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 create -f - --namespace=kubectl-6670'
Sep 27 06:23:05.770: INFO: stderr: ""
Sep 27 06:23:05.770: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep 27 06:23:06.773: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 06:23:06.773: INFO: Found 0 / 1
Sep 27 06:23:07.775: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 06:23:07.775: INFO: Found 1 / 1
Sep 27 06:23:07.775: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 27 06:23:07.777: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 06:23:07.777: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 27 06:23:07.777: INFO: wait on redis-master startup in kubectl-6670 
Sep 27 06:23:07.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 logs redis-master-dc5wk redis-master --namespace=kubectl-6670'
Sep 27 06:23:07.876: INFO: stderr: ""
Sep 27 06:23:07.876: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Sep 06:23:06.589 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Sep 06:23:06.589 # Server started, Redis version 3.2.12\n1:M 27 Sep 06:23:06.589 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Sep 06:23:06.589 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Sep 27 06:23:07.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-6670'
Sep 27 06:23:07.981: INFO: stderr: ""
Sep 27 06:23:07.981: INFO: stdout: "service/rm2 exposed\n"
Sep 27 06:23:07.987: INFO: Service rm2 in namespace kubectl-6670 found.
STEP: exposing service
Sep 27 06:23:09.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-6670'
Sep 27 06:23:10.094: INFO: stderr: ""
Sep 27 06:23:10.094: INFO: stdout: "service/rm3 exposed\n"
Sep 27 06:23:10.099: INFO: Service rm3 in namespace kubectl-6670 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:23:12.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6670" for this suite.
Sep 27 06:23:34.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:23:34.203: INFO: namespace kubectl-6670 deletion completed in 22.08972591s

• [SLOW TEST:28.938 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:23:34.203: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5891
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 06:23:34.351: INFO: Waiting up to 5m0s for pod "downwardapi-volume-91298dbe-e9ed-4207-bbd9-4fdff6df3537" in namespace "downward-api-5891" to be "success or failure"
Sep 27 06:23:34.356: INFO: Pod "downwardapi-volume-91298dbe-e9ed-4207-bbd9-4fdff6df3537": Phase="Pending", Reason="", readiness=false. Elapsed: 5.02106ms
Sep 27 06:23:36.359: INFO: Pod "downwardapi-volume-91298dbe-e9ed-4207-bbd9-4fdff6df3537": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008222336s
STEP: Saw pod success
Sep 27 06:23:36.359: INFO: Pod "downwardapi-volume-91298dbe-e9ed-4207-bbd9-4fdff6df3537" satisfied condition "success or failure"
Sep 27 06:23:36.362: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod downwardapi-volume-91298dbe-e9ed-4207-bbd9-4fdff6df3537 container client-container: <nil>
STEP: delete the pod
Sep 27 06:23:36.379: INFO: Waiting for pod downwardapi-volume-91298dbe-e9ed-4207-bbd9-4fdff6df3537 to disappear
Sep 27 06:23:36.381: INFO: Pod downwardapi-volume-91298dbe-e9ed-4207-bbd9-4fdff6df3537 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:23:36.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5891" for this suite.
Sep 27 06:23:42.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:23:42.484: INFO: namespace downward-api-5891 deletion completed in 6.098036458s

• [SLOW TEST:8.281 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:23:42.484: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7275
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Sep 27 06:23:42.627: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Sep 27 06:23:42.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 create -f - --namespace=kubectl-7275'
Sep 27 06:23:42.914: INFO: stderr: ""
Sep 27 06:23:42.914: INFO: stdout: "service/redis-slave created\n"
Sep 27 06:23:42.914: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Sep 27 06:23:42.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 create -f - --namespace=kubectl-7275'
Sep 27 06:23:43.200: INFO: stderr: ""
Sep 27 06:23:43.200: INFO: stdout: "service/redis-master created\n"
Sep 27 06:23:43.200: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Sep 27 06:23:43.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 create -f - --namespace=kubectl-7275'
Sep 27 06:23:43.485: INFO: stderr: ""
Sep 27 06:23:43.485: INFO: stdout: "service/frontend created\n"
Sep 27 06:23:43.486: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Sep 27 06:23:43.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 create -f - --namespace=kubectl-7275'
Sep 27 06:23:43.709: INFO: stderr: ""
Sep 27 06:23:43.709: INFO: stdout: "deployment.apps/frontend created\n"
Sep 27 06:23:43.709: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Sep 27 06:23:43.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 create -f - --namespace=kubectl-7275'
Sep 27 06:23:43.916: INFO: stderr: ""
Sep 27 06:23:43.916: INFO: stdout: "deployment.apps/redis-master created\n"
Sep 27 06:23:43.916: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Sep 27 06:23:43.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 create -f - --namespace=kubectl-7275'
Sep 27 06:23:44.209: INFO: stderr: ""
Sep 27 06:23:44.209: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Sep 27 06:23:44.209: INFO: Waiting for all frontend pods to be Running.
Sep 27 06:23:49.259: INFO: Waiting for frontend to serve content.
Sep 27 06:23:49.294: INFO: Trying to add a new entry to the guestbook.
Sep 27 06:23:49.308: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Sep 27 06:23:49.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 delete --grace-period=0 --force -f - --namespace=kubectl-7275'
Sep 27 06:23:49.441: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 27 06:23:49.441: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Sep 27 06:23:49.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 delete --grace-period=0 --force -f - --namespace=kubectl-7275'
Sep 27 06:23:49.557: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 27 06:23:49.557: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep 27 06:23:49.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 delete --grace-period=0 --force -f - --namespace=kubectl-7275'
Sep 27 06:23:49.705: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 27 06:23:49.705: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep 27 06:23:49.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 delete --grace-period=0 --force -f - --namespace=kubectl-7275'
Sep 27 06:23:49.794: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 27 06:23:49.794: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep 27 06:23:49.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 delete --grace-period=0 --force -f - --namespace=kubectl-7275'
Sep 27 06:23:49.878: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 27 06:23:49.878: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep 27 06:23:49.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 delete --grace-period=0 --force -f - --namespace=kubectl-7275'
Sep 27 06:23:49.960: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 27 06:23:49.960: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:23:49.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7275" for this suite.
Sep 27 06:24:31.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:24:32.084: INFO: namespace kubectl-7275 deletion completed in 42.119313204s

• [SLOW TEST:49.600 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:24:32.084: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9753
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 06:24:32.228: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7c9797f2-3183-4c72-afa0-a27a89a63b37" in namespace "downward-api-9753" to be "success or failure"
Sep 27 06:24:32.230: INFO: Pod "downwardapi-volume-7c9797f2-3183-4c72-afa0-a27a89a63b37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.106677ms
Sep 27 06:24:34.233: INFO: Pod "downwardapi-volume-7c9797f2-3183-4c72-afa0-a27a89a63b37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005173792s
STEP: Saw pod success
Sep 27 06:24:34.233: INFO: Pod "downwardapi-volume-7c9797f2-3183-4c72-afa0-a27a89a63b37" satisfied condition "success or failure"
Sep 27 06:24:34.235: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod downwardapi-volume-7c9797f2-3183-4c72-afa0-a27a89a63b37 container client-container: <nil>
STEP: delete the pod
Sep 27 06:24:34.252: INFO: Waiting for pod downwardapi-volume-7c9797f2-3183-4c72-afa0-a27a89a63b37 to disappear
Sep 27 06:24:34.254: INFO: Pod downwardapi-volume-7c9797f2-3183-4c72-afa0-a27a89a63b37 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:24:34.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9753" for this suite.
Sep 27 06:24:40.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:24:40.348: INFO: namespace downward-api-9753 deletion completed in 6.090070297s

• [SLOW TEST:8.264 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:24:40.349: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-2320
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Sep 27 06:24:40.495: INFO: Waiting up to 5m0s for pod "client-containers-cc0e6e4c-4c9c-47f8-b362-7887b82e22cd" in namespace "containers-2320" to be "success or failure"
Sep 27 06:24:40.498: INFO: Pod "client-containers-cc0e6e4c-4c9c-47f8-b362-7887b82e22cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.453947ms
Sep 27 06:24:42.500: INFO: Pod "client-containers-cc0e6e4c-4c9c-47f8-b362-7887b82e22cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005246797s
STEP: Saw pod success
Sep 27 06:24:42.500: INFO: Pod "client-containers-cc0e6e4c-4c9c-47f8-b362-7887b82e22cd" satisfied condition "success or failure"
Sep 27 06:24:42.502: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod client-containers-cc0e6e4c-4c9c-47f8-b362-7887b82e22cd container test-container: <nil>
STEP: delete the pod
Sep 27 06:24:42.518: INFO: Waiting for pod client-containers-cc0e6e4c-4c9c-47f8-b362-7887b82e22cd to disappear
Sep 27 06:24:42.521: INFO: Pod client-containers-cc0e6e4c-4c9c-47f8-b362-7887b82e22cd no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:24:42.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2320" for this suite.
Sep 27 06:24:48.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:24:48.613: INFO: namespace containers-2320 deletion completed in 6.08752823s

• [SLOW TEST:8.264 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:24:48.613: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-6167
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Sep 27 06:24:52.778: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6167 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 06:24:52.778: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
Sep 27 06:24:52.874: INFO: Exec stderr: ""
Sep 27 06:24:52.874: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6167 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 06:24:52.874: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
Sep 27 06:24:52.960: INFO: Exec stderr: ""
Sep 27 06:24:52.960: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6167 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 06:24:52.960: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
Sep 27 06:24:53.045: INFO: Exec stderr: ""
Sep 27 06:24:53.045: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6167 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 06:24:53.045: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
Sep 27 06:24:53.140: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Sep 27 06:24:53.140: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6167 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 06:24:53.140: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
Sep 27 06:24:53.232: INFO: Exec stderr: ""
Sep 27 06:24:53.232: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6167 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 06:24:53.232: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
Sep 27 06:24:53.342: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Sep 27 06:24:53.342: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6167 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 06:24:53.342: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
Sep 27 06:24:53.434: INFO: Exec stderr: ""
Sep 27 06:24:53.434: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6167 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 06:24:53.434: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
Sep 27 06:24:53.529: INFO: Exec stderr: ""
Sep 27 06:24:53.529: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6167 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 06:24:53.529: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
Sep 27 06:24:53.638: INFO: Exec stderr: ""
Sep 27 06:24:53.638: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6167 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 06:24:53.638: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
Sep 27 06:24:53.727: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:24:53.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-6167" for this suite.
Sep 27 06:25:43.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:25:43.846: INFO: namespace e2e-kubelet-etc-hosts-6167 deletion completed in 50.111411032s

• [SLOW TEST:55.233 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:25:43.846: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-0
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Sep 27 06:25:46.015: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-833349834 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Sep 27 06:25:56.104: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:25:56.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-0" for this suite.
Sep 27 06:26:02.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:26:02.220: INFO: namespace pods-0 deletion completed in 6.109056587s

• [SLOW TEST:18.374 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:26:02.221: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-909
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep 27 06:26:06.394: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 06:26:06.397: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 27 06:26:08.397: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 06:26:08.401: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 27 06:26:10.397: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 06:26:10.401: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 27 06:26:12.398: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 06:26:12.401: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 27 06:26:14.397: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 06:26:14.400: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 27 06:26:16.397: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 06:26:16.402: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 27 06:26:18.397: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 06:26:18.400: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 27 06:26:20.397: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 06:26:20.400: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 27 06:26:22.397: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 06:26:22.403: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 27 06:26:24.397: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 06:26:24.400: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 27 06:26:26.397: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 06:26:26.400: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 27 06:26:28.397: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 06:26:28.407: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 27 06:26:30.397: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 06:26:30.400: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 27 06:26:32.397: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 06:26:32.400: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:26:32.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-909" for this suite.
Sep 27 06:26:54.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:26:54.500: INFO: namespace container-lifecycle-hook-909 deletion completed in 22.088512965s

• [SLOW TEST:52.280 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:26:54.500: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6487
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-7eef88bc-b990-48db-90f6-793f7100fc60
STEP: Creating a pod to test consume configMaps
Sep 27 06:26:54.650: INFO: Waiting up to 5m0s for pod "pod-configmaps-6e440303-1891-43cd-a7d4-7f4d32419701" in namespace "configmap-6487" to be "success or failure"
Sep 27 06:26:54.654: INFO: Pod "pod-configmaps-6e440303-1891-43cd-a7d4-7f4d32419701": Phase="Pending", Reason="", readiness=false. Elapsed: 3.580526ms
Sep 27 06:26:56.657: INFO: Pod "pod-configmaps-6e440303-1891-43cd-a7d4-7f4d32419701": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007314284s
STEP: Saw pod success
Sep 27 06:26:56.657: INFO: Pod "pod-configmaps-6e440303-1891-43cd-a7d4-7f4d32419701" satisfied condition "success or failure"
Sep 27 06:26:56.660: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-configmaps-6e440303-1891-43cd-a7d4-7f4d32419701 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 06:26:56.681: INFO: Waiting for pod pod-configmaps-6e440303-1891-43cd-a7d4-7f4d32419701 to disappear
Sep 27 06:26:56.683: INFO: Pod pod-configmaps-6e440303-1891-43cd-a7d4-7f4d32419701 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:26:56.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6487" for this suite.
Sep 27 06:27:02.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:27:02.772: INFO: namespace configmap-6487 deletion completed in 6.083576315s

• [SLOW TEST:8.272 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:27:02.772: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8003
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep 27 06:27:02.919: INFO: Waiting up to 5m0s for pod "pod-5b856c3b-7cbc-41d7-9578-68de517a3b98" in namespace "emptydir-8003" to be "success or failure"
Sep 27 06:27:02.922: INFO: Pod "pod-5b856c3b-7cbc-41d7-9578-68de517a3b98": Phase="Pending", Reason="", readiness=false. Elapsed: 3.198483ms
Sep 27 06:27:04.932: INFO: Pod "pod-5b856c3b-7cbc-41d7-9578-68de517a3b98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013242926s
STEP: Saw pod success
Sep 27 06:27:04.932: INFO: Pod "pod-5b856c3b-7cbc-41d7-9578-68de517a3b98" satisfied condition "success or failure"
Sep 27 06:27:04.938: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-5b856c3b-7cbc-41d7-9578-68de517a3b98 container test-container: <nil>
STEP: delete the pod
Sep 27 06:27:04.969: INFO: Waiting for pod pod-5b856c3b-7cbc-41d7-9578-68de517a3b98 to disappear
Sep 27 06:27:04.980: INFO: Pod pod-5b856c3b-7cbc-41d7-9578-68de517a3b98 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:27:04.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8003" for this suite.
Sep 27 06:27:11.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:27:11.074: INFO: namespace emptydir-8003 deletion completed in 6.087886351s

• [SLOW TEST:8.302 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:27:11.074: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1842
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-1842
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Sep 27 06:27:11.236: INFO: Found 0 stateful pods, waiting for 3
Sep 27 06:27:21.241: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 27 06:27:21.241: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 27 06:27:21.241: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep 27 06:27:21.267: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Sep 27 06:27:31.300: INFO: Updating stateful set ss2
Sep 27 06:27:31.309: INFO: Waiting for Pod statefulset-1842/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Sep 27 06:27:41.351: INFO: Found 1 stateful pods, waiting for 3
Sep 27 06:27:51.355: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 27 06:27:51.355: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 27 06:27:51.355: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Sep 27 06:27:51.379: INFO: Updating stateful set ss2
Sep 27 06:27:51.388: INFO: Waiting for Pod statefulset-1842/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep 27 06:28:01.421: INFO: Updating stateful set ss2
Sep 27 06:28:01.431: INFO: Waiting for StatefulSet statefulset-1842/ss2 to complete update
Sep 27 06:28:01.431: INFO: Waiting for Pod statefulset-1842/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep 27 06:28:11.438: INFO: Deleting all statefulset in ns statefulset-1842
Sep 27 06:28:11.441: INFO: Scaling statefulset ss2 to 0
Sep 27 06:28:31.457: INFO: Waiting for statefulset status.replicas updated to 0
Sep 27 06:28:31.460: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:28:31.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1842" for this suite.
Sep 27 06:28:37.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:28:37.575: INFO: namespace statefulset-1842 deletion completed in 6.098190985s

• [SLOW TEST:86.500 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:28:37.575: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3112
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:28:37.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3112" for this suite.
Sep 27 06:28:59.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:28:59.905: INFO: namespace pods-3112 deletion completed in 22.101727239s

• [SLOW TEST:22.330 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:28:59.905: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6484
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 06:29:00.064: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:29:02.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6484" for this suite.
Sep 27 06:29:40.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:29:40.273: INFO: namespace pods-6484 deletion completed in 38.089404904s

• [SLOW TEST:40.368 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:29:40.273: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2046
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-068a8f4a-31ee-4b62-90bb-d047c65b0e80
STEP: Creating a pod to test consume configMaps
Sep 27 06:29:40.421: INFO: Waiting up to 5m0s for pod "pod-configmaps-04cfebbc-647f-4b5e-a2d1-542862e7fc4e" in namespace "configmap-2046" to be "success or failure"
Sep 27 06:29:40.426: INFO: Pod "pod-configmaps-04cfebbc-647f-4b5e-a2d1-542862e7fc4e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.851166ms
Sep 27 06:29:42.429: INFO: Pod "pod-configmaps-04cfebbc-647f-4b5e-a2d1-542862e7fc4e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0079271s
STEP: Saw pod success
Sep 27 06:29:42.429: INFO: Pod "pod-configmaps-04cfebbc-647f-4b5e-a2d1-542862e7fc4e" satisfied condition "success or failure"
Sep 27 06:29:42.431: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-configmaps-04cfebbc-647f-4b5e-a2d1-542862e7fc4e container configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 06:29:42.448: INFO: Waiting for pod pod-configmaps-04cfebbc-647f-4b5e-a2d1-542862e7fc4e to disappear
Sep 27 06:29:42.450: INFO: Pod pod-configmaps-04cfebbc-647f-4b5e-a2d1-542862e7fc4e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:29:42.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2046" for this suite.
Sep 27 06:29:48.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:29:48.547: INFO: namespace configmap-2046 deletion completed in 6.092491313s

• [SLOW TEST:8.275 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:29:48.548: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7493
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 06:29:48.703: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8f3d80da-d740-4ba5-a58b-d9dbfbb308a6" in namespace "downward-api-7493" to be "success or failure"
Sep 27 06:29:48.706: INFO: Pod "downwardapi-volume-8f3d80da-d740-4ba5-a58b-d9dbfbb308a6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.485618ms
Sep 27 06:29:50.709: INFO: Pod "downwardapi-volume-8f3d80da-d740-4ba5-a58b-d9dbfbb308a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006442391s
STEP: Saw pod success
Sep 27 06:29:50.709: INFO: Pod "downwardapi-volume-8f3d80da-d740-4ba5-a58b-d9dbfbb308a6" satisfied condition "success or failure"
Sep 27 06:29:50.711: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod downwardapi-volume-8f3d80da-d740-4ba5-a58b-d9dbfbb308a6 container client-container: <nil>
STEP: delete the pod
Sep 27 06:29:50.728: INFO: Waiting for pod downwardapi-volume-8f3d80da-d740-4ba5-a58b-d9dbfbb308a6 to disappear
Sep 27 06:29:50.730: INFO: Pod downwardapi-volume-8f3d80da-d740-4ba5-a58b-d9dbfbb308a6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:29:50.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7493" for this suite.
Sep 27 06:29:56.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:29:56.832: INFO: namespace downward-api-7493 deletion completed in 6.0968087s

• [SLOW TEST:8.283 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:29:56.832: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8256
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 06:29:56.974: INFO: Waiting up to 5m0s for pod "downwardapi-volume-42d7e51a-9a5b-4756-ac3e-f87c0f13dcaf" in namespace "projected-8256" to be "success or failure"
Sep 27 06:29:56.978: INFO: Pod "downwardapi-volume-42d7e51a-9a5b-4756-ac3e-f87c0f13dcaf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.330046ms
Sep 27 06:29:58.982: INFO: Pod "downwardapi-volume-42d7e51a-9a5b-4756-ac3e-f87c0f13dcaf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007447409s
STEP: Saw pod success
Sep 27 06:29:58.982: INFO: Pod "downwardapi-volume-42d7e51a-9a5b-4756-ac3e-f87c0f13dcaf" satisfied condition "success or failure"
Sep 27 06:29:58.984: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod downwardapi-volume-42d7e51a-9a5b-4756-ac3e-f87c0f13dcaf container client-container: <nil>
STEP: delete the pod
Sep 27 06:29:59.005: INFO: Waiting for pod downwardapi-volume-42d7e51a-9a5b-4756-ac3e-f87c0f13dcaf to disappear
Sep 27 06:29:59.007: INFO: Pod downwardapi-volume-42d7e51a-9a5b-4756-ac3e-f87c0f13dcaf no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:29:59.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8256" for this suite.
Sep 27 06:30:05.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:30:05.105: INFO: namespace projected-8256 deletion completed in 6.093151704s

• [SLOW TEST:8.273 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:30:05.105: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1104
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 06:30:05.255: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c89a6c5f-62cf-46ab-81ef-65a0d8adfdf0" in namespace "projected-1104" to be "success or failure"
Sep 27 06:30:05.258: INFO: Pod "downwardapi-volume-c89a6c5f-62cf-46ab-81ef-65a0d8adfdf0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.991307ms
Sep 27 06:30:07.262: INFO: Pod "downwardapi-volume-c89a6c5f-62cf-46ab-81ef-65a0d8adfdf0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006423236s
STEP: Saw pod success
Sep 27 06:30:07.262: INFO: Pod "downwardapi-volume-c89a6c5f-62cf-46ab-81ef-65a0d8adfdf0" satisfied condition "success or failure"
Sep 27 06:30:07.265: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod downwardapi-volume-c89a6c5f-62cf-46ab-81ef-65a0d8adfdf0 container client-container: <nil>
STEP: delete the pod
Sep 27 06:30:07.283: INFO: Waiting for pod downwardapi-volume-c89a6c5f-62cf-46ab-81ef-65a0d8adfdf0 to disappear
Sep 27 06:30:07.285: INFO: Pod downwardapi-volume-c89a6c5f-62cf-46ab-81ef-65a0d8adfdf0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:30:07.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1104" for this suite.
Sep 27 06:30:13.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:30:13.373: INFO: namespace projected-1104 deletion completed in 6.083694454s

• [SLOW TEST:8.268 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:30:13.374: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8116
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Sep 27 06:30:13.518: INFO: Waiting up to 5m0s for pod "client-containers-a2a90a05-6d6f-4730-9e5c-b149e96aa56c" in namespace "containers-8116" to be "success or failure"
Sep 27 06:30:13.522: INFO: Pod "client-containers-a2a90a05-6d6f-4730-9e5c-b149e96aa56c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.635462ms
Sep 27 06:30:15.525: INFO: Pod "client-containers-a2a90a05-6d6f-4730-9e5c-b149e96aa56c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006657388s
STEP: Saw pod success
Sep 27 06:30:15.525: INFO: Pod "client-containers-a2a90a05-6d6f-4730-9e5c-b149e96aa56c" satisfied condition "success or failure"
Sep 27 06:30:15.527: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod client-containers-a2a90a05-6d6f-4730-9e5c-b149e96aa56c container test-container: <nil>
STEP: delete the pod
Sep 27 06:30:15.545: INFO: Waiting for pod client-containers-a2a90a05-6d6f-4730-9e5c-b149e96aa56c to disappear
Sep 27 06:30:15.547: INFO: Pod client-containers-a2a90a05-6d6f-4730-9e5c-b149e96aa56c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:30:15.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8116" for this suite.
Sep 27 06:30:21.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:30:21.648: INFO: namespace containers-8116 deletion completed in 6.095516554s

• [SLOW TEST:8.274 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:30:21.649: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9084
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-9084
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-9084
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9084
Sep 27 06:30:21.812: INFO: Found 0 stateful pods, waiting for 1
Sep 27 06:30:31.815: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Sep 27 06:30:31.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 exec --namespace=statefulset-9084 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 27 06:30:32.164: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 27 06:30:32.164: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 27 06:30:32.164: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 27 06:30:32.168: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep 27 06:30:42.171: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 27 06:30:42.171: INFO: Waiting for statefulset status.replicas updated to 0
Sep 27 06:30:42.184: INFO: POD   NODE                            PHASE    GRACE  CONDITIONS
Sep 27 06:30:42.184: INFO: ss-0  worker3.dev-bj.kubeoperator.io  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:21 +0000 UTC  }]
Sep 27 06:30:42.184: INFO: 
Sep 27 06:30:42.184: INFO: StatefulSet ss has not reached scale 3, at 1
Sep 27 06:30:43.187: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996896762s
Sep 27 06:30:44.190: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993542373s
Sep 27 06:30:45.194: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.990223544s
Sep 27 06:30:46.197: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.986977857s
Sep 27 06:30:47.202: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.983120149s
Sep 27 06:30:48.205: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.978939704s
Sep 27 06:30:49.208: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.975688427s
Sep 27 06:30:50.211: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.97243328s
Sep 27 06:30:51.215: INFO: Verifying statefulset ss doesn't scale past 3 for another 969.074709ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9084
Sep 27 06:30:52.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 exec --namespace=statefulset-9084 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 27 06:30:52.400: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 27 06:30:52.400: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 27 06:30:52.400: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 27 06:30:52.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 exec --namespace=statefulset-9084 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 27 06:30:52.591: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep 27 06:30:52.591: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 27 06:30:52.591: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 27 06:30:52.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 exec --namespace=statefulset-9084 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 27 06:30:52.873: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep 27 06:30:52.873: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 27 06:30:52.873: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 27 06:30:52.876: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Sep 27 06:31:02.880: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 27 06:31:02.880: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 27 06:31:02.880: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Sep 27 06:31:02.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 exec --namespace=statefulset-9084 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 27 06:31:03.058: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 27 06:31:03.058: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 27 06:31:03.058: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 27 06:31:03.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 exec --namespace=statefulset-9084 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 27 06:31:03.251: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 27 06:31:03.251: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 27 06:31:03.251: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 27 06:31:03.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 exec --namespace=statefulset-9084 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 27 06:31:03.448: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 27 06:31:03.448: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 27 06:31:03.448: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 27 06:31:03.448: INFO: Waiting for statefulset status.replicas updated to 0
Sep 27 06:31:03.451: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Sep 27 06:31:13.458: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 27 06:31:13.458: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep 27 06:31:13.458: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep 27 06:31:13.468: INFO: POD   NODE                            PHASE    GRACE  CONDITIONS
Sep 27 06:31:13.468: INFO: ss-0  worker3.dev-bj.kubeoperator.io  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:21 +0000 UTC  }]
Sep 27 06:31:13.468: INFO: ss-1  worker1.dev-bj.kubeoperator.io  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  }]
Sep 27 06:31:13.468: INFO: ss-2  worker2.dev-bj.kubeoperator.io  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  }]
Sep 27 06:31:13.468: INFO: 
Sep 27 06:31:13.468: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 27 06:31:14.472: INFO: POD   NODE                            PHASE    GRACE  CONDITIONS
Sep 27 06:31:14.472: INFO: ss-0  worker3.dev-bj.kubeoperator.io  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:21 +0000 UTC  }]
Sep 27 06:31:14.472: INFO: ss-1  worker1.dev-bj.kubeoperator.io  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  }]
Sep 27 06:31:14.472: INFO: ss-2  worker2.dev-bj.kubeoperator.io  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  }]
Sep 27 06:31:14.472: INFO: 
Sep 27 06:31:14.472: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 27 06:31:15.476: INFO: POD   NODE                            PHASE    GRACE  CONDITIONS
Sep 27 06:31:15.476: INFO: ss-0  worker3.dev-bj.kubeoperator.io  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:21 +0000 UTC  }]
Sep 27 06:31:15.476: INFO: ss-1  worker1.dev-bj.kubeoperator.io  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  }]
Sep 27 06:31:15.476: INFO: ss-2  worker2.dev-bj.kubeoperator.io  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  }]
Sep 27 06:31:15.476: INFO: 
Sep 27 06:31:15.476: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 27 06:31:16.479: INFO: POD   NODE                            PHASE    GRACE  CONDITIONS
Sep 27 06:31:16.479: INFO: ss-0  worker3.dev-bj.kubeoperator.io  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:21 +0000 UTC  }]
Sep 27 06:31:16.479: INFO: ss-1  worker1.dev-bj.kubeoperator.io  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  }]
Sep 27 06:31:16.479: INFO: ss-2  worker2.dev-bj.kubeoperator.io  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  }]
Sep 27 06:31:16.479: INFO: 
Sep 27 06:31:16.479: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 27 06:31:17.483: INFO: POD   NODE                            PHASE    GRACE  CONDITIONS
Sep 27 06:31:17.483: INFO: ss-0  worker3.dev-bj.kubeoperator.io  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:21 +0000 UTC  }]
Sep 27 06:31:17.483: INFO: ss-1  worker1.dev-bj.kubeoperator.io  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  }]
Sep 27 06:31:17.483: INFO: ss-2  worker2.dev-bj.kubeoperator.io  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  }]
Sep 27 06:31:17.483: INFO: 
Sep 27 06:31:17.483: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 27 06:31:18.486: INFO: POD   NODE                            PHASE    GRACE  CONDITIONS
Sep 27 06:31:18.487: INFO: ss-0  worker3.dev-bj.kubeoperator.io  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:21 +0000 UTC  }]
Sep 27 06:31:18.487: INFO: ss-1  worker1.dev-bj.kubeoperator.io  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  }]
Sep 27 06:31:18.487: INFO: ss-2  worker2.dev-bj.kubeoperator.io  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  }]
Sep 27 06:31:18.487: INFO: 
Sep 27 06:31:18.487: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 27 06:31:19.491: INFO: POD   NODE                            PHASE    GRACE  CONDITIONS
Sep 27 06:31:19.491: INFO: ss-0  worker3.dev-bj.kubeoperator.io  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:21 +0000 UTC  }]
Sep 27 06:31:19.491: INFO: ss-1  worker1.dev-bj.kubeoperator.io  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  }]
Sep 27 06:31:19.491: INFO: ss-2  worker2.dev-bj.kubeoperator.io  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  }]
Sep 27 06:31:19.491: INFO: 
Sep 27 06:31:19.491: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 27 06:31:20.494: INFO: POD   NODE                            PHASE    GRACE  CONDITIONS
Sep 27 06:31:20.494: INFO: ss-0  worker3.dev-bj.kubeoperator.io  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:21 +0000 UTC  }]
Sep 27 06:31:20.494: INFO: ss-2  worker2.dev-bj.kubeoperator.io  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  }]
Sep 27 06:31:20.494: INFO: 
Sep 27 06:31:20.494: INFO: StatefulSet ss has not reached scale 0, at 2
Sep 27 06:31:21.497: INFO: POD   NODE                            PHASE    GRACE  CONDITIONS
Sep 27 06:31:21.497: INFO: ss-2  worker2.dev-bj.kubeoperator.io  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  }]
Sep 27 06:31:21.498: INFO: 
Sep 27 06:31:21.498: INFO: StatefulSet ss has not reached scale 0, at 1
Sep 27 06:31:22.501: INFO: POD   NODE                            PHASE    GRACE  CONDITIONS
Sep 27 06:31:22.501: INFO: ss-2  worker2.dev-bj.kubeoperator.io  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:31:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:30:42 +0000 UTC  }]
Sep 27 06:31:22.501: INFO: 
Sep 27 06:31:22.501: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9084
Sep 27 06:31:23.504: INFO: Scaling statefulset ss to 0
Sep 27 06:31:23.511: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep 27 06:31:23.514: INFO: Deleting all statefulset in ns statefulset-9084
Sep 27 06:31:23.516: INFO: Scaling statefulset ss to 0
Sep 27 06:31:23.524: INFO: Waiting for statefulset status.replicas updated to 0
Sep 27 06:31:23.526: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:31:23.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9084" for this suite.
Sep 27 06:31:29.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:31:29.641: INFO: namespace statefulset-9084 deletion completed in 6.095341401s

• [SLOW TEST:67.993 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:31:29.641: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-4947
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-4947
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 27 06:31:29.795: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 27 06:31:49.876: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.20.3.40:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4947 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 06:31:49.876: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
Sep 27 06:31:49.979: INFO: Found all expected endpoints: [netserver-0]
Sep 27 06:31:49.982: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.20.5.146:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4947 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 06:31:49.982: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
Sep 27 06:31:50.077: INFO: Found all expected endpoints: [netserver-1]
Sep 27 06:31:50.079: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.20.4.27:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4947 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 06:31:50.079: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
Sep 27 06:31:50.173: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:31:50.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4947" for this suite.
Sep 27 06:32:12.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:32:12.269: INFO: namespace pod-network-test-4947 deletion completed in 22.090960691s

• [SLOW TEST:42.628 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:32:12.269: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3591
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep 27 06:32:14.939: INFO: Successfully updated pod "pod-update-activedeadlineseconds-b84c6bd9-42fa-4ee5-8938-612484d1d018"
Sep 27 06:32:14.939: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-b84c6bd9-42fa-4ee5-8938-612484d1d018" in namespace "pods-3591" to be "terminated due to deadline exceeded"
Sep 27 06:32:14.941: INFO: Pod "pod-update-activedeadlineseconds-b84c6bd9-42fa-4ee5-8938-612484d1d018": Phase="Running", Reason="", readiness=true. Elapsed: 1.986234ms
Sep 27 06:32:16.946: INFO: Pod "pod-update-activedeadlineseconds-b84c6bd9-42fa-4ee5-8938-612484d1d018": Phase="Running", Reason="", readiness=true. Elapsed: 2.006345243s
Sep 27 06:32:18.949: INFO: Pod "pod-update-activedeadlineseconds-b84c6bd9-42fa-4ee5-8938-612484d1d018": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.009707006s
Sep 27 06:32:18.949: INFO: Pod "pod-update-activedeadlineseconds-b84c6bd9-42fa-4ee5-8938-612484d1d018" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:32:18.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3591" for this suite.
Sep 27 06:32:24.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:32:25.037: INFO: namespace pods-3591 deletion completed in 6.083658879s

• [SLOW TEST:12.768 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:32:25.037: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-139
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-prc8r in namespace proxy-139
I0927 06:32:25.194676      16 runners.go:180] Created replication controller with name: proxy-service-prc8r, namespace: proxy-139, replica count: 1
I0927 06:32:26.245040      16 runners.go:180] proxy-service-prc8r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0927 06:32:27.245212      16 runners.go:180] proxy-service-prc8r Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0927 06:32:28.245384      16 runners.go:180] proxy-service-prc8r Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 27 06:32:28.248: INFO: setup took 3.075129192s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Sep 27 06:32:28.261: INFO: (0) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:160/proxy/: foo (200; 12.765517ms)
Sep 27 06:32:28.262: INFO: (0) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:162/proxy/: bar (200; 13.170556ms)
Sep 27 06:32:28.262: INFO: (0) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname2/proxy/: bar (200; 13.932473ms)
Sep 27 06:32:28.262: INFO: (0) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:160/proxy/: foo (200; 13.806826ms)
Sep 27 06:32:28.263: INFO: (0) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/rewriteme">test</... (200; 14.154686ms)
Sep 27 06:32:28.263: INFO: (0) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:162/proxy/: bar (200; 14.450752ms)
Sep 27 06:32:28.263: INFO: (0) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/rewriteme">test</a> (200; 14.428522ms)
Sep 27 06:32:28.263: INFO: (0) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/rewriteme">t... (200; 14.189779ms)
Sep 27 06:32:28.268: INFO: (0) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname1/proxy/: foo (200; 18.838694ms)
Sep 27 06:32:28.268: INFO: (0) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname2/proxy/: bar (200; 19.320229ms)
Sep 27 06:32:28.268: INFO: (0) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:460/proxy/: tls baz (200; 19.755252ms)
Sep 27 06:32:28.268: INFO: (0) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname1/proxy/: tls baz (200; 19.47526ms)
Sep 27 06:32:28.269: INFO: (0) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname1/proxy/: foo (200; 20.211789ms)
Sep 27 06:32:28.270: INFO: (0) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/tlsrewriteme... (200; 21.353388ms)
Sep 27 06:32:28.270: INFO: (0) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:462/proxy/: tls qux (200; 21.719387ms)
Sep 27 06:32:28.273: INFO: (0) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname2/proxy/: tls qux (200; 24.696596ms)
Sep 27 06:32:28.277: INFO: (1) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:160/proxy/: foo (200; 3.994561ms)
Sep 27 06:32:28.278: INFO: (1) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:162/proxy/: bar (200; 4.395655ms)
Sep 27 06:32:28.279: INFO: (1) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/rewriteme">test</... (200; 4.872445ms)
Sep 27 06:32:28.279: INFO: (1) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:460/proxy/: tls baz (200; 5.230863ms)
Sep 27 06:32:28.279: INFO: (1) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/rewriteme">t... (200; 5.374143ms)
Sep 27 06:32:28.281: INFO: (1) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:160/proxy/: foo (200; 6.580021ms)
Sep 27 06:32:28.282: INFO: (1) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:462/proxy/: tls qux (200; 7.391005ms)
Sep 27 06:32:28.283: INFO: (1) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname1/proxy/: foo (200; 9.185514ms)
Sep 27 06:32:28.283: INFO: (1) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/tlsrewriteme... (200; 8.319587ms)
Sep 27 06:32:28.286: INFO: (1) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:162/proxy/: bar (200; 11.393229ms)
Sep 27 06:32:28.287: INFO: (1) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname2/proxy/: bar (200; 12.900024ms)
Sep 27 06:32:28.287: INFO: (1) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/rewriteme">test</a> (200; 12.47299ms)
Sep 27 06:32:28.287: INFO: (1) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname1/proxy/: foo (200; 13.386152ms)
Sep 27 06:32:28.289: INFO: (1) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname1/proxy/: tls baz (200; 14.188284ms)
Sep 27 06:32:28.289: INFO: (1) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname2/proxy/: tls qux (200; 14.721563ms)
Sep 27 06:32:28.289: INFO: (1) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname2/proxy/: bar (200; 15.004329ms)
Sep 27 06:32:28.295: INFO: (2) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:162/proxy/: bar (200; 6.014712ms)
Sep 27 06:32:28.299: INFO: (2) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/rewriteme">test</... (200; 8.916475ms)
Sep 27 06:32:28.300: INFO: (2) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:160/proxy/: foo (200; 9.522669ms)
Sep 27 06:32:28.300: INFO: (2) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:162/proxy/: bar (200; 10.276641ms)
Sep 27 06:32:28.300: INFO: (2) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname1/proxy/: foo (200; 11.01131ms)
Sep 27 06:32:28.301: INFO: (2) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/rewriteme">test</a> (200; 9.984792ms)
Sep 27 06:32:28.301: INFO: (2) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/rewriteme">t... (200; 10.907066ms)
Sep 27 06:32:28.301: INFO: (2) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname2/proxy/: bar (200; 11.388003ms)
Sep 27 06:32:28.301: INFO: (2) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:460/proxy/: tls baz (200; 10.995543ms)
Sep 27 06:32:28.301: INFO: (2) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:462/proxy/: tls qux (200; 11.194613ms)
Sep 27 06:32:28.302: INFO: (2) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname1/proxy/: foo (200; 11.966825ms)
Sep 27 06:32:28.302: INFO: (2) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:160/proxy/: foo (200; 10.709215ms)
Sep 27 06:32:28.302: INFO: (2) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/tlsrewriteme... (200; 11.26281ms)
Sep 27 06:32:28.304: INFO: (2) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname2/proxy/: bar (200; 13.260173ms)
Sep 27 06:32:28.305: INFO: (2) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname1/proxy/: tls baz (200; 14.857972ms)
Sep 27 06:32:28.306: INFO: (2) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname2/proxy/: tls qux (200; 14.871088ms)
Sep 27 06:32:28.311: INFO: (3) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:460/proxy/: tls baz (200; 5.516043ms)
Sep 27 06:32:28.312: INFO: (3) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/rewriteme">t... (200; 6.265374ms)
Sep 27 06:32:28.312: INFO: (3) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:462/proxy/: tls qux (200; 6.014573ms)
Sep 27 06:32:28.312: INFO: (3) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/rewriteme">test</a> (200; 5.885972ms)
Sep 27 06:32:28.314: INFO: (3) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:162/proxy/: bar (200; 7.814716ms)
Sep 27 06:32:28.314: INFO: (3) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:160/proxy/: foo (200; 8.233868ms)
Sep 27 06:32:28.314: INFO: (3) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname1/proxy/: foo (200; 8.893307ms)
Sep 27 06:32:28.314: INFO: (3) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:162/proxy/: bar (200; 8.078544ms)
Sep 27 06:32:28.315: INFO: (3) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname2/proxy/: tls qux (200; 8.797855ms)
Sep 27 06:32:28.315: INFO: (3) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:160/proxy/: foo (200; 8.551154ms)
Sep 27 06:32:28.318: INFO: (3) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/rewriteme">test</... (200; 11.002559ms)
Sep 27 06:32:28.318: INFO: (3) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/tlsrewriteme... (200; 11.562614ms)
Sep 27 06:32:28.320: INFO: (3) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname2/proxy/: bar (200; 13.463326ms)
Sep 27 06:32:28.321: INFO: (3) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname2/proxy/: bar (200; 14.352961ms)
Sep 27 06:32:28.321: INFO: (3) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname1/proxy/: foo (200; 14.221516ms)
Sep 27 06:32:28.321: INFO: (3) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname1/proxy/: tls baz (200; 14.562626ms)
Sep 27 06:32:28.330: INFO: (4) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:160/proxy/: foo (200; 8.58101ms)
Sep 27 06:32:28.330: INFO: (4) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/rewriteme">test</... (200; 8.152325ms)
Sep 27 06:32:28.331: INFO: (4) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/tlsrewriteme... (200; 8.272941ms)
Sep 27 06:32:28.331: INFO: (4) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:162/proxy/: bar (200; 8.508547ms)
Sep 27 06:32:28.331: INFO: (4) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:160/proxy/: foo (200; 8.059755ms)
Sep 27 06:32:28.331: INFO: (4) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/rewriteme">t... (200; 8.956261ms)
Sep 27 06:32:28.331: INFO: (4) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:460/proxy/: tls baz (200; 8.865475ms)
Sep 27 06:32:28.331: INFO: (4) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:462/proxy/: tls qux (200; 8.701198ms)
Sep 27 06:32:28.331: INFO: (4) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname1/proxy/: foo (200; 9.43049ms)
Sep 27 06:32:28.331: INFO: (4) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/rewriteme">test</a> (200; 8.289056ms)
Sep 27 06:32:28.331: INFO: (4) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:162/proxy/: bar (200; 8.898791ms)
Sep 27 06:32:28.333: INFO: (4) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname2/proxy/: bar (200; 11.487407ms)
Sep 27 06:32:28.334: INFO: (4) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname1/proxy/: tls baz (200; 11.714943ms)
Sep 27 06:32:28.334: INFO: (4) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname1/proxy/: foo (200; 12.660127ms)
Sep 27 06:32:28.334: INFO: (4) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname2/proxy/: tls qux (200; 11.830222ms)
Sep 27 06:32:28.335: INFO: (4) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname2/proxy/: bar (200; 12.189171ms)
Sep 27 06:32:28.342: INFO: (5) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/rewriteme">test</... (200; 7.318875ms)
Sep 27 06:32:28.343: INFO: (5) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:462/proxy/: tls qux (200; 8.365501ms)
Sep 27 06:32:28.344: INFO: (5) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/rewriteme">test</a> (200; 8.367491ms)
Sep 27 06:32:28.344: INFO: (5) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:160/proxy/: foo (200; 8.969951ms)
Sep 27 06:32:28.344: INFO: (5) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/rewriteme">t... (200; 9.332771ms)
Sep 27 06:32:28.345: INFO: (5) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/tlsrewriteme... (200; 9.192934ms)
Sep 27 06:32:28.345: INFO: (5) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:460/proxy/: tls baz (200; 10.469988ms)
Sep 27 06:32:28.345: INFO: (5) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:160/proxy/: foo (200; 10.152785ms)
Sep 27 06:32:28.345: INFO: (5) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:162/proxy/: bar (200; 10.438879ms)
Sep 27 06:32:28.347: INFO: (5) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname2/proxy/: bar (200; 11.995635ms)
Sep 27 06:32:28.347: INFO: (5) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:162/proxy/: bar (200; 12.171513ms)
Sep 27 06:32:28.348: INFO: (5) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname1/proxy/: tls baz (200; 12.82395ms)
Sep 27 06:32:28.348: INFO: (5) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname2/proxy/: tls qux (200; 12.862075ms)
Sep 27 06:32:28.349: INFO: (5) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname1/proxy/: foo (200; 12.8657ms)
Sep 27 06:32:28.349: INFO: (5) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname1/proxy/: foo (200; 13.133978ms)
Sep 27 06:32:28.349: INFO: (5) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname2/proxy/: bar (200; 13.0966ms)
Sep 27 06:32:28.356: INFO: (6) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:162/proxy/: bar (200; 5.871888ms)
Sep 27 06:32:28.356: INFO: (6) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:160/proxy/: foo (200; 5.575777ms)
Sep 27 06:32:28.356: INFO: (6) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/rewriteme">test</a> (200; 6.030093ms)
Sep 27 06:32:28.356: INFO: (6) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:160/proxy/: foo (200; 6.171781ms)
Sep 27 06:32:28.358: INFO: (6) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname1/proxy/: foo (200; 9.104112ms)
Sep 27 06:32:28.358: INFO: (6) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/rewriteme">test</... (200; 7.563414ms)
Sep 27 06:32:28.358: INFO: (6) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:162/proxy/: bar (200; 7.994292ms)
Sep 27 06:32:28.358: INFO: (6) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/rewriteme">t... (200; 8.942578ms)
Sep 27 06:32:28.358: INFO: (6) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/tlsrewriteme... (200; 7.951896ms)
Sep 27 06:32:28.358: INFO: (6) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:462/proxy/: tls qux (200; 8.679962ms)
Sep 27 06:32:28.358: INFO: (6) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:460/proxy/: tls baz (200; 9.075231ms)
Sep 27 06:32:28.361: INFO: (6) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname2/proxy/: bar (200; 10.90262ms)
Sep 27 06:32:28.362: INFO: (6) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname1/proxy/: tls baz (200; 12.167196ms)
Sep 27 06:32:28.362: INFO: (6) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname2/proxy/: tls qux (200; 12.119554ms)
Sep 27 06:32:28.362: INFO: (6) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname2/proxy/: bar (200; 11.605231ms)
Sep 27 06:32:28.362: INFO: (6) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname1/proxy/: foo (200; 11.799424ms)
Sep 27 06:32:28.368: INFO: (7) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:162/proxy/: bar (200; 5.683671ms)
Sep 27 06:32:28.369: INFO: (7) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:162/proxy/: bar (200; 6.61702ms)
Sep 27 06:32:28.369: INFO: (7) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/tlsrewriteme... (200; 6.483559ms)
Sep 27 06:32:28.369: INFO: (7) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:460/proxy/: tls baz (200; 6.766113ms)
Sep 27 06:32:28.369: INFO: (7) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:462/proxy/: tls qux (200; 7.048401ms)
Sep 27 06:32:28.370: INFO: (7) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:160/proxy/: foo (200; 7.102677ms)
Sep 27 06:32:28.370: INFO: (7) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname1/proxy/: tls baz (200; 8.161978ms)
Sep 27 06:32:28.371: INFO: (7) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/rewriteme">t... (200; 8.239941ms)
Sep 27 06:32:28.371: INFO: (7) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:160/proxy/: foo (200; 8.29947ms)
Sep 27 06:32:28.371: INFO: (7) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/rewriteme">test</... (200; 8.518209ms)
Sep 27 06:32:28.371: INFO: (7) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/rewriteme">test</a> (200; 8.447102ms)
Sep 27 06:32:28.374: INFO: (7) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname2/proxy/: tls qux (200; 11.053068ms)
Sep 27 06:32:28.376: INFO: (7) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname1/proxy/: foo (200; 12.673089ms)
Sep 27 06:32:28.376: INFO: (7) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname2/proxy/: bar (200; 12.81494ms)
Sep 27 06:32:28.376: INFO: (7) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname1/proxy/: foo (200; 12.896371ms)
Sep 27 06:32:28.376: INFO: (7) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname2/proxy/: bar (200; 13.018731ms)
Sep 27 06:32:28.383: INFO: (8) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/rewriteme">t... (200; 7.00105ms)
Sep 27 06:32:28.383: INFO: (8) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/rewriteme">test</... (200; 7.553394ms)
Sep 27 06:32:28.384: INFO: (8) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:162/proxy/: bar (200; 7.595762ms)
Sep 27 06:32:28.385: INFO: (8) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:162/proxy/: bar (200; 8.38336ms)
Sep 27 06:32:28.385: INFO: (8) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/tlsrewriteme... (200; 7.899702ms)
Sep 27 06:32:28.385: INFO: (8) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:462/proxy/: tls qux (200; 8.397971ms)
Sep 27 06:32:28.385: INFO: (8) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname2/proxy/: tls qux (200; 9.29427ms)
Sep 27 06:32:28.385: INFO: (8) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:160/proxy/: foo (200; 8.432875ms)
Sep 27 06:32:28.385: INFO: (8) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/rewriteme">test</a> (200; 8.541606ms)
Sep 27 06:32:28.385: INFO: (8) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:460/proxy/: tls baz (200; 8.856797ms)
Sep 27 06:32:28.385: INFO: (8) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:160/proxy/: foo (200; 8.400768ms)
Sep 27 06:32:28.388: INFO: (8) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname2/proxy/: bar (200; 12.452428ms)
Sep 27 06:32:28.389: INFO: (8) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname1/proxy/: foo (200; 12.701199ms)
Sep 27 06:32:28.389: INFO: (8) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname1/proxy/: foo (200; 12.733801ms)
Sep 27 06:32:28.389: INFO: (8) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname2/proxy/: bar (200; 11.699998ms)
Sep 27 06:32:28.389: INFO: (8) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname1/proxy/: tls baz (200; 11.626385ms)
Sep 27 06:32:28.395: INFO: (9) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/rewriteme">test</... (200; 6.480144ms)
Sep 27 06:32:28.398: INFO: (9) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:162/proxy/: bar (200; 8.982106ms)
Sep 27 06:32:28.398: INFO: (9) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:162/proxy/: bar (200; 8.844528ms)
Sep 27 06:32:28.399: INFO: (9) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:460/proxy/: tls baz (200; 9.481982ms)
Sep 27 06:32:28.399: INFO: (9) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/rewriteme">test</a> (200; 9.429921ms)
Sep 27 06:32:28.399: INFO: (9) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/rewriteme">t... (200; 9.896495ms)
Sep 27 06:32:28.399: INFO: (9) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/tlsrewriteme... (200; 9.896233ms)
Sep 27 06:32:28.399: INFO: (9) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname2/proxy/: tls qux (200; 10.532057ms)
Sep 27 06:32:28.399: INFO: (9) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:462/proxy/: tls qux (200; 9.753225ms)
Sep 27 06:32:28.400: INFO: (9) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:160/proxy/: foo (200; 10.24446ms)
Sep 27 06:32:28.400: INFO: (9) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:160/proxy/: foo (200; 10.305155ms)
Sep 27 06:32:28.402: INFO: (9) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname2/proxy/: bar (200; 12.796895ms)
Sep 27 06:32:28.402: INFO: (9) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname2/proxy/: bar (200; 13.273627ms)
Sep 27 06:32:28.402: INFO: (9) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname1/proxy/: foo (200; 13.470974ms)
Sep 27 06:32:28.403: INFO: (9) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname1/proxy/: tls baz (200; 13.24551ms)
Sep 27 06:32:28.403: INFO: (9) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname1/proxy/: foo (200; 13.634982ms)
Sep 27 06:32:28.410: INFO: (10) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:160/proxy/: foo (200; 6.205415ms)
Sep 27 06:32:28.411: INFO: (10) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:460/proxy/: tls baz (200; 8.461136ms)
Sep 27 06:32:28.412: INFO: (10) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname1/proxy/: foo (200; 9.263263ms)
Sep 27 06:32:28.412: INFO: (10) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:162/proxy/: bar (200; 8.847185ms)
Sep 27 06:32:28.412: INFO: (10) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/rewriteme">test</... (200; 7.723205ms)
Sep 27 06:32:28.413: INFO: (10) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:162/proxy/: bar (200; 8.883642ms)
Sep 27 06:32:28.413: INFO: (10) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:160/proxy/: foo (200; 9.154436ms)
Sep 27 06:32:28.413: INFO: (10) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname2/proxy/: tls qux (200; 9.387106ms)
Sep 27 06:32:28.413: INFO: (10) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:462/proxy/: tls qux (200; 9.693167ms)
Sep 27 06:32:28.413: INFO: (10) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/rewriteme">test</a> (200; 9.404276ms)
Sep 27 06:32:28.413: INFO: (10) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/tlsrewriteme... (200; 9.113917ms)
Sep 27 06:32:28.413: INFO: (10) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/rewriteme">t... (200; 10.06038ms)
Sep 27 06:32:28.416: INFO: (10) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname2/proxy/: bar (200; 11.983136ms)
Sep 27 06:32:28.416: INFO: (10) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname2/proxy/: bar (200; 12.364837ms)
Sep 27 06:32:28.417: INFO: (10) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname1/proxy/: foo (200; 12.443544ms)
Sep 27 06:32:28.417: INFO: (10) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname1/proxy/: tls baz (200; 13.387681ms)
Sep 27 06:32:28.424: INFO: (11) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/rewriteme">test</... (200; 7.380495ms)
Sep 27 06:32:28.425: INFO: (11) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:160/proxy/: foo (200; 7.440625ms)
Sep 27 06:32:28.425: INFO: (11) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/rewriteme">test</a> (200; 7.929137ms)
Sep 27 06:32:28.426: INFO: (11) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:160/proxy/: foo (200; 8.281674ms)
Sep 27 06:32:28.426: INFO: (11) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/rewriteme">t... (200; 9.186097ms)
Sep 27 06:32:28.427: INFO: (11) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/tlsrewriteme... (200; 9.341277ms)
Sep 27 06:32:28.427: INFO: (11) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:162/proxy/: bar (200; 9.445868ms)
Sep 27 06:32:28.427: INFO: (11) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:462/proxy/: tls qux (200; 9.535725ms)
Sep 27 06:32:28.427: INFO: (11) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:460/proxy/: tls baz (200; 9.942415ms)
Sep 27 06:32:28.427: INFO: (11) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:162/proxy/: bar (200; 9.960482ms)
Sep 27 06:32:28.428: INFO: (11) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname2/proxy/: bar (200; 10.392959ms)
Sep 27 06:32:28.429: INFO: (11) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname1/proxy/: foo (200; 10.84527ms)
Sep 27 06:32:28.430: INFO: (11) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname1/proxy/: tls baz (200; 12.336387ms)
Sep 27 06:32:28.430: INFO: (11) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname2/proxy/: tls qux (200; 12.814058ms)
Sep 27 06:32:28.430: INFO: (11) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname1/proxy/: foo (200; 12.516585ms)
Sep 27 06:32:28.430: INFO: (11) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname2/proxy/: bar (200; 12.485947ms)
Sep 27 06:32:28.437: INFO: (12) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:460/proxy/: tls baz (200; 5.561696ms)
Sep 27 06:32:28.438: INFO: (12) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:160/proxy/: foo (200; 5.780064ms)
Sep 27 06:32:28.438: INFO: (12) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:162/proxy/: bar (200; 6.367184ms)
Sep 27 06:32:28.439: INFO: (12) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:162/proxy/: bar (200; 7.182403ms)
Sep 27 06:32:28.439: INFO: (12) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:462/proxy/: tls qux (200; 7.513256ms)
Sep 27 06:32:28.439: INFO: (12) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:160/proxy/: foo (200; 7.229016ms)
Sep 27 06:32:28.439: INFO: (12) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/rewriteme">test</a> (200; 7.413712ms)
Sep 27 06:32:28.439: INFO: (12) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/rewriteme">t... (200; 8.288929ms)
Sep 27 06:32:28.439: INFO: (12) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/tlsrewriteme... (200; 7.388847ms)
Sep 27 06:32:28.440: INFO: (12) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/rewriteme">test</... (200; 9.067583ms)
Sep 27 06:32:28.442: INFO: (12) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname1/proxy/: foo (200; 11.095312ms)
Sep 27 06:32:28.442: INFO: (12) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname2/proxy/: bar (200; 11.778229ms)
Sep 27 06:32:28.442: INFO: (12) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname1/proxy/: foo (200; 11.80419ms)
Sep 27 06:32:28.443: INFO: (12) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname2/proxy/: bar (200; 11.884952ms)
Sep 27 06:32:28.443: INFO: (12) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname1/proxy/: tls baz (200; 11.146316ms)
Sep 27 06:32:28.443: INFO: (12) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname2/proxy/: tls qux (200; 11.319158ms)
Sep 27 06:32:28.448: INFO: (13) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/rewriteme">test</... (200; 5.076751ms)
Sep 27 06:32:28.450: INFO: (13) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:162/proxy/: bar (200; 6.211998ms)
Sep 27 06:32:28.450: INFO: (13) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:460/proxy/: tls baz (200; 7.086436ms)
Sep 27 06:32:28.450: INFO: (13) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/tlsrewriteme... (200; 6.792089ms)
Sep 27 06:32:28.450: INFO: (13) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/rewriteme">t... (200; 7.210151ms)
Sep 27 06:32:28.451: INFO: (13) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:162/proxy/: bar (200; 7.35117ms)
Sep 27 06:32:28.451: INFO: (13) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:462/proxy/: tls qux (200; 7.479049ms)
Sep 27 06:32:28.451: INFO: (13) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:160/proxy/: foo (200; 6.93075ms)
Sep 27 06:32:28.451: INFO: (13) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/rewriteme">test</a> (200; 7.017417ms)
Sep 27 06:32:28.451: INFO: (13) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:160/proxy/: foo (200; 6.932133ms)
Sep 27 06:32:28.453: INFO: (13) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname1/proxy/: tls baz (200; 9.379115ms)
Sep 27 06:32:28.455: INFO: (13) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname2/proxy/: tls qux (200; 10.81786ms)
Sep 27 06:32:28.456: INFO: (13) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname1/proxy/: foo (200; 11.738978ms)
Sep 27 06:32:28.456: INFO: (13) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname1/proxy/: foo (200; 11.731227ms)
Sep 27 06:32:28.456: INFO: (13) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname2/proxy/: bar (200; 12.34706ms)
Sep 27 06:32:28.456: INFO: (13) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname2/proxy/: bar (200; 11.76395ms)
Sep 27 06:32:28.461: INFO: (14) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:460/proxy/: tls baz (200; 5.421449ms)
Sep 27 06:32:28.463: INFO: (14) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:162/proxy/: bar (200; 6.632481ms)
Sep 27 06:32:28.464: INFO: (14) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:162/proxy/: bar (200; 7.454726ms)
Sep 27 06:32:28.464: INFO: (14) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/tlsrewriteme... (200; 7.169973ms)
Sep 27 06:32:28.464: INFO: (14) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:462/proxy/: tls qux (200; 7.498073ms)
Sep 27 06:32:28.465: INFO: (14) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/rewriteme">test</a> (200; 8.19068ms)
Sep 27 06:32:28.465: INFO: (14) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:160/proxy/: foo (200; 9.172885ms)
Sep 27 06:32:28.465: INFO: (14) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:160/proxy/: foo (200; 8.647394ms)
Sep 27 06:32:28.467: INFO: (14) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/rewriteme">test</... (200; 9.294194ms)
Sep 27 06:32:28.467: INFO: (14) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/rewriteme">t... (200; 9.489223ms)
Sep 27 06:32:28.467: INFO: (14) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname2/proxy/: bar (200; 10.465385ms)
Sep 27 06:32:28.467: INFO: (14) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname1/proxy/: tls baz (200; 10.632993ms)
Sep 27 06:32:28.468: INFO: (14) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname2/proxy/: bar (200; 10.924147ms)
Sep 27 06:32:28.469: INFO: (14) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname1/proxy/: foo (200; 11.931176ms)
Sep 27 06:32:28.469: INFO: (14) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname2/proxy/: tls qux (200; 12.530204ms)
Sep 27 06:32:28.469: INFO: (14) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname1/proxy/: foo (200; 12.41463ms)
Sep 27 06:32:28.475: INFO: (15) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:162/proxy/: bar (200; 5.186266ms)
Sep 27 06:32:28.475: INFO: (15) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/rewriteme">t... (200; 5.509544ms)
Sep 27 06:32:28.475: INFO: (15) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/rewriteme">test</... (200; 5.706394ms)
Sep 27 06:32:28.477: INFO: (15) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:460/proxy/: tls baz (200; 7.39615ms)
Sep 27 06:32:28.479: INFO: (15) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname1/proxy/: foo (200; 9.819023ms)
Sep 27 06:32:28.481: INFO: (15) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:160/proxy/: foo (200; 10.503957ms)
Sep 27 06:32:28.482: INFO: (15) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname1/proxy/: foo (200; 12.847609ms)
Sep 27 06:32:28.482: INFO: (15) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:162/proxy/: bar (200; 12.400127ms)
Sep 27 06:32:28.482: INFO: (15) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:462/proxy/: tls qux (200; 12.343797ms)
Sep 27 06:32:28.482: INFO: (15) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname2/proxy/: bar (200; 12.735013ms)
Sep 27 06:32:28.482: INFO: (15) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname2/proxy/: bar (200; 12.231108ms)
Sep 27 06:32:28.482: INFO: (15) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/tlsrewriteme... (200; 12.285116ms)
Sep 27 06:32:28.482: INFO: (15) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/rewriteme">test</a> (200; 12.150907ms)
Sep 27 06:32:28.482: INFO: (15) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:160/proxy/: foo (200; 12.242646ms)
Sep 27 06:32:28.484: INFO: (15) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname2/proxy/: tls qux (200; 13.917453ms)
Sep 27 06:32:28.485: INFO: (15) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname1/proxy/: tls baz (200; 14.296725ms)
Sep 27 06:32:28.495: INFO: (16) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:160/proxy/: foo (200; 9.704906ms)
Sep 27 06:32:28.495: INFO: (16) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:160/proxy/: foo (200; 9.90156ms)
Sep 27 06:32:28.495: INFO: (16) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/rewriteme">t... (200; 9.053443ms)
Sep 27 06:32:28.498: INFO: (16) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/rewriteme">test</a> (200; 13.335676ms)
Sep 27 06:32:28.498: INFO: (16) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:462/proxy/: tls qux (200; 13.502793ms)
Sep 27 06:32:28.498: INFO: (16) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:162/proxy/: bar (200; 13.607149ms)
Sep 27 06:32:28.498: INFO: (16) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/tlsrewriteme... (200; 13.098244ms)
Sep 27 06:32:28.498: INFO: (16) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:162/proxy/: bar (200; 13.193465ms)
Sep 27 06:32:28.498: INFO: (16) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/rewriteme">test</... (200; 12.779533ms)
Sep 27 06:32:28.498: INFO: (16) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:460/proxy/: tls baz (200; 13.800098ms)
Sep 27 06:32:28.498: INFO: (16) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname1/proxy/: foo (200; 12.688204ms)
Sep 27 06:32:28.499: INFO: (16) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname2/proxy/: bar (200; 13.499681ms)
Sep 27 06:32:28.499: INFO: (16) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname1/proxy/: tls baz (200; 13.50237ms)
Sep 27 06:32:28.499: INFO: (16) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname1/proxy/: foo (200; 13.389459ms)
Sep 27 06:32:28.499: INFO: (16) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname2/proxy/: bar (200; 13.78786ms)
Sep 27 06:32:28.500: INFO: (16) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname2/proxy/: tls qux (200; 14.654311ms)
Sep 27 06:32:28.505: INFO: (17) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:160/proxy/: foo (200; 5.229497ms)
Sep 27 06:32:28.507: INFO: (17) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:162/proxy/: bar (200; 6.868248ms)
Sep 27 06:32:28.508: INFO: (17) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/rewriteme">t... (200; 7.56777ms)
Sep 27 06:32:28.508: INFO: (17) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:462/proxy/: tls qux (200; 7.347303ms)
Sep 27 06:32:28.509: INFO: (17) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname1/proxy/: foo (200; 8.94411ms)
Sep 27 06:32:28.509: INFO: (17) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/rewriteme">test</... (200; 9.021544ms)
Sep 27 06:32:28.509: INFO: (17) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:160/proxy/: foo (200; 8.76312ms)
Sep 27 06:32:28.510: INFO: (17) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:162/proxy/: bar (200; 9.124508ms)
Sep 27 06:32:28.510: INFO: (17) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/tlsrewriteme... (200; 9.082789ms)
Sep 27 06:32:28.510: INFO: (17) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname2/proxy/: bar (200; 9.827723ms)
Sep 27 06:32:28.510: INFO: (17) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:460/proxy/: tls baz (200; 9.615995ms)
Sep 27 06:32:28.510: INFO: (17) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/rewriteme">test</a> (200; 9.17178ms)
Sep 27 06:32:28.510: INFO: (17) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname1/proxy/: foo (200; 10.289658ms)
Sep 27 06:32:28.512: INFO: (17) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname2/proxy/: bar (200; 11.268737ms)
Sep 27 06:32:28.513: INFO: (17) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname1/proxy/: tls baz (200; 11.994729ms)
Sep 27 06:32:28.513: INFO: (17) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname2/proxy/: tls qux (200; 12.073282ms)
Sep 27 06:32:28.518: INFO: (18) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:460/proxy/: tls baz (200; 5.014104ms)
Sep 27 06:32:28.519: INFO: (18) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:160/proxy/: foo (200; 5.846406ms)
Sep 27 06:32:28.519: INFO: (18) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:162/proxy/: bar (200; 6.494203ms)
Sep 27 06:32:28.520: INFO: (18) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:462/proxy/: tls qux (200; 6.487865ms)
Sep 27 06:32:28.521: INFO: (18) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:162/proxy/: bar (200; 7.139123ms)
Sep 27 06:32:28.521: INFO: (18) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/tlsrewriteme... (200; 7.423102ms)
Sep 27 06:32:28.521: INFO: (18) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/rewriteme">test</a> (200; 7.898501ms)
Sep 27 06:32:28.522: INFO: (18) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:160/proxy/: foo (200; 8.38832ms)
Sep 27 06:32:28.522: INFO: (18) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/rewriteme">test</... (200; 8.551139ms)
Sep 27 06:32:28.522: INFO: (18) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/rewriteme">t... (200; 8.356192ms)
Sep 27 06:32:28.523: INFO: (18) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname2/proxy/: tls qux (200; 9.508424ms)
Sep 27 06:32:28.523: INFO: (18) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname2/proxy/: bar (200; 9.791673ms)
Sep 27 06:32:28.525: INFO: (18) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname1/proxy/: foo (200; 10.550172ms)
Sep 27 06:32:28.525: INFO: (18) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname1/proxy/: foo (200; 11.126114ms)
Sep 27 06:32:28.525: INFO: (18) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname2/proxy/: bar (200; 11.508488ms)
Sep 27 06:32:28.525: INFO: (18) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname1/proxy/: tls baz (200; 11.729472ms)
Sep 27 06:32:28.530: INFO: (19) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:1080/proxy/rewriteme">test</... (200; 4.603847ms)
Sep 27 06:32:28.531: INFO: (19) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:460/proxy/: tls baz (200; 5.474849ms)
Sep 27 06:32:28.531: INFO: (19) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:462/proxy/: tls qux (200; 5.537529ms)
Sep 27 06:32:28.532: INFO: (19) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:162/proxy/: bar (200; 6.236119ms)
Sep 27 06:32:28.532: INFO: (19) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:1080/proxy/rewriteme">t... (200; 6.446231ms)
Sep 27 06:32:28.532: INFO: (19) /api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/https:proxy-service-prc8r-b78lp:443/proxy/tlsrewriteme... (200; 6.229221ms)
Sep 27 06:32:28.533: INFO: (19) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:162/proxy/: bar (200; 7.086374ms)
Sep 27 06:32:28.534: INFO: (19) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/: <a href="/api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp/proxy/rewriteme">test</a> (200; 7.322228ms)
Sep 27 06:32:28.534: INFO: (19) /api/v1/namespaces/proxy-139/pods/proxy-service-prc8r-b78lp:160/proxy/: foo (200; 7.878271ms)
Sep 27 06:32:28.535: INFO: (19) /api/v1/namespaces/proxy-139/pods/http:proxy-service-prc8r-b78lp:160/proxy/: foo (200; 8.409837ms)
Sep 27 06:32:28.535: INFO: (19) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname2/proxy/: bar (200; 8.970781ms)
Sep 27 06:32:28.536: INFO: (19) /api/v1/namespaces/proxy-139/services/proxy-service-prc8r:portname1/proxy/: foo (200; 9.612437ms)
Sep 27 06:32:28.537: INFO: (19) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname1/proxy/: foo (200; 10.644969ms)
Sep 27 06:32:28.537: INFO: (19) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname2/proxy/: tls qux (200; 11.094107ms)
Sep 27 06:32:28.538: INFO: (19) /api/v1/namespaces/proxy-139/services/https:proxy-service-prc8r:tlsportname1/proxy/: tls baz (200; 11.317684ms)
Sep 27 06:32:28.538: INFO: (19) /api/v1/namespaces/proxy-139/services/http:proxy-service-prc8r:portname2/proxy/: bar (200; 11.452833ms)
STEP: deleting ReplicationController proxy-service-prc8r in namespace proxy-139, will wait for the garbage collector to delete the pods
Sep 27 06:32:28.598: INFO: Deleting ReplicationController proxy-service-prc8r took: 7.378944ms
Sep 27 06:32:28.898: INFO: Terminating ReplicationController proxy-service-prc8r pods took: 300.235561ms
[AfterEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:32:41.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-139" for this suite.
Sep 27 06:32:47.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:32:47.520: INFO: namespace proxy-139 deletion completed in 6.110342841s

• [SLOW TEST:22.482 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:32:47.520: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6504
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 06:33:03.682: INFO: Container started at 2019-09-27 06:32:48 +0000 UTC, pod became ready at 2019-09-27 06:33:03 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:33:03.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6504" for this suite.
Sep 27 06:33:25.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:33:25.904: INFO: namespace container-probe-6504 deletion completed in 22.216355274s

• [SLOW TEST:38.384 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:33:25.904: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7573
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7573.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7573.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 27 06:33:30.283: INFO: DNS probes using dns-7573/dns-test-97c5cc87-0a31-4e92-a4fd-3590243eb579 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:33:30.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7573" for this suite.
Sep 27 06:33:36.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:33:36.633: INFO: namespace dns-7573 deletion completed in 6.227846798s

• [SLOW TEST:10.728 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:33:36.633: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9348
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Sep 27 06:33:36.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 create -f - --namespace=kubectl-9348'
Sep 27 06:33:37.817: INFO: stderr: ""
Sep 27 06:33:37.817: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 27 06:33:37.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9348'
Sep 27 06:33:37.942: INFO: stderr: ""
Sep 27 06:33:37.942: INFO: stdout: "update-demo-nautilus-7x4qq "
STEP: Replicas for name=update-demo: expected=2 actual=1
Sep 27 06:33:42.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9348'
Sep 27 06:33:43.028: INFO: stderr: ""
Sep 27 06:33:43.028: INFO: stdout: "update-demo-nautilus-7x4qq update-demo-nautilus-b9p5h "
Sep 27 06:33:43.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods update-demo-nautilus-7x4qq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9348'
Sep 27 06:33:43.113: INFO: stderr: ""
Sep 27 06:33:43.113: INFO: stdout: "true"
Sep 27 06:33:43.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods update-demo-nautilus-7x4qq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9348'
Sep 27 06:33:43.215: INFO: stderr: ""
Sep 27 06:33:43.215: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 27 06:33:43.215: INFO: validating pod update-demo-nautilus-7x4qq
Sep 27 06:33:43.309: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 27 06:33:43.309: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 27 06:33:43.309: INFO: update-demo-nautilus-7x4qq is verified up and running
Sep 27 06:33:43.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods update-demo-nautilus-b9p5h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9348'
Sep 27 06:33:43.392: INFO: stderr: ""
Sep 27 06:33:43.392: INFO: stdout: "true"
Sep 27 06:33:43.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods update-demo-nautilus-b9p5h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9348'
Sep 27 06:33:43.474: INFO: stderr: ""
Sep 27 06:33:43.474: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 27 06:33:43.474: INFO: validating pod update-demo-nautilus-b9p5h
Sep 27 06:33:43.798: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 27 06:33:43.798: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 27 06:33:43.798: INFO: update-demo-nautilus-b9p5h is verified up and running
STEP: scaling down the replication controller
Sep 27 06:33:43.799: INFO: scanned /root for discovery docs: <nil>
Sep 27 06:33:43.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-9348'
Sep 27 06:33:44.919: INFO: stderr: ""
Sep 27 06:33:44.919: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 27 06:33:44.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9348'
Sep 27 06:33:45.014: INFO: stderr: ""
Sep 27 06:33:45.014: INFO: stdout: "update-demo-nautilus-7x4qq update-demo-nautilus-b9p5h "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep 27 06:33:50.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9348'
Sep 27 06:33:50.119: INFO: stderr: ""
Sep 27 06:33:50.119: INFO: stdout: "update-demo-nautilus-7x4qq "
Sep 27 06:33:50.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods update-demo-nautilus-7x4qq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9348'
Sep 27 06:33:50.240: INFO: stderr: ""
Sep 27 06:33:50.240: INFO: stdout: "true"
Sep 27 06:33:50.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods update-demo-nautilus-7x4qq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9348'
Sep 27 06:33:50.341: INFO: stderr: ""
Sep 27 06:33:50.341: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 27 06:33:50.341: INFO: validating pod update-demo-nautilus-7x4qq
Sep 27 06:33:50.356: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 27 06:33:50.356: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 27 06:33:50.356: INFO: update-demo-nautilus-7x4qq is verified up and running
STEP: scaling up the replication controller
Sep 27 06:33:50.357: INFO: scanned /root for discovery docs: <nil>
Sep 27 06:33:50.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-9348'
Sep 27 06:33:51.511: INFO: stderr: ""
Sep 27 06:33:51.511: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 27 06:33:51.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9348'
Sep 27 06:33:51.625: INFO: stderr: ""
Sep 27 06:33:51.625: INFO: stdout: "update-demo-nautilus-56gsh update-demo-nautilus-7x4qq "
Sep 27 06:33:51.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods update-demo-nautilus-56gsh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9348'
Sep 27 06:33:51.724: INFO: stderr: ""
Sep 27 06:33:51.724: INFO: stdout: "true"
Sep 27 06:33:51.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods update-demo-nautilus-56gsh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9348'
Sep 27 06:33:51.801: INFO: stderr: ""
Sep 27 06:33:51.801: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 27 06:33:51.801: INFO: validating pod update-demo-nautilus-56gsh
Sep 27 06:33:51.806: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 27 06:33:51.806: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 27 06:33:51.806: INFO: update-demo-nautilus-56gsh is verified up and running
Sep 27 06:33:51.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods update-demo-nautilus-7x4qq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9348'
Sep 27 06:33:51.883: INFO: stderr: ""
Sep 27 06:33:51.883: INFO: stdout: "true"
Sep 27 06:33:51.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods update-demo-nautilus-7x4qq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9348'
Sep 27 06:33:51.960: INFO: stderr: ""
Sep 27 06:33:51.960: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 27 06:33:51.960: INFO: validating pod update-demo-nautilus-7x4qq
Sep 27 06:33:51.963: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 27 06:33:51.963: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 27 06:33:51.963: INFO: update-demo-nautilus-7x4qq is verified up and running
STEP: using delete to clean up resources
Sep 27 06:33:51.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 delete --grace-period=0 --force -f - --namespace=kubectl-9348'
Sep 27 06:33:52.046: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 27 06:33:52.046: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep 27 06:33:52.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9348'
Sep 27 06:33:52.137: INFO: stderr: "No resources found.\n"
Sep 27 06:33:52.137: INFO: stdout: ""
Sep 27 06:33:52.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods -l name=update-demo --namespace=kubectl-9348 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 27 06:33:52.216: INFO: stderr: ""
Sep 27 06:33:52.216: INFO: stdout: "update-demo-nautilus-56gsh\nupdate-demo-nautilus-7x4qq\n"
Sep 27 06:33:52.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9348'
Sep 27 06:33:52.804: INFO: stderr: "No resources found.\n"
Sep 27 06:33:52.804: INFO: stdout: ""
Sep 27 06:33:52.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods -l name=update-demo --namespace=kubectl-9348 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 27 06:33:52.880: INFO: stderr: ""
Sep 27 06:33:52.880: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:33:52.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9348" for this suite.
Sep 27 06:34:14.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:34:14.970: INFO: namespace kubectl-9348 deletion completed in 22.085095965s

• [SLOW TEST:38.337 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:34:14.970: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-273
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep 27 06:34:15.130: INFO: Waiting up to 5m0s for pod "pod-5bdf7995-2b00-4960-8c0e-b457d8f3c12d" in namespace "emptydir-273" to be "success or failure"
Sep 27 06:34:15.133: INFO: Pod "pod-5bdf7995-2b00-4960-8c0e-b457d8f3c12d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.535863ms
Sep 27 06:34:17.139: INFO: Pod "pod-5bdf7995-2b00-4960-8c0e-b457d8f3c12d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008803671s
STEP: Saw pod success
Sep 27 06:34:17.139: INFO: Pod "pod-5bdf7995-2b00-4960-8c0e-b457d8f3c12d" satisfied condition "success or failure"
Sep 27 06:34:17.141: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-5bdf7995-2b00-4960-8c0e-b457d8f3c12d container test-container: <nil>
STEP: delete the pod
Sep 27 06:34:17.162: INFO: Waiting for pod pod-5bdf7995-2b00-4960-8c0e-b457d8f3c12d to disappear
Sep 27 06:34:17.164: INFO: Pod pod-5bdf7995-2b00-4960-8c0e-b457d8f3c12d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:34:17.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-273" for this suite.
Sep 27 06:34:23.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:34:23.274: INFO: namespace emptydir-273 deletion completed in 6.103518063s

• [SLOW TEST:8.304 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:34:23.275: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-388
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Sep 27 06:34:23.458: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:34:31.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-388" for this suite.
Sep 27 06:34:37.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:34:37.530: INFO: namespace pods-388 deletion completed in 6.193753438s

• [SLOW TEST:14.255 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:34:37.530: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9507
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Sep 27 06:34:37.740: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 27 06:34:37.771: INFO: Waiting for terminating namespaces to be deleted...
Sep 27 06:34:37.774: INFO: 
Logging pods the kubelet thinks is on node worker1.dev-bj.kubeoperator.io before test
Sep 27 06:34:37.791: INFO: kube-flannel-ds-amd64-2tjkj from kube-system started at 2019-09-27 03:42:32 +0000 UTC (1 container statuses recorded)
Sep 27 06:34:37.791: INFO: 	Container kube-flannel ready: true, restart count 0
Sep 27 06:34:37.791: INFO: weave-scope-app-7d78556c95-hlvsr from weave started at 2019-09-27 03:45:13 +0000 UTC (1 container statuses recorded)
Sep 27 06:34:37.791: INFO: 	Container app ready: true, restart count 0
Sep 27 06:34:37.791: INFO: weave-scope-agent-fd4jr from weave started at 2019-09-27 03:45:13 +0000 UTC (1 container statuses recorded)
Sep 27 06:34:37.791: INFO: 	Container scope-agent ready: true, restart count 0
Sep 27 06:34:37.791: INFO: sonobuoy-e2e-job-4960befc9aee4574 from sonobuoy started at 2019-09-27 05:46:05 +0000 UTC (2 container statuses recorded)
Sep 27 06:34:37.791: INFO: 	Container e2e ready: true, restart count 0
Sep 27 06:34:37.791: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 27 06:34:37.791: INFO: sonobuoy-systemd-logs-daemon-set-7f0ec8e8c9ff47b9-2pvqs from sonobuoy started at 2019-09-27 05:46:06 +0000 UTC (2 container statuses recorded)
Sep 27 06:34:37.791: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 27 06:34:37.791: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 27 06:34:37.791: INFO: tiller-deploy-7cf9b9d4d9-2hhhb from kube-system started at 2019-09-27 03:44:15 +0000 UTC (1 container statuses recorded)
Sep 27 06:34:37.791: INFO: 	Container tiller ready: true, restart count 0
Sep 27 06:34:37.791: INFO: coredns-6647cfd5f7-5wgqm from kube-system started at 2019-09-27 03:44:35 +0000 UTC (1 container statuses recorded)
Sep 27 06:34:37.791: INFO: 	Container coredns ready: true, restart count 0
Sep 27 06:34:37.791: INFO: f2c-prometheus-server-59b7445459-cdgrc from monitoring started at 2019-09-27 03:45:02 +0000 UTC (2 container statuses recorded)
Sep 27 06:34:37.791: INFO: 	Container prometheus-server ready: true, restart count 0
Sep 27 06:34:37.791: INFO: 	Container prometheus-server-configmap-reload ready: true, restart count 0
Sep 27 06:34:37.791: INFO: traefik-ingress-lb-5hr58 from kube-system started at 2019-09-27 03:44:43 +0000 UTC (1 container statuses recorded)
Sep 27 06:34:37.791: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Sep 27 06:34:37.791: INFO: sonobuoy from sonobuoy started at 2019-09-27 05:46:03 +0000 UTC (1 container statuses recorded)
Sep 27 06:34:37.791: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 27 06:34:37.791: INFO: f2c-prometheus-node-exporter-9jg5c from monitoring started at 2019-09-27 03:45:00 +0000 UTC (1 container statuses recorded)
Sep 27 06:34:37.791: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Sep 27 06:34:37.791: INFO: 
Logging pods the kubelet thinks is on node worker2.dev-bj.kubeoperator.io before test
Sep 27 06:34:37.802: INFO: traefik-ingress-lb-cmrlj from kube-system started at 2019-09-27 03:44:43 +0000 UTC (1 container statuses recorded)
Sep 27 06:34:37.802: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Sep 27 06:34:37.802: INFO: f2c-grafana-6dd4b6bc5c-822q6 from monitoring started at 2019-09-27 03:45:09 +0000 UTC (1 container statuses recorded)
Sep 27 06:34:37.802: INFO: 	Container grafana ready: true, restart count 0
Sep 27 06:34:37.802: INFO: weave-scope-cluster-agent-6fdcc8f6dd-247hz from weave started at 2019-09-27 03:45:13 +0000 UTC (1 container statuses recorded)
Sep 27 06:34:37.802: INFO: 	Container scope-cluster-agent ready: true, restart count 0
Sep 27 06:34:37.802: INFO: f2c-prometheus-node-exporter-kgb24 from monitoring started at 2019-09-27 03:45:00 +0000 UTC (1 container statuses recorded)
Sep 27 06:34:37.802: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Sep 27 06:34:37.802: INFO: weave-scope-agent-rrlfg from weave started at 2019-09-27 03:45:13 +0000 UTC (1 container statuses recorded)
Sep 27 06:34:37.802: INFO: 	Container scope-agent ready: true, restart count 0
Sep 27 06:34:37.802: INFO: kube-registry-dh5pv from kube-system started at 2019-09-27 03:45:49 +0000 UTC (2 container statuses recorded)
Sep 27 06:34:37.802: INFO: 	Container registry ready: true, restart count 0
Sep 27 06:34:37.802: INFO: 	Container registry-ui ready: true, restart count 0
Sep 27 06:34:37.802: INFO: sonobuoy-systemd-logs-daemon-set-7f0ec8e8c9ff47b9-rg9hc from sonobuoy started at 2019-09-27 05:46:06 +0000 UTC (2 container statuses recorded)
Sep 27 06:34:37.802: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 27 06:34:37.802: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 27 06:34:37.802: INFO: kube-flannel-ds-amd64-ptljm from kube-system started at 2019-09-27 03:42:32 +0000 UTC (1 container statuses recorded)
Sep 27 06:34:37.802: INFO: 	Container kube-flannel ready: true, restart count 0
Sep 27 06:34:37.802: INFO: coredns-6647cfd5f7-m24g4 from kube-system started at 2019-09-27 03:44:35 +0000 UTC (1 container statuses recorded)
Sep 27 06:34:37.802: INFO: 	Container coredns ready: true, restart count 0
Sep 27 06:34:37.802: INFO: heapster-5646c79465-tpqxz from kube-system started at 2019-09-27 03:44:50 +0000 UTC (1 container statuses recorded)
Sep 27 06:34:37.802: INFO: 	Container heapster ready: true, restart count 0
Sep 27 06:34:37.802: INFO: 
Logging pods the kubelet thinks is on node worker3.dev-bj.kubeoperator.io before test
Sep 27 06:34:37.823: INFO: f2c-prometheus-alertmanager-65f9fd5bf5-8fc2f from monitoring started at 2019-09-27 03:45:02 +0000 UTC (2 container statuses recorded)
Sep 27 06:34:37.823: INFO: 	Container prometheus-alertmanager ready: true, restart count 0
Sep 27 06:34:37.823: INFO: 	Container prometheus-alertmanager-configmap-reload ready: true, restart count 0
Sep 27 06:34:37.823: INFO: f2c-prometheus-node-exporter-p2zc6 from monitoring started at 2019-09-27 03:45:01 +0000 UTC (1 container statuses recorded)
Sep 27 06:34:37.823: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Sep 27 06:34:37.823: INFO: sonobuoy-systemd-logs-daemon-set-7f0ec8e8c9ff47b9-j8dzb from sonobuoy started at 2019-09-27 05:46:06 +0000 UTC (2 container statuses recorded)
Sep 27 06:34:37.823: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 27 06:34:37.823: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 27 06:34:37.823: INFO: kubernetes-dashboard-5bc5db49-r7vvg from kube-system started at 2019-09-27 03:44:49 +0000 UTC (1 container statuses recorded)
Sep 27 06:34:37.823: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep 27 06:34:37.823: INFO: weave-scope-agent-64k6h from weave started at 2019-09-27 03:45:13 +0000 UTC (1 container statuses recorded)
Sep 27 06:34:37.823: INFO: 	Container scope-agent ready: true, restart count 0
Sep 27 06:34:37.823: INFO: kube-flannel-ds-amd64-frff7 from kube-system started at 2019-09-27 03:42:32 +0000 UTC (1 container statuses recorded)
Sep 27 06:34:37.823: INFO: 	Container kube-flannel ready: true, restart count 0
Sep 27 06:34:37.823: INFO: traefik-ingress-lb-tst7r from kube-system started at 2019-09-27 03:44:43 +0000 UTC (1 container statuses recorded)
Sep 27 06:34:37.823: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Sep 27 06:34:37.823: INFO: f2c-prometheus-kube-state-metrics-5b66c65d69-b5znb from monitoring started at 2019-09-27 03:45:01 +0000 UTC (1 container statuses recorded)
Sep 27 06:34:37.823: INFO: 	Container prometheus-kube-state-metrics ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15c838082a8a723d], Reason = [FailedScheduling], Message = [0/6 nodes are available: 3 node(s) didn't match node selector, 3 node(s) were unschedulable.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:34:38.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9507" for this suite.
Sep 27 06:34:44.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:34:45.107: INFO: namespace sched-pred-9507 deletion completed in 6.230709156s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:7.578 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:34:45.108: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-5041
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Sep 27 06:34:45.368: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5041,SelfLink:/api/v1/namespaces/watch-5041/configmaps/e2e-watch-test-label-changed,UID:c865a0d5-8f10-40bf-a283-21630a250390,ResourceVersion:20552,Generation:0,CreationTimestamp:2019-09-27 06:34:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 27 06:34:45.368: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5041,SelfLink:/api/v1/namespaces/watch-5041/configmaps/e2e-watch-test-label-changed,UID:c865a0d5-8f10-40bf-a283-21630a250390,ResourceVersion:20553,Generation:0,CreationTimestamp:2019-09-27 06:34:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep 27 06:34:45.374: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5041,SelfLink:/api/v1/namespaces/watch-5041/configmaps/e2e-watch-test-label-changed,UID:c865a0d5-8f10-40bf-a283-21630a250390,ResourceVersion:20554,Generation:0,CreationTimestamp:2019-09-27 06:34:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Sep 27 06:34:55.529: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5041,SelfLink:/api/v1/namespaces/watch-5041/configmaps/e2e-watch-test-label-changed,UID:c865a0d5-8f10-40bf-a283-21630a250390,ResourceVersion:20575,Generation:0,CreationTimestamp:2019-09-27 06:34:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 27 06:34:55.530: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5041,SelfLink:/api/v1/namespaces/watch-5041/configmaps/e2e-watch-test-label-changed,UID:c865a0d5-8f10-40bf-a283-21630a250390,ResourceVersion:20576,Generation:0,CreationTimestamp:2019-09-27 06:34:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Sep 27 06:34:55.530: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5041,SelfLink:/api/v1/namespaces/watch-5041/configmaps/e2e-watch-test-label-changed,UID:c865a0d5-8f10-40bf-a283-21630a250390,ResourceVersion:20577,Generation:0,CreationTimestamp:2019-09-27 06:34:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:34:55.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5041" for this suite.
Sep 27 06:35:01.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:35:01.649: INFO: namespace watch-5041 deletion completed in 6.110071491s

• [SLOW TEST:16.541 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:35:01.649: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3644
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-37b633a1-79ec-4fa4-bdf1-abefeb83603d
STEP: Creating a pod to test consume secrets
Sep 27 06:35:01.830: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-456a3bbe-81da-4d59-ad12-dcf2ca2b15c3" in namespace "projected-3644" to be "success or failure"
Sep 27 06:35:01.836: INFO: Pod "pod-projected-secrets-456a3bbe-81da-4d59-ad12-dcf2ca2b15c3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.363621ms
Sep 27 06:35:03.839: INFO: Pod "pod-projected-secrets-456a3bbe-81da-4d59-ad12-dcf2ca2b15c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00927312s
STEP: Saw pod success
Sep 27 06:35:03.839: INFO: Pod "pod-projected-secrets-456a3bbe-81da-4d59-ad12-dcf2ca2b15c3" satisfied condition "success or failure"
Sep 27 06:35:03.844: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-projected-secrets-456a3bbe-81da-4d59-ad12-dcf2ca2b15c3 container secret-volume-test: <nil>
STEP: delete the pod
Sep 27 06:35:03.865: INFO: Waiting for pod pod-projected-secrets-456a3bbe-81da-4d59-ad12-dcf2ca2b15c3 to disappear
Sep 27 06:35:03.867: INFO: Pod pod-projected-secrets-456a3bbe-81da-4d59-ad12-dcf2ca2b15c3 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:35:03.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3644" for this suite.
Sep 27 06:35:09.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:35:09.965: INFO: namespace projected-3644 deletion completed in 6.092933262s

• [SLOW TEST:8.316 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:35:09.965: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5139
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0927 06:35:10.691074      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 27 06:35:10.691: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:35:10.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5139" for this suite.
Sep 27 06:35:16.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:35:16.778: INFO: namespace gc-5139 deletion completed in 6.082846774s

• [SLOW TEST:6.812 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:35:16.778: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7653
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Sep 27 06:35:16.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 create -f - --namespace=kubectl-7653'
Sep 27 06:35:17.170: INFO: stderr: ""
Sep 27 06:35:17.170: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 27 06:35:17.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7653'
Sep 27 06:35:17.255: INFO: stderr: ""
Sep 27 06:35:17.255: INFO: stdout: "update-demo-nautilus-6nmw6 update-demo-nautilus-f9knv "
Sep 27 06:35:17.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods update-demo-nautilus-6nmw6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7653'
Sep 27 06:35:17.345: INFO: stderr: ""
Sep 27 06:35:17.345: INFO: stdout: ""
Sep 27 06:35:17.345: INFO: update-demo-nautilus-6nmw6 is created but not running
Sep 27 06:35:22.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7653'
Sep 27 06:35:22.434: INFO: stderr: ""
Sep 27 06:35:22.434: INFO: stdout: "update-demo-nautilus-6nmw6 update-demo-nautilus-f9knv "
Sep 27 06:35:22.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods update-demo-nautilus-6nmw6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7653'
Sep 27 06:35:22.511: INFO: stderr: ""
Sep 27 06:35:22.511: INFO: stdout: "true"
Sep 27 06:35:22.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods update-demo-nautilus-6nmw6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7653'
Sep 27 06:35:22.595: INFO: stderr: ""
Sep 27 06:35:22.595: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 27 06:35:22.595: INFO: validating pod update-demo-nautilus-6nmw6
Sep 27 06:35:22.602: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 27 06:35:22.602: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 27 06:35:22.602: INFO: update-demo-nautilus-6nmw6 is verified up and running
Sep 27 06:35:22.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods update-demo-nautilus-f9knv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7653'
Sep 27 06:35:22.688: INFO: stderr: ""
Sep 27 06:35:22.688: INFO: stdout: "true"
Sep 27 06:35:22.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods update-demo-nautilus-f9knv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7653'
Sep 27 06:35:22.768: INFO: stderr: ""
Sep 27 06:35:22.768: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 27 06:35:22.768: INFO: validating pod update-demo-nautilus-f9knv
Sep 27 06:35:22.773: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 27 06:35:22.773: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 27 06:35:22.773: INFO: update-demo-nautilus-f9knv is verified up and running
STEP: rolling-update to new replication controller
Sep 27 06:35:22.774: INFO: scanned /root for discovery docs: <nil>
Sep 27 06:35:22.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-7653'
Sep 27 06:35:45.207: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep 27 06:35:45.207: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 27 06:35:45.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7653'
Sep 27 06:35:45.296: INFO: stderr: ""
Sep 27 06:35:45.296: INFO: stdout: "update-demo-kitten-d9x7j update-demo-kitten-vf9ht "
Sep 27 06:35:45.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods update-demo-kitten-d9x7j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7653'
Sep 27 06:35:45.374: INFO: stderr: ""
Sep 27 06:35:45.374: INFO: stdout: "true"
Sep 27 06:35:45.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods update-demo-kitten-d9x7j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7653'
Sep 27 06:35:45.452: INFO: stderr: ""
Sep 27 06:35:45.452: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep 27 06:35:45.452: INFO: validating pod update-demo-kitten-d9x7j
Sep 27 06:35:45.460: INFO: got data: {
  "image": "kitten.jpg"
}

Sep 27 06:35:45.460: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep 27 06:35:45.460: INFO: update-demo-kitten-d9x7j is verified up and running
Sep 27 06:35:45.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods update-demo-kitten-vf9ht -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7653'
Sep 27 06:35:45.542: INFO: stderr: ""
Sep 27 06:35:45.542: INFO: stdout: "true"
Sep 27 06:35:45.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods update-demo-kitten-vf9ht -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7653'
Sep 27 06:35:45.625: INFO: stderr: ""
Sep 27 06:35:45.625: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep 27 06:35:45.625: INFO: validating pod update-demo-kitten-vf9ht
Sep 27 06:35:45.638: INFO: got data: {
  "image": "kitten.jpg"
}

Sep 27 06:35:45.638: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep 27 06:35:45.638: INFO: update-demo-kitten-vf9ht is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:35:45.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7653" for this suite.
Sep 27 06:36:07.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:36:07.754: INFO: namespace kubectl-7653 deletion completed in 22.10324975s

• [SLOW TEST:50.977 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:36:07.755: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6674
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-6674
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-6674
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6674
Sep 27 06:36:07.932: INFO: Found 0 stateful pods, waiting for 1
Sep 27 06:36:17.936: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Sep 27 06:36:17.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 exec --namespace=statefulset-6674 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 27 06:36:18.116: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 27 06:36:18.116: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 27 06:36:18.116: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 27 06:36:18.119: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep 27 06:36:28.122: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 27 06:36:28.122: INFO: Waiting for statefulset status.replicas updated to 0
Sep 27 06:36:28.135: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999725s
Sep 27 06:36:29.138: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997433368s
Sep 27 06:36:30.141: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.994375784s
Sep 27 06:36:31.144: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.991116558s
Sep 27 06:36:32.147: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.987828621s
Sep 27 06:36:33.151: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.984739616s
Sep 27 06:36:34.154: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.981430867s
Sep 27 06:36:35.157: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.978157606s
Sep 27 06:36:36.161: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.974959292s
Sep 27 06:36:37.164: INFO: Verifying statefulset ss doesn't scale past 1 for another 971.46246ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6674
Sep 27 06:36:38.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 exec --namespace=statefulset-6674 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 27 06:36:38.346: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 27 06:36:38.346: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 27 06:36:38.346: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 27 06:36:38.349: INFO: Found 1 stateful pods, waiting for 3
Sep 27 06:36:48.357: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 27 06:36:48.357: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 27 06:36:48.357: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Sep 27 06:36:48.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 exec --namespace=statefulset-6674 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 27 06:36:48.594: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 27 06:36:48.594: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 27 06:36:48.594: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 27 06:36:48.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 exec --namespace=statefulset-6674 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 27 06:36:48.878: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 27 06:36:48.878: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 27 06:36:48.878: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 27 06:36:48.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 exec --namespace=statefulset-6674 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 27 06:36:49.136: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 27 06:36:49.136: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 27 06:36:49.136: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 27 06:36:49.136: INFO: Waiting for statefulset status.replicas updated to 0
Sep 27 06:36:49.146: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Sep 27 06:36:59.158: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 27 06:36:59.158: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep 27 06:36:59.158: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep 27 06:36:59.171: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999308s
Sep 27 06:37:00.175: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995861415s
Sep 27 06:37:01.178: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992484386s
Sep 27 06:37:02.182: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989120738s
Sep 27 06:37:03.186: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.984930521s
Sep 27 06:37:04.189: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.981495776s
Sep 27 06:37:05.193: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.978330443s
Sep 27 06:37:06.196: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.97468937s
Sep 27 06:37:07.199: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.97135004s
Sep 27 06:37:08.203: INFO: Verifying statefulset ss doesn't scale past 3 for another 967.948604ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6674
Sep 27 06:37:09.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 exec --namespace=statefulset-6674 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 27 06:37:09.395: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 27 06:37:09.395: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 27 06:37:09.395: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 27 06:37:09.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 exec --namespace=statefulset-6674 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 27 06:37:09.583: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 27 06:37:09.583: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 27 06:37:09.583: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 27 06:37:09.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 exec --namespace=statefulset-6674 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 27 06:37:09.763: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 27 06:37:09.763: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 27 06:37:09.763: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 27 06:37:09.763: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep 27 06:37:39.786: INFO: Deleting all statefulset in ns statefulset-6674
Sep 27 06:37:39.789: INFO: Scaling statefulset ss to 0
Sep 27 06:37:39.802: INFO: Waiting for statefulset status.replicas updated to 0
Sep 27 06:37:39.805: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:37:39.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6674" for this suite.
Sep 27 06:37:45.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:37:45.927: INFO: namespace statefulset-6674 deletion completed in 6.102918826s

• [SLOW TEST:98.172 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:37:45.928: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9226
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-e28f029d-7ca4-433d-8272-97a535e4d450 in namespace container-probe-9226
Sep 27 06:37:48.094: INFO: Started pod liveness-e28f029d-7ca4-433d-8272-97a535e4d450 in namespace container-probe-9226
STEP: checking the pod's current state and verifying that restartCount is present
Sep 27 06:37:48.096: INFO: Initial restart count of pod liveness-e28f029d-7ca4-433d-8272-97a535e4d450 is 0
Sep 27 06:38:06.130: INFO: Restart count of pod container-probe-9226/liveness-e28f029d-7ca4-433d-8272-97a535e4d450 is now 1 (18.034029706s elapsed)
Sep 27 06:38:28.177: INFO: Restart count of pod container-probe-9226/liveness-e28f029d-7ca4-433d-8272-97a535e4d450 is now 2 (40.080218502s elapsed)
Sep 27 06:38:48.215: INFO: Restart count of pod container-probe-9226/liveness-e28f029d-7ca4-433d-8272-97a535e4d450 is now 3 (1m0.118128326s elapsed)
Sep 27 06:39:08.244: INFO: Restart count of pod container-probe-9226/liveness-e28f029d-7ca4-433d-8272-97a535e4d450 is now 4 (1m20.147268873s elapsed)
Sep 27 06:40:16.358: INFO: Restart count of pod container-probe-9226/liveness-e28f029d-7ca4-433d-8272-97a535e4d450 is now 5 (2m28.261356588s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:40:16.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9226" for this suite.
Sep 27 06:40:22.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:40:22.481: INFO: namespace container-probe-9226 deletion completed in 6.100717616s

• [SLOW TEST:156.554 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:40:22.482: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3261
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-3261
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-3261
STEP: Creating statefulset with conflicting port in namespace statefulset-3261
STEP: Waiting until pod test-pod will start running in namespace statefulset-3261
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3261
Sep 27 06:40:24.659: INFO: Observed stateful pod in namespace: statefulset-3261, name: ss-0, uid: f9ea0c06-9d8d-4cc2-a183-49496bd45f6f, status phase: Pending. Waiting for statefulset controller to delete.
Sep 27 06:40:29.967: INFO: Observed stateful pod in namespace: statefulset-3261, name: ss-0, uid: f9ea0c06-9d8d-4cc2-a183-49496bd45f6f, status phase: Failed. Waiting for statefulset controller to delete.
Sep 27 06:40:29.974: INFO: Observed stateful pod in namespace: statefulset-3261, name: ss-0, uid: f9ea0c06-9d8d-4cc2-a183-49496bd45f6f, status phase: Failed. Waiting for statefulset controller to delete.
Sep 27 06:40:29.980: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3261
STEP: Removing pod with conflicting port in namespace statefulset-3261
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3261 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep 27 06:40:32.002: INFO: Deleting all statefulset in ns statefulset-3261
Sep 27 06:40:32.005: INFO: Scaling statefulset ss to 0
Sep 27 06:40:42.018: INFO: Waiting for statefulset status.replicas updated to 0
Sep 27 06:40:42.021: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:40:42.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3261" for this suite.
Sep 27 06:40:48.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:40:48.148: INFO: namespace statefulset-3261 deletion completed in 6.106394268s

• [SLOW TEST:25.666 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:40:48.148: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8246
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Sep 27 06:41:28.326: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:41:28.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0927 06:41:28.326329      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-8246" for this suite.
Sep 27 06:41:34.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:41:34.423: INFO: namespace gc-8246 deletion completed in 6.093114702s

• [SLOW TEST:46.276 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:41:34.424: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-730
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 27 06:41:35.629: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:41:35.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-730" for this suite.
Sep 27 06:41:41.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:41:41.742: INFO: namespace container-runtime-730 deletion completed in 6.094551475s

• [SLOW TEST:7.319 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:41:41.743: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5201
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-b95351d7-0627-491f-a257-63f21edd2813 in namespace container-probe-5201
Sep 27 06:41:43.907: INFO: Started pod liveness-b95351d7-0627-491f-a257-63f21edd2813 in namespace container-probe-5201
STEP: checking the pod's current state and verifying that restartCount is present
Sep 27 06:41:43.909: INFO: Initial restart count of pod liveness-b95351d7-0627-491f-a257-63f21edd2813 is 0
Sep 27 06:42:01.943: INFO: Restart count of pod container-probe-5201/liveness-b95351d7-0627-491f-a257-63f21edd2813 is now 1 (18.033232819s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:42:01.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5201" for this suite.
Sep 27 06:42:07.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:42:08.055: INFO: namespace container-probe-5201 deletion completed in 6.095688312s

• [SLOW TEST:26.312 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:42:08.055: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5098
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Sep 27 06:42:10.726: INFO: Successfully updated pod "annotationupdate60375ecd-ee0a-4a4c-92e5-10f132eb11b2"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:42:14.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5098" for this suite.
Sep 27 06:42:36.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:42:36.850: INFO: namespace downward-api-5098 deletion completed in 22.096988561s

• [SLOW TEST:28.796 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:42:36.850: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8566
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-e6f793ab-5b54-47a9-be68-f08e9fb04012
STEP: Creating configMap with name cm-test-opt-upd-2369fe70-1ad8-4e38-992a-73444e102620
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-e6f793ab-5b54-47a9-be68-f08e9fb04012
STEP: Updating configmap cm-test-opt-upd-2369fe70-1ad8-4e38-992a-73444e102620
STEP: Creating configMap with name cm-test-opt-create-1ea85e69-49ce-4d73-af58-438c5bd78ff4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:42:41.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8566" for this suite.
Sep 27 06:43:03.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:43:03.188: INFO: namespace configmap-8566 deletion completed in 22.110650278s

• [SLOW TEST:26.338 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:43:03.189: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9151
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 06:43:03.347: INFO: Pod name rollover-pod: Found 0 pods out of 1
Sep 27 06:43:08.350: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 27 06:43:08.350: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Sep 27 06:43:10.354: INFO: Creating deployment "test-rollover-deployment"
Sep 27 06:43:10.362: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Sep 27 06:43:12.370: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Sep 27 06:43:12.377: INFO: Ensure that both replica sets have 1 created replica
Sep 27 06:43:12.382: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Sep 27 06:43:12.395: INFO: Updating deployment test-rollover-deployment
Sep 27 06:43:12.395: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Sep 27 06:43:14.404: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Sep 27 06:43:14.410: INFO: Make sure deployment "test-rollover-deployment" is complete
Sep 27 06:43:14.419: INFO: all replica sets need to contain the pod-template-hash label
Sep 27 06:43:14.419: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705163390, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705163390, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705163393, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705163390, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 27 06:43:16.428: INFO: all replica sets need to contain the pod-template-hash label
Sep 27 06:43:16.428: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705163390, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705163390, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705163393, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705163390, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 27 06:43:18.425: INFO: all replica sets need to contain the pod-template-hash label
Sep 27 06:43:18.425: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705163390, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705163390, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705163393, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705163390, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 27 06:43:20.426: INFO: all replica sets need to contain the pod-template-hash label
Sep 27 06:43:20.426: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705163390, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705163390, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705163393, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705163390, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 27 06:43:22.425: INFO: all replica sets need to contain the pod-template-hash label
Sep 27 06:43:22.425: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705163390, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705163390, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705163393, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705163390, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 27 06:43:24.425: INFO: 
Sep 27 06:43:24.425: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Sep 27 06:43:24.434: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-9151,SelfLink:/apis/apps/v1/namespaces/deployment-9151/deployments/test-rollover-deployment,UID:46cf300b-5230-443e-ad19-ef3a69b82c09,ResourceVersion:22546,Generation:2,CreationTimestamp:2019-09-27 06:43:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-27 06:43:10 +0000 UTC 2019-09-27 06:43:10 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-27 06:43:23 +0000 UTC 2019-09-27 06:43:10 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep 27 06:43:24.437: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-9151,SelfLink:/apis/apps/v1/namespaces/deployment-9151/replicasets/test-rollover-deployment-854595fc44,UID:221bbb8c-64ed-4356-999d-e9b1acecb82d,ResourceVersion:22535,Generation:2,CreationTimestamp:2019-09-27 06:43:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 46cf300b-5230-443e-ad19-ef3a69b82c09 0xc003971ee7 0xc003971ee8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep 27 06:43:24.437: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Sep 27 06:43:24.437: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-9151,SelfLink:/apis/apps/v1/namespaces/deployment-9151/replicasets/test-rollover-controller,UID:083a55f9-745c-40dd-b9fa-f021a812ba08,ResourceVersion:22544,Generation:2,CreationTimestamp:2019-09-27 06:43:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 46cf300b-5230-443e-ad19-ef3a69b82c09 0xc003971e17 0xc003971e18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 27 06:43:24.437: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-9151,SelfLink:/apis/apps/v1/namespaces/deployment-9151/replicasets/test-rollover-deployment-9b8b997cf,UID:e2cc252e-1bc0-420c-a7a1-51bd6a1368ea,ResourceVersion:22504,Generation:2,CreationTimestamp:2019-09-27 06:43:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 46cf300b-5230-443e-ad19-ef3a69b82c09 0xc003971fb0 0xc003971fb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 27 06:43:24.440: INFO: Pod "test-rollover-deployment-854595fc44-mjwfs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-mjwfs,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-9151,SelfLink:/api/v1/namespaces/deployment-9151/pods/test-rollover-deployment-854595fc44-mjwfs,UID:8e1dc05c-bd7e-4b51-ac64-3e391572ce68,ResourceVersion:22510,Generation:0,CreationTimestamp:2019-09-27 06:43:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 221bbb8c-64ed-4356-999d-e9b1acecb82d 0xc002b464d7 0xc002b464d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-92plw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92plw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-92plw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker3.dev-bj.kubeoperator.io,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:12 +0000 UTC  }],Message:,Reason:,HostIP:172.16.10.234,PodIP:172.20.5.172,StartTime:2019-09-27 06:43:12 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-27 06:43:13 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker://sha256:e4423e943a205fe1d81768e60603c8f2c5821576bad0801c1e91b8ba586124a0 docker://f234f2fd3cfa7c25bae3c0f4c95f81fad90df55a025655bf43705df7bf902bf6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:43:24.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9151" for this suite.
Sep 27 06:43:30.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:43:30.528: INFO: namespace deployment-9151 deletion completed in 6.084593212s

• [SLOW TEST:27.340 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:43:30.528: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5284
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep 27 06:43:30.673: INFO: Waiting up to 5m0s for pod "pod-db2e5d7a-7e73-47e4-a38f-f575d03863a3" in namespace "emptydir-5284" to be "success or failure"
Sep 27 06:43:30.675: INFO: Pod "pod-db2e5d7a-7e73-47e4-a38f-f575d03863a3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.264107ms
Sep 27 06:43:32.681: INFO: Pod "pod-db2e5d7a-7e73-47e4-a38f-f575d03863a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007838588s
STEP: Saw pod success
Sep 27 06:43:32.681: INFO: Pod "pod-db2e5d7a-7e73-47e4-a38f-f575d03863a3" satisfied condition "success or failure"
Sep 27 06:43:32.684: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-db2e5d7a-7e73-47e4-a38f-f575d03863a3 container test-container: <nil>
STEP: delete the pod
Sep 27 06:43:32.711: INFO: Waiting for pod pod-db2e5d7a-7e73-47e4-a38f-f575d03863a3 to disappear
Sep 27 06:43:32.713: INFO: Pod pod-db2e5d7a-7e73-47e4-a38f-f575d03863a3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:43:32.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5284" for this suite.
Sep 27 06:43:38.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:43:38.811: INFO: namespace emptydir-5284 deletion completed in 6.093421257s

• [SLOW TEST:8.283 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:43:38.811: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3969
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep 27 06:43:38.957: INFO: Waiting up to 5m0s for pod "pod-f27584b8-7f44-4ad7-b03c-c0ed1129650a" in namespace "emptydir-3969" to be "success or failure"
Sep 27 06:43:38.965: INFO: Pod "pod-f27584b8-7f44-4ad7-b03c-c0ed1129650a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.477339ms
Sep 27 06:43:40.968: INFO: Pod "pod-f27584b8-7f44-4ad7-b03c-c0ed1129650a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010669376s
STEP: Saw pod success
Sep 27 06:43:40.968: INFO: Pod "pod-f27584b8-7f44-4ad7-b03c-c0ed1129650a" satisfied condition "success or failure"
Sep 27 06:43:40.970: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-f27584b8-7f44-4ad7-b03c-c0ed1129650a container test-container: <nil>
STEP: delete the pod
Sep 27 06:43:40.990: INFO: Waiting for pod pod-f27584b8-7f44-4ad7-b03c-c0ed1129650a to disappear
Sep 27 06:43:40.993: INFO: Pod pod-f27584b8-7f44-4ad7-b03c-c0ed1129650a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:43:40.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3969" for this suite.
Sep 27 06:43:47.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:43:47.076: INFO: namespace emptydir-3969 deletion completed in 6.078833544s

• [SLOW TEST:8.265 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:43:47.076: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8358
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-8358/secret-test-96b0e75b-a981-405d-a835-0017c6c54ec2
STEP: Creating a pod to test consume secrets
Sep 27 06:43:47.234: INFO: Waiting up to 5m0s for pod "pod-configmaps-409e8e4b-dd1e-4179-a32c-96c3d391bae2" in namespace "secrets-8358" to be "success or failure"
Sep 27 06:43:47.237: INFO: Pod "pod-configmaps-409e8e4b-dd1e-4179-a32c-96c3d391bae2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.915976ms
Sep 27 06:43:49.240: INFO: Pod "pod-configmaps-409e8e4b-dd1e-4179-a32c-96c3d391bae2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005944401s
STEP: Saw pod success
Sep 27 06:43:49.240: INFO: Pod "pod-configmaps-409e8e4b-dd1e-4179-a32c-96c3d391bae2" satisfied condition "success or failure"
Sep 27 06:43:49.242: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-configmaps-409e8e4b-dd1e-4179-a32c-96c3d391bae2 container env-test: <nil>
STEP: delete the pod
Sep 27 06:43:49.263: INFO: Waiting for pod pod-configmaps-409e8e4b-dd1e-4179-a32c-96c3d391bae2 to disappear
Sep 27 06:43:49.265: INFO: Pod pod-configmaps-409e8e4b-dd1e-4179-a32c-96c3d391bae2 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:43:49.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8358" for this suite.
Sep 27 06:43:55.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:43:55.354: INFO: namespace secrets-8358 deletion completed in 6.085218319s

• [SLOW TEST:8.278 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:43:55.355: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9448
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 06:43:55.492: INFO: Creating deployment "nginx-deployment"
Sep 27 06:43:55.498: INFO: Waiting for observed generation 1
Sep 27 06:43:57.506: INFO: Waiting for all required pods to come up
Sep 27 06:43:57.510: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Sep 27 06:43:59.518: INFO: Waiting for deployment "nginx-deployment" to complete
Sep 27 06:43:59.523: INFO: Updating deployment "nginx-deployment" with a non-existent image
Sep 27 06:43:59.531: INFO: Updating deployment nginx-deployment
Sep 27 06:43:59.531: INFO: Waiting for observed generation 2
Sep 27 06:44:01.537: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Sep 27 06:44:01.540: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Sep 27 06:44:01.542: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep 27 06:44:01.548: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Sep 27 06:44:01.548: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Sep 27 06:44:01.550: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep 27 06:44:01.554: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Sep 27 06:44:01.554: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Sep 27 06:44:01.561: INFO: Updating deployment nginx-deployment
Sep 27 06:44:01.561: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Sep 27 06:44:01.568: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Sep 27 06:44:01.571: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Sep 27 06:44:01.592: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-9448,SelfLink:/apis/apps/v1/namespaces/deployment-9448/deployments/nginx-deployment,UID:a8daffdc-d20d-4dec-a0ce-a4b8459a61bd,ResourceVersion:22915,Generation:3,CreationTimestamp:2019-09-27 06:43:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Progressing True 2019-09-27 06:43:59 +0000 UTC 2019-09-27 06:43:55 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.} {Available False 2019-09-27 06:44:01 +0000 UTC 2019-09-27 06:44:01 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Sep 27 06:44:01.601: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-9448,SelfLink:/apis/apps/v1/namespaces/deployment-9448/replicasets/nginx-deployment-55fb7cb77f,UID:b1145f3e-40c5-4c19-92fd-f3455320e8ce,ResourceVersion:22912,Generation:3,CreationTimestamp:2019-09-27 06:43:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment a8daffdc-d20d-4dec-a0ce-a4b8459a61bd 0xc00245bad7 0xc00245bad8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 27 06:44:01.601: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Sep 27 06:44:01.602: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-9448,SelfLink:/apis/apps/v1/namespaces/deployment-9448/replicasets/nginx-deployment-7b8c6f4498,UID:ec43c57a-5f2f-4a25-a225-640655b9cee2,ResourceVersion:22910,Generation:3,CreationTimestamp:2019-09-27 06:43:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment a8daffdc-d20d-4dec-a0ce-a4b8459a61bd 0xc00245bbc7 0xc00245bbc8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Sep 27 06:44:01.606: INFO: Pod "nginx-deployment-55fb7cb77f-69xnc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-69xnc,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-9448,SelfLink:/api/v1/namespaces/deployment-9448/pods/nginx-deployment-55fb7cb77f-69xnc,UID:be711a69-f6e1-46ca-bd85-3131026ef2fe,ResourceVersion:22891,Generation:0,CreationTimestamp:2019-09-27 06:43:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f b1145f3e-40c5-4c19-92fd-f3455320e8ce 0xc003a20d37 0xc003a20d38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l89bw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l89bw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l89bw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker3.dev-bj.kubeoperator.io,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:59 +0000 UTC  }],Message:,Reason:,HostIP:172.16.10.234,PodIP:,StartTime:2019-09-27 06:43:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 06:44:01.607: INFO: Pod "nginx-deployment-55fb7cb77f-kg8d8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-kg8d8,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-9448,SelfLink:/api/v1/namespaces/deployment-9448/pods/nginx-deployment-55fb7cb77f-kg8d8,UID:faf9ace9-cef1-4bf6-80a7-33f1a3a872d5,ResourceVersion:22893,Generation:0,CreationTimestamp:2019-09-27 06:43:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f b1145f3e-40c5-4c19-92fd-f3455320e8ce 0xc003a20e70 0xc003a20e71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l89bw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l89bw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l89bw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1.dev-bj.kubeoperator.io,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:59 +0000 UTC  }],Message:,Reason:,HostIP:172.16.10.236,PodIP:,StartTime:2019-09-27 06:43:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 06:44:01.607: INFO: Pod "nginx-deployment-55fb7cb77f-qxgxh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-qxgxh,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-9448,SelfLink:/api/v1/namespaces/deployment-9448/pods/nginx-deployment-55fb7cb77f-qxgxh,UID:0785bc15-a232-409d-a492-e05abd1001e6,ResourceVersion:22855,Generation:0,CreationTimestamp:2019-09-27 06:43:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f b1145f3e-40c5-4c19-92fd-f3455320e8ce 0xc003a20f90 0xc003a20f91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l89bw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l89bw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l89bw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker3.dev-bj.kubeoperator.io,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:59 +0000 UTC  }],Message:,Reason:,HostIP:172.16.10.234,PodIP:,StartTime:2019-09-27 06:43:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 06:44:01.607: INFO: Pod "nginx-deployment-55fb7cb77f-tx7zh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-tx7zh,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-9448,SelfLink:/api/v1/namespaces/deployment-9448/pods/nginx-deployment-55fb7cb77f-tx7zh,UID:0d239c6c-58b3-41ed-a244-3660c2d1df32,ResourceVersion:22872,Generation:0,CreationTimestamp:2019-09-27 06:43:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f b1145f3e-40c5-4c19-92fd-f3455320e8ce 0xc003a210b0 0xc003a210b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l89bw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l89bw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l89bw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2.dev-bj.kubeoperator.io,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:59 +0000 UTC  }],Message:,Reason:,HostIP:172.16.10.231,PodIP:,StartTime:2019-09-27 06:43:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 06:44:01.607: INFO: Pod "nginx-deployment-55fb7cb77f-z8qcb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-z8qcb,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-9448,SelfLink:/api/v1/namespaces/deployment-9448/pods/nginx-deployment-55fb7cb77f-z8qcb,UID:d8d4d19c-a8c7-4b5c-8401-1d24e69af397,ResourceVersion:22923,Generation:0,CreationTimestamp:2019-09-27 06:44:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f b1145f3e-40c5-4c19-92fd-f3455320e8ce 0xc003a211d0 0xc003a211d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l89bw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l89bw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l89bw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2.dev-bj.kubeoperator.io,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:44:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 06:44:01.607: INFO: Pod "nginx-deployment-55fb7cb77f-zvks5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-zvks5,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-9448,SelfLink:/api/v1/namespaces/deployment-9448/pods/nginx-deployment-55fb7cb77f-zvks5,UID:9f0b2db4-4e77-4685-bbfb-76361f5528f9,ResourceVersion:22861,Generation:0,CreationTimestamp:2019-09-27 06:43:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f b1145f3e-40c5-4c19-92fd-f3455320e8ce 0xc003a212a0 0xc003a212a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l89bw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l89bw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l89bw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1.dev-bj.kubeoperator.io,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:59 +0000 UTC  }],Message:,Reason:,HostIP:172.16.10.236,PodIP:,StartTime:2019-09-27 06:43:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 06:44:01.607: INFO: Pod "nginx-deployment-7b8c6f4498-2gnnb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-2gnnb,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9448,SelfLink:/api/v1/namespaces/deployment-9448/pods/nginx-deployment-7b8c6f4498-2gnnb,UID:b7a2a6e8-4b21-470e-8b66-170e86ef5139,ResourceVersion:22830,Generation:0,CreationTimestamp:2019-09-27 06:43:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec43c57a-5f2f-4a25-a225-640655b9cee2 0xc003a213c0 0xc003a213c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l89bw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l89bw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l89bw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker3.dev-bj.kubeoperator.io,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:55 +0000 UTC  }],Message:,Reason:,HostIP:172.16.10.234,PodIP:172.20.5.177,StartTime:2019-09-27 06:43:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-27 06:43:56 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker://sha256:8a2fb25a19f5dc1528b7a3fabe8b3145ff57fe10e4f1edac6c718a3cf4aa4b73 docker://ef1c181083ab38764f3349931b5a5158de42d22a78ddc5c8091073b7832a8f52}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 06:44:01.607: INFO: Pod "nginx-deployment-7b8c6f4498-b974j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-b974j,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9448,SelfLink:/api/v1/namespaces/deployment-9448/pods/nginx-deployment-7b8c6f4498-b974j,UID:a327ef39-7001-48bd-aaf5-c9f5d3598a8e,ResourceVersion:22924,Generation:0,CreationTimestamp:2019-09-27 06:44:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec43c57a-5f2f-4a25-a225-640655b9cee2 0xc003a214d7 0xc003a214d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l89bw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l89bw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l89bw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1.dev-bj.kubeoperator.io,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:44:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 06:44:01.608: INFO: Pod "nginx-deployment-7b8c6f4498-g6fql" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-g6fql,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9448,SelfLink:/api/v1/namespaces/deployment-9448/pods/nginx-deployment-7b8c6f4498-g6fql,UID:325e8f28-eafb-4877-bbae-faa8196754d0,ResourceVersion:22821,Generation:0,CreationTimestamp:2019-09-27 06:43:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec43c57a-5f2f-4a25-a225-640655b9cee2 0xc003a215a0 0xc003a215a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l89bw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l89bw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l89bw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2.dev-bj.kubeoperator.io,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:55 +0000 UTC  }],Message:,Reason:,HostIP:172.16.10.231,PodIP:172.20.4.32,StartTime:2019-09-27 06:43:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-27 06:43:56 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker://sha256:8a2fb25a19f5dc1528b7a3fabe8b3145ff57fe10e4f1edac6c718a3cf4aa4b73 docker://468be140e8b537d2cc68f574c45514b2fe2bc25a551c1cb7c3ae249c4f1e1db4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 06:44:01.608: INFO: Pod "nginx-deployment-7b8c6f4498-jd74k" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-jd74k,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9448,SelfLink:/api/v1/namespaces/deployment-9448/pods/nginx-deployment-7b8c6f4498-jd74k,UID:98a07af2-5bf9-49a5-9791-51e1b31fef28,ResourceVersion:22832,Generation:0,CreationTimestamp:2019-09-27 06:43:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec43c57a-5f2f-4a25-a225-640655b9cee2 0xc003a216b0 0xc003a216b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l89bw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l89bw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l89bw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker3.dev-bj.kubeoperator.io,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:55 +0000 UTC  }],Message:,Reason:,HostIP:172.16.10.234,PodIP:172.20.5.178,StartTime:2019-09-27 06:43:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-27 06:43:56 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker://sha256:8a2fb25a19f5dc1528b7a3fabe8b3145ff57fe10e4f1edac6c718a3cf4aa4b73 docker://d70a936265492a13709e7fd75700df92923af5c3bc671a0f2319fe16805b5ba3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 06:44:01.608: INFO: Pod "nginx-deployment-7b8c6f4498-n9v9h" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-n9v9h,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9448,SelfLink:/api/v1/namespaces/deployment-9448/pods/nginx-deployment-7b8c6f4498-n9v9h,UID:788c8fd9-7da7-4c17-bab0-e48287c7899e,ResourceVersion:22811,Generation:0,CreationTimestamp:2019-09-27 06:43:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec43c57a-5f2f-4a25-a225-640655b9cee2 0xc003a217c7 0xc003a217c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l89bw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l89bw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l89bw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1.dev-bj.kubeoperator.io,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:56 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:55 +0000 UTC  }],Message:,Reason:,HostIP:172.16.10.236,PodIP:172.20.3.54,StartTime:2019-09-27 06:43:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-27 06:43:56 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker://sha256:8a2fb25a19f5dc1528b7a3fabe8b3145ff57fe10e4f1edac6c718a3cf4aa4b73 docker://35dbced5fcd29e467b5c69398a9631efa4502771727760e18a4ff8335c2f2f93}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 06:44:01.608: INFO: Pod "nginx-deployment-7b8c6f4498-sk2s5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-sk2s5,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9448,SelfLink:/api/v1/namespaces/deployment-9448/pods/nginx-deployment-7b8c6f4498-sk2s5,UID:d5ff3018-652e-4e1d-a3dc-218a2fb32f07,ResourceVersion:22808,Generation:0,CreationTimestamp:2019-09-27 06:43:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec43c57a-5f2f-4a25-a225-640655b9cee2 0xc003a218f0 0xc003a218f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l89bw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l89bw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l89bw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1.dev-bj.kubeoperator.io,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:56 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:55 +0000 UTC  }],Message:,Reason:,HostIP:172.16.10.236,PodIP:172.20.3.56,StartTime:2019-09-27 06:43:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-27 06:43:56 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker://sha256:8a2fb25a19f5dc1528b7a3fabe8b3145ff57fe10e4f1edac6c718a3cf4aa4b73 docker://f0098e651bb7c7041dd669f6090f5c3d869d2e6a95b544b4e38c2b05b1e82a24}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 06:44:01.608: INFO: Pod "nginx-deployment-7b8c6f4498-ttrxb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-ttrxb,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9448,SelfLink:/api/v1/namespaces/deployment-9448/pods/nginx-deployment-7b8c6f4498-ttrxb,UID:97e77fa3-29e0-4bed-ab11-2910d80984a9,ResourceVersion:22914,Generation:0,CreationTimestamp:2019-09-27 06:44:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec43c57a-5f2f-4a25-a225-640655b9cee2 0xc003a21a10 0xc003a21a11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l89bw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l89bw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l89bw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2.dev-bj.kubeoperator.io,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:44:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 06:44:01.609: INFO: Pod "nginx-deployment-7b8c6f4498-vh746" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-vh746,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9448,SelfLink:/api/v1/namespaces/deployment-9448/pods/nginx-deployment-7b8c6f4498-vh746,UID:18dd97a8-26ae-4716-9605-45a90417350c,ResourceVersion:22824,Generation:0,CreationTimestamp:2019-09-27 06:43:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec43c57a-5f2f-4a25-a225-640655b9cee2 0xc003a21ae0 0xc003a21ae1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l89bw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l89bw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l89bw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker3.dev-bj.kubeoperator.io,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:55 +0000 UTC  }],Message:,Reason:,HostIP:172.16.10.234,PodIP:172.20.5.176,StartTime:2019-09-27 06:43:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-27 06:43:56 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker://sha256:8a2fb25a19f5dc1528b7a3fabe8b3145ff57fe10e4f1edac6c718a3cf4aa4b73 docker://523d791d167c7f7e47a43977ca7215864bdcb9586829cb1f7254fefbfa1d2c86}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 06:44:01.609: INFO: Pod "nginx-deployment-7b8c6f4498-wd68j" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-wd68j,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9448,SelfLink:/api/v1/namespaces/deployment-9448/pods/nginx-deployment-7b8c6f4498-wd68j,UID:b7d9d6a5-3226-4168-bf92-5f9be2d13da0,ResourceVersion:22813,Generation:0,CreationTimestamp:2019-09-27 06:43:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec43c57a-5f2f-4a25-a225-640655b9cee2 0xc003a21bf7 0xc003a21bf8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l89bw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l89bw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l89bw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1.dev-bj.kubeoperator.io,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:56 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:55 +0000 UTC  }],Message:,Reason:,HostIP:172.16.10.236,PodIP:172.20.3.55,StartTime:2019-09-27 06:43:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-27 06:43:56 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker://sha256:8a2fb25a19f5dc1528b7a3fabe8b3145ff57fe10e4f1edac6c718a3cf4aa4b73 docker://8ac542bdbe7249d2d1ebcfadbc3eb68e07731b9f2f44863d6617f2cf84186332}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 06:44:01.609: INFO: Pod "nginx-deployment-7b8c6f4498-zhnkr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-zhnkr,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9448,SelfLink:/api/v1/namespaces/deployment-9448/pods/nginx-deployment-7b8c6f4498-zhnkr,UID:9466dc25-47cc-45d2-9b53-7fc6a0f4a5b4,ResourceVersion:22925,Generation:0,CreationTimestamp:2019-09-27 06:44:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec43c57a-5f2f-4a25-a225-640655b9cee2 0xc003a21d10 0xc003a21d11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l89bw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l89bw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l89bw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2.dev-bj.kubeoperator.io,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:44:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 06:44:01.609: INFO: Pod "nginx-deployment-7b8c6f4498-zrgf2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-zrgf2,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9448,SelfLink:/api/v1/namespaces/deployment-9448/pods/nginx-deployment-7b8c6f4498-zrgf2,UID:c3bbf858-c87b-4051-8cbc-9c4945d7e4b6,ResourceVersion:22826,Generation:0,CreationTimestamp:2019-09-27 06:43:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ec43c57a-5f2f-4a25-a225-640655b9cee2 0xc003a21e00 0xc003a21e01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l89bw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l89bw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l89bw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker3.dev-bj.kubeoperator.io,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:43:55 +0000 UTC  }],Message:,Reason:,HostIP:172.16.10.234,PodIP:172.20.5.179,StartTime:2019-09-27 06:43:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-27 06:43:56 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker://sha256:8a2fb25a19f5dc1528b7a3fabe8b3145ff57fe10e4f1edac6c718a3cf4aa4b73 docker://d9c6d18d3279b7cf587759ebf86807926f0172cbd4426f6a20da94cfb7e5d1a9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:44:01.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9448" for this suite.
Sep 27 06:44:09.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:44:09.801: INFO: namespace deployment-9448 deletion completed in 8.18622216s

• [SLOW TEST:14.446 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:44:09.801: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6903
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:44:15.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6903" for this suite.
Sep 27 06:44:21.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:44:21.705: INFO: namespace watch-6903 deletion completed in 6.196444163s

• [SLOW TEST:11.904 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:44:21.705: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3957
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-5aafcee8-3af0-4d32-9f85-0bd7a94d753d
STEP: Creating a pod to test consume secrets
Sep 27 06:44:21.916: INFO: Waiting up to 5m0s for pod "pod-secrets-3695e6a5-fd80-4525-8bce-54f2495394be" in namespace "secrets-3957" to be "success or failure"
Sep 27 06:44:21.920: INFO: Pod "pod-secrets-3695e6a5-fd80-4525-8bce-54f2495394be": Phase="Pending", Reason="", readiness=false. Elapsed: 3.505984ms
Sep 27 06:44:23.923: INFO: Pod "pod-secrets-3695e6a5-fd80-4525-8bce-54f2495394be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006654037s
STEP: Saw pod success
Sep 27 06:44:23.923: INFO: Pod "pod-secrets-3695e6a5-fd80-4525-8bce-54f2495394be" satisfied condition "success or failure"
Sep 27 06:44:23.925: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-secrets-3695e6a5-fd80-4525-8bce-54f2495394be container secret-volume-test: <nil>
STEP: delete the pod
Sep 27 06:44:23.944: INFO: Waiting for pod pod-secrets-3695e6a5-fd80-4525-8bce-54f2495394be to disappear
Sep 27 06:44:23.947: INFO: Pod pod-secrets-3695e6a5-fd80-4525-8bce-54f2495394be no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:44:23.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3957" for this suite.
Sep 27 06:44:29.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:44:30.043: INFO: namespace secrets-3957 deletion completed in 6.089299707s

• [SLOW TEST:8.337 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:44:30.043: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8245
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Sep 27 06:44:32.256: INFO: Pod pod-hostip-536e82df-a282-46bf-9ac8-f9fdcebee8a3 has hostIP: 172.16.10.234
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:44:32.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8245" for this suite.
Sep 27 06:44:46.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:44:46.371: INFO: namespace pods-8245 deletion completed in 14.109901989s

• [SLOW TEST:16.328 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:44:46.371: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8336
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Sep 27 06:44:47.178: INFO: PodSpec: initContainers in spec.initContainers
Sep 27 06:45:32.766: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-d49785bc-3796-4fc4-bdc2-6afc94b555c6", GenerateName:"", Namespace:"init-container-8336", SelfLink:"/api/v1/namespaces/init-container-8336/pods/pod-init-d49785bc-3796-4fc4-bdc2-6afc94b555c6", UID:"c6a6c2c9-b099-49e1-b971-aa327e25d5e8", ResourceVersion:"23530", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63705163487, loc:(*time.Location)(0x7ec7a20)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"178465555"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-fsmjw", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0030ba3c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fsmjw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fsmjw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fsmjw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0032d5b78), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"worker3.dev-bj.kubeoperator.io", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002d77b60), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration(nil), HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0032d5be0), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705163487, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705163487, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705163487, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705163487, loc:(*time.Location)(0x7ec7a20)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.16.10.234", PodIP:"172.20.5.187", StartTime:(*v1.Time)(0xc0010c7700), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000c7d1f0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000c7d2d0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker://sha256:758ec7f3a1ee85f8f08399b55641bfb13e8c1109287ddc5e22b68c3d653152ee", ContainerID:"docker://995ff201f23e4249b31735412b7f463cbc4d529f139ddcc3a3fdcbebb1d775cb"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0010c7780), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0010c7740), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:45:32.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8336" for this suite.
Sep 27 06:46:00.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:46:00.870: INFO: namespace init-container-8336 deletion completed in 28.096392887s

• [SLOW TEST:74.499 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:46:00.871: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8752
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Sep 27 06:46:01.038: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-8752,SelfLink:/api/v1/namespaces/watch-8752/configmaps/e2e-watch-test-resource-version,UID:2a3cd2d0-106f-4893-9988-61faec2ddff6,ResourceVersion:23604,Generation:0,CreationTimestamp:2019-09-27 06:46:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 27 06:46:01.038: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-8752,SelfLink:/api/v1/namespaces/watch-8752/configmaps/e2e-watch-test-resource-version,UID:2a3cd2d0-106f-4893-9988-61faec2ddff6,ResourceVersion:23605,Generation:0,CreationTimestamp:2019-09-27 06:46:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:46:01.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8752" for this suite.
Sep 27 06:46:07.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:46:07.138: INFO: namespace watch-8752 deletion completed in 6.095230897s

• [SLOW TEST:6.267 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:46:07.138: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-112
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Sep 27 06:46:07.287: INFO: Waiting up to 5m0s for pod "pod-0cd591a0-8c69-4399-b5da-9c58de7ef0f4" in namespace "emptydir-112" to be "success or failure"
Sep 27 06:46:07.292: INFO: Pod "pod-0cd591a0-8c69-4399-b5da-9c58de7ef0f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.870342ms
Sep 27 06:46:09.296: INFO: Pod "pod-0cd591a0-8c69-4399-b5da-9c58de7ef0f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009500532s
STEP: Saw pod success
Sep 27 06:46:09.296: INFO: Pod "pod-0cd591a0-8c69-4399-b5da-9c58de7ef0f4" satisfied condition "success or failure"
Sep 27 06:46:09.300: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-0cd591a0-8c69-4399-b5da-9c58de7ef0f4 container test-container: <nil>
STEP: delete the pod
Sep 27 06:46:09.359: INFO: Waiting for pod pod-0cd591a0-8c69-4399-b5da-9c58de7ef0f4 to disappear
Sep 27 06:46:09.363: INFO: Pod pod-0cd591a0-8c69-4399-b5da-9c58de7ef0f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:46:09.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-112" for this suite.
Sep 27 06:46:15.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:46:15.480: INFO: namespace emptydir-112 deletion completed in 6.102663416s

• [SLOW TEST:8.342 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:46:15.480: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8091
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Sep 27 06:46:15.632: INFO: Waiting up to 5m0s for pod "client-containers-5b73daad-4da5-4010-9944-fc73ec109813" in namespace "containers-8091" to be "success or failure"
Sep 27 06:46:15.637: INFO: Pod "client-containers-5b73daad-4da5-4010-9944-fc73ec109813": Phase="Pending", Reason="", readiness=false. Elapsed: 4.762216ms
Sep 27 06:46:17.640: INFO: Pod "client-containers-5b73daad-4da5-4010-9944-fc73ec109813": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007794123s
STEP: Saw pod success
Sep 27 06:46:17.640: INFO: Pod "client-containers-5b73daad-4da5-4010-9944-fc73ec109813" satisfied condition "success or failure"
Sep 27 06:46:17.642: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod client-containers-5b73daad-4da5-4010-9944-fc73ec109813 container test-container: <nil>
STEP: delete the pod
Sep 27 06:46:17.671: INFO: Waiting for pod client-containers-5b73daad-4da5-4010-9944-fc73ec109813 to disappear
Sep 27 06:46:17.674: INFO: Pod client-containers-5b73daad-4da5-4010-9944-fc73ec109813 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:46:17.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8091" for this suite.
Sep 27 06:46:23.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:46:23.780: INFO: namespace containers-8091 deletion completed in 6.100751478s

• [SLOW TEST:8.300 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:46:23.780: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5072
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-7c9ffe2c-b822-422b-add3-d900a3ce8c86
STEP: Creating secret with name s-test-opt-upd-eb8915bf-d237-4962-9125-c5d7e17091d7
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-7c9ffe2c-b822-422b-add3-d900a3ce8c86
STEP: Updating secret s-test-opt-upd-eb8915bf-d237-4962-9125-c5d7e17091d7
STEP: Creating secret with name s-test-opt-create-e146b985-77ac-401e-9104-a17bfa448ab1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:46:28.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5072" for this suite.
Sep 27 06:46:50.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:46:50.123: INFO: namespace projected-5072 deletion completed in 22.089844484s

• [SLOW TEST:26.343 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:46:50.124: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-116
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep 27 06:46:54.313: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 27 06:46:54.316: INFO: Pod pod-with-prestop-http-hook still exists
Sep 27 06:46:56.316: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 27 06:46:56.319: INFO: Pod pod-with-prestop-http-hook still exists
Sep 27 06:46:58.316: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 27 06:46:58.320: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:46:58.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-116" for this suite.
Sep 27 06:47:20.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:47:20.426: INFO: namespace container-lifecycle-hook-116 deletion completed in 22.093336411s

• [SLOW TEST:30.302 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:47:20.426: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2505
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 06:47:20.576: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ceb31402-653b-4710-94c3-9f1e429989b4" in namespace "projected-2505" to be "success or failure"
Sep 27 06:47:20.585: INFO: Pod "downwardapi-volume-ceb31402-653b-4710-94c3-9f1e429989b4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.341592ms
Sep 27 06:47:22.588: INFO: Pod "downwardapi-volume-ceb31402-653b-4710-94c3-9f1e429989b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012314556s
STEP: Saw pod success
Sep 27 06:47:22.588: INFO: Pod "downwardapi-volume-ceb31402-653b-4710-94c3-9f1e429989b4" satisfied condition "success or failure"
Sep 27 06:47:22.590: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod downwardapi-volume-ceb31402-653b-4710-94c3-9f1e429989b4 container client-container: <nil>
STEP: delete the pod
Sep 27 06:47:22.610: INFO: Waiting for pod downwardapi-volume-ceb31402-653b-4710-94c3-9f1e429989b4 to disappear
Sep 27 06:47:22.613: INFO: Pod downwardapi-volume-ceb31402-653b-4710-94c3-9f1e429989b4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:47:22.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2505" for this suite.
Sep 27 06:47:28.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:47:28.730: INFO: namespace projected-2505 deletion completed in 6.111759533s

• [SLOW TEST:8.304 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:47:28.730: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2834
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-efee570d-cef9-4ab2-8fd9-6be9dc5abca8
STEP: Creating a pod to test consume configMaps
Sep 27 06:47:28.882: INFO: Waiting up to 5m0s for pod "pod-configmaps-70913071-4cd6-407a-a486-3364eca71203" in namespace "configmap-2834" to be "success or failure"
Sep 27 06:47:28.887: INFO: Pod "pod-configmaps-70913071-4cd6-407a-a486-3364eca71203": Phase="Pending", Reason="", readiness=false. Elapsed: 5.440855ms
Sep 27 06:47:30.890: INFO: Pod "pod-configmaps-70913071-4cd6-407a-a486-3364eca71203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008406206s
STEP: Saw pod success
Sep 27 06:47:30.890: INFO: Pod "pod-configmaps-70913071-4cd6-407a-a486-3364eca71203" satisfied condition "success or failure"
Sep 27 06:47:30.892: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-configmaps-70913071-4cd6-407a-a486-3364eca71203 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 06:47:30.909: INFO: Waiting for pod pod-configmaps-70913071-4cd6-407a-a486-3364eca71203 to disappear
Sep 27 06:47:30.911: INFO: Pod pod-configmaps-70913071-4cd6-407a-a486-3364eca71203 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:47:30.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2834" for this suite.
Sep 27 06:47:36.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:47:37.015: INFO: namespace configmap-2834 deletion completed in 6.100183017s

• [SLOW TEST:8.285 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:47:37.015: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8210
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 06:47:37.179: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a89cb6a4-7061-4f01-9ab5-128b91053238" in namespace "downward-api-8210" to be "success or failure"
Sep 27 06:47:37.181: INFO: Pod "downwardapi-volume-a89cb6a4-7061-4f01-9ab5-128b91053238": Phase="Pending", Reason="", readiness=false. Elapsed: 2.186125ms
Sep 27 06:47:39.186: INFO: Pod "downwardapi-volume-a89cb6a4-7061-4f01-9ab5-128b91053238": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006826009s
STEP: Saw pod success
Sep 27 06:47:39.186: INFO: Pod "downwardapi-volume-a89cb6a4-7061-4f01-9ab5-128b91053238" satisfied condition "success or failure"
Sep 27 06:47:39.189: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod downwardapi-volume-a89cb6a4-7061-4f01-9ab5-128b91053238 container client-container: <nil>
STEP: delete the pod
Sep 27 06:47:39.218: INFO: Waiting for pod downwardapi-volume-a89cb6a4-7061-4f01-9ab5-128b91053238 to disappear
Sep 27 06:47:39.222: INFO: Pod downwardapi-volume-a89cb6a4-7061-4f01-9ab5-128b91053238 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:47:39.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8210" for this suite.
Sep 27 06:47:45.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:47:45.325: INFO: namespace downward-api-8210 deletion completed in 6.09448702s

• [SLOW TEST:8.310 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:47:45.325: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-145
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-dad83a59-17dc-4ac2-9c03-802ce150d2da
STEP: Creating a pod to test consume configMaps
Sep 27 06:47:45.474: INFO: Waiting up to 5m0s for pod "pod-configmaps-68d6c90c-48c7-4f84-89dd-b56d2413f4cf" in namespace "configmap-145" to be "success or failure"
Sep 27 06:47:45.478: INFO: Pod "pod-configmaps-68d6c90c-48c7-4f84-89dd-b56d2413f4cf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.166888ms
Sep 27 06:47:47.482: INFO: Pod "pod-configmaps-68d6c90c-48c7-4f84-89dd-b56d2413f4cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007601071s
STEP: Saw pod success
Sep 27 06:47:47.482: INFO: Pod "pod-configmaps-68d6c90c-48c7-4f84-89dd-b56d2413f4cf" satisfied condition "success or failure"
Sep 27 06:47:47.484: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-configmaps-68d6c90c-48c7-4f84-89dd-b56d2413f4cf container configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 06:47:47.502: INFO: Waiting for pod pod-configmaps-68d6c90c-48c7-4f84-89dd-b56d2413f4cf to disappear
Sep 27 06:47:47.505: INFO: Pod pod-configmaps-68d6c90c-48c7-4f84-89dd-b56d2413f4cf no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:47:47.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-145" for this suite.
Sep 27 06:47:53.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:47:53.610: INFO: namespace configmap-145 deletion completed in 6.100411362s

• [SLOW TEST:8.285 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:47:53.610: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3020
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep 27 06:47:53.755: INFO: Waiting up to 5m0s for pod "pod-fd4786ef-e9e4-4f0d-b9af-2d892560f545" in namespace "emptydir-3020" to be "success or failure"
Sep 27 06:47:53.757: INFO: Pod "pod-fd4786ef-e9e4-4f0d-b9af-2d892560f545": Phase="Pending", Reason="", readiness=false. Elapsed: 2.24472ms
Sep 27 06:47:55.761: INFO: Pod "pod-fd4786ef-e9e4-4f0d-b9af-2d892560f545": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006067829s
STEP: Saw pod success
Sep 27 06:47:55.761: INFO: Pod "pod-fd4786ef-e9e4-4f0d-b9af-2d892560f545" satisfied condition "success or failure"
Sep 27 06:47:55.764: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-fd4786ef-e9e4-4f0d-b9af-2d892560f545 container test-container: <nil>
STEP: delete the pod
Sep 27 06:47:55.784: INFO: Waiting for pod pod-fd4786ef-e9e4-4f0d-b9af-2d892560f545 to disappear
Sep 27 06:47:55.786: INFO: Pod pod-fd4786ef-e9e4-4f0d-b9af-2d892560f545 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:47:55.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3020" for this suite.
Sep 27 06:48:01.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:48:01.886: INFO: namespace emptydir-3020 deletion completed in 6.095107679s

• [SLOW TEST:8.275 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:48:01.886: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-2237
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-2237
I0927 06:48:02.033829      16 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-2237, replica count: 1
I0927 06:48:03.084233      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0927 06:48:04.084419      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 27 06:48:04.196: INFO: Created: latency-svc-5qgjr
Sep 27 06:48:04.210: INFO: Got endpoints: latency-svc-5qgjr [25.73425ms]
Sep 27 06:48:04.231: INFO: Created: latency-svc-v99sn
Sep 27 06:48:04.237: INFO: Got endpoints: latency-svc-v99sn [27.429433ms]
Sep 27 06:48:04.246: INFO: Created: latency-svc-nsqc8
Sep 27 06:48:04.255: INFO: Got endpoints: latency-svc-nsqc8 [44.488782ms]
Sep 27 06:48:04.263: INFO: Created: latency-svc-9l7s2
Sep 27 06:48:04.269: INFO: Got endpoints: latency-svc-9l7s2 [58.260243ms]
Sep 27 06:48:04.280: INFO: Created: latency-svc-8ndd9
Sep 27 06:48:04.291: INFO: Got endpoints: latency-svc-8ndd9 [81.078766ms]
Sep 27 06:48:04.304: INFO: Created: latency-svc-6rxf4
Sep 27 06:48:04.308: INFO: Got endpoints: latency-svc-6rxf4 [97.238334ms]
Sep 27 06:48:04.321: INFO: Created: latency-svc-xnhg8
Sep 27 06:48:04.335: INFO: Created: latency-svc-xs7qh
Sep 27 06:48:04.335: INFO: Got endpoints: latency-svc-xnhg8 [124.377306ms]
Sep 27 06:48:04.344: INFO: Got endpoints: latency-svc-xs7qh [133.191746ms]
Sep 27 06:48:04.349: INFO: Created: latency-svc-c4c8w
Sep 27 06:48:04.359: INFO: Got endpoints: latency-svc-c4c8w [148.676021ms]
Sep 27 06:48:04.370: INFO: Created: latency-svc-zwq6x
Sep 27 06:48:04.378: INFO: Got endpoints: latency-svc-zwq6x [167.585615ms]
Sep 27 06:48:04.391: INFO: Created: latency-svc-2h867
Sep 27 06:48:04.403: INFO: Got endpoints: latency-svc-2h867 [192.380012ms]
Sep 27 06:48:04.419: INFO: Created: latency-svc-2nhpm
Sep 27 06:48:04.426: INFO: Got endpoints: latency-svc-2nhpm [215.141528ms]
Sep 27 06:48:04.437: INFO: Created: latency-svc-cl27r
Sep 27 06:48:04.444: INFO: Got endpoints: latency-svc-cl27r [233.446774ms]
Sep 27 06:48:04.457: INFO: Created: latency-svc-stbj8
Sep 27 06:48:04.467: INFO: Got endpoints: latency-svc-stbj8 [256.255831ms]
Sep 27 06:48:04.477: INFO: Created: latency-svc-td76d
Sep 27 06:48:04.493: INFO: Got endpoints: latency-svc-td76d [282.744019ms]
Sep 27 06:48:04.498: INFO: Created: latency-svc-dxgwh
Sep 27 06:48:04.509: INFO: Got endpoints: latency-svc-dxgwh [298.450813ms]
Sep 27 06:48:04.516: INFO: Created: latency-svc-gtt7h
Sep 27 06:48:04.526: INFO: Got endpoints: latency-svc-gtt7h [288.692424ms]
Sep 27 06:48:04.531: INFO: Created: latency-svc-m9thk
Sep 27 06:48:04.541: INFO: Got endpoints: latency-svc-m9thk [285.5852ms]
Sep 27 06:48:04.551: INFO: Created: latency-svc-9wqbn
Sep 27 06:48:04.552: INFO: Got endpoints: latency-svc-9wqbn [283.444112ms]
Sep 27 06:48:04.567: INFO: Created: latency-svc-jg6qj
Sep 27 06:48:04.576: INFO: Got endpoints: latency-svc-jg6qj [284.067523ms]
Sep 27 06:48:04.585: INFO: Created: latency-svc-tpstc
Sep 27 06:48:04.592: INFO: Got endpoints: latency-svc-tpstc [284.38539ms]
Sep 27 06:48:04.610: INFO: Created: latency-svc-6mrsf
Sep 27 06:48:04.618: INFO: Created: latency-svc-v92x6
Sep 27 06:48:04.621: INFO: Got endpoints: latency-svc-6mrsf [286.408801ms]
Sep 27 06:48:04.629: INFO: Got endpoints: latency-svc-v92x6 [285.12425ms]
Sep 27 06:48:04.638: INFO: Created: latency-svc-5zszb
Sep 27 06:48:04.641: INFO: Got endpoints: latency-svc-5zszb [282.236439ms]
Sep 27 06:48:04.655: INFO: Created: latency-svc-blxb4
Sep 27 06:48:04.658: INFO: Got endpoints: latency-svc-blxb4 [279.961295ms]
Sep 27 06:48:04.685: INFO: Created: latency-svc-x967g
Sep 27 06:48:04.696: INFO: Got endpoints: latency-svc-x967g [292.546313ms]
Sep 27 06:48:04.703: INFO: Created: latency-svc-7btqj
Sep 27 06:48:04.714: INFO: Created: latency-svc-sckjm
Sep 27 06:48:04.714: INFO: Got endpoints: latency-svc-7btqj [288.721727ms]
Sep 27 06:48:04.722: INFO: Got endpoints: latency-svc-sckjm [278.132949ms]
Sep 27 06:48:04.737: INFO: Created: latency-svc-2cklm
Sep 27 06:48:04.752: INFO: Created: latency-svc-wth2s
Sep 27 06:48:04.763: INFO: Got endpoints: latency-svc-2cklm [296.453872ms]
Sep 27 06:48:04.767: INFO: Got endpoints: latency-svc-wth2s [273.357629ms]
Sep 27 06:48:04.773: INFO: Created: latency-svc-spr85
Sep 27 06:48:04.782: INFO: Created: latency-svc-lj86w
Sep 27 06:48:04.806: INFO: Created: latency-svc-9d7zx
Sep 27 06:48:04.811: INFO: Got endpoints: latency-svc-lj86w [285.276878ms]
Sep 27 06:48:04.812: INFO: Got endpoints: latency-svc-spr85 [302.728787ms]
Sep 27 06:48:04.820: INFO: Got endpoints: latency-svc-9d7zx [278.738516ms]
Sep 27 06:48:04.830: INFO: Created: latency-svc-sbrn4
Sep 27 06:48:04.839: INFO: Got endpoints: latency-svc-sbrn4 [286.73962ms]
Sep 27 06:48:04.845: INFO: Created: latency-svc-62r88
Sep 27 06:48:04.856: INFO: Got endpoints: latency-svc-62r88 [280.002518ms]
Sep 27 06:48:04.861: INFO: Created: latency-svc-sg594
Sep 27 06:48:04.866: INFO: Got endpoints: latency-svc-sg594 [273.539685ms]
Sep 27 06:48:04.878: INFO: Created: latency-svc-6jj69
Sep 27 06:48:04.882: INFO: Got endpoints: latency-svc-6jj69 [260.292605ms]
Sep 27 06:48:04.892: INFO: Created: latency-svc-8mcxx
Sep 27 06:48:04.901: INFO: Got endpoints: latency-svc-8mcxx [271.883227ms]
Sep 27 06:48:04.909: INFO: Created: latency-svc-tvkgv
Sep 27 06:48:04.924: INFO: Got endpoints: latency-svc-tvkgv [282.231772ms]
Sep 27 06:48:04.930: INFO: Created: latency-svc-lk75r
Sep 27 06:48:04.940: INFO: Created: latency-svc-8vvr2
Sep 27 06:48:04.947: INFO: Got endpoints: latency-svc-lk75r [288.674122ms]
Sep 27 06:48:04.950: INFO: Got endpoints: latency-svc-8vvr2 [254.051549ms]
Sep 27 06:48:04.965: INFO: Created: latency-svc-ddlwz
Sep 27 06:48:04.973: INFO: Got endpoints: latency-svc-ddlwz [258.486575ms]
Sep 27 06:48:04.986: INFO: Created: latency-svc-h2z79
Sep 27 06:48:05.009: INFO: Got endpoints: latency-svc-h2z79 [287.161861ms]
Sep 27 06:48:05.036: INFO: Created: latency-svc-kqjbm
Sep 27 06:48:05.038: INFO: Got endpoints: latency-svc-kqjbm [274.492457ms]
Sep 27 06:48:05.060: INFO: Created: latency-svc-z7gmk
Sep 27 06:48:05.068: INFO: Got endpoints: latency-svc-z7gmk [301.040169ms]
Sep 27 06:48:05.079: INFO: Created: latency-svc-dxwkf
Sep 27 06:48:05.090: INFO: Got endpoints: latency-svc-dxwkf [278.127059ms]
Sep 27 06:48:05.096: INFO: Created: latency-svc-fbdqv
Sep 27 06:48:05.102: INFO: Got endpoints: latency-svc-fbdqv [289.840176ms]
Sep 27 06:48:05.113: INFO: Created: latency-svc-h6779
Sep 27 06:48:05.164: INFO: Got endpoints: latency-svc-h6779 [343.970355ms]
Sep 27 06:48:05.167: INFO: Created: latency-svc-2rwp6
Sep 27 06:48:05.173: INFO: Got endpoints: latency-svc-2rwp6 [333.932065ms]
Sep 27 06:48:05.193: INFO: Created: latency-svc-jqjqn
Sep 27 06:48:05.205: INFO: Created: latency-svc-zck5c
Sep 27 06:48:05.208: INFO: Got endpoints: latency-svc-jqjqn [352.207536ms]
Sep 27 06:48:05.224: INFO: Created: latency-svc-8ml4j
Sep 27 06:48:05.237: INFO: Created: latency-svc-mvgnn
Sep 27 06:48:05.252: INFO: Created: latency-svc-wdbl9
Sep 27 06:48:05.260: INFO: Got endpoints: latency-svc-zck5c [394.516346ms]
Sep 27 06:48:05.269: INFO: Created: latency-svc-c4qkx
Sep 27 06:48:05.284: INFO: Created: latency-svc-5z2lh
Sep 27 06:48:05.304: INFO: Created: latency-svc-pz7gq
Sep 27 06:48:05.310: INFO: Got endpoints: latency-svc-8ml4j [427.74312ms]
Sep 27 06:48:05.318: INFO: Created: latency-svc-mglb6
Sep 27 06:48:05.330: INFO: Created: latency-svc-t27tx
Sep 27 06:48:05.344: INFO: Created: latency-svc-lrwsl
Sep 27 06:48:05.361: INFO: Got endpoints: latency-svc-mvgnn [460.738703ms]
Sep 27 06:48:05.364: INFO: Created: latency-svc-5vr98
Sep 27 06:48:05.379: INFO: Created: latency-svc-bmsgt
Sep 27 06:48:05.391: INFO: Created: latency-svc-hdcd8
Sep 27 06:48:05.408: INFO: Got endpoints: latency-svc-wdbl9 [484.220297ms]
Sep 27 06:48:05.415: INFO: Created: latency-svc-x7ntq
Sep 27 06:48:05.427: INFO: Created: latency-svc-m76v5
Sep 27 06:48:05.439: INFO: Created: latency-svc-55vfx
Sep 27 06:48:05.454: INFO: Created: latency-svc-56242
Sep 27 06:48:05.463: INFO: Got endpoints: latency-svc-c4qkx [516.194066ms]
Sep 27 06:48:05.481: INFO: Created: latency-svc-wwbm5
Sep 27 06:48:05.509: INFO: Got endpoints: latency-svc-5z2lh [559.437849ms]
Sep 27 06:48:05.510: INFO: Created: latency-svc-m7ns8
Sep 27 06:48:05.522: INFO: Created: latency-svc-nsth7
Sep 27 06:48:05.535: INFO: Created: latency-svc-svlqb
Sep 27 06:48:05.560: INFO: Got endpoints: latency-svc-pz7gq [586.745315ms]
Sep 27 06:48:05.572: INFO: Created: latency-svc-qwjgg
Sep 27 06:48:05.606: INFO: Got endpoints: latency-svc-mglb6 [596.31497ms]
Sep 27 06:48:05.624: INFO: Created: latency-svc-8zlz7
Sep 27 06:48:05.663: INFO: Got endpoints: latency-svc-t27tx [624.91086ms]
Sep 27 06:48:05.690: INFO: Created: latency-svc-vtwwp
Sep 27 06:48:05.706: INFO: Got endpoints: latency-svc-lrwsl [637.733511ms]
Sep 27 06:48:05.729: INFO: Created: latency-svc-5sj6h
Sep 27 06:48:05.773: INFO: Got endpoints: latency-svc-5vr98 [683.061363ms]
Sep 27 06:48:05.794: INFO: Created: latency-svc-xkggf
Sep 27 06:48:05.811: INFO: Got endpoints: latency-svc-bmsgt [709.433265ms]
Sep 27 06:48:05.833: INFO: Created: latency-svc-zxsfg
Sep 27 06:48:05.857: INFO: Got endpoints: latency-svc-hdcd8 [693.620738ms]
Sep 27 06:48:05.879: INFO: Created: latency-svc-x6vh9
Sep 27 06:48:05.905: INFO: Got endpoints: latency-svc-x7ntq [732.051562ms]
Sep 27 06:48:05.926: INFO: Created: latency-svc-nr6pl
Sep 27 06:48:05.955: INFO: Got endpoints: latency-svc-m76v5 [747.330512ms]
Sep 27 06:48:05.970: INFO: Created: latency-svc-s8mdr
Sep 27 06:48:06.008: INFO: Got endpoints: latency-svc-55vfx [748.308165ms]
Sep 27 06:48:06.034: INFO: Created: latency-svc-hwnmh
Sep 27 06:48:06.057: INFO: Got endpoints: latency-svc-56242 [746.971221ms]
Sep 27 06:48:06.078: INFO: Created: latency-svc-qqmhq
Sep 27 06:48:06.105: INFO: Got endpoints: latency-svc-wwbm5 [743.938114ms]
Sep 27 06:48:06.124: INFO: Created: latency-svc-8vt75
Sep 27 06:48:06.158: INFO: Got endpoints: latency-svc-m7ns8 [749.636851ms]
Sep 27 06:48:06.197: INFO: Created: latency-svc-7wzfc
Sep 27 06:48:06.207: INFO: Got endpoints: latency-svc-nsth7 [743.882855ms]
Sep 27 06:48:06.227: INFO: Created: latency-svc-kjnph
Sep 27 06:48:06.258: INFO: Got endpoints: latency-svc-svlqb [748.512407ms]
Sep 27 06:48:06.279: INFO: Created: latency-svc-tml7x
Sep 27 06:48:06.309: INFO: Got endpoints: latency-svc-qwjgg [748.821336ms]
Sep 27 06:48:06.328: INFO: Created: latency-svc-q9h8h
Sep 27 06:48:06.354: INFO: Got endpoints: latency-svc-8zlz7 [748.528893ms]
Sep 27 06:48:06.369: INFO: Created: latency-svc-pd5bp
Sep 27 06:48:06.406: INFO: Got endpoints: latency-svc-vtwwp [743.447346ms]
Sep 27 06:48:06.419: INFO: Created: latency-svc-5pcl4
Sep 27 06:48:06.460: INFO: Got endpoints: latency-svc-5sj6h [754.084514ms]
Sep 27 06:48:06.484: INFO: Created: latency-svc-h75hp
Sep 27 06:48:06.507: INFO: Got endpoints: latency-svc-xkggf [734.406104ms]
Sep 27 06:48:06.526: INFO: Created: latency-svc-xg74g
Sep 27 06:48:06.558: INFO: Got endpoints: latency-svc-zxsfg [746.874643ms]
Sep 27 06:48:06.574: INFO: Created: latency-svc-trd84
Sep 27 06:48:06.609: INFO: Got endpoints: latency-svc-x6vh9 [751.64485ms]
Sep 27 06:48:06.627: INFO: Created: latency-svc-wmpdg
Sep 27 06:48:06.666: INFO: Got endpoints: latency-svc-nr6pl [760.729072ms]
Sep 27 06:48:06.688: INFO: Created: latency-svc-ptvd6
Sep 27 06:48:06.708: INFO: Got endpoints: latency-svc-s8mdr [752.52261ms]
Sep 27 06:48:06.747: INFO: Created: latency-svc-9jfk4
Sep 27 06:48:06.759: INFO: Got endpoints: latency-svc-hwnmh [750.672826ms]
Sep 27 06:48:06.779: INFO: Created: latency-svc-xf47r
Sep 27 06:48:06.809: INFO: Got endpoints: latency-svc-qqmhq [752.827904ms]
Sep 27 06:48:06.827: INFO: Created: latency-svc-xmhl8
Sep 27 06:48:06.855: INFO: Got endpoints: latency-svc-8vt75 [749.520147ms]
Sep 27 06:48:06.875: INFO: Created: latency-svc-8hss5
Sep 27 06:48:06.906: INFO: Got endpoints: latency-svc-7wzfc [748.258746ms]
Sep 27 06:48:06.919: INFO: Created: latency-svc-hd56j
Sep 27 06:48:06.956: INFO: Got endpoints: latency-svc-kjnph [748.577139ms]
Sep 27 06:48:06.974: INFO: Created: latency-svc-dvnzx
Sep 27 06:48:07.008: INFO: Got endpoints: latency-svc-tml7x [750.137847ms]
Sep 27 06:48:07.024: INFO: Created: latency-svc-wnskw
Sep 27 06:48:07.060: INFO: Got endpoints: latency-svc-q9h8h [751.16803ms]
Sep 27 06:48:07.073: INFO: Created: latency-svc-qm75b
Sep 27 06:48:07.116: INFO: Got endpoints: latency-svc-pd5bp [761.804583ms]
Sep 27 06:48:07.153: INFO: Created: latency-svc-2ds96
Sep 27 06:48:07.157: INFO: Got endpoints: latency-svc-5pcl4 [750.758692ms]
Sep 27 06:48:07.178: INFO: Created: latency-svc-kx8bh
Sep 27 06:48:07.208: INFO: Got endpoints: latency-svc-h75hp [748.215675ms]
Sep 27 06:48:07.230: INFO: Created: latency-svc-k992p
Sep 27 06:48:07.257: INFO: Got endpoints: latency-svc-xg74g [749.528074ms]
Sep 27 06:48:07.278: INFO: Created: latency-svc-f76qb
Sep 27 06:48:07.310: INFO: Got endpoints: latency-svc-trd84 [751.352579ms]
Sep 27 06:48:07.328: INFO: Created: latency-svc-l2smt
Sep 27 06:48:07.359: INFO: Got endpoints: latency-svc-wmpdg [749.751344ms]
Sep 27 06:48:07.382: INFO: Created: latency-svc-tkx87
Sep 27 06:48:07.407: INFO: Got endpoints: latency-svc-ptvd6 [740.482938ms]
Sep 27 06:48:07.432: INFO: Created: latency-svc-v8hps
Sep 27 06:48:07.455: INFO: Got endpoints: latency-svc-9jfk4 [746.837745ms]
Sep 27 06:48:07.469: INFO: Created: latency-svc-hwj5r
Sep 27 06:48:07.507: INFO: Got endpoints: latency-svc-xf47r [747.320637ms]
Sep 27 06:48:07.532: INFO: Created: latency-svc-lcqnn
Sep 27 06:48:07.559: INFO: Got endpoints: latency-svc-xmhl8 [749.787551ms]
Sep 27 06:48:07.574: INFO: Created: latency-svc-wlnld
Sep 27 06:48:07.606: INFO: Got endpoints: latency-svc-8hss5 [750.642476ms]
Sep 27 06:48:07.625: INFO: Created: latency-svc-2lcpg
Sep 27 06:48:07.672: INFO: Got endpoints: latency-svc-hd56j [765.647847ms]
Sep 27 06:48:07.705: INFO: Created: latency-svc-9fr2d
Sep 27 06:48:07.707: INFO: Got endpoints: latency-svc-dvnzx [751.29992ms]
Sep 27 06:48:07.724: INFO: Created: latency-svc-cbdng
Sep 27 06:48:07.758: INFO: Got endpoints: latency-svc-wnskw [749.740193ms]
Sep 27 06:48:07.788: INFO: Created: latency-svc-vd69s
Sep 27 06:48:07.804: INFO: Got endpoints: latency-svc-qm75b [744.318182ms]
Sep 27 06:48:07.825: INFO: Created: latency-svc-t9lhl
Sep 27 06:48:07.858: INFO: Got endpoints: latency-svc-2ds96 [741.232425ms]
Sep 27 06:48:07.876: INFO: Created: latency-svc-lqmqx
Sep 27 06:48:07.906: INFO: Got endpoints: latency-svc-kx8bh [748.831525ms]
Sep 27 06:48:07.922: INFO: Created: latency-svc-9t4t8
Sep 27 06:48:07.961: INFO: Got endpoints: latency-svc-k992p [752.524549ms]
Sep 27 06:48:07.981: INFO: Created: latency-svc-bswzj
Sep 27 06:48:08.006: INFO: Got endpoints: latency-svc-f76qb [749.310728ms]
Sep 27 06:48:08.023: INFO: Created: latency-svc-qvx8z
Sep 27 06:48:08.064: INFO: Got endpoints: latency-svc-l2smt [753.936416ms]
Sep 27 06:48:08.081: INFO: Created: latency-svc-d6lpq
Sep 27 06:48:08.105: INFO: Got endpoints: latency-svc-tkx87 [746.01591ms]
Sep 27 06:48:08.122: INFO: Created: latency-svc-52pzd
Sep 27 06:48:08.158: INFO: Got endpoints: latency-svc-v8hps [751.700748ms]
Sep 27 06:48:08.216: INFO: Created: latency-svc-7hrzj
Sep 27 06:48:08.231: INFO: Got endpoints: latency-svc-hwj5r [776.298916ms]
Sep 27 06:48:08.262: INFO: Created: latency-svc-lpnlw
Sep 27 06:48:08.265: INFO: Got endpoints: latency-svc-lcqnn [758.480408ms]
Sep 27 06:48:08.284: INFO: Created: latency-svc-7wvb2
Sep 27 06:48:08.308: INFO: Got endpoints: latency-svc-wlnld [748.243933ms]
Sep 27 06:48:08.321: INFO: Created: latency-svc-nt4hw
Sep 27 06:48:08.360: INFO: Got endpoints: latency-svc-2lcpg [754.668602ms]
Sep 27 06:48:08.375: INFO: Created: latency-svc-jgt7w
Sep 27 06:48:08.406: INFO: Got endpoints: latency-svc-9fr2d [734.293106ms]
Sep 27 06:48:08.425: INFO: Created: latency-svc-f9qm8
Sep 27 06:48:08.455: INFO: Got endpoints: latency-svc-cbdng [747.688868ms]
Sep 27 06:48:08.474: INFO: Created: latency-svc-rmdx8
Sep 27 06:48:08.510: INFO: Got endpoints: latency-svc-vd69s [752.73614ms]
Sep 27 06:48:08.533: INFO: Created: latency-svc-dfs6p
Sep 27 06:48:08.571: INFO: Got endpoints: latency-svc-t9lhl [766.723058ms]
Sep 27 06:48:08.597: INFO: Created: latency-svc-zks52
Sep 27 06:48:08.607: INFO: Got endpoints: latency-svc-lqmqx [749.125024ms]
Sep 27 06:48:08.625: INFO: Created: latency-svc-7pjcj
Sep 27 06:48:08.659: INFO: Got endpoints: latency-svc-9t4t8 [753.410325ms]
Sep 27 06:48:08.691: INFO: Created: latency-svc-xgmdx
Sep 27 06:48:08.711: INFO: Got endpoints: latency-svc-bswzj [750.188752ms]
Sep 27 06:48:08.728: INFO: Created: latency-svc-bmwvr
Sep 27 06:48:08.755: INFO: Got endpoints: latency-svc-qvx8z [748.696641ms]
Sep 27 06:48:08.773: INFO: Created: latency-svc-4q2rs
Sep 27 06:48:08.805: INFO: Got endpoints: latency-svc-d6lpq [741.758346ms]
Sep 27 06:48:08.823: INFO: Created: latency-svc-97bj9
Sep 27 06:48:08.859: INFO: Got endpoints: latency-svc-52pzd [754.54664ms]
Sep 27 06:48:08.889: INFO: Created: latency-svc-vt27x
Sep 27 06:48:08.906: INFO: Got endpoints: latency-svc-7hrzj [747.794205ms]
Sep 27 06:48:08.927: INFO: Created: latency-svc-sckr7
Sep 27 06:48:08.956: INFO: Got endpoints: latency-svc-lpnlw [724.989126ms]
Sep 27 06:48:08.975: INFO: Created: latency-svc-bwlcz
Sep 27 06:48:09.011: INFO: Got endpoints: latency-svc-7wvb2 [745.566078ms]
Sep 27 06:48:09.031: INFO: Created: latency-svc-rq8dl
Sep 27 06:48:09.057: INFO: Got endpoints: latency-svc-nt4hw [749.164549ms]
Sep 27 06:48:09.075: INFO: Created: latency-svc-v8r8g
Sep 27 06:48:09.109: INFO: Got endpoints: latency-svc-jgt7w [748.684843ms]
Sep 27 06:48:09.122: INFO: Created: latency-svc-dkc5x
Sep 27 06:48:09.156: INFO: Got endpoints: latency-svc-f9qm8 [750.024799ms]
Sep 27 06:48:09.169: INFO: Created: latency-svc-pzf4b
Sep 27 06:48:09.206: INFO: Got endpoints: latency-svc-rmdx8 [751.561439ms]
Sep 27 06:48:09.225: INFO: Created: latency-svc-6nq52
Sep 27 06:48:09.260: INFO: Got endpoints: latency-svc-dfs6p [749.879664ms]
Sep 27 06:48:09.279: INFO: Created: latency-svc-rnk7k
Sep 27 06:48:09.306: INFO: Got endpoints: latency-svc-zks52 [735.460839ms]
Sep 27 06:48:09.322: INFO: Created: latency-svc-65dfm
Sep 27 06:48:09.355: INFO: Got endpoints: latency-svc-7pjcj [748.71267ms]
Sep 27 06:48:09.373: INFO: Created: latency-svc-7gxhn
Sep 27 06:48:09.404: INFO: Got endpoints: latency-svc-xgmdx [745.008325ms]
Sep 27 06:48:09.420: INFO: Created: latency-svc-6hn7k
Sep 27 06:48:09.455: INFO: Got endpoints: latency-svc-bmwvr [744.010925ms]
Sep 27 06:48:09.478: INFO: Created: latency-svc-hxrxv
Sep 27 06:48:09.504: INFO: Got endpoints: latency-svc-4q2rs [748.987949ms]
Sep 27 06:48:09.521: INFO: Created: latency-svc-mpnfl
Sep 27 06:48:09.560: INFO: Got endpoints: latency-svc-97bj9 [755.074218ms]
Sep 27 06:48:09.576: INFO: Created: latency-svc-rls7t
Sep 27 06:48:09.607: INFO: Got endpoints: latency-svc-vt27x [747.669072ms]
Sep 27 06:48:09.623: INFO: Created: latency-svc-vxcxs
Sep 27 06:48:09.654: INFO: Got endpoints: latency-svc-sckr7 [748.228032ms]
Sep 27 06:48:09.674: INFO: Created: latency-svc-grwvw
Sep 27 06:48:09.709: INFO: Got endpoints: latency-svc-bwlcz [752.540167ms]
Sep 27 06:48:09.721: INFO: Created: latency-svc-lm8hh
Sep 27 06:48:09.754: INFO: Got endpoints: latency-svc-rq8dl [743.411367ms]
Sep 27 06:48:09.782: INFO: Created: latency-svc-sdvpv
Sep 27 06:48:09.807: INFO: Got endpoints: latency-svc-v8r8g [750.570662ms]
Sep 27 06:48:09.836: INFO: Created: latency-svc-k7m2g
Sep 27 06:48:09.857: INFO: Got endpoints: latency-svc-dkc5x [747.333829ms]
Sep 27 06:48:09.884: INFO: Created: latency-svc-5njjr
Sep 27 06:48:09.905: INFO: Got endpoints: latency-svc-pzf4b [748.903464ms]
Sep 27 06:48:09.919: INFO: Created: latency-svc-xdrz6
Sep 27 06:48:09.956: INFO: Got endpoints: latency-svc-6nq52 [749.524201ms]
Sep 27 06:48:09.969: INFO: Created: latency-svc-4kj64
Sep 27 06:48:10.005: INFO: Got endpoints: latency-svc-rnk7k [744.139852ms]
Sep 27 06:48:10.021: INFO: Created: latency-svc-48tc9
Sep 27 06:48:10.055: INFO: Got endpoints: latency-svc-65dfm [749.064266ms]
Sep 27 06:48:10.077: INFO: Created: latency-svc-wqdcx
Sep 27 06:48:10.106: INFO: Got endpoints: latency-svc-7gxhn [750.319376ms]
Sep 27 06:48:10.137: INFO: Created: latency-svc-bjg5c
Sep 27 06:48:10.154: INFO: Got endpoints: latency-svc-6hn7k [749.963565ms]
Sep 27 06:48:10.173: INFO: Created: latency-svc-wlwss
Sep 27 06:48:10.210: INFO: Got endpoints: latency-svc-hxrxv [754.78948ms]
Sep 27 06:48:10.229: INFO: Created: latency-svc-t6xqg
Sep 27 06:48:10.256: INFO: Got endpoints: latency-svc-mpnfl [752.115213ms]
Sep 27 06:48:10.296: INFO: Created: latency-svc-n2fbg
Sep 27 06:48:10.307: INFO: Got endpoints: latency-svc-rls7t [746.180607ms]
Sep 27 06:48:10.330: INFO: Created: latency-svc-lpsjt
Sep 27 06:48:10.355: INFO: Got endpoints: latency-svc-vxcxs [747.653819ms]
Sep 27 06:48:10.379: INFO: Created: latency-svc-g99sh
Sep 27 06:48:10.408: INFO: Got endpoints: latency-svc-grwvw [753.695998ms]
Sep 27 06:48:10.426: INFO: Created: latency-svc-tnbwt
Sep 27 06:48:10.454: INFO: Got endpoints: latency-svc-lm8hh [745.554983ms]
Sep 27 06:48:10.473: INFO: Created: latency-svc-nw877
Sep 27 06:48:10.505: INFO: Got endpoints: latency-svc-sdvpv [750.968638ms]
Sep 27 06:48:10.525: INFO: Created: latency-svc-mv2xz
Sep 27 06:48:10.556: INFO: Got endpoints: latency-svc-k7m2g [748.218455ms]
Sep 27 06:48:10.571: INFO: Created: latency-svc-5v57z
Sep 27 06:48:10.611: INFO: Got endpoints: latency-svc-5njjr [754.336738ms]
Sep 27 06:48:10.638: INFO: Created: latency-svc-pw827
Sep 27 06:48:10.656: INFO: Got endpoints: latency-svc-xdrz6 [751.259608ms]
Sep 27 06:48:10.722: INFO: Got endpoints: latency-svc-4kj64 [765.961842ms]
Sep 27 06:48:10.725: INFO: Created: latency-svc-9jstn
Sep 27 06:48:10.739: INFO: Created: latency-svc-7djg7
Sep 27 06:48:10.756: INFO: Got endpoints: latency-svc-48tc9 [751.60878ms]
Sep 27 06:48:10.775: INFO: Created: latency-svc-b9czc
Sep 27 06:48:10.806: INFO: Got endpoints: latency-svc-wqdcx [750.363302ms]
Sep 27 06:48:10.823: INFO: Created: latency-svc-phm26
Sep 27 06:48:10.856: INFO: Got endpoints: latency-svc-bjg5c [750.430025ms]
Sep 27 06:48:10.873: INFO: Created: latency-svc-dd5qm
Sep 27 06:48:10.909: INFO: Got endpoints: latency-svc-wlwss [754.036208ms]
Sep 27 06:48:10.925: INFO: Created: latency-svc-x2xlj
Sep 27 06:48:10.956: INFO: Got endpoints: latency-svc-t6xqg [746.680324ms]
Sep 27 06:48:10.976: INFO: Created: latency-svc-j4k8s
Sep 27 06:48:11.008: INFO: Got endpoints: latency-svc-n2fbg [751.769967ms]
Sep 27 06:48:11.028: INFO: Created: latency-svc-954f5
Sep 27 06:48:11.055: INFO: Got endpoints: latency-svc-lpsjt [748.555415ms]
Sep 27 06:48:11.072: INFO: Created: latency-svc-kg5hb
Sep 27 06:48:11.104: INFO: Got endpoints: latency-svc-g99sh [749.34751ms]
Sep 27 06:48:11.120: INFO: Created: latency-svc-ll8rp
Sep 27 06:48:11.160: INFO: Got endpoints: latency-svc-tnbwt [752.098619ms]
Sep 27 06:48:11.176: INFO: Created: latency-svc-h78jl
Sep 27 06:48:11.207: INFO: Got endpoints: latency-svc-nw877 [753.28291ms]
Sep 27 06:48:11.226: INFO: Created: latency-svc-r87zd
Sep 27 06:48:11.256: INFO: Got endpoints: latency-svc-mv2xz [751.176462ms]
Sep 27 06:48:11.290: INFO: Created: latency-svc-blpvc
Sep 27 06:48:11.310: INFO: Got endpoints: latency-svc-5v57z [754.221392ms]
Sep 27 06:48:11.329: INFO: Created: latency-svc-qch6b
Sep 27 06:48:11.359: INFO: Got endpoints: latency-svc-pw827 [748.427926ms]
Sep 27 06:48:11.379: INFO: Created: latency-svc-572x5
Sep 27 06:48:11.408: INFO: Got endpoints: latency-svc-9jstn [751.378015ms]
Sep 27 06:48:11.428: INFO: Created: latency-svc-qsn96
Sep 27 06:48:11.456: INFO: Got endpoints: latency-svc-7djg7 [734.447731ms]
Sep 27 06:48:11.480: INFO: Created: latency-svc-fmnbl
Sep 27 06:48:11.505: INFO: Got endpoints: latency-svc-b9czc [749.043216ms]
Sep 27 06:48:11.523: INFO: Created: latency-svc-l4j4v
Sep 27 06:48:11.563: INFO: Got endpoints: latency-svc-phm26 [756.985298ms]
Sep 27 06:48:11.579: INFO: Created: latency-svc-twlvw
Sep 27 06:48:11.607: INFO: Got endpoints: latency-svc-dd5qm [750.219379ms]
Sep 27 06:48:11.626: INFO: Created: latency-svc-f85r8
Sep 27 06:48:11.667: INFO: Got endpoints: latency-svc-x2xlj [758.618312ms]
Sep 27 06:48:11.707: INFO: Created: latency-svc-hp5n8
Sep 27 06:48:11.707: INFO: Got endpoints: latency-svc-j4k8s [750.727366ms]
Sep 27 06:48:11.722: INFO: Created: latency-svc-glx2l
Sep 27 06:48:11.755: INFO: Got endpoints: latency-svc-954f5 [746.963601ms]
Sep 27 06:48:11.803: INFO: Created: latency-svc-r8fx6
Sep 27 06:48:11.809: INFO: Got endpoints: latency-svc-kg5hb [753.900116ms]
Sep 27 06:48:11.830: INFO: Created: latency-svc-7gcbk
Sep 27 06:48:11.860: INFO: Got endpoints: latency-svc-ll8rp [755.436545ms]
Sep 27 06:48:11.880: INFO: Created: latency-svc-7t8gl
Sep 27 06:48:11.906: INFO: Got endpoints: latency-svc-h78jl [745.158384ms]
Sep 27 06:48:11.924: INFO: Created: latency-svc-89bmr
Sep 27 06:48:11.961: INFO: Got endpoints: latency-svc-r87zd [753.176494ms]
Sep 27 06:48:11.976: INFO: Created: latency-svc-rsxxk
Sep 27 06:48:12.010: INFO: Got endpoints: latency-svc-blpvc [754.07661ms]
Sep 27 06:48:12.035: INFO: Created: latency-svc-9kgvb
Sep 27 06:48:12.057: INFO: Got endpoints: latency-svc-qch6b [747.388173ms]
Sep 27 06:48:12.108: INFO: Got endpoints: latency-svc-572x5 [748.726247ms]
Sep 27 06:48:12.157: INFO: Got endpoints: latency-svc-qsn96 [748.928719ms]
Sep 27 06:48:12.205: INFO: Got endpoints: latency-svc-fmnbl [748.212772ms]
Sep 27 06:48:12.257: INFO: Got endpoints: latency-svc-l4j4v [751.495003ms]
Sep 27 06:48:12.315: INFO: Got endpoints: latency-svc-twlvw [751.802219ms]
Sep 27 06:48:12.358: INFO: Got endpoints: latency-svc-f85r8 [751.283411ms]
Sep 27 06:48:12.406: INFO: Got endpoints: latency-svc-hp5n8 [738.689575ms]
Sep 27 06:48:12.458: INFO: Got endpoints: latency-svc-glx2l [751.0189ms]
Sep 27 06:48:12.508: INFO: Got endpoints: latency-svc-r8fx6 [752.468269ms]
Sep 27 06:48:12.557: INFO: Got endpoints: latency-svc-7gcbk [747.422454ms]
Sep 27 06:48:12.609: INFO: Got endpoints: latency-svc-7t8gl [749.33998ms]
Sep 27 06:48:12.666: INFO: Got endpoints: latency-svc-89bmr [760.078593ms]
Sep 27 06:48:12.714: INFO: Got endpoints: latency-svc-rsxxk [753.733638ms]
Sep 27 06:48:12.757: INFO: Got endpoints: latency-svc-9kgvb [746.706168ms]
Sep 27 06:48:12.757: INFO: Latencies: [27.429433ms 44.488782ms 58.260243ms 81.078766ms 97.238334ms 124.377306ms 133.191746ms 148.676021ms 167.585615ms 192.380012ms 215.141528ms 233.446774ms 254.051549ms 256.255831ms 258.486575ms 260.292605ms 271.883227ms 273.357629ms 273.539685ms 274.492457ms 278.127059ms 278.132949ms 278.738516ms 279.961295ms 280.002518ms 282.231772ms 282.236439ms 282.744019ms 283.444112ms 284.067523ms 284.38539ms 285.12425ms 285.276878ms 285.5852ms 286.408801ms 286.73962ms 287.161861ms 288.674122ms 288.692424ms 288.721727ms 289.840176ms 292.546313ms 296.453872ms 298.450813ms 301.040169ms 302.728787ms 333.932065ms 343.970355ms 352.207536ms 394.516346ms 427.74312ms 460.738703ms 484.220297ms 516.194066ms 559.437849ms 586.745315ms 596.31497ms 624.91086ms 637.733511ms 683.061363ms 693.620738ms 709.433265ms 724.989126ms 732.051562ms 734.293106ms 734.406104ms 734.447731ms 735.460839ms 738.689575ms 740.482938ms 741.232425ms 741.758346ms 743.411367ms 743.447346ms 743.882855ms 743.938114ms 744.010925ms 744.139852ms 744.318182ms 745.008325ms 745.158384ms 745.554983ms 745.566078ms 746.01591ms 746.180607ms 746.680324ms 746.706168ms 746.837745ms 746.874643ms 746.963601ms 746.971221ms 747.320637ms 747.330512ms 747.333829ms 747.388173ms 747.422454ms 747.653819ms 747.669072ms 747.688868ms 747.794205ms 748.212772ms 748.215675ms 748.218455ms 748.228032ms 748.243933ms 748.258746ms 748.308165ms 748.427926ms 748.512407ms 748.528893ms 748.555415ms 748.577139ms 748.684843ms 748.696641ms 748.71267ms 748.726247ms 748.821336ms 748.831525ms 748.903464ms 748.928719ms 748.987949ms 749.043216ms 749.064266ms 749.125024ms 749.164549ms 749.310728ms 749.33998ms 749.34751ms 749.520147ms 749.524201ms 749.528074ms 749.636851ms 749.740193ms 749.751344ms 749.787551ms 749.879664ms 749.963565ms 750.024799ms 750.137847ms 750.188752ms 750.219379ms 750.319376ms 750.363302ms 750.430025ms 750.570662ms 750.642476ms 750.672826ms 750.727366ms 750.758692ms 750.968638ms 751.0189ms 751.16803ms 751.176462ms 751.259608ms 751.283411ms 751.29992ms 751.352579ms 751.378015ms 751.495003ms 751.561439ms 751.60878ms 751.64485ms 751.700748ms 751.769967ms 751.802219ms 752.098619ms 752.115213ms 752.468269ms 752.52261ms 752.524549ms 752.540167ms 752.73614ms 752.827904ms 753.176494ms 753.28291ms 753.410325ms 753.695998ms 753.733638ms 753.900116ms 753.936416ms 754.036208ms 754.07661ms 754.084514ms 754.221392ms 754.336738ms 754.54664ms 754.668602ms 754.78948ms 755.074218ms 755.436545ms 756.985298ms 758.480408ms 758.618312ms 760.078593ms 760.729072ms 761.804583ms 765.647847ms 765.961842ms 766.723058ms 776.298916ms]
Sep 27 06:48:12.757: INFO: 50 %ile: 748.212772ms
Sep 27 06:48:12.757: INFO: 90 %ile: 754.036208ms
Sep 27 06:48:12.757: INFO: 99 %ile: 766.723058ms
Sep 27 06:48:12.757: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:48:12.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-2237" for this suite.
Sep 27 06:48:26.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:48:26.866: INFO: namespace svc-latency-2237 deletion completed in 14.100148s

• [SLOW TEST:24.981 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:48:26.867: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-5969
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Sep 27 06:48:27.005: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 27 06:48:27.013: INFO: Waiting for terminating namespaces to be deleted...
Sep 27 06:48:27.016: INFO: 
Logging pods the kubelet thinks is on node worker1.dev-bj.kubeoperator.io before test
Sep 27 06:48:27.025: INFO: coredns-6647cfd5f7-5wgqm from kube-system started at 2019-09-27 03:44:35 +0000 UTC (1 container statuses recorded)
Sep 27 06:48:27.025: INFO: 	Container coredns ready: true, restart count 0
Sep 27 06:48:27.025: INFO: f2c-prometheus-server-59b7445459-cdgrc from monitoring started at 2019-09-27 03:45:02 +0000 UTC (2 container statuses recorded)
Sep 27 06:48:27.025: INFO: 	Container prometheus-server ready: true, restart count 0
Sep 27 06:48:27.025: INFO: 	Container prometheus-server-configmap-reload ready: true, restart count 0
Sep 27 06:48:27.025: INFO: tiller-deploy-7cf9b9d4d9-2hhhb from kube-system started at 2019-09-27 03:44:15 +0000 UTC (1 container statuses recorded)
Sep 27 06:48:27.025: INFO: 	Container tiller ready: true, restart count 0
Sep 27 06:48:27.025: INFO: sonobuoy from sonobuoy started at 2019-09-27 05:46:03 +0000 UTC (1 container statuses recorded)
Sep 27 06:48:27.025: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 27 06:48:27.025: INFO: traefik-ingress-lb-5hr58 from kube-system started at 2019-09-27 03:44:43 +0000 UTC (1 container statuses recorded)
Sep 27 06:48:27.025: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Sep 27 06:48:27.025: INFO: f2c-prometheus-node-exporter-9jg5c from monitoring started at 2019-09-27 03:45:00 +0000 UTC (1 container statuses recorded)
Sep 27 06:48:27.025: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Sep 27 06:48:27.025: INFO: weave-scope-app-7d78556c95-hlvsr from weave started at 2019-09-27 03:45:13 +0000 UTC (1 container statuses recorded)
Sep 27 06:48:27.025: INFO: 	Container app ready: true, restart count 0
Sep 27 06:48:27.025: INFO: weave-scope-agent-fd4jr from weave started at 2019-09-27 03:45:13 +0000 UTC (1 container statuses recorded)
Sep 27 06:48:27.025: INFO: 	Container scope-agent ready: true, restart count 0
Sep 27 06:48:27.025: INFO: sonobuoy-e2e-job-4960befc9aee4574 from sonobuoy started at 2019-09-27 05:46:05 +0000 UTC (2 container statuses recorded)
Sep 27 06:48:27.025: INFO: 	Container e2e ready: true, restart count 0
Sep 27 06:48:27.025: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 27 06:48:27.025: INFO: sonobuoy-systemd-logs-daemon-set-7f0ec8e8c9ff47b9-2pvqs from sonobuoy started at 2019-09-27 05:46:06 +0000 UTC (2 container statuses recorded)
Sep 27 06:48:27.025: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 27 06:48:27.025: INFO: 	Container systemd-logs ready: true, restart count 1
Sep 27 06:48:27.025: INFO: kube-flannel-ds-amd64-2tjkj from kube-system started at 2019-09-27 03:42:32 +0000 UTC (1 container statuses recorded)
Sep 27 06:48:27.025: INFO: 	Container kube-flannel ready: true, restart count 0
Sep 27 06:48:27.025: INFO: 
Logging pods the kubelet thinks is on node worker2.dev-bj.kubeoperator.io before test
Sep 27 06:48:27.035: INFO: traefik-ingress-lb-cmrlj from kube-system started at 2019-09-27 03:44:43 +0000 UTC (1 container statuses recorded)
Sep 27 06:48:27.035: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Sep 27 06:48:27.035: INFO: kube-registry-dh5pv from kube-system started at 2019-09-27 03:45:49 +0000 UTC (2 container statuses recorded)
Sep 27 06:48:27.035: INFO: 	Container registry ready: true, restart count 0
Sep 27 06:48:27.035: INFO: 	Container registry-ui ready: true, restart count 0
Sep 27 06:48:27.035: INFO: coredns-6647cfd5f7-m24g4 from kube-system started at 2019-09-27 03:44:35 +0000 UTC (1 container statuses recorded)
Sep 27 06:48:27.035: INFO: 	Container coredns ready: true, restart count 0
Sep 27 06:48:27.035: INFO: f2c-prometheus-node-exporter-kgb24 from monitoring started at 2019-09-27 03:45:00 +0000 UTC (1 container statuses recorded)
Sep 27 06:48:27.035: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Sep 27 06:48:27.035: INFO: weave-scope-agent-rrlfg from weave started at 2019-09-27 03:45:13 +0000 UTC (1 container statuses recorded)
Sep 27 06:48:27.035: INFO: 	Container scope-agent ready: true, restart count 0
Sep 27 06:48:27.035: INFO: f2c-grafana-6dd4b6bc5c-822q6 from monitoring started at 2019-09-27 03:45:09 +0000 UTC (1 container statuses recorded)
Sep 27 06:48:27.035: INFO: 	Container grafana ready: true, restart count 0
Sep 27 06:48:27.035: INFO: weave-scope-cluster-agent-6fdcc8f6dd-247hz from weave started at 2019-09-27 03:45:13 +0000 UTC (1 container statuses recorded)
Sep 27 06:48:27.035: INFO: 	Container scope-cluster-agent ready: true, restart count 0
Sep 27 06:48:27.035: INFO: kube-flannel-ds-amd64-ptljm from kube-system started at 2019-09-27 03:42:32 +0000 UTC (1 container statuses recorded)
Sep 27 06:48:27.035: INFO: 	Container kube-flannel ready: true, restart count 0
Sep 27 06:48:27.035: INFO: heapster-5646c79465-tpqxz from kube-system started at 2019-09-27 03:44:50 +0000 UTC (1 container statuses recorded)
Sep 27 06:48:27.035: INFO: 	Container heapster ready: true, restart count 0
Sep 27 06:48:27.035: INFO: sonobuoy-systemd-logs-daemon-set-7f0ec8e8c9ff47b9-rg9hc from sonobuoy started at 2019-09-27 05:46:06 +0000 UTC (2 container statuses recorded)
Sep 27 06:48:27.035: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 27 06:48:27.035: INFO: 	Container systemd-logs ready: true, restart count 1
Sep 27 06:48:27.035: INFO: 
Logging pods the kubelet thinks is on node worker3.dev-bj.kubeoperator.io before test
Sep 27 06:48:27.042: INFO: kube-flannel-ds-amd64-frff7 from kube-system started at 2019-09-27 03:42:32 +0000 UTC (1 container statuses recorded)
Sep 27 06:48:27.042: INFO: 	Container kube-flannel ready: true, restart count 0
Sep 27 06:48:27.042: INFO: traefik-ingress-lb-tst7r from kube-system started at 2019-09-27 03:44:43 +0000 UTC (1 container statuses recorded)
Sep 27 06:48:27.042: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Sep 27 06:48:27.042: INFO: f2c-prometheus-kube-state-metrics-5b66c65d69-b5znb from monitoring started at 2019-09-27 03:45:01 +0000 UTC (1 container statuses recorded)
Sep 27 06:48:27.042: INFO: 	Container prometheus-kube-state-metrics ready: true, restart count 0
Sep 27 06:48:27.042: INFO: f2c-prometheus-alertmanager-65f9fd5bf5-8fc2f from monitoring started at 2019-09-27 03:45:02 +0000 UTC (2 container statuses recorded)
Sep 27 06:48:27.042: INFO: 	Container prometheus-alertmanager ready: true, restart count 0
Sep 27 06:48:27.042: INFO: 	Container prometheus-alertmanager-configmap-reload ready: true, restart count 0
Sep 27 06:48:27.042: INFO: f2c-prometheus-node-exporter-p2zc6 from monitoring started at 2019-09-27 03:45:01 +0000 UTC (1 container statuses recorded)
Sep 27 06:48:27.042: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Sep 27 06:48:27.042: INFO: sonobuoy-systemd-logs-daemon-set-7f0ec8e8c9ff47b9-j8dzb from sonobuoy started at 2019-09-27 05:46:06 +0000 UTC (2 container statuses recorded)
Sep 27 06:48:27.042: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 27 06:48:27.042: INFO: 	Container systemd-logs ready: true, restart count 1
Sep 27 06:48:27.042: INFO: kubernetes-dashboard-5bc5db49-r7vvg from kube-system started at 2019-09-27 03:44:49 +0000 UTC (1 container statuses recorded)
Sep 27 06:48:27.042: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep 27 06:48:27.042: INFO: weave-scope-agent-64k6h from weave started at 2019-09-27 03:45:13 +0000 UTC (1 container statuses recorded)
Sep 27 06:48:27.042: INFO: 	Container scope-agent ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-f7b2267f-261c-47e5-af69-2fc5ff5c6511 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-f7b2267f-261c-47e5-af69-2fc5ff5c6511 off the node worker3.dev-bj.kubeoperator.io
STEP: verifying the node doesn't have the label kubernetes.io/e2e-f7b2267f-261c-47e5-af69-2fc5ff5c6511
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:48:31.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5969" for this suite.
Sep 27 06:48:39.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:48:39.225: INFO: namespace sched-pred-5969 deletion completed in 8.080675532s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:12.358 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:48:39.225: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-6159
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Sep 27 06:48:39.580: INFO: Pod name wrapped-volume-race-0fe5908a-ec67-4967-ac41-b96bd0c53a5d: Found 0 pods out of 5
Sep 27 06:48:44.586: INFO: Pod name wrapped-volume-race-0fe5908a-ec67-4967-ac41-b96bd0c53a5d: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-0fe5908a-ec67-4967-ac41-b96bd0c53a5d in namespace emptydir-wrapper-6159, will wait for the garbage collector to delete the pods
Sep 27 06:48:54.665: INFO: Deleting ReplicationController wrapped-volume-race-0fe5908a-ec67-4967-ac41-b96bd0c53a5d took: 10.28936ms
Sep 27 06:48:55.065: INFO: Terminating ReplicationController wrapped-volume-race-0fe5908a-ec67-4967-ac41-b96bd0c53a5d pods took: 400.22962ms
STEP: Creating RC which spawns configmap-volume pods
Sep 27 06:49:40.082: INFO: Pod name wrapped-volume-race-acd361e7-a6cc-4fc9-832b-d030a9462a4d: Found 0 pods out of 5
Sep 27 06:49:45.087: INFO: Pod name wrapped-volume-race-acd361e7-a6cc-4fc9-832b-d030a9462a4d: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-acd361e7-a6cc-4fc9-832b-d030a9462a4d in namespace emptydir-wrapper-6159, will wait for the garbage collector to delete the pods
Sep 27 06:49:55.165: INFO: Deleting ReplicationController wrapped-volume-race-acd361e7-a6cc-4fc9-832b-d030a9462a4d took: 9.784247ms
Sep 27 06:49:55.565: INFO: Terminating ReplicationController wrapped-volume-race-acd361e7-a6cc-4fc9-832b-d030a9462a4d pods took: 400.207271ms
STEP: Creating RC which spawns configmap-volume pods
Sep 27 06:50:47.547: INFO: Pod name wrapped-volume-race-f7d9a75f-51f9-4848-8042-cf24dd39f002: Found 0 pods out of 5
Sep 27 06:50:52.631: INFO: Pod name wrapped-volume-race-f7d9a75f-51f9-4848-8042-cf24dd39f002: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-f7d9a75f-51f9-4848-8042-cf24dd39f002 in namespace emptydir-wrapper-6159, will wait for the garbage collector to delete the pods
Sep 27 06:51:02.716: INFO: Deleting ReplicationController wrapped-volume-race-f7d9a75f-51f9-4848-8042-cf24dd39f002 took: 8.589863ms
Sep 27 06:51:03.116: INFO: Terminating ReplicationController wrapped-volume-race-f7d9a75f-51f9-4848-8042-cf24dd39f002 pods took: 400.20759ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:51:41.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-6159" for this suite.
Sep 27 06:51:49.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:51:49.543: INFO: namespace emptydir-wrapper-6159 deletion completed in 8.116639214s

• [SLOW TEST:190.318 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:51:49.543: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7863
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1558
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 27 06:51:49.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-7863'
Sep 27 06:51:50.411: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 27 06:51:50.411: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
Sep 27 06:51:54.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 delete deployment e2e-test-nginx-deployment --namespace=kubectl-7863'
Sep 27 06:51:54.563: INFO: stderr: ""
Sep 27 06:51:54.563: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:51:54.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7863" for this suite.
Sep 27 06:52:16.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:52:16.679: INFO: namespace kubectl-7863 deletion completed in 22.111968897s

• [SLOW TEST:27.137 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:52:16.680: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8026
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Sep 27 06:52:19.368: INFO: Successfully updated pod "annotationupdate17fbfe40-803f-4cfc-8ca7-6103b58dfcb4"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:52:23.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8026" for this suite.
Sep 27 06:52:45.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:52:45.498: INFO: namespace projected-8026 deletion completed in 22.0987735s

• [SLOW TEST:28.818 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:52:45.498: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-3582
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-3582
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-3582
STEP: Deleting pre-stop pod
Sep 27 06:52:54.707: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:52:54.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-3582" for this suite.
Sep 27 06:53:32.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:53:32.822: INFO: namespace prestop-3582 deletion completed in 38.103330131s

• [SLOW TEST:47.323 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:53:32.822: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6295
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 06:53:32.998: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"e7f5b12f-171a-48f5-83d7-406cc5556888", Controller:(*bool)(0xc00245a6ca), BlockOwnerDeletion:(*bool)(0xc00245a6cb)}}
Sep 27 06:53:33.004: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"5de1671e-6895-4f29-a5cd-cfd58b76e7d0", Controller:(*bool)(0xc00213435a), BlockOwnerDeletion:(*bool)(0xc00213435b)}}
Sep 27 06:53:33.012: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"58236e43-778e-45b8-ae3e-fd3ff51e5d70", Controller:(*bool)(0xc001b28346), BlockOwnerDeletion:(*bool)(0xc001b28347)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:53:38.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6295" for this suite.
Sep 27 06:53:44.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:53:44.184: INFO: namespace gc-6295 deletion completed in 6.150165592s

• [SLOW TEST:11.362 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:53:44.184: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7906
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep 27 06:53:44.362: INFO: Waiting up to 5m0s for pod "pod-cf4dc26c-d57c-4fd3-8551-5a53f98c0631" in namespace "emptydir-7906" to be "success or failure"
Sep 27 06:53:44.370: INFO: Pod "pod-cf4dc26c-d57c-4fd3-8551-5a53f98c0631": Phase="Pending", Reason="", readiness=false. Elapsed: 7.950623ms
Sep 27 06:53:46.373: INFO: Pod "pod-cf4dc26c-d57c-4fd3-8551-5a53f98c0631": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011737589s
STEP: Saw pod success
Sep 27 06:53:46.373: INFO: Pod "pod-cf4dc26c-d57c-4fd3-8551-5a53f98c0631" satisfied condition "success or failure"
Sep 27 06:53:46.381: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-cf4dc26c-d57c-4fd3-8551-5a53f98c0631 container test-container: <nil>
STEP: delete the pod
Sep 27 06:53:46.436: INFO: Waiting for pod pod-cf4dc26c-d57c-4fd3-8551-5a53f98c0631 to disappear
Sep 27 06:53:46.443: INFO: Pod pod-cf4dc26c-d57c-4fd3-8551-5a53f98c0631 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:53:46.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7906" for this suite.
Sep 27 06:53:52.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:53:52.800: INFO: namespace emptydir-7906 deletion completed in 6.340967558s

• [SLOW TEST:8.617 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:53:52.801: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7105
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-lgvh
STEP: Creating a pod to test atomic-volume-subpath
Sep 27 06:53:53.070: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-lgvh" in namespace "subpath-7105" to be "success or failure"
Sep 27 06:53:53.080: INFO: Pod "pod-subpath-test-secret-lgvh": Phase="Pending", Reason="", readiness=false. Elapsed: 9.866555ms
Sep 27 06:53:55.086: INFO: Pod "pod-subpath-test-secret-lgvh": Phase="Running", Reason="", readiness=true. Elapsed: 2.015417031s
Sep 27 06:53:57.089: INFO: Pod "pod-subpath-test-secret-lgvh": Phase="Running", Reason="", readiness=true. Elapsed: 4.019008645s
Sep 27 06:53:59.093: INFO: Pod "pod-subpath-test-secret-lgvh": Phase="Running", Reason="", readiness=true. Elapsed: 6.02329814s
Sep 27 06:54:01.097: INFO: Pod "pod-subpath-test-secret-lgvh": Phase="Running", Reason="", readiness=true. Elapsed: 8.027267305s
Sep 27 06:54:03.101: INFO: Pod "pod-subpath-test-secret-lgvh": Phase="Running", Reason="", readiness=true. Elapsed: 10.030644779s
Sep 27 06:54:05.105: INFO: Pod "pod-subpath-test-secret-lgvh": Phase="Running", Reason="", readiness=true. Elapsed: 12.034484142s
Sep 27 06:54:07.108: INFO: Pod "pod-subpath-test-secret-lgvh": Phase="Running", Reason="", readiness=true. Elapsed: 14.038248887s
Sep 27 06:54:09.112: INFO: Pod "pod-subpath-test-secret-lgvh": Phase="Running", Reason="", readiness=true. Elapsed: 16.041537531s
Sep 27 06:54:11.118: INFO: Pod "pod-subpath-test-secret-lgvh": Phase="Running", Reason="", readiness=true. Elapsed: 18.047968183s
Sep 27 06:54:13.138: INFO: Pod "pod-subpath-test-secret-lgvh": Phase="Running", Reason="", readiness=true. Elapsed: 20.067808645s
Sep 27 06:54:15.148: INFO: Pod "pod-subpath-test-secret-lgvh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.078198094s
STEP: Saw pod success
Sep 27 06:54:15.148: INFO: Pod "pod-subpath-test-secret-lgvh" satisfied condition "success or failure"
Sep 27 06:54:15.156: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-subpath-test-secret-lgvh container test-container-subpath-secret-lgvh: <nil>
STEP: delete the pod
Sep 27 06:54:15.199: INFO: Waiting for pod pod-subpath-test-secret-lgvh to disappear
Sep 27 06:54:15.202: INFO: Pod pod-subpath-test-secret-lgvh no longer exists
STEP: Deleting pod pod-subpath-test-secret-lgvh
Sep 27 06:54:15.202: INFO: Deleting pod "pod-subpath-test-secret-lgvh" in namespace "subpath-7105"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:54:15.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7105" for this suite.
Sep 27 06:54:21.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:54:21.346: INFO: namespace subpath-7105 deletion completed in 6.122244652s

• [SLOW TEST:28.545 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:54:21.346: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9493
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 06:54:21.485: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Sep 27 06:54:21.495: INFO: Pod name sample-pod: Found 0 pods out of 1
Sep 27 06:54:26.501: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 27 06:54:26.501: INFO: Creating deployment "test-rolling-update-deployment"
Sep 27 06:54:26.507: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Sep 27 06:54:26.513: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Sep 27 06:54:28.520: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Sep 27 06:54:28.522: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Sep 27 06:54:28.530: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-9493,SelfLink:/apis/apps/v1/namespaces/deployment-9493/deployments/test-rolling-update-deployment,UID:3a680c3e-84e0-4098-b450-e730c2337ad8,ResourceVersion:27525,Generation:1,CreationTimestamp:2019-09-27 06:54:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-27 06:54:26 +0000 UTC 2019-09-27 06:54:26 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-27 06:54:27 +0000 UTC 2019-09-27 06:54:26 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep 27 06:54:28.532: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-9493,SelfLink:/apis/apps/v1/namespaces/deployment-9493/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:e21df289-859f-414a-81c3-32fca9eae6f9,ResourceVersion:27514,Generation:1,CreationTimestamp:2019-09-27 06:54:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 3a680c3e-84e0-4098-b450-e730c2337ad8 0xc002959927 0xc002959928}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep 27 06:54:28.532: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Sep 27 06:54:28.532: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-9493,SelfLink:/apis/apps/v1/namespaces/deployment-9493/replicasets/test-rolling-update-controller,UID:56d7b347-b3b0-4ef1-8c6a-06ce47db1bb9,ResourceVersion:27524,Generation:2,CreationTimestamp:2019-09-27 06:54:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 3a680c3e-84e0-4098-b450-e730c2337ad8 0xc002959857 0xc002959858}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 27 06:54:28.535: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-bwhcv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-bwhcv,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-9493,SelfLink:/api/v1/namespaces/deployment-9493/pods/test-rolling-update-deployment-79f6b9d75c-bwhcv,UID:b2297aa6-5dc6-4a7b-a72e-f7d9c64a40d5,ResourceVersion:27513,Generation:0,CreationTimestamp:2019-09-27 06:54:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c e21df289-859f-414a-81c3-32fca9eae6f9 0xc002ccec27 0xc002ccec28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r6zs9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r6zs9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-r6zs9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker3.dev-bj.kubeoperator.io,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:54:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:54:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:54:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 06:54:26 +0000 UTC  }],Message:,Reason:,HostIP:172.16.10.234,PodIP:172.20.5.211,StartTime:2019-09-27 06:54:26 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-27 06:54:27 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker://sha256:e4423e943a205fe1d81768e60603c8f2c5821576bad0801c1e91b8ba586124a0 docker://51d1a6e64e5b84d59d2e1de952c4fca209c78b58043e56e5bb8813267ab6aa21}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:54:28.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9493" for this suite.
Sep 27 06:54:34.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:54:34.769: INFO: namespace deployment-9493 deletion completed in 6.229447265s

• [SLOW TEST:13.423 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:54:34.769: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4793
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1613
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 27 06:54:34.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-4793'
Sep 27 06:54:35.079: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 27 06:54:35.079: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1618
Sep 27 06:54:35.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 delete jobs e2e-test-nginx-job --namespace=kubectl-4793'
Sep 27 06:54:35.206: INFO: stderr: ""
Sep 27 06:54:35.206: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:54:35.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4793" for this suite.
Sep 27 06:54:57.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:54:57.336: INFO: namespace kubectl-4793 deletion completed in 22.114360735s

• [SLOW TEST:22.567 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:54:57.336: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4835
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Sep 27 06:54:57.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 create -f - --namespace=kubectl-4835'
Sep 27 06:54:57.691: INFO: stderr: ""
Sep 27 06:54:57.691: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 27 06:54:57.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4835'
Sep 27 06:54:57.776: INFO: stderr: ""
Sep 27 06:54:57.776: INFO: stdout: "update-demo-nautilus-99zc9 update-demo-nautilus-ph4mq "
Sep 27 06:54:57.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods update-demo-nautilus-99zc9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4835'
Sep 27 06:54:57.857: INFO: stderr: ""
Sep 27 06:54:57.857: INFO: stdout: ""
Sep 27 06:54:57.857: INFO: update-demo-nautilus-99zc9 is created but not running
Sep 27 06:55:02.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4835'
Sep 27 06:55:02.941: INFO: stderr: ""
Sep 27 06:55:02.941: INFO: stdout: "update-demo-nautilus-99zc9 update-demo-nautilus-ph4mq "
Sep 27 06:55:02.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods update-demo-nautilus-99zc9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4835'
Sep 27 06:55:03.022: INFO: stderr: ""
Sep 27 06:55:03.022: INFO: stdout: "true"
Sep 27 06:55:03.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods update-demo-nautilus-99zc9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4835'
Sep 27 06:55:03.101: INFO: stderr: ""
Sep 27 06:55:03.101: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 27 06:55:03.101: INFO: validating pod update-demo-nautilus-99zc9
Sep 27 06:55:03.105: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 27 06:55:03.105: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 27 06:55:03.105: INFO: update-demo-nautilus-99zc9 is verified up and running
Sep 27 06:55:03.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods update-demo-nautilus-ph4mq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4835'
Sep 27 06:55:03.180: INFO: stderr: ""
Sep 27 06:55:03.180: INFO: stdout: "true"
Sep 27 06:55:03.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods update-demo-nautilus-ph4mq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4835'
Sep 27 06:55:03.266: INFO: stderr: ""
Sep 27 06:55:03.266: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 27 06:55:03.266: INFO: validating pod update-demo-nautilus-ph4mq
Sep 27 06:55:03.271: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 27 06:55:03.271: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 27 06:55:03.271: INFO: update-demo-nautilus-ph4mq is verified up and running
STEP: using delete to clean up resources
Sep 27 06:55:03.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 delete --grace-period=0 --force -f - --namespace=kubectl-4835'
Sep 27 06:55:03.361: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 27 06:55:03.361: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep 27 06:55:03.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4835'
Sep 27 06:55:03.443: INFO: stderr: "No resources found.\n"
Sep 27 06:55:03.443: INFO: stdout: ""
Sep 27 06:55:03.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods -l name=update-demo --namespace=kubectl-4835 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 27 06:55:03.525: INFO: stderr: ""
Sep 27 06:55:03.525: INFO: stdout: "update-demo-nautilus-99zc9\nupdate-demo-nautilus-ph4mq\n"
Sep 27 06:55:04.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4835'
Sep 27 06:55:04.111: INFO: stderr: "No resources found.\n"
Sep 27 06:55:04.111: INFO: stdout: ""
Sep 27 06:55:04.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods -l name=update-demo --namespace=kubectl-4835 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 27 06:55:04.193: INFO: stderr: ""
Sep 27 06:55:04.193: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:55:04.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4835" for this suite.
Sep 27 06:55:26.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:55:26.284: INFO: namespace kubectl-4835 deletion completed in 22.087004329s

• [SLOW TEST:28.948 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:55:26.285: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1453
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 06:55:26.437: INFO: Waiting up to 5m0s for pod "downwardapi-volume-08af3460-c622-46de-a649-8ec4b575fb29" in namespace "projected-1453" to be "success or failure"
Sep 27 06:55:26.441: INFO: Pod "downwardapi-volume-08af3460-c622-46de-a649-8ec4b575fb29": Phase="Pending", Reason="", readiness=false. Elapsed: 4.049231ms
Sep 27 06:55:28.445: INFO: Pod "downwardapi-volume-08af3460-c622-46de-a649-8ec4b575fb29": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007579431s
STEP: Saw pod success
Sep 27 06:55:28.445: INFO: Pod "downwardapi-volume-08af3460-c622-46de-a649-8ec4b575fb29" satisfied condition "success or failure"
Sep 27 06:55:28.447: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod downwardapi-volume-08af3460-c622-46de-a649-8ec4b575fb29 container client-container: <nil>
STEP: delete the pod
Sep 27 06:55:28.466: INFO: Waiting for pod downwardapi-volume-08af3460-c622-46de-a649-8ec4b575fb29 to disappear
Sep 27 06:55:28.469: INFO: Pod downwardapi-volume-08af3460-c622-46de-a649-8ec4b575fb29 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:55:28.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1453" for this suite.
Sep 27 06:55:34.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:55:34.577: INFO: namespace projected-1453 deletion completed in 6.102649331s

• [SLOW TEST:8.292 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:55:34.578: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3944
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-3944
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 27 06:55:34.722: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 27 06:55:54.816: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.20.4.38 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3944 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 06:55:54.816: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
Sep 27 06:55:55.923: INFO: Found all expected endpoints: [netserver-0]
Sep 27 06:55:55.926: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.20.5.215 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3944 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 06:55:55.927: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
Sep 27 06:55:57.037: INFO: Found all expected endpoints: [netserver-1]
Sep 27 06:55:57.041: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.20.3.78 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3944 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 06:55:57.041: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
Sep 27 06:55:58.137: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:55:58.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3944" for this suite.
Sep 27 06:56:20.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:56:20.248: INFO: namespace pod-network-test-3944 deletion completed in 22.105807975s

• [SLOW TEST:45.671 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:56:20.248: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-844
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-0cd6604f-2054-4312-b236-24e09cfbae94 in namespace container-probe-844
Sep 27 06:56:22.411: INFO: Started pod busybox-0cd6604f-2054-4312-b236-24e09cfbae94 in namespace container-probe-844
STEP: checking the pod's current state and verifying that restartCount is present
Sep 27 06:56:22.414: INFO: Initial restart count of pod busybox-0cd6604f-2054-4312-b236-24e09cfbae94 is 0
Sep 27 06:57:14.523: INFO: Restart count of pod container-probe-844/busybox-0cd6604f-2054-4312-b236-24e09cfbae94 is now 1 (52.10930082s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:57:14.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-844" for this suite.
Sep 27 06:57:20.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:57:20.634: INFO: namespace container-probe-844 deletion completed in 6.092648624s

• [SLOW TEST:60.386 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:57:20.635: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6252
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-d25f608e-68ad-42ab-9a5a-56f09974ca79
STEP: Creating a pod to test consume secrets
Sep 27 06:57:20.803: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1c3402f2-200d-40b6-8f32-6eec26904d26" in namespace "projected-6252" to be "success or failure"
Sep 27 06:57:20.807: INFO: Pod "pod-projected-secrets-1c3402f2-200d-40b6-8f32-6eec26904d26": Phase="Pending", Reason="", readiness=false. Elapsed: 4.582107ms
Sep 27 06:57:22.811: INFO: Pod "pod-projected-secrets-1c3402f2-200d-40b6-8f32-6eec26904d26": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008319684s
STEP: Saw pod success
Sep 27 06:57:22.811: INFO: Pod "pod-projected-secrets-1c3402f2-200d-40b6-8f32-6eec26904d26" satisfied condition "success or failure"
Sep 27 06:57:22.814: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-projected-secrets-1c3402f2-200d-40b6-8f32-6eec26904d26 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 27 06:57:22.838: INFO: Waiting for pod pod-projected-secrets-1c3402f2-200d-40b6-8f32-6eec26904d26 to disappear
Sep 27 06:57:22.840: INFO: Pod pod-projected-secrets-1c3402f2-200d-40b6-8f32-6eec26904d26 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:57:22.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6252" for this suite.
Sep 27 06:57:28.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:57:28.938: INFO: namespace projected-6252 deletion completed in 6.093257466s

• [SLOW TEST:8.303 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:57:28.938: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1588
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Sep 27 06:57:39.134: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W0927 06:57:39.134772      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 27 06:57:39.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1588" for this suite.
Sep 27 06:57:45.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:57:45.244: INFO: namespace gc-1588 deletion completed in 6.104211624s

• [SLOW TEST:16.306 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:57:45.244: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6748
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 06:57:45.397: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e7a163b9-a3f7-44b9-bc8f-dfcffa79402a" in namespace "projected-6748" to be "success or failure"
Sep 27 06:57:45.403: INFO: Pod "downwardapi-volume-e7a163b9-a3f7-44b9-bc8f-dfcffa79402a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.813976ms
Sep 27 06:57:47.407: INFO: Pod "downwardapi-volume-e7a163b9-a3f7-44b9-bc8f-dfcffa79402a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009391104s
STEP: Saw pod success
Sep 27 06:57:47.407: INFO: Pod "downwardapi-volume-e7a163b9-a3f7-44b9-bc8f-dfcffa79402a" satisfied condition "success or failure"
Sep 27 06:57:47.410: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod downwardapi-volume-e7a163b9-a3f7-44b9-bc8f-dfcffa79402a container client-container: <nil>
STEP: delete the pod
Sep 27 06:57:47.440: INFO: Waiting for pod downwardapi-volume-e7a163b9-a3f7-44b9-bc8f-dfcffa79402a to disappear
Sep 27 06:57:47.443: INFO: Pod downwardapi-volume-e7a163b9-a3f7-44b9-bc8f-dfcffa79402a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:57:47.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6748" for this suite.
Sep 27 06:57:53.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:57:53.549: INFO: namespace projected-6748 deletion completed in 6.102339454s

• [SLOW TEST:8.305 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:57:53.550: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6506
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 06:57:53.707: INFO: Waiting up to 5m0s for pod "downwardapi-volume-60340c21-64d3-4257-a2fd-76a160538b27" in namespace "downward-api-6506" to be "success or failure"
Sep 27 06:57:53.711: INFO: Pod "downwardapi-volume-60340c21-64d3-4257-a2fd-76a160538b27": Phase="Pending", Reason="", readiness=false. Elapsed: 4.094717ms
Sep 27 06:57:55.715: INFO: Pod "downwardapi-volume-60340c21-64d3-4257-a2fd-76a160538b27": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007899358s
STEP: Saw pod success
Sep 27 06:57:55.715: INFO: Pod "downwardapi-volume-60340c21-64d3-4257-a2fd-76a160538b27" satisfied condition "success or failure"
Sep 27 06:57:55.717: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod downwardapi-volume-60340c21-64d3-4257-a2fd-76a160538b27 container client-container: <nil>
STEP: delete the pod
Sep 27 06:57:55.740: INFO: Waiting for pod downwardapi-volume-60340c21-64d3-4257-a2fd-76a160538b27 to disappear
Sep 27 06:57:55.743: INFO: Pod downwardapi-volume-60340c21-64d3-4257-a2fd-76a160538b27 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:57:55.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6506" for this suite.
Sep 27 06:58:01.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:58:01.850: INFO: namespace downward-api-6506 deletion completed in 6.103562903s

• [SLOW TEST:8.301 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:58:01.851: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8420
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:58:01.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8420" for this suite.
Sep 27 06:58:08.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:58:08.095: INFO: namespace services-8420 deletion completed in 6.091894943s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.244 seconds]
[sig-network] Services
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:58:08.095: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8113
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1517
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 27 06:58:08.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-8113'
Sep 27 06:58:08.341: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 27 06:58:08.341: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Sep 27 06:58:08.353: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Sep 27 06:58:08.368: INFO: scanned /root for discovery docs: <nil>
Sep 27 06:58:08.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-8113'
Sep 27 06:58:24.185: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep 27 06:58:24.185: INFO: stdout: "Created e2e-test-nginx-rc-f152cf2a32fa8bd49aa54ad65951a8cc\nScaling up e2e-test-nginx-rc-f152cf2a32fa8bd49aa54ad65951a8cc from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-f152cf2a32fa8bd49aa54ad65951a8cc up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-f152cf2a32fa8bd49aa54ad65951a8cc to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Sep 27 06:58:24.185: INFO: stdout: "Created e2e-test-nginx-rc-f152cf2a32fa8bd49aa54ad65951a8cc\nScaling up e2e-test-nginx-rc-f152cf2a32fa8bd49aa54ad65951a8cc from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-f152cf2a32fa8bd49aa54ad65951a8cc up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-f152cf2a32fa8bd49aa54ad65951a8cc to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Sep 27 06:58:24.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-8113'
Sep 27 06:58:24.268: INFO: stderr: ""
Sep 27 06:58:24.268: INFO: stdout: "e2e-test-nginx-rc-f152cf2a32fa8bd49aa54ad65951a8cc-85tf7 "
Sep 27 06:58:24.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods e2e-test-nginx-rc-f152cf2a32fa8bd49aa54ad65951a8cc-85tf7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8113'
Sep 27 06:58:24.346: INFO: stderr: ""
Sep 27 06:58:24.346: INFO: stdout: "true"
Sep 27 06:58:24.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods e2e-test-nginx-rc-f152cf2a32fa8bd49aa54ad65951a8cc-85tf7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8113'
Sep 27 06:58:24.419: INFO: stderr: ""
Sep 27 06:58:24.419: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Sep 27 06:58:24.419: INFO: e2e-test-nginx-rc-f152cf2a32fa8bd49aa54ad65951a8cc-85tf7 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1523
Sep 27 06:58:24.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 delete rc e2e-test-nginx-rc --namespace=kubectl-8113'
Sep 27 06:58:24.502: INFO: stderr: ""
Sep 27 06:58:24.502: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:58:24.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8113" for this suite.
Sep 27 06:58:30.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:58:30.605: INFO: namespace kubectl-8113 deletion completed in 6.098139164s

• [SLOW TEST:22.510 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:58:30.606: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3463
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Sep 27 06:58:33.285: INFO: Successfully updated pod "labelsupdate26aff6d7-d216-4d24-b315-6e007323e494"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:58:37.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3463" for this suite.
Sep 27 06:58:59.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:58:59.419: INFO: namespace downward-api-3463 deletion completed in 22.100885121s

• [SLOW TEST:28.813 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:58:59.419: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1667
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep 27 06:58:59.623: INFO: Waiting up to 5m0s for pod "pod-e0395fc5-081b-4b7b-9da8-034c4df74a18" in namespace "emptydir-1667" to be "success or failure"
Sep 27 06:58:59.627: INFO: Pod "pod-e0395fc5-081b-4b7b-9da8-034c4df74a18": Phase="Pending", Reason="", readiness=false. Elapsed: 3.89578ms
Sep 27 06:59:01.630: INFO: Pod "pod-e0395fc5-081b-4b7b-9da8-034c4df74a18": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007392842s
STEP: Saw pod success
Sep 27 06:59:01.630: INFO: Pod "pod-e0395fc5-081b-4b7b-9da8-034c4df74a18" satisfied condition "success or failure"
Sep 27 06:59:01.633: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-e0395fc5-081b-4b7b-9da8-034c4df74a18 container test-container: <nil>
STEP: delete the pod
Sep 27 06:59:01.653: INFO: Waiting for pod pod-e0395fc5-081b-4b7b-9da8-034c4df74a18 to disappear
Sep 27 06:59:01.671: INFO: Pod pod-e0395fc5-081b-4b7b-9da8-034c4df74a18 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:59:01.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1667" for this suite.
Sep 27 06:59:07.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 06:59:07.800: INFO: namespace emptydir-1667 deletion completed in 6.11802132s

• [SLOW TEST:8.381 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 06:59:07.800: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-452
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep 27 06:59:11.996: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 06:59:11.998: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 06:59:13.999: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 06:59:14.002: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 06:59:15.999: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 06:59:16.007: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 06:59:17.999: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 06:59:18.002: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 06:59:19.999: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 06:59:20.002: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 06:59:21.999: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 06:59:22.005: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 06:59:23.999: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 06:59:24.002: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 06:59:25.999: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 06:59:26.002: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 06:59:27.999: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 06:59:28.002: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 06:59:29.999: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 06:59:30.002: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 06:59:31.999: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 06:59:32.003: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 06:59:33.999: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 06:59:34.002: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 06:59:35.999: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 06:59:36.002: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 06:59:37.999: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 06:59:38.002: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 06:59:39.999: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 06:59:40.002: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 06:59:41.999: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 06:59:42.002: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 06:59:42.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-452" for this suite.
Sep 27 07:00:04.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:00:04.100: INFO: namespace container-lifecycle-hook-452 deletion completed in 22.093621745s

• [SLOW TEST:56.300 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:00:04.100: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4089
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-9165
STEP: Creating secret with name secret-test-c146300e-ede6-48fc-a16b-e55c03c7772d
STEP: Creating a pod to test consume secrets
Sep 27 07:00:04.418: INFO: Waiting up to 5m0s for pod "pod-secrets-361615f6-baab-4b3e-af27-2a04c7c047be" in namespace "secrets-4089" to be "success or failure"
Sep 27 07:00:04.423: INFO: Pod "pod-secrets-361615f6-baab-4b3e-af27-2a04c7c047be": Phase="Pending", Reason="", readiness=false. Elapsed: 4.6039ms
Sep 27 07:00:06.426: INFO: Pod "pod-secrets-361615f6-baab-4b3e-af27-2a04c7c047be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0082489s
STEP: Saw pod success
Sep 27 07:00:06.426: INFO: Pod "pod-secrets-361615f6-baab-4b3e-af27-2a04c7c047be" satisfied condition "success or failure"
Sep 27 07:00:06.429: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-secrets-361615f6-baab-4b3e-af27-2a04c7c047be container secret-volume-test: <nil>
STEP: delete the pod
Sep 27 07:00:06.450: INFO: Waiting for pod pod-secrets-361615f6-baab-4b3e-af27-2a04c7c047be to disappear
Sep 27 07:00:06.454: INFO: Pod pod-secrets-361615f6-baab-4b3e-af27-2a04c7c047be no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:00:06.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4089" for this suite.
Sep 27 07:00:12.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:00:12.558: INFO: namespace secrets-4089 deletion completed in 6.100055911s
STEP: Destroying namespace "secret-namespace-9165" for this suite.
Sep 27 07:00:18.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:00:18.646: INFO: namespace secret-namespace-9165 deletion completed in 6.087466067s

• [SLOW TEST:14.546 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:00:18.646: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5204
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep 27 07:00:18.807: INFO: Waiting up to 5m0s for pod "downward-api-7088b812-04f7-4ea5-bd6f-8ab5e5fe180b" in namespace "downward-api-5204" to be "success or failure"
Sep 27 07:00:18.812: INFO: Pod "downward-api-7088b812-04f7-4ea5-bd6f-8ab5e5fe180b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.807112ms
Sep 27 07:00:20.817: INFO: Pod "downward-api-7088b812-04f7-4ea5-bd6f-8ab5e5fe180b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009328209s
STEP: Saw pod success
Sep 27 07:00:20.817: INFO: Pod "downward-api-7088b812-04f7-4ea5-bd6f-8ab5e5fe180b" satisfied condition "success or failure"
Sep 27 07:00:20.821: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod downward-api-7088b812-04f7-4ea5-bd6f-8ab5e5fe180b container dapi-container: <nil>
STEP: delete the pod
Sep 27 07:00:20.854: INFO: Waiting for pod downward-api-7088b812-04f7-4ea5-bd6f-8ab5e5fe180b to disappear
Sep 27 07:00:20.857: INFO: Pod downward-api-7088b812-04f7-4ea5-bd6f-8ab5e5fe180b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:00:20.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5204" for this suite.
Sep 27 07:00:26.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:00:26.952: INFO: namespace downward-api-5204 deletion completed in 6.090956257s

• [SLOW TEST:8.306 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:00:26.953: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5492
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:00:27.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5492" for this suite.
Sep 27 07:00:33.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:00:33.231: INFO: namespace kubelet-test-5492 deletion completed in 6.104095647s

• [SLOW TEST:6.278 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:00:33.231: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6506
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep 27 07:00:33.385: INFO: Waiting up to 5m0s for pod "pod-f694264d-8d32-43cd-9a87-303cfa2e6466" in namespace "emptydir-6506" to be "success or failure"
Sep 27 07:00:33.389: INFO: Pod "pod-f694264d-8d32-43cd-9a87-303cfa2e6466": Phase="Pending", Reason="", readiness=false. Elapsed: 4.192968ms
Sep 27 07:00:35.393: INFO: Pod "pod-f694264d-8d32-43cd-9a87-303cfa2e6466": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007737506s
STEP: Saw pod success
Sep 27 07:00:35.393: INFO: Pod "pod-f694264d-8d32-43cd-9a87-303cfa2e6466" satisfied condition "success or failure"
Sep 27 07:00:35.396: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-f694264d-8d32-43cd-9a87-303cfa2e6466 container test-container: <nil>
STEP: delete the pod
Sep 27 07:00:35.418: INFO: Waiting for pod pod-f694264d-8d32-43cd-9a87-303cfa2e6466 to disappear
Sep 27 07:00:35.421: INFO: Pod pod-f694264d-8d32-43cd-9a87-303cfa2e6466 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:00:35.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6506" for this suite.
Sep 27 07:00:41.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:00:41.518: INFO: namespace emptydir-6506 deletion completed in 6.093035066s

• [SLOW TEST:8.287 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:00:41.518: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8129
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-f439d56b-788b-4644-92c9-f78764252ef1
STEP: Creating a pod to test consume configMaps
Sep 27 07:00:41.680: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b158d7a9-01a3-4c7f-a01f-05f860ef4863" in namespace "projected-8129" to be "success or failure"
Sep 27 07:00:41.685: INFO: Pod "pod-projected-configmaps-b158d7a9-01a3-4c7f-a01f-05f860ef4863": Phase="Pending", Reason="", readiness=false. Elapsed: 4.838259ms
Sep 27 07:00:43.689: INFO: Pod "pod-projected-configmaps-b158d7a9-01a3-4c7f-a01f-05f860ef4863": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009309033s
STEP: Saw pod success
Sep 27 07:00:43.689: INFO: Pod "pod-projected-configmaps-b158d7a9-01a3-4c7f-a01f-05f860ef4863" satisfied condition "success or failure"
Sep 27 07:00:43.692: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-projected-configmaps-b158d7a9-01a3-4c7f-a01f-05f860ef4863 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 07:00:43.713: INFO: Waiting for pod pod-projected-configmaps-b158d7a9-01a3-4c7f-a01f-05f860ef4863 to disappear
Sep 27 07:00:43.715: INFO: Pod pod-projected-configmaps-b158d7a9-01a3-4c7f-a01f-05f860ef4863 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:00:43.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8129" for this suite.
Sep 27 07:00:49.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:00:49.836: INFO: namespace projected-8129 deletion completed in 6.114826818s

• [SLOW TEST:8.318 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:00:49.837: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8519
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep 27 07:00:49.996: INFO: Waiting up to 5m0s for pod "pod-b382ad65-9a16-4593-a7b2-59caa2e4f2f6" in namespace "emptydir-8519" to be "success or failure"
Sep 27 07:00:50.001: INFO: Pod "pod-b382ad65-9a16-4593-a7b2-59caa2e4f2f6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.557196ms
Sep 27 07:00:52.004: INFO: Pod "pod-b382ad65-9a16-4593-a7b2-59caa2e4f2f6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008297305s
STEP: Saw pod success
Sep 27 07:00:52.004: INFO: Pod "pod-b382ad65-9a16-4593-a7b2-59caa2e4f2f6" satisfied condition "success or failure"
Sep 27 07:00:52.007: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-b382ad65-9a16-4593-a7b2-59caa2e4f2f6 container test-container: <nil>
STEP: delete the pod
Sep 27 07:00:52.025: INFO: Waiting for pod pod-b382ad65-9a16-4593-a7b2-59caa2e4f2f6 to disappear
Sep 27 07:00:52.032: INFO: Pod pod-b382ad65-9a16-4593-a7b2-59caa2e4f2f6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:00:52.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8519" for this suite.
Sep 27 07:00:58.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:00:58.130: INFO: namespace emptydir-8519 deletion completed in 6.09357466s

• [SLOW TEST:8.293 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:00:58.130: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9029
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Sep 27 07:00:58.328: INFO: Waiting up to 5m0s for pod "client-containers-163301b3-9243-427e-aa5f-0ad589ca0a01" in namespace "containers-9029" to be "success or failure"
Sep 27 07:00:58.331: INFO: Pod "client-containers-163301b3-9243-427e-aa5f-0ad589ca0a01": Phase="Pending", Reason="", readiness=false. Elapsed: 3.38197ms
Sep 27 07:01:00.335: INFO: Pod "client-containers-163301b3-9243-427e-aa5f-0ad589ca0a01": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00683228s
STEP: Saw pod success
Sep 27 07:01:00.335: INFO: Pod "client-containers-163301b3-9243-427e-aa5f-0ad589ca0a01" satisfied condition "success or failure"
Sep 27 07:01:00.337: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod client-containers-163301b3-9243-427e-aa5f-0ad589ca0a01 container test-container: <nil>
STEP: delete the pod
Sep 27 07:01:00.355: INFO: Waiting for pod client-containers-163301b3-9243-427e-aa5f-0ad589ca0a01 to disappear
Sep 27 07:01:00.357: INFO: Pod client-containers-163301b3-9243-427e-aa5f-0ad589ca0a01 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:01:00.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9029" for this suite.
Sep 27 07:01:06.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:01:06.457: INFO: namespace containers-9029 deletion completed in 6.09526826s

• [SLOW TEST:8.326 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:01:06.457: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-709
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1211
STEP: creating the pod
Sep 27 07:01:06.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 create -f - --namespace=kubectl-709'
Sep 27 07:01:06.887: INFO: stderr: ""
Sep 27 07:01:06.887: INFO: stdout: "pod/pause created\n"
Sep 27 07:01:06.887: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Sep 27 07:01:06.887: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-709" to be "running and ready"
Sep 27 07:01:06.893: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.421503ms
Sep 27 07:01:08.897: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.00908865s
Sep 27 07:01:08.897: INFO: Pod "pause" satisfied condition "running and ready"
Sep 27 07:01:08.897: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Sep 27 07:01:08.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 label pods pause testing-label=testing-label-value --namespace=kubectl-709'
Sep 27 07:01:08.982: INFO: stderr: ""
Sep 27 07:01:08.982: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Sep 27 07:01:08.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pod pause -L testing-label --namespace=kubectl-709'
Sep 27 07:01:09.068: INFO: stderr: ""
Sep 27 07:01:09.068: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Sep 27 07:01:09.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 label pods pause testing-label- --namespace=kubectl-709'
Sep 27 07:01:09.148: INFO: stderr: ""
Sep 27 07:01:09.148: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Sep 27 07:01:09.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pod pause -L testing-label --namespace=kubectl-709'
Sep 27 07:01:09.225: INFO: stderr: ""
Sep 27 07:01:09.225: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1218
STEP: using delete to clean up resources
Sep 27 07:01:09.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 delete --grace-period=0 --force -f - --namespace=kubectl-709'
Sep 27 07:01:09.323: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 27 07:01:09.323: INFO: stdout: "pod \"pause\" force deleted\n"
Sep 27 07:01:09.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get rc,svc -l name=pause --no-headers --namespace=kubectl-709'
Sep 27 07:01:09.417: INFO: stderr: "No resources found.\n"
Sep 27 07:01:09.417: INFO: stdout: ""
Sep 27 07:01:09.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 get pods -l name=pause --namespace=kubectl-709 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 27 07:01:09.503: INFO: stderr: ""
Sep 27 07:01:09.503: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:01:09.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-709" for this suite.
Sep 27 07:01:15.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:01:15.597: INFO: namespace kubectl-709 deletion completed in 6.088815901s

• [SLOW TEST:9.140 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:01:15.597: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7435
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep 27 07:01:15.747: INFO: Waiting up to 5m0s for pod "downward-api-970b61bd-32c2-46de-a70a-6f0e926ffd38" in namespace "downward-api-7435" to be "success or failure"
Sep 27 07:01:15.752: INFO: Pod "downward-api-970b61bd-32c2-46de-a70a-6f0e926ffd38": Phase="Pending", Reason="", readiness=false. Elapsed: 5.230164ms
Sep 27 07:01:17.755: INFO: Pod "downward-api-970b61bd-32c2-46de-a70a-6f0e926ffd38": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008332932s
STEP: Saw pod success
Sep 27 07:01:17.755: INFO: Pod "downward-api-970b61bd-32c2-46de-a70a-6f0e926ffd38" satisfied condition "success or failure"
Sep 27 07:01:17.758: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod downward-api-970b61bd-32c2-46de-a70a-6f0e926ffd38 container dapi-container: <nil>
STEP: delete the pod
Sep 27 07:01:17.779: INFO: Waiting for pod downward-api-970b61bd-32c2-46de-a70a-6f0e926ffd38 to disappear
Sep 27 07:01:17.782: INFO: Pod downward-api-970b61bd-32c2-46de-a70a-6f0e926ffd38 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:01:17.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7435" for this suite.
Sep 27 07:01:23.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:01:23.889: INFO: namespace downward-api-7435 deletion completed in 6.103255149s

• [SLOW TEST:8.292 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:01:23.889: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-1324
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:01:27.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1324" for this suite.
Sep 27 07:01:49.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:01:49.216: INFO: namespace replication-controller-1324 deletion completed in 22.094591342s

• [SLOW TEST:25.327 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:01:49.216: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-537
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 07:01:49.359: INFO: Creating ReplicaSet my-hostname-basic-9b0838c8-554b-4d90-a6d2-1d1fd5267f6c
Sep 27 07:01:49.367: INFO: Pod name my-hostname-basic-9b0838c8-554b-4d90-a6d2-1d1fd5267f6c: Found 0 pods out of 1
Sep 27 07:01:54.371: INFO: Pod name my-hostname-basic-9b0838c8-554b-4d90-a6d2-1d1fd5267f6c: Found 1 pods out of 1
Sep 27 07:01:54.371: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-9b0838c8-554b-4d90-a6d2-1d1fd5267f6c" is running
Sep 27 07:01:54.373: INFO: Pod "my-hostname-basic-9b0838c8-554b-4d90-a6d2-1d1fd5267f6c-h7r7x" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-27 07:01:49 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-27 07:01:51 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-27 07:01:51 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-27 07:01:49 +0000 UTC Reason: Message:}])
Sep 27 07:01:54.373: INFO: Trying to dial the pod
Sep 27 07:01:59.384: INFO: Controller my-hostname-basic-9b0838c8-554b-4d90-a6d2-1d1fd5267f6c: Got expected result from replica 1 [my-hostname-basic-9b0838c8-554b-4d90-a6d2-1d1fd5267f6c-h7r7x]: "my-hostname-basic-9b0838c8-554b-4d90-a6d2-1d1fd5267f6c-h7r7x", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:01:59.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-537" for this suite.
Sep 27 07:02:05.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:02:05.478: INFO: namespace replicaset-537 deletion completed in 6.090113679s

• [SLOW TEST:16.262 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:02:05.478: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-882
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Sep 27 07:02:08.156: INFO: Successfully updated pod "labelsupdate940ebfa3-6dd9-4cc3-8fb1-80c26dcbd922"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:02:10.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-882" for this suite.
Sep 27 07:02:32.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:02:32.266: INFO: namespace projected-882 deletion completed in 22.089918226s

• [SLOW TEST:26.788 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:02:32.266: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9798
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Sep 27 07:02:32.409: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-833349834 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:02:32.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9798" for this suite.
Sep 27 07:02:38.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:02:38.566: INFO: namespace kubectl-9798 deletion completed in 6.087367214s

• [SLOW TEST:6.300 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:02:38.567: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-183
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep 27 07:02:38.719: INFO: Waiting up to 5m0s for pod "downward-api-cb16ddf6-4828-433e-951a-1de59ce00ca5" in namespace "downward-api-183" to be "success or failure"
Sep 27 07:02:38.725: INFO: Pod "downward-api-cb16ddf6-4828-433e-951a-1de59ce00ca5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.862055ms
Sep 27 07:02:40.729: INFO: Pod "downward-api-cb16ddf6-4828-433e-951a-1de59ce00ca5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009784914s
STEP: Saw pod success
Sep 27 07:02:40.729: INFO: Pod "downward-api-cb16ddf6-4828-433e-951a-1de59ce00ca5" satisfied condition "success or failure"
Sep 27 07:02:40.731: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod downward-api-cb16ddf6-4828-433e-951a-1de59ce00ca5 container dapi-container: <nil>
STEP: delete the pod
Sep 27 07:02:40.754: INFO: Waiting for pod downward-api-cb16ddf6-4828-433e-951a-1de59ce00ca5 to disappear
Sep 27 07:02:40.757: INFO: Pod downward-api-cb16ddf6-4828-433e-951a-1de59ce00ca5 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:02:40.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-183" for this suite.
Sep 27 07:02:46.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:02:46.853: INFO: namespace downward-api-183 deletion completed in 6.09182106s

• [SLOW TEST:8.286 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:02:46.853: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8800
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-8800/configmap-test-69ac3276-e6cc-4c7b-a373-d93b56e2a325
STEP: Creating a pod to test consume configMaps
Sep 27 07:02:47.065: INFO: Waiting up to 5m0s for pod "pod-configmaps-cce56327-93a0-467a-8565-92bb3070d893" in namespace "configmap-8800" to be "success or failure"
Sep 27 07:02:47.070: INFO: Pod "pod-configmaps-cce56327-93a0-467a-8565-92bb3070d893": Phase="Pending", Reason="", readiness=false. Elapsed: 4.291818ms
Sep 27 07:02:49.073: INFO: Pod "pod-configmaps-cce56327-93a0-467a-8565-92bb3070d893": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007477211s
STEP: Saw pod success
Sep 27 07:02:49.073: INFO: Pod "pod-configmaps-cce56327-93a0-467a-8565-92bb3070d893" satisfied condition "success or failure"
Sep 27 07:02:49.075: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-configmaps-cce56327-93a0-467a-8565-92bb3070d893 container env-test: <nil>
STEP: delete the pod
Sep 27 07:02:49.094: INFO: Waiting for pod pod-configmaps-cce56327-93a0-467a-8565-92bb3070d893 to disappear
Sep 27 07:02:49.097: INFO: Pod pod-configmaps-cce56327-93a0-467a-8565-92bb3070d893 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:02:49.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8800" for this suite.
Sep 27 07:02:55.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:02:55.192: INFO: namespace configmap-8800 deletion completed in 6.091235604s

• [SLOW TEST:8.340 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:02:55.192: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-114
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Sep 27 07:02:57.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-833349834 exec pod-sharedvolume-5c9e9651-6b92-41ba-bb63-2dfc803aae2d -c busybox-main-container --namespace=emptydir-114 -- cat /usr/share/volumeshare/shareddata.txt'
Sep 27 07:02:57.765: INFO: stderr: ""
Sep 27 07:02:57.765: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:02:57.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-114" for this suite.
Sep 27 07:03:03.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:03:03.869: INFO: namespace emptydir-114 deletion completed in 6.098807079s

• [SLOW TEST:8.677 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:03:03.869: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5401
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-5401
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 27 07:03:04.010: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 27 07:03:26.098: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.20.5.244:8080/dial?request=hostName&protocol=udp&host=172.20.3.80&port=8081&tries=1'] Namespace:pod-network-test-5401 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 07:03:26.098: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
Sep 27 07:03:26.218: INFO: Waiting for endpoints: map[]
Sep 27 07:03:26.222: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.20.5.244:8080/dial?request=hostName&protocol=udp&host=172.20.4.39&port=8081&tries=1'] Namespace:pod-network-test-5401 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 07:03:26.222: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
Sep 27 07:03:26.326: INFO: Waiting for endpoints: map[]
Sep 27 07:03:26.330: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.20.5.244:8080/dial?request=hostName&protocol=udp&host=172.20.5.243&port=8081&tries=1'] Namespace:pod-network-test-5401 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 07:03:26.330: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
Sep 27 07:03:26.426: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:03:26.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5401" for this suite.
Sep 27 07:03:48.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:03:48.523: INFO: namespace pod-network-test-5401 deletion completed in 22.091357359s

• [SLOW TEST:44.654 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:03:48.523: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-8800
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:03:50.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-8800" for this suite.
Sep 27 07:03:56.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:03:56.853: INFO: namespace emptydir-wrapper-8800 deletion completed in 6.111635433s

• [SLOW TEST:8.330 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:03:56.854: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8165
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 07:03:59.041: INFO: Waiting up to 5m0s for pod "client-envvars-3fe1d5fc-56cd-4b45-b878-77cfd29e0e78" in namespace "pods-8165" to be "success or failure"
Sep 27 07:03:59.046: INFO: Pod "client-envvars-3fe1d5fc-56cd-4b45-b878-77cfd29e0e78": Phase="Pending", Reason="", readiness=false. Elapsed: 4.57688ms
Sep 27 07:04:01.050: INFO: Pod "client-envvars-3fe1d5fc-56cd-4b45-b878-77cfd29e0e78": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00866126s
STEP: Saw pod success
Sep 27 07:04:01.050: INFO: Pod "client-envvars-3fe1d5fc-56cd-4b45-b878-77cfd29e0e78" satisfied condition "success or failure"
Sep 27 07:04:01.053: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod client-envvars-3fe1d5fc-56cd-4b45-b878-77cfd29e0e78 container env3cont: <nil>
STEP: delete the pod
Sep 27 07:04:01.074: INFO: Waiting for pod client-envvars-3fe1d5fc-56cd-4b45-b878-77cfd29e0e78 to disappear
Sep 27 07:04:01.077: INFO: Pod client-envvars-3fe1d5fc-56cd-4b45-b878-77cfd29e0e78 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:04:01.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8165" for this suite.
Sep 27 07:04:39.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:04:39.175: INFO: namespace pods-8165 deletion completed in 38.093513355s

• [SLOW TEST:42.321 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:04:39.175: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3468
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-7873cb3d-1380-4c83-9003-324bdc9e215e
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:04:39.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3468" for this suite.
Sep 27 07:04:45.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:04:45.419: INFO: namespace configmap-3468 deletion completed in 6.091123605s

• [SLOW TEST:6.244 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:04:45.419: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3792
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-5eb29acb-5a8f-4405-89ec-b105ae932896
STEP: Creating a pod to test consume secrets
Sep 27 07:04:45.570: INFO: Waiting up to 5m0s for pod "pod-secrets-91564fa5-aee0-4ac0-8973-1602a07a19a3" in namespace "secrets-3792" to be "success or failure"
Sep 27 07:04:45.574: INFO: Pod "pod-secrets-91564fa5-aee0-4ac0-8973-1602a07a19a3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.360191ms
Sep 27 07:04:47.578: INFO: Pod "pod-secrets-91564fa5-aee0-4ac0-8973-1602a07a19a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007560001s
STEP: Saw pod success
Sep 27 07:04:47.578: INFO: Pod "pod-secrets-91564fa5-aee0-4ac0-8973-1602a07a19a3" satisfied condition "success or failure"
Sep 27 07:04:47.580: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-secrets-91564fa5-aee0-4ac0-8973-1602a07a19a3 container secret-volume-test: <nil>
STEP: delete the pod
Sep 27 07:04:47.601: INFO: Waiting for pod pod-secrets-91564fa5-aee0-4ac0-8973-1602a07a19a3 to disappear
Sep 27 07:04:47.604: INFO: Pod pod-secrets-91564fa5-aee0-4ac0-8973-1602a07a19a3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:04:47.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3792" for this suite.
Sep 27 07:04:53.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:04:53.726: INFO: namespace secrets-3792 deletion completed in 6.117289017s

• [SLOW TEST:8.307 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:04:53.726: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8550
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-10e049dd-e597-47e4-a494-1f122dbc7ce1 in namespace container-probe-8550
Sep 27 07:04:55.912: INFO: Started pod test-webserver-10e049dd-e597-47e4-a494-1f122dbc7ce1 in namespace container-probe-8550
STEP: checking the pod's current state and verifying that restartCount is present
Sep 27 07:04:55.914: INFO: Initial restart count of pod test-webserver-10e049dd-e597-47e4-a494-1f122dbc7ce1 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:08:56.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8550" for this suite.
Sep 27 07:09:02.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:09:02.500: INFO: namespace container-probe-8550 deletion completed in 6.088411588s

• [SLOW TEST:248.774 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:09:02.500: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2536
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Sep 27 07:09:02.647: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2536,SelfLink:/api/v1/namespaces/watch-2536/configmaps/e2e-watch-test-configmap-a,UID:00ee3cd6-a52a-4181-b0db-640bee467a95,ResourceVersion:30497,Generation:0,CreationTimestamp:2019-09-27 07:09:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 27 07:09:02.648: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2536,SelfLink:/api/v1/namespaces/watch-2536/configmaps/e2e-watch-test-configmap-a,UID:00ee3cd6-a52a-4181-b0db-640bee467a95,ResourceVersion:30497,Generation:0,CreationTimestamp:2019-09-27 07:09:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Sep 27 07:09:12.656: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2536,SelfLink:/api/v1/namespaces/watch-2536/configmaps/e2e-watch-test-configmap-a,UID:00ee3cd6-a52a-4181-b0db-640bee467a95,ResourceVersion:30517,Generation:0,CreationTimestamp:2019-09-27 07:09:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep 27 07:09:12.656: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2536,SelfLink:/api/v1/namespaces/watch-2536/configmaps/e2e-watch-test-configmap-a,UID:00ee3cd6-a52a-4181-b0db-640bee467a95,ResourceVersion:30517,Generation:0,CreationTimestamp:2019-09-27 07:09:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Sep 27 07:09:22.672: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2536,SelfLink:/api/v1/namespaces/watch-2536/configmaps/e2e-watch-test-configmap-a,UID:00ee3cd6-a52a-4181-b0db-640bee467a95,ResourceVersion:30538,Generation:0,CreationTimestamp:2019-09-27 07:09:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 27 07:09:22.672: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2536,SelfLink:/api/v1/namespaces/watch-2536/configmaps/e2e-watch-test-configmap-a,UID:00ee3cd6-a52a-4181-b0db-640bee467a95,ResourceVersion:30538,Generation:0,CreationTimestamp:2019-09-27 07:09:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Sep 27 07:09:32.680: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2536,SelfLink:/api/v1/namespaces/watch-2536/configmaps/e2e-watch-test-configmap-a,UID:00ee3cd6-a52a-4181-b0db-640bee467a95,ResourceVersion:30562,Generation:0,CreationTimestamp:2019-09-27 07:09:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 27 07:09:32.680: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2536,SelfLink:/api/v1/namespaces/watch-2536/configmaps/e2e-watch-test-configmap-a,UID:00ee3cd6-a52a-4181-b0db-640bee467a95,ResourceVersion:30562,Generation:0,CreationTimestamp:2019-09-27 07:09:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Sep 27 07:09:42.691: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-2536,SelfLink:/api/v1/namespaces/watch-2536/configmaps/e2e-watch-test-configmap-b,UID:c8bbe223-e776-48fe-a3bd-813c15433039,ResourceVersion:30582,Generation:0,CreationTimestamp:2019-09-27 07:09:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 27 07:09:42.691: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-2536,SelfLink:/api/v1/namespaces/watch-2536/configmaps/e2e-watch-test-configmap-b,UID:c8bbe223-e776-48fe-a3bd-813c15433039,ResourceVersion:30582,Generation:0,CreationTimestamp:2019-09-27 07:09:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Sep 27 07:09:52.700: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-2536,SelfLink:/api/v1/namespaces/watch-2536/configmaps/e2e-watch-test-configmap-b,UID:c8bbe223-e776-48fe-a3bd-813c15433039,ResourceVersion:30602,Generation:0,CreationTimestamp:2019-09-27 07:09:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 27 07:09:52.700: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-2536,SelfLink:/api/v1/namespaces/watch-2536/configmaps/e2e-watch-test-configmap-b,UID:c8bbe223-e776-48fe-a3bd-813c15433039,ResourceVersion:30602,Generation:0,CreationTimestamp:2019-09-27 07:09:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:10:02.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2536" for this suite.
Sep 27 07:10:08.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:10:08.815: INFO: namespace watch-2536 deletion completed in 6.109540184s

• [SLOW TEST:66.315 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:10:08.815: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4198
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-c93a14f4-652c-47a7-ac7f-446b575785b6
STEP: Creating a pod to test consume secrets
Sep 27 07:10:08.972: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-09f1ecc3-fb3e-43e3-b16d-88a3cdde0b11" in namespace "projected-4198" to be "success or failure"
Sep 27 07:10:08.977: INFO: Pod "pod-projected-secrets-09f1ecc3-fb3e-43e3-b16d-88a3cdde0b11": Phase="Pending", Reason="", readiness=false. Elapsed: 4.804118ms
Sep 27 07:10:10.980: INFO: Pod "pod-projected-secrets-09f1ecc3-fb3e-43e3-b16d-88a3cdde0b11": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008093304s
STEP: Saw pod success
Sep 27 07:10:10.980: INFO: Pod "pod-projected-secrets-09f1ecc3-fb3e-43e3-b16d-88a3cdde0b11" satisfied condition "success or failure"
Sep 27 07:10:10.983: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-projected-secrets-09f1ecc3-fb3e-43e3-b16d-88a3cdde0b11 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 27 07:10:11.007: INFO: Waiting for pod pod-projected-secrets-09f1ecc3-fb3e-43e3-b16d-88a3cdde0b11 to disappear
Sep 27 07:10:11.010: INFO: Pod pod-projected-secrets-09f1ecc3-fb3e-43e3-b16d-88a3cdde0b11 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:10:11.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4198" for this suite.
Sep 27 07:10:17.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:10:17.110: INFO: namespace projected-4198 deletion completed in 6.096462935s

• [SLOW TEST:8.295 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:10:17.111: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4003
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-267f3fe8-ad91-4af8-a4d6-3e67be2e2b17
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-267f3fe8-ad91-4af8-a4d6-3e67be2e2b17
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:10:21.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4003" for this suite.
Sep 27 07:10:43.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:10:43.428: INFO: namespace projected-4003 deletion completed in 22.094588993s

• [SLOW TEST:26.317 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:10:43.428: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8010
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:11:04.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8010" for this suite.
Sep 27 07:11:10.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:11:10.886: INFO: namespace container-runtime-8010 deletion completed in 6.10290286s

• [SLOW TEST:27.458 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:11:10.886: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-119
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep 27 07:11:11.060: INFO: Waiting up to 5m0s for pod "downward-api-7f5de8d4-ff40-49a8-8b4c-d808e15a4559" in namespace "downward-api-119" to be "success or failure"
Sep 27 07:11:11.075: INFO: Pod "downward-api-7f5de8d4-ff40-49a8-8b4c-d808e15a4559": Phase="Pending", Reason="", readiness=false. Elapsed: 14.437294ms
Sep 27 07:11:13.078: INFO: Pod "downward-api-7f5de8d4-ff40-49a8-8b4c-d808e15a4559": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01794181s
STEP: Saw pod success
Sep 27 07:11:13.078: INFO: Pod "downward-api-7f5de8d4-ff40-49a8-8b4c-d808e15a4559" satisfied condition "success or failure"
Sep 27 07:11:13.081: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod downward-api-7f5de8d4-ff40-49a8-8b4c-d808e15a4559 container dapi-container: <nil>
STEP: delete the pod
Sep 27 07:11:13.104: INFO: Waiting for pod downward-api-7f5de8d4-ff40-49a8-8b4c-d808e15a4559 to disappear
Sep 27 07:11:13.106: INFO: Pod downward-api-7f5de8d4-ff40-49a8-8b4c-d808e15a4559 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:11:13.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-119" for this suite.
Sep 27 07:11:19.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:11:19.201: INFO: namespace downward-api-119 deletion completed in 6.090415654s

• [SLOW TEST:8.315 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:11:19.201: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6122
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-e4a06224-7f5d-4752-828a-eff7692a4474
STEP: Creating a pod to test consume configMaps
Sep 27 07:11:19.364: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c3f2f7e9-ddcd-476c-9d89-d27b939bd39a" in namespace "projected-6122" to be "success or failure"
Sep 27 07:11:19.368: INFO: Pod "pod-projected-configmaps-c3f2f7e9-ddcd-476c-9d89-d27b939bd39a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.758679ms
Sep 27 07:11:21.372: INFO: Pod "pod-projected-configmaps-c3f2f7e9-ddcd-476c-9d89-d27b939bd39a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007915766s
STEP: Saw pod success
Sep 27 07:11:21.372: INFO: Pod "pod-projected-configmaps-c3f2f7e9-ddcd-476c-9d89-d27b939bd39a" satisfied condition "success or failure"
Sep 27 07:11:21.374: INFO: Trying to get logs from node worker3.dev-bj.kubeoperator.io pod pod-projected-configmaps-c3f2f7e9-ddcd-476c-9d89-d27b939bd39a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 07:11:21.394: INFO: Waiting for pod pod-projected-configmaps-c3f2f7e9-ddcd-476c-9d89-d27b939bd39a to disappear
Sep 27 07:11:21.396: INFO: Pod pod-projected-configmaps-c3f2f7e9-ddcd-476c-9d89-d27b939bd39a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:11:21.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6122" for this suite.
Sep 27 07:11:27.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:11:27.497: INFO: namespace projected-6122 deletion completed in 6.095068237s

• [SLOW TEST:8.296 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 07:11:27.498: INFO: >>> kubeConfig: /tmp/kubeconfig-833349834
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7967
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 07:12:27.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7967" for this suite.
Sep 27 07:12:49.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 07:12:49.770: INFO: namespace container-probe-7967 deletion completed in 22.111140498s

• [SLOW TEST:82.272 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSep 27 07:12:49.770: INFO: Running AfterSuite actions on all nodes
Sep 27 07:12:49.770: INFO: Running AfterSuite actions on node 1
Sep 27 07:12:49.770: INFO: Skipping dumping logs from cluster

Ran 215 of 4413 Specs in 5198.373 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4198 Skipped
PASS

Ginkgo ran 1 suite in 1h26m42.304841669s
Test Suite Passed

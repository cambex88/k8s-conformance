I1211 09:12:29.093586      18 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-357251099
I1211 09:12:29.093690      18 e2e.go:224] Starting e2e run "e1fd8686-fd24-11e8-897d-5ac57959ef46" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1544519548 - Will randomize all specs
Will run 201 of 1946 specs

Dec 11 09:12:29.193: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
Dec 11 09:12:29.195: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec 11 09:12:29.210: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec 11 09:12:29.246: INFO: 35 / 35 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec 11 09:12:29.246: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
Dec 11 09:12:29.246: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec 11 09:12:29.253: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Dec 11 09:12:29.253: INFO: e2e test version: v1.13.0
Dec 11 09:12:29.255: INFO: kube-apiserver version: v1.10.6
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:12:29.255: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename pods
Dec 11 09:12:29.361: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 11 09:12:33.430: INFO: Waiting up to 5m0s for pod "client-envvars-e4cea11f-fd24-11e8-897d-5ac57959ef46" in namespace "e2e-tests-pods-7tlm2" to be "success or failure"
Dec 11 09:12:33.432: INFO: Pod "client-envvars-e4cea11f-fd24-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.179686ms
Dec 11 09:12:35.435: INFO: Pod "client-envvars-e4cea11f-fd24-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004595417s
Dec 11 09:12:37.437: INFO: Pod "client-envvars-e4cea11f-fd24-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007311963s
STEP: Saw pod success
Dec 11 09:12:37.438: INFO: Pod "client-envvars-e4cea11f-fd24-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:12:37.440: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod client-envvars-e4cea11f-fd24-11e8-897d-5ac57959ef46 container env3cont: <nil>
STEP: delete the pod
Dec 11 09:12:37.471: INFO: Waiting for pod client-envvars-e4cea11f-fd24-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:12:37.473: INFO: Pod client-envvars-e4cea11f-fd24-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:12:37.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-7tlm2" for this suite.
Dec 11 09:13:15.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:13:15.535: INFO: namespace: e2e-tests-pods-7tlm2, resource: bindings, ignored listing per whitelist
Dec 11 09:13:15.566: INFO: namespace e2e-tests-pods-7tlm2 deletion completed in 38.088880269s

• [SLOW TEST:46.311 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:13:15.566: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec 11 09:13:22.699: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:13:23.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-4rdvk" for this suite.
Dec 11 09:13:45.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:13:45.763: INFO: namespace: e2e-tests-replicaset-4rdvk, resource: bindings, ignored listing per whitelist
Dec 11 09:13:45.813: INFO: namespace e2e-tests-replicaset-4rdvk deletion completed in 22.091457642s

• [SLOW TEST:30.247 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:13:45.813: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec 11 09:13:50.456: INFO: Successfully updated pod "annotationupdate1004464f-fd25-11e8-897d-5ac57959ef46"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:13:52.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pdxfq" for this suite.
Dec 11 09:14:14.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:14:14.536: INFO: namespace: e2e-tests-projected-pdxfq, resource: bindings, ignored listing per whitelist
Dec 11 09:14:14.560: INFO: namespace e2e-tests-projected-pdxfq deletion completed in 22.087402316s

• [SLOW TEST:28.746 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:14:14.560: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 11 09:14:14.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 version --client'
Dec 11 09:14:14.703: INFO: stderr: ""
Dec 11 09:14:14.703: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Dec 11 09:14:14.705: INFO: Not supported for server versions before "1.13.0"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:14:14.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ccg6q" for this suite.
Dec 11 09:14:20.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:14:20.766: INFO: namespace: e2e-tests-kubectl-ccg6q, resource: bindings, ignored listing per whitelist
Dec 11 09:14:20.799: INFO: namespace e2e-tests-kubectl-ccg6q deletion completed in 6.089595014s

S [SKIPPING] [6.240 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance] [It]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

    Dec 11 09:14:14.705: Not supported for server versions before "1.13.0"

    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:14:20.800: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Dec 11 09:14:21.432: INFO: created pod pod-service-account-defaultsa
Dec 11 09:14:21.432: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec 11 09:14:21.442: INFO: created pod pod-service-account-mountsa
Dec 11 09:14:21.442: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec 11 09:14:21.455: INFO: created pod pod-service-account-nomountsa
Dec 11 09:14:21.455: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec 11 09:14:21.469: INFO: created pod pod-service-account-defaultsa-mountspec
Dec 11 09:14:21.469: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec 11 09:14:21.484: INFO: created pod pod-service-account-mountsa-mountspec
Dec 11 09:14:21.484: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec 11 09:14:21.498: INFO: created pod pod-service-account-nomountsa-mountspec
Dec 11 09:14:21.498: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec 11 09:14:21.512: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec 11 09:14:21.512: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec 11 09:14:21.525: INFO: created pod pod-service-account-mountsa-nomountspec
Dec 11 09:14:21.525: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec 11 09:14:21.535: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec 11 09:14:21.535: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:14:21.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-ffw56" for this suite.
Dec 11 09:14:27.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:14:27.566: INFO: namespace: e2e-tests-svcaccounts-ffw56, resource: bindings, ignored listing per whitelist
Dec 11 09:14:27.626: INFO: namespace e2e-tests-svcaccounts-ffw56 deletion completed in 6.087014009s

• [SLOW TEST:6.827 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:14:27.626: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Dec 11 09:14:27.734: INFO: Waiting up to 5m0s for pod "var-expansion-28efee05-fd25-11e8-897d-5ac57959ef46" in namespace "e2e-tests-var-expansion-h6q6k" to be "success or failure"
Dec 11 09:14:27.736: INFO: Pod "var-expansion-28efee05-fd25-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.951676ms
Dec 11 09:14:29.739: INFO: Pod "var-expansion-28efee05-fd25-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004631357s
Dec 11 09:14:31.742: INFO: Pod "var-expansion-28efee05-fd25-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007753293s
STEP: Saw pod success
Dec 11 09:14:31.742: INFO: Pod "var-expansion-28efee05-fd25-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:14:31.744: INFO: Trying to get logs from node ip-172-25-45-107.us-west-1.compute.internal pod var-expansion-28efee05-fd25-11e8-897d-5ac57959ef46 container dapi-container: <nil>
STEP: delete the pod
Dec 11 09:14:31.772: INFO: Waiting for pod var-expansion-28efee05-fd25-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:14:31.774: INFO: Pod var-expansion-28efee05-fd25-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:14:31.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-h6q6k" for this suite.
Dec 11 09:14:37.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:14:37.852: INFO: namespace: e2e-tests-var-expansion-h6q6k, resource: bindings, ignored listing per whitelist
Dec 11 09:14:37.868: INFO: namespace e2e-tests-var-expansion-h6q6k deletion completed in 6.08880624s

• [SLOW TEST:10.241 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:14:37.868: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-x84ms A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-x84ms;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-x84ms A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-x84ms;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-x84ms.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-x84ms.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-x84ms.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-x84ms.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-x84ms.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-x84ms.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-x84ms.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x84ms.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-x84ms.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-x84ms.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-x84ms.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-x84ms.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-x84ms.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 120.189.68.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.68.189.120_udp@PTR;check="$$(dig +tcp +noall +answer +search 120.189.68.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.68.189.120_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-x84ms A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-x84ms;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-x84ms A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-x84ms;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-x84ms.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-x84ms.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-x84ms.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-x84ms.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-x84ms.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-x84ms.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-x84ms.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x84ms.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-x84ms.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-x84ms.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-x84ms.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-x84ms.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-x84ms.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 120.189.68.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.68.189.120_udp@PTR;check="$$(dig +tcp +noall +answer +search 120.189.68.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.68.189.120_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 11 09:14:48.041: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-x84ms/dns-test-2f1267d6-fd25-11e8-897d-5ac57959ef46: the server could not find the requested resource (get pods dns-test-2f1267d6-fd25-11e8-897d-5ac57959ef46)
Dec 11 09:14:48.044: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-x84ms/dns-test-2f1267d6-fd25-11e8-897d-5ac57959ef46: the server could not find the requested resource (get pods dns-test-2f1267d6-fd25-11e8-897d-5ac57959ef46)
Dec 11 09:14:48.046: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-x84ms from pod e2e-tests-dns-x84ms/dns-test-2f1267d6-fd25-11e8-897d-5ac57959ef46: the server could not find the requested resource (get pods dns-test-2f1267d6-fd25-11e8-897d-5ac57959ef46)
Dec 11 09:14:48.049: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-x84ms from pod e2e-tests-dns-x84ms/dns-test-2f1267d6-fd25-11e8-897d-5ac57959ef46: the server could not find the requested resource (get pods dns-test-2f1267d6-fd25-11e8-897d-5ac57959ef46)
Dec 11 09:14:48.052: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-x84ms.svc from pod e2e-tests-dns-x84ms/dns-test-2f1267d6-fd25-11e8-897d-5ac57959ef46: the server could not find the requested resource (get pods dns-test-2f1267d6-fd25-11e8-897d-5ac57959ef46)
Dec 11 09:14:48.055: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-x84ms.svc from pod e2e-tests-dns-x84ms/dns-test-2f1267d6-fd25-11e8-897d-5ac57959ef46: the server could not find the requested resource (get pods dns-test-2f1267d6-fd25-11e8-897d-5ac57959ef46)
Dec 11 09:14:48.057: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-x84ms.svc from pod e2e-tests-dns-x84ms/dns-test-2f1267d6-fd25-11e8-897d-5ac57959ef46: the server could not find the requested resource (get pods dns-test-2f1267d6-fd25-11e8-897d-5ac57959ef46)
Dec 11 09:14:48.060: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x84ms.svc from pod e2e-tests-dns-x84ms/dns-test-2f1267d6-fd25-11e8-897d-5ac57959ef46: the server could not find the requested resource (get pods dns-test-2f1267d6-fd25-11e8-897d-5ac57959ef46)
Dec 11 09:14:48.116: INFO: Lookups using e2e-tests-dns-x84ms/dns-test-2f1267d6-fd25-11e8-897d-5ac57959ef46 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-x84ms wheezy_tcp@dns-test-service.e2e-tests-dns-x84ms wheezy_udp@dns-test-service.e2e-tests-dns-x84ms.svc wheezy_tcp@dns-test-service.e2e-tests-dns-x84ms.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-x84ms.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x84ms.svc]

Dec 11 09:14:53.194: INFO: DNS probes using e2e-tests-dns-x84ms/dns-test-2f1267d6-fd25-11e8-897d-5ac57959ef46 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:14:53.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-x84ms" for this suite.
Dec 11 09:14:59.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:14:59.360: INFO: namespace: e2e-tests-dns-x84ms, resource: bindings, ignored listing per whitelist
Dec 11 09:14:59.375: INFO: namespace e2e-tests-dns-x84ms deletion completed in 6.087191936s

• [SLOW TEST:21.508 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:14:59.375: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 11 09:14:59.488: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3bdd1e7f-fd25-11e8-897d-5ac57959ef46" in namespace "e2e-tests-downward-api-lgqf8" to be "success or failure"
Dec 11 09:14:59.490: INFO: Pod "downwardapi-volume-3bdd1e7f-fd25-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.272992ms
Dec 11 09:15:01.493: INFO: Pod "downwardapi-volume-3bdd1e7f-fd25-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005407404s
STEP: Saw pod success
Dec 11 09:15:01.493: INFO: Pod "downwardapi-volume-3bdd1e7f-fd25-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:15:01.495: INFO: Trying to get logs from node ip-172-25-45-107.us-west-1.compute.internal pod downwardapi-volume-3bdd1e7f-fd25-11e8-897d-5ac57959ef46 container client-container: <nil>
STEP: delete the pod
Dec 11 09:15:01.524: INFO: Waiting for pod downwardapi-volume-3bdd1e7f-fd25-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:15:01.526: INFO: Pod downwardapi-volume-3bdd1e7f-fd25-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:15:01.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lgqf8" for this suite.
Dec 11 09:15:07.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:15:07.600: INFO: namespace: e2e-tests-downward-api-lgqf8, resource: bindings, ignored listing per whitelist
Dec 11 09:15:07.618: INFO: namespace e2e-tests-downward-api-lgqf8 deletion completed in 6.087690525s

• [SLOW TEST:8.242 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:15:07.618: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 11 09:15:07.728: INFO: Waiting up to 5m0s for pod "downward-api-40c67f9f-fd25-11e8-897d-5ac57959ef46" in namespace "e2e-tests-downward-api-7662b" to be "success or failure"
Dec 11 09:15:07.730: INFO: Pod "downward-api-40c67f9f-fd25-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.100988ms
Dec 11 09:15:09.733: INFO: Pod "downward-api-40c67f9f-fd25-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00501517s
STEP: Saw pod success
Dec 11 09:15:09.733: INFO: Pod "downward-api-40c67f9f-fd25-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:15:09.735: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod downward-api-40c67f9f-fd25-11e8-897d-5ac57959ef46 container dapi-container: <nil>
STEP: delete the pod
Dec 11 09:15:09.762: INFO: Waiting for pod downward-api-40c67f9f-fd25-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:15:09.765: INFO: Pod downward-api-40c67f9f-fd25-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:15:09.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7662b" for this suite.
Dec 11 09:15:15.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:15:15.844: INFO: namespace: e2e-tests-downward-api-7662b, resource: bindings, ignored listing per whitelist
Dec 11 09:15:15.855: INFO: namespace e2e-tests-downward-api-7662b deletion completed in 6.085629065s

• [SLOW TEST:8.237 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:15:15.855: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-m824m
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-m824m
STEP: Deleting pre-stop pod
Dec 11 09:15:27.002: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:15:27.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-m824m" for this suite.
Dec 11 09:16:05.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:16:05.072: INFO: namespace: e2e-tests-prestop-m824m, resource: bindings, ignored listing per whitelist
Dec 11 09:16:05.105: INFO: namespace e2e-tests-prestop-m824m deletion completed in 38.0872831s

• [SLOW TEST:49.251 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:16:05.106: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec 11 09:16:05.208: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:16:08.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-h7lsh" for this suite.
Dec 11 09:16:14.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:16:14.565: INFO: namespace: e2e-tests-init-container-h7lsh, resource: bindings, ignored listing per whitelist
Dec 11 09:16:14.593: INFO: namespace e2e-tests-init-container-h7lsh deletion completed in 6.087505147s

• [SLOW TEST:9.487 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:16:14.593: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 11 09:16:14.750: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"68b52e22-fd25-11e8-8e03-0681e6464a68", Controller:(*bool)(0xc001401cf2), BlockOwnerDeletion:(*bool)(0xc001401cf3)}}
Dec 11 09:16:14.762: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"68b1c39e-fd25-11e8-8e03-0681e6464a68", Controller:(*bool)(0xc000d14922), BlockOwnerDeletion:(*bool)(0xc000d14923)}}
Dec 11 09:16:14.774: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"68b35e9a-fd25-11e8-8e03-0681e6464a68", Controller:(*bool)(0xc000d14b2a), BlockOwnerDeletion:(*bool)(0xc000d14b2b)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:16:19.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-rs2lq" for this suite.
Dec 11 09:16:25.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:16:25.877: INFO: namespace: e2e-tests-gc-rs2lq, resource: bindings, ignored listing per whitelist
Dec 11 09:16:25.881: INFO: namespace e2e-tests-gc-rs2lq deletion completed in 6.088764484s

• [SLOW TEST:11.288 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:16:25.881: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Dec 11 09:16:25.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 create -f - --namespace=e2e-tests-kubectl-d9tx8'
Dec 11 09:16:26.254: INFO: stderr: ""
Dec 11 09:16:26.254: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Dec 11 09:16:27.257: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 09:16:27.257: INFO: Found 0 / 1
Dec 11 09:16:28.257: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 09:16:28.257: INFO: Found 0 / 1
Dec 11 09:16:29.257: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 09:16:29.257: INFO: Found 1 / 1
Dec 11 09:16:29.257: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 11 09:16:29.259: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 09:16:29.259: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Dec 11 09:16:29.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 logs redis-master-z96d6 redis-master --namespace=e2e-tests-kubectl-d9tx8'
Dec 11 09:16:29.326: INFO: stderr: ""
Dec 11 09:16:29.326: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 11 Dec 09:16:28.147 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 11 Dec 09:16:28.147 # Server started, Redis version 3.2.12\n1:M 11 Dec 09:16:28.147 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 11 Dec 09:16:28.147 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Dec 11 09:16:29.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 log redis-master-z96d6 redis-master --namespace=e2e-tests-kubectl-d9tx8 --tail=1'
Dec 11 09:16:29.392: INFO: stderr: ""
Dec 11 09:16:29.392: INFO: stdout: "1:M 11 Dec 09:16:28.147 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Dec 11 09:16:29.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 log redis-master-z96d6 redis-master --namespace=e2e-tests-kubectl-d9tx8 --limit-bytes=1'
Dec 11 09:16:29.458: INFO: stderr: ""
Dec 11 09:16:29.458: INFO: stdout: " "
STEP: exposing timestamps
Dec 11 09:16:29.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 log redis-master-z96d6 redis-master --namespace=e2e-tests-kubectl-d9tx8 --tail=1 --timestamps'
Dec 11 09:16:29.524: INFO: stderr: ""
Dec 11 09:16:29.524: INFO: stdout: "2018-12-11T09:16:28.148014766Z 1:M 11 Dec 09:16:28.147 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Dec 11 09:16:32.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 log redis-master-z96d6 redis-master --namespace=e2e-tests-kubectl-d9tx8 --since=1s'
Dec 11 09:16:32.090: INFO: stderr: ""
Dec 11 09:16:32.090: INFO: stdout: ""
Dec 11 09:16:32.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 log redis-master-z96d6 redis-master --namespace=e2e-tests-kubectl-d9tx8 --since=24h'
Dec 11 09:16:32.155: INFO: stderr: ""
Dec 11 09:16:32.155: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 11 Dec 09:16:28.147 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 11 Dec 09:16:28.147 # Server started, Redis version 3.2.12\n1:M 11 Dec 09:16:28.147 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 11 Dec 09:16:28.147 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Dec 11 09:16:32.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-d9tx8'
Dec 11 09:16:32.221: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 11 09:16:32.221: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Dec 11 09:16:32.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-d9tx8'
Dec 11 09:16:32.283: INFO: stderr: "No resources found.\n"
Dec 11 09:16:32.283: INFO: stdout: ""
Dec 11 09:16:32.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods -l name=nginx --namespace=e2e-tests-kubectl-d9tx8 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 11 09:16:32.339: INFO: stderr: ""
Dec 11 09:16:32.339: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:16:32.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d9tx8" for this suite.
Dec 11 09:16:38.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:16:38.372: INFO: namespace: e2e-tests-kubectl-d9tx8, resource: bindings, ignored listing per whitelist
Dec 11 09:16:38.433: INFO: namespace e2e-tests-kubectl-d9tx8 deletion completed in 6.088900062s

• [SLOW TEST:12.552 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:16:38.433: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 11 09:16:38.543: INFO: (0) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.364219ms)
Dec 11 09:16:38.546: INFO: (1) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.985572ms)
Dec 11 09:16:38.549: INFO: (2) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.457514ms)
Dec 11 09:16:38.553: INFO: (3) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.157117ms)
Dec 11 09:16:38.556: INFO: (4) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.592507ms)
Dec 11 09:16:38.560: INFO: (5) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.282061ms)
Dec 11 09:16:38.563: INFO: (6) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.194116ms)
Dec 11 09:16:38.566: INFO: (7) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.966682ms)
Dec 11 09:16:38.569: INFO: (8) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.968378ms)
Dec 11 09:16:38.572: INFO: (9) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.319227ms)
Dec 11 09:16:38.575: INFO: (10) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.184572ms)
Dec 11 09:16:38.579: INFO: (11) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.364829ms)
Dec 11 09:16:38.582: INFO: (12) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.892794ms)
Dec 11 09:16:38.585: INFO: (13) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.921873ms)
Dec 11 09:16:38.588: INFO: (14) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.979415ms)
Dec 11 09:16:38.591: INFO: (15) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.115218ms)
Dec 11 09:16:38.594: INFO: (16) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.921682ms)
Dec 11 09:16:38.597: INFO: (17) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.958741ms)
Dec 11 09:16:38.599: INFO: (18) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.896579ms)
Dec 11 09:16:38.602: INFO: (19) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.942165ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:16:38.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-cd752" for this suite.
Dec 11 09:16:44.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:16:44.676: INFO: namespace: e2e-tests-proxy-cd752, resource: bindings, ignored listing per whitelist
Dec 11 09:16:44.696: INFO: namespace e2e-tests-proxy-cd752 deletion completed in 6.089078744s

• [SLOW TEST:6.263 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:16:44.696: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-zhfx
STEP: Creating a pod to test atomic-volume-subpath
Dec 11 09:16:44.827: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-zhfx" in namespace "e2e-tests-subpath-bmzng" to be "success or failure"
Dec 11 09:16:44.829: INFO: Pod "pod-subpath-test-secret-zhfx": Phase="Pending", Reason="", readiness=false. Elapsed: 1.983572ms
Dec 11 09:16:46.833: INFO: Pod "pod-subpath-test-secret-zhfx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005925822s
Dec 11 09:16:48.836: INFO: Pod "pod-subpath-test-secret-zhfx": Phase="Running", Reason="", readiness=false. Elapsed: 4.008969701s
Dec 11 09:16:50.839: INFO: Pod "pod-subpath-test-secret-zhfx": Phase="Running", Reason="", readiness=false. Elapsed: 6.011789665s
Dec 11 09:16:52.842: INFO: Pod "pod-subpath-test-secret-zhfx": Phase="Running", Reason="", readiness=false. Elapsed: 8.014849545s
Dec 11 09:16:54.845: INFO: Pod "pod-subpath-test-secret-zhfx": Phase="Running", Reason="", readiness=false. Elapsed: 10.017615665s
Dec 11 09:16:56.848: INFO: Pod "pod-subpath-test-secret-zhfx": Phase="Running", Reason="", readiness=false. Elapsed: 12.020330546s
Dec 11 09:16:58.851: INFO: Pod "pod-subpath-test-secret-zhfx": Phase="Running", Reason="", readiness=false. Elapsed: 14.023278753s
Dec 11 09:17:00.854: INFO: Pod "pod-subpath-test-secret-zhfx": Phase="Running", Reason="", readiness=false. Elapsed: 16.02630614s
Dec 11 09:17:02.857: INFO: Pod "pod-subpath-test-secret-zhfx": Phase="Running", Reason="", readiness=false. Elapsed: 18.029232177s
Dec 11 09:17:04.860: INFO: Pod "pod-subpath-test-secret-zhfx": Phase="Running", Reason="", readiness=false. Elapsed: 20.032027155s
Dec 11 09:17:06.862: INFO: Pod "pod-subpath-test-secret-zhfx": Phase="Running", Reason="", readiness=false. Elapsed: 22.034590406s
Dec 11 09:17:08.865: INFO: Pod "pod-subpath-test-secret-zhfx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.037526243s
STEP: Saw pod success
Dec 11 09:17:08.865: INFO: Pod "pod-subpath-test-secret-zhfx" satisfied condition "success or failure"
Dec 11 09:17:08.868: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-subpath-test-secret-zhfx container test-container-subpath-secret-zhfx: <nil>
STEP: delete the pod
Dec 11 09:17:08.895: INFO: Waiting for pod pod-subpath-test-secret-zhfx to disappear
Dec 11 09:17:08.896: INFO: Pod pod-subpath-test-secret-zhfx no longer exists
STEP: Deleting pod pod-subpath-test-secret-zhfx
Dec 11 09:17:08.896: INFO: Deleting pod "pod-subpath-test-secret-zhfx" in namespace "e2e-tests-subpath-bmzng"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:17:08.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-bmzng" for this suite.
Dec 11 09:17:14.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:17:14.936: INFO: namespace: e2e-tests-subpath-bmzng, resource: bindings, ignored listing per whitelist
Dec 11 09:17:14.989: INFO: namespace e2e-tests-subpath-bmzng deletion completed in 6.086395814s

• [SLOW TEST:30.293 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:17:14.989: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 11 09:17:15.098: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec 11 09:17:20.101: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 11 09:17:20.101: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 11 09:17:20.122: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-b4bvc,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-b4bvc/deployments/test-cleanup-deployment,UID:8faf7b19-fd25-11e8-8e03-0681e6464a68,ResourceVersion:21953584,Generation:1,CreationTimestamp:2018-12-11 09:17:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Dec 11 09:17:20.124: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:17:20.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-b4bvc" for this suite.
Dec 11 09:17:26.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:17:26.210: INFO: namespace: e2e-tests-deployment-b4bvc, resource: bindings, ignored listing per whitelist
Dec 11 09:17:26.217: INFO: namespace e2e-tests-deployment-b4bvc deletion completed in 6.086438223s

• [SLOW TEST:11.229 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:17:26.217: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec 11 09:17:26.856: INFO: Pod name wrapped-volume-race-93b29b30-fd25-11e8-897d-5ac57959ef46: Found 0 pods out of 5
Dec 11 09:17:31.862: INFO: Pod name wrapped-volume-race-93b29b30-fd25-11e8-897d-5ac57959ef46: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-93b29b30-fd25-11e8-897d-5ac57959ef46 in namespace e2e-tests-emptydir-wrapper-sbszd, will wait for the garbage collector to delete the pods
Dec 11 09:19:59.950: INFO: Deleting ReplicationController wrapped-volume-race-93b29b30-fd25-11e8-897d-5ac57959ef46 took: 14.391977ms
Dec 11 09:20:00.050: INFO: Terminating ReplicationController wrapped-volume-race-93b29b30-fd25-11e8-897d-5ac57959ef46 pods took: 100.265133ms
STEP: Creating RC which spawns configmap-volume pods
Dec 11 09:20:36.378: INFO: Pod name wrapped-volume-race-04a81a46-fd26-11e8-897d-5ac57959ef46: Found 0 pods out of 5
Dec 11 09:20:41.383: INFO: Pod name wrapped-volume-race-04a81a46-fd26-11e8-897d-5ac57959ef46: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-04a81a46-fd26-11e8-897d-5ac57959ef46 in namespace e2e-tests-emptydir-wrapper-sbszd, will wait for the garbage collector to delete the pods
Dec 11 09:23:35.470: INFO: Deleting ReplicationController wrapped-volume-race-04a81a46-fd26-11e8-897d-5ac57959ef46 took: 13.300846ms
Dec 11 09:23:35.571: INFO: Terminating ReplicationController wrapped-volume-race-04a81a46-fd26-11e8-897d-5ac57959ef46 pods took: 100.217352ms
STEP: Creating RC which spawns configmap-volume pods
Dec 11 09:24:14.490: INFO: Pod name wrapped-volume-race-86aa9a07-fd26-11e8-897d-5ac57959ef46: Found 0 pods out of 5
Dec 11 09:24:19.495: INFO: Pod name wrapped-volume-race-86aa9a07-fd26-11e8-897d-5ac57959ef46: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-86aa9a07-fd26-11e8-897d-5ac57959ef46 in namespace e2e-tests-emptydir-wrapper-sbszd, will wait for the garbage collector to delete the pods
Dec 11 09:27:15.586: INFO: Deleting ReplicationController wrapped-volume-race-86aa9a07-fd26-11e8-897d-5ac57959ef46 took: 14.391581ms
Dec 11 09:27:15.687: INFO: Terminating ReplicationController wrapped-volume-race-86aa9a07-fd26-11e8-897d-5ac57959ef46 pods took: 100.211744ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:27:54.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-sbszd" for this suite.
Dec 11 09:28:02.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:28:02.799: INFO: namespace: e2e-tests-emptydir-wrapper-sbszd, resource: bindings, ignored listing per whitelist
Dec 11 09:28:02.812: INFO: namespace e2e-tests-emptydir-wrapper-sbszd deletion completed in 8.085831343s

• [SLOW TEST:636.595 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:28:02.813: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-596tf
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 11 09:28:02.909: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 11 09:28:23.002: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.111.88.30:8080/dial?request=hostName&protocol=udp&host=100.111.88.29&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-596tf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 09:28:23.002: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
Dec 11 09:28:23.080: INFO: Waiting for endpoints: map[]
Dec 11 09:28:23.083: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.111.88.30:8080/dial?request=hostName&protocol=udp&host=100.122.170.118&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-596tf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 09:28:23.083: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
Dec 11 09:28:23.167: INFO: Waiting for endpoints: map[]
Dec 11 09:28:23.169: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.111.88.30:8080/dial?request=hostName&protocol=udp&host=100.111.240.245&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-596tf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 09:28:23.169: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
Dec 11 09:28:23.249: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:28:23.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-596tf" for this suite.
Dec 11 09:28:45.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:28:45.326: INFO: namespace: e2e-tests-pod-network-test-596tf, resource: bindings, ignored listing per whitelist
Dec 11 09:28:45.341: INFO: namespace e2e-tests-pod-network-test-596tf deletion completed in 22.088160933s

• [SLOW TEST:42.529 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:28:45.342: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-4r5t4
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 11 09:28:45.443: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 11 09:29:05.538: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 100.111.88.39 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-4r5t4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 09:29:05.538: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
Dec 11 09:29:06.613: INFO: Found all expected endpoints: [netserver-0]
Dec 11 09:29:06.615: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 100.122.170.119 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-4r5t4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 09:29:06.615: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
Dec 11 09:29:07.686: INFO: Found all expected endpoints: [netserver-1]
Dec 11 09:29:07.689: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 100.111.240.247 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-4r5t4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 09:29:07.689: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
Dec 11 09:29:08.764: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:29:08.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-4r5t4" for this suite.
Dec 11 09:29:30.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:29:30.838: INFO: namespace: e2e-tests-pod-network-test-4r5t4, resource: bindings, ignored listing per whitelist
Dec 11 09:29:30.861: INFO: namespace e2e-tests-pod-network-test-4r5t4 deletion completed in 22.092407252s

• [SLOW TEST:45.519 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:29:30.861: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 11 09:29:30.967: INFO: Waiting up to 5m0s for pod "pod-434e6a19-fd27-11e8-897d-5ac57959ef46" in namespace "e2e-tests-emptydir-2l7hl" to be "success or failure"
Dec 11 09:29:30.969: INFO: Pod "pod-434e6a19-fd27-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.921113ms
Dec 11 09:29:32.971: INFO: Pod "pod-434e6a19-fd27-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004482882s
Dec 11 09:29:34.974: INFO: Pod "pod-434e6a19-fd27-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007243572s
STEP: Saw pod success
Dec 11 09:29:34.974: INFO: Pod "pod-434e6a19-fd27-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:29:34.976: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-434e6a19-fd27-11e8-897d-5ac57959ef46 container test-container: <nil>
STEP: delete the pod
Dec 11 09:29:35.004: INFO: Waiting for pod pod-434e6a19-fd27-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:29:35.006: INFO: Pod pod-434e6a19-fd27-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:29:35.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2l7hl" for this suite.
Dec 11 09:29:41.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:29:41.073: INFO: namespace: e2e-tests-emptydir-2l7hl, resource: bindings, ignored listing per whitelist
Dec 11 09:29:41.099: INFO: namespace e2e-tests-emptydir-2l7hl deletion completed in 6.088333595s

• [SLOW TEST:10.238 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:29:41.099: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-4968ab9e-fd27-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume secrets
Dec 11 09:29:41.217: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-496a3820-fd27-11e8-897d-5ac57959ef46" in namespace "e2e-tests-projected-nhtlj" to be "success or failure"
Dec 11 09:29:41.219: INFO: Pod "pod-projected-secrets-496a3820-fd27-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.973436ms
Dec 11 09:29:43.222: INFO: Pod "pod-projected-secrets-496a3820-fd27-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005039568s
STEP: Saw pod success
Dec 11 09:29:43.222: INFO: Pod "pod-projected-secrets-496a3820-fd27-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:29:43.224: INFO: Trying to get logs from node ip-172-25-45-107.us-west-1.compute.internal pod pod-projected-secrets-496a3820-fd27-11e8-897d-5ac57959ef46 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 11 09:29:43.253: INFO: Waiting for pod pod-projected-secrets-496a3820-fd27-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:29:43.255: INFO: Pod pod-projected-secrets-496a3820-fd27-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:29:43.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nhtlj" for this suite.
Dec 11 09:29:49.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:29:49.306: INFO: namespace: e2e-tests-projected-nhtlj, resource: bindings, ignored listing per whitelist
Dec 11 09:29:49.349: INFO: namespace e2e-tests-projected-nhtlj deletion completed in 6.089557428s

• [SLOW TEST:8.250 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:29:49.349: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-4e539ed6-fd27-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume secrets
Dec 11 09:29:49.469: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4e556078-fd27-11e8-897d-5ac57959ef46" in namespace "e2e-tests-projected-58pgz" to be "success or failure"
Dec 11 09:29:49.471: INFO: Pod "pod-projected-secrets-4e556078-fd27-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.114917ms
Dec 11 09:29:51.473: INFO: Pod "pod-projected-secrets-4e556078-fd27-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004931048s
STEP: Saw pod success
Dec 11 09:29:51.474: INFO: Pod "pod-projected-secrets-4e556078-fd27-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:29:51.476: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-projected-secrets-4e556078-fd27-11e8-897d-5ac57959ef46 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 11 09:29:51.504: INFO: Waiting for pod pod-projected-secrets-4e556078-fd27-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:29:51.506: INFO: Pod pod-projected-secrets-4e556078-fd27-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:29:51.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-58pgz" for this suite.
Dec 11 09:29:57.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:29:57.576: INFO: namespace: e2e-tests-projected-58pgz, resource: bindings, ignored listing per whitelist
Dec 11 09:29:57.601: INFO: namespace e2e-tests-projected-58pgz deletion completed in 6.090342501s

• [SLOW TEST:8.252 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:29:57.601: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-533f3919-fd27-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume secrets
Dec 11 09:29:57.722: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5340c98a-fd27-11e8-897d-5ac57959ef46" in namespace "e2e-tests-projected-dtf7q" to be "success or failure"
Dec 11 09:29:57.725: INFO: Pod "pod-projected-secrets-5340c98a-fd27-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.276151ms
Dec 11 09:29:59.727: INFO: Pod "pod-projected-secrets-5340c98a-fd27-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005149699s
STEP: Saw pod success
Dec 11 09:29:59.727: INFO: Pod "pod-projected-secrets-5340c98a-fd27-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:29:59.730: INFO: Trying to get logs from node ip-172-25-45-107.us-west-1.compute.internal pod pod-projected-secrets-5340c98a-fd27-11e8-897d-5ac57959ef46 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 11 09:29:59.758: INFO: Waiting for pod pod-projected-secrets-5340c98a-fd27-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:29:59.761: INFO: Pod pod-projected-secrets-5340c98a-fd27-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:29:59.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dtf7q" for this suite.
Dec 11 09:30:05.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:30:05.820: INFO: namespace: e2e-tests-projected-dtf7q, resource: bindings, ignored listing per whitelist
Dec 11 09:30:05.853: INFO: namespace e2e-tests-projected-dtf7q deletion completed in 6.088137259s

• [SLOW TEST:8.252 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:30:05.854: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec 11 09:30:05.949: INFO: namespace e2e-tests-kubectl-cxwfl
Dec 11 09:30:05.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 create -f - --namespace=e2e-tests-kubectl-cxwfl'
Dec 11 09:30:06.185: INFO: stderr: ""
Dec 11 09:30:06.185: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 11 09:30:07.188: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 09:30:07.188: INFO: Found 0 / 1
Dec 11 09:30:08.188: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 09:30:08.188: INFO: Found 0 / 1
Dec 11 09:30:09.188: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 09:30:09.188: INFO: Found 1 / 1
Dec 11 09:30:09.188: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 11 09:30:09.191: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 09:30:09.191: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 11 09:30:09.191: INFO: wait on redis-master startup in e2e-tests-kubectl-cxwfl 
Dec 11 09:30:09.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 logs redis-master-qrvtw redis-master --namespace=e2e-tests-kubectl-cxwfl'
Dec 11 09:30:09.258: INFO: stderr: ""
Dec 11 09:30:09.258: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 11 Dec 09:30:07.989 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 11 Dec 09:30:07.989 # Server started, Redis version 3.2.12\n1:M 11 Dec 09:30:07.989 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 11 Dec 09:30:07.989 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Dec 11 09:30:09.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-cxwfl'
Dec 11 09:30:09.362: INFO: stderr: ""
Dec 11 09:30:09.362: INFO: stdout: "service/rm2 exposed\n"
Dec 11 09:30:09.364: INFO: Service rm2 in namespace e2e-tests-kubectl-cxwfl found.
STEP: exposing service
Dec 11 09:30:11.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-cxwfl'
Dec 11 09:30:11.483: INFO: stderr: ""
Dec 11 09:30:11.483: INFO: stdout: "service/rm3 exposed\n"
Dec 11 09:30:11.486: INFO: Service rm3 in namespace e2e-tests-kubectl-cxwfl found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:30:13.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cxwfl" for this suite.
Dec 11 09:30:35.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:30:35.529: INFO: namespace: e2e-tests-kubectl-cxwfl, resource: bindings, ignored listing per whitelist
Dec 11 09:30:35.586: INFO: namespace e2e-tests-kubectl-cxwfl deletion completed in 22.091823181s

• [SLOW TEST:29.733 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:30:35.586: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 11 09:30:35.685: INFO: Creating deployment "test-recreate-deployment"
Dec 11 09:30:35.696: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec 11 09:30:35.699: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Dec 11 09:30:37.705: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec 11 09:30:37.708: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec 11 09:30:37.723: INFO: Updating deployment test-recreate-deployment
Dec 11 09:30:37.723: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 11 09:30:37.842: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-4h2j9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4h2j9/deployments/test-recreate-deployment,UID:69e3505f-fd27-11e8-8e03-0681e6464a68,ResourceVersion:21955634,Generation:2,CreationTimestamp:2018-12-11 09:30:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2018-12-11 09:30:37 +0000 UTC 2018-12-11 09:30:37 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-12-11 09:30:37 +0000 UTC 2018-12-11 09:30:35 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5ddc654f" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Dec 11 09:30:37.845: INFO: New ReplicaSet "test-recreate-deployment-5ddc654f" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5ddc654f,GenerateName:,Namespace:e2e-tests-deployment-4h2j9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4h2j9/replicasets/test-recreate-deployment-5ddc654f,UID:6b22b666-fd27-11e8-8e03-0681e6464a68,ResourceVersion:21955632,Generation:1,CreationTimestamp:2018-12-11 09:30:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 18872109,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{extensions/v1beta1 Deployment test-recreate-deployment 69e3505f-fd27-11e8-8e03-0681e6464a68 0xc001e026c8 0xc001e026c9}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 18872109,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 18872109,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 11 09:30:37.845: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec 11 09:30:37.845: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6994d7fc5d,GenerateName:,Namespace:e2e-tests-deployment-4h2j9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4h2j9/replicasets/test-recreate-deployment-6994d7fc5d,UID:69e51cb7-fd27-11e8-8e03-0681e6464a68,ResourceVersion:21955625,Generation:2,CreationTimestamp:2018-12-11 09:30:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 2550839718,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{extensions/v1beta1 Deployment test-recreate-deployment 69e3505f-fd27-11e8-8e03-0681e6464a68 0xc001e0277a 0xc001e0277b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 2550839718,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 2550839718,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 11 09:30:37.848: INFO: Pod "test-recreate-deployment-5ddc654f-rnbrc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5ddc654f-rnbrc,GenerateName:test-recreate-deployment-5ddc654f-,Namespace:e2e-tests-deployment-4h2j9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4h2j9/pods/test-recreate-deployment-5ddc654f-rnbrc,UID:6b2450dd-fd27-11e8-8e03-0681e6464a68,ResourceVersion:21955633,Generation:0,CreationTimestamp:2018-12-11 09:30:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 18872109,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet test-recreate-deployment-5ddc654f 6b22b666-fd27-11e8-8e03-0681e6464a68 0xc001e032c8 0xc001e032c9}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4lbwq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4lbwq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4lbwq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-62-1.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e03510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e03580}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:30:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:30:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:30:37 +0000 UTC  }],Message:,Reason:,HostIP:172.25.62.1,PodIP:,StartTime:2018-12-11 09:30:37 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:30:37.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-4h2j9" for this suite.
Dec 11 09:30:43.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:30:43.906: INFO: namespace: e2e-tests-deployment-4h2j9, resource: bindings, ignored listing per whitelist
Dec 11 09:30:43.940: INFO: namespace e2e-tests-deployment-4h2j9 deletion completed in 6.087758069s

• [SLOW TEST:8.354 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:30:43.940: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-7hjqr
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7hjqr to expose endpoints map[]
Dec 11 09:30:44.076: INFO: Get endpoints failed (1.88691ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Dec 11 09:30:45.079: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7hjqr exposes endpoints map[] (1.004805809s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-7hjqr
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7hjqr to expose endpoints map[pod1:[80]]
Dec 11 09:30:48.111: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7hjqr exposes endpoints map[pod1:[80]] (3.018960455s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-7hjqr
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7hjqr to expose endpoints map[pod2:[80] pod1:[80]]
Dec 11 09:30:51.151: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7hjqr exposes endpoints map[pod1:[80] pod2:[80]] (3.028441401s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-7hjqr
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7hjqr to expose endpoints map[pod2:[80]]
Dec 11 09:30:52.171: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7hjqr exposes endpoints map[pod2:[80]] (1.008388226s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-7hjqr
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7hjqr to expose endpoints map[]
Dec 11 09:30:53.187: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7hjqr exposes endpoints map[] (1.004677843s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:30:53.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-7hjqr" for this suite.
Dec 11 09:31:15.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:31:15.288: INFO: namespace: e2e-tests-services-7hjqr, resource: bindings, ignored listing per whitelist
Dec 11 09:31:15.322: INFO: namespace e2e-tests-services-7hjqr deletion completed in 22.089430557s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:31.382 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:31:15.322: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 11 09:31:15.431: INFO: Waiting up to 5m0s for pod "pod-819232a4-fd27-11e8-897d-5ac57959ef46" in namespace "e2e-tests-emptydir-2p46h" to be "success or failure"
Dec 11 09:31:15.433: INFO: Pod "pod-819232a4-fd27-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.093481ms
Dec 11 09:31:17.436: INFO: Pod "pod-819232a4-fd27-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00508309s
STEP: Saw pod success
Dec 11 09:31:17.436: INFO: Pod "pod-819232a4-fd27-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:31:17.438: INFO: Trying to get logs from node ip-172-25-45-107.us-west-1.compute.internal pod pod-819232a4-fd27-11e8-897d-5ac57959ef46 container test-container: <nil>
STEP: delete the pod
Dec 11 09:31:17.466: INFO: Waiting for pod pod-819232a4-fd27-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:31:17.468: INFO: Pod pod-819232a4-fd27-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:31:17.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2p46h" for this suite.
Dec 11 09:31:23.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:31:23.499: INFO: namespace: e2e-tests-emptydir-2p46h, resource: bindings, ignored listing per whitelist
Dec 11 09:31:23.565: INFO: namespace e2e-tests-emptydir-2p46h deletion completed in 6.092788916s

• [SLOW TEST:8.243 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:31:23.566: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-7tsw
STEP: Creating a pod to test atomic-volume-subpath
Dec 11 09:31:23.698: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-7tsw" in namespace "e2e-tests-subpath-ldvqc" to be "success or failure"
Dec 11 09:31:23.700: INFO: Pod "pod-subpath-test-configmap-7tsw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.09517ms
Dec 11 09:31:25.704: INFO: Pod "pod-subpath-test-configmap-7tsw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005627866s
Dec 11 09:31:27.707: INFO: Pod "pod-subpath-test-configmap-7tsw": Phase="Running", Reason="", readiness=false. Elapsed: 4.008888511s
Dec 11 09:31:29.710: INFO: Pod "pod-subpath-test-configmap-7tsw": Phase="Running", Reason="", readiness=false. Elapsed: 6.011624344s
Dec 11 09:31:31.713: INFO: Pod "pod-subpath-test-configmap-7tsw": Phase="Running", Reason="", readiness=false. Elapsed: 8.014850772s
Dec 11 09:31:33.715: INFO: Pod "pod-subpath-test-configmap-7tsw": Phase="Running", Reason="", readiness=false. Elapsed: 10.017569729s
Dec 11 09:31:35.718: INFO: Pod "pod-subpath-test-configmap-7tsw": Phase="Running", Reason="", readiness=false. Elapsed: 12.020552411s
Dec 11 09:31:37.722: INFO: Pod "pod-subpath-test-configmap-7tsw": Phase="Running", Reason="", readiness=false. Elapsed: 14.023689487s
Dec 11 09:31:39.725: INFO: Pod "pod-subpath-test-configmap-7tsw": Phase="Running", Reason="", readiness=false. Elapsed: 16.026884669s
Dec 11 09:31:41.728: INFO: Pod "pod-subpath-test-configmap-7tsw": Phase="Running", Reason="", readiness=false. Elapsed: 18.029721686s
Dec 11 09:31:43.731: INFO: Pod "pod-subpath-test-configmap-7tsw": Phase="Running", Reason="", readiness=false. Elapsed: 20.032771553s
Dec 11 09:31:45.734: INFO: Pod "pod-subpath-test-configmap-7tsw": Phase="Running", Reason="", readiness=false. Elapsed: 22.036054769s
Dec 11 09:31:47.737: INFO: Pod "pod-subpath-test-configmap-7tsw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.039058844s
STEP: Saw pod success
Dec 11 09:31:47.737: INFO: Pod "pod-subpath-test-configmap-7tsw" satisfied condition "success or failure"
Dec 11 09:31:47.739: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-subpath-test-configmap-7tsw container test-container-subpath-configmap-7tsw: <nil>
STEP: delete the pod
Dec 11 09:31:47.768: INFO: Waiting for pod pod-subpath-test-configmap-7tsw to disappear
Dec 11 09:31:47.770: INFO: Pod pod-subpath-test-configmap-7tsw no longer exists
STEP: Deleting pod pod-subpath-test-configmap-7tsw
Dec 11 09:31:47.770: INFO: Deleting pod "pod-subpath-test-configmap-7tsw" in namespace "e2e-tests-subpath-ldvqc"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:31:47.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-ldvqc" for this suite.
Dec 11 09:31:53.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:31:53.834: INFO: namespace: e2e-tests-subpath-ldvqc, resource: bindings, ignored listing per whitelist
Dec 11 09:31:53.863: INFO: namespace e2e-tests-subpath-ldvqc deletion completed in 6.086835755s

• [SLOW TEST:30.297 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:31:53.863: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec 11 09:31:53.997: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-hchhr,SelfLink:/api/v1/namespaces/e2e-tests-watch-hchhr/configmaps/e2e-watch-test-label-changed,UID:988b7355-fd27-11e8-8e03-0681e6464a68,ResourceVersion:21955908,Generation:0,CreationTimestamp:2018-12-11 09:31:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 11 09:31:53.997: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-hchhr,SelfLink:/api/v1/namespaces/e2e-tests-watch-hchhr/configmaps/e2e-watch-test-label-changed,UID:988b7355-fd27-11e8-8e03-0681e6464a68,ResourceVersion:21955909,Generation:0,CreationTimestamp:2018-12-11 09:31:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 11 09:31:53.997: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-hchhr,SelfLink:/api/v1/namespaces/e2e-tests-watch-hchhr/configmaps/e2e-watch-test-label-changed,UID:988b7355-fd27-11e8-8e03-0681e6464a68,ResourceVersion:21955910,Generation:0,CreationTimestamp:2018-12-11 09:31:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec 11 09:32:04.046: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-hchhr,SelfLink:/api/v1/namespaces/e2e-tests-watch-hchhr/configmaps/e2e-watch-test-label-changed,UID:988b7355-fd27-11e8-8e03-0681e6464a68,ResourceVersion:21955928,Generation:0,CreationTimestamp:2018-12-11 09:31:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 11 09:32:04.046: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-hchhr,SelfLink:/api/v1/namespaces/e2e-tests-watch-hchhr/configmaps/e2e-watch-test-label-changed,UID:988b7355-fd27-11e8-8e03-0681e6464a68,ResourceVersion:21955929,Generation:0,CreationTimestamp:2018-12-11 09:31:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec 11 09:32:04.046: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-hchhr,SelfLink:/api/v1/namespaces/e2e-tests-watch-hchhr/configmaps/e2e-watch-test-label-changed,UID:988b7355-fd27-11e8-8e03-0681e6464a68,ResourceVersion:21955930,Generation:0,CreationTimestamp:2018-12-11 09:31:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:32:04.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-hchhr" for this suite.
Dec 11 09:32:10.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:32:10.087: INFO: namespace: e2e-tests-watch-hchhr, resource: bindings, ignored listing per whitelist
Dec 11 09:32:10.178: INFO: namespace e2e-tests-watch-hchhr deletion completed in 6.127607884s

• [SLOW TEST:16.315 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:32:10.178: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Dec 11 09:32:10.290: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-22gs7" to be "success or failure"
Dec 11 09:32:10.292: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051262ms
Dec 11 09:32:12.295: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004753891s
STEP: Saw pod success
Dec 11 09:32:12.295: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec 11 09:32:12.297: INFO: Trying to get logs from node ip-172-25-45-107.us-west-1.compute.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec 11 09:32:12.329: INFO: Waiting for pod pod-host-path-test to disappear
Dec 11 09:32:12.331: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:32:12.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-22gs7" for this suite.
Dec 11 09:32:18.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:32:18.409: INFO: namespace: e2e-tests-hostpath-22gs7, resource: bindings, ignored listing per whitelist
Dec 11 09:32:18.429: INFO: namespace e2e-tests-hostpath-22gs7 deletion completed in 6.093229514s

• [SLOW TEST:8.251 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:32:18.429: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:32:18.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-7s8vn" for this suite.
Dec 11 09:32:24.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:32:24.609: INFO: namespace: e2e-tests-services-7s8vn, resource: bindings, ignored listing per whitelist
Dec 11 09:32:24.617: INFO: namespace e2e-tests-services-7s8vn deletion completed in 6.0847521s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.188 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:32:24.617: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1211 09:33:04.749796      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 11 09:33:04.749: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:33:04.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-6qngh" for this suite.
Dec 11 09:33:10.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:33:10.801: INFO: namespace: e2e-tests-gc-6qngh, resource: bindings, ignored listing per whitelist
Dec 11 09:33:10.839: INFO: namespace e2e-tests-gc-6qngh deletion completed in 6.085484263s

• [SLOW TEST:46.222 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:33:10.839: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 11 09:33:10.956: INFO: Waiting up to 5m0s for pod "pod-c66de07d-fd27-11e8-897d-5ac57959ef46" in namespace "e2e-tests-emptydir-xrcdq" to be "success or failure"
Dec 11 09:33:10.958: INFO: Pod "pod-c66de07d-fd27-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.152093ms
Dec 11 09:33:12.961: INFO: Pod "pod-c66de07d-fd27-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004909875s
Dec 11 09:33:14.963: INFO: Pod "pod-c66de07d-fd27-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007482929s
STEP: Saw pod success
Dec 11 09:33:14.963: INFO: Pod "pod-c66de07d-fd27-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:33:14.965: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-c66de07d-fd27-11e8-897d-5ac57959ef46 container test-container: <nil>
STEP: delete the pod
Dec 11 09:33:14.992: INFO: Waiting for pod pod-c66de07d-fd27-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:33:14.994: INFO: Pod pod-c66de07d-fd27-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:33:14.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xrcdq" for this suite.
Dec 11 09:33:21.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:33:21.041: INFO: namespace: e2e-tests-emptydir-xrcdq, resource: bindings, ignored listing per whitelist
Dec 11 09:33:21.081: INFO: namespace e2e-tests-emptydir-xrcdq deletion completed in 6.083072169s

• [SLOW TEST:10.242 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:33:21.082: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-cc876ecf-fd27-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume configMaps
Dec 11 09:33:21.199: INFO: Waiting up to 5m0s for pod "pod-configmaps-cc88ea1e-fd27-11e8-897d-5ac57959ef46" in namespace "e2e-tests-configmap-jl4h6" to be "success or failure"
Dec 11 09:33:21.201: INFO: Pod "pod-configmaps-cc88ea1e-fd27-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.938484ms
Dec 11 09:33:23.203: INFO: Pod "pod-configmaps-cc88ea1e-fd27-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004309494s
STEP: Saw pod success
Dec 11 09:33:23.203: INFO: Pod "pod-configmaps-cc88ea1e-fd27-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:33:23.205: INFO: Trying to get logs from node ip-172-25-45-107.us-west-1.compute.internal pod pod-configmaps-cc88ea1e-fd27-11e8-897d-5ac57959ef46 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 09:33:23.233: INFO: Waiting for pod pod-configmaps-cc88ea1e-fd27-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:33:23.234: INFO: Pod pod-configmaps-cc88ea1e-fd27-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:33:23.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jl4h6" for this suite.
Dec 11 09:33:29.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:33:29.320: INFO: namespace: e2e-tests-configmap-jl4h6, resource: bindings, ignored listing per whitelist
Dec 11 09:33:29.324: INFO: namespace e2e-tests-configmap-jl4h6 deletion completed in 6.085347604s

• [SLOW TEST:8.242 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:33:29.324: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 11 09:33:29.431: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d1712ade-fd27-11e8-897d-5ac57959ef46" in namespace "e2e-tests-downward-api-ts25d" to be "success or failure"
Dec 11 09:33:29.433: INFO: Pod "downwardapi-volume-d1712ade-fd27-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029146ms
Dec 11 09:33:31.436: INFO: Pod "downwardapi-volume-d1712ade-fd27-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005034891s
STEP: Saw pod success
Dec 11 09:33:31.436: INFO: Pod "downwardapi-volume-d1712ade-fd27-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:33:31.439: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod downwardapi-volume-d1712ade-fd27-11e8-897d-5ac57959ef46 container client-container: <nil>
STEP: delete the pod
Dec 11 09:33:31.467: INFO: Waiting for pod downwardapi-volume-d1712ade-fd27-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:33:31.469: INFO: Pod downwardapi-volume-d1712ade-fd27-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:33:31.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ts25d" for this suite.
Dec 11 09:33:37.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:33:37.515: INFO: namespace: e2e-tests-downward-api-ts25d, resource: bindings, ignored listing per whitelist
Dec 11 09:33:37.559: INFO: namespace e2e-tests-downward-api-ts25d deletion completed in 6.086040016s

• [SLOW TEST:8.235 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:33:37.559: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 11 09:33:37.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-r6xvn'
Dec 11 09:33:37.729: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 11 09:33:37.729: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Dec 11 09:33:39.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-r6xvn'
Dec 11 09:33:39.807: INFO: stderr: ""
Dec 11 09:33:39.807: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:33:39.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-r6xvn" for this suite.
Dec 11 09:34:01.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:34:01.857: INFO: namespace: e2e-tests-kubectl-r6xvn, resource: bindings, ignored listing per whitelist
Dec 11 09:34:01.899: INFO: namespace e2e-tests-kubectl-r6xvn deletion completed in 22.087361716s

• [SLOW TEST:24.339 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:34:01.899: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 11 09:34:04.532: INFO: Successfully updated pod "pod-update-e4dbdd8e-fd27-11e8-897d-5ac57959ef46"
STEP: verifying the updated pod is in kubernetes
Dec 11 09:34:04.537: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:34:04.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-c6tss" for this suite.
Dec 11 09:34:26.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:34:26.617: INFO: namespace: e2e-tests-pods-c6tss, resource: bindings, ignored listing per whitelist
Dec 11 09:34:26.633: INFO: namespace e2e-tests-pods-c6tss deletion completed in 22.092194645s

• [SLOW TEST:24.734 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:34:26.633: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 11 09:34:26.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-28vwm'
Dec 11 09:34:26.802: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 11 09:34:26.802: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Dec 11 09:34:30.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-28vwm'
Dec 11 09:34:30.878: INFO: stderr: ""
Dec 11 09:34:30.878: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:34:30.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-28vwm" for this suite.
Dec 11 09:34:52.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:34:52.960: INFO: namespace: e2e-tests-kubectl-28vwm, resource: bindings, ignored listing per whitelist
Dec 11 09:34:52.971: INFO: namespace e2e-tests-kubectl-28vwm deletion completed in 22.087731801s

• [SLOW TEST:26.338 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:34:52.971: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 11 09:34:53.066: INFO: Creating ReplicaSet my-hostname-basic-034c81a6-fd28-11e8-897d-5ac57959ef46
Dec 11 09:34:53.079: INFO: Pod name my-hostname-basic-034c81a6-fd28-11e8-897d-5ac57959ef46: Found 0 pods out of 1
Dec 11 09:34:58.081: INFO: Pod name my-hostname-basic-034c81a6-fd28-11e8-897d-5ac57959ef46: Found 1 pods out of 1
Dec 11 09:34:58.081: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-034c81a6-fd28-11e8-897d-5ac57959ef46" is running
Dec 11 09:34:58.084: INFO: Pod "my-hostname-basic-034c81a6-fd28-11e8-897d-5ac57959ef46-bg9pt" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-11 09:34:53 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-11 09:34:55 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-11 09:34:53 +0000 UTC Reason: Message:}])
Dec 11 09:34:58.084: INFO: Trying to dial the pod
Dec 11 09:35:03.092: INFO: Controller my-hostname-basic-034c81a6-fd28-11e8-897d-5ac57959ef46: Got expected result from replica 1 [my-hostname-basic-034c81a6-fd28-11e8-897d-5ac57959ef46-bg9pt]: "my-hostname-basic-034c81a6-fd28-11e8-897d-5ac57959ef46-bg9pt", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:35:03.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-mk8rh" for this suite.
Dec 11 09:35:09.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:35:09.158: INFO: namespace: e2e-tests-replicaset-mk8rh, resource: bindings, ignored listing per whitelist
Dec 11 09:35:09.183: INFO: namespace e2e-tests-replicaset-mk8rh deletion completed in 6.086145217s

• [SLOW TEST:16.212 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:35:09.183: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-0cf721c6-fd28-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume configMaps
Dec 11 09:35:09.305: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0cf8ae47-fd28-11e8-897d-5ac57959ef46" in namespace "e2e-tests-projected-dn9p8" to be "success or failure"
Dec 11 09:35:09.307: INFO: Pod "pod-projected-configmaps-0cf8ae47-fd28-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.228993ms
Dec 11 09:35:11.310: INFO: Pod "pod-projected-configmaps-0cf8ae47-fd28-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004720419s
STEP: Saw pod success
Dec 11 09:35:11.310: INFO: Pod "pod-projected-configmaps-0cf8ae47-fd28-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:35:11.312: INFO: Trying to get logs from node ip-172-25-45-107.us-west-1.compute.internal pod pod-projected-configmaps-0cf8ae47-fd28-11e8-897d-5ac57959ef46 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 09:35:11.339: INFO: Waiting for pod pod-projected-configmaps-0cf8ae47-fd28-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:35:11.341: INFO: Pod pod-projected-configmaps-0cf8ae47-fd28-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:35:11.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dn9p8" for this suite.
Dec 11 09:35:17.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:35:17.417: INFO: namespace: e2e-tests-projected-dn9p8, resource: bindings, ignored listing per whitelist
Dec 11 09:35:17.435: INFO: namespace e2e-tests-projected-dn9p8 deletion completed in 6.090343765s

• [SLOW TEST:8.252 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:35:17.435: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-11e20573-fd28-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume configMaps
Dec 11 09:35:17.555: INFO: Waiting up to 5m0s for pod "pod-configmaps-11e38412-fd28-11e8-897d-5ac57959ef46" in namespace "e2e-tests-configmap-n5k9j" to be "success or failure"
Dec 11 09:35:17.557: INFO: Pod "pod-configmaps-11e38412-fd28-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.103482ms
Dec 11 09:35:19.560: INFO: Pod "pod-configmaps-11e38412-fd28-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00528333s
STEP: Saw pod success
Dec 11 09:35:19.560: INFO: Pod "pod-configmaps-11e38412-fd28-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:35:19.562: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-configmaps-11e38412-fd28-11e8-897d-5ac57959ef46 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 09:35:19.589: INFO: Waiting for pod pod-configmaps-11e38412-fd28-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:35:19.591: INFO: Pod pod-configmaps-11e38412-fd28-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:35:19.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-n5k9j" for this suite.
Dec 11 09:35:25.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:35:25.644: INFO: namespace: e2e-tests-configmap-n5k9j, resource: bindings, ignored listing per whitelist
Dec 11 09:35:25.683: INFO: namespace e2e-tests-configmap-n5k9j deletion completed in 6.087335672s

• [SLOW TEST:8.247 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:35:25.683: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 11 09:35:31.830: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 11 09:35:31.832: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 11 09:35:33.833: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 11 09:35:33.835: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 11 09:35:35.833: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 11 09:35:35.835: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 11 09:35:37.833: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 11 09:35:37.835: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 11 09:35:39.833: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 11 09:35:39.835: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 11 09:35:41.833: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 11 09:35:41.835: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 11 09:35:43.833: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 11 09:35:43.835: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 11 09:35:45.833: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 11 09:35:45.835: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 11 09:35:47.833: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 11 09:35:47.835: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 11 09:35:49.833: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 11 09:35:49.835: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:35:49.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-q6mx6" for this suite.
Dec 11 09:36:11.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:36:11.888: INFO: namespace: e2e-tests-container-lifecycle-hook-q6mx6, resource: bindings, ignored listing per whitelist
Dec 11 09:36:11.942: INFO: namespace e2e-tests-container-lifecycle-hook-q6mx6 deletion completed in 22.09664598s

• [SLOW TEST:46.259 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:36:11.942: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 11 09:36:12.058: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3260012f-fd28-11e8-897d-5ac57959ef46" in namespace "e2e-tests-projected-qm78m" to be "success or failure"
Dec 11 09:36:12.060: INFO: Pod "downwardapi-volume-3260012f-fd28-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.137456ms
Dec 11 09:36:14.063: INFO: Pod "downwardapi-volume-3260012f-fd28-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00456536s
STEP: Saw pod success
Dec 11 09:36:14.063: INFO: Pod "downwardapi-volume-3260012f-fd28-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:36:14.065: INFO: Trying to get logs from node ip-172-25-45-107.us-west-1.compute.internal pod downwardapi-volume-3260012f-fd28-11e8-897d-5ac57959ef46 container client-container: <nil>
STEP: delete the pod
Dec 11 09:36:14.093: INFO: Waiting for pod downwardapi-volume-3260012f-fd28-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:36:14.095: INFO: Pod downwardapi-volume-3260012f-fd28-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:36:14.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qm78m" for this suite.
Dec 11 09:36:20.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:36:20.170: INFO: namespace: e2e-tests-projected-qm78m, resource: bindings, ignored listing per whitelist
Dec 11 09:36:20.199: INFO: namespace e2e-tests-projected-qm78m deletion completed in 6.099394535s

• [SLOW TEST:8.256 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:36:20.199: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 11 09:36:20.312: INFO: Waiting up to 5m0s for pod "downwardapi-volume-374b6ae5-fd28-11e8-897d-5ac57959ef46" in namespace "e2e-tests-projected-sd4bf" to be "success or failure"
Dec 11 09:36:20.315: INFO: Pod "downwardapi-volume-374b6ae5-fd28-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.282511ms
Dec 11 09:36:22.317: INFO: Pod "downwardapi-volume-374b6ae5-fd28-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005028577s
STEP: Saw pod success
Dec 11 09:36:22.317: INFO: Pod "downwardapi-volume-374b6ae5-fd28-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:36:22.320: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod downwardapi-volume-374b6ae5-fd28-11e8-897d-5ac57959ef46 container client-container: <nil>
STEP: delete the pod
Dec 11 09:36:22.346: INFO: Waiting for pod downwardapi-volume-374b6ae5-fd28-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:36:22.348: INFO: Pod downwardapi-volume-374b6ae5-fd28-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:36:22.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sd4bf" for this suite.
Dec 11 09:36:28.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:36:28.382: INFO: namespace: e2e-tests-projected-sd4bf, resource: bindings, ignored listing per whitelist
Dec 11 09:36:28.439: INFO: namespace e2e-tests-projected-sd4bf deletion completed in 6.086556474s

• [SLOW TEST:8.240 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:36:28.439: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1211 09:36:59.075688      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 11 09:36:59.075: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:36:59.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-f848z" for this suite.
Dec 11 09:37:05.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:37:05.167: INFO: namespace: e2e-tests-gc-f848z, resource: bindings, ignored listing per whitelist
Dec 11 09:37:05.169: INFO: namespace e2e-tests-gc-f848z deletion completed in 6.08987036s

• [SLOW TEST:36.730 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:37:05.170: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Dec 11 09:37:05.277: INFO: Waiting up to 5m0s for pod "client-containers-52189cf7-fd28-11e8-897d-5ac57959ef46" in namespace "e2e-tests-containers-tl5lj" to be "success or failure"
Dec 11 09:37:05.279: INFO: Pod "client-containers-52189cf7-fd28-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.959457ms
Dec 11 09:37:07.281: INFO: Pod "client-containers-52189cf7-fd28-11e8-897d-5ac57959ef46": Phase="Running", Reason="", readiness=true. Elapsed: 2.004215075s
Dec 11 09:37:09.284: INFO: Pod "client-containers-52189cf7-fd28-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006970454s
STEP: Saw pod success
Dec 11 09:37:09.284: INFO: Pod "client-containers-52189cf7-fd28-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:37:09.286: INFO: Trying to get logs from node ip-172-25-45-107.us-west-1.compute.internal pod client-containers-52189cf7-fd28-11e8-897d-5ac57959ef46 container test-container: <nil>
STEP: delete the pod
Dec 11 09:37:09.314: INFO: Waiting for pod client-containers-52189cf7-fd28-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:37:09.316: INFO: Pod client-containers-52189cf7-fd28-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:37:09.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-tl5lj" for this suite.
Dec 11 09:37:15.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:37:15.351: INFO: namespace: e2e-tests-containers-tl5lj, resource: bindings, ignored listing per whitelist
Dec 11 09:37:15.405: INFO: namespace e2e-tests-containers-tl5lj deletion completed in 6.084975408s

• [SLOW TEST:10.235 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:37:15.405: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-v8mr6.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-v8mr6.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-v8mr6.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-v8mr6.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-v8mr6.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-v8mr6.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 11 09:37:17.583: INFO: DNS probes using e2e-tests-dns-v8mr6/dns-test-583317f8-fd28-11e8-897d-5ac57959ef46 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:37:17.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-v8mr6" for this suite.
Dec 11 09:37:23.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:37:23.660: INFO: namespace: e2e-tests-dns-v8mr6, resource: bindings, ignored listing per whitelist
Dec 11 09:37:23.697: INFO: namespace e2e-tests-dns-v8mr6 deletion completed in 6.08786769s

• [SLOW TEST:8.292 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:37:23.697: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 11 09:37:23.800: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5d22e829-fd28-11e8-897d-5ac57959ef46" in namespace "e2e-tests-downward-api-bpmlj" to be "success or failure"
Dec 11 09:37:23.802: INFO: Pod "downwardapi-volume-5d22e829-fd28-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.142695ms
Dec 11 09:37:25.805: INFO: Pod "downwardapi-volume-5d22e829-fd28-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005150166s
STEP: Saw pod success
Dec 11 09:37:25.805: INFO: Pod "downwardapi-volume-5d22e829-fd28-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:37:25.807: INFO: Trying to get logs from node ip-172-25-45-107.us-west-1.compute.internal pod downwardapi-volume-5d22e829-fd28-11e8-897d-5ac57959ef46 container client-container: <nil>
STEP: delete the pod
Dec 11 09:37:25.836: INFO: Waiting for pod downwardapi-volume-5d22e829-fd28-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:37:25.838: INFO: Pod downwardapi-volume-5d22e829-fd28-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:37:25.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bpmlj" for this suite.
Dec 11 09:37:31.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:37:31.874: INFO: namespace: e2e-tests-downward-api-bpmlj, resource: bindings, ignored listing per whitelist
Dec 11 09:37:31.927: INFO: namespace e2e-tests-downward-api-bpmlj deletion completed in 6.085100161s

• [SLOW TEST:8.230 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:37:31.928: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 11 09:37:36.073: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 11 09:37:36.075: INFO: Pod pod-with-prestop-http-hook still exists
Dec 11 09:37:38.075: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 11 09:37:38.078: INFO: Pod pod-with-prestop-http-hook still exists
Dec 11 09:37:40.075: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 11 09:37:40.078: INFO: Pod pod-with-prestop-http-hook still exists
Dec 11 09:37:42.075: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 11 09:37:42.078: INFO: Pod pod-with-prestop-http-hook still exists
Dec 11 09:37:44.075: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 11 09:37:44.078: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:37:44.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-9c4xk" for this suite.
Dec 11 09:38:06.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:38:06.139: INFO: namespace: e2e-tests-container-lifecycle-hook-9c4xk, resource: bindings, ignored listing per whitelist
Dec 11 09:38:06.178: INFO: namespace e2e-tests-container-lifecycle-hook-9c4xk deletion completed in 22.089119334s

• [SLOW TEST:34.250 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:38:06.178: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 11 09:38:06.288: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7675fb34-fd28-11e8-897d-5ac57959ef46" in namespace "e2e-tests-downward-api-wt4b5" to be "success or failure"
Dec 11 09:38:06.290: INFO: Pod "downwardapi-volume-7675fb34-fd28-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.899404ms
Dec 11 09:38:08.293: INFO: Pod "downwardapi-volume-7675fb34-fd28-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004656777s
STEP: Saw pod success
Dec 11 09:38:08.293: INFO: Pod "downwardapi-volume-7675fb34-fd28-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:38:08.295: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod downwardapi-volume-7675fb34-fd28-11e8-897d-5ac57959ef46 container client-container: <nil>
STEP: delete the pod
Dec 11 09:38:08.322: INFO: Waiting for pod downwardapi-volume-7675fb34-fd28-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:38:08.324: INFO: Pod downwardapi-volume-7675fb34-fd28-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:38:08.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wt4b5" for this suite.
Dec 11 09:38:14.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:38:14.392: INFO: namespace: e2e-tests-downward-api-wt4b5, resource: bindings, ignored listing per whitelist
Dec 11 09:38:14.418: INFO: namespace e2e-tests-downward-api-wt4b5 deletion completed in 6.089970166s

• [SLOW TEST:8.240 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:38:14.418: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1211 09:38:24.547503      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 11 09:38:24.547: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:38:24.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-2m4xr" for this suite.
Dec 11 09:38:30.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:38:30.619: INFO: namespace: e2e-tests-gc-2m4xr, resource: bindings, ignored listing per whitelist
Dec 11 09:38:30.639: INFO: namespace e2e-tests-gc-2m4xr deletion completed in 6.087726063s

• [SLOW TEST:16.221 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:38:30.639: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1211 09:38:40.845669      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 11 09:38:40.845: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:38:40.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-pqttm" for this suite.
Dec 11 09:38:46.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:38:46.937: INFO: namespace: e2e-tests-gc-pqttm, resource: bindings, ignored listing per whitelist
Dec 11 09:38:46.961: INFO: namespace e2e-tests-gc-pqttm deletion completed in 6.111500904s

• [SLOW TEST:16.323 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:38:46.962: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 11 09:38:47.081: INFO: Waiting up to 5m0s for pod "pod-8ec60239-fd28-11e8-897d-5ac57959ef46" in namespace "e2e-tests-emptydir-9w7tk" to be "success or failure"
Dec 11 09:38:47.083: INFO: Pod "pod-8ec60239-fd28-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.998904ms
Dec 11 09:38:49.086: INFO: Pod "pod-8ec60239-fd28-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004844978s
Dec 11 09:38:51.089: INFO: Pod "pod-8ec60239-fd28-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007465681s
STEP: Saw pod success
Dec 11 09:38:51.089: INFO: Pod "pod-8ec60239-fd28-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:38:51.091: INFO: Trying to get logs from node ip-172-25-45-107.us-west-1.compute.internal pod pod-8ec60239-fd28-11e8-897d-5ac57959ef46 container test-container: <nil>
STEP: delete the pod
Dec 11 09:38:51.117: INFO: Waiting for pod pod-8ec60239-fd28-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:38:51.119: INFO: Pod pod-8ec60239-fd28-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:38:51.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9w7tk" for this suite.
Dec 11 09:38:57.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:38:57.172: INFO: namespace: e2e-tests-emptydir-9w7tk, resource: bindings, ignored listing per whitelist
Dec 11 09:38:57.211: INFO: namespace e2e-tests-emptydir-9w7tk deletion completed in 6.087628602s

• [SLOW TEST:10.249 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:38:57.211: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-d8v95
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-d8v95 to expose endpoints map[]
Dec 11 09:38:57.342: INFO: Get endpoints failed (1.928406ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Dec 11 09:38:58.344: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-d8v95 exposes endpoints map[] (1.004609281s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-d8v95
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-d8v95 to expose endpoints map[pod1:[100]]
Dec 11 09:39:01.375: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-d8v95 exposes endpoints map[pod1:[100]] (3.01798232s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-d8v95
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-d8v95 to expose endpoints map[pod1:[100] pod2:[101]]
Dec 11 09:39:03.405: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-d8v95 exposes endpoints map[pod2:[101] pod1:[100]] (2.019169167s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-d8v95
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-d8v95 to expose endpoints map[pod2:[101]]
Dec 11 09:39:04.425: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-d8v95 exposes endpoints map[pod2:[101]] (1.008916915s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-d8v95
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-d8v95 to expose endpoints map[]
Dec 11 09:39:05.441: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-d8v95 exposes endpoints map[] (1.00424676s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:39:05.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-d8v95" for this suite.
Dec 11 09:39:11.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:39:11.544: INFO: namespace: e2e-tests-services-d8v95, resource: bindings, ignored listing per whitelist
Dec 11 09:39:11.575: INFO: namespace e2e-tests-services-d8v95 deletion completed in 6.086283891s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:14.363 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:39:11.575: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Dec 11 09:39:11.681: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-357251099 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:39:11.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-z772d" for this suite.
Dec 11 09:39:17.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:39:17.770: INFO: namespace: e2e-tests-kubectl-z772d, resource: bindings, ignored listing per whitelist
Dec 11 09:39:17.832: INFO: namespace e2e-tests-kubectl-z772d deletion completed in 6.094173731s

• [SLOW TEST:6.257 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:39:17.832: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:39:21.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-gkfb7" for this suite.
Dec 11 09:39:27.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:39:28.009: INFO: namespace: e2e-tests-kubelet-test-gkfb7, resource: bindings, ignored listing per whitelist
Dec 11 09:39:28.039: INFO: namespace e2e-tests-kubelet-test-gkfb7 deletion completed in 6.087337915s

• [SLOW TEST:10.208 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:39:28.039: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-nvlxd in namespace e2e-tests-proxy-fvnzd
I1211 09:39:28.183117      18 runners.go:184] Created replication controller with name: proxy-service-nvlxd, namespace: e2e-tests-proxy-fvnzd, replica count: 1
I1211 09:39:29.233537      18 runners.go:184] proxy-service-nvlxd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1211 09:39:30.233798      18 runners.go:184] proxy-service-nvlxd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1211 09:39:31.234106      18 runners.go:184] proxy-service-nvlxd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1211 09:39:32.234403      18 runners.go:184] proxy-service-nvlxd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1211 09:39:33.234660      18 runners.go:184] proxy-service-nvlxd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1211 09:39:34.234939      18 runners.go:184] proxy-service-nvlxd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1211 09:39:35.235157      18 runners.go:184] proxy-service-nvlxd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1211 09:39:36.235347      18 runners.go:184] proxy-service-nvlxd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1211 09:39:37.235561      18 runners.go:184] proxy-service-nvlxd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1211 09:39:38.235771      18 runners.go:184] proxy-service-nvlxd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1211 09:39:39.236013      18 runners.go:184] proxy-service-nvlxd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1211 09:39:40.236143      18 runners.go:184] proxy-service-nvlxd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1211 09:39:41.236377      18 runners.go:184] proxy-service-nvlxd Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 11 09:39:41.238: INFO: setup took 13.097613113s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec 11 09:39:41.243: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/... (200; 4.935523ms)
Dec 11 09:39:41.243: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/rewriteme"... (200; 5.129073ms)
Dec 11 09:39:41.244: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:162/proxy/: bar (200; 5.378663ms)
Dec 11 09:39:41.244: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:160/proxy/: foo (200; 5.4603ms)
Dec 11 09:39:41.244: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname1/proxy/: foo (200; 5.484982ms)
Dec 11 09:39:41.244: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:162/proxy/: bar (200; 5.739988ms)
Dec 11 09:39:41.244: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname2/proxy/: bar (200; 5.752119ms)
Dec 11 09:39:41.244: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:160/proxy/: foo (200; 5.936242ms)
Dec 11 09:39:41.244: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/rewri... (200; 6.23842ms)
Dec 11 09:39:41.245: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname2/proxy/: bar (200; 6.526591ms)
Dec 11 09:39:41.245: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname1/proxy/: foo (200; 6.471789ms)
Dec 11 09:39:41.249: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:462/proxy/: tls qux (200; 11.310804ms)
Dec 11 09:39:41.250: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname2/proxy/: tls qux (200; 11.401664ms)
Dec 11 09:39:41.250: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:460/proxy/: tls baz (200; 12.287883ms)
Dec 11 09:39:41.251: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname1/proxy/: tls baz (200; 12.620572ms)
Dec 11 09:39:41.252: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/... (200; 13.447392ms)
Dec 11 09:39:41.255: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:162/proxy/: bar (200; 3.235717ms)
Dec 11 09:39:41.255: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:462/proxy/: tls qux (200; 3.462653ms)
Dec 11 09:39:41.255: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/rewriteme"... (200; 3.55402ms)
Dec 11 09:39:41.255: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:160/proxy/: foo (200; 3.400314ms)
Dec 11 09:39:41.255: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:162/proxy/: bar (200; 3.461426ms)
Dec 11 09:39:41.256: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:460/proxy/: tls baz (200; 3.713869ms)
Dec 11 09:39:41.256: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/... (200; 3.787618ms)
Dec 11 09:39:41.256: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/... (200; 3.765411ms)
Dec 11 09:39:41.256: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/rewri... (200; 3.811049ms)
Dec 11 09:39:41.256: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:160/proxy/: foo (200; 3.88586ms)
Dec 11 09:39:41.256: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname1/proxy/: foo (200; 3.959502ms)
Dec 11 09:39:41.256: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname2/proxy/: tls qux (200; 3.942792ms)
Dec 11 09:39:41.256: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname2/proxy/: bar (200; 4.202421ms)
Dec 11 09:39:41.256: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname1/proxy/: foo (200; 4.128839ms)
Dec 11 09:39:41.256: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname2/proxy/: bar (200; 4.158144ms)
Dec 11 09:39:41.256: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname1/proxy/: tls baz (200; 4.463692ms)
Dec 11 09:39:41.260: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:162/proxy/: bar (200; 3.932767ms)
Dec 11 09:39:41.261: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/... (200; 4.28265ms)
Dec 11 09:39:41.261: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/... (200; 4.318183ms)
Dec 11 09:39:41.261: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/rewri... (200; 4.406558ms)
Dec 11 09:39:41.261: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/rewriteme"... (200; 4.724175ms)
Dec 11 09:39:41.261: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:460/proxy/: tls baz (200; 4.637643ms)
Dec 11 09:39:41.261: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:162/proxy/: bar (200; 4.703678ms)
Dec 11 09:39:41.261: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:160/proxy/: foo (200; 4.760385ms)
Dec 11 09:39:41.261: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:160/proxy/: foo (200; 4.929557ms)
Dec 11 09:39:41.261: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:462/proxy/: tls qux (200; 4.872321ms)
Dec 11 09:39:41.261: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname2/proxy/: bar (200; 4.913369ms)
Dec 11 09:39:41.261: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname1/proxy/: foo (200; 4.925692ms)
Dec 11 09:39:41.262: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname1/proxy/: foo (200; 5.212121ms)
Dec 11 09:39:41.262: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname2/proxy/: bar (200; 5.177704ms)
Dec 11 09:39:41.262: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname2/proxy/: tls qux (200; 5.164645ms)
Dec 11 09:39:41.262: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname1/proxy/: tls baz (200; 5.418185ms)
Dec 11 09:39:41.265: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:160/proxy/: foo (200; 3.274068ms)
Dec 11 09:39:41.265: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/... (200; 3.342889ms)
Dec 11 09:39:41.265: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:462/proxy/: tls qux (200; 3.348578ms)
Dec 11 09:39:41.265: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/rewri... (200; 3.300031ms)
Dec 11 09:39:41.265: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:162/proxy/: bar (200; 3.25394ms)
Dec 11 09:39:41.265: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/rewriteme"... (200; 3.53965ms)
Dec 11 09:39:41.266: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname1/proxy/: foo (200; 3.756947ms)
Dec 11 09:39:41.266: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname2/proxy/: tls qux (200; 3.815855ms)
Dec 11 09:39:41.266: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname2/proxy/: bar (200; 3.992582ms)
Dec 11 09:39:41.266: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname1/proxy/: foo (200; 4.000937ms)
Dec 11 09:39:41.266: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:160/proxy/: foo (200; 4.28681ms)
Dec 11 09:39:41.267: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:460/proxy/: tls baz (200; 4.469501ms)
Dec 11 09:39:41.267: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:162/proxy/: bar (200; 4.573907ms)
Dec 11 09:39:41.267: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname1/proxy/: tls baz (200; 4.570435ms)
Dec 11 09:39:41.267: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/... (200; 4.607745ms)
Dec 11 09:39:41.267: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname2/proxy/: bar (200; 4.621251ms)
Dec 11 09:39:41.270: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:462/proxy/: tls qux (200; 2.650663ms)
Dec 11 09:39:41.270: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname2/proxy/: tls qux (200; 3.228347ms)
Dec 11 09:39:41.270: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/rewri... (200; 2.989991ms)
Dec 11 09:39:41.270: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:162/proxy/: bar (200; 3.279718ms)
Dec 11 09:39:41.270: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname1/proxy/: tls baz (200; 3.647458ms)
Dec 11 09:39:41.271: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/... (200; 3.31771ms)
Dec 11 09:39:41.271: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/rewriteme"... (200; 3.666271ms)
Dec 11 09:39:41.271: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname1/proxy/: foo (200; 3.856068ms)
Dec 11 09:39:41.271: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:160/proxy/: foo (200; 3.62912ms)
Dec 11 09:39:41.271: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:162/proxy/: bar (200; 3.303216ms)
Dec 11 09:39:41.271: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:460/proxy/: tls baz (200; 3.272201ms)
Dec 11 09:39:41.271: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname2/proxy/: bar (200; 3.962825ms)
Dec 11 09:39:41.271: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/... (200; 3.884804ms)
Dec 11 09:39:41.271: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:160/proxy/: foo (200; 3.566543ms)
Dec 11 09:39:41.271: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname1/proxy/: foo (200; 3.957822ms)
Dec 11 09:39:41.271: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname2/proxy/: bar (200; 3.881303ms)
Dec 11 09:39:41.274: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:162/proxy/: bar (200; 3.034121ms)
Dec 11 09:39:41.274: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:462/proxy/: tls qux (200; 3.11087ms)
Dec 11 09:39:41.275: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname2/proxy/: bar (200; 3.44171ms)
Dec 11 09:39:41.275: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname1/proxy/: foo (200; 3.557338ms)
Dec 11 09:39:41.275: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname2/proxy/: tls qux (200; 3.438277ms)
Dec 11 09:39:41.275: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/rewri... (200; 3.477724ms)
Dec 11 09:39:41.275: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname1/proxy/: foo (200; 3.633363ms)
Dec 11 09:39:41.275: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/... (200; 3.855116ms)
Dec 11 09:39:41.275: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname2/proxy/: bar (200; 4.021323ms)
Dec 11 09:39:41.275: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:160/proxy/: foo (200; 4.1135ms)
Dec 11 09:39:41.275: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:460/proxy/: tls baz (200; 4.154032ms)
Dec 11 09:39:41.275: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/rewriteme"... (200; 4.134173ms)
Dec 11 09:39:41.276: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:160/proxy/: foo (200; 4.384287ms)
Dec 11 09:39:41.276: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/... (200; 4.372917ms)
Dec 11 09:39:41.276: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:162/proxy/: bar (200; 4.564435ms)
Dec 11 09:39:41.276: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname1/proxy/: tls baz (200; 4.928301ms)
Dec 11 09:39:41.281: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname2/proxy/: bar (200; 4.495448ms)
Dec 11 09:39:41.281: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/rewri... (200; 4.603913ms)
Dec 11 09:39:41.281: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/rewriteme"... (200; 4.82942ms)
Dec 11 09:39:41.281: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:460/proxy/: tls baz (200; 4.89471ms)
Dec 11 09:39:41.281: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/... (200; 4.870634ms)
Dec 11 09:39:41.281: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:462/proxy/: tls qux (200; 5.03745ms)
Dec 11 09:39:41.281: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:160/proxy/: foo (200; 5.084028ms)
Dec 11 09:39:41.281: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:162/proxy/: bar (200; 5.062194ms)
Dec 11 09:39:41.282: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:162/proxy/: bar (200; 5.150216ms)
Dec 11 09:39:41.282: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/... (200; 5.133053ms)
Dec 11 09:39:41.282: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:160/proxy/: foo (200; 5.147554ms)
Dec 11 09:39:41.282: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname2/proxy/: bar (200; 5.409527ms)
Dec 11 09:39:41.282: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname1/proxy/: foo (200; 5.430716ms)
Dec 11 09:39:41.282: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname1/proxy/: foo (200; 5.466454ms)
Dec 11 09:39:41.282: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname2/proxy/: tls qux (200; 5.566748ms)
Dec 11 09:39:41.282: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname1/proxy/: tls baz (200; 5.84603ms)
Dec 11 09:39:41.286: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:460/proxy/: tls baz (200; 3.381997ms)
Dec 11 09:39:41.286: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:162/proxy/: bar (200; 3.855632ms)
Dec 11 09:39:41.286: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:162/proxy/: bar (200; 4.18038ms)
Dec 11 09:39:41.287: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/... (200; 4.247301ms)
Dec 11 09:39:41.287: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname2/proxy/: bar (200; 4.430352ms)
Dec 11 09:39:41.287: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:160/proxy/: foo (200; 4.379476ms)
Dec 11 09:39:41.287: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/rewri... (200; 4.512525ms)
Dec 11 09:39:41.287: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/rewriteme"... (200; 4.642557ms)
Dec 11 09:39:41.287: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname2/proxy/: bar (200; 4.67649ms)
Dec 11 09:39:41.287: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:160/proxy/: foo (200; 4.887392ms)
Dec 11 09:39:41.287: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname2/proxy/: tls qux (200; 4.889362ms)
Dec 11 09:39:41.287: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname1/proxy/: foo (200; 4.941331ms)
Dec 11 09:39:41.287: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/... (200; 4.980787ms)
Dec 11 09:39:41.287: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:462/proxy/: tls qux (200; 5.01005ms)
Dec 11 09:39:41.287: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname1/proxy/: tls baz (200; 5.010361ms)
Dec 11 09:39:41.288: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname1/proxy/: foo (200; 5.392568ms)
Dec 11 09:39:41.291: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname1/proxy/: foo (200; 2.970335ms)
Dec 11 09:39:41.291: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:160/proxy/: foo (200; 2.998682ms)
Dec 11 09:39:41.291: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:162/proxy/: bar (200; 3.011806ms)
Dec 11 09:39:41.291: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/... (200; 3.047575ms)
Dec 11 09:39:41.291: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:462/proxy/: tls qux (200; 3.353787ms)
Dec 11 09:39:41.291: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/rewriteme"... (200; 3.585713ms)
Dec 11 09:39:41.291: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname2/proxy/: tls qux (200; 3.560991ms)
Dec 11 09:39:41.292: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:160/proxy/: foo (200; 3.806907ms)
Dec 11 09:39:41.292: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:162/proxy/: bar (200; 3.843943ms)
Dec 11 09:39:41.292: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname2/proxy/: bar (200; 3.954129ms)
Dec 11 09:39:41.292: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:460/proxy/: tls baz (200; 4.039069ms)
Dec 11 09:39:41.292: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/... (200; 4.030791ms)
Dec 11 09:39:41.292: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname1/proxy/: foo (200; 4.139478ms)
Dec 11 09:39:41.292: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/rewri... (200; 4.272175ms)
Dec 11 09:39:41.292: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname2/proxy/: bar (200; 4.399728ms)
Dec 11 09:39:41.292: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname1/proxy/: tls baz (200; 4.684199ms)
Dec 11 09:39:41.296: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/... (200; 3.736046ms)
Dec 11 09:39:41.297: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:460/proxy/: tls baz (200; 4.354276ms)
Dec 11 09:39:41.297: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/rewri... (200; 4.272694ms)
Dec 11 09:39:41.297: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname1/proxy/: tls baz (200; 4.337368ms)
Dec 11 09:39:41.297: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:162/proxy/: bar (200; 4.395975ms)
Dec 11 09:39:41.297: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:160/proxy/: foo (200; 4.408632ms)
Dec 11 09:39:41.297: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/... (200; 4.41596ms)
Dec 11 09:39:41.297: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:160/proxy/: foo (200; 4.481438ms)
Dec 11 09:39:41.297: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname2/proxy/: tls qux (200; 4.451353ms)
Dec 11 09:39:41.297: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname2/proxy/: bar (200; 4.393412ms)
Dec 11 09:39:41.297: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:462/proxy/: tls qux (200; 4.411214ms)
Dec 11 09:39:41.297: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname1/proxy/: foo (200; 4.699034ms)
Dec 11 09:39:41.297: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname2/proxy/: bar (200; 4.685795ms)
Dec 11 09:39:41.297: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/rewriteme"... (200; 4.60323ms)
Dec 11 09:39:41.297: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:162/proxy/: bar (200; 4.766205ms)
Dec 11 09:39:41.298: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname1/proxy/: foo (200; 5.147197ms)
Dec 11 09:39:41.301: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:462/proxy/: tls qux (200; 3.376481ms)
Dec 11 09:39:41.301: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:160/proxy/: foo (200; 3.439122ms)
Dec 11 09:39:41.301: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:162/proxy/: bar (200; 3.459153ms)
Dec 11 09:39:41.301: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:160/proxy/: foo (200; 3.483696ms)
Dec 11 09:39:41.301: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:460/proxy/: tls baz (200; 3.658565ms)
Dec 11 09:39:41.302: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname1/proxy/: foo (200; 3.756205ms)
Dec 11 09:39:41.302: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/rewri... (200; 3.661911ms)
Dec 11 09:39:41.302: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/... (200; 3.666256ms)
Dec 11 09:39:41.302: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/rewriteme"... (200; 3.703067ms)
Dec 11 09:39:41.302: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname1/proxy/: tls baz (200; 3.840706ms)
Dec 11 09:39:41.302: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:162/proxy/: bar (200; 3.874021ms)
Dec 11 09:39:41.302: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/... (200; 3.919775ms)
Dec 11 09:39:41.302: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname1/proxy/: foo (200; 4.363351ms)
Dec 11 09:39:41.302: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname2/proxy/: bar (200; 4.274741ms)
Dec 11 09:39:41.302: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname2/proxy/: tls qux (200; 4.453109ms)
Dec 11 09:39:41.302: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname2/proxy/: bar (200; 4.336073ms)
Dec 11 09:39:41.305: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/... (200; 2.751323ms)
Dec 11 09:39:41.305: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:162/proxy/: bar (200; 3.178035ms)
Dec 11 09:39:41.305: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:160/proxy/: foo (200; 3.267451ms)
Dec 11 09:39:41.306: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:460/proxy/: tls baz (200; 3.45695ms)
Dec 11 09:39:41.306: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname1/proxy/: tls baz (200; 3.530244ms)
Dec 11 09:39:41.306: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname2/proxy/: tls qux (200; 3.51054ms)
Dec 11 09:39:41.306: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/rewriteme"... (200; 3.631739ms)
Dec 11 09:39:41.306: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:462/proxy/: tls qux (200; 3.767103ms)
Dec 11 09:39:41.306: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:160/proxy/: foo (200; 3.844341ms)
Dec 11 09:39:41.306: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname1/proxy/: foo (200; 3.834878ms)
Dec 11 09:39:41.306: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/rewri... (200; 3.819499ms)
Dec 11 09:39:41.306: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/... (200; 3.892233ms)
Dec 11 09:39:41.306: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname2/proxy/: bar (200; 4.044596ms)
Dec 11 09:39:41.306: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:162/proxy/: bar (200; 4.01753ms)
Dec 11 09:39:41.307: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname1/proxy/: foo (200; 4.366313ms)
Dec 11 09:39:41.307: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname2/proxy/: bar (200; 4.363458ms)
Dec 11 09:39:41.310: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/rewriteme"... (200; 3.593542ms)
Dec 11 09:39:41.310: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:160/proxy/: foo (200; 3.747828ms)
Dec 11 09:39:41.310: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:162/proxy/: bar (200; 3.68ms)
Dec 11 09:39:41.312: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname1/proxy/: tls baz (200; 5.211037ms)
Dec 11 09:39:41.312: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname1/proxy/: foo (200; 5.150279ms)
Dec 11 09:39:41.312: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/... (200; 5.182629ms)
Dec 11 09:39:41.312: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname2/proxy/: bar (200; 5.197786ms)
Dec 11 09:39:41.312: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname1/proxy/: foo (200; 5.255768ms)
Dec 11 09:39:41.312: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:162/proxy/: bar (200; 5.195378ms)
Dec 11 09:39:41.312: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:160/proxy/: foo (200; 5.130826ms)
Dec 11 09:39:41.312: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/rewri... (200; 5.155349ms)
Dec 11 09:39:41.312: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname2/proxy/: tls qux (200; 5.293122ms)
Dec 11 09:39:41.312: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:462/proxy/: tls qux (200; 5.170189ms)
Dec 11 09:39:41.312: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname2/proxy/: bar (200; 5.160209ms)
Dec 11 09:39:41.312: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/... (200; 5.238063ms)
Dec 11 09:39:41.312: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:460/proxy/: tls baz (200; 5.185513ms)
Dec 11 09:39:41.315: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/rewri... (200; 2.972616ms)
Dec 11 09:39:41.315: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:160/proxy/: foo (200; 2.866678ms)
Dec 11 09:39:41.315: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:462/proxy/: tls qux (200; 3.244954ms)
Dec 11 09:39:41.316: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:162/proxy/: bar (200; 3.668125ms)
Dec 11 09:39:41.316: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/... (200; 3.960175ms)
Dec 11 09:39:41.316: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/... (200; 3.982703ms)
Dec 11 09:39:41.316: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname2/proxy/: bar (200; 4.172068ms)
Dec 11 09:39:41.316: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/rewriteme"... (200; 4.064834ms)
Dec 11 09:39:41.316: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:160/proxy/: foo (200; 4.059065ms)
Dec 11 09:39:41.316: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:162/proxy/: bar (200; 4.088817ms)
Dec 11 09:39:41.317: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname2/proxy/: bar (200; 4.332136ms)
Dec 11 09:39:41.317: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname1/proxy/: foo (200; 4.271631ms)
Dec 11 09:39:41.317: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname1/proxy/: tls baz (200; 4.359917ms)
Dec 11 09:39:41.317: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:460/proxy/: tls baz (200; 4.336598ms)
Dec 11 09:39:41.317: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname1/proxy/: foo (200; 4.528641ms)
Dec 11 09:39:41.317: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname2/proxy/: tls qux (200; 4.467825ms)
Dec 11 09:39:41.320: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:160/proxy/: foo (200; 3.165727ms)
Dec 11 09:39:41.320: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/... (200; 3.062543ms)
Dec 11 09:39:41.320: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:462/proxy/: tls qux (200; 3.375212ms)
Dec 11 09:39:41.320: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/rewri... (200; 3.503135ms)
Dec 11 09:39:41.321: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:162/proxy/: bar (200; 3.705278ms)
Dec 11 09:39:41.321: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/rewriteme"... (200; 3.661754ms)
Dec 11 09:39:41.321: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:160/proxy/: foo (200; 3.725149ms)
Dec 11 09:39:41.321: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:162/proxy/: bar (200; 3.742358ms)
Dec 11 09:39:41.321: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:460/proxy/: tls baz (200; 3.859283ms)
Dec 11 09:39:41.321: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname2/proxy/: bar (200; 3.846579ms)
Dec 11 09:39:41.321: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname1/proxy/: tls baz (200; 4.065219ms)
Dec 11 09:39:41.321: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname1/proxy/: foo (200; 4.264221ms)
Dec 11 09:39:41.321: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname2/proxy/: bar (200; 4.3062ms)
Dec 11 09:39:41.321: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname1/proxy/: foo (200; 4.354186ms)
Dec 11 09:39:41.321: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/... (200; 4.440537ms)
Dec 11 09:39:41.321: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname2/proxy/: tls qux (200; 4.536358ms)
Dec 11 09:39:41.325: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:160/proxy/: foo (200; 3.546989ms)
Dec 11 09:39:41.326: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:462/proxy/: tls qux (200; 4.04442ms)
Dec 11 09:39:41.326: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:460/proxy/: tls baz (200; 4.070433ms)
Dec 11 09:39:41.326: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:162/proxy/: bar (200; 4.02254ms)
Dec 11 09:39:41.326: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname2/proxy/: bar (200; 4.004355ms)
Dec 11 09:39:41.326: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/... (200; 4.307148ms)
Dec 11 09:39:41.326: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/rewriteme"... (200; 4.439418ms)
Dec 11 09:39:41.326: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/rewri... (200; 4.331042ms)
Dec 11 09:39:41.326: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:162/proxy/: bar (200; 4.295269ms)
Dec 11 09:39:41.326: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname2/proxy/: tls qux (200; 4.350976ms)
Dec 11 09:39:41.326: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname1/proxy/: foo (200; 4.549001ms)
Dec 11 09:39:41.326: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:160/proxy/: foo (200; 4.333543ms)
Dec 11 09:39:41.326: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/... (200; 4.362164ms)
Dec 11 09:39:41.326: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname1/proxy/: tls baz (200; 4.30392ms)
Dec 11 09:39:41.326: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname1/proxy/: foo (200; 4.438085ms)
Dec 11 09:39:41.326: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname2/proxy/: bar (200; 4.701296ms)
Dec 11 09:39:41.330: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:162/proxy/: bar (200; 3.792299ms)
Dec 11 09:39:41.330: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/... (200; 3.699885ms)
Dec 11 09:39:41.330: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/rewri... (200; 3.973338ms)
Dec 11 09:39:41.330: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:462/proxy/: tls qux (200; 4.036508ms)
Dec 11 09:39:41.330: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:460/proxy/: tls baz (200; 3.958488ms)
Dec 11 09:39:41.330: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:162/proxy/: bar (200; 3.962356ms)
Dec 11 09:39:41.330: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:160/proxy/: foo (200; 3.993547ms)
Dec 11 09:39:41.330: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:160/proxy/: foo (200; 3.982139ms)
Dec 11 09:39:41.331: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/rewriteme"... (200; 4.144208ms)
Dec 11 09:39:41.331: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/... (200; 4.152281ms)
Dec 11 09:39:41.331: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname2/proxy/: bar (200; 4.293487ms)
Dec 11 09:39:41.331: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname2/proxy/: tls qux (200; 4.377164ms)
Dec 11 09:39:41.331: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname1/proxy/: foo (200; 4.391426ms)
Dec 11 09:39:41.331: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname2/proxy/: bar (200; 4.361685ms)
Dec 11 09:39:41.331: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname1/proxy/: tls baz (200; 4.445779ms)
Dec 11 09:39:41.331: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname1/proxy/: foo (200; 4.657492ms)
Dec 11 09:39:41.334: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:460/proxy/: tls baz (200; 3.328366ms)
Dec 11 09:39:41.334: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/rewri... (200; 3.352211ms)
Dec 11 09:39:41.335: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/... (200; 3.495114ms)
Dec 11 09:39:41.335: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:162/proxy/: bar (200; 3.512232ms)
Dec 11 09:39:41.335: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/... (200; 3.688657ms)
Dec 11 09:39:41.335: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:160/proxy/: foo (200; 3.65107ms)
Dec 11 09:39:41.335: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:160/proxy/: foo (200; 3.728558ms)
Dec 11 09:39:41.335: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:162/proxy/: bar (200; 3.675434ms)
Dec 11 09:39:41.335: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname2/proxy/: bar (200; 3.774457ms)
Dec 11 09:39:41.335: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname2/proxy/: tls qux (200; 3.862853ms)
Dec 11 09:39:41.335: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname1/proxy/: foo (200; 4.002233ms)
Dec 11 09:39:41.335: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:462/proxy/: tls qux (200; 4.044617ms)
Dec 11 09:39:41.335: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname1/proxy/: tls baz (200; 4.048625ms)
Dec 11 09:39:41.336: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/rewriteme"... (200; 4.610783ms)
Dec 11 09:39:41.336: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname1/proxy/: foo (200; 4.997175ms)
Dec 11 09:39:41.336: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname2/proxy/: bar (200; 5.038437ms)
Dec 11 09:39:41.339: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:462/proxy/: tls qux (200; 2.989191ms)
Dec 11 09:39:41.339: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:460/proxy/: tls baz (200; 3.106924ms)
Dec 11 09:39:41.339: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:162/proxy/: bar (200; 3.190489ms)
Dec 11 09:39:41.340: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname2/proxy/: tls qux (200; 3.413998ms)
Dec 11 09:39:41.340: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/... (200; 3.349556ms)
Dec 11 09:39:41.340: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:160/proxy/: foo (200; 3.360763ms)
Dec 11 09:39:41.340: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname1/proxy/: foo (200; 3.660433ms)
Dec 11 09:39:41.340: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/... (200; 3.932295ms)
Dec 11 09:39:41.340: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname2/proxy/: bar (200; 3.946279ms)
Dec 11 09:39:41.340: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/rewriteme"... (200; 3.933863ms)
Dec 11 09:39:41.340: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname1/proxy/: foo (200; 4.047105ms)
Dec 11 09:39:41.340: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/rewri... (200; 4.208738ms)
Dec 11 09:39:41.341: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:162/proxy/: bar (200; 4.379047ms)
Dec 11 09:39:41.341: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:160/proxy/: foo (200; 4.418363ms)
Dec 11 09:39:41.341: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname2/proxy/: bar (200; 4.525764ms)
Dec 11 09:39:41.341: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname1/proxy/: tls baz (200; 4.601598ms)
Dec 11 09:39:41.344: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:162/proxy/: bar (200; 3.425345ms)
Dec 11 09:39:41.344: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:1080/proxy/... (200; 3.496467ms)
Dec 11 09:39:41.345: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:160/proxy/: foo (200; 3.688676ms)
Dec 11 09:39:41.345: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/http:proxy-service-nvlxd-hz875:162/proxy/: bar (200; 3.722686ms)
Dec 11 09:39:41.345: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:160/proxy/: foo (200; 3.79819ms)
Dec 11 09:39:41.345: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875:1080/proxy/rewri... (200; 3.849731ms)
Dec 11 09:39:41.345: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname2/proxy/: tls qux (200; 3.76463ms)
Dec 11 09:39:41.345: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/proxy-service-nvlxd-hz875/proxy/rewriteme"... (200; 3.848217ms)
Dec 11 09:39:41.345: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname2/proxy/: bar (200; 3.849154ms)
Dec 11 09:39:41.345: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname1/proxy/: foo (200; 4.206944ms)
Dec 11 09:39:41.345: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:460/proxy/: tls baz (200; 4.247033ms)
Dec 11 09:39:41.345: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:443/proxy/... (200; 4.185009ms)
Dec 11 09:39:41.345: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-fvnzd/pods/https:proxy-service-nvlxd-hz875:462/proxy/: tls qux (200; 4.228716ms)
Dec 11 09:39:41.345: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/https:proxy-service-nvlxd:tlsportname1/proxy/: tls baz (200; 4.477173ms)
Dec 11 09:39:41.346: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/http:proxy-service-nvlxd:portname1/proxy/: foo (200; 4.712202ms)
Dec 11 09:39:41.346: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-fvnzd/services/proxy-service-nvlxd:portname2/proxy/: bar (200; 4.673275ms)
STEP: deleting ReplicationController proxy-service-nvlxd in namespace e2e-tests-proxy-fvnzd, will wait for the garbage collector to delete the pods
Dec 11 09:39:41.409: INFO: Deleting ReplicationController proxy-service-nvlxd took: 10.791251ms
Dec 11 09:39:41.509: INFO: Terminating ReplicationController proxy-service-nvlxd pods took: 100.257432ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:39:54.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-fvnzd" for this suite.
Dec 11 09:40:00.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:40:00.155: INFO: namespace: e2e-tests-proxy-fvnzd, resource: bindings, ignored listing per whitelist
Dec 11 09:40:00.197: INFO: namespace e2e-tests-proxy-fvnzd deletion completed in 6.082885208s

• [SLOW TEST:32.157 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:40:00.197: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-ba6b5b66-fd28-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume secrets
Dec 11 09:40:00.315: INFO: Waiting up to 5m0s for pod "pod-secrets-ba6d124a-fd28-11e8-897d-5ac57959ef46" in namespace "e2e-tests-secrets-scdgp" to be "success or failure"
Dec 11 09:40:00.317: INFO: Pod "pod-secrets-ba6d124a-fd28-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.094007ms
Dec 11 09:40:02.320: INFO: Pod "pod-secrets-ba6d124a-fd28-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0048998s
STEP: Saw pod success
Dec 11 09:40:02.320: INFO: Pod "pod-secrets-ba6d124a-fd28-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:40:02.322: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-secrets-ba6d124a-fd28-11e8-897d-5ac57959ef46 container secret-volume-test: <nil>
STEP: delete the pod
Dec 11 09:40:02.349: INFO: Waiting for pod pod-secrets-ba6d124a-fd28-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:40:02.350: INFO: Pod pod-secrets-ba6d124a-fd28-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:40:02.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-scdgp" for this suite.
Dec 11 09:40:08.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:40:08.417: INFO: namespace: e2e-tests-secrets-scdgp, resource: bindings, ignored listing per whitelist
Dec 11 09:40:08.446: INFO: namespace e2e-tests-secrets-scdgp deletion completed in 6.091079847s

• [SLOW TEST:8.249 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:40:08.446: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-v6sw
STEP: Creating a pod to test atomic-volume-subpath
Dec 11 09:40:08.576: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-v6sw" in namespace "e2e-tests-subpath-wvqv8" to be "success or failure"
Dec 11 09:40:08.579: INFO: Pod "pod-subpath-test-projected-v6sw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.14383ms
Dec 11 09:40:10.582: INFO: Pod "pod-subpath-test-projected-v6sw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005203082s
Dec 11 09:40:12.585: INFO: Pod "pod-subpath-test-projected-v6sw": Phase="Running", Reason="", readiness=false. Elapsed: 4.008158857s
Dec 11 09:40:14.587: INFO: Pod "pod-subpath-test-projected-v6sw": Phase="Running", Reason="", readiness=false. Elapsed: 6.011000203s
Dec 11 09:40:16.591: INFO: Pod "pod-subpath-test-projected-v6sw": Phase="Running", Reason="", readiness=false. Elapsed: 8.014376238s
Dec 11 09:40:18.594: INFO: Pod "pod-subpath-test-projected-v6sw": Phase="Running", Reason="", readiness=false. Elapsed: 10.017439734s
Dec 11 09:40:20.597: INFO: Pod "pod-subpath-test-projected-v6sw": Phase="Running", Reason="", readiness=false. Elapsed: 12.020235498s
Dec 11 09:40:22.600: INFO: Pod "pod-subpath-test-projected-v6sw": Phase="Running", Reason="", readiness=false. Elapsed: 14.023452067s
Dec 11 09:40:24.603: INFO: Pod "pod-subpath-test-projected-v6sw": Phase="Running", Reason="", readiness=false. Elapsed: 16.026109461s
Dec 11 09:40:26.606: INFO: Pod "pod-subpath-test-projected-v6sw": Phase="Running", Reason="", readiness=false. Elapsed: 18.02924571s
Dec 11 09:40:28.609: INFO: Pod "pod-subpath-test-projected-v6sw": Phase="Running", Reason="", readiness=false. Elapsed: 20.032184515s
Dec 11 09:40:30.612: INFO: Pod "pod-subpath-test-projected-v6sw": Phase="Running", Reason="", readiness=false. Elapsed: 22.035150547s
Dec 11 09:40:32.615: INFO: Pod "pod-subpath-test-projected-v6sw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.038244959s
STEP: Saw pod success
Dec 11 09:40:32.615: INFO: Pod "pod-subpath-test-projected-v6sw" satisfied condition "success or failure"
Dec 11 09:40:32.617: INFO: Trying to get logs from node ip-172-25-45-107.us-west-1.compute.internal pod pod-subpath-test-projected-v6sw container test-container-subpath-projected-v6sw: <nil>
STEP: delete the pod
Dec 11 09:40:32.645: INFO: Waiting for pod pod-subpath-test-projected-v6sw to disappear
Dec 11 09:40:32.647: INFO: Pod pod-subpath-test-projected-v6sw no longer exists
STEP: Deleting pod pod-subpath-test-projected-v6sw
Dec 11 09:40:32.647: INFO: Deleting pod "pod-subpath-test-projected-v6sw" in namespace "e2e-tests-subpath-wvqv8"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:40:32.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-wvqv8" for this suite.
Dec 11 09:40:38.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:40:38.676: INFO: namespace: e2e-tests-subpath-wvqv8, resource: bindings, ignored listing per whitelist
Dec 11 09:40:38.741: INFO: namespace e2e-tests-subpath-wvqv8 deletion completed in 6.088185772s

• [SLOW TEST:30.295 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:40:38.741: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-tbzqh/secret-test-d164ff4b-fd28-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume secrets
Dec 11 09:40:38.859: INFO: Waiting up to 5m0s for pod "pod-configmaps-d1669f51-fd28-11e8-897d-5ac57959ef46" in namespace "e2e-tests-secrets-tbzqh" to be "success or failure"
Dec 11 09:40:38.861: INFO: Pod "pod-configmaps-d1669f51-fd28-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077411ms
Dec 11 09:40:40.864: INFO: Pod "pod-configmaps-d1669f51-fd28-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004773948s
STEP: Saw pod success
Dec 11 09:40:40.864: INFO: Pod "pod-configmaps-d1669f51-fd28-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:40:40.866: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-configmaps-d1669f51-fd28-11e8-897d-5ac57959ef46 container env-test: <nil>
STEP: delete the pod
Dec 11 09:40:40.892: INFO: Waiting for pod pod-configmaps-d1669f51-fd28-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:40:40.894: INFO: Pod pod-configmaps-d1669f51-fd28-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:40:40.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-tbzqh" for this suite.
Dec 11 09:40:46.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:40:46.975: INFO: namespace: e2e-tests-secrets-tbzqh, resource: bindings, ignored listing per whitelist
Dec 11 09:40:46.990: INFO: namespace e2e-tests-secrets-tbzqh deletion completed in 6.092467281s

• [SLOW TEST:8.249 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:40:46.991: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:40:53.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-kknb4" for this suite.
Dec 11 09:40:59.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:40:59.291: INFO: namespace: e2e-tests-namespaces-kknb4, resource: bindings, ignored listing per whitelist
Dec 11 09:40:59.328: INFO: namespace e2e-tests-namespaces-kknb4 deletion completed in 6.088023004s
STEP: Destroying namespace "e2e-tests-nsdeletetest-klz5v" for this suite.
Dec 11 09:40:59.330: INFO: Namespace e2e-tests-nsdeletetest-klz5v was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-th4z6" for this suite.
Dec 11 09:41:05.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:41:05.370: INFO: namespace: e2e-tests-nsdeletetest-th4z6, resource: bindings, ignored listing per whitelist
Dec 11 09:41:05.419: INFO: namespace e2e-tests-nsdeletetest-th4z6 deletion completed in 6.089673301s

• [SLOW TEST:18.429 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:41:05.420: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:41:05.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-b2592" for this suite.
Dec 11 09:41:11.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:41:11.634: INFO: namespace: e2e-tests-kubelet-test-b2592, resource: bindings, ignored listing per whitelist
Dec 11 09:41:11.657: INFO: namespace e2e-tests-kubelet-test-b2592 deletion completed in 6.089018777s

• [SLOW TEST:6.237 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:41:11.657: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-e503a270-fd28-11e8-897d-5ac57959ef46
STEP: Creating secret with name s-test-opt-upd-e503a2ae-fd28-11e8-897d-5ac57959ef46
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-e503a270-fd28-11e8-897d-5ac57959ef46
STEP: Updating secret s-test-opt-upd-e503a2ae-fd28-11e8-897d-5ac57959ef46
STEP: Creating secret with name s-test-opt-create-e503a2d1-fd28-11e8-897d-5ac57959ef46
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:41:15.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qc5tb" for this suite.
Dec 11 09:41:37.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:41:37.933: INFO: namespace: e2e-tests-projected-qc5tb, resource: bindings, ignored listing per whitelist
Dec 11 09:41:37.953: INFO: namespace e2e-tests-projected-qc5tb deletion completed in 22.08698006s

• [SLOW TEST:26.296 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:41:37.953: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec 11 09:41:38.069: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2dmxf,SelfLink:/api/v1/namespaces/e2e-tests-watch-2dmxf/configmaps/e2e-watch-test-configmap-a,UID:f4b1629a-fd28-11e8-8e03-0681e6464a68,ResourceVersion:21958296,Generation:0,CreationTimestamp:2018-12-11 09:41:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 11 09:41:38.069: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2dmxf,SelfLink:/api/v1/namespaces/e2e-tests-watch-2dmxf/configmaps/e2e-watch-test-configmap-a,UID:f4b1629a-fd28-11e8-8e03-0681e6464a68,ResourceVersion:21958296,Generation:0,CreationTimestamp:2018-12-11 09:41:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec 11 09:41:48.082: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2dmxf,SelfLink:/api/v1/namespaces/e2e-tests-watch-2dmxf/configmaps/e2e-watch-test-configmap-a,UID:f4b1629a-fd28-11e8-8e03-0681e6464a68,ResourceVersion:21958313,Generation:0,CreationTimestamp:2018-12-11 09:41:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 11 09:41:48.082: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2dmxf,SelfLink:/api/v1/namespaces/e2e-tests-watch-2dmxf/configmaps/e2e-watch-test-configmap-a,UID:f4b1629a-fd28-11e8-8e03-0681e6464a68,ResourceVersion:21958313,Generation:0,CreationTimestamp:2018-12-11 09:41:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec 11 09:41:58.098: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2dmxf,SelfLink:/api/v1/namespaces/e2e-tests-watch-2dmxf/configmaps/e2e-watch-test-configmap-a,UID:f4b1629a-fd28-11e8-8e03-0681e6464a68,ResourceVersion:21958329,Generation:0,CreationTimestamp:2018-12-11 09:41:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 11 09:41:58.098: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2dmxf,SelfLink:/api/v1/namespaces/e2e-tests-watch-2dmxf/configmaps/e2e-watch-test-configmap-a,UID:f4b1629a-fd28-11e8-8e03-0681e6464a68,ResourceVersion:21958329,Generation:0,CreationTimestamp:2018-12-11 09:41:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec 11 09:42:08.109: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2dmxf,SelfLink:/api/v1/namespaces/e2e-tests-watch-2dmxf/configmaps/e2e-watch-test-configmap-a,UID:f4b1629a-fd28-11e8-8e03-0681e6464a68,ResourceVersion:21958345,Generation:0,CreationTimestamp:2018-12-11 09:41:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 11 09:42:08.109: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2dmxf,SelfLink:/api/v1/namespaces/e2e-tests-watch-2dmxf/configmaps/e2e-watch-test-configmap-a,UID:f4b1629a-fd28-11e8-8e03-0681e6464a68,ResourceVersion:21958345,Generation:0,CreationTimestamp:2018-12-11 09:41:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec 11 09:42:18.122: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-2dmxf,SelfLink:/api/v1/namespaces/e2e-tests-watch-2dmxf/configmaps/e2e-watch-test-configmap-b,UID:0c90d14a-fd29-11e8-8e03-0681e6464a68,ResourceVersion:21958362,Generation:0,CreationTimestamp:2018-12-11 09:42:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 11 09:42:18.122: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-2dmxf,SelfLink:/api/v1/namespaces/e2e-tests-watch-2dmxf/configmaps/e2e-watch-test-configmap-b,UID:0c90d14a-fd29-11e8-8e03-0681e6464a68,ResourceVersion:21958362,Generation:0,CreationTimestamp:2018-12-11 09:42:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec 11 09:42:28.133: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-2dmxf,SelfLink:/api/v1/namespaces/e2e-tests-watch-2dmxf/configmaps/e2e-watch-test-configmap-b,UID:0c90d14a-fd29-11e8-8e03-0681e6464a68,ResourceVersion:21958379,Generation:0,CreationTimestamp:2018-12-11 09:42:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 11 09:42:28.133: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-2dmxf,SelfLink:/api/v1/namespaces/e2e-tests-watch-2dmxf/configmaps/e2e-watch-test-configmap-b,UID:0c90d14a-fd29-11e8-8e03-0681e6464a68,ResourceVersion:21958379,Generation:0,CreationTimestamp:2018-12-11 09:42:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:42:38.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-2dmxf" for this suite.
Dec 11 09:42:44.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:42:44.214: INFO: namespace: e2e-tests-watch-2dmxf, resource: bindings, ignored listing per whitelist
Dec 11 09:42:44.237: INFO: namespace e2e-tests-watch-2dmxf deletion completed in 6.099022199s

• [SLOW TEST:66.284 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:42:44.237: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-ldjb6
Dec 11 09:42:48.359: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-ldjb6
STEP: checking the pod's current state and verifying that restartCount is present
Dec 11 09:42:48.361: INFO: Initial restart count of pod liveness-http is 0
Dec 11 09:42:58.378: INFO: Restart count of pod e2e-tests-container-probe-ldjb6/liveness-http is now 1 (10.016743937s elapsed)
Dec 11 09:43:20.409: INFO: Restart count of pod e2e-tests-container-probe-ldjb6/liveness-http is now 2 (32.048506175s elapsed)
Dec 11 09:43:40.439: INFO: Restart count of pod e2e-tests-container-probe-ldjb6/liveness-http is now 3 (52.077618129s elapsed)
Dec 11 09:43:58.466: INFO: Restart count of pod e2e-tests-container-probe-ldjb6/liveness-http is now 4 (1m10.104530172s elapsed)
Dec 11 09:45:14.591: INFO: Restart count of pod e2e-tests-container-probe-ldjb6/liveness-http is now 5 (2m26.229543177s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:45:14.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-ldjb6" for this suite.
Dec 11 09:45:20.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:45:20.673: INFO: namespace: e2e-tests-container-probe-ldjb6, resource: bindings, ignored listing per whitelist
Dec 11 09:45:20.702: INFO: namespace e2e-tests-container-probe-ldjb6 deletion completed in 6.085806604s

• [SLOW TEST:156.465 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:45:20.702: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-7975db18-fd29-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume configMaps
Dec 11 09:45:20.826: INFO: Waiting up to 5m0s for pod "pod-configmaps-7977623b-fd29-11e8-897d-5ac57959ef46" in namespace "e2e-tests-configmap-ff4gf" to be "success or failure"
Dec 11 09:45:20.828: INFO: Pod "pod-configmaps-7977623b-fd29-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.852071ms
Dec 11 09:45:22.831: INFO: Pod "pod-configmaps-7977623b-fd29-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00468345s
STEP: Saw pod success
Dec 11 09:45:22.831: INFO: Pod "pod-configmaps-7977623b-fd29-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:45:22.833: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-configmaps-7977623b-fd29-11e8-897d-5ac57959ef46 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 09:45:22.861: INFO: Waiting for pod pod-configmaps-7977623b-fd29-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:45:22.863: INFO: Pod pod-configmaps-7977623b-fd29-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:45:22.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ff4gf" for this suite.
Dec 11 09:45:28.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:45:28.946: INFO: namespace: e2e-tests-configmap-ff4gf, resource: bindings, ignored listing per whitelist
Dec 11 09:45:28.953: INFO: namespace e2e-tests-configmap-ff4gf deletion completed in 6.085471553s

• [SLOW TEST:8.251 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:45:28.953: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Dec 11 09:45:29.048: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 11 09:45:29.056: INFO: Waiting for terminating namespaces to be deleted...
Dec 11 09:45:29.059: INFO: 
Logging pods the kubelet thinks is on node ip-172-25-45-107.us-west-1.compute.internal before test
Dec 11 09:45:29.072: INFO: prd-keycloak-pgpool-58b949979d-wllt4 from platform started at 2018-11-19 14:59:42 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container prd-keycloak-pgpool ready: true, restart count 2
Dec 11 09:45:29.072: INFO: prd-pf-sign-svc-platform-signup-svc-7dcfdd559-llx49 from platform started at 2018-11-19 14:59:48 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.072: INFO: 	Container prd-pf-sign-svc-platform-signup-svc ready: true, restart count 0
Dec 11 09:45:29.072: INFO: prd-botfactory-chatbot-ui-pfm-botfactory-chatbot-ui-7bd798pjt9m from platform started at 2018-11-21 10:41:40 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container pfm-botfactory-chatbot-ui ready: true, restart count 0
Dec 11 09:45:29.072: INFO: datadog-kube-state-metrics-7d48b4db57-9245w from infra started at 2018-11-19 14:59:40 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container kube-state-metrics ready: true, restart count 0
Dec 11 09:45:29.072: INFO: prd-efk-elasticsearch-client-8655b8d9b9-jt8zw from infra started at 2018-11-19 14:59:40 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container es-client ready: true, restart count 0
Dec 11 09:45:29.072: INFO: prd-dss-leadcloser-ui-658768bd4b-84zb9 from platform started at 2018-11-20 12:27:09 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container dss-leadcloser-ui ready: true, restart count 0
Dec 11 09:45:29.072: INFO: prd-ibf-botfactory-admin-svc-botfactory-admin-service-59f4n5m5f from platform started at 2018-11-21 11:08:42 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container botfactory-admin-service ready: true, restart count 0
Dec 11 09:45:29.072: INFO: tiller-deploy-f55c64689-4jfg5 from kube-system started at 2018-11-19 14:59:40 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container tiller ready: true, restart count 0
Dec 11 09:45:29.072: INFO: prd-efk-elasticsearch-kibana-654b6d5965-xfvj2 from infra started at 2018-11-19 14:59:41 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container kibana ready: true, restart count 0
Dec 11 09:45:29.072: INFO: prd-dss-pm-profile-svc-dss-pm-profile-service-556b68d65-rlqgv from platform started at 2018-11-19 14:59:42 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container dss-pm-profile-service ready: true, restart count 0
Dec 11 09:45:29.072: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.072: INFO: default-http-backend-66b447d9cf-cvp7c from ingress-nginx started at 2018-11-19 14:59:42 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container default-http-backend ready: true, restart count 0
Dec 11 09:45:29.072: INFO: prd-pf-doc-svc-platform-doc-svc-6bc8488db8-cncz8 from platform started at 2018-11-19 14:59:45 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.072: INFO: 	Container prd-pf-doc-svc-platform-doc-svc ready: true, restart count 0
Dec 11 09:45:29.072: INFO: prd-efk-elasticsearch-fluentd-78wvq from infra started at 2018-11-19 14:57:43 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container fluentd ready: true, restart count 0
Dec 11 09:45:29.072: INFO: metrics-server-8555b5f58f-7qjkk from kube-system started at 2018-11-19 14:59:40 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container metrics-server ready: true, restart count 0
Dec 11 09:45:29.072: INFO: prd-ibf-botfactory-agent-svc-botfactory-agent-service-56f5mkg6f from platform started at 2018-11-21 10:57:49 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container botfactory-agent-service ready: true, restart count 0
Dec 11 09:45:29.072: INFO: prd-pf-iam-svc-platform-iam-svc-5d57975b5-vjrk6 from platform started at 2018-11-19 14:59:47 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.072: INFO: 	Container prd-pf-iam-svc-platform-iam-svc ready: true, restart count 0
Dec 11 09:45:29.072: INFO: prd-efk-elasticsearch-data-1 from infra started at 2018-11-19 14:59:19 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container es-data ready: true, restart count 0
Dec 11 09:45:29.072: INFO: dr-kong-kong-55df5b9f69-tn88c from platform started at 2018-11-19 14:59:40 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container dr-kong-kong ready: true, restart count 1
Dec 11 09:45:29.072: INFO: prd-pf-notes-svc-platform-notes-svc-5c99df689c-bdfww from platform started at 2018-11-19 14:59:47 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.072: INFO: 	Container prd-pf-notes-svc-platform-notes-svc ready: true, restart count 0
Dec 11 09:45:29.072: INFO: prd-efk-elasticsearch-master-1 from infra started at 2018-11-19 14:59:16 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container es-master ready: true, restart count 0
Dec 11 09:45:29.072: INFO: platform-utils-svc-5bb47f77bd-jjdgj from platform started at 2018-11-19 14:59:40 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container platform-utils-svc ready: true, restart count 0
Dec 11 09:45:29.072: INFO: prd-pf-calen-svc-platform-calen-svc-59dc958758-kgjtc from platform started at 2018-11-19 14:59:44 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.072: INFO: 	Container prd-pf-calen-svc-platform-calen-svc ready: true, restart count 0
Dec 11 09:45:29.072: INFO: kube-proxy-ip-172-25-45-107.us-west-1.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Dec 11 09:45:29.072: INFO: datadog-datadog-5m28x from infra started at 2018-11-19 14:57:43 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container datadog ready: true, restart count 2
Dec 11 09:45:29.072: INFO: calico-node-j87ww from kube-system started at 2018-11-19 14:57:43 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container calico-node ready: true, restart count 0
Dec 11 09:45:29.072: INFO: 	Container install-cni ready: true, restart count 0
Dec 11 09:45:29.072: INFO: kube-dns-autoscaler-f4c47db64-rwllv from kube-system started at 2018-11-19 14:59:40 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container autoscaler ready: true, restart count 0
Dec 11 09:45:29.072: INFO: ubuntu-5f89d47d59-pz2h8 from platform started at 2018-11-19 14:59:40 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container ubuntu ready: true, restart count 0
Dec 11 09:45:29.072: INFO: kube-dns-7c4d8456dd-k6dkm from kube-system started at 2018-11-19 14:59:40 +0000 UTC (3 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container dnsmasq ready: true, restart count 0
Dec 11 09:45:29.072: INFO: 	Container kubedns ready: true, restart count 0
Dec 11 09:45:29.072: INFO: 	Container sidecar ready: true, restart count 0
Dec 11 09:45:29.072: INFO: prd-pf-blkusrimp-svc-platform-blkusrimp-svc-7d8d5c459f-78l6p from platform started at 2018-11-19 14:59:44 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.072: INFO: 	Container prd-pf-blkusrimp-svc-platform-blkusrimp-svc ready: true, restart count 0
Dec 11 09:45:29.072: INFO: prd-pf-contact-svc-platform-contact-svc-7fdb7698d8-ksnzv from platform started at 2018-11-19 14:59:45 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.072: INFO: 	Container prd-pf-contact-svc-platform-contact-svc ready: true, restart count 0
Dec 11 09:45:29.072: INFO: prd-pf-email-svc-platform-email-svc-8696f76496-9gbn5 from platform started at 2018-11-19 14:59:45 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.072: INFO: 	Container prd-pf-email-svc-platform-email-svc ready: true, restart count 0
Dec 11 09:45:29.072: INFO: prd-pf-notif-svc-platform-notif-svc-84dd77bbd8-74825 from platform started at 2018-11-19 14:59:47 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.072: INFO: 	Container prd-pf-notif-svc-platform-notif-svc ready: true, restart count 0
Dec 11 09:45:29.072: INFO: prd-pfm-svc-data-6448cbb64-w464d from platform started at 2018-11-19 14:59:48 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.072: INFO: 	Container prd-pf-data-svc-prd-pfm-svc-data ready: true, restart count 0
Dec 11 09:45:29.072: INFO: prd-pf-activity-svc-platform-activity-svc-855df677b4-s5r9p from platform started at 2018-11-19 14:59:43 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.072: INFO: 	Container prd-pf-activity-svc-platform-activity-svc ready: true, restart count 0
Dec 11 09:45:29.072: INFO: prd-pf-audit-svc-platform-audit-svc-78f5998486-2rmn5 from platform started at 2018-11-19 14:59:44 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.072: INFO: 	Container prd-pf-audit-svc-platform-audit-svc ready: true, restart count 0
Dec 11 09:45:29.072: INFO: prd-dss-qni-illustration-svc-dss-qni-illustration-service-tjbw9 from platform started at 2018-11-26 11:18:56 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.072: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.072: INFO: 	Container prd-dss-qni-illustration-svc-dss-qni-illustration-service ready: true, restart count 0
Dec 11 09:45:29.072: INFO: 
Logging pods the kubelet thinks is on node ip-172-25-62-1.us-west-1.compute.internal before test
Dec 11 09:45:29.082: INFO: prd-pf-prflmgmt-ui-platform-prflmgmt-ui-654ff59c99-tl62p from platform started at 2018-11-20 11:46:41 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container platform-prflmgmt-ui ready: true, restart count 0
Dec 11 09:45:29.082: INFO: prd-dss-ppc-svc-ppc-svc-58f5d567d-8msxj from platform started at 2018-11-26 11:36:47 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.082: INFO: 	Container ppc-svc ready: true, restart count 0
Dec 11 09:45:29.082: INFO: prd-efk-elasticsearch-fluentd-t6bxk from infra started at 2018-11-19 17:03:43 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container fluentd ready: true, restart count 0
Dec 11 09:45:29.082: INFO: prd-pf-conf-svc-platform-conf-svc-6f8c9c5649-hrx2v from platform started at 2018-11-20 08:43:48 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.082: INFO: 	Container prd-pf-conf-svc-platform-conf-svc ready: true, restart count 0
Dec 11 09:45:29.082: INFO: prd-pf-dashboard-ui-platform-dashboard-ui-859cf5d999-9qp8v from platform started at 2018-11-20 11:23:38 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container platform-dashboard-ui ready: true, restart count 0
Dec 11 09:45:29.082: INFO: prd-pf-admin-ui-platform-admin-ui-85c98dcc66-9vj7s from platform started at 2018-11-20 11:40:28 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container platform-admin-ui ready: true, restart count 0
Dec 11 09:45:29.082: INFO: prd-pf-dashboard-ui-platform-dashboard-ui-859cf5d999-mwwgd from platform started at 2018-11-20 11:23:32 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container platform-dashboard-ui ready: true, restart count 0
Dec 11 09:45:29.082: INFO: prd-pf-accmgmt-ui-platform-accmgmt-ui-5cbc4c9d66-krr5g from platform started at 2018-11-20 11:50:04 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container platform-accmgmt-ui ready: true, restart count 0
Dec 11 09:45:29.082: INFO: prd-dss-qni-quote-svc-dss-qni-quote-service-84cbc8c6c8-qm5jw from platform started at 2018-11-26 11:13:14 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container dss-qni-quote-service ready: true, restart count 0
Dec 11 09:45:29.082: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.082: INFO: datadog-datadog-lqmmz from infra started at 2018-11-19 17:03:43 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container datadog ready: true, restart count 0
Dec 11 09:45:29.082: INFO: calico-node-trxzw from kube-system started at 2018-11-19 17:03:43 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container calico-node ready: true, restart count 0
Dec 11 09:45:29.082: INFO: 	Container install-cni ready: true, restart count 0
Dec 11 09:45:29.082: INFO: prd-dss-quote-ui-7475c4bdc-lg6c6 from platform started at 2018-11-21 10:07:09 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container dss-quote-ui ready: true, restart count 0
Dec 11 09:45:29.082: INFO: prd-botfactory-ui-pfm-botfactory-ui-7ff78b89f7-xnmkr from platform started at 2018-11-21 11:30:22 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container pfm-botfactory-ui ready: true, restart count 0
Dec 11 09:45:29.082: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-11 09:12:13 +0000 UTC (3 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container cleanup ready: true, restart count 0
Dec 11 09:45:29.082: INFO: 	Container forwarder ready: true, restart count 0
Dec 11 09:45:29.082: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 11 09:45:29.082: INFO: prd-efk-elasticsearch-curator-1544317200-qxdt5 from infra started at 2018-12-09 01:00:06 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container curator ready: false, restart count 0
Dec 11 09:45:29.082: INFO: prd-dss-leadcloser-ui-658768bd4b-zbbdr from platform started at 2018-11-20 12:27:05 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container dss-leadcloser-ui ready: true, restart count 0
Dec 11 09:45:29.082: INFO: prd-dss-ppc-ratetables-ppc-svc-cfb7cd6b9-6qcrh from platform started at 2018-11-26 11:48:21 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.082: INFO: 	Container ppc-svc ready: true, restart count 0
Dec 11 09:45:29.082: INFO: prd-pf-apimgmt-ui-platform-apimgmt-ui-699d4df9d-nb79x from platform started at 2018-11-20 11:37:39 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container platform-apimgmt-ui ready: true, restart count 0
Dec 11 09:45:29.082: INFO: prd-dss-lc-svc-dss-lc-service-6c8748f77b-7sj75 from platform started at 2018-11-20 13:24:04 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container dss-lc-service ready: true, restart count 0
Dec 11 09:45:29.082: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.082: INFO: prd-ibf-botfactory-platform-svc-botfactory-platform-servicszx9g from platform started at 2018-11-21 11:04:39 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container botfactory-platform-service ready: true, restart count 0
Dec 11 09:45:29.082: INFO: prd-efk-elasticsearch-curator-1544403600-dgbl8 from infra started at 2018-12-10 01:00:08 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container curator ready: false, restart count 0
Dec 11 09:45:29.082: INFO: prd-pf-signup-ui-platform-signup-ui-54ffdd6f94-pzb82 from platform started at 2018-11-20 11:30:55 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container platform-signup-ui ready: true, restart count 0
Dec 11 09:45:29.082: INFO: prd-efk-elasticsearch-curator-1544490000-4wpv9 from infra started at 2018-12-11 01:00:07 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container curator ready: false, restart count 0
Dec 11 09:45:29.082: INFO: prd-dss-ppc-ui-64f9cf489c-zj4pk from platform started at 2018-11-20 14:04:47 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container dss-ppc-ui ready: true, restart count 0
Dec 11 09:45:29.082: INFO: prd-dss-ppc-masterdata-ppc-svc-7d8577dd7c-pb92m from platform started at 2018-11-26 11:42:41 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.082: INFO: 	Container ppc-svc ready: true, restart count 0
Dec 11 09:45:29.082: INFO: prd-ai-sentiment-eng-svc-ai-sentiment-svc-69bd5d994b-7wcr2 from ai started at 2018-11-20 13:34:13 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container prd-ai-sentiment-eng-svc-ai-sentiment-svc ready: true, restart count 0
Dec 11 09:45:29.082: INFO: prd-ibf-botfactory-adapter-svc-botfactory-adapter-service-p5vcf from platform started at 2018-11-21 11:11:42 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container botfactory-adapter-service ready: true, restart count 0
Dec 11 09:45:29.082: INFO: kube-proxy-ip-172-25-62-1.us-west-1.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Dec 11 09:45:29.082: INFO: prd-pfm-svc-telephony-55658c585-sp22g from platform started at 2018-11-20 08:24:26 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.082: INFO: 	Container prd-pf-telephony-svc-prd-pfm-svc-telephony ready: true, restart count 0
Dec 11 09:45:29.082: INFO: prd-pf-acc-svc-platform-acc-svc-56c66dc6bc-jl2qm from platform started at 2018-11-20 08:35:58 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.082: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.082: INFO: 	Container prd-pf-acc-svc-platform-acc-svc ready: true, restart count 0
Dec 11 09:45:29.082: INFO: 
Logging pods the kubelet thinks is on node ip-172-25-93-75.us-west-1.compute.internal before test
Dec 11 09:45:29.104: INFO: prd-pf-iam-svc-platform-iam-svc-5d57975b5-b8fcg from platform started at 2018-11-19 16:59:28 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.104: INFO: 	Container prd-pf-iam-svc-platform-iam-svc ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-pfm-svc-data-6448cbb64-djfdf from platform started at 2018-11-19 16:59:30 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.104: INFO: 	Container prd-pf-data-svc-prd-pfm-svc-data ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-dss-lcbulk-svc-dss-lcbulk-service-77b5449544-6nkdr from platform started at 2018-11-19 16:59:28 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container dss-lcbulk-service ready: true, restart count 0
Dec 11 09:45:29.104: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.104: INFO: kube-dns-7c4d8456dd-np757 from kube-system started at 2018-11-19 16:59:29 +0000 UTC (3 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container dnsmasq ready: true, restart count 0
Dec 11 09:45:29.104: INFO: 	Container kubedns ready: true, restart count 0
Dec 11 09:45:29.104: INFO: 	Container sidecar ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-pf-audit-svc-platform-audit-svc-78f5998486-4vlp5 from platform started at 2018-11-19 16:59:29 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.104: INFO: 	Container prd-pf-audit-svc-platform-audit-svc ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-keycloak-pgpool-58b949979d-ndwgn from platform started at 2018-11-19 16:59:30 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container prd-keycloak-pgpool ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-efk-elasticsearch-client-8655b8d9b9-5fmbv from infra started at 2018-11-19 16:59:30 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container es-client ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-pf-signup-ui-platform-signup-ui-54ffdd6f94-62xr7 from platform started at 2018-11-20 11:30:50 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container platform-signup-ui ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-pf-blkusrimp-svc-platform-blkusrimp-svc-7d8d5c459f-q24h8 from platform started at 2018-11-19 16:59:28 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.104: INFO: 	Container prd-pf-blkusrimp-svc-platform-blkusrimp-svc ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-pf-notif-svc-platform-notif-svc-84dd77bbd8-qhxw5 from platform started at 2018-11-19 16:59:29 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.104: INFO: 	Container prd-pf-notif-svc-platform-notif-svc ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-pf-admin-ui-platform-admin-ui-85c98dcc66-rbgt5 from platform started at 2018-11-20 11:40:24 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container platform-admin-ui ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-botfactory-chatbot-ui-pfm-botfactory-chatbot-ui-7bd798cnb8c from platform started at 2018-11-21 10:41:40 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container pfm-botfactory-chatbot-ui ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-dss-pm-profile-svc-dss-pm-profile-service-556b68d65-qmntq from platform started at 2018-11-19 16:59:31 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container dss-pm-profile-service ready: true, restart count 0
Dec 11 09:45:29.104: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-pf-email-svc-platform-email-svc-8696f76496-wkzqt from platform started at 2018-11-19 16:59:31 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.104: INFO: 	Container prd-pf-email-svc-platform-email-svc ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-efk-elasticsearch-master-2 from infra started at 2018-11-19 17:03:49 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container es-master ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-dss-qni-illustration-svc-dss-qni-illustration-service-r2rhd from platform started at 2018-11-26 11:18:56 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.104: INFO: 	Container prd-dss-qni-illustration-svc-dss-qni-illustration-service ready: true, restart count 0
Dec 11 09:45:29.104: INFO: calico-node-p7n2j from kube-system started at 2018-11-19 16:53:44 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container calico-node ready: true, restart count 0
Dec 11 09:45:29.104: INFO: 	Container install-cni ready: true, restart count 0
Dec 11 09:45:29.104: INFO: datadog-datadog-r4px7 from infra started at 2018-11-19 16:53:44 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container datadog ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-pf-notes-svc-platform-notes-svc-5c99df689c-vs8g5 from platform started at 2018-11-19 16:59:28 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.104: INFO: 	Container prd-pf-notes-svc-platform-notes-svc ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-keycloak-keycloak-78d64cbc4f-scj6l from platform started at 2018-11-19 16:59:29 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container prd-keycloak-keycloak ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-ai-sentiment-eng-svc-ai-sentiment-svc-69bd5d994b-vn2sr from ai started at 2018-11-20 13:34:13 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container prd-ai-sentiment-eng-svc-ai-sentiment-svc ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-botfactory-ui-pfm-botfactory-ui-7ff78b89f7-ljt45 from platform started at 2018-11-21 11:30:22 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container pfm-botfactory-ui ready: true, restart count 0
Dec 11 09:45:29.104: INFO: kube-proxy-ip-172-25-93-75.us-west-1.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Dec 11 09:45:29.104: INFO: prd-efk-elasticsearch-master-0 from infra started at 2018-11-19 16:59:28 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container es-master ready: true, restart count 0
Dec 11 09:45:29.104: INFO: nginx-ingress-controller-5ccb96dd7b-ldrbm from ingress-nginx started at 2018-11-19 17:11:11 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-pf-accmgmt-ui-platform-accmgmt-ui-5cbc4c9d66-g4wqj from platform started at 2018-11-20 11:49:59 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container platform-accmgmt-ui ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-pf-activity-svc-platform-activity-svc-855df677b4-htnqk from platform started at 2018-11-19 16:59:30 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.104: INFO: 	Container prd-pf-activity-svc-platform-activity-svc ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-pf-apimgmt-ui-platform-apimgmt-ui-699d4df9d-cd7lv from platform started at 2018-11-20 11:37:33 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container platform-apimgmt-ui ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-pf-contact-svc-platform-contact-svc-7fdb7698d8-6s89f from platform started at 2018-11-19 16:59:28 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.104: INFO: 	Container prd-pf-contact-svc-platform-contact-svc ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-dss-ppc-ui-64f9cf489c-r64qn from platform started at 2018-11-20 14:04:47 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container dss-ppc-ui ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-pf-calen-svc-platform-calen-svc-59dc958758-gq7dn from platform started at 2018-11-19 16:59:29 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.104: INFO: 	Container prd-pf-calen-svc-platform-calen-svc ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-pf-sign-svc-platform-signup-svc-7dcfdd559-c26zr from platform started at 2018-11-19 16:59:30 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.104: INFO: 	Container prd-pf-sign-svc-platform-signup-svc ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-efk-elasticsearch-fluentd-gv7g8 from infra started at 2018-11-19 16:53:44 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container fluentd ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-efk-elasticsearch-data-0 from infra started at 2018-11-19 16:59:28 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container es-data ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-pf-prflmgmt-ui-platform-prflmgmt-ui-654ff59c99-mntgc from platform started at 2018-11-20 11:46:36 +0000 UTC (1 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container platform-prflmgmt-ui ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-pfm-svc-telephony-55658c585-l2cmb from platform started at 2018-11-20 08:24:26 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.104: INFO: 	Container prd-pf-telephony-svc-prd-pfm-svc-telephony ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-pf-acc-svc-platform-acc-svc-56c66dc6bc-c76pd from platform started at 2018-11-20 08:35:58 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.104: INFO: 	Container prd-pf-acc-svc-platform-acc-svc ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-pf-conf-svc-platform-conf-svc-6f8c9c5649-js8zv from platform started at 2018-11-20 08:43:48 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.104: INFO: 	Container prd-pf-conf-svc-platform-conf-svc ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-dss-lc-svc-dss-lc-service-6c8748f77b-tffh5 from platform started at 2018-11-20 13:24:04 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container dss-lc-service ready: true, restart count 0
Dec 11 09:45:29.104: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.104: INFO: heapster-6d9d49d496-zxs9t from kube-system started at 2018-11-19 16:59:28 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container heapster ready: true, restart count 0
Dec 11 09:45:29.104: INFO: 	Container heapster-nanny ready: true, restart count 0
Dec 11 09:45:29.104: INFO: prd-pf-doc-svc-platform-doc-svc-6bc8488db8-b6mbr from platform started at 2018-11-19 16:59:28 +0000 UTC (2 container statuses recorded)
Dec 11 09:45:29.104: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:45:29.104: INFO: 	Container prd-pf-doc-svc-platform-doc-svc ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node ip-172-25-45-107.us-west-1.compute.internal
STEP: verifying the node has the label node ip-172-25-62-1.us-west-1.compute.internal
STEP: verifying the node has the label node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-ai-sentiment-eng-svc-ai-sentiment-svc-69bd5d994b-7wcr2 requesting resource cpu=250m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-ai-sentiment-eng-svc-ai-sentiment-svc-69bd5d994b-vn2sr requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod datadog-datadog-5m28x requesting resource cpu=100m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod datadog-datadog-lqmmz requesting resource cpu=100m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod datadog-datadog-r4px7 requesting resource cpu=100m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod datadog-kube-state-metrics-7d48b4db57-9245w requesting resource cpu=0m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-efk-elasticsearch-client-8655b8d9b9-5fmbv requesting resource cpu=0m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-efk-elasticsearch-client-8655b8d9b9-jt8zw requesting resource cpu=0m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-efk-elasticsearch-data-0 requesting resource cpu=0m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-efk-elasticsearch-data-1 requesting resource cpu=0m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-efk-elasticsearch-fluentd-78wvq requesting resource cpu=100m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-efk-elasticsearch-fluentd-gv7g8 requesting resource cpu=100m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-efk-elasticsearch-fluentd-t6bxk requesting resource cpu=100m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-efk-elasticsearch-kibana-654b6d5965-xfvj2 requesting resource cpu=100m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-efk-elasticsearch-master-0 requesting resource cpu=0m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-efk-elasticsearch-master-1 requesting resource cpu=0m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-efk-elasticsearch-master-2 requesting resource cpu=0m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod default-http-backend-66b447d9cf-cvp7c requesting resource cpu=10m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod nginx-ingress-controller-5ccb96dd7b-ldrbm requesting resource cpu=0m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod calico-node-j87ww requesting resource cpu=20m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod calico-node-p7n2j requesting resource cpu=20m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod calico-node-trxzw requesting resource cpu=20m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod heapster-6d9d49d496-zxs9t requesting resource cpu=133m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod kube-dns-7c4d8456dd-k6dkm requesting resource cpu=260m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod kube-dns-7c4d8456dd-np757 requesting resource cpu=260m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod kube-dns-autoscaler-f4c47db64-rwllv requesting resource cpu=20m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod kube-proxy-ip-172-25-45-107.us-west-1.compute.internal requesting resource cpu=100m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod kube-proxy-ip-172-25-62-1.us-west-1.compute.internal requesting resource cpu=100m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod kube-proxy-ip-172-25-93-75.us-west-1.compute.internal requesting resource cpu=100m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod metrics-server-8555b5f58f-7qjkk requesting resource cpu=0m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod tiller-deploy-f55c64689-4jfg5 requesting resource cpu=0m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod dr-kong-kong-55df5b9f69-tn88c requesting resource cpu=250m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod platform-utils-svc-5bb47f77bd-jjdgj requesting resource cpu=0m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-botfactory-chatbot-ui-pfm-botfactory-chatbot-ui-7bd798cnb8c requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-botfactory-chatbot-ui-pfm-botfactory-chatbot-ui-7bd798pjt9m requesting resource cpu=250m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-botfactory-ui-pfm-botfactory-ui-7ff78b89f7-ljt45 requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-botfactory-ui-pfm-botfactory-ui-7ff78b89f7-xnmkr requesting resource cpu=250m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-dss-lc-svc-dss-lc-service-6c8748f77b-7sj75 requesting resource cpu=250m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-dss-lc-svc-dss-lc-service-6c8748f77b-tffh5 requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-dss-lcbulk-svc-dss-lcbulk-service-77b5449544-6nkdr requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-dss-leadcloser-ui-658768bd4b-84zb9 requesting resource cpu=250m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-dss-leadcloser-ui-658768bd4b-zbbdr requesting resource cpu=250m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-dss-pm-profile-svc-dss-pm-profile-service-556b68d65-qmntq requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-dss-pm-profile-svc-dss-pm-profile-service-556b68d65-rlqgv requesting resource cpu=250m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-dss-ppc-masterdata-ppc-svc-7d8577dd7c-pb92m requesting resource cpu=250m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-dss-ppc-ratetables-ppc-svc-cfb7cd6b9-6qcrh requesting resource cpu=250m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-dss-ppc-svc-ppc-svc-58f5d567d-8msxj requesting resource cpu=250m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-dss-ppc-ui-64f9cf489c-r64qn requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-dss-ppc-ui-64f9cf489c-zj4pk requesting resource cpu=250m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-dss-qni-illustration-svc-dss-qni-illustration-service-r2rhd requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-dss-qni-illustration-svc-dss-qni-illustration-service-tjbw9 requesting resource cpu=250m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-dss-qni-quote-svc-dss-qni-quote-service-84cbc8c6c8-qm5jw requesting resource cpu=250m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-dss-quote-ui-7475c4bdc-lg6c6 requesting resource cpu=250m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-ibf-botfactory-adapter-svc-botfactory-adapter-service-p5vcf requesting resource cpu=250m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-ibf-botfactory-admin-svc-botfactory-admin-service-59f4n5m5f requesting resource cpu=250m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.204: INFO: Pod prd-ibf-botfactory-agent-svc-botfactory-agent-service-56f5mkg6f requesting resource cpu=250m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-ibf-botfactory-platform-svc-botfactory-platform-servicszx9g requesting resource cpu=250m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-keycloak-keycloak-78d64cbc4f-scj6l requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-keycloak-pgpool-58b949979d-ndwgn requesting resource cpu=50m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-keycloak-pgpool-58b949979d-wllt4 requesting resource cpu=50m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-acc-svc-platform-acc-svc-56c66dc6bc-c76pd requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-acc-svc-platform-acc-svc-56c66dc6bc-jl2qm requesting resource cpu=250m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-accmgmt-ui-platform-accmgmt-ui-5cbc4c9d66-g4wqj requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-accmgmt-ui-platform-accmgmt-ui-5cbc4c9d66-krr5g requesting resource cpu=250m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-activity-svc-platform-activity-svc-855df677b4-htnqk requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-activity-svc-platform-activity-svc-855df677b4-s5r9p requesting resource cpu=250m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-admin-ui-platform-admin-ui-85c98dcc66-9vj7s requesting resource cpu=250m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-admin-ui-platform-admin-ui-85c98dcc66-rbgt5 requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-apimgmt-ui-platform-apimgmt-ui-699d4df9d-cd7lv requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-apimgmt-ui-platform-apimgmt-ui-699d4df9d-nb79x requesting resource cpu=250m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-audit-svc-platform-audit-svc-78f5998486-2rmn5 requesting resource cpu=250m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-audit-svc-platform-audit-svc-78f5998486-4vlp5 requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-blkusrimp-svc-platform-blkusrimp-svc-7d8d5c459f-78l6p requesting resource cpu=250m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-blkusrimp-svc-platform-blkusrimp-svc-7d8d5c459f-q24h8 requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-calen-svc-platform-calen-svc-59dc958758-gq7dn requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-calen-svc-platform-calen-svc-59dc958758-kgjtc requesting resource cpu=250m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-conf-svc-platform-conf-svc-6f8c9c5649-hrx2v requesting resource cpu=250m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-conf-svc-platform-conf-svc-6f8c9c5649-js8zv requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-contact-svc-platform-contact-svc-7fdb7698d8-6s89f requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-contact-svc-platform-contact-svc-7fdb7698d8-ksnzv requesting resource cpu=250m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-dashboard-ui-platform-dashboard-ui-859cf5d999-9qp8v requesting resource cpu=250m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-dashboard-ui-platform-dashboard-ui-859cf5d999-mwwgd requesting resource cpu=250m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-doc-svc-platform-doc-svc-6bc8488db8-b6mbr requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-doc-svc-platform-doc-svc-6bc8488db8-cncz8 requesting resource cpu=250m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-email-svc-platform-email-svc-8696f76496-9gbn5 requesting resource cpu=250m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-email-svc-platform-email-svc-8696f76496-wkzqt requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-iam-svc-platform-iam-svc-5d57975b5-b8fcg requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-iam-svc-platform-iam-svc-5d57975b5-vjrk6 requesting resource cpu=250m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-notes-svc-platform-notes-svc-5c99df689c-bdfww requesting resource cpu=250m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-notes-svc-platform-notes-svc-5c99df689c-vs8g5 requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-notif-svc-platform-notif-svc-84dd77bbd8-74825 requesting resource cpu=250m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-notif-svc-platform-notif-svc-84dd77bbd8-qhxw5 requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-prflmgmt-ui-platform-prflmgmt-ui-654ff59c99-mntgc requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-prflmgmt-ui-platform-prflmgmt-ui-654ff59c99-tl62p requesting resource cpu=250m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-sign-svc-platform-signup-svc-7dcfdd559-c26zr requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-sign-svc-platform-signup-svc-7dcfdd559-llx49 requesting resource cpu=250m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-signup-ui-platform-signup-ui-54ffdd6f94-62xr7 requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pf-signup-ui-platform-signup-ui-54ffdd6f94-pzb82 requesting resource cpu=250m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pfm-svc-data-6448cbb64-djfdf requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pfm-svc-data-6448cbb64-w464d requesting resource cpu=250m on Node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pfm-svc-telephony-55658c585-l2cmb requesting resource cpu=250m on Node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod prd-pfm-svc-telephony-55658c585-sp22g requesting resource cpu=250m on Node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:45:29.205: INFO: Pod ubuntu-5f89d47d59-pz2h8 requesting resource cpu=0m on Node ip-172-25-45-107.us-west-1.compute.internal
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7e779163-fd29-11e8-897d-5ac57959ef46.156f3e25c96eaefe], Reason = [Scheduled], Message = [Successfully assigned filler-pod-7e779163-fd29-11e8-897d-5ac57959ef46 to ip-172-25-45-107.us-west-1.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7e779163-fd29-11e8-897d-5ac57959ef46.156f3e25d42ec6ae], Reason = [SuccessfulMountVolume], Message = [MountVolume.SetUp succeeded for volume "default-token-ggvgj" ]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7e779163-fd29-11e8-897d-5ac57959ef46.156f3e25f5bb3e6f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7e779163-fd29-11e8-897d-5ac57959ef46.156f3e25f9409038], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7e779163-fd29-11e8-897d-5ac57959ef46.156f3e25fe1ec23e], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7e795e38-fd29-11e8-897d-5ac57959ef46.156f3e25ca2d4c0e], Reason = [Scheduled], Message = [Successfully assigned filler-pod-7e795e38-fd29-11e8-897d-5ac57959ef46 to ip-172-25-62-1.us-west-1.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7e795e38-fd29-11e8-897d-5ac57959ef46.156f3e25db6358c4], Reason = [SuccessfulMountVolume], Message = [MountVolume.SetUp succeeded for volume "default-token-ggvgj" ]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7e795e38-fd29-11e8-897d-5ac57959ef46.156f3e25f561a6e0], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7e795e38-fd29-11e8-897d-5ac57959ef46.156f3e25f7d51205], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7e795e38-fd29-11e8-897d-5ac57959ef46.156f3e25fb7944f9], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7e7b3a2b-fd29-11e8-897d-5ac57959ef46.156f3e25cafa7949], Reason = [Scheduled], Message = [Successfully assigned filler-pod-7e7b3a2b-fd29-11e8-897d-5ac57959ef46 to ip-172-25-93-75.us-west-1.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7e7b3a2b-fd29-11e8-897d-5ac57959ef46.156f3e25d5f8b92b], Reason = [SuccessfulMountVolume], Message = [MountVolume.SetUp succeeded for volume "default-token-ggvgj" ]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7e7b3a2b-fd29-11e8-897d-5ac57959ef46.156f3e25f73aa2c1], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7e7b3a2b-fd29-11e8-897d-5ac57959ef46.156f3e25f9b057b5], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7e7b3a2b-fd29-11e8-897d-5ac57959ef46.156f3e25fe7b7e6f], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.156f3e264318bb11], Reason = [FailedScheduling], Message = [0/6 nodes are available: 6 Insufficient cpu.]
STEP: removing the label node off the node ip-172-25-45-107.us-west-1.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-25-62-1.us-west-1.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-25-93-75.us-west-1.compute.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:45:32.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-2srrn" for this suite.
Dec 11 09:45:38.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:45:38.404: INFO: namespace: e2e-tests-sched-pred-2srrn, resource: bindings, ignored listing per whitelist
Dec 11 09:45:38.417: INFO: namespace e2e-tests-sched-pred-2srrn deletion completed in 6.08580721s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.464 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:45:38.417: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Dec 11 09:45:38.524: INFO: Waiting up to 5m0s for pod "var-expansion-8403be7b-fd29-11e8-897d-5ac57959ef46" in namespace "e2e-tests-var-expansion-24xw7" to be "success or failure"
Dec 11 09:45:38.526: INFO: Pod "var-expansion-8403be7b-fd29-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010412ms
Dec 11 09:45:40.529: INFO: Pod "var-expansion-8403be7b-fd29-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004569013s
STEP: Saw pod success
Dec 11 09:45:40.529: INFO: Pod "var-expansion-8403be7b-fd29-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:45:40.531: INFO: Trying to get logs from node ip-172-25-45-107.us-west-1.compute.internal pod var-expansion-8403be7b-fd29-11e8-897d-5ac57959ef46 container dapi-container: <nil>
STEP: delete the pod
Dec 11 09:45:40.558: INFO: Waiting for pod var-expansion-8403be7b-fd29-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:45:40.560: INFO: Pod var-expansion-8403be7b-fd29-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:45:40.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-24xw7" for this suite.
Dec 11 09:45:46.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:45:46.594: INFO: namespace: e2e-tests-var-expansion-24xw7, resource: bindings, ignored listing per whitelist
Dec 11 09:45:46.660: INFO: namespace e2e-tests-var-expansion-24xw7 deletion completed in 6.09563569s

• [SLOW TEST:8.243 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:45:46.660: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-88edb8bf-fd29-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume secrets
Dec 11 09:45:46.778: INFO: Waiting up to 5m0s for pod "pod-secrets-88ef44dc-fd29-11e8-897d-5ac57959ef46" in namespace "e2e-tests-secrets-4rrp2" to be "success or failure"
Dec 11 09:45:46.780: INFO: Pod "pod-secrets-88ef44dc-fd29-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054559ms
Dec 11 09:45:48.783: INFO: Pod "pod-secrets-88ef44dc-fd29-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005194825s
STEP: Saw pod success
Dec 11 09:45:48.783: INFO: Pod "pod-secrets-88ef44dc-fd29-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:45:48.786: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-secrets-88ef44dc-fd29-11e8-897d-5ac57959ef46 container secret-volume-test: <nil>
STEP: delete the pod
Dec 11 09:45:48.815: INFO: Waiting for pod pod-secrets-88ef44dc-fd29-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:45:48.818: INFO: Pod pod-secrets-88ef44dc-fd29-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:45:48.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4rrp2" for this suite.
Dec 11 09:45:54.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:45:54.913: INFO: namespace: e2e-tests-secrets-4rrp2, resource: bindings, ignored listing per whitelist
Dec 11 09:45:54.917: INFO: namespace e2e-tests-secrets-4rrp2 deletion completed in 6.094347678s

• [SLOW TEST:8.257 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:45:54.917: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 11 09:45:55.040: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec 11 09:45:55.055: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:45:55.055: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:45:55.055: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:45:55.057: INFO: Number of nodes with available pods: 0
Dec 11 09:45:55.057: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:45:56.062: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:45:56.062: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:45:56.062: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:45:56.064: INFO: Number of nodes with available pods: 0
Dec 11 09:45:56.065: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:45:57.062: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:45:57.062: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:45:57.062: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:45:57.064: INFO: Number of nodes with available pods: 2
Dec 11 09:45:57.064: INFO: Node ip-172-25-93-75.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:45:58.061: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:45:58.061: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:45:58.061: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:45:58.064: INFO: Number of nodes with available pods: 3
Dec 11 09:45:58.064: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec 11 09:45:58.089: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:45:58.089: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:45:58.089: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:45:58.094: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:45:58.094: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:45:58.094: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:45:59.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:45:59.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:45:59.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:45:59.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:45:59.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:45:59.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:00.096: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:00.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:00.096: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:00.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:00.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:00.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:01.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:01.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:01.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:01.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:01.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:01.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:02.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:02.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:02.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:02.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:02.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:02.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:03.096: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:03.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:03.096: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:03.100: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:03.100: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:03.100: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:04.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:04.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:04.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:04.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:04.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:04.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:05.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:05.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:05.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:05.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:05.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:05.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:06.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:06.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:06.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:06.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:06.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:06.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:07.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:07.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:07.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:07.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:07.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:07.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:08.096: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:08.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:08.096: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:08.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:08.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:08.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:09.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:09.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:09.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:09.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:09.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:09.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:10.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:10.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:10.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:10.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:10.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:10.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:11.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:11.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:11.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:11.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:11.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:11.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:12.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:12.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:12.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:12.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:12.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:12.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:13.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:13.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:13.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:13.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:13.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:13.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:14.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:14.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:14.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:14.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:14.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:14.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:15.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:15.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:15.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:15.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:15.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:15.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:16.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:16.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:16.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:16.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:16.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:16.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:17.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:17.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:17.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:17.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:17.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:17.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:18.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:18.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:18.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:18.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:18.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:18.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:19.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:19.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:19.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:19.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:19.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:19.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:20.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:20.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:20.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:20.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:20.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:20.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:21.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:21.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:21.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:21.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:21.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:21.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:22.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:22.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:22.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:22.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:22.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:22.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:23.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:23.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:23.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:23.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:23.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:23.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:24.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:24.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:24.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:24.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:24.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:24.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:25.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:25.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:25.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:25.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:25.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:25.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:26.096: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:26.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:26.096: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:26.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:26.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:26.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:27.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:27.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:27.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:27.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:27.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:27.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:28.096: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:28.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:28.096: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:28.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:28.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:28.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:29.096: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:29.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:29.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:29.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:29.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:29.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:30.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:30.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:30.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:30.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:30.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:30.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:31.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:31.097: INFO: Pod daemon-set-8jjf9 is not available
Dec 11 09:46:31.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:31.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:31.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:31.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:31.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:32.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:32.097: INFO: Pod daemon-set-8jjf9 is not available
Dec 11 09:46:32.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:32.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:32.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:32.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:32.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:33.097: INFO: Wrong image for pod: daemon-set-8jjf9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:33.097: INFO: Pod daemon-set-8jjf9 is not available
Dec 11 09:46:33.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:33.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:33.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:33.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:33.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:34.097: INFO: Pod daemon-set-4kn62 is not available
Dec 11 09:46:34.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:34.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:34.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:34.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:34.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:35.097: INFO: Pod daemon-set-4kn62 is not available
Dec 11 09:46:35.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:35.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:35.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:35.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:35.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:36.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:36.096: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:36.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:36.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:36.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:37.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:37.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:37.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:37.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:37.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:38.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:38.096: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:38.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:38.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:38.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:39.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:39.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:39.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:39.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:39.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:40.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:40.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:40.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:40.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:40.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:41.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:41.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:41.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:41.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:41.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:42.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:42.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:42.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:42.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:42.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:43.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:43.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:43.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:43.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:43.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:44.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:44.096: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:44.100: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:44.100: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:44.100: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:45.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:45.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:45.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:45.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:45.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:46.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:46.096: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:46.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:46.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:46.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:47.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:47.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:47.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:47.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:47.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:48.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:48.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:48.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:48.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:48.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:49.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:49.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:49.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:49.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:49.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:50.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:50.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:50.100: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:50.100: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:50.100: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:51.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:51.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:51.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:51.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:51.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:52.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:52.096: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:52.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:52.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:52.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:53.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:53.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:53.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:53.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:53.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:54.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:54.096: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:54.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:54.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:54.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:55.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:55.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:55.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:55.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:55.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:56.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:56.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:56.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:56.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:56.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:57.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:57.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:57.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:57.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:57.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:58.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:58.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:58.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:58.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:58.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:59.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:59.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:46:59.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:59.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:46:59.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:00.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:00.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:00.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:00.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:00.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:01.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:01.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:01.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:01.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:01.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:02.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:02.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:02.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:02.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:02.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:03.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:03.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:03.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:03.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:03.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:04.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:04.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:04.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:04.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:04.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:05.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:05.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:05.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:05.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:05.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:06.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:06.096: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:06.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:06.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:06.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:07.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:07.096: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:07.096: INFO: Pod daemon-set-pfv2z is not available
Dec 11 09:47:07.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:07.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:07.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:08.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:08.096: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:08.096: INFO: Pod daemon-set-pfv2z is not available
Dec 11 09:47:08.100: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:08.100: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:08.100: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:09.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:09.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:09.097: INFO: Pod daemon-set-pfv2z is not available
Dec 11 09:47:09.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:09.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:09.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:10.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:10.096: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:10.096: INFO: Pod daemon-set-pfv2z is not available
Dec 11 09:47:10.100: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:10.100: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:10.100: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:11.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:11.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:11.097: INFO: Pod daemon-set-pfv2z is not available
Dec 11 09:47:11.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:11.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:11.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:12.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:12.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:12.097: INFO: Pod daemon-set-pfv2z is not available
Dec 11 09:47:12.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:12.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:12.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:13.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:13.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:13.097: INFO: Pod daemon-set-pfv2z is not available
Dec 11 09:47:13.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:13.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:13.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:14.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:14.097: INFO: Wrong image for pod: daemon-set-pfv2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:14.097: INFO: Pod daemon-set-pfv2z is not available
Dec 11 09:47:14.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:14.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:14.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:15.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:15.096: INFO: Pod daemon-set-tq75t is not available
Dec 11 09:47:15.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:15.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:15.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:16.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:16.097: INFO: Pod daemon-set-tq75t is not available
Dec 11 09:47:16.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:16.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:16.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:17.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:17.097: INFO: Pod daemon-set-tq75t is not available
Dec 11 09:47:17.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:17.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:17.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:18.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:18.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:18.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:18.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:19.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:19.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:19.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:19.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:20.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:20.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:20.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:20.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:21.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:21.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:21.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:21.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:22.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:22.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:22.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:22.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:23.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:23.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:23.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:23.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:24.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:24.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:24.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:24.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:25.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:25.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:25.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:25.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:26.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:26.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:26.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:26.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:27.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:27.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:27.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:27.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:28.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:28.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:28.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:28.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:29.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:29.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:29.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:29.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:30.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:30.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:30.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:30.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:31.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:31.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:31.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:31.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:32.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:32.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:32.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:32.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:33.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:33.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:33.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:33.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:34.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:34.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:34.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:34.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:35.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:35.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:35.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:35.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:36.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:36.100: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:36.100: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:36.100: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:37.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:37.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:37.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:37.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:38.098: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:38.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:38.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:38.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:39.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:39.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:39.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:39.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:40.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:40.102: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:40.102: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:40.102: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:41.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:41.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:41.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:41.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:42.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:42.100: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:42.100: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:42.100: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:43.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:43.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:43.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:43.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:44.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:44.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:44.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:44.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:45.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:45.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:45.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:45.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:46.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:46.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:46.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:46.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:47.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:47.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:47.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:47.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:48.097: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:48.101: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:48.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:48.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:49.096: INFO: Wrong image for pod: daemon-set-gtvxg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 11 09:47:49.096: INFO: Pod daemon-set-gtvxg is not available
Dec 11 09:47:49.100: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:49.101: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:49.101: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:50.096: INFO: Pod daemon-set-swn96 is not available
Dec 11 09:47:50.100: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:50.100: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:50.100: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Dec 11 09:47:50.105: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:50.105: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:50.105: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:50.107: INFO: Number of nodes with available pods: 2
Dec 11 09:47:50.107: INFO: Node ip-172-25-62-1.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:47:51.111: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:51.111: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:51.111: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:47:51.114: INFO: Number of nodes with available pods: 3
Dec 11 09:47:51.114: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-v29c6, will wait for the garbage collector to delete the pods
Dec 11 09:47:51.188: INFO: Deleting DaemonSet.extensions daemon-set took: 11.236095ms
Dec 11 09:47:51.288: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.211188ms
Dec 11 09:48:04.091: INFO: Number of nodes with available pods: 0
Dec 11 09:48:04.091: INFO: Number of running nodes: 0, number of available pods: 0
Dec 11 09:48:04.093: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-v29c6/daemonsets","resourceVersion":"21959228"},"items":null}

Dec 11 09:48:04.095: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-v29c6/pods","resourceVersion":"21959228"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:48:04.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-v29c6" for this suite.
Dec 11 09:48:10.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:48:10.147: INFO: namespace: e2e-tests-daemonsets-v29c6, resource: bindings, ignored listing per whitelist
Dec 11 09:48:10.199: INFO: namespace e2e-tests-daemonsets-v29c6 deletion completed in 6.088336142s

• [SLOW TEST:135.282 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:48:10.199: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Dec 11 09:48:10.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 create -f - --namespace=e2e-tests-kubectl-ghlcq'
Dec 11 09:48:10.538: INFO: stderr: ""
Dec 11 09:48:10.538: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 11 09:48:10.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ghlcq'
Dec 11 09:48:10.600: INFO: stderr: ""
Dec 11 09:48:10.600: INFO: stdout: "update-demo-nautilus-hdvft update-demo-nautilus-l4zs8 "
Dec 11 09:48:10.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-nautilus-hdvft -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ghlcq'
Dec 11 09:48:10.658: INFO: stderr: ""
Dec 11 09:48:10.658: INFO: stdout: ""
Dec 11 09:48:10.658: INFO: update-demo-nautilus-hdvft is created but not running
Dec 11 09:48:15.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ghlcq'
Dec 11 09:48:15.718: INFO: stderr: ""
Dec 11 09:48:15.718: INFO: stdout: "update-demo-nautilus-hdvft update-demo-nautilus-l4zs8 "
Dec 11 09:48:15.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-nautilus-hdvft -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ghlcq'
Dec 11 09:48:15.774: INFO: stderr: ""
Dec 11 09:48:15.774: INFO: stdout: "true"
Dec 11 09:48:15.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-nautilus-hdvft -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ghlcq'
Dec 11 09:48:15.829: INFO: stderr: ""
Dec 11 09:48:15.829: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 11 09:48:15.829: INFO: validating pod update-demo-nautilus-hdvft
Dec 11 09:48:15.833: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 11 09:48:15.833: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 11 09:48:15.833: INFO: update-demo-nautilus-hdvft is verified up and running
Dec 11 09:48:15.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-nautilus-l4zs8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ghlcq'
Dec 11 09:48:15.890: INFO: stderr: ""
Dec 11 09:48:15.890: INFO: stdout: "true"
Dec 11 09:48:15.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-nautilus-l4zs8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ghlcq'
Dec 11 09:48:15.946: INFO: stderr: ""
Dec 11 09:48:15.946: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 11 09:48:15.946: INFO: validating pod update-demo-nautilus-l4zs8
Dec 11 09:48:15.952: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 11 09:48:15.952: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 11 09:48:15.952: INFO: update-demo-nautilus-l4zs8 is verified up and running
STEP: rolling-update to new replication controller
Dec 11 09:48:15.952: INFO: scanned /root for discovery docs: <nil>
Dec 11 09:48:15.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-ghlcq'
Dec 11 09:48:38.275: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 11 09:48:38.275: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 11 09:48:38.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ghlcq'
Dec 11 09:48:38.334: INFO: stderr: ""
Dec 11 09:48:38.334: INFO: stdout: "update-demo-kitten-cfj4d update-demo-kitten-lts9k "
Dec 11 09:48:38.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-kitten-cfj4d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ghlcq'
Dec 11 09:48:38.390: INFO: stderr: ""
Dec 11 09:48:38.390: INFO: stdout: "true"
Dec 11 09:48:38.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-kitten-cfj4d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ghlcq'
Dec 11 09:48:38.446: INFO: stderr: ""
Dec 11 09:48:38.446: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 11 09:48:38.446: INFO: validating pod update-demo-kitten-cfj4d
Dec 11 09:48:38.452: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 11 09:48:38.452: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 11 09:48:38.452: INFO: update-demo-kitten-cfj4d is verified up and running
Dec 11 09:48:38.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-kitten-lts9k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ghlcq'
Dec 11 09:48:38.509: INFO: stderr: ""
Dec 11 09:48:38.509: INFO: stdout: "true"
Dec 11 09:48:38.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-kitten-lts9k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ghlcq'
Dec 11 09:48:38.566: INFO: stderr: ""
Dec 11 09:48:38.566: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 11 09:48:38.566: INFO: validating pod update-demo-kitten-lts9k
Dec 11 09:48:38.570: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 11 09:48:38.570: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 11 09:48:38.570: INFO: update-demo-kitten-lts9k is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:48:38.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ghlcq" for this suite.
Dec 11 09:49:00.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:49:00.671: INFO: namespace: e2e-tests-kubectl-ghlcq, resource: bindings, ignored listing per whitelist
Dec 11 09:49:00.671: INFO: namespace e2e-tests-kubectl-ghlcq deletion completed in 22.097203129s

• [SLOW TEST:50.472 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:49:00.671: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 11 09:49:00.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-w78vj'
Dec 11 09:49:00.840: INFO: stderr: ""
Dec 11 09:49:00.840: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Dec 11 09:49:05.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-w78vj -o json'
Dec 11 09:49:05.949: INFO: stderr: ""
Dec 11 09:49:05.949: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2018-12-11T09:49:00Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-w78vj\",\n        \"resourceVersion\": \"21959457\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-w78vj/pods/e2e-test-nginx-pod\",\n        \"uid\": \"fc9a2231-fd29-11e8-8e03-0681e6464a68\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-xczdg\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"ip-172-25-45-107.us-west-1.compute.internal\",\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-xczdg\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-xczdg\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-11T09:49:00Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-11T09:49:02Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-11T09:49:00Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://a00de961234ef7c2e622795068d00647d2ef40806a6370d24f503483e0cb638a\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2018-12-11T09:49:01Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.25.45.107\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.111.240.250\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2018-12-11T09:49:00Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec 11 09:49:05.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 replace -f - --namespace=e2e-tests-kubectl-w78vj'
Dec 11 09:49:06.070: INFO: stderr: ""
Dec 11 09:49:06.070: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Dec 11 09:49:06.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-w78vj'
Dec 11 09:49:08.628: INFO: stderr: ""
Dec 11 09:49:08.628: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:49:08.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-w78vj" for this suite.
Dec 11 09:49:14.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:49:14.660: INFO: namespace: e2e-tests-kubectl-w78vj, resource: bindings, ignored listing per whitelist
Dec 11 09:49:14.726: INFO: namespace e2e-tests-kubectl-w78vj deletion completed in 6.093118447s

• [SLOW TEST:14.055 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:49:14.726: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-fz2fk
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-fz2fk
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-fz2fk
Dec 11 09:49:14.853: INFO: Found 0 stateful pods, waiting for 1
Dec 11 09:49:24.855: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec 11 09:49:24.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 exec --namespace=e2e-tests-statefulset-fz2fk ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 11 09:49:24.987: INFO: stderr: ""
Dec 11 09:49:24.987: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 11 09:49:24.987: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 11 09:49:24.989: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 11 09:49:34.992: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 11 09:49:34.992: INFO: Waiting for statefulset status.replicas updated to 0
Dec 11 09:49:35.010: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Dec 11 09:49:35.010: INFO: ss-0  ip-172-25-62-1.us-west-1.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:14 +0000 UTC  }]
Dec 11 09:49:35.010: INFO: 
Dec 11 09:49:35.010: INFO: StatefulSet ss has not reached scale 3, at 1
Dec 11 09:49:36.012: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997597429s
Dec 11 09:49:37.015: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.994956648s
Dec 11 09:49:38.019: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.99202365s
Dec 11 09:49:39.021: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.988825436s
Dec 11 09:49:40.024: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.985962562s
Dec 11 09:49:41.027: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.982911881s
Dec 11 09:49:42.030: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.980090841s
Dec 11 09:49:43.033: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.977079049s
Dec 11 09:49:44.038: INFO: Verifying statefulset ss doesn't scale past 3 for another 973.965224ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-fz2fk
Dec 11 09:49:45.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 exec --namespace=e2e-tests-statefulset-fz2fk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 11 09:49:45.171: INFO: stderr: ""
Dec 11 09:49:45.171: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 11 09:49:45.171: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 11 09:49:45.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 exec --namespace=e2e-tests-statefulset-fz2fk ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 11 09:49:45.318: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec 11 09:49:45.318: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 11 09:49:45.318: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 11 09:49:45.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 exec --namespace=e2e-tests-statefulset-fz2fk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 11 09:49:45.451: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec 11 09:49:45.451: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 11 09:49:45.451: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 11 09:49:45.453: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 11 09:49:45.453: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 11 09:49:45.453: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec 11 09:49:45.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 exec --namespace=e2e-tests-statefulset-fz2fk ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 11 09:49:45.585: INFO: stderr: ""
Dec 11 09:49:45.585: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 11 09:49:45.585: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 11 09:49:45.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 exec --namespace=e2e-tests-statefulset-fz2fk ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 11 09:49:45.733: INFO: stderr: ""
Dec 11 09:49:45.733: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 11 09:49:45.733: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 11 09:49:45.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 exec --namespace=e2e-tests-statefulset-fz2fk ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 11 09:49:45.867: INFO: stderr: ""
Dec 11 09:49:45.867: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 11 09:49:45.867: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 11 09:49:45.867: INFO: Waiting for statefulset status.replicas updated to 0
Dec 11 09:49:45.870: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec 11 09:49:55.877: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 11 09:49:55.877: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 11 09:49:55.877: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 11 09:49:55.894: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Dec 11 09:49:55.894: INFO: ss-0  ip-172-25-62-1.us-west-1.compute.internal    Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:14 +0000 UTC  }]
Dec 11 09:49:55.894: INFO: ss-1  ip-172-25-93-75.us-west-1.compute.internal   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  }]
Dec 11 09:49:55.894: INFO: ss-2  ip-172-25-45-107.us-west-1.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  }]
Dec 11 09:49:55.894: INFO: 
Dec 11 09:49:55.894: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 11 09:49:56.897: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Dec 11 09:49:56.897: INFO: ss-0  ip-172-25-62-1.us-west-1.compute.internal    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:14 +0000 UTC  }]
Dec 11 09:49:56.897: INFO: ss-1  ip-172-25-93-75.us-west-1.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  }]
Dec 11 09:49:56.897: INFO: ss-2  ip-172-25-45-107.us-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  }]
Dec 11 09:49:56.897: INFO: 
Dec 11 09:49:56.897: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 11 09:49:57.900: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Dec 11 09:49:57.900: INFO: ss-0  ip-172-25-62-1.us-west-1.compute.internal    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:14 +0000 UTC  }]
Dec 11 09:49:57.900: INFO: ss-1  ip-172-25-93-75.us-west-1.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  }]
Dec 11 09:49:57.900: INFO: ss-2  ip-172-25-45-107.us-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  }]
Dec 11 09:49:57.900: INFO: 
Dec 11 09:49:57.900: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 11 09:49:58.903: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Dec 11 09:49:58.903: INFO: ss-0  ip-172-25-62-1.us-west-1.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:14 +0000 UTC  }]
Dec 11 09:49:58.903: INFO: ss-1  ip-172-25-93-75.us-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  }]
Dec 11 09:49:58.903: INFO: 
Dec 11 09:49:58.903: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 11 09:49:59.906: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Dec 11 09:49:59.906: INFO: ss-0  ip-172-25-62-1.us-west-1.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:14 +0000 UTC  }]
Dec 11 09:49:59.906: INFO: ss-1  ip-172-25-93-75.us-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  }]
Dec 11 09:49:59.906: INFO: 
Dec 11 09:49:59.906: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 11 09:50:00.909: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Dec 11 09:50:00.909: INFO: ss-0  ip-172-25-62-1.us-west-1.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:14 +0000 UTC  }]
Dec 11 09:50:00.909: INFO: ss-1  ip-172-25-93-75.us-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  }]
Dec 11 09:50:00.909: INFO: 
Dec 11 09:50:00.909: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 11 09:50:01.912: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Dec 11 09:50:01.912: INFO: ss-0  ip-172-25-62-1.us-west-1.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:14 +0000 UTC  }]
Dec 11 09:50:01.912: INFO: ss-1  ip-172-25-93-75.us-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  }]
Dec 11 09:50:01.912: INFO: 
Dec 11 09:50:01.912: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 11 09:50:02.915: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Dec 11 09:50:02.915: INFO: ss-0  ip-172-25-62-1.us-west-1.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:14 +0000 UTC  }]
Dec 11 09:50:02.915: INFO: ss-1  ip-172-25-93-75.us-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  }]
Dec 11 09:50:02.915: INFO: 
Dec 11 09:50:02.915: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 11 09:50:03.918: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Dec 11 09:50:03.918: INFO: ss-1  ip-172-25-93-75.us-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  }]
Dec 11 09:50:03.918: INFO: 
Dec 11 09:50:03.918: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 11 09:50:04.921: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Dec 11 09:50:04.921: INFO: ss-1  ip-172-25-93-75.us-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:49:35 +0000 UTC  }]
Dec 11 09:50:04.921: INFO: 
Dec 11 09:50:04.921: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-fz2fk
Dec 11 09:50:05.927: INFO: Scaling statefulset ss to 0
Dec 11 09:50:05.934: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 11 09:50:05.936: INFO: Deleting all statefulset in ns e2e-tests-statefulset-fz2fk
Dec 11 09:50:05.939: INFO: Scaling statefulset ss to 0
Dec 11 09:50:05.946: INFO: Waiting for statefulset status.replicas updated to 0
Dec 11 09:50:05.948: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:50:05.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-fz2fk" for this suite.
Dec 11 09:50:11.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:50:12.018: INFO: namespace: e2e-tests-statefulset-fz2fk, resource: bindings, ignored listing per whitelist
Dec 11 09:50:12.064: INFO: namespace e2e-tests-statefulset-fz2fk deletion completed in 6.096821277s

• [SLOW TEST:57.338 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:50:12.065: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 11 09:50:12.180: INFO: Waiting up to 5m0s for pod "downwardapi-volume-272065cf-fd2a-11e8-897d-5ac57959ef46" in namespace "e2e-tests-projected-sc82s" to be "success or failure"
Dec 11 09:50:12.182: INFO: Pod "downwardapi-volume-272065cf-fd2a-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048263ms
Dec 11 09:50:14.185: INFO: Pod "downwardapi-volume-272065cf-fd2a-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00503122s
STEP: Saw pod success
Dec 11 09:50:14.185: INFO: Pod "downwardapi-volume-272065cf-fd2a-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:50:14.188: INFO: Trying to get logs from node ip-172-25-45-107.us-west-1.compute.internal pod downwardapi-volume-272065cf-fd2a-11e8-897d-5ac57959ef46 container client-container: <nil>
STEP: delete the pod
Dec 11 09:50:14.216: INFO: Waiting for pod downwardapi-volume-272065cf-fd2a-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:50:14.218: INFO: Pod downwardapi-volume-272065cf-fd2a-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:50:14.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sc82s" for this suite.
Dec 11 09:50:20.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:50:20.308: INFO: namespace: e2e-tests-projected-sc82s, resource: bindings, ignored listing per whitelist
Dec 11 09:50:20.314: INFO: namespace e2e-tests-projected-sc82s deletion completed in 6.091275495s

• [SLOW TEST:8.249 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:50:20.314: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 11 09:50:20.423: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec 11 09:50:25.426: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 11 09:50:25.426: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec 11 09:50:27.429: INFO: Creating deployment "test-rollover-deployment"
Dec 11 09:50:27.442: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec 11 09:50:31.447: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec 11 09:50:31.451: INFO: Ensure that both replica sets have 1 created replica
Dec 11 09:50:31.456: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec 11 09:50:31.470: INFO: Updating deployment test-rollover-deployment
Dec 11 09:50:31.470: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec 11 09:50:33.475: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec 11 09:50:33.496: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec 11 09:50:33.506: INFO: 
Dec 11 09:50:33.506: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680118630, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680118630, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680118632, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680118630, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d79ff688f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 11 09:50:35.512: INFO: 
Dec 11 09:50:35.512: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680118630, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680118630, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680118632, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680118630, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d79ff688f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 11 09:50:37.511: INFO: 
Dec 11 09:50:37.511: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680118630, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680118630, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680118632, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680118630, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d79ff688f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 11 09:50:39.512: INFO: 
Dec 11 09:50:39.512: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680118630, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680118630, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680118632, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680118630, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d79ff688f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 11 09:50:41.511: INFO: 
Dec 11 09:50:41.511: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680118630, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680118630, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680118632, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680118630, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d79ff688f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 11 09:50:43.511: INFO: 
Dec 11 09:50:43.511: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 11 09:50:43.517: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-dkxxq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-dkxxq/deployments/test-rollover-deployment,UID:303905b6-fd2a-11e8-8e03-0681e6464a68,ResourceVersion:21959842,Generation:2,CreationTimestamp:2018-12-11 09:50:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-11 09:50:30 +0000 UTC 2018-12-11 09:50:30 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-11 09:50:42 +0000 UTC 2018-12-11 09:50:30 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5d79ff688f" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec 11 09:50:43.520: INFO: New ReplicaSet "test-rollover-deployment-5d79ff688f" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5d79ff688f,GenerateName:,Namespace:e2e-tests-deployment-dkxxq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-dkxxq/replicasets/test-rollover-deployment-5d79ff688f,UID:32a179e1-fd2a-11e8-8e03-0681e6464a68,ResourceVersion:21959835,Generation:2,CreationTimestamp:2018-12-11 09:50:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 1835992449,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{extensions/v1beta1 Deployment test-rollover-deployment 303905b6-fd2a-11e8-8e03-0681e6464a68 0xc001f9360a 0xc001f9360b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 1835992449,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 1835992449,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec 11 09:50:43.520: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec 11 09:50:43.520: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-dkxxq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-dkxxq/replicasets/test-rollover-controller,UID:2c0a1b7a-fd2a-11e8-8e03-0681e6464a68,ResourceVersion:21959841,Generation:4,CreationTimestamp:2018-12-11 09:50:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,pod-template-hash: 2418519119,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{extensions/v1beta1 Deployment test-rollover-deployment 303905b6-fd2a-11e8-8e03-0681e6464a68 0xc001f9354a 0xc001f9354b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,pod-template-hash: 2418519119,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,pod-template-hash: 2418519119,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 11 09:50:43.520: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-84489556b,GenerateName:,Namespace:e2e-tests-deployment-dkxxq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-dkxxq/replicasets/test-rollover-deployment-84489556b,UID:320b5a5d-fd2a-11e8-8e03-0681e6464a68,ResourceVersion:21959806,Generation:2,CreationTimestamp:2018-12-11 09:50:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 400451126,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{extensions/v1beta1 Deployment test-rollover-deployment 303905b6-fd2a-11e8-8e03-0681e6464a68 0xc001f936b9 0xc001f936ba}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 400451126,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 400451126,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 11 09:50:43.523: INFO: Pod "test-rollover-deployment-5d79ff688f-wz25t" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5d79ff688f-wz25t,GenerateName:test-rollover-deployment-5d79ff688f-,Namespace:e2e-tests-deployment-dkxxq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-dkxxq/pods/test-rollover-deployment-5d79ff688f-wz25t,UID:32a86926-fd2a-11e8-8e03-0681e6464a68,ResourceVersion:21959816,Generation:0,CreationTimestamp:2018-12-11 09:50:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 1835992449,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet test-rollover-deployment-5d79ff688f 32a179e1-fd2a-11e8-8e03-0681e6464a68 0xc001edc27a 0xc001edc27b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tcbzd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tcbzd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-tcbzd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-62-1.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001edc2f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001edc310}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:50:31 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:50:32 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:50:31 +0000 UTC  }],Message:,Reason:,HostIP:172.25.62.1,PodIP:100.111.88.29,StartTime:2018-12-11 09:50:31 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-11 09:50:32 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://04a56d4550e2c7619407e37b4c480304b13bc46677cb5713f699e0c6f211445a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:50:43.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-dkxxq" for this suite.
Dec 11 09:50:49.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:50:49.600: INFO: namespace: e2e-tests-deployment-dkxxq, resource: bindings, ignored listing per whitelist
Dec 11 09:50:49.613: INFO: namespace e2e-tests-deployment-dkxxq deletion completed in 6.085961348s

• [SLOW TEST:29.299 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:50:49.613: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 11 09:50:49.747: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:49.747: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:49.747: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:49.748: INFO: Number of nodes with available pods: 0
Dec 11 09:50:49.748: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:50:50.753: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:50.753: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:50.753: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:50.755: INFO: Number of nodes with available pods: 1
Dec 11 09:50:50.755: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:50:51.753: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:51.753: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:51.753: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:51.756: INFO: Number of nodes with available pods: 3
Dec 11 09:50:51.756: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec 11 09:50:51.777: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:51.777: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:51.777: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:51.779: INFO: Number of nodes with available pods: 2
Dec 11 09:50:51.779: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:50:52.784: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:52.784: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:52.784: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:52.786: INFO: Number of nodes with available pods: 2
Dec 11 09:50:52.787: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:50:53.784: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:53.784: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:53.784: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:53.787: INFO: Number of nodes with available pods: 2
Dec 11 09:50:53.787: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:50:54.783: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:54.783: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:54.783: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:54.785: INFO: Number of nodes with available pods: 2
Dec 11 09:50:54.785: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:50:55.784: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:55.784: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:55.784: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:55.788: INFO: Number of nodes with available pods: 2
Dec 11 09:50:55.788: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:50:56.784: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:56.784: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:56.784: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:56.786: INFO: Number of nodes with available pods: 2
Dec 11 09:50:56.787: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:50:57.784: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:57.784: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:57.784: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:57.787: INFO: Number of nodes with available pods: 2
Dec 11 09:50:57.787: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:50:58.784: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:58.784: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:58.784: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:58.786: INFO: Number of nodes with available pods: 2
Dec 11 09:50:58.786: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:50:59.784: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:59.784: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:59.784: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:50:59.786: INFO: Number of nodes with available pods: 2
Dec 11 09:50:59.786: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:00.784: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:00.784: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:00.784: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:00.786: INFO: Number of nodes with available pods: 2
Dec 11 09:51:00.786: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:01.784: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:01.784: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:01.784: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:01.786: INFO: Number of nodes with available pods: 2
Dec 11 09:51:01.786: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:02.783: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:02.783: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:02.783: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:02.785: INFO: Number of nodes with available pods: 2
Dec 11 09:51:02.785: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:03.783: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:03.783: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:03.783: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:03.785: INFO: Number of nodes with available pods: 2
Dec 11 09:51:03.785: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:04.784: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:04.784: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:04.784: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:04.786: INFO: Number of nodes with available pods: 2
Dec 11 09:51:04.786: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:05.784: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:05.784: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:05.784: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:05.786: INFO: Number of nodes with available pods: 2
Dec 11 09:51:05.786: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:06.783: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:06.783: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:06.783: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:06.785: INFO: Number of nodes with available pods: 2
Dec 11 09:51:06.785: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:07.784: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:07.784: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:07.784: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:07.786: INFO: Number of nodes with available pods: 2
Dec 11 09:51:07.786: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:08.783: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:08.783: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:08.783: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:08.785: INFO: Number of nodes with available pods: 2
Dec 11 09:51:08.785: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:09.783: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:09.783: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:09.783: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:09.786: INFO: Number of nodes with available pods: 2
Dec 11 09:51:09.786: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:10.784: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:10.784: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:10.784: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:10.786: INFO: Number of nodes with available pods: 2
Dec 11 09:51:10.786: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:11.783: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:11.783: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:11.783: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:11.786: INFO: Number of nodes with available pods: 2
Dec 11 09:51:11.786: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:12.784: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:12.784: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:12.784: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:12.787: INFO: Number of nodes with available pods: 2
Dec 11 09:51:12.787: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:13.784: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:13.784: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:13.784: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:13.786: INFO: Number of nodes with available pods: 2
Dec 11 09:51:13.786: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:14.784: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:14.784: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:14.784: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:14.787: INFO: Number of nodes with available pods: 2
Dec 11 09:51:14.787: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:15.784: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:15.784: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:15.784: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:15.787: INFO: Number of nodes with available pods: 2
Dec 11 09:51:15.787: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:16.784: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:16.784: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:16.784: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:16.786: INFO: Number of nodes with available pods: 2
Dec 11 09:51:16.786: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:17.784: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:17.784: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:17.784: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:17.787: INFO: Number of nodes with available pods: 2
Dec 11 09:51:17.787: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:18.784: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:18.784: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:18.784: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:18.786: INFO: Number of nodes with available pods: 2
Dec 11 09:51:18.786: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:19.784: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:19.784: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:19.784: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:19.786: INFO: Number of nodes with available pods: 2
Dec 11 09:51:19.786: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:20.783: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:20.783: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:20.783: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:20.786: INFO: Number of nodes with available pods: 2
Dec 11 09:51:20.786: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:21.783: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:21.783: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:21.783: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:21.786: INFO: Number of nodes with available pods: 2
Dec 11 09:51:21.786: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:22.783: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:22.783: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:22.783: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:22.786: INFO: Number of nodes with available pods: 2
Dec 11 09:51:22.786: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:23.783: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:23.783: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:23.783: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:23.785: INFO: Number of nodes with available pods: 2
Dec 11 09:51:23.785: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:24.783: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:24.783: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:24.783: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:24.785: INFO: Number of nodes with available pods: 2
Dec 11 09:51:24.785: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:25.783: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:25.783: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:25.783: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:25.785: INFO: Number of nodes with available pods: 2
Dec 11 09:51:25.785: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:26.783: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:26.783: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:26.783: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:26.786: INFO: Number of nodes with available pods: 2
Dec 11 09:51:26.786: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:27.783: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:27.783: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:27.783: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:27.785: INFO: Number of nodes with available pods: 2
Dec 11 09:51:27.785: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:28.783: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:28.783: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:28.783: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:28.785: INFO: Number of nodes with available pods: 2
Dec 11 09:51:28.785: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:29.784: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:29.784: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:29.784: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:29.786: INFO: Number of nodes with available pods: 2
Dec 11 09:51:29.786: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:30.783: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:30.783: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:30.783: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:30.786: INFO: Number of nodes with available pods: 2
Dec 11 09:51:30.786: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:31.784: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:31.784: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:31.784: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:31.786: INFO: Number of nodes with available pods: 2
Dec 11 09:51:31.786: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:32.783: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:32.783: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:32.783: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:32.786: INFO: Number of nodes with available pods: 2
Dec 11 09:51:32.786: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:33.784: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:33.784: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:33.784: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:33.786: INFO: Number of nodes with available pods: 2
Dec 11 09:51:33.786: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:34.783: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:34.783: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:34.783: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:34.785: INFO: Number of nodes with available pods: 2
Dec 11 09:51:34.785: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 09:51:35.783: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:35.783: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:35.783: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 09:51:35.785: INFO: Number of nodes with available pods: 3
Dec 11 09:51:35.785: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-skg7g, will wait for the garbage collector to delete the pods
Dec 11 09:51:35.850: INFO: Deleting DaemonSet.extensions daemon-set took: 10.986305ms
Dec 11 09:51:35.950: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.230976ms
Dec 11 09:52:14.153: INFO: Number of nodes with available pods: 0
Dec 11 09:52:14.153: INFO: Number of running nodes: 0, number of available pods: 0
Dec 11 09:52:14.155: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-skg7g/daemonsets","resourceVersion":"21960095"},"items":null}

Dec 11 09:52:14.157: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-skg7g/pods","resourceVersion":"21960095"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:52:14.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-skg7g" for this suite.
Dec 11 09:52:20.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:52:20.258: INFO: namespace: e2e-tests-daemonsets-skg7g, resource: bindings, ignored listing per whitelist
Dec 11 09:52:20.266: INFO: namespace e2e-tests-daemonsets-skg7g deletion completed in 6.090709628s

• [SLOW TEST:90.653 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:52:20.266: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 11 09:52:20.377: INFO: Waiting up to 5m0s for pod "pod-7389baab-fd2a-11e8-897d-5ac57959ef46" in namespace "e2e-tests-emptydir-dg482" to be "success or failure"
Dec 11 09:52:20.379: INFO: Pod "pod-7389baab-fd2a-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041775ms
Dec 11 09:52:22.382: INFO: Pod "pod-7389baab-fd2a-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004732022s
Dec 11 09:52:24.384: INFO: Pod "pod-7389baab-fd2a-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00745867s
STEP: Saw pod success
Dec 11 09:52:24.384: INFO: Pod "pod-7389baab-fd2a-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:52:24.386: INFO: Trying to get logs from node ip-172-25-45-107.us-west-1.compute.internal pod pod-7389baab-fd2a-11e8-897d-5ac57959ef46 container test-container: <nil>
STEP: delete the pod
Dec 11 09:52:24.415: INFO: Waiting for pod pod-7389baab-fd2a-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:52:24.417: INFO: Pod pod-7389baab-fd2a-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:52:24.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dg482" for this suite.
Dec 11 09:52:30.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:52:30.479: INFO: namespace: e2e-tests-emptydir-dg482, resource: bindings, ignored listing per whitelist
Dec 11 09:52:30.519: INFO: namespace e2e-tests-emptydir-dg482 deletion completed in 6.09760084s

• [SLOW TEST:10.253 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:52:30.519: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 11 09:52:30.630: INFO: Waiting up to 5m0s for pod "downwardapi-volume-79a63131-fd2a-11e8-897d-5ac57959ef46" in namespace "e2e-tests-projected-7r8qq" to be "success or failure"
Dec 11 09:52:30.632: INFO: Pod "downwardapi-volume-79a63131-fd2a-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009299ms
Dec 11 09:52:32.635: INFO: Pod "downwardapi-volume-79a63131-fd2a-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004852464s
STEP: Saw pod success
Dec 11 09:52:32.635: INFO: Pod "downwardapi-volume-79a63131-fd2a-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:52:32.637: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod downwardapi-volume-79a63131-fd2a-11e8-897d-5ac57959ef46 container client-container: <nil>
STEP: delete the pod
Dec 11 09:52:32.664: INFO: Waiting for pod downwardapi-volume-79a63131-fd2a-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:52:32.666: INFO: Pod downwardapi-volume-79a63131-fd2a-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:52:32.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7r8qq" for this suite.
Dec 11 09:52:38.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:52:38.751: INFO: namespace: e2e-tests-projected-7r8qq, resource: bindings, ignored listing per whitelist
Dec 11 09:52:38.766: INFO: namespace e2e-tests-projected-7r8qq deletion completed in 6.095456798s

• [SLOW TEST:8.247 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:52:38.766: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 11 09:52:38.880: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7e90f3cd-fd2a-11e8-897d-5ac57959ef46" in namespace "e2e-tests-projected-nj7lh" to be "success or failure"
Dec 11 09:52:38.883: INFO: Pod "downwardapi-volume-7e90f3cd-fd2a-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.226162ms
Dec 11 09:52:40.886: INFO: Pod "downwardapi-volume-7e90f3cd-fd2a-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005293876s
STEP: Saw pod success
Dec 11 09:52:40.886: INFO: Pod "downwardapi-volume-7e90f3cd-fd2a-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:52:40.888: INFO: Trying to get logs from node ip-172-25-45-107.us-west-1.compute.internal pod downwardapi-volume-7e90f3cd-fd2a-11e8-897d-5ac57959ef46 container client-container: <nil>
STEP: delete the pod
Dec 11 09:52:40.917: INFO: Waiting for pod downwardapi-volume-7e90f3cd-fd2a-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:52:40.919: INFO: Pod downwardapi-volume-7e90f3cd-fd2a-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:52:40.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nj7lh" for this suite.
Dec 11 09:52:46.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:52:46.952: INFO: namespace: e2e-tests-projected-nj7lh, resource: bindings, ignored listing per whitelist
Dec 11 09:52:47.014: INFO: namespace e2e-tests-projected-nj7lh deletion completed in 6.090060802s

• [SLOW TEST:8.248 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:52:47.014: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-837b37e0-fd2a-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume configMaps
Dec 11 09:52:47.136: INFO: Waiting up to 5m0s for pod "pod-configmaps-837cc9db-fd2a-11e8-897d-5ac57959ef46" in namespace "e2e-tests-configmap-zmr6s" to be "success or failure"
Dec 11 09:52:47.138: INFO: Pod "pod-configmaps-837cc9db-fd2a-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.161589ms
Dec 11 09:52:49.141: INFO: Pod "pod-configmaps-837cc9db-fd2a-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005228385s
STEP: Saw pod success
Dec 11 09:52:49.142: INFO: Pod "pod-configmaps-837cc9db-fd2a-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:52:49.144: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-configmaps-837cc9db-fd2a-11e8-897d-5ac57959ef46 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 09:52:49.176: INFO: Waiting for pod pod-configmaps-837cc9db-fd2a-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:52:49.178: INFO: Pod pod-configmaps-837cc9db-fd2a-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:52:49.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zmr6s" for this suite.
Dec 11 09:52:55.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:52:55.265: INFO: namespace: e2e-tests-configmap-zmr6s, resource: bindings, ignored listing per whitelist
Dec 11 09:52:55.274: INFO: namespace e2e-tests-configmap-zmr6s deletion completed in 6.091705012s

• [SLOW TEST:8.260 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:52:55.274: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:52:57.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-858k5" for this suite.
Dec 11 09:53:51.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:53:51.469: INFO: namespace: e2e-tests-kubelet-test-858k5, resource: bindings, ignored listing per whitelist
Dec 11 09:53:51.495: INFO: namespace e2e-tests-kubelet-test-858k5 deletion completed in 54.09469988s

• [SLOW TEST:56.221 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:53:51.495: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-tzhkf
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-tzhkf
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-tzhkf
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-tzhkf
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-tzhkf
Dec 11 09:53:57.642: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-tzhkf, name: ss-0, uid: ad489f3c-fd2a-11e8-8e03-0681e6464a68, status phase: Pending. Waiting for statefulset controller to delete.
Dec 11 09:53:57.826: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-tzhkf, name: ss-0, uid: ad489f3c-fd2a-11e8-8e03-0681e6464a68, status phase: Failed. Waiting for statefulset controller to delete.
Dec 11 09:53:57.838: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-tzhkf, name: ss-0, uid: ad489f3c-fd2a-11e8-8e03-0681e6464a68, status phase: Failed. Waiting for statefulset controller to delete.
Dec 11 09:53:57.848: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-tzhkf
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-tzhkf
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-tzhkf and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 11 09:54:01.878: INFO: Deleting all statefulset in ns e2e-tests-statefulset-tzhkf
Dec 11 09:54:01.880: INFO: Scaling statefulset ss to 0
Dec 11 09:54:11.899: INFO: Waiting for statefulset status.replicas updated to 0
Dec 11 09:54:11.901: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:54:11.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-tzhkf" for this suite.
Dec 11 09:54:17.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:54:17.961: INFO: namespace: e2e-tests-statefulset-tzhkf, resource: bindings, ignored listing per whitelist
Dec 11 09:54:18.013: INFO: namespace e2e-tests-statefulset-tzhkf deletion completed in 6.091062092s

• [SLOW TEST:26.518 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:54:18.013: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
STEP: Collecting events from namespace "e2e-tests-kubelet-test-lgml9".
STEP: Found 5 events.
Dec 11 09:55:20.139: INFO: At 2018-12-11 09:54:18 +0000 UTC - event for busybox-host-aliasese1ff809a-fd24-11e8-897d-5ac57959ef46: {default-scheduler } Scheduled: Successfully assigned busybox-host-aliasese1ff809a-fd24-11e8-897d-5ac57959ef46 to ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:55:20.139: INFO: At 2018-12-11 09:54:18 +0000 UTC - event for busybox-host-aliasese1ff809a-fd24-11e8-897d-5ac57959ef46: {kubelet ip-172-25-62-1.us-west-1.compute.internal} SuccessfulMountVolume: MountVolume.SetUp succeeded for volume "default-token-dj6x2" 
Dec 11 09:55:20.139: INFO: At 2018-12-11 09:54:18 +0000 UTC - event for busybox-host-aliasese1ff809a-fd24-11e8-897d-5ac57959ef46: {kubelet ip-172-25-62-1.us-west-1.compute.internal} Pulled: Container image "docker.io/library/busybox:1.29" already present on machine
Dec 11 09:55:20.139: INFO: At 2018-12-11 09:54:18 +0000 UTC - event for busybox-host-aliasese1ff809a-fd24-11e8-897d-5ac57959ef46: {kubelet ip-172-25-62-1.us-west-1.compute.internal} Created: Created container
Dec 11 09:55:20.139: INFO: At 2018-12-11 09:54:18 +0000 UTC - event for busybox-host-aliasese1ff809a-fd24-11e8-897d-5ac57959ef46: {kubelet ip-172-25-62-1.us-west-1.compute.internal} Started: Started container
Dec 11 09:55:20.167: INFO: POD                                                                  NODE                                         PHASE      GRACE  CONDITIONS
Dec 11 09:55:20.167: INFO: prd-ai-sentiment-eng-svc-ai-sentiment-svc-69bd5d994b-7wcr2           ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 13:34:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 13:34:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 13:34:13 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-ai-sentiment-eng-svc-ai-sentiment-svc-69bd5d994b-vn2sr           ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 13:34:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 13:34:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 13:34:13 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: busybox-host-aliasese1ff809a-fd24-11e8-897d-5ac57959ef46             ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:54:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:54:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:54:18 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: sonobuoy                                                             ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:12:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:12:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:12:13 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: sonobuoy-e2e-job-20dd198901204d4d                                    ip-172-25-84-67.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:12:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:12:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:12:16 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: datadog-datadog-5m28x                                                ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:57:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 08:09:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:57:43 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: datadog-datadog-lqmmz                                                ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:03:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:04:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:03:43 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: datadog-datadog-r4px7                                                ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:53:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:54:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:53:44 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: datadog-kube-state-metrics-7d48b4db57-9245w                          ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 15:00:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:40 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-efk-elasticsearch-client-8655b8d9b9-5fmbv                        ip-172-25-93-75.us-west-1.compute.internal   Pending    30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:54:56 +0000 UTC ContainersNotReady containers with unready status: [es-client]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:30 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-efk-elasticsearch-client-8655b8d9b9-jt8zw                        ip-172-25-45-107.us-west-1.compute.internal  Pending    30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:54:55 +0000 UTC ContainersNotReady containers with unready status: [es-client]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:40 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-efk-elasticsearch-client-8655b8d9b9-t4lvs                        ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:54:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:54:52 +0000 UTC ContainersNotReady containers with unready status: [es-client]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:54:52 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-efk-elasticsearch-client-8655b8d9b9-vbpbh                        ip-172-25-62-1.us-west-1.compute.internal    Pending           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:54:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:54:52 +0000 UTC ContainersNotReady containers with unready status: [es-client]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:54:52 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-efk-elasticsearch-curator-1544317200-qxdt5                       ip-172-25-62-1.us-west-1.compute.internal    Succeeded         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 01:00:06 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 01:00:10 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 01:00:06 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-efk-elasticsearch-curator-1544403600-dgbl8                       ip-172-25-62-1.us-west-1.compute.internal    Succeeded         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 01:00:08 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 01:00:12 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 01:00:08 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-efk-elasticsearch-curator-1544490000-4wpv9                       ip-172-25-62-1.us-west-1.compute.internal    Succeeded         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 01:00:07 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 01:00:12 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 01:00:07 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-efk-elasticsearch-data-0                                         ip-172-25-93-75.us-west-1.compute.internal   Running    30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:03:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:54:55 +0000 UTC ContainersNotReady containers with unready status: [es-data]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:28 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-efk-elasticsearch-data-1                                         ip-172-25-45-107.us-west-1.compute.internal  Running    30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:54:55 +0000 UTC ContainersNotReady containers with unready status: [es-data]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:19 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-efk-elasticsearch-fluentd-78wvq                                  ip-172-25-45-107.us-west-1.compute.internal  Pending    30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 15:04:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:54:55 +0000 UTC ContainersNotReady containers with unready status: [fluentd]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:57:43 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-efk-elasticsearch-fluentd-d8gqp                                  ip-172-25-62-180.us-west-1.compute.internal  Running    30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:18:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:54:53 +0000 UTC ContainersNotReady containers with unready status: [fluentd]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:13:47 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-efk-elasticsearch-fluentd-gv7g8                                  ip-172-25-93-75.us-west-1.compute.internal   Pending    30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:58:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:54:55 +0000 UTC ContainersNotReady containers with unready status: [fluentd]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:53:44 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-efk-elasticsearch-fluentd-jhbrx                                  ip-172-25-84-67.us-west-1.compute.internal   Running    30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:53:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:54:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:49:41 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-efk-elasticsearch-fluentd-mk4n2                                  ip-172-25-61-224.us-west-1.compute.internal  Pending    30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:32:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:54:54 +0000 UTC ContainersNotReady containers with unready status: [fluentd]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:28:42 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-efk-elasticsearch-fluentd-t6bxk                                  ip-172-25-62-1.us-west-1.compute.internal    Running    30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:08:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:08:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:03:43 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-efk-elasticsearch-kibana-654b6d5965-9qdfj                        ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:54:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:55:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:54:52 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-efk-elasticsearch-kibana-654b6d5965-xfvj2                        ip-172-25-45-107.us-west-1.compute.internal  Running    30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 15:00:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:41 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-efk-elasticsearch-master-0                                       ip-172-25-93-75.us-west-1.compute.internal   Running    30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:03:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:54:56 +0000 UTC ContainersNotReady containers with unready status: [es-master]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:28 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-efk-elasticsearch-master-1                                       ip-172-25-45-107.us-west-1.compute.internal  Pending    30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:54:55 +0000 UTC ContainersNotReady containers with unready status: [es-master]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:16 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-efk-elasticsearch-master-2                                       ip-172-25-93-75.us-west-1.compute.internal   Running    30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:04:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 09:54:55 +0000 UTC ContainersNotReady containers with unready status: [es-master]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:03:49 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: default-http-backend-66b447d9cf-cvp7c                                ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 15:00:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:42 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: nginx-ingress-controller-5ccb96dd7b-ldrbm                            ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:11:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:12:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:11:11 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: calico-kube-controllers-d97b7c4c8-wnnjq                              ip-172-25-61-224.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:52:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:52:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:52:24 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: calico-node-27rw4                                                    ip-172-25-84-67.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:49:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:49:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:49:41 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: calico-node-7px7g                                                    ip-172-25-61-224.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:28:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:28:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:28:42 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: calico-node-j87ww                                                    ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:57:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:58:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:57:43 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: calico-node-p7n2j                                                    ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:53:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:54:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:53:44 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: calico-node-trxzw                                                    ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:03:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:04:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:03:43 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: calico-node-z2gn6                                                    ip-172-25-62-180.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:13:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:13:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:13:47 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: dns-controller-55fb5dcc77-5nz8k                                      ip-172-25-61-224.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:31:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:31:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:31:24 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: etcd-server-events-ip-172-25-61-224.us-west-1.compute.internal       ip-172-25-61-224.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:28:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:28:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:28:21 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: etcd-server-events-ip-172-25-62-180.us-west-1.compute.internal       ip-172-25-62-180.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:13:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:13:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:13:26 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: etcd-server-events-ip-172-25-84-67.us-west-1.compute.internal        ip-172-25-84-67.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:49:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:49:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:49:27 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: etcd-server-ip-172-25-61-224.us-west-1.compute.internal              ip-172-25-61-224.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:28:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:28:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:28:21 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: etcd-server-ip-172-25-62-180.us-west-1.compute.internal              ip-172-25-62-180.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:13:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:13:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:13:26 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: etcd-server-ip-172-25-84-67.us-west-1.compute.internal               ip-172-25-84-67.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:49:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:49:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:49:27 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: heapster-6d9d49d496-zxs9t                                            ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:43 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:28 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: kube-apiserver-ip-172-25-61-224.us-west-1.compute.internal           ip-172-25-61-224.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:28:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:28:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:28:21 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: kube-apiserver-ip-172-25-62-180.us-west-1.compute.internal           ip-172-25-62-180.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:13:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:13:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:13:26 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: kube-apiserver-ip-172-25-84-67.us-west-1.compute.internal            ip-172-25-84-67.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:49:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:49:32 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:49:28 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: kube-controller-manager-ip-172-25-61-224.us-west-1.compute.internal  ip-172-25-61-224.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:28:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:28:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:28:21 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: kube-controller-manager-ip-172-25-62-180.us-west-1.compute.internal  ip-172-25-62-180.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:13:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:13:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:13:26 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: kube-controller-manager-ip-172-25-84-67.us-west-1.compute.internal   ip-172-25-84-67.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:49:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:49:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:49:28 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: kube-dns-7c4d8456dd-k6dkm                                            ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 15:04:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:40 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: kube-dns-7c4d8456dd-np757                                            ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:03:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:29 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: kube-dns-autoscaler-f4c47db64-rwllv                                  ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:43 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:40 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: kube-proxy-ip-172-25-45-107.us-west-1.compute.internal               ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:57:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:57:32 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:57:27 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: kube-proxy-ip-172-25-61-224.us-west-1.compute.internal               ip-172-25-61-224.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:28:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:28:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:28:21 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: kube-proxy-ip-172-25-62-1.us-west-1.compute.internal                 ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:03:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:03:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:03:26 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: kube-proxy-ip-172-25-62-180.us-west-1.compute.internal               ip-172-25-62-180.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:13:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:13:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:13:26 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: kube-proxy-ip-172-25-84-67.us-west-1.compute.internal                ip-172-25-84-67.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:49:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:49:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:49:28 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: kube-proxy-ip-172-25-93-75.us-west-1.compute.internal                ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:53:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:53:32 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:53:28 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: kube-scheduler-ip-172-25-61-224.us-west-1.compute.internal           ip-172-25-61-224.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:28:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:28:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:28:21 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: kube-scheduler-ip-172-25-62-180.us-west-1.compute.internal           ip-172-25-62-180.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:13:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:13:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:13:26 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: kube-scheduler-ip-172-25-84-67.us-west-1.compute.internal            ip-172-25-84-67.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:49:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:49:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:49:28 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: metrics-server-8555b5f58f-7qjkk                                      ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:53 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:40 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: tiller-deploy-f55c64689-4jfg5                                        ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 15:00:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:40 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: dr-kong-kong-55df5b9f69-tn88c                                        ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 15:02:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:40 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: platform-utils-svc-5bb47f77bd-jjdgj                                  ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 15:00:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:40 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-botfactory-chatbot-ui-pfm-botfactory-chatbot-ui-7bd798cnb8c      ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 10:41:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 10:41:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 10:41:40 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-botfactory-chatbot-ui-pfm-botfactory-chatbot-ui-7bd798pjt9m      ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 10:41:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 10:41:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 10:41:40 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-botfactory-ui-pfm-botfactory-ui-7ff78b89f7-ljt45                 ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 11:30:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 11:30:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 11:30:22 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-botfactory-ui-pfm-botfactory-ui-7ff78b89f7-xnmkr                 ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 11:30:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 11:30:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 11:30:22 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-dss-lc-svc-dss-lc-service-6c8748f77b-7sj75                       ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 13:24:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 13:24:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 13:24:04 +0000 UTC  }]
Dec 11 09:55:20.167: INFO: prd-dss-lc-svc-dss-lc-service-6c8748f77b-tffh5                       ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 13:24:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 13:24:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 13:24:04 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-dss-lcbulk-svc-dss-lcbulk-service-77b5449544-6nkdr               ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:00:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:27 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-dss-leadcloser-ui-658768bd4b-84zb9                               ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 12:27:09 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 12:27:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 12:27:09 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-dss-leadcloser-ui-658768bd4b-zbbdr                               ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 12:27:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 12:27:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 12:27:05 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-dss-pm-profile-svc-dss-pm-profile-service-556b68d65-qmntq        ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:31 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:02:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:31 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-dss-pm-profile-svc-dss-pm-profile-service-556b68d65-rlqgv        ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 15:02:15 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:42 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-dss-ppc-masterdata-ppc-svc-7d8577dd7c-pb92m                      ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-26 11:42:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-26 11:42:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-26 11:42:41 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-dss-ppc-ratetables-ppc-svc-cfb7cd6b9-6qcrh                       ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-26 11:48:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-26 11:48:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-26 11:48:21 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-dss-ppc-svc-ppc-svc-58f5d567d-8msxj                              ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-26 11:36:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-26 11:36:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-26 11:36:47 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-dss-ppc-ui-64f9cf489c-r64qn                                      ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 14:04:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 14:04:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 14:04:47 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-dss-ppc-ui-64f9cf489c-zj4pk                                      ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 14:04:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 14:04:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 14:04:47 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-dss-qni-illustration-svc-dss-qni-illustration-service-r2rhd      ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-26 11:18:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-26 11:18:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-26 11:18:56 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-dss-qni-illustration-svc-dss-qni-illustration-service-tjbw9      ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-26 11:18:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-26 11:19:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-26 11:18:56 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-dss-qni-quote-svc-dss-qni-quote-service-84cbc8c6c8-qm5jw         ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-26 11:13:14 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-26 11:13:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-26 11:13:14 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-dss-quote-ui-7475c4bdc-lg6c6                                     ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 10:07:09 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 10:07:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 10:07:09 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-ibf-botfactory-adapter-svc-botfactory-adapter-service-p5vcf      ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 11:11:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 11:11:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 11:11:42 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-ibf-botfactory-admin-svc-botfactory-admin-service-59f4n5m5f      ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 11:08:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 11:08:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 11:08:42 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-ibf-botfactory-agent-svc-botfactory-agent-service-56f5mkg6f      ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 10:57:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 10:57:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 10:57:49 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-ibf-botfactory-platform-svc-botfactory-platform-servicszx9g      ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 11:04:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 11:04:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-21 11:04:39 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-keycloak-keycloak-78d64cbc4f-scj6l                               ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:01:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:29 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-keycloak-pgpool-58b949979d-ndwgn                                 ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:01:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:30 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-keycloak-pgpool-58b949979d-wllt4                                 ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 15:01:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:42 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-acc-svc-platform-acc-svc-56c66dc6bc-c76pd                     ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 08:35:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 08:36:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 08:35:58 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-acc-svc-platform-acc-svc-56c66dc6bc-jl2qm                     ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 08:35:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 08:36:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 08:35:58 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-accmgmt-ui-platform-accmgmt-ui-5cbc4c9d66-g4wqj               ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:49:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:50:03 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:49:59 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-accmgmt-ui-platform-accmgmt-ui-5cbc4c9d66-krr5g               ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:50:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:50:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:50:03 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-activity-svc-platform-activity-svc-855df677b4-htnqk           ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:02:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:30 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-activity-svc-platform-activity-svc-855df677b4-s5r9p           ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 15:03:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:43 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-admin-ui-platform-admin-ui-85c98dcc66-9vj7s                   ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:40:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:40:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:40:28 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-admin-ui-platform-admin-ui-85c98dcc66-rbgt5                   ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:40:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:40:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:40:24 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-apimgmt-ui-platform-apimgmt-ui-699d4df9d-cd7lv                ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:37:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:37:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:37:33 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-apimgmt-ui-platform-apimgmt-ui-699d4df9d-nb79x                ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:37:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:37:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:37:39 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-audit-svc-platform-audit-svc-78f5998486-2rmn5                 ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 15:04:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:44 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-audit-svc-platform-audit-svc-78f5998486-4vlp5                 ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:03:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:29 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-blkusrimp-svc-platform-blkusrimp-svc-7d8d5c459f-78l6p         ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 15:02:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:44 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-blkusrimp-svc-platform-blkusrimp-svc-7d8d5c459f-q24h8         ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:00:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:28 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-calen-svc-platform-calen-svc-59dc958758-gq7dn                 ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:03:22 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:29 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-calen-svc-platform-calen-svc-59dc958758-kgjtc                 ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 15:02:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:44 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-conf-svc-platform-conf-svc-6f8c9c5649-hrx2v                   ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 08:43:48 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 08:43:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 08:43:48 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-conf-svc-platform-conf-svc-6f8c9c5649-js8zv                   ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 08:43:48 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 08:43:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 08:43:48 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-contact-svc-platform-contact-svc-7fdb7698d8-6s89f             ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:03:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:28 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-contact-svc-platform-contact-svc-7fdb7698d8-ksnzv             ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 15:03:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:45 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-dashboard-ui-platform-dashboard-ui-859cf5d999-9qp8v           ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:23:38 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:23:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:23:38 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-dashboard-ui-platform-dashboard-ui-859cf5d999-mwwgd           ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:23:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:23:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:23:32 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-doc-svc-platform-doc-svc-6bc8488db8-b6mbr                     ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:01:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:28 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-doc-svc-platform-doc-svc-6bc8488db8-cncz8                     ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 15:04:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:45 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-email-svc-platform-email-svc-8696f76496-9gbn5                 ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 15:03:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:45 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-email-svc-platform-email-svc-8696f76496-wkzqt                 ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:31 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:02:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:31 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-iam-svc-platform-iam-svc-5d57975b5-b8fcg                      ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:00:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:28 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-iam-svc-platform-iam-svc-5d57975b5-vjrk6                      ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 15:03:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:46 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-notes-svc-platform-notes-svc-5c99df689c-bdfww                 ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 15:05:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:46 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-notes-svc-platform-notes-svc-5c99df689c-vs8g5                 ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:02:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:28 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-notif-svc-platform-notif-svc-84dd77bbd8-74825                 ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 15:03:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:46 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-notif-svc-platform-notif-svc-84dd77bbd8-qhxw5                 ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:03:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:29 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-prflmgmt-ui-platform-prflmgmt-ui-654ff59c99-mntgc             ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:46:36 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:46:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:46:36 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-prflmgmt-ui-platform-prflmgmt-ui-654ff59c99-tl62p             ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:46:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:46:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:46:41 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-sign-svc-platform-signup-svc-7dcfdd559-c26zr                  ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:03:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:30 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-sign-svc-platform-signup-svc-7dcfdd559-llx49                  ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:48 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 15:05:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:47 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-signup-ui-platform-signup-ui-54ffdd6f94-62xr7                 ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:30:50 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:30:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:30:50 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pf-signup-ui-platform-signup-ui-54ffdd6f94-pzb82                 ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:30:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:30:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 11:30:55 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pfm-svc-data-6448cbb64-djfdf                                     ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 17:03:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 16:59:30 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pfm-svc-data-6448cbb64-w464d                                     ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:48 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 15:04:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:46 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pfm-svc-telephony-55658c585-l2cmb                                ip-172-25-93-75.us-west-1.compute.internal   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 08:24:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 08:24:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 08:24:26 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: prd-pfm-svc-telephony-55658c585-sp22g                                ip-172-25-62-1.us-west-1.compute.internal    Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 08:24:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 08:24:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-20 08:24:26 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: ubuntu-5f89d47d59-pz2h8                                              ip-172-25-45-107.us-west-1.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-19 14:59:40 +0000 UTC  }]
Dec 11 09:55:20.168: INFO: 
Dec 11 09:55:20.172: INFO: 
Logging node info for node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:55:20.174: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:ip-172-25-45-107.us-west-1.compute.internal,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal,UID:7812d1fe-ec0b-11e8-a743-0611d656c330,ResourceVersion:21960783,Generation:0,CreationTimestamp:2018-11-19 14:57:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: r4.4xlarge,beta.kubernetes.io/os: linux,failure-domain.beta.kubernetes.io/region: us-west-1,failure-domain.beta.kubernetes.io/zone: us-west-1a,kops.k8s.io/instancegroup: nodes,kubernetes.io/hostname: ip-172-25-45-107.us-west-1.compute.internal,kubernetes.io/role: node,node-role.kubernetes.io/node: ,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:NodeSpec{PodCIDR:100.96.1.0/24,DoNotUse_ExternalID:i-0cc3be3047d7c585d,ProviderID:aws:///us-west-1a/i-0cc3be3047d7c585d,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{cpu: {{16 0} {<nil>} 16 DecimalSI},ephemeral-storage: {{137426350080 0} {<nil>} 134205420Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{128672694272 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{16 0} {<nil>} 16 DecimalSI},ephemeral-storage: {{123683714868 0} {<nil>} 123683714868 DecimalSI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{128567836672 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2018-12-11 09:55:15 +0000 UTC 2018-11-19 14:57:43 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2018-12-11 09:55:15 +0000 UTC 2018-11-19 14:57:43 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2018-12-11 09:55:15 +0000 UTC 2018-11-19 14:57:43 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2018-12-11 09:55:15 +0000 UTC 2018-11-19 14:57:43 +0000 UTC KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2018-12-11 09:55:15 +0000 UTC 2018-11-19 14:58:23 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 172.25.45.107} {InternalDNS ip-172-25-45-107.us-west-1.compute.internal} {Hostname ip-172-25-45-107.us-west-1.compute.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:79dd2393d78d4cb6b03c148a802b0382,SystemUUID:EC2B69A7-51A3-EB61-086A-3D25FC12079E,BootID:a1cc580d-2b49-49b9-be53-28fe04707b1a,KernelVersion:3.10.0-693.el7.x86_64,OSImage:Red Hat Enterprise Linux Server 7.4 (Maipo),ContainerRuntimeVersion:docker://17.3.2,KubeletVersion:v1.10.6,KubeProxyVersion:v1.10.6,OperatingSystem:linux,Architecture:amd64,},Images:[{[docker.elastic.co/kibana/kibana-oss@sha256:967a599383a02ad3d5c03a923cc620e33da6d9fd6aee41163943690cba278c4f docker.elastic.co/kibana/kibana-oss:6.0.0] 476707342} {[intellectdesigndevteam/platform-document-service@sha256:f03450a8ad1d44a2398de68a4e74211ed3f6206bff7d54c7c0430c9ae43e925f intellectdesigndevteam/platform-document-service:qa-18.3.1.19] 382667587} {[intellectdesigndevteam/qni-illustration-service@sha256:2dbc0c4bddb98df953dae7e1f07ac6eb974b2c69e29581ae14e39dd51ff6a7c1 intellectdesigndevteam/qni-illustration-service:18.4.0-dev] 363345689} {[datadog/agent@sha256:f3427a04d93b0f0b82674be9b7217aba03e064898e2a6c59e94897b8be293823 datadog/agent:6.0.0] 337278068} {[intellectdevcloud/platform-filebeat@sha256:393f2e866d3511565997e464359984fa8949c885fc3998c095963325daef20da intellectdevcloud/platform-filebeat:latest] 318649904} {[intellectdesigndevteam/platform-bulkuserimport-service@sha256:3cc549cb89e2987f129157d3706d2f36abe0ca63e1cc5e14751134968724c9f5 intellectdesigndevteam/platform-bulkuserimport-service:qa-18.3.1.19] 315312535} {[intellectdesigndevteam/qni-quote-service@sha256:c8d1e58b2a60d495304e765ba0227220f70eae50ab8bcb42ee6ad13950859769 intellectdesigndevteam/qni-quote-service:18.4.0-dev] 305213621} {[intellectdesigndevteam/platform-data-service@sha256:b11e43b1a1dc43060d9633936625e934e3e0d37bc4f021c5e2d0719933d67250 intellectdesigndevteam/platform-data-service:qa-18.3.1.6] 297525539} {[quay.io/calico/node@sha256:7758c25549fcfe677699bbcd3c279b3a174e7cbbbf9d16f3d71713d68f695dfb quay.io/calico/node:v2.6.7] 281572001} {[protokube:1.10.0] 278482183} {[intellectdesigndevteam/platform-signup-service@sha256:c47bdd7deef21a19e3165e2d144c562794e994320d74276839e8455e04e83643 intellectdesigndevteam/platform-signup-service:qa-18.3.1.16] 270601639} {[intellectdesigndevteam/platform-iam-service@sha256:d8d4429e9b83213cd7597411359575b9999dc32f8b911aecedd7d74ec574e7ee intellectdesigndevteam/platform-iam-service:qa-18.3.1.26] 265195612} {[intellectdevcloud/pm-profile-service@sha256:f0e96b993041268fab1cb2ea9b0822135c0580c65d1260e865491639f044ecbd intellectdevcloud/pm-profile-service:18.2.0.1-150618-k8s] 263694180} {[intellectdesigndevteam/platform-telephony-service@sha256:71d6f3e29872035c89a8bd3f2bf672d069f2711e3bc50a7a1a8e007f96f2fe8b intellectdesigndevteam/platform-telephony-service:qa-18.3.1.1] 255496670} {[intellectdesigndevteam/platform-calendar-service@sha256:e77b861007c53296e66fb457c5e5578906a25f8b4cfd2161d1895509f3c5a8bc intellectdesigndevteam/platform-calendar-service:qa-18.3.1.20] 253851461} {[intellectdesigndevteam/platform-contact-service@sha256:feaac96a8e27ed41579d61aee99676d6e0bf5a211b9f952b90fae829dfceaa67 intellectdesigndevteam/platform-contact-service:qa-18.3.1.16] 253833597} {[intellectdesigndevteam/platform-notification-service@sha256:7d5d03a40c32661827903b5f6f616a252311d59b0297e24ef4d8da5974d588b5 intellectdesigndevteam/platform-notification-service:qa-18.3.1.19] 250643389} {[intellectdesigndevteam/platform-config-service@sha256:06b65c100e8716cab80d1eb18a0884d2d9fd4bfd5eefb680c3a7dc484fd27e33 intellectdesigndevteam/platform-config-service:stag-18.3.1.17.1] 250153994} {[intellectdesigndevteam/platform-activity-service@sha256:09d1fdad637da213bc1d9fac6ebc696d4f279677fe7a87b7c683f8043c2dd15b intellectdesigndevteam/platform-activity-service:qa-18.3.1.18] 249015063} {[intellectdesigndevteam/platform-account-service@sha256:b93f93ee912665999b662494989d8cb0af5c46e6e87d0aaed81a4040c43c1942 intellectdesigndevteam/platform-account-service:stag-18.3.1.22.1] 247829302} {[intellectdesigndevteam/platform-audit-service@sha256:6fd07e5804be5f2c50f171440cfcd683c8a0fc5462cc658e76e147a69aabc1ef intellectdesigndevteam/platform-audit-service:qa-18.3.1.20] 244793295} {[intellectdesigndevteam/platform-notes-service@sha256:fe7a79441bbfc780ba0e120dce6b3a3745f39f07bf8549abec7211f1fecdcdbb intellectdesigndevteam/platform-notes-service:qa-18.3.1.15] 242664197} {[intellectdesigndevteam/platform-email-service@sha256:9e56b9b3b9a57d070a36a218cd0d701313c961dc618e0cdd0666345c40adc5b7 intellectdesigndevteam/platform-email-service:qa-18.3.1.14] 241218721} {[intellectdesigndevteam/leadcloser-service@sha256:3ec1f000c589dff6cec4ac74e3b2af778195f61aeed034f652d30727acef6323 intellectdesigndevteam/leadcloser-service:dev-18.3.1.57] 237593029} {[intellectdesigndevteam/pgpool@sha256:672d1b41d58c9b7c849de2d8d0c042b3a913b358a7b38f042e83d44cd46e3a0c intellectdesigndevteam/pgpool:HEAD.138] 228082404} {[fluent/fluentd-kubernetes-daemonset@sha256:752aed38ede9b0bbf7ae411761672d83d60ecc54bfa567972f7c6076713bec9f fluent/fluentd-kubernetes-daemonset:v0.12-debian-elasticsearch] 228009678} {[intellectdesigndevteam/botfactory-agent-service@sha256:4d3e8c2c17342dece71a4637f02e5576489c9f6b1b7f519e5f4207457c5285fd intellectdesigndevteam/botfactory-agent-service:qa-1.0.3] 193293720} {[intellectdevcloud/platform-util-service@sha256:ce2cb2047a82af3cb824daba46ffdb32005efb7986abee527c41bcd80f49e4bc intellectdevcloud/platform-util-service:qa-18.3.1.2] 190629400} {[quay.io/kubernetes-ingress-controller/nginx-ingress-controller@sha256:39cc6ce23e5bcdf8aa78bc28bbcfe0999e449bf99fe2e8d60984b417facc5cd4 quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.9.0] 189866039} {[intellectdesigndevteam/botfactory-admin-service@sha256:2435ae71c0f75f8dec9d2cb17c50f56f34a1691571154a5eb7d8a8c6ea9459d8 intellectdesigndevteam/botfactory-admin-service:qa-1.0.2] 182201474} {[prasadg193/test@sha256:1090dbb139c4f7cdbc154dfad21ae3bde42f1cb868ca614351127d4c14dc5c61 prasadg193/test:ubuntu] 138544282} {[quay.io/pires/docker-elasticsearch-kubernetes@sha256:62d1dbf7b7c0a47a560b97a53753c980be62c719db55c3fc9128d7a9315daa1e quay.io/pires/docker-elasticsearch-kubernetes:6.0.0] 122667485} {[intellectdesigndevteam/platform-api-management-ui@sha256:a8d9bfb0f90d06774795d901b98f2c373d0bb6d1fb69d422cfc471a85a2f186a intellectdesigndevteam/platform-api-management-ui:qa-18.3.1.5] 113907865} {[intellectdesigndevteam/platform-admin-ui@sha256:168bcbf6a6cbfe14cac6c975d5b6563af06a606cb0646f9d1f03157acab8ca99 intellectdesigndevteam/platform-admin-ui:qa-18.3.1.5] 109695063} {[nginx@sha256:5d32f60db294b5deb55d078cd4feb410ad88e6fe77500c87d3970eca97f54dba nginx:latest] 109096776} {[intellectdesigndevteam/dss-leadcloser-ui@sha256:876da18e3d331956a4a032dd9b6de6e6d795a8fc68b537d270a228e4554c51aa intellectdesigndevteam/dss-leadcloser-ui:INFRA-3185] 103175252} {[intellectdesigndevteam/dss-leadcloser-ui@sha256:ebefb74aff30c289ba5a83a715a5ac732ae6c64686d003550aae247f1bf8eba2 intellectdesigndevteam/dss-leadcloser-ui:18.3.1] 102985492} {[k8s.gcr.io/kube-proxy@sha256:99a9e5ce663a27603a297981156cef2163cb6eee3a2e4fcf958063ec09a4cfc0 k8s.gcr.io/kube-proxy:v1.10.6] 97861102} {[intellectdevcloud/kong@sha256:2bca3a827d648ab8a7a6ff8c6881037c83db64ec912b5c018b1faf527a2e0bd2 intellectdevcloud/kong:0.13.1] 96512701} {[intellectdesigndevteam/platform-dashboard-ui@sha256:39ca7d2277802e3bfe87a6b779d049143b8543aa1bef5fc4a38db93de75789bf intellectdesigndevteam/platform-dashboard-ui:qa-18.3.1.5] 92532926} {[intellectdesigndevteam/platform-account-management-ui@sha256:38b6bac1384c0d3140483e3c6045d0ea7d5acf5bc962ef76ad1c76689ccc5131 intellectdesigndevteam/platform-account-management-ui:qa-18.3.1.5] 88970310} {[intellectdesigndevteam/platform-profile-management-ui@sha256:15ae94ffb55848026ce69c904695ab8c02838758b8b0755f59226500e459d144 intellectdesigndevteam/platform-profile-management-ui:qa-18.3.1.5] 87805996} {[intellectdesigndevteam/platform-signup-ui@sha256:0ff2d304f36a12e7d66beaf2313993c558155deaacbc58e9c6a5a5cbb5416371 intellectdesigndevteam/platform-signup-ui:qa-18.3.1.5] 86564054} {[intellectdesigndevteam/botfactory-chatbot-ui@sha256:1a5c90b58acce17dc85806214db90edbcf567c5ffc3dc7442da22f5c7440cdd5 intellectdesigndevteam/botfactory-chatbot-ui:qa-1.0.4] 71259465} {[quay.io/calico/cni@sha256:3a23e093b1e98cf232a226fedff591d33919f5297f016a41d8012efc83b23a84 quay.io/calico/cni:v1.11.2] 70781000} {[gcr.io/google_containers/cluster-proportional-autoscaler-amd64@sha256:003f98d9f411ddfa6ff6d539196355e03ddd69fa4ed38c7ffb8fec6f729afe2d gcr.io/google_containers/cluster-proportional-autoscaler-amd64:1.1.2-r2] 49644153} {[gcr.io/google_containers/k8s-dns-kube-dns-amd64@sha256:b99fc3eee2a9f052f7eb4cc00f15eb12fc405fa41019baa2d6b79847ae7284a8 gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.14.10] 49545125} {[gcr.io/google_containers/metrics-server-amd64@sha256:49a9f12f7067d11f42c803dbe61ed2c1299959ad85cb315b25ff7eef8e6b8892 gcr.io/google_containers/metrics-server-amd64:v0.2.1] 42541759} {[gcr.io/google_containers/k8s-dns-sidecar-amd64@sha256:4f1ab957f87b94a5ec1edc26fae50da2175461f00afecf68940c4aa079bd08a4 gcr.io/google_containers/k8s-dns-sidecar-amd64:1.14.10] 41630977} {[gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64@sha256:bbb2a290a568125b3b996028958eb773f33b5b87a6b37bf38a28f8b62dddb3c8 gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.10] 40367821}],VolumesInUse:[kubernetes.io/aws-ebs/aws://us-west-1a/vol-05c8a76c15a0fd0da kubernetes.io/aws-ebs/aws://us-west-1a/vol-0ee3f666256321c29],VolumesAttached:[{kubernetes.io/aws-ebs/aws://us-west-1a/vol-05c8a76c15a0fd0da /dev/xvdby} {kubernetes.io/aws-ebs/aws://us-west-1a/vol-0ee3f666256321c29 /dev/xvdcz}],Config:nil,},}
Dec 11 09:55:20.175: INFO: 
Logging kubelet events for node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:55:20.177: INFO: 
Logging pods the kubelet thinks is on node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:55:20.188: INFO: prd-efk-elasticsearch-master-1 started at 2018-11-19 14:59:16 +0000 UTC (1+1 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Init container init-sysctl ready: true, restart count 0
Dec 11 09:55:20.188: INFO: 	Container es-master ready: false, restart count 0
Dec 11 09:55:20.188: INFO: platform-utils-svc-5bb47f77bd-jjdgj started at 2018-11-19 14:59:40 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container platform-utils-svc ready: true, restart count 0
Dec 11 09:55:20.188: INFO: prd-pf-calen-svc-platform-calen-svc-59dc958758-kgjtc started at 2018-11-19 14:59:44 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.188: INFO: 	Container prd-pf-calen-svc-platform-calen-svc ready: true, restart count 0
Dec 11 09:55:20.188: INFO: prd-pf-blkusrimp-svc-platform-blkusrimp-svc-7d8d5c459f-78l6p started at 2018-11-19 14:59:44 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.188: INFO: 	Container prd-pf-blkusrimp-svc-platform-blkusrimp-svc ready: true, restart count 0
Dec 11 09:55:20.188: INFO: kube-proxy-ip-172-25-45-107.us-west-1.compute.internal started at <nil> (0+0 container statuses recorded)
Dec 11 09:55:20.188: INFO: datadog-datadog-5m28x started at 2018-11-19 14:57:43 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container datadog ready: true, restart count 2
Dec 11 09:55:20.188: INFO: calico-node-j87ww started at 2018-11-19 14:57:43 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container calico-node ready: true, restart count 0
Dec 11 09:55:20.188: INFO: 	Container install-cni ready: true, restart count 0
Dec 11 09:55:20.188: INFO: kube-dns-autoscaler-f4c47db64-rwllv started at 2018-11-19 14:59:40 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container autoscaler ready: true, restart count 0
Dec 11 09:55:20.188: INFO: ubuntu-5f89d47d59-pz2h8 started at 2018-11-19 14:59:40 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container ubuntu ready: true, restart count 0
Dec 11 09:55:20.188: INFO: kube-dns-7c4d8456dd-k6dkm started at 2018-11-19 14:59:40 +0000 UTC (0+3 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container dnsmasq ready: true, restart count 0
Dec 11 09:55:20.188: INFO: 	Container kubedns ready: true, restart count 0
Dec 11 09:55:20.188: INFO: 	Container sidecar ready: true, restart count 0
Dec 11 09:55:20.188: INFO: prd-pf-contact-svc-platform-contact-svc-7fdb7698d8-ksnzv started at 2018-11-19 14:59:45 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.188: INFO: 	Container prd-pf-contact-svc-platform-contact-svc ready: true, restart count 0
Dec 11 09:55:20.188: INFO: prd-pf-email-svc-platform-email-svc-8696f76496-9gbn5 started at 2018-11-19 14:59:45 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.188: INFO: 	Container prd-pf-email-svc-platform-email-svc ready: true, restart count 0
Dec 11 09:55:20.188: INFO: prd-pf-notif-svc-platform-notif-svc-84dd77bbd8-74825 started at 2018-11-19 14:59:47 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.188: INFO: 	Container prd-pf-notif-svc-platform-notif-svc ready: true, restart count 0
Dec 11 09:55:20.188: INFO: prd-pfm-svc-data-6448cbb64-w464d started at 2018-11-19 14:59:48 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.188: INFO: 	Container prd-pf-data-svc-prd-pfm-svc-data ready: true, restart count 0
Dec 11 09:55:20.188: INFO: prd-pf-activity-svc-platform-activity-svc-855df677b4-s5r9p started at 2018-11-19 14:59:43 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.188: INFO: 	Container prd-pf-activity-svc-platform-activity-svc ready: true, restart count 0
Dec 11 09:55:20.188: INFO: prd-pf-audit-svc-platform-audit-svc-78f5998486-2rmn5 started at 2018-11-19 14:59:44 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.188: INFO: 	Container prd-pf-audit-svc-platform-audit-svc ready: true, restart count 0
Dec 11 09:55:20.188: INFO: prd-dss-qni-illustration-svc-dss-qni-illustration-service-tjbw9 started at 2018-11-26 11:18:56 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.188: INFO: 	Container prd-dss-qni-illustration-svc-dss-qni-illustration-service ready: true, restart count 0
Dec 11 09:55:20.188: INFO: prd-keycloak-pgpool-58b949979d-wllt4 started at 2018-11-19 14:59:42 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container prd-keycloak-pgpool ready: true, restart count 2
Dec 11 09:55:20.188: INFO: prd-pf-sign-svc-platform-signup-svc-7dcfdd559-llx49 started at 2018-11-19 14:59:48 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.188: INFO: 	Container prd-pf-sign-svc-platform-signup-svc ready: true, restart count 0
Dec 11 09:55:20.188: INFO: prd-botfactory-chatbot-ui-pfm-botfactory-chatbot-ui-7bd798pjt9m started at 2018-11-21 10:41:40 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container pfm-botfactory-chatbot-ui ready: true, restart count 0
Dec 11 09:55:20.188: INFO: datadog-kube-state-metrics-7d48b4db57-9245w started at 2018-11-19 14:59:40 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container kube-state-metrics ready: true, restart count 0
Dec 11 09:55:20.188: INFO: prd-efk-elasticsearch-client-8655b8d9b9-jt8zw started at 2018-11-19 14:59:40 +0000 UTC (1+1 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Init container init-sysctl ready: true, restart count 0
Dec 11 09:55:20.188: INFO: 	Container es-client ready: false, restart count 0
Dec 11 09:55:20.188: INFO: prd-dss-leadcloser-ui-658768bd4b-84zb9 started at 2018-11-20 12:27:09 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container dss-leadcloser-ui ready: true, restart count 0
Dec 11 09:55:20.188: INFO: prd-ibf-botfactory-admin-svc-botfactory-admin-service-59f4n5m5f started at 2018-11-21 11:08:42 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container botfactory-admin-service ready: true, restart count 0
Dec 11 09:55:20.188: INFO: tiller-deploy-f55c64689-4jfg5 started at 2018-11-19 14:59:40 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container tiller ready: true, restart count 0
Dec 11 09:55:20.188: INFO: prd-efk-elasticsearch-kibana-654b6d5965-xfvj2 started at 2018-11-19 14:59:41 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container kibana ready: true, restart count 0
Dec 11 09:55:20.188: INFO: prd-dss-pm-profile-svc-dss-pm-profile-service-556b68d65-rlqgv started at 2018-11-19 14:59:42 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container dss-pm-profile-service ready: true, restart count 0
Dec 11 09:55:20.188: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.188: INFO: default-http-backend-66b447d9cf-cvp7c started at 2018-11-19 14:59:42 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container default-http-backend ready: true, restart count 0
Dec 11 09:55:20.188: INFO: prd-pf-doc-svc-platform-doc-svc-6bc8488db8-cncz8 started at 2018-11-19 14:59:45 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.188: INFO: 	Container prd-pf-doc-svc-platform-doc-svc ready: true, restart count 0
Dec 11 09:55:20.188: INFO: prd-efk-elasticsearch-fluentd-78wvq started at 2018-11-19 14:57:43 +0000 UTC (1+1 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Init container init-fluentd ready: true, restart count 0
Dec 11 09:55:20.188: INFO: 	Container fluentd ready: false, restart count 0
Dec 11 09:55:20.188: INFO: metrics-server-8555b5f58f-7qjkk started at 2018-11-19 14:59:40 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container metrics-server ready: true, restart count 0
Dec 11 09:55:20.188: INFO: prd-ibf-botfactory-agent-svc-botfactory-agent-service-56f5mkg6f started at 2018-11-21 10:57:49 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container botfactory-agent-service ready: true, restart count 0
Dec 11 09:55:20.188: INFO: prd-pf-iam-svc-platform-iam-svc-5d57975b5-vjrk6 started at 2018-11-19 14:59:47 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.188: INFO: 	Container prd-pf-iam-svc-platform-iam-svc ready: true, restart count 0
Dec 11 09:55:20.188: INFO: prd-efk-elasticsearch-data-1 started at 2018-11-19 14:59:19 +0000 UTC (1+1 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Init container init-sysctl ready: true, restart count 0
Dec 11 09:55:20.188: INFO: 	Container es-data ready: false, restart count 0
Dec 11 09:55:20.188: INFO: dr-kong-kong-55df5b9f69-tn88c started at 2018-11-19 14:59:40 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container dr-kong-kong ready: true, restart count 1
Dec 11 09:55:20.188: INFO: prd-pf-notes-svc-platform-notes-svc-5c99df689c-bdfww started at 2018-11-19 14:59:47 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.188: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.188: INFO: 	Container prd-pf-notes-svc-platform-notes-svc ready: true, restart count 0
W1211 09:55:20.192415      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 11 09:55:20.214: INFO: 
Latency metrics for node ip-172-25-45-107.us-west-1.compute.internal
Dec 11 09:55:20.214: INFO: {Operation:stop_container Method:docker_operations_latency_microseconds Quantile:0.99 Latency:30.055902s}
Dec 11 09:55:20.214: INFO: 
Logging node info for node ip-172-25-61-224.us-west-1.compute.internal
Dec 11 09:55:20.216: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:ip-172-25-61-224.us-west-1.compute.internal,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/ip-172-25-61-224.us-west-1.compute.internal,UID:69ee6d0c-ec07-11e8-a743-0611d656c330,ResourceVersion:21960769,Generation:0,CreationTimestamp:2018-11-19 14:28:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: c4.2xlarge,beta.kubernetes.io/os: linux,failure-domain.beta.kubernetes.io/region: us-west-1,failure-domain.beta.kubernetes.io/zone: us-west-1a,kops.k8s.io/instancegroup: master-us-west-1a-2,kubernetes.io/hostname: ip-172-25-61-224.us-west-1.compute.internal,kubernetes.io/role: master,node-role.kubernetes.io/master: ,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:NodeSpec{PodCIDR:100.96.10.0/24,DoNotUse_ExternalID:i-0831ee6a3ab37a8e2,ProviderID:aws:///us-west-1a/i-0831ee6a3ab37a8e2,Unschedulable:false,Taints:[{node-role.kubernetes.io/master  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{cpu: {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage: {{68706873344 0} {<nil>} 67096556Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{15600160768 0} {<nil>} 15234532Ki BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage: {{61836185908 0} {<nil>} 61836185908 DecimalSI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{15495303168 0} {<nil>} 15132132Ki BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2018-12-11 09:55:10 +0000 UTC 2018-11-19 14:28:38 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2018-12-11 09:55:10 +0000 UTC 2018-11-19 14:28:38 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2018-12-11 09:55:10 +0000 UTC 2018-11-19 14:28:38 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2018-12-11 09:55:10 +0000 UTC 2018-11-19 14:28:38 +0000 UTC KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2018-12-11 09:55:10 +0000 UTC 2018-11-19 14:29:02 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 172.25.61.224} {InternalDNS ip-172-25-61-224.us-west-1.compute.internal} {Hostname ip-172-25-61-224.us-west-1.compute.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:fc8760606d444502a6a6a294d85f3281,SystemUUID:EC25D84B-7F02-C042-2481-19927513E1F1,BootID:f365974b-7772-4005-a12e-818b84eb4fd4,KernelVersion:3.10.0-693.el7.x86_64,OSImage:Red Hat Enterprise Linux Server 7.4 (Maipo),ContainerRuntimeVersion:docker://17.3.2,KubeletVersion:v1.10.6,KubeProxyVersion:v1.10.6,OperatingSystem:linux,Architecture:amd64,},Images:[{[quay.io/calico/node@sha256:7758c25549fcfe677699bbcd3c279b3a174e7cbbbf9d16f3d71713d68f695dfb quay.io/calico/node:v2.6.7] 281572001} {[protokube:1.10.0] 278482183} {[k8s.gcr.io/kube-apiserver@sha256:3283c534aab386bc678986c74c2fc855db46b3f424884d547641c82dba6ec5de k8s.gcr.io/kube-apiserver:v1.10.6] 228066280} {[fluent/fluentd-kubernetes-daemonset@sha256:752aed38ede9b0bbf7ae411761672d83d60ecc54bfa567972f7c6076713bec9f fluent/fluentd-kubernetes-daemonset:v0.12-debian-elasticsearch] 228009678} {[k8s.gcr.io/kube-controller-manager@sha256:93bbd2218a04253db98438ee49d9512359ee9d2a89e2a4247d520b21296acfd6 k8s.gcr.io/kube-controller-manager:v1.10.6] 150824264} {[kope/dns-controller@sha256:a4f5c5490b23e6bad32028d223b172f3fc9a6d4251cc5eea6e5e389c8dc12024 kope/dns-controller:1.10.0] 119435348} {[k8s.gcr.io/kube-proxy@sha256:99a9e5ce663a27603a297981156cef2163cb6eee3a2e4fcf958063ec09a4cfc0 k8s.gcr.io/kube-proxy:v1.10.6] 97861102} {[quay.io/calico/cni@sha256:3a23e093b1e98cf232a226fedff591d33919f5297f016a41d8012efc83b23a84 quay.io/calico/cni:v1.11.2] 70781000} {[quay.io/calico/kube-controllers@sha256:e60bdbab2f57540e68f9e8b1a585913e14f0e8ff0628f1e42ad69e4bfb706840 quay.io/calico/kube-controllers:v1.0.3] 52247098} {[k8s.gcr.io/kube-scheduler@sha256:83eb7da923c75ef02fd0f8665b2411d6f3bf5e2df0de35849890c65a3d667d7a k8s.gcr.io/kube-scheduler:v1.10.6] 51215735} {[k8s.gcr.io/etcd@sha256:19544a655157fb089b62d4dac02bbd095f82ca245dd5e31dd1684d175b109947 k8s.gcr.io/etcd:2.2.1] 28191895} {[odise/busybox-curl@sha256:815ad8389785898c19a63afcaca0df0026a6574731ffd44daf2ae0f885c21fda odise/busybox-curl:stable] 7070717} {[k8s.gcr.io/pause-amd64@sha256:163ac025575b775d1c0f9bf0bdd0f086883171eb475b5068e7defa4ca9e76516 k8s.gcr.io/pause-amd64:3.0] 746888}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
Dec 11 09:55:20.217: INFO: 
Logging kubelet events for node ip-172-25-61-224.us-west-1.compute.internal
Dec 11 09:55:20.219: INFO: 
Logging pods the kubelet thinks is on node ip-172-25-61-224.us-west-1.compute.internal
Dec 11 09:55:20.230: INFO: kube-apiserver-ip-172-25-61-224.us-west-1.compute.internal started at <nil> (0+0 container statuses recorded)
Dec 11 09:55:20.230: INFO: kube-proxy-ip-172-25-61-224.us-west-1.compute.internal started at <nil> (0+0 container statuses recorded)
Dec 11 09:55:20.230: INFO: kube-controller-manager-ip-172-25-61-224.us-west-1.compute.internal started at <nil> (0+0 container statuses recorded)
Dec 11 09:55:20.230: INFO: kube-scheduler-ip-172-25-61-224.us-west-1.compute.internal started at <nil> (0+0 container statuses recorded)
Dec 11 09:55:20.230: INFO: prd-efk-elasticsearch-fluentd-mk4n2 started at 2018-11-19 14:28:42 +0000 UTC (1+1 container statuses recorded)
Dec 11 09:55:20.230: INFO: 	Init container init-fluentd ready: true, restart count 0
Dec 11 09:55:20.230: INFO: 	Container fluentd ready: false, restart count 0
Dec 11 09:55:20.230: INFO: calico-node-7px7g started at 2018-11-19 14:28:42 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.230: INFO: 	Container calico-node ready: true, restart count 0
Dec 11 09:55:20.230: INFO: 	Container install-cni ready: true, restart count 0
Dec 11 09:55:20.230: INFO: dns-controller-55fb5dcc77-5nz8k started at 2018-11-19 14:31:24 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.230: INFO: 	Container dns-controller ready: true, restart count 0
Dec 11 09:55:20.230: INFO: calico-kube-controllers-d97b7c4c8-wnnjq started at 2018-11-19 14:52:24 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.230: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec 11 09:55:20.230: INFO: etcd-server-events-ip-172-25-61-224.us-west-1.compute.internal started at <nil> (0+0 container statuses recorded)
Dec 11 09:55:20.230: INFO: etcd-server-ip-172-25-61-224.us-west-1.compute.internal started at <nil> (0+0 container statuses recorded)
W1211 09:55:20.233961      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 11 09:55:20.257: INFO: 
Latency metrics for node ip-172-25-61-224.us-west-1.compute.internal
Dec 11 09:55:20.257: INFO: 
Logging node info for node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:55:20.259: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:ip-172-25-62-1.us-west-1.compute.internal,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/ip-172-25-62-1.us-west-1.compute.internal,UID:119fa5b1-ec1d-11e8-8e03-0681e6464a68,ResourceVersion:21960773,Generation:0,CreationTimestamp:2018-11-19 17:03:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: r4.4xlarge,beta.kubernetes.io/os: linux,failure-domain.beta.kubernetes.io/region: us-west-1,failure-domain.beta.kubernetes.io/zone: us-west-1a,kops.k8s.io/instancegroup: nodes,kubernetes.io/hostname: ip-172-25-62-1.us-west-1.compute.internal,kubernetes.io/role: node,node-role.kubernetes.io/node: ,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:NodeSpec{PodCIDR:100.96.3.0/24,DoNotUse_ExternalID:i-035f158a49803b8b9,ProviderID:aws:///us-west-1a/i-035f158a49803b8b9,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{cpu: {{16 0} {<nil>} 16 DecimalSI},ephemeral-storage: {{137426350080 0} {<nil>} 134205420Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{128672694272 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{16 0} {<nil>} 16 DecimalSI},ephemeral-storage: {{123683714868 0} {<nil>} 123683714868 DecimalSI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{128567836672 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2018-12-11 09:55:12 +0000 UTC 2018-11-19 17:03:42 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2018-12-11 09:55:12 +0000 UTC 2018-11-19 17:03:42 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2018-12-11 09:55:12 +0000 UTC 2018-11-19 17:03:42 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2018-12-11 09:55:12 +0000 UTC 2018-11-19 17:03:42 +0000 UTC KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2018-12-11 09:55:12 +0000 UTC 2018-11-19 17:04:12 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 172.25.62.1} {InternalDNS ip-172-25-62-1.us-west-1.compute.internal} {Hostname ip-172-25-62-1.us-west-1.compute.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:18f25f6ad76748408343b1c33636edf6,SystemUUID:EC2ED1E3-2AFA-BCA8-329C-8DA86B043F95,BootID:d4d18c7a-3d50-49ea-a1f8-223c7974d123,KernelVersion:3.10.0-693.el7.x86_64,OSImage:Red Hat Enterprise Linux Server 7.4 (Maipo),ContainerRuntimeVersion:docker://17.3.2,KubeletVersion:v1.10.6,KubeProxyVersion:v1.10.6,OperatingSystem:linux,Architecture:amd64,},Images:[{[intellectdesigndevteam/qni-illustration-service@sha256:2dbc0c4bddb98df953dae7e1f07ac6eb974b2c69e29581ae14e39dd51ff6a7c1 intellectdesigndevteam/qni-illustration-service:18.4.0-dev] 363345689} {[datadog/agent@sha256:f3427a04d93b0f0b82674be9b7217aba03e064898e2a6c59e94897b8be293823 datadog/agent:6.0.0] 337278068} {[intellectdesigndevteam/ai-sentiment-service@sha256:1b826b7681ae487b5f981e2bdf9b89c87b3bae67faa8e1328c097dc2e4eca363 intellectdesigndevteam/ai-sentiment-service:v18.4.1.1] 336713753} {[intellectdevcloud/platform-filebeat@sha256:393f2e866d3511565997e464359984fa8949c885fc3998c095963325daef20da intellectdevcloud/platform-filebeat:latest] 318649904} {[intellectdesigndevteam/ppc-service@sha256:fb0ee174d747b88899c53b718eb9b58940dd87f842d74b5ac59bcb3dc8b7754b intellectdesigndevteam/ppc-service:dev-18.3.1.78] 317682270} {[intellectdesigndevteam/ppc-ratetables@sha256:830e3145284e3909f7dc3f2a5117719c0700385552eabf54bbd2973e070f356d intellectdesigndevteam/ppc-ratetables:dev-18.3.1.90] 317600861} {[intellectdesigndevteam/ppc-masterdata@sha256:ee86166f586d21bfc6d3af50d9358a1b3aaaad57062b3be090ce172de6a4f0aa intellectdesigndevteam/ppc-masterdata:dev-18.3.1.32] 317132416} {[intellectdesigndevteam/qni-quote-service@sha256:c8d1e58b2a60d495304e765ba0227220f70eae50ab8bcb42ee6ad13950859769 intellectdesigndevteam/qni-quote-service:18.4.0-dev] 305213621} {[quay.io/calico/node@sha256:7758c25549fcfe677699bbcd3c279b3a174e7cbbbf9d16f3d71713d68f695dfb quay.io/calico/node:v2.6.7] 281572001} {[protokube:1.10.0] 278482183} {[intellectdesigndevteam/platform-telephony-service@sha256:71d6f3e29872035c89a8bd3f2bf672d069f2711e3bc50a7a1a8e007f96f2fe8b intellectdesigndevteam/platform-telephony-service:qa-18.3.1.1] 255496670} {[intellectdesigndevteam/platform-config-service@sha256:06b65c100e8716cab80d1eb18a0884d2d9fd4bfd5eefb680c3a7dc484fd27e33 intellectdesigndevteam/platform-config-service:stag-18.3.1.17.1] 250153994} {[intellectdesigndevteam/platform-account-service@sha256:b93f93ee912665999b662494989d8cb0af5c46e6e87d0aaed81a4040c43c1942 intellectdesigndevteam/platform-account-service:stag-18.3.1.22.1] 247829302} {[intellectdesigndevteam/leadcloser-service@sha256:3ec1f000c589dff6cec4ac74e3b2af778195f61aeed034f652d30727acef6323 intellectdesigndevteam/leadcloser-service:dev-18.3.1.57] 237593029} {[intellectdesigndevteam/leadcloser-service@sha256:8ecf7a2a2728badce272f97649ca8874fd8db1646e9a5a60dcfbd6013ad465d9 intellectdesigndevteam/leadcloser-service:dev-18.3.1.86] 237242743} {[fluent/fluentd-kubernetes-daemonset@sha256:752aed38ede9b0bbf7ae411761672d83d60ecc54bfa567972f7c6076713bec9f fluent/fluentd-kubernetes-daemonset:v0.12-debian-elasticsearch] 228009678} {[gcr.io/kubernetes-e2e-test-images/jessie-dnsutils@sha256:ad583e33cb284f7ef046673809b146ec4053cda19b54a85d2b180a86169715eb gcr.io/kubernetes-e2e-test-images/jessie-dnsutils:1.0] 195633300} {[intellectdesigndevteam/botfactory-platform-service@sha256:18883ea4625302ae13d58e151a33cbcbefeaf438f14f5518889573428212f34b intellectdesigndevteam/botfactory-platform-service:qa-1.0.4] 189961031} {[intellectdesigndevteam/botfactory-adapter-service@sha256:ecea13507bb26cb7e90f56ba1d886ae9f9f9b0dce52842fa812fee4813046890 intellectdesigndevteam/botfactory-adapter-service:qa-1.0.2] 179133038} {[intellectdesigndevteam/platform-api-management-ui@sha256:6f6046562ccdde80afd488baa69e90521f8a831a14f3386ddca93ce71aaac285 intellectdesigndevteam/platform-api-management-ui:qa-18.3.1.6] 125219964} {[intellectdesigndevteam/platform-admin-ui@sha256:2c09773e964ca577d3a6ea9159dfef15bff34f2d7f1c6e8ef22a2cff919d3b01 intellectdesigndevteam/platform-admin-ui:qa-18.3.1.6] 121019110} {[intellectdesigndevteam/platform-api-management-ui@sha256:a8d9bfb0f90d06774795d901b98f2c373d0bb6d1fb69d422cfc471a85a2f186a intellectdesigndevteam/platform-api-management-ui:qa-18.3.1.5] 113907865} {[intellectdesigndevteam/platform-admin-ui@sha256:168bcbf6a6cbfe14cac6c975d5b6563af06a606cb0646f9d1f03157acab8ca99 intellectdesigndevteam/platform-admin-ui:qa-18.3.1.5] 109695063} {[nginx@sha256:5d32f60db294b5deb55d078cd4feb410ad88e6fe77500c87d3970eca97f54dba nginx:latest] 109096776} {[bobrik/curator@sha256:8ce8af15b1004da7e977e4a8eba74e338fd8686d705708e7e02db0562b686be9 bobrik/curator:latest] 108526735} {[intellectdesigndevteam/platform-dashboard-ui@sha256:9857882525b36edd28af322684b4a56838a69cfb2316fcfa9021eaf474716edc intellectdesigndevteam/platform-dashboard-ui:qa-18.3.1.6] 103845025} {[intellectdesigndevteam/dss-leadcloser-ui@sha256:876da18e3d331956a4a032dd9b6de6e6d795a8fc68b537d270a228e4554c51aa intellectdesigndevteam/dss-leadcloser-ui:INFRA-3185] 103175252} {[intellectdesigndevteam/dss-ppc-ui@sha256:bca0a9321b60817564383baf99cf1e9b1b0ff784d364373102c6b25e29113de0 intellectdesigndevteam/dss-ppc-ui:18.3.1] 102355561} {[intellectdesigndevteam/platform-account-management-ui@sha256:d2494446e3133ec5e8b2da0ea464e27dd3b60eda41a4accbf9141d4724fb5a41 intellectdesigndevteam/platform-account-management-ui:qa-18.3.1.6] 100282409} {[intellectdesigndevteam/botfactory-ui@sha256:e9c763ac3dd601e9ff9f965390fc3b236f2e85bf20bbbcc4f5f3b7ae930ecdc3 intellectdesigndevteam/botfactory-ui:qa-1.0.3] 99649323} {[intellectdesigndevteam/platform-profile-management-ui@sha256:92ec762dd3287b4d2e6e494ab3ce870f876934c8a970f52e33c496ab471088cc intellectdesigndevteam/platform-profile-management-ui:qa-18.3.1.6] 99094508} {[intellectdesigndevteam/dss-quote-ui@sha256:92e610e927192613435b9420693c9720a1755397e1cc1f8dd60b261abb8e9d0f intellectdesigndevteam/dss-quote-ui:18.4.0] 98515373} {[intellectdesigndevteam/platform-signup-ui@sha256:f0ea5b4fdbc4c6bc312539b4aa4384b2fdae1d3e8cc23aaa707f2f85fb40a025 intellectdesigndevteam/platform-signup-ui:qa-18.3.1.6] 97876153} {[k8s.gcr.io/kube-proxy@sha256:99a9e5ce663a27603a297981156cef2163cb6eee3a2e4fcf958063ec09a4cfc0 k8s.gcr.io/kube-proxy:v1.10.6] 97861102} {[intellectdesigndevteam/platform-dashboard-ui@sha256:39ca7d2277802e3bfe87a6b779d049143b8543aa1bef5fc4a38db93de75789bf intellectdesigndevteam/platform-dashboard-ui:qa-18.3.1.5] 92532926} {[intellectdesigndevteam/platform-account-management-ui@sha256:38b6bac1384c0d3140483e3c6045d0ea7d5acf5bc962ef76ad1c76689ccc5131 intellectdesigndevteam/platform-account-management-ui:qa-18.3.1.5] 88970310} {[intellectdesigndevteam/platform-profile-management-ui@sha256:15ae94ffb55848026ce69c904695ab8c02838758b8b0755f59226500e459d144 intellectdesigndevteam/platform-profile-management-ui:qa-18.3.1.5] 87805996} {[intellectdesigndevteam/platform-signup-ui@sha256:0ff2d304f36a12e7d66beaf2313993c558155deaacbc58e9c6a5a5cbb5416371 intellectdesigndevteam/platform-signup-ui:qa-18.3.1.5] 86564054} {[quay.io/calico/cni@sha256:3a23e093b1e98cf232a226fedff591d33919f5297f016a41d8012efc83b23a84 quay.io/calico/cni:v1.11.2] 70781000} {[gcr.io/heptio-images/namespace-deleter@sha256:3ae93c027111ac894a5093663572e1afd5872597d7ecc6af0a2a75d6e6be8b3d gcr.io/heptio-images/namespace-deleter:v0.0.1] 43012728} {[gcr.io/heptio-images/sonobuoy@sha256:11d129bc56862d008e3351a458faa3ca36a0780cb25efa38a54d163ebc150c77 gcr.io/heptio-images/sonobuoy:v0.13] 33389023} {[nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 nginx:1.14-alpine] 17719543} {[gcr.io/heptio-images/scanner-forwarder@sha256:a4a1761a4cb5c6aed71302e8a605926cc297c58907018fefe5436a65aaaf884f gcr.io/heptio-images/scanner-forwarder:v0.0.4] 10882452} {[gcr.io/kubernetes-e2e-test-images/dnsutils@sha256:2abeee84efb79c14d731966e034af33bf324d3b26ca28497555511ff094b3ddd gcr.io/kubernetes-e2e-test-images/dnsutils:1.1] 9345437} {[gcr.io/kubernetes-e2e-test-images/hostexec@sha256:90dfe59da029f9e536385037bc64e86cd3d6e55bae613ddbe69e554d79b0639d gcr.io/kubernetes-e2e-test-images/hostexec:1.1] 8467158} {[odise/busybox-curl@sha256:815ad8389785898c19a63afcaca0df0026a6574731ffd44daf2ae0f885c21fda odise/busybox-curl:stable] 7070717} {[gcr.io/kubernetes-e2e-test-images/netexec@sha256:203f0e11dde4baf4b08e27de094890eb3447d807c8b3e990b764b799d3a9e8b7 gcr.io/kubernetes-e2e-test-images/netexec:1.1] 6705349} {[gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 gcr.io/kubernetes-e2e-test-images/redis:1.0] 5901328} {[gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1] 5851985} {[gcr.io/kubernetes-e2e-test-images/test-webserver@sha256:7f93d6e32798ff28bc6289254d0c2867fe2c849c8e46edc50f8624734309812e gcr.io/kubernetes-e2e-test-images/test-webserver:1.0] 4732240}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
Dec 11 09:55:20.259: INFO: 
Logging kubelet events for node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:55:20.261: INFO: 
Logging pods the kubelet thinks is on node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:55:20.271: INFO: prd-dss-quote-ui-7475c4bdc-lg6c6 started at 2018-11-21 10:07:09 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.271: INFO: 	Container dss-quote-ui ready: true, restart count 0
Dec 11 09:55:20.271: INFO: prd-botfactory-ui-pfm-botfactory-ui-7ff78b89f7-xnmkr started at 2018-11-21 11:30:22 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.271: INFO: 	Container pfm-botfactory-ui ready: true, restart count 0
Dec 11 09:55:20.271: INFO: prd-dss-qni-quote-svc-dss-qni-quote-service-84cbc8c6c8-qm5jw started at 2018-11-26 11:13:14 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.271: INFO: 	Container dss-qni-quote-service ready: true, restart count 0
Dec 11 09:55:20.271: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.271: INFO: datadog-datadog-lqmmz started at 2018-11-19 17:03:43 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.271: INFO: 	Container datadog ready: true, restart count 0
Dec 11 09:55:20.271: INFO: calico-node-trxzw started at 2018-11-19 17:03:43 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.271: INFO: 	Container calico-node ready: true, restart count 0
Dec 11 09:55:20.271: INFO: 	Container install-cni ready: true, restart count 0
Dec 11 09:55:20.271: INFO: prd-efk-elasticsearch-client-8655b8d9b9-vbpbh started at 2018-12-11 09:54:52 +0000 UTC (1+1 container statuses recorded)
Dec 11 09:55:20.271: INFO: 	Init container init-sysctl ready: true, restart count 0
Dec 11 09:55:20.271: INFO: 	Container es-client ready: false, restart count 0
Dec 11 09:55:20.271: INFO: prd-dss-lc-svc-dss-lc-service-6c8748f77b-7sj75 started at 2018-11-20 13:24:04 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.271: INFO: 	Container dss-lc-service ready: true, restart count 0
Dec 11 09:55:20.271: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.271: INFO: prd-ibf-botfactory-platform-svc-botfactory-platform-servicszx9g started at 2018-11-21 11:04:39 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.271: INFO: 	Container botfactory-platform-service ready: true, restart count 0
Dec 11 09:55:20.271: INFO: sonobuoy started at 2018-12-11 09:12:13 +0000 UTC (0+3 container statuses recorded)
Dec 11 09:55:20.271: INFO: 	Container cleanup ready: true, restart count 0
Dec 11 09:55:20.271: INFO: 	Container forwarder ready: true, restart count 0
Dec 11 09:55:20.271: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 11 09:55:20.271: INFO: prd-efk-elasticsearch-curator-1544317200-qxdt5 started at 2018-12-09 01:00:06 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.271: INFO: 	Container curator ready: false, restart count 0
Dec 11 09:55:20.271: INFO: prd-dss-leadcloser-ui-658768bd4b-zbbdr started at 2018-11-20 12:27:05 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.271: INFO: 	Container dss-leadcloser-ui ready: true, restart count 0
Dec 11 09:55:20.271: INFO: prd-dss-ppc-ratetables-ppc-svc-cfb7cd6b9-6qcrh started at 2018-11-26 11:48:21 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.271: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.271: INFO: 	Container ppc-svc ready: true, restart count 0
Dec 11 09:55:20.271: INFO: prd-pf-apimgmt-ui-platform-apimgmt-ui-699d4df9d-nb79x started at 2018-11-20 11:37:39 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.271: INFO: 	Container platform-apimgmt-ui ready: true, restart count 0
Dec 11 09:55:20.271: INFO: prd-efk-elasticsearch-curator-1544403600-dgbl8 started at 2018-12-10 01:00:08 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.271: INFO: 	Container curator ready: false, restart count 0
Dec 11 09:55:20.271: INFO: prd-pf-signup-ui-platform-signup-ui-54ffdd6f94-pzb82 started at 2018-11-20 11:30:55 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.271: INFO: 	Container platform-signup-ui ready: true, restart count 0
Dec 11 09:55:20.271: INFO: prd-efk-elasticsearch-curator-1544490000-4wpv9 started at 2018-12-11 01:00:07 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.271: INFO: 	Container curator ready: false, restart count 0
Dec 11 09:55:20.271: INFO: prd-dss-ppc-ui-64f9cf489c-zj4pk started at 2018-11-20 14:04:47 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.271: INFO: 	Container dss-ppc-ui ready: true, restart count 0
Dec 11 09:55:20.271: INFO: prd-dss-ppc-masterdata-ppc-svc-7d8577dd7c-pb92m started at 2018-11-26 11:42:41 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.271: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.271: INFO: 	Container ppc-svc ready: true, restart count 0
Dec 11 09:55:20.271: INFO: prd-ai-sentiment-eng-svc-ai-sentiment-svc-69bd5d994b-7wcr2 started at 2018-11-20 13:34:13 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.271: INFO: 	Container prd-ai-sentiment-eng-svc-ai-sentiment-svc ready: true, restart count 0
Dec 11 09:55:20.271: INFO: prd-ibf-botfactory-adapter-svc-botfactory-adapter-service-p5vcf started at 2018-11-21 11:11:42 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.271: INFO: 	Container botfactory-adapter-service ready: true, restart count 0
Dec 11 09:55:20.271: INFO: prd-efk-elasticsearch-kibana-654b6d5965-9qdfj started at 2018-12-11 09:54:52 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.271: INFO: 	Container kibana ready: true, restart count 0
Dec 11 09:55:20.271: INFO: prd-pf-acc-svc-platform-acc-svc-56c66dc6bc-jl2qm started at 2018-11-20 08:35:58 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.271: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.271: INFO: 	Container prd-pf-acc-svc-platform-acc-svc ready: true, restart count 0
Dec 11 09:55:20.271: INFO: kube-proxy-ip-172-25-62-1.us-west-1.compute.internal started at <nil> (0+0 container statuses recorded)
Dec 11 09:55:20.271: INFO: prd-pfm-svc-telephony-55658c585-sp22g started at 2018-11-20 08:24:26 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.271: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.271: INFO: 	Container prd-pf-telephony-svc-prd-pfm-svc-telephony ready: true, restart count 0
Dec 11 09:55:20.271: INFO: busybox-host-aliasese1ff809a-fd24-11e8-897d-5ac57959ef46 started at 2018-12-11 09:54:18 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.271: INFO: 	Container busybox-host-aliasese1ff809a-fd24-11e8-897d-5ac57959ef46 ready: true, restart count 0
Dec 11 09:55:20.271: INFO: prd-pf-admin-ui-platform-admin-ui-85c98dcc66-9vj7s started at 2018-11-20 11:40:28 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.272: INFO: 	Container platform-admin-ui ready: true, restart count 0
Dec 11 09:55:20.272: INFO: prd-pf-prflmgmt-ui-platform-prflmgmt-ui-654ff59c99-tl62p started at 2018-11-20 11:46:41 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.272: INFO: 	Container platform-prflmgmt-ui ready: true, restart count 0
Dec 11 09:55:20.272: INFO: prd-dss-ppc-svc-ppc-svc-58f5d567d-8msxj started at 2018-11-26 11:36:47 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.272: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.272: INFO: 	Container ppc-svc ready: true, restart count 0
Dec 11 09:55:20.272: INFO: prd-efk-elasticsearch-fluentd-t6bxk started at 2018-11-19 17:03:43 +0000 UTC (1+1 container statuses recorded)
Dec 11 09:55:20.272: INFO: 	Init container init-fluentd ready: true, restart count 0
Dec 11 09:55:20.272: INFO: 	Container fluentd ready: true, restart count 0
Dec 11 09:55:20.272: INFO: prd-pf-conf-svc-platform-conf-svc-6f8c9c5649-hrx2v started at 2018-11-20 08:43:48 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.272: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.272: INFO: 	Container prd-pf-conf-svc-platform-conf-svc ready: true, restart count 0
Dec 11 09:55:20.272: INFO: prd-pf-dashboard-ui-platform-dashboard-ui-859cf5d999-9qp8v started at 2018-11-20 11:23:38 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.272: INFO: 	Container platform-dashboard-ui ready: true, restart count 0
Dec 11 09:55:20.272: INFO: prd-pf-dashboard-ui-platform-dashboard-ui-859cf5d999-mwwgd started at 2018-11-20 11:23:32 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.272: INFO: 	Container platform-dashboard-ui ready: true, restart count 0
Dec 11 09:55:20.272: INFO: prd-pf-accmgmt-ui-platform-accmgmt-ui-5cbc4c9d66-krr5g started at 2018-11-20 11:50:04 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.272: INFO: 	Container platform-accmgmt-ui ready: true, restart count 0
W1211 09:55:20.275361      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 11 09:55:20.309: INFO: 
Latency metrics for node ip-172-25-62-1.us-west-1.compute.internal
Dec 11 09:55:20.309: INFO: {Operation:stop_container Method:docker_operations_latency_microseconds Quantile:0.99 Latency:30.04662s}
Dec 11 09:55:20.309: INFO: 
Logging node info for node ip-172-25-62-180.us-west-1.compute.internal
Dec 11 09:55:20.311: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:ip-172-25-62-180.us-west-1.compute.internal,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/ip-172-25-62-180.us-west-1.compute.internal,UID:5489cb6c-ec05-11e8-8e03-0681e6464a68,ResourceVersion:21960780,Generation:0,CreationTimestamp:2018-11-19 14:13:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: c4.2xlarge,beta.kubernetes.io/os: linux,failure-domain.beta.kubernetes.io/region: us-west-1,failure-domain.beta.kubernetes.io/zone: us-west-1a,kops.k8s.io/instancegroup: master-us-west-1a-1,kubernetes.io/hostname: ip-172-25-62-180.us-west-1.compute.internal,kubernetes.io/role: master,node-role.kubernetes.io/master: ,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:NodeSpec{PodCIDR:100.96.9.0/24,DoNotUse_ExternalID:i-07ea9375fa375b708,ProviderID:aws:///us-west-1a/i-07ea9375fa375b708,Unschedulable:false,Taints:[{node-role.kubernetes.io/master  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{cpu: {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage: {{68706873344 0} {<nil>} 67096556Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{15600160768 0} {<nil>} 15234532Ki BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage: {{61836185908 0} {<nil>} 61836185908 DecimalSI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{15495303168 0} {<nil>} 15132132Ki BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2018-12-11 09:55:14 +0000 UTC 2018-11-19 14:13:43 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2018-12-11 09:55:14 +0000 UTC 2018-11-19 14:13:43 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2018-12-11 09:55:14 +0000 UTC 2018-11-19 14:13:43 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2018-12-11 09:55:14 +0000 UTC 2018-11-19 14:13:43 +0000 UTC KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2018-12-11 09:55:14 +0000 UTC 2018-11-19 14:14:07 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 172.25.62.180} {InternalDNS ip-172-25-62-180.us-west-1.compute.internal} {Hostname ip-172-25-62-180.us-west-1.compute.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:3fae03a9ff024c86b61fd4f52ad2438f,SystemUUID:EC27A1F3-97F8-95F3-8C9F-E5C62C1C4E85,BootID:7bcb3bd8-237e-4f14-93db-4adafd1289bb,KernelVersion:3.10.0-693.el7.x86_64,OSImage:Red Hat Enterprise Linux Server 7.4 (Maipo),ContainerRuntimeVersion:docker://17.3.2,KubeletVersion:v1.10.6,KubeProxyVersion:v1.10.6,OperatingSystem:linux,Architecture:amd64,},Images:[{[quay.io/calico/node@sha256:7758c25549fcfe677699bbcd3c279b3a174e7cbbbf9d16f3d71713d68f695dfb quay.io/calico/node:v2.6.7] 281572001} {[protokube:1.10.0] 278482183} {[k8s.gcr.io/kube-apiserver@sha256:3283c534aab386bc678986c74c2fc855db46b3f424884d547641c82dba6ec5de k8s.gcr.io/kube-apiserver:v1.10.6] 228066280} {[fluent/fluentd-kubernetes-daemonset@sha256:752aed38ede9b0bbf7ae411761672d83d60ecc54bfa567972f7c6076713bec9f fluent/fluentd-kubernetes-daemonset:v0.12-debian-elasticsearch] 228009678} {[k8s.gcr.io/kube-controller-manager@sha256:93bbd2218a04253db98438ee49d9512359ee9d2a89e2a4247d520b21296acfd6 k8s.gcr.io/kube-controller-manager:v1.10.6] 150824264} {[k8s.gcr.io/kube-proxy@sha256:99a9e5ce663a27603a297981156cef2163cb6eee3a2e4fcf958063ec09a4cfc0 k8s.gcr.io/kube-proxy:v1.10.6] 97861102} {[quay.io/calico/cni@sha256:3a23e093b1e98cf232a226fedff591d33919f5297f016a41d8012efc83b23a84 quay.io/calico/cni:v1.11.2] 70781000} {[k8s.gcr.io/kube-scheduler@sha256:83eb7da923c75ef02fd0f8665b2411d6f3bf5e2df0de35849890c65a3d667d7a k8s.gcr.io/kube-scheduler:v1.10.6] 51215735} {[k8s.gcr.io/etcd@sha256:19544a655157fb089b62d4dac02bbd095f82ca245dd5e31dd1684d175b109947 k8s.gcr.io/etcd:2.2.1] 28191895} {[odise/busybox-curl@sha256:815ad8389785898c19a63afcaca0df0026a6574731ffd44daf2ae0f885c21fda odise/busybox-curl:stable] 7070717} {[k8s.gcr.io/pause-amd64@sha256:163ac025575b775d1c0f9bf0bdd0f086883171eb475b5068e7defa4ca9e76516 k8s.gcr.io/pause-amd64:3.0] 746888}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
Dec 11 09:55:20.311: INFO: 
Logging kubelet events for node ip-172-25-62-180.us-west-1.compute.internal
Dec 11 09:55:20.313: INFO: 
Logging pods the kubelet thinks is on node ip-172-25-62-180.us-west-1.compute.internal
Dec 11 09:55:20.323: INFO: calico-node-z2gn6 started at 2018-11-19 14:13:47 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.323: INFO: 	Container calico-node ready: true, restart count 0
Dec 11 09:55:20.323: INFO: 	Container install-cni ready: true, restart count 0
Dec 11 09:55:20.323: INFO: etcd-server-events-ip-172-25-62-180.us-west-1.compute.internal started at <nil> (0+0 container statuses recorded)
Dec 11 09:55:20.323: INFO: etcd-server-ip-172-25-62-180.us-west-1.compute.internal started at <nil> (0+0 container statuses recorded)
Dec 11 09:55:20.323: INFO: kube-apiserver-ip-172-25-62-180.us-west-1.compute.internal started at <nil> (0+0 container statuses recorded)
Dec 11 09:55:20.323: INFO: kube-controller-manager-ip-172-25-62-180.us-west-1.compute.internal started at <nil> (0+0 container statuses recorded)
Dec 11 09:55:20.323: INFO: kube-proxy-ip-172-25-62-180.us-west-1.compute.internal started at <nil> (0+0 container statuses recorded)
Dec 11 09:55:20.323: INFO: kube-scheduler-ip-172-25-62-180.us-west-1.compute.internal started at <nil> (0+0 container statuses recorded)
Dec 11 09:55:20.323: INFO: prd-efk-elasticsearch-fluentd-d8gqp started at 2018-11-19 14:13:47 +0000 UTC (1+1 container statuses recorded)
Dec 11 09:55:20.323: INFO: 	Init container init-fluentd ready: true, restart count 0
Dec 11 09:55:20.323: INFO: 	Container fluentd ready: false, restart count 0
W1211 09:55:20.326865      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 11 09:55:20.350: INFO: 
Latency metrics for node ip-172-25-62-180.us-west-1.compute.internal
Dec 11 09:55:20.350: INFO: 
Logging node info for node ip-172-25-84-67.us-west-1.compute.internal
Dec 11 09:55:20.352: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:ip-172-25-84-67.us-west-1.compute.internal,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/ip-172-25-84-67.us-west-1.compute.internal,UID:58aa1dd3-ec0a-11e8-b4a2-0219198c6576,ResourceVersion:21960772,Generation:0,CreationTimestamp:2018-11-19 14:49:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: c4.2xlarge,beta.kubernetes.io/os: linux,failure-domain.beta.kubernetes.io/region: us-west-1,failure-domain.beta.kubernetes.io/zone: us-west-1b,kops.k8s.io/instancegroup: master-us-west-1b-1,kubernetes.io/hostname: ip-172-25-84-67.us-west-1.compute.internal,kubernetes.io/role: master,node-role.kubernetes.io/master: ,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:NodeSpec{PodCIDR:100.96.0.0/24,DoNotUse_ExternalID:i-07f6eec792b90de36,ProviderID:aws:///us-west-1b/i-07f6eec792b90de36,Unschedulable:false,Taints:[{node-role.kubernetes.io/master  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{cpu: {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage: {{68706873344 0} {<nil>} 67096556Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{15600160768 0} {<nil>} 15234532Ki BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage: {{61836185908 0} {<nil>} 61836185908 DecimalSI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{15495303168 0} {<nil>} 15132132Ki BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2018-12-11 09:55:12 +0000 UTC 2018-11-19 14:49:37 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2018-12-11 09:55:12 +0000 UTC 2018-11-19 14:49:37 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2018-12-11 09:55:12 +0000 UTC 2018-11-19 14:49:37 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2018-12-11 09:55:12 +0000 UTC 2018-11-19 14:49:37 +0000 UTC KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2018-12-11 09:55:12 +0000 UTC 2018-11-19 14:50:01 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 172.25.84.67} {InternalDNS ip-172-25-84-67.us-west-1.compute.internal} {Hostname ip-172-25-84-67.us-west-1.compute.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:596fc367b0d54f6789a3d8658dc51e41,SystemUUID:EC2BB0A6-71A0-1568-83CD-30B2523805CE,BootID:a7474875-0e03-47fc-853d-d1990ff96a49,KernelVersion:3.10.0-693.el7.x86_64,OSImage:Red Hat Enterprise Linux Server 7.4 (Maipo),ContainerRuntimeVersion:docker://17.3.2,KubeletVersion:v1.10.6,KubeProxyVersion:v1.10.6,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/heptio-images/kube-conformance@sha256:ad05dd6563350277db4706010fbc237a4f25c558caa9d27a12be266055a48801 gcr.io/heptio-images/kube-conformance:latest] 462484279} {[quay.io/calico/node@sha256:7758c25549fcfe677699bbcd3c279b3a174e7cbbbf9d16f3d71713d68f695dfb quay.io/calico/node:v2.6.7] 281572001} {[protokube:1.10.0] 278482183} {[k8s.gcr.io/kube-apiserver@sha256:3283c534aab386bc678986c74c2fc855db46b3f424884d547641c82dba6ec5de k8s.gcr.io/kube-apiserver:v1.10.6] 228066280} {[fluent/fluentd-kubernetes-daemonset@sha256:752aed38ede9b0bbf7ae411761672d83d60ecc54bfa567972f7c6076713bec9f fluent/fluentd-kubernetes-daemonset:v0.12-debian-elasticsearch] 228009678} {[k8s.gcr.io/kube-controller-manager@sha256:93bbd2218a04253db98438ee49d9512359ee9d2a89e2a4247d520b21296acfd6 k8s.gcr.io/kube-controller-manager:v1.10.6] 150824264} {[k8s.gcr.io/kube-proxy@sha256:99a9e5ce663a27603a297981156cef2163cb6eee3a2e4fcf958063ec09a4cfc0 k8s.gcr.io/kube-proxy:v1.10.6] 97861102} {[quay.io/calico/cni@sha256:3a23e093b1e98cf232a226fedff591d33919f5297f016a41d8012efc83b23a84 quay.io/calico/cni:v1.11.2] 70781000} {[k8s.gcr.io/kube-scheduler@sha256:83eb7da923c75ef02fd0f8665b2411d6f3bf5e2df0de35849890c65a3d667d7a k8s.gcr.io/kube-scheduler:v1.10.6] 51215735} {[gcr.io/heptio-images/sonobuoy@sha256:11d129bc56862d008e3351a458faa3ca36a0780cb25efa38a54d163ebc150c77 gcr.io/heptio-images/sonobuoy:v0.13] 33389023} {[k8s.gcr.io/etcd@sha256:19544a655157fb089b62d4dac02bbd095f82ca245dd5e31dd1684d175b109947 k8s.gcr.io/etcd:2.2.1] 28191895} {[odise/busybox-curl@sha256:815ad8389785898c19a63afcaca0df0026a6574731ffd44daf2ae0f885c21fda odise/busybox-curl:stable] 7070717} {[k8s.gcr.io/pause-amd64@sha256:163ac025575b775d1c0f9bf0bdd0f086883171eb475b5068e7defa4ca9e76516 k8s.gcr.io/pause-amd64:3.0] 746888}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
Dec 11 09:55:20.353: INFO: 
Logging kubelet events for node ip-172-25-84-67.us-west-1.compute.internal
Dec 11 09:55:20.355: INFO: 
Logging pods the kubelet thinks is on node ip-172-25-84-67.us-west-1.compute.internal
Dec 11 09:55:20.374: INFO: etcd-server-events-ip-172-25-84-67.us-west-1.compute.internal started at <nil> (0+0 container statuses recorded)
Dec 11 09:55:20.374: INFO: etcd-server-ip-172-25-84-67.us-west-1.compute.internal started at <nil> (0+0 container statuses recorded)
Dec 11 09:55:20.374: INFO: kube-apiserver-ip-172-25-84-67.us-west-1.compute.internal started at <nil> (0+0 container statuses recorded)
Dec 11 09:55:20.374: INFO: kube-proxy-ip-172-25-84-67.us-west-1.compute.internal started at <nil> (0+0 container statuses recorded)
Dec 11 09:55:20.374: INFO: calico-node-27rw4 started at 2018-11-19 14:49:41 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.374: INFO: 	Container calico-node ready: true, restart count 0
Dec 11 09:55:20.374: INFO: 	Container install-cni ready: true, restart count 0
Dec 11 09:55:20.374: INFO: prd-efk-elasticsearch-fluentd-jhbrx started at 2018-11-19 14:49:41 +0000 UTC (1+1 container statuses recorded)
Dec 11 09:55:20.374: INFO: 	Init container init-fluentd ready: true, restart count 0
Dec 11 09:55:20.374: INFO: 	Container fluentd ready: true, restart count 0
Dec 11 09:55:20.374: INFO: kube-controller-manager-ip-172-25-84-67.us-west-1.compute.internal started at <nil> (0+0 container statuses recorded)
Dec 11 09:55:20.374: INFO: kube-scheduler-ip-172-25-84-67.us-west-1.compute.internal started at <nil> (0+0 container statuses recorded)
Dec 11 09:55:20.374: INFO: sonobuoy-e2e-job-20dd198901204d4d started at 2018-12-11 09:12:16 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.374: INFO: 	Container e2e ready: true, restart count 0
Dec 11 09:55:20.374: INFO: 	Container sonobuoy-worker ready: true, restart count 0
W1211 09:55:20.377601      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 11 09:55:20.396: INFO: 
Latency metrics for node ip-172-25-84-67.us-west-1.compute.internal
Dec 11 09:55:20.396: INFO: 
Logging node info for node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:55:20.399: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:ip-172-25-93-75.us-west-1.compute.internal,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/ip-172-25-93-75.us-west-1.compute.internal,UID:ad10fac3-ec1b-11e8-b4a2-0219198c6576,ResourceVersion:21960788,Generation:0,CreationTimestamp:2018-11-19 16:53:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: r4.4xlarge,beta.kubernetes.io/os: linux,failure-domain.beta.kubernetes.io/region: us-west-1,failure-domain.beta.kubernetes.io/zone: us-west-1b,kops.k8s.io/instancegroup: nodes,kubernetes.io/hostname: ip-172-25-93-75.us-west-1.compute.internal,kubernetes.io/role: node,node-role.kubernetes.io/node: ,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:NodeSpec{PodCIDR:100.96.2.0/24,DoNotUse_ExternalID:i-00c94fcff533a9f28,ProviderID:aws:///us-west-1b/i-00c94fcff533a9f28,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{cpu: {{16 0} {<nil>} 16 DecimalSI},ephemeral-storage: {{137426350080 0} {<nil>} 134205420Ki BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{128672694272 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{16 0} {<nil>} 16 DecimalSI},ephemeral-storage: {{123683714868 0} {<nil>} 123683714868 DecimalSI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{128567836672 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2018-12-11 09:55:19 +0000 UTC 2018-11-19 16:53:44 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2018-12-11 09:55:19 +0000 UTC 2018-11-19 16:53:44 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2018-12-11 09:55:19 +0000 UTC 2018-11-19 16:53:44 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2018-12-11 09:55:19 +0000 UTC 2018-11-19 16:53:44 +0000 UTC KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2018-12-11 09:55:19 +0000 UTC 2018-11-19 16:54:54 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 172.25.93.75} {InternalDNS ip-172-25-93-75.us-west-1.compute.internal} {Hostname ip-172-25-93-75.us-west-1.compute.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:fc3eb768d0ac4f9fa0110e149402c00e,SystemUUID:EC206936-51AD-2905-BD22-C891A7CEAC94,BootID:8f0e5b68-6543-4555-a555-6d2803b61eee,KernelVersion:3.10.0-693.el7.x86_64,OSImage:Red Hat Enterprise Linux Server 7.4 (Maipo),ContainerRuntimeVersion:docker://17.3.2,KubeletVersion:v1.10.6,KubeProxyVersion:v1.10.6,OperatingSystem:linux,Architecture:amd64,},Images:[{[intellectdesigndevteam/keycloak@sha256:04745df1a705938a69a680ef1f218fa05acd3ddeae05ed0b27059cac77d079bd intellectdesigndevteam/keycloak:HEAD.138] 776327486} {[quay.io/kubernetes-ingress-controller/nginx-ingress-controller@sha256:f6180c5397d2361c317aff1314dc192ab0f9f515346a5319422cdc264f05d2d9 quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.20.0] 513053329} {[intellectdesigndevteam/platform-document-service@sha256:f03450a8ad1d44a2398de68a4e74211ed3f6206bff7d54c7c0430c9ae43e925f intellectdesigndevteam/platform-document-service:qa-18.3.1.19] 382667587} {[intellectdesigndevteam/qni-illustration-service@sha256:2dbc0c4bddb98df953dae7e1f07ac6eb974b2c69e29581ae14e39dd51ff6a7c1 intellectdesigndevteam/qni-illustration-service:18.4.0-dev] 363345689} {[datadog/agent@sha256:f3427a04d93b0f0b82674be9b7217aba03e064898e2a6c59e94897b8be293823 datadog/agent:6.0.0] 337278068} {[intellectdesigndevteam/ai-sentiment-service@sha256:1b826b7681ae487b5f981e2bdf9b89c87b3bae67faa8e1328c097dc2e4eca363 intellectdesigndevteam/ai-sentiment-service:v18.4.1.1] 336713753} {[intellectdevcloud/platform-filebeat@sha256:393f2e866d3511565997e464359984fa8949c885fc3998c095963325daef20da intellectdevcloud/platform-filebeat:latest] 318649904} {[intellectdesigndevteam/platform-bulkuserimport-service@sha256:3cc549cb89e2987f129157d3706d2f36abe0ca63e1cc5e14751134968724c9f5 intellectdesigndevteam/platform-bulkuserimport-service:qa-18.3.1.19] 315312535} {[intellectdesigndevteam/platform-data-service@sha256:b11e43b1a1dc43060d9633936625e934e3e0d37bc4f021c5e2d0719933d67250 intellectdesigndevteam/platform-data-service:qa-18.3.1.6] 297525539} {[quay.io/calico/node@sha256:7758c25549fcfe677699bbcd3c279b3a174e7cbbbf9d16f3d71713d68f695dfb quay.io/calico/node:v2.6.7] 281572001} {[protokube:1.10.0] 278482183} {[intellectdesigndevteam/platform-signup-service@sha256:c47bdd7deef21a19e3165e2d144c562794e994320d74276839e8455e04e83643 intellectdesigndevteam/platform-signup-service:qa-18.3.1.16] 270601639} {[intellectdesigndevteam/platform-iam-service@sha256:d8d4429e9b83213cd7597411359575b9999dc32f8b911aecedd7d74ec574e7ee intellectdesigndevteam/platform-iam-service:qa-18.3.1.26] 265195612} {[intellectdevcloud/pm-profile-service@sha256:f0e96b993041268fab1cb2ea9b0822135c0580c65d1260e865491639f044ecbd intellectdevcloud/pm-profile-service:18.2.0.1-150618-k8s] 263694180} {[intellectdesigndevteam/platform-telephony-service@sha256:71d6f3e29872035c89a8bd3f2bf672d069f2711e3bc50a7a1a8e007f96f2fe8b intellectdesigndevteam/platform-telephony-service:qa-18.3.1.1] 255496670} {[intellectdesigndevteam/platform-calendar-service@sha256:e77b861007c53296e66fb457c5e5578906a25f8b4cfd2161d1895509f3c5a8bc intellectdesigndevteam/platform-calendar-service:qa-18.3.1.20] 253851461} {[intellectdesigndevteam/platform-contact-service@sha256:feaac96a8e27ed41579d61aee99676d6e0bf5a211b9f952b90fae829dfceaa67 intellectdesigndevteam/platform-contact-service:qa-18.3.1.16] 253833597} {[intellectdesigndevteam/platform-notification-service@sha256:7d5d03a40c32661827903b5f6f616a252311d59b0297e24ef4d8da5974d588b5 intellectdesigndevteam/platform-notification-service:qa-18.3.1.19] 250643389} {[intellectdesigndevteam/platform-config-service@sha256:06b65c100e8716cab80d1eb18a0884d2d9fd4bfd5eefb680c3a7dc484fd27e33 intellectdesigndevteam/platform-config-service:stag-18.3.1.17.1] 250153994} {[intellectdesigndevteam/platform-activity-service@sha256:09d1fdad637da213bc1d9fac6ebc696d4f279677fe7a87b7c683f8043c2dd15b intellectdesigndevteam/platform-activity-service:qa-18.3.1.18] 249015063} {[intellectdesigndevteam/platform-account-service@sha256:b93f93ee912665999b662494989d8cb0af5c46e6e87d0aaed81a4040c43c1942 intellectdesigndevteam/platform-account-service:stag-18.3.1.22.1] 247829302} {[intellectdesigndevteam/platform-audit-service@sha256:6fd07e5804be5f2c50f171440cfcd683c8a0fc5462cc658e76e147a69aabc1ef intellectdesigndevteam/platform-audit-service:qa-18.3.1.20] 244793295} {[intellectdesigndevteam/platform-notes-service@sha256:fe7a79441bbfc780ba0e120dce6b3a3745f39f07bf8549abec7211f1fecdcdbb intellectdesigndevteam/platform-notes-service:qa-18.3.1.15] 242664197} {[intellectdesigndevteam/platform-email-service@sha256:9e56b9b3b9a57d070a36a218cd0d701313c961dc618e0cdd0666345c40adc5b7 intellectdesigndevteam/platform-email-service:qa-18.3.1.14] 241218721} {[intellectdesigndevteam/leadcloser-service@sha256:3ec1f000c589dff6cec4ac74e3b2af778195f61aeed034f652d30727acef6323 intellectdesigndevteam/leadcloser-service:dev-18.3.1.57] 237593029} {[intellectdesigndevteam/leadcloser-service@sha256:8ecf7a2a2728badce272f97649ca8874fd8db1646e9a5a60dcfbd6013ad465d9 intellectdesigndevteam/leadcloser-service:dev-18.3.1.86] 237242743} {[intellectdesigndevteam/pgpool@sha256:672d1b41d58c9b7c849de2d8d0c042b3a913b358a7b38f042e83d44cd46e3a0c intellectdesigndevteam/pgpool:HEAD.138] 228082404} {[fluent/fluentd-kubernetes-daemonset@sha256:752aed38ede9b0bbf7ae411761672d83d60ecc54bfa567972f7c6076713bec9f fluent/fluentd-kubernetes-daemonset:v0.12-debian-elasticsearch] 228009678} {[intellectdesigndevteam/leadcloser-bulkupload-service@sha256:106f3c3aee6b5c5bb7c1304bf379aaad673de259965a29b8a588cdd40f45f51e intellectdesigndevteam/leadcloser-bulkupload-service:dev-18.3.1.32] 216168459} {[intellectdesigndevteam/platform-api-management-ui@sha256:6f6046562ccdde80afd488baa69e90521f8a831a14f3386ddca93ce71aaac285 intellectdesigndevteam/platform-api-management-ui:qa-18.3.1.6] 125219964} {[quay.io/pires/docker-elasticsearch-kubernetes@sha256:62d1dbf7b7c0a47a560b97a53753c980be62c719db55c3fc9128d7a9315daa1e quay.io/pires/docker-elasticsearch-kubernetes:6.0.0] 122667485} {[intellectdesigndevteam/platform-admin-ui@sha256:2c09773e964ca577d3a6ea9159dfef15bff34f2d7f1c6e8ef22a2cff919d3b01 intellectdesigndevteam/platform-admin-ui:qa-18.3.1.6] 121019110} {[intellectdesigndevteam/platform-api-management-ui@sha256:a8d9bfb0f90d06774795d901b98f2c373d0bb6d1fb69d422cfc471a85a2f186a intellectdesigndevteam/platform-api-management-ui:qa-18.3.1.5] 113907865} {[intellectdesigndevteam/platform-admin-ui@sha256:168bcbf6a6cbfe14cac6c975d5b6563af06a606cb0646f9d1f03157acab8ca99 intellectdesigndevteam/platform-admin-ui:qa-18.3.1.5] 109695063} {[intellectdesigndevteam/dss-leadcloser-ui@sha256:ebefb74aff30c289ba5a83a715a5ac732ae6c64686d003550aae247f1bf8eba2 intellectdesigndevteam/dss-leadcloser-ui:18.3.1] 102985492} {[intellectdesigndevteam/dss-ppc-ui@sha256:bca0a9321b60817564383baf99cf1e9b1b0ff784d364373102c6b25e29113de0 intellectdesigndevteam/dss-ppc-ui:18.3.1] 102355561} {[intellectdesigndevteam/platform-account-management-ui@sha256:d2494446e3133ec5e8b2da0ea464e27dd3b60eda41a4accbf9141d4724fb5a41 intellectdesigndevteam/platform-account-management-ui:qa-18.3.1.6] 100282409} {[intellectdesigndevteam/botfactory-ui@sha256:e9c763ac3dd601e9ff9f965390fc3b236f2e85bf20bbbcc4f5f3b7ae930ecdc3 intellectdesigndevteam/botfactory-ui:qa-1.0.3] 99649323} {[intellectdesigndevteam/platform-profile-management-ui@sha256:92ec762dd3287b4d2e6e494ab3ce870f876934c8a970f52e33c496ab471088cc intellectdesigndevteam/platform-profile-management-ui:qa-18.3.1.6] 99094508} {[intellectdesigndevteam/platform-signup-ui@sha256:f0ea5b4fdbc4c6bc312539b4aa4384b2fdae1d3e8cc23aaa707f2f85fb40a025 intellectdesigndevteam/platform-signup-ui:qa-18.3.1.6] 97876153} {[k8s.gcr.io/kube-proxy@sha256:99a9e5ce663a27603a297981156cef2163cb6eee3a2e4fcf958063ec09a4cfc0 k8s.gcr.io/kube-proxy:v1.10.6] 97861102} {[intellectdesigndevteam/platform-dashboard-ui@sha256:39ca7d2277802e3bfe87a6b779d049143b8543aa1bef5fc4a38db93de75789bf intellectdesigndevteam/platform-dashboard-ui:qa-18.3.1.5] 92532926} {[intellectdesigndevteam/platform-account-management-ui@sha256:38b6bac1384c0d3140483e3c6045d0ea7d5acf5bc962ef76ad1c76689ccc5131 intellectdesigndevteam/platform-account-management-ui:qa-18.3.1.5] 88970310} {[intellectdesigndevteam/platform-profile-management-ui@sha256:15ae94ffb55848026ce69c904695ab8c02838758b8b0755f59226500e459d144 intellectdesigndevteam/platform-profile-management-ui:qa-18.3.1.5] 87805996} {[intellectdesigndevteam/platform-signup-ui@sha256:0ff2d304f36a12e7d66beaf2313993c558155deaacbc58e9c6a5a5cbb5416371 intellectdesigndevteam/platform-signup-ui:qa-18.3.1.5] 86564054} {[k8s.gcr.io/heapster@sha256:b77cebeff2180d03e21cc9f9c6b69a0d9710caa9f6263e675eab7938019631ef k8s.gcr.io/heapster:v1.4.0] 73395475} {[intellectdesigndevteam/botfactory-chatbot-ui@sha256:1a5c90b58acce17dc85806214db90edbcf567c5ffc3dc7442da22f5c7440cdd5 intellectdesigndevteam/botfactory-chatbot-ui:qa-1.0.4] 71259465} {[quay.io/calico/cni@sha256:3a23e093b1e98cf232a226fedff591d33919f5297f016a41d8012efc83b23a84 quay.io/calico/cni:v1.11.2] 70781000} {[gcr.io/google_containers/k8s-dns-kube-dns-amd64@sha256:b99fc3eee2a9f052f7eb4cc00f15eb12fc405fa41019baa2d6b79847ae7284a8 gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.14.10] 49545125} {[gcr.io/google_containers/k8s-dns-sidecar-amd64@sha256:4f1ab957f87b94a5ec1edc26fae50da2175461f00afecf68940c4aa079bd08a4 gcr.io/google_containers/k8s-dns-sidecar-amd64:1.14.10] 41630977}],VolumesInUse:[kubernetes.io/aws-ebs/aws://us-west-1b/vol-05e233cba14fdde4c kubernetes.io/aws-ebs/aws://us-west-1b/vol-06c2933258576513b kubernetes.io/aws-ebs/aws://us-west-1b/vol-0af80a01aa34cfa2c],VolumesAttached:[{kubernetes.io/aws-ebs/aws://us-west-1b/vol-0af80a01aa34cfa2c /dev/xvdcq} {kubernetes.io/aws-ebs/aws://us-west-1b/vol-05e233cba14fdde4c /dev/xvdbe} {kubernetes.io/aws-ebs/aws://us-west-1b/vol-06c2933258576513b /dev/xvdbt}],Config:nil,},}
Dec 11 09:55:20.399: INFO: 
Logging kubelet events for node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:55:20.401: INFO: 
Logging pods the kubelet thinks is on node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:55:20.414: INFO: prd-efk-elasticsearch-data-0 started at 2018-11-19 16:59:28 +0000 UTC (1+1 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Init container init-sysctl ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container es-data ready: false, restart count 0
Dec 11 09:55:20.414: INFO: prd-pf-apimgmt-ui-platform-apimgmt-ui-699d4df9d-cd7lv started at 2018-11-20 11:37:33 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container platform-apimgmt-ui ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-pf-contact-svc-platform-contact-svc-7fdb7698d8-6s89f started at 2018-11-19 16:59:28 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container prd-pf-contact-svc-platform-contact-svc ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-dss-ppc-ui-64f9cf489c-r64qn started at 2018-11-20 14:04:47 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container dss-ppc-ui ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-pf-calen-svc-platform-calen-svc-59dc958758-gq7dn started at 2018-11-19 16:59:29 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container prd-pf-calen-svc-platform-calen-svc ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-pf-sign-svc-platform-signup-svc-7dcfdd559-c26zr started at 2018-11-19 16:59:30 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container prd-pf-sign-svc-platform-signup-svc ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-efk-elasticsearch-fluentd-gv7g8 started at 2018-11-19 16:53:44 +0000 UTC (1+1 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Init container init-fluentd ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container fluentd ready: false, restart count 0
Dec 11 09:55:20.414: INFO: prd-pf-doc-svc-platform-doc-svc-6bc8488db8-b6mbr started at 2018-11-19 16:59:28 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container prd-pf-doc-svc-platform-doc-svc ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-pf-prflmgmt-ui-platform-prflmgmt-ui-654ff59c99-mntgc started at 2018-11-20 11:46:36 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container platform-prflmgmt-ui ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-pfm-svc-telephony-55658c585-l2cmb started at 2018-11-20 08:24:26 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container prd-pf-telephony-svc-prd-pfm-svc-telephony ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-pf-acc-svc-platform-acc-svc-56c66dc6bc-c76pd started at 2018-11-20 08:35:58 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container prd-pf-acc-svc-platform-acc-svc ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-pf-conf-svc-platform-conf-svc-6f8c9c5649-js8zv started at 2018-11-20 08:43:48 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container prd-pf-conf-svc-platform-conf-svc ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-dss-lc-svc-dss-lc-service-6c8748f77b-tffh5 started at 2018-11-20 13:24:04 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container dss-lc-service ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.414: INFO: heapster-6d9d49d496-zxs9t started at 2018-11-19 16:59:28 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container heapster ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container heapster-nanny ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-pf-iam-svc-platform-iam-svc-5d57975b5-b8fcg started at 2018-11-19 16:59:28 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container prd-pf-iam-svc-platform-iam-svc ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-pfm-svc-data-6448cbb64-djfdf started at 2018-11-19 16:59:30 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container prd-pf-data-svc-prd-pfm-svc-data ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-dss-lcbulk-svc-dss-lcbulk-service-77b5449544-6nkdr started at 2018-11-19 16:59:28 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container dss-lcbulk-service ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-pf-notif-svc-platform-notif-svc-84dd77bbd8-qhxw5 started at 2018-11-19 16:59:29 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container prd-pf-notif-svc-platform-notif-svc ready: true, restart count 0
Dec 11 09:55:20.414: INFO: kube-dns-7c4d8456dd-np757 started at 2018-11-19 16:59:29 +0000 UTC (0+3 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container dnsmasq ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container kubedns ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container sidecar ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-pf-audit-svc-platform-audit-svc-78f5998486-4vlp5 started at 2018-11-19 16:59:29 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container prd-pf-audit-svc-platform-audit-svc ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-keycloak-pgpool-58b949979d-ndwgn started at 2018-11-19 16:59:30 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container prd-keycloak-pgpool ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-efk-elasticsearch-client-8655b8d9b9-5fmbv started at 2018-11-19 16:59:30 +0000 UTC (1+1 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Init container init-sysctl ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container es-client ready: false, restart count 0
Dec 11 09:55:20.414: INFO: prd-pf-signup-ui-platform-signup-ui-54ffdd6f94-62xr7 started at 2018-11-20 11:30:50 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container platform-signup-ui ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-pf-blkusrimp-svc-platform-blkusrimp-svc-7d8d5c459f-q24h8 started at 2018-11-19 16:59:28 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container prd-pf-blkusrimp-svc-platform-blkusrimp-svc ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-botfactory-chatbot-ui-pfm-botfactory-chatbot-ui-7bd798cnb8c started at 2018-11-21 10:41:40 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container pfm-botfactory-chatbot-ui ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-pf-admin-ui-platform-admin-ui-85c98dcc66-rbgt5 started at 2018-11-20 11:40:24 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container platform-admin-ui ready: true, restart count 0
Dec 11 09:55:20.414: INFO: datadog-datadog-r4px7 started at 2018-11-19 16:53:44 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container datadog ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-dss-pm-profile-svc-dss-pm-profile-service-556b68d65-qmntq started at 2018-11-19 16:59:31 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container dss-pm-profile-service ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-pf-email-svc-platform-email-svc-8696f76496-wkzqt started at 2018-11-19 16:59:31 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container prd-pf-email-svc-platform-email-svc ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-efk-elasticsearch-master-2 started at 2018-11-19 17:03:49 +0000 UTC (1+1 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Init container init-sysctl ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container es-master ready: false, restart count 0
Dec 11 09:55:20.414: INFO: prd-dss-qni-illustration-svc-dss-qni-illustration-service-r2rhd started at 2018-11-26 11:18:56 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container prd-dss-qni-illustration-svc-dss-qni-illustration-service ready: true, restart count 0
Dec 11 09:55:20.414: INFO: calico-node-p7n2j started at 2018-11-19 16:53:44 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container calico-node ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container install-cni ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-efk-elasticsearch-master-0 started at 2018-11-19 16:59:28 +0000 UTC (1+1 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Init container init-sysctl ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container es-master ready: false, restart count 0
Dec 11 09:55:20.414: INFO: prd-pf-notes-svc-platform-notes-svc-5c99df689c-vs8g5 started at 2018-11-19 16:59:28 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container prd-pf-notes-svc-platform-notes-svc ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-keycloak-keycloak-78d64cbc4f-scj6l started at 2018-11-19 16:59:29 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container prd-keycloak-keycloak ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-ai-sentiment-eng-svc-ai-sentiment-svc-69bd5d994b-vn2sr started at 2018-11-20 13:34:13 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container prd-ai-sentiment-eng-svc-ai-sentiment-svc ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-botfactory-ui-pfm-botfactory-ui-7ff78b89f7-ljt45 started at 2018-11-21 11:30:22 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container pfm-botfactory-ui ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-efk-elasticsearch-client-8655b8d9b9-t4lvs started at 2018-12-11 09:54:52 +0000 UTC (1+1 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Init container init-sysctl ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container es-client ready: false, restart count 0
Dec 11 09:55:20.414: INFO: kube-proxy-ip-172-25-93-75.us-west-1.compute.internal started at <nil> (0+0 container statuses recorded)
Dec 11 09:55:20.414: INFO: prd-pf-activity-svc-platform-activity-svc-855df677b4-htnqk started at 2018-11-19 16:59:30 +0000 UTC (0+2 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 09:55:20.414: INFO: 	Container prd-pf-activity-svc-platform-activity-svc ready: true, restart count 0
Dec 11 09:55:20.414: INFO: nginx-ingress-controller-5ccb96dd7b-ldrbm started at 2018-11-19 17:11:11 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec 11 09:55:20.414: INFO: prd-pf-accmgmt-ui-platform-accmgmt-ui-5cbc4c9d66-g4wqj started at 2018-11-20 11:49:59 +0000 UTC (0+1 container statuses recorded)
Dec 11 09:55:20.414: INFO: 	Container platform-accmgmt-ui ready: true, restart count 0
W1211 09:55:20.417642      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 11 09:55:20.445: INFO: 
Latency metrics for node ip-172-25-93-75.us-west-1.compute.internal
Dec 11 09:55:20.445: INFO: {Operation:stop_container Method:docker_operations_latency_microseconds Quantile:0.99 Latency:30.050199s}
Dec 11 09:55:20.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-lgml9" for this suite.
Dec 11 09:56:04.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:56:04.522: INFO: namespace: e2e-tests-kubelet-test-lgml9, resource: bindings, ignored listing per whitelist
Dec 11 09:56:04.539: INFO: namespace e2e-tests-kubelet-test-lgml9 deletion completed in 44.090700763s

• Failure [106.526 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance] [It]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

    Timed out after 60.000s.
    Expected
        <*errors.errorString | 0xc00200c2e0>: {
            s: "expected hosts file to contain entries from HostAliases. Got:\n# Kubernetes-managed hosts file.\n127.0.0.1\tlocalhost\n::1\tlocalhost ip6-localhost ip6-loopback\nfe00::0\tip6-localnet\nfe00::0\tip6-mcastprefix\nfe00::1\tip6-allnodes\nfe00::2\tip6-allrouters\n100.111.88.41\tbusybox-host-aliasese1ff809a-fd24-11e8-897d-5ac57959ef46\n\n# Entries added by HostAliases.\n123.45.67.89\tfoo\n123.45.67.89\tbar\n",
        }
    to be nil

    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:183
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:56:04.539: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
Dec 11 09:56:13.885: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:56:30.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-pkzx6" for this suite.
Dec 11 09:56:36.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:56:36.857: INFO: namespace: e2e-tests-namespaces-pkzx6, resource: bindings, ignored listing per whitelist
Dec 11 09:56:36.868: INFO: namespace e2e-tests-namespaces-pkzx6 deletion completed in 6.086995582s
STEP: Destroying namespace "e2e-tests-nsdeletetest-kxqc9" for this suite.
Dec 11 09:56:36.870: INFO: Namespace e2e-tests-nsdeletetest-kxqc9 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-rqv96" for this suite.
Dec 11 09:56:42.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:56:42.957: INFO: namespace: e2e-tests-nsdeletetest-rqv96, resource: bindings, ignored listing per whitelist
Dec 11 09:56:42.961: INFO: namespace e2e-tests-nsdeletetest-rqv96 deletion completed in 6.090921702s

• [SLOW TEST:38.422 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:56:42.961: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec 11 09:56:43.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 create -f - --namespace=e2e-tests-kubectl-tmnns'
Dec 11 09:56:43.174: INFO: stderr: ""
Dec 11 09:56:43.174: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 11 09:56:44.177: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 09:56:44.177: INFO: Found 0 / 1
Dec 11 09:56:45.176: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 09:56:45.176: INFO: Found 1 / 1
Dec 11 09:56:45.176: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec 11 09:56:45.178: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 09:56:45.179: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 11 09:56:45.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 patch pod redis-master-pxdnh --namespace=e2e-tests-kubectl-tmnns -p {"metadata":{"annotations":{"x":"y"}}}'
Dec 11 09:56:45.247: INFO: stderr: ""
Dec 11 09:56:45.247: INFO: stdout: "pod/redis-master-pxdnh patched\n"
STEP: checking annotations
Dec 11 09:56:45.250: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 09:56:45.250: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:56:45.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tmnns" for this suite.
Dec 11 09:57:07.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:57:07.278: INFO: namespace: e2e-tests-kubectl-tmnns, resource: bindings, ignored listing per whitelist
Dec 11 09:57:07.338: INFO: namespace e2e-tests-kubectl-tmnns deletion completed in 22.085375716s

• [SLOW TEST:24.378 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:57:07.339: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 11 09:57:11.488: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 11 09:57:11.491: INFO: Pod pod-with-poststart-http-hook still exists
Dec 11 09:57:13.491: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 11 09:57:13.494: INFO: Pod pod-with-poststart-http-hook still exists
Dec 11 09:57:15.491: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 11 09:57:15.494: INFO: Pod pod-with-poststart-http-hook still exists
Dec 11 09:57:17.491: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 11 09:57:17.494: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:57:17.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-fk2sq" for this suite.
Dec 11 09:57:39.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:57:39.531: INFO: namespace: e2e-tests-container-lifecycle-hook-fk2sq, resource: bindings, ignored listing per whitelist
Dec 11 09:57:39.583: INFO: namespace e2e-tests-container-lifecycle-hook-fk2sq deletion completed in 22.085503214s

• [SLOW TEST:32.244 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:57:39.583: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Dec 11 09:57:39.688: INFO: Waiting up to 5m0s for pod "pod-31dcbb1c-fd2b-11e8-897d-5ac57959ef46" in namespace "e2e-tests-emptydir-7zgn8" to be "success or failure"
Dec 11 09:57:39.690: INFO: Pod "pod-31dcbb1c-fd2b-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.169353ms
Dec 11 09:57:41.693: INFO: Pod "pod-31dcbb1c-fd2b-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004966563s
STEP: Saw pod success
Dec 11 09:57:41.693: INFO: Pod "pod-31dcbb1c-fd2b-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 09:57:41.695: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-31dcbb1c-fd2b-11e8-897d-5ac57959ef46 container test-container: <nil>
STEP: delete the pod
Dec 11 09:57:41.721: INFO: Waiting for pod pod-31dcbb1c-fd2b-11e8-897d-5ac57959ef46 to disappear
Dec 11 09:57:41.723: INFO: Pod pod-31dcbb1c-fd2b-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:57:41.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7zgn8" for this suite.
Dec 11 09:57:47.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:57:47.774: INFO: namespace: e2e-tests-emptydir-7zgn8, resource: bindings, ignored listing per whitelist
Dec 11 09:57:47.816: INFO: namespace e2e-tests-emptydir-7zgn8 deletion completed in 6.089343178s

• [SLOW TEST:8.233 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:57:47.816: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-7q926
Dec 11 09:57:51.926: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-7q926
STEP: checking the pod's current state and verifying that restartCount is present
Dec 11 09:57:51.929: INFO: Initial restart count of pod liveness-http is 0
Dec 11 09:58:09.955: INFO: Restart count of pod e2e-tests-container-probe-7q926/liveness-http is now 1 (18.026470359s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:58:09.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-7q926" for this suite.
Dec 11 09:58:15.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:58:16.008: INFO: namespace: e2e-tests-container-probe-7q926, resource: bindings, ignored listing per whitelist
Dec 11 09:58:16.070: INFO: namespace e2e-tests-container-probe-7q926 deletion completed in 6.089655831s

• [SLOW TEST:28.255 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:58:16.071: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-gczw4
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-gczw4
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-gczw4
Dec 11 09:58:16.195: INFO: Found 0 stateful pods, waiting for 1
Dec 11 09:58:26.198: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec 11 09:58:26.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 exec --namespace=e2e-tests-statefulset-gczw4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 11 09:58:26.330: INFO: stderr: ""
Dec 11 09:58:26.330: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 11 09:58:26.330: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 11 09:58:26.332: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 11 09:58:36.335: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 11 09:58:36.335: INFO: Waiting for statefulset status.replicas updated to 0
Dec 11 09:58:36.354: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999576s
Dec 11 09:58:37.357: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997502722s
Dec 11 09:58:38.360: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.994649068s
Dec 11 09:58:39.363: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.991646423s
Dec 11 09:58:40.366: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.988704245s
Dec 11 09:58:41.369: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.986160448s
Dec 11 09:58:42.371: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.98321946s
Dec 11 09:58:43.374: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.980431699s
Dec 11 09:58:44.377: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.977415636s
Dec 11 09:58:45.380: INFO: Verifying statefulset ss doesn't scale past 1 for another 974.715702ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-gczw4
Dec 11 09:58:46.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 exec --namespace=e2e-tests-statefulset-gczw4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 11 09:58:46.511: INFO: stderr: ""
Dec 11 09:58:46.511: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 11 09:58:46.511: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 11 09:58:46.514: INFO: Found 1 stateful pods, waiting for 3
Dec 11 09:58:56.517: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 11 09:58:56.517: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 11 09:58:56.517: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec 11 09:58:56.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 exec --namespace=e2e-tests-statefulset-gczw4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 11 09:58:56.653: INFO: stderr: ""
Dec 11 09:58:56.653: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 11 09:58:56.653: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 11 09:58:56.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 exec --namespace=e2e-tests-statefulset-gczw4 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 11 09:58:56.795: INFO: stderr: ""
Dec 11 09:58:56.795: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 11 09:58:56.795: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 11 09:58:56.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 exec --namespace=e2e-tests-statefulset-gczw4 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 11 09:58:56.929: INFO: stderr: ""
Dec 11 09:58:56.929: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 11 09:58:56.929: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 11 09:58:56.929: INFO: Waiting for statefulset status.replicas updated to 0
Dec 11 09:58:56.932: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec 11 09:59:06.937: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 11 09:59:06.937: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 11 09:59:06.937: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 11 09:59:06.953: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999955s
Dec 11 09:59:07.957: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997454432s
Dec 11 09:59:08.960: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993439271s
Dec 11 09:59:09.963: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.990393837s
Dec 11 09:59:10.966: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.987164485s
Dec 11 09:59:11.969: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.984244475s
Dec 11 09:59:12.972: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.981253568s
Dec 11 09:59:13.976: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.977682032s
Dec 11 09:59:14.979: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.974464678s
Dec 11 09:59:15.982: INFO: Verifying statefulset ss doesn't scale past 3 for another 971.222426ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-gczw4
Dec 11 09:59:16.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 exec --namespace=e2e-tests-statefulset-gczw4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 11 09:59:17.116: INFO: stderr: ""
Dec 11 09:59:17.116: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 11 09:59:17.116: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 11 09:59:17.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 exec --namespace=e2e-tests-statefulset-gczw4 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 11 09:59:17.263: INFO: stderr: ""
Dec 11 09:59:17.263: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 11 09:59:17.263: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 11 09:59:17.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 exec --namespace=e2e-tests-statefulset-gczw4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 11 09:59:17.394: INFO: stderr: ""
Dec 11 09:59:17.394: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 11 09:59:17.394: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 11 09:59:17.394: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 11 09:59:37.405: INFO: Deleting all statefulset in ns e2e-tests-statefulset-gczw4
Dec 11 09:59:37.408: INFO: Scaling statefulset ss to 0
Dec 11 09:59:37.415: INFO: Waiting for statefulset status.replicas updated to 0
Dec 11 09:59:37.417: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:59:37.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-gczw4" for this suite.
Dec 11 09:59:43.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 09:59:43.472: INFO: namespace: e2e-tests-statefulset-gczw4, resource: bindings, ignored listing per whitelist
Dec 11 09:59:43.565: INFO: namespace e2e-tests-statefulset-gczw4 deletion completed in 6.127512213s

• [SLOW TEST:87.494 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 09:59:43.565: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-7bc424a8-fd2b-11e8-897d-5ac57959ef46
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-7bc424a8-fd2b-11e8-897d-5ac57959ef46
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 09:59:47.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-trm7z" for this suite.
Dec 11 10:00:09.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:00:09.799: INFO: namespace: e2e-tests-projected-trm7z, resource: bindings, ignored listing per whitelist
Dec 11 10:00:09.818: INFO: namespace e2e-tests-projected-trm7z deletion completed in 22.090398799s

• [SLOW TEST:26.253 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:00:09.818: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-42h7d
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Dec 11 10:00:09.939: INFO: Found 0 stateful pods, waiting for 3
Dec 11 10:00:19.942: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 11 10:00:19.942: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 11 10:00:19.942: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec 11 10:00:19.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 exec --namespace=e2e-tests-statefulset-42h7d ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 11 10:00:20.096: INFO: stderr: ""
Dec 11 10:00:20.096: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 11 10:00:20.096: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec 11 10:00:30.131: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec 11 10:00:40.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 exec --namespace=e2e-tests-statefulset-42h7d ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 11 10:00:40.291: INFO: stderr: ""
Dec 11 10:00:40.291: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 11 10:00:40.291: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 11 10:00:50.307: INFO: Waiting for StatefulSet e2e-tests-statefulset-42h7d/ss2 to complete update
Dec 11 10:00:50.307: INFO: Waiting for Pod e2e-tests-statefulset-42h7d/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec 11 10:00:50.307: INFO: Waiting for Pod e2e-tests-statefulset-42h7d/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec 11 10:00:50.307: INFO: Waiting for Pod e2e-tests-statefulset-42h7d/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec 11 10:01:00.312: INFO: Waiting for StatefulSet e2e-tests-statefulset-42h7d/ss2 to complete update
Dec 11 10:01:00.312: INFO: Waiting for Pod e2e-tests-statefulset-42h7d/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec 11 10:01:00.312: INFO: Waiting for Pod e2e-tests-statefulset-42h7d/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec 11 10:01:10.312: INFO: Waiting for StatefulSet e2e-tests-statefulset-42h7d/ss2 to complete update
Dec 11 10:01:10.312: INFO: Waiting for Pod e2e-tests-statefulset-42h7d/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Dec 11 10:01:20.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 exec --namespace=e2e-tests-statefulset-42h7d ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 11 10:01:20.457: INFO: stderr: ""
Dec 11 10:01:20.457: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 11 10:01:20.457: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 11 10:01:30.492: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec 11 10:01:40.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 exec --namespace=e2e-tests-statefulset-42h7d ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 11 10:01:40.648: INFO: stderr: ""
Dec 11 10:01:40.648: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 11 10:01:40.648: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 11 10:01:50.662: INFO: Waiting for StatefulSet e2e-tests-statefulset-42h7d/ss2 to complete update
Dec 11 10:01:50.662: INFO: Waiting for Pod e2e-tests-statefulset-42h7d/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Dec 11 10:01:50.662: INFO: Waiting for Pod e2e-tests-statefulset-42h7d/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Dec 11 10:01:50.662: INFO: Waiting for Pod e2e-tests-statefulset-42h7d/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Dec 11 10:02:00.668: INFO: Waiting for StatefulSet e2e-tests-statefulset-42h7d/ss2 to complete update
Dec 11 10:02:00.668: INFO: Waiting for Pod e2e-tests-statefulset-42h7d/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 11 10:02:10.669: INFO: Deleting all statefulset in ns e2e-tests-statefulset-42h7d
Dec 11 10:02:10.671: INFO: Scaling statefulset ss2 to 0
Dec 11 10:02:50.691: INFO: Waiting for statefulset status.replicas updated to 0
Dec 11 10:02:50.694: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:02:50.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-42h7d" for this suite.
Dec 11 10:02:56.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:02:56.799: INFO: namespace: e2e-tests-statefulset-42h7d, resource: bindings, ignored listing per whitelist
Dec 11 10:02:56.808: INFO: namespace e2e-tests-statefulset-42h7d deletion completed in 6.094825696s

• [SLOW TEST:166.991 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:02:56.809: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 11 10:02:56.905: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec 11 10:02:56.918: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 11 10:03:01.962: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 11 10:03:01.962: INFO: Creating deployment "test-rolling-update-deployment"
Dec 11 10:03:01.974: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec 11 10:03:01.978: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec 11 10:03:03.983: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec 11 10:03:05.983: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec 11 10:03:05.985: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680119385, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680119385, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680119385, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680119385, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-6bf7d9958b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 11 10:03:07.988: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 11 10:03:07.995: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-x2zqg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-x2zqg/deployments/test-rolling-update-deployment,UID:f1f590a9-fd2b-11e8-8e03-0681e6464a68,ResourceVersion:21962343,Generation:1,CreationTimestamp:2018-12-11 10:03:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-11 10:03:05 +0000 UTC 2018-12-11 10:03:05 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-11 10:03:06 +0000 UTC 2018-12-11 10:03:05 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-6bf7d9958b" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec 11 10:03:07.998: INFO: New ReplicaSet "test-rolling-update-deployment-6bf7d9958b" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-6bf7d9958b,GenerateName:,Namespace:e2e-tests-deployment-x2zqg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-x2zqg/replicasets/test-rolling-update-deployment-6bf7d9958b,UID:f3c8441f-fd2b-11e8-8e03-0681e6464a68,ResourceVersion:21962336,Generation:1,CreationTimestamp:2018-12-11 10:03:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 2693855146,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{extensions/v1beta1 Deployment test-rolling-update-deployment f1f590a9-fd2b-11e8-8e03-0681e6464a68 0xc002015d4a 0xc002015d4b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 2693855146,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 2693855146,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec 11 10:03:07.998: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec 11 10:03:07.998: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-x2zqg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-x2zqg/replicasets/test-rolling-update-controller,UID:eef1ef89-fd2b-11e8-8e03-0681e6464a68,ResourceVersion:21962342,Generation:4,CreationTimestamp:2018-12-11 10:02:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,pod-template-hash: 108001640,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{extensions/v1beta1 Deployment test-rolling-update-deployment f1f590a9-fd2b-11e8-8e03-0681e6464a68 0xc002015c0a 0xc002015c0b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,pod-template-hash: 108001640,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,pod-template-hash: 108001640,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 11 10:03:08.000: INFO: Pod "test-rolling-update-deployment-6bf7d9958b-m4b6c" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-6bf7d9958b-m4b6c,GenerateName:test-rolling-update-deployment-6bf7d9958b-,Namespace:e2e-tests-deployment-x2zqg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-x2zqg/pods/test-rolling-update-deployment-6bf7d9958b-m4b6c,UID:f3c9e62f-fd2b-11e8-8e03-0681e6464a68,ResourceVersion:21962335,Generation:0,CreationTimestamp:2018-12-11 10:03:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 2693855146,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet test-rolling-update-deployment-6bf7d9958b f3c8441f-fd2b-11e8-8e03-0681e6464a68 0xc001de479a 0xc001de479b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cdd6z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cdd6z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-cdd6z true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-62-1.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001de4820} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001de4840}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:03:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:03:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:03:05 +0000 UTC  }],Message:,Reason:,HostIP:172.25.62.1,PodIP:100.111.88.57,StartTime:2018-12-11 10:03:05 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-11 10:03:05 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://41a26e0a5ababf0fd9105b3eef20a23719a82a860516703d3a0bc6bcf49e5a19}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:03:08.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-x2zqg" for this suite.
Dec 11 10:03:14.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:03:14.055: INFO: namespace: e2e-tests-deployment-x2zqg, resource: bindings, ignored listing per whitelist
Dec 11 10:03:14.095: INFO: namespace e2e-tests-deployment-x2zqg deletion completed in 6.090502295s

• [SLOW TEST:17.286 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:03:14.095: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 11 10:03:14.204: INFO: Waiting up to 5m0s for pod "pod-f93fa50c-fd2b-11e8-897d-5ac57959ef46" in namespace "e2e-tests-emptydir-c2hl5" to be "success or failure"
Dec 11 10:03:14.206: INFO: Pod "pod-f93fa50c-fd2b-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.178101ms
Dec 11 10:03:16.209: INFO: Pod "pod-f93fa50c-fd2b-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005132478s
STEP: Saw pod success
Dec 11 10:03:16.209: INFO: Pod "pod-f93fa50c-fd2b-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:03:16.211: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-f93fa50c-fd2b-11e8-897d-5ac57959ef46 container test-container: <nil>
STEP: delete the pod
Dec 11 10:03:16.243: INFO: Waiting for pod pod-f93fa50c-fd2b-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:03:16.245: INFO: Pod pod-f93fa50c-fd2b-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:03:16.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-c2hl5" for this suite.
Dec 11 10:03:22.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:03:22.309: INFO: namespace: e2e-tests-emptydir-c2hl5, resource: bindings, ignored listing per whitelist
Dec 11 10:03:22.339: INFO: namespace e2e-tests-emptydir-c2hl5 deletion completed in 6.090346479s

• [SLOW TEST:8.244 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:03:22.339: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 11 10:03:22.448: INFO: Waiting up to 5m0s for pod "pod-fe29b01f-fd2b-11e8-897d-5ac57959ef46" in namespace "e2e-tests-emptydir-g288d" to be "success or failure"
Dec 11 10:03:22.450: INFO: Pod "pod-fe29b01f-fd2b-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024046ms
Dec 11 10:03:24.453: INFO: Pod "pod-fe29b01f-fd2b-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004688227s
STEP: Saw pod success
Dec 11 10:03:24.453: INFO: Pod "pod-fe29b01f-fd2b-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:03:24.455: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-fe29b01f-fd2b-11e8-897d-5ac57959ef46 container test-container: <nil>
STEP: delete the pod
Dec 11 10:03:24.483: INFO: Waiting for pod pod-fe29b01f-fd2b-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:03:24.484: INFO: Pod pod-fe29b01f-fd2b-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:03:24.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-g288d" for this suite.
Dec 11 10:03:30.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:03:30.527: INFO: namespace: e2e-tests-emptydir-g288d, resource: bindings, ignored listing per whitelist
Dec 11 10:03:30.576: INFO: namespace e2e-tests-emptydir-g288d deletion completed in 6.088265397s

• [SLOW TEST:8.237 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:03:30.576: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-8jxzr
I1211 10:03:30.687267      18 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-8jxzr, replica count: 1
I1211 10:03:31.737793      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1211 10:03:32.738018      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 11 10:03:32.871: INFO: Created: latency-svc-nktlw
Dec 11 10:03:32.884: INFO: Got endpoints: latency-svc-nktlw [45.936094ms]
Dec 11 10:03:32.917: INFO: Created: latency-svc-fc849
Dec 11 10:03:32.929: INFO: Got endpoints: latency-svc-fc849 [45.498071ms]
Dec 11 10:03:32.939: INFO: Created: latency-svc-nbt94
Dec 11 10:03:32.951: INFO: Got endpoints: latency-svc-nbt94 [67.582869ms]
Dec 11 10:03:32.961: INFO: Created: latency-svc-p7dfd
Dec 11 10:03:32.974: INFO: Got endpoints: latency-svc-p7dfd [89.793273ms]
Dec 11 10:03:32.984: INFO: Created: latency-svc-g2r58
Dec 11 10:03:32.997: INFO: Got endpoints: latency-svc-g2r58 [112.812628ms]
Dec 11 10:03:33.007: INFO: Created: latency-svc-97ps8
Dec 11 10:03:33.019: INFO: Got endpoints: latency-svc-97ps8 [135.201208ms]
Dec 11 10:03:33.031: INFO: Created: latency-svc-qwhpn
Dec 11 10:03:33.043: INFO: Got endpoints: latency-svc-qwhpn [159.16429ms]
Dec 11 10:03:33.053: INFO: Created: latency-svc-8bb2x
Dec 11 10:03:33.066: INFO: Got endpoints: latency-svc-8bb2x [182.029764ms]
Dec 11 10:03:33.076: INFO: Created: latency-svc-m6xsh
Dec 11 10:03:33.088: INFO: Got endpoints: latency-svc-m6xsh [204.306886ms]
Dec 11 10:03:33.098: INFO: Created: latency-svc-bjhz5
Dec 11 10:03:33.110: INFO: Got endpoints: latency-svc-bjhz5 [225.527942ms]
Dec 11 10:03:33.120: INFO: Created: latency-svc-ngfzk
Dec 11 10:03:33.132: INFO: Got endpoints: latency-svc-ngfzk [247.976715ms]
Dec 11 10:03:33.142: INFO: Created: latency-svc-jwndm
Dec 11 10:03:33.154: INFO: Got endpoints: latency-svc-jwndm [270.07697ms]
Dec 11 10:03:33.165: INFO: Created: latency-svc-rfd2j
Dec 11 10:03:33.178: INFO: Got endpoints: latency-svc-rfd2j [293.940058ms]
Dec 11 10:03:33.191: INFO: Created: latency-svc-mxjq4
Dec 11 10:03:33.203: INFO: Got endpoints: latency-svc-mxjq4 [319.228994ms]
Dec 11 10:03:33.214: INFO: Created: latency-svc-lc47n
Dec 11 10:03:33.226: INFO: Got endpoints: latency-svc-lc47n [341.697898ms]
Dec 11 10:03:33.235: INFO: Created: latency-svc-pv6lp
Dec 11 10:03:33.247: INFO: Got endpoints: latency-svc-pv6lp [362.682431ms]
Dec 11 10:03:33.256: INFO: Created: latency-svc-tgfkv
Dec 11 10:03:33.268: INFO: Got endpoints: latency-svc-tgfkv [339.047608ms]
Dec 11 10:03:33.278: INFO: Created: latency-svc-dhjks
Dec 11 10:03:33.290: INFO: Got endpoints: latency-svc-dhjks [338.312535ms]
Dec 11 10:03:33.299: INFO: Created: latency-svc-vjgd6
Dec 11 10:03:33.312: INFO: Got endpoints: latency-svc-vjgd6 [338.243457ms]
Dec 11 10:03:33.321: INFO: Created: latency-svc-jzctm
Dec 11 10:03:33.334: INFO: Got endpoints: latency-svc-jzctm [337.041414ms]
Dec 11 10:03:33.343: INFO: Created: latency-svc-mvqgs
Dec 11 10:03:33.354: INFO: Got endpoints: latency-svc-mvqgs [335.141932ms]
Dec 11 10:03:33.365: INFO: Created: latency-svc-js66d
Dec 11 10:03:33.379: INFO: Got endpoints: latency-svc-js66d [335.73798ms]
Dec 11 10:03:33.389: INFO: Created: latency-svc-qbwk7
Dec 11 10:03:33.400: INFO: Got endpoints: latency-svc-qbwk7 [334.024361ms]
Dec 11 10:03:33.409: INFO: Created: latency-svc-gcmqw
Dec 11 10:03:33.423: INFO: Got endpoints: latency-svc-gcmqw [335.060482ms]
Dec 11 10:03:33.432: INFO: Created: latency-svc-2zb4z
Dec 11 10:03:33.444: INFO: Got endpoints: latency-svc-2zb4z [334.750765ms]
Dec 11 10:03:33.454: INFO: Created: latency-svc-qsg7q
Dec 11 10:03:33.466: INFO: Got endpoints: latency-svc-qsg7q [333.635216ms]
Dec 11 10:03:33.476: INFO: Created: latency-svc-x28dz
Dec 11 10:03:33.488: INFO: Got endpoints: latency-svc-x28dz [333.744103ms]
Dec 11 10:03:33.499: INFO: Created: latency-svc-wfws8
Dec 11 10:03:33.511: INFO: Got endpoints: latency-svc-wfws8 [332.674782ms]
Dec 11 10:03:33.521: INFO: Created: latency-svc-m248d
Dec 11 10:03:33.534: INFO: Got endpoints: latency-svc-m248d [330.971809ms]
Dec 11 10:03:33.544: INFO: Created: latency-svc-5sd4p
Dec 11 10:03:33.557: INFO: Got endpoints: latency-svc-5sd4p [330.881893ms]
Dec 11 10:03:33.566: INFO: Created: latency-svc-vbhfs
Dec 11 10:03:33.580: INFO: Got endpoints: latency-svc-vbhfs [333.513832ms]
Dec 11 10:03:33.590: INFO: Created: latency-svc-d592b
Dec 11 10:03:33.602: INFO: Got endpoints: latency-svc-d592b [333.224541ms]
Dec 11 10:03:33.612: INFO: Created: latency-svc-hfjgh
Dec 11 10:03:33.624: INFO: Got endpoints: latency-svc-hfjgh [334.120305ms]
Dec 11 10:03:33.634: INFO: Created: latency-svc-8wsls
Dec 11 10:03:33.647: INFO: Got endpoints: latency-svc-8wsls [335.002789ms]
Dec 11 10:03:33.657: INFO: Created: latency-svc-dmj4f
Dec 11 10:03:33.668: INFO: Got endpoints: latency-svc-dmj4f [334.352093ms]
Dec 11 10:03:33.678: INFO: Created: latency-svc-vfvtm
Dec 11 10:03:33.691: INFO: Got endpoints: latency-svc-vfvtm [336.352271ms]
Dec 11 10:03:33.704: INFO: Created: latency-svc-xx2pw
Dec 11 10:03:33.715: INFO: Got endpoints: latency-svc-xx2pw [336.071447ms]
Dec 11 10:03:33.725: INFO: Created: latency-svc-rvzlx
Dec 11 10:03:33.736: INFO: Got endpoints: latency-svc-rvzlx [336.257907ms]
Dec 11 10:03:33.746: INFO: Created: latency-svc-cbsnr
Dec 11 10:03:33.758: INFO: Got endpoints: latency-svc-cbsnr [334.658901ms]
Dec 11 10:03:33.775: INFO: Created: latency-svc-jhtzb
Dec 11 10:03:33.787: INFO: Got endpoints: latency-svc-jhtzb [342.414739ms]
Dec 11 10:03:33.789: INFO: Created: latency-svc-r92rw
Dec 11 10:03:33.801: INFO: Got endpoints: latency-svc-r92rw [335.022794ms]
Dec 11 10:03:33.812: INFO: Created: latency-svc-q8tg7
Dec 11 10:03:33.825: INFO: Got endpoints: latency-svc-q8tg7 [337.171508ms]
Dec 11 10:03:33.833: INFO: Created: latency-svc-mkvc7
Dec 11 10:03:33.848: INFO: Got endpoints: latency-svc-mkvc7 [336.789083ms]
Dec 11 10:03:33.859: INFO: Created: latency-svc-fd7wp
Dec 11 10:03:33.870: INFO: Got endpoints: latency-svc-fd7wp [335.682754ms]
Dec 11 10:03:33.880: INFO: Created: latency-svc-7fbpk
Dec 11 10:03:33.892: INFO: Got endpoints: latency-svc-7fbpk [335.522795ms]
Dec 11 10:03:33.904: INFO: Created: latency-svc-2r7jg
Dec 11 10:03:33.916: INFO: Got endpoints: latency-svc-2r7jg [335.26845ms]
Dec 11 10:03:33.926: INFO: Created: latency-svc-4zm5x
Dec 11 10:03:33.939: INFO: Got endpoints: latency-svc-4zm5x [336.840939ms]
Dec 11 10:03:33.947: INFO: Created: latency-svc-hfr9q
Dec 11 10:03:33.960: INFO: Got endpoints: latency-svc-hfr9q [335.827435ms]
Dec 11 10:03:33.969: INFO: Created: latency-svc-dlbcp
Dec 11 10:03:33.982: INFO: Got endpoints: latency-svc-dlbcp [334.628333ms]
Dec 11 10:03:33.992: INFO: Created: latency-svc-hzw94
Dec 11 10:03:34.004: INFO: Got endpoints: latency-svc-hzw94 [335.930168ms]
Dec 11 10:03:34.016: INFO: Created: latency-svc-gpgzl
Dec 11 10:03:34.031: INFO: Got endpoints: latency-svc-gpgzl [339.837894ms]
Dec 11 10:03:34.040: INFO: Created: latency-svc-dtxp5
Dec 11 10:03:34.053: INFO: Got endpoints: latency-svc-dtxp5 [337.555334ms]
Dec 11 10:03:34.062: INFO: Created: latency-svc-h6tlt
Dec 11 10:03:34.077: INFO: Got endpoints: latency-svc-h6tlt [340.514979ms]
Dec 11 10:03:34.090: INFO: Created: latency-svc-4tjwj
Dec 11 10:03:34.103: INFO: Got endpoints: latency-svc-4tjwj [345.066392ms]
Dec 11 10:03:34.113: INFO: Created: latency-svc-xm7f2
Dec 11 10:03:34.134: INFO: Got endpoints: latency-svc-xm7f2 [347.558865ms]
Dec 11 10:03:34.149: INFO: Created: latency-svc-65t44
Dec 11 10:03:34.164: INFO: Created: latency-svc-n2wvt
Dec 11 10:03:34.181: INFO: Got endpoints: latency-svc-65t44 [379.793609ms]
Dec 11 10:03:34.187: INFO: Created: latency-svc-c5vwh
Dec 11 10:03:34.210: INFO: Created: latency-svc-w7c84
Dec 11 10:03:34.237: INFO: Got endpoints: latency-svc-n2wvt [411.67688ms]
Dec 11 10:03:34.246: INFO: Created: latency-svc-shl9w
Dec 11 10:03:34.277: INFO: Created: latency-svc-r4szd
Dec 11 10:03:34.287: INFO: Got endpoints: latency-svc-c5vwh [439.590736ms]
Dec 11 10:03:34.308: INFO: Created: latency-svc-5dhhb
Dec 11 10:03:34.329: INFO: Created: latency-svc-m6kls
Dec 11 10:03:34.332: INFO: Got endpoints: latency-svc-w7c84 [462.046954ms]
Dec 11 10:03:34.353: INFO: Created: latency-svc-4lnv4
Dec 11 10:03:34.376: INFO: Created: latency-svc-nvk4l
Dec 11 10:03:34.387: INFO: Got endpoints: latency-svc-shl9w [494.740263ms]
Dec 11 10:03:34.396: INFO: Created: latency-svc-p5ckl
Dec 11 10:03:34.418: INFO: Created: latency-svc-cmsmj
Dec 11 10:03:34.438: INFO: Got endpoints: latency-svc-r4szd [522.283648ms]
Dec 11 10:03:34.448: INFO: Created: latency-svc-v76vb
Dec 11 10:03:34.469: INFO: Created: latency-svc-zpdv2
Dec 11 10:03:34.486: INFO: Got endpoints: latency-svc-5dhhb [547.700879ms]
Dec 11 10:03:34.493: INFO: Created: latency-svc-htgpz
Dec 11 10:03:34.515: INFO: Created: latency-svc-khvpn
Dec 11 10:03:34.533: INFO: Got endpoints: latency-svc-m6kls [573.158616ms]
Dec 11 10:03:34.535: INFO: Created: latency-svc-wlgtr
Dec 11 10:03:34.558: INFO: Created: latency-svc-sv4hk
Dec 11 10:03:34.579: INFO: Created: latency-svc-vr7dw
Dec 11 10:03:34.581: INFO: Got endpoints: latency-svc-4lnv4 [599.475962ms]
Dec 11 10:03:34.603: INFO: Created: latency-svc-xr8kd
Dec 11 10:03:34.624: INFO: Created: latency-svc-t8vnc
Dec 11 10:03:34.633: INFO: Got endpoints: latency-svc-nvk4l [628.804707ms]
Dec 11 10:03:34.646: INFO: Created: latency-svc-2pkhm
Dec 11 10:03:34.667: INFO: Created: latency-svc-kfzkq
Dec 11 10:03:34.683: INFO: Got endpoints: latency-svc-p5ckl [652.860404ms]
Dec 11 10:03:34.690: INFO: Created: latency-svc-s78hb
Dec 11 10:03:34.713: INFO: Created: latency-svc-vjp2l
Dec 11 10:03:34.732: INFO: Got endpoints: latency-svc-cmsmj [679.644239ms]
Dec 11 10:03:34.734: INFO: Created: latency-svc-9tj77
Dec 11 10:03:34.764: INFO: Created: latency-svc-8744b
Dec 11 10:03:34.781: INFO: Got endpoints: latency-svc-v76vb [703.51542ms]
Dec 11 10:03:34.812: INFO: Created: latency-svc-hjt6r
Dec 11 10:03:34.831: INFO: Got endpoints: latency-svc-zpdv2 [727.696369ms]
Dec 11 10:03:34.863: INFO: Created: latency-svc-t8vqd
Dec 11 10:03:34.882: INFO: Got endpoints: latency-svc-htgpz [747.858766ms]
Dec 11 10:03:34.914: INFO: Created: latency-svc-sh9cj
Dec 11 10:03:34.930: INFO: Got endpoints: latency-svc-khvpn [749.866026ms]
Dec 11 10:03:34.962: INFO: Created: latency-svc-cwzkq
Dec 11 10:03:34.982: INFO: Got endpoints: latency-svc-wlgtr [744.835594ms]
Dec 11 10:03:35.012: INFO: Created: latency-svc-p7rvv
Dec 11 10:03:35.032: INFO: Got endpoints: latency-svc-sv4hk [745.084075ms]
Dec 11 10:03:35.064: INFO: Created: latency-svc-g96rh
Dec 11 10:03:35.081: INFO: Got endpoints: latency-svc-vr7dw [748.699208ms]
Dec 11 10:03:35.112: INFO: Created: latency-svc-99zct
Dec 11 10:03:35.131: INFO: Got endpoints: latency-svc-xr8kd [743.686389ms]
Dec 11 10:03:35.164: INFO: Created: latency-svc-twdqj
Dec 11 10:03:35.181: INFO: Got endpoints: latency-svc-t8vnc [743.324105ms]
Dec 11 10:03:35.213: INFO: Created: latency-svc-qrllm
Dec 11 10:03:35.231: INFO: Got endpoints: latency-svc-2pkhm [745.007744ms]
Dec 11 10:03:35.262: INFO: Created: latency-svc-66nz7
Dec 11 10:03:35.282: INFO: Got endpoints: latency-svc-kfzkq [748.986463ms]
Dec 11 10:03:35.314: INFO: Created: latency-svc-955nc
Dec 11 10:03:35.331: INFO: Got endpoints: latency-svc-s78hb [750.258374ms]
Dec 11 10:03:35.362: INFO: Created: latency-svc-c9555
Dec 11 10:03:35.381: INFO: Got endpoints: latency-svc-vjp2l [748.460022ms]
Dec 11 10:03:35.412: INFO: Created: latency-svc-t9wd5
Dec 11 10:03:35.431: INFO: Got endpoints: latency-svc-9tj77 [747.098033ms]
Dec 11 10:03:35.462: INFO: Created: latency-svc-rdff7
Dec 11 10:03:35.490: INFO: Got endpoints: latency-svc-8744b [757.861936ms]
Dec 11 10:03:35.530: INFO: Created: latency-svc-4f5xp
Dec 11 10:03:35.533: INFO: Got endpoints: latency-svc-hjt6r [752.145908ms]
Dec 11 10:03:35.565: INFO: Created: latency-svc-zqv8l
Dec 11 10:03:35.581: INFO: Got endpoints: latency-svc-t8vqd [749.837128ms]
Dec 11 10:03:35.614: INFO: Created: latency-svc-lmfn6
Dec 11 10:03:35.631: INFO: Got endpoints: latency-svc-sh9cj [748.787556ms]
Dec 11 10:03:35.662: INFO: Created: latency-svc-95p24
Dec 11 10:03:35.681: INFO: Got endpoints: latency-svc-cwzkq [750.45482ms]
Dec 11 10:03:35.712: INFO: Created: latency-svc-564nd
Dec 11 10:03:35.731: INFO: Got endpoints: latency-svc-p7rvv [749.071526ms]
Dec 11 10:03:35.762: INFO: Created: latency-svc-8pglf
Dec 11 10:03:35.782: INFO: Got endpoints: latency-svc-g96rh [749.50101ms]
Dec 11 10:03:35.814: INFO: Created: latency-svc-hjllf
Dec 11 10:03:35.831: INFO: Got endpoints: latency-svc-99zct [750.123476ms]
Dec 11 10:03:35.863: INFO: Created: latency-svc-mjjj8
Dec 11 10:03:35.881: INFO: Got endpoints: latency-svc-twdqj [750.215555ms]
Dec 11 10:03:35.913: INFO: Created: latency-svc-zkpjp
Dec 11 10:03:35.932: INFO: Got endpoints: latency-svc-qrllm [750.242891ms]
Dec 11 10:03:35.963: INFO: Created: latency-svc-gf66l
Dec 11 10:03:35.981: INFO: Got endpoints: latency-svc-66nz7 [749.752216ms]
Dec 11 10:03:36.014: INFO: Created: latency-svc-kvcrg
Dec 11 10:03:36.036: INFO: Got endpoints: latency-svc-955nc [754.020499ms]
Dec 11 10:03:36.068: INFO: Created: latency-svc-wkclt
Dec 11 10:03:36.081: INFO: Got endpoints: latency-svc-c9555 [749.753202ms]
Dec 11 10:03:36.115: INFO: Created: latency-svc-hcvz6
Dec 11 10:03:36.131: INFO: Got endpoints: latency-svc-t9wd5 [749.384369ms]
Dec 11 10:03:36.162: INFO: Created: latency-svc-2m9zw
Dec 11 10:03:36.181: INFO: Got endpoints: latency-svc-rdff7 [750.379592ms]
Dec 11 10:03:36.214: INFO: Created: latency-svc-mp6v6
Dec 11 10:03:36.232: INFO: Got endpoints: latency-svc-4f5xp [741.317297ms]
Dec 11 10:03:36.263: INFO: Created: latency-svc-xczxc
Dec 11 10:03:36.281: INFO: Got endpoints: latency-svc-zqv8l [748.361521ms]
Dec 11 10:03:36.313: INFO: Created: latency-svc-lw2d2
Dec 11 10:03:36.332: INFO: Got endpoints: latency-svc-lmfn6 [750.736688ms]
Dec 11 10:03:36.365: INFO: Created: latency-svc-9tppw
Dec 11 10:03:36.381: INFO: Got endpoints: latency-svc-95p24 [750.158125ms]
Dec 11 10:03:36.413: INFO: Created: latency-svc-mf4cc
Dec 11 10:03:36.431: INFO: Got endpoints: latency-svc-564nd [749.749463ms]
Dec 11 10:03:36.463: INFO: Created: latency-svc-tzmx8
Dec 11 10:03:36.481: INFO: Got endpoints: latency-svc-8pglf [750.027951ms]
Dec 11 10:03:36.513: INFO: Created: latency-svc-n4c6g
Dec 11 10:03:36.532: INFO: Got endpoints: latency-svc-hjllf [750.50452ms]
Dec 11 10:03:36.564: INFO: Created: latency-svc-pjx25
Dec 11 10:03:36.581: INFO: Got endpoints: latency-svc-mjjj8 [749.593134ms]
Dec 11 10:03:36.611: INFO: Created: latency-svc-b9n8l
Dec 11 10:03:36.630: INFO: Got endpoints: latency-svc-zkpjp [749.341729ms]
Dec 11 10:03:36.664: INFO: Created: latency-svc-p7sml
Dec 11 10:03:36.681: INFO: Got endpoints: latency-svc-gf66l [749.025412ms]
Dec 11 10:03:36.713: INFO: Created: latency-svc-gj4s7
Dec 11 10:03:36.731: INFO: Got endpoints: latency-svc-kvcrg [750.157568ms]
Dec 11 10:03:36.763: INFO: Created: latency-svc-7jj8c
Dec 11 10:03:36.781: INFO: Got endpoints: latency-svc-wkclt [745.213308ms]
Dec 11 10:03:36.816: INFO: Created: latency-svc-sszvz
Dec 11 10:03:36.832: INFO: Got endpoints: latency-svc-hcvz6 [750.41235ms]
Dec 11 10:03:36.864: INFO: Created: latency-svc-s4mlp
Dec 11 10:03:36.882: INFO: Got endpoints: latency-svc-2m9zw [750.77996ms]
Dec 11 10:03:36.915: INFO: Created: latency-svc-hzbwg
Dec 11 10:03:36.931: INFO: Got endpoints: latency-svc-mp6v6 [750.43567ms]
Dec 11 10:03:36.964: INFO: Created: latency-svc-m8rrg
Dec 11 10:03:36.983: INFO: Got endpoints: latency-svc-xczxc [751.072251ms]
Dec 11 10:03:37.016: INFO: Created: latency-svc-8m5hv
Dec 11 10:03:37.033: INFO: Got endpoints: latency-svc-lw2d2 [752.274834ms]
Dec 11 10:03:37.066: INFO: Created: latency-svc-ns4mq
Dec 11 10:03:37.082: INFO: Got endpoints: latency-svc-9tppw [750.41661ms]
Dec 11 10:03:37.114: INFO: Created: latency-svc-gnbnj
Dec 11 10:03:37.132: INFO: Got endpoints: latency-svc-mf4cc [751.05899ms]
Dec 11 10:03:37.166: INFO: Created: latency-svc-g8tvq
Dec 11 10:03:37.183: INFO: Got endpoints: latency-svc-tzmx8 [751.93246ms]
Dec 11 10:03:37.216: INFO: Created: latency-svc-cr6t4
Dec 11 10:03:37.232: INFO: Got endpoints: latency-svc-n4c6g [751.122219ms]
Dec 11 10:03:37.271: INFO: Created: latency-svc-2mcxz
Dec 11 10:03:37.282: INFO: Got endpoints: latency-svc-pjx25 [749.331252ms]
Dec 11 10:03:37.317: INFO: Created: latency-svc-fkm2f
Dec 11 10:03:37.331: INFO: Got endpoints: latency-svc-b9n8l [750.222385ms]
Dec 11 10:03:37.365: INFO: Created: latency-svc-fsnh2
Dec 11 10:03:37.383: INFO: Got endpoints: latency-svc-p7sml [752.77666ms]
Dec 11 10:03:37.416: INFO: Created: latency-svc-6xqzn
Dec 11 10:03:37.431: INFO: Got endpoints: latency-svc-gj4s7 [750.71384ms]
Dec 11 10:03:37.464: INFO: Created: latency-svc-qc88g
Dec 11 10:03:37.482: INFO: Got endpoints: latency-svc-7jj8c [750.24855ms]
Dec 11 10:03:37.515: INFO: Created: latency-svc-kbntv
Dec 11 10:03:37.532: INFO: Got endpoints: latency-svc-sszvz [750.617423ms]
Dec 11 10:03:37.564: INFO: Created: latency-svc-tzl8r
Dec 11 10:03:37.581: INFO: Got endpoints: latency-svc-s4mlp [749.571153ms]
Dec 11 10:03:37.628: INFO: Created: latency-svc-8dcjb
Dec 11 10:03:37.634: INFO: Got endpoints: latency-svc-hzbwg [752.402285ms]
Dec 11 10:03:37.668: INFO: Created: latency-svc-t8cks
Dec 11 10:03:37.682: INFO: Got endpoints: latency-svc-m8rrg [750.262711ms]
Dec 11 10:03:37.739: INFO: Created: latency-svc-pbn6r
Dec 11 10:03:37.740: INFO: Got endpoints: latency-svc-8m5hv [757.469795ms]
Dec 11 10:03:37.778: INFO: Created: latency-svc-xdtxv
Dec 11 10:03:37.784: INFO: Got endpoints: latency-svc-ns4mq [750.588086ms]
Dec 11 10:03:37.815: INFO: Created: latency-svc-zk8hs
Dec 11 10:03:37.831: INFO: Got endpoints: latency-svc-gnbnj [749.193675ms]
Dec 11 10:03:37.863: INFO: Created: latency-svc-tqsms
Dec 11 10:03:37.881: INFO: Got endpoints: latency-svc-g8tvq [748.752212ms]
Dec 11 10:03:37.913: INFO: Created: latency-svc-w5tbs
Dec 11 10:03:37.931: INFO: Got endpoints: latency-svc-cr6t4 [748.462454ms]
Dec 11 10:03:37.963: INFO: Created: latency-svc-jlk48
Dec 11 10:03:37.981: INFO: Got endpoints: latency-svc-2mcxz [749.060315ms]
Dec 11 10:03:38.012: INFO: Created: latency-svc-74m5j
Dec 11 10:03:38.033: INFO: Got endpoints: latency-svc-fkm2f [751.05108ms]
Dec 11 10:03:38.067: INFO: Created: latency-svc-djmls
Dec 11 10:03:38.081: INFO: Got endpoints: latency-svc-fsnh2 [750.503322ms]
Dec 11 10:03:38.112: INFO: Created: latency-svc-zg685
Dec 11 10:03:38.131: INFO: Got endpoints: latency-svc-6xqzn [748.042042ms]
Dec 11 10:03:38.162: INFO: Created: latency-svc-v29gh
Dec 11 10:03:38.181: INFO: Got endpoints: latency-svc-qc88g [749.601953ms]
Dec 11 10:03:38.214: INFO: Created: latency-svc-hzt7w
Dec 11 10:03:38.231: INFO: Got endpoints: latency-svc-kbntv [749.177232ms]
Dec 11 10:03:38.262: INFO: Created: latency-svc-cb98w
Dec 11 10:03:38.281: INFO: Got endpoints: latency-svc-tzl8r [748.699651ms]
Dec 11 10:03:38.313: INFO: Created: latency-svc-p5ds9
Dec 11 10:03:38.331: INFO: Got endpoints: latency-svc-8dcjb [749.94323ms]
Dec 11 10:03:38.363: INFO: Created: latency-svc-v5hsk
Dec 11 10:03:38.382: INFO: Got endpoints: latency-svc-t8cks [747.739884ms]
Dec 11 10:03:38.413: INFO: Created: latency-svc-7bg26
Dec 11 10:03:38.431: INFO: Got endpoints: latency-svc-pbn6r [749.106994ms]
Dec 11 10:03:38.463: INFO: Created: latency-svc-qlkfh
Dec 11 10:03:38.481: INFO: Got endpoints: latency-svc-xdtxv [740.73814ms]
Dec 11 10:03:38.511: INFO: Created: latency-svc-s98ns
Dec 11 10:03:38.532: INFO: Got endpoints: latency-svc-zk8hs [748.196421ms]
Dec 11 10:03:38.563: INFO: Created: latency-svc-t5nkc
Dec 11 10:03:38.581: INFO: Got endpoints: latency-svc-tqsms [750.251851ms]
Dec 11 10:03:38.613: INFO: Created: latency-svc-zk5vb
Dec 11 10:03:38.631: INFO: Got endpoints: latency-svc-w5tbs [749.708658ms]
Dec 11 10:03:38.662: INFO: Created: latency-svc-tnskz
Dec 11 10:03:38.682: INFO: Got endpoints: latency-svc-jlk48 [750.462573ms]
Dec 11 10:03:38.713: INFO: Created: latency-svc-fm292
Dec 11 10:03:38.732: INFO: Got endpoints: latency-svc-74m5j [750.840112ms]
Dec 11 10:03:38.764: INFO: Created: latency-svc-g9hcg
Dec 11 10:03:38.781: INFO: Got endpoints: latency-svc-djmls [747.881628ms]
Dec 11 10:03:38.812: INFO: Created: latency-svc-9s4mp
Dec 11 10:03:38.830: INFO: Got endpoints: latency-svc-zg685 [749.077507ms]
Dec 11 10:03:38.861: INFO: Created: latency-svc-87m8f
Dec 11 10:03:38.881: INFO: Got endpoints: latency-svc-v29gh [749.513174ms]
Dec 11 10:03:38.915: INFO: Created: latency-svc-xzqfr
Dec 11 10:03:38.931: INFO: Got endpoints: latency-svc-hzt7w [750.288343ms]
Dec 11 10:03:38.968: INFO: Created: latency-svc-5h6bt
Dec 11 10:03:38.982: INFO: Got endpoints: latency-svc-cb98w [751.562953ms]
Dec 11 10:03:39.014: INFO: Created: latency-svc-nswmk
Dec 11 10:03:39.032: INFO: Got endpoints: latency-svc-p5ds9 [750.869176ms]
Dec 11 10:03:39.065: INFO: Created: latency-svc-zhg7w
Dec 11 10:03:39.081: INFO: Got endpoints: latency-svc-v5hsk [749.480734ms]
Dec 11 10:03:39.112: INFO: Created: latency-svc-s6tw4
Dec 11 10:03:39.131: INFO: Got endpoints: latency-svc-7bg26 [748.832938ms]
Dec 11 10:03:39.163: INFO: Created: latency-svc-m6t9f
Dec 11 10:03:39.181: INFO: Got endpoints: latency-svc-qlkfh [749.966631ms]
Dec 11 10:03:39.213: INFO: Created: latency-svc-rqr6d
Dec 11 10:03:39.231: INFO: Got endpoints: latency-svc-s98ns [750.332499ms]
Dec 11 10:03:39.264: INFO: Created: latency-svc-smzgt
Dec 11 10:03:39.281: INFO: Got endpoints: latency-svc-t5nkc [749.152632ms]
Dec 11 10:03:39.312: INFO: Created: latency-svc-gv4qq
Dec 11 10:03:39.331: INFO: Got endpoints: latency-svc-zk5vb [749.668755ms]
Dec 11 10:03:39.363: INFO: Created: latency-svc-h5bxc
Dec 11 10:03:39.380: INFO: Got endpoints: latency-svc-tnskz [749.528911ms]
Dec 11 10:03:39.412: INFO: Created: latency-svc-h7px5
Dec 11 10:03:39.431: INFO: Got endpoints: latency-svc-fm292 [749.19685ms]
Dec 11 10:03:39.464: INFO: Created: latency-svc-w57n4
Dec 11 10:03:39.482: INFO: Got endpoints: latency-svc-g9hcg [749.629655ms]
Dec 11 10:03:39.515: INFO: Created: latency-svc-nm7fl
Dec 11 10:03:39.532: INFO: Got endpoints: latency-svc-9s4mp [751.584147ms]
Dec 11 10:03:39.566: INFO: Created: latency-svc-fmbql
Dec 11 10:03:39.581: INFO: Got endpoints: latency-svc-87m8f [750.698103ms]
Dec 11 10:03:39.613: INFO: Created: latency-svc-vxsgr
Dec 11 10:03:39.631: INFO: Got endpoints: latency-svc-xzqfr [750.348858ms]
Dec 11 10:03:39.663: INFO: Created: latency-svc-wcbbk
Dec 11 10:03:39.681: INFO: Got endpoints: latency-svc-5h6bt [749.956659ms]
Dec 11 10:03:39.713: INFO: Created: latency-svc-5hlcs
Dec 11 10:03:39.730: INFO: Got endpoints: latency-svc-nswmk [747.789714ms]
Dec 11 10:03:39.763: INFO: Created: latency-svc-wk9m5
Dec 11 10:03:39.781: INFO: Got endpoints: latency-svc-zhg7w [749.704905ms]
Dec 11 10:03:39.815: INFO: Created: latency-svc-cctzj
Dec 11 10:03:39.831: INFO: Got endpoints: latency-svc-s6tw4 [750.643528ms]
Dec 11 10:03:39.863: INFO: Created: latency-svc-hfgbn
Dec 11 10:03:39.882: INFO: Got endpoints: latency-svc-m6t9f [750.768424ms]
Dec 11 10:03:39.914: INFO: Created: latency-svc-xb9b2
Dec 11 10:03:39.932: INFO: Got endpoints: latency-svc-rqr6d [750.600133ms]
Dec 11 10:03:39.964: INFO: Created: latency-svc-lxcqd
Dec 11 10:03:39.982: INFO: Got endpoints: latency-svc-smzgt [750.287145ms]
Dec 11 10:03:40.013: INFO: Created: latency-svc-p5ldm
Dec 11 10:03:40.032: INFO: Got endpoints: latency-svc-gv4qq [750.752239ms]
Dec 11 10:03:40.068: INFO: Created: latency-svc-txp7d
Dec 11 10:03:40.080: INFO: Got endpoints: latency-svc-h5bxc [749.092388ms]
Dec 11 10:03:40.112: INFO: Created: latency-svc-gmdlj
Dec 11 10:03:40.131: INFO: Got endpoints: latency-svc-h7px5 [750.756456ms]
Dec 11 10:03:40.164: INFO: Created: latency-svc-qrhld
Dec 11 10:03:40.182: INFO: Got endpoints: latency-svc-w57n4 [750.640613ms]
Dec 11 10:03:40.214: INFO: Created: latency-svc-5jxff
Dec 11 10:03:40.231: INFO: Got endpoints: latency-svc-nm7fl [749.616121ms]
Dec 11 10:03:40.263: INFO: Created: latency-svc-mmf9m
Dec 11 10:03:40.281: INFO: Got endpoints: latency-svc-fmbql [748.44045ms]
Dec 11 10:03:40.318: INFO: Created: latency-svc-vmqpw
Dec 11 10:03:40.331: INFO: Got endpoints: latency-svc-vxsgr [750.154762ms]
Dec 11 10:03:40.363: INFO: Created: latency-svc-8hvv4
Dec 11 10:03:40.381: INFO: Got endpoints: latency-svc-wcbbk [749.609062ms]
Dec 11 10:03:40.413: INFO: Created: latency-svc-dgjxv
Dec 11 10:03:40.431: INFO: Got endpoints: latency-svc-5hlcs [749.611162ms]
Dec 11 10:03:40.463: INFO: Created: latency-svc-4q8l4
Dec 11 10:03:40.481: INFO: Got endpoints: latency-svc-wk9m5 [751.193507ms]
Dec 11 10:03:40.515: INFO: Created: latency-svc-kvb94
Dec 11 10:03:40.532: INFO: Got endpoints: latency-svc-cctzj [750.994539ms]
Dec 11 10:03:40.564: INFO: Created: latency-svc-9kzff
Dec 11 10:03:40.581: INFO: Got endpoints: latency-svc-hfgbn [749.867505ms]
Dec 11 10:03:40.612: INFO: Created: latency-svc-4kfx5
Dec 11 10:03:40.631: INFO: Got endpoints: latency-svc-xb9b2 [748.991622ms]
Dec 11 10:03:40.663: INFO: Created: latency-svc-wgj5r
Dec 11 10:03:40.682: INFO: Got endpoints: latency-svc-lxcqd [750.600006ms]
Dec 11 10:03:40.714: INFO: Created: latency-svc-g9qgw
Dec 11 10:03:40.731: INFO: Got endpoints: latency-svc-p5ldm [749.740734ms]
Dec 11 10:03:40.781: INFO: Got endpoints: latency-svc-txp7d [748.802564ms]
Dec 11 10:03:40.831: INFO: Got endpoints: latency-svc-gmdlj [750.863148ms]
Dec 11 10:03:40.882: INFO: Got endpoints: latency-svc-qrhld [751.119961ms]
Dec 11 10:03:40.931: INFO: Got endpoints: latency-svc-5jxff [749.829663ms]
Dec 11 10:03:40.981: INFO: Got endpoints: latency-svc-mmf9m [749.885992ms]
Dec 11 10:03:41.032: INFO: Got endpoints: latency-svc-vmqpw [751.656449ms]
Dec 11 10:03:41.081: INFO: Got endpoints: latency-svc-8hvv4 [749.44023ms]
Dec 11 10:03:41.132: INFO: Got endpoints: latency-svc-dgjxv [750.726184ms]
Dec 11 10:03:41.181: INFO: Got endpoints: latency-svc-4q8l4 [750.019187ms]
Dec 11 10:03:41.232: INFO: Got endpoints: latency-svc-kvb94 [750.222555ms]
Dec 11 10:03:41.282: INFO: Got endpoints: latency-svc-9kzff [749.212286ms]
Dec 11 10:03:41.331: INFO: Got endpoints: latency-svc-4kfx5 [749.325439ms]
Dec 11 10:03:41.381: INFO: Got endpoints: latency-svc-wgj5r [750.674894ms]
Dec 11 10:03:41.432: INFO: Got endpoints: latency-svc-g9qgw [749.388037ms]
Dec 11 10:03:41.432: INFO: Latencies: [45.498071ms 67.582869ms 89.793273ms 112.812628ms 135.201208ms 159.16429ms 182.029764ms 204.306886ms 225.527942ms 247.976715ms 270.07697ms 293.940058ms 319.228994ms 330.881893ms 330.971809ms 332.674782ms 333.224541ms 333.513832ms 333.635216ms 333.744103ms 334.024361ms 334.120305ms 334.352093ms 334.628333ms 334.658901ms 334.750765ms 335.002789ms 335.022794ms 335.060482ms 335.141932ms 335.26845ms 335.522795ms 335.682754ms 335.73798ms 335.827435ms 335.930168ms 336.071447ms 336.257907ms 336.352271ms 336.789083ms 336.840939ms 337.041414ms 337.171508ms 337.555334ms 338.243457ms 338.312535ms 339.047608ms 339.837894ms 340.514979ms 341.697898ms 342.414739ms 345.066392ms 347.558865ms 362.682431ms 379.793609ms 411.67688ms 439.590736ms 462.046954ms 494.740263ms 522.283648ms 547.700879ms 573.158616ms 599.475962ms 628.804707ms 652.860404ms 679.644239ms 703.51542ms 727.696369ms 740.73814ms 741.317297ms 743.324105ms 743.686389ms 744.835594ms 745.007744ms 745.084075ms 745.213308ms 747.098033ms 747.739884ms 747.789714ms 747.858766ms 747.881628ms 748.042042ms 748.196421ms 748.361521ms 748.44045ms 748.460022ms 748.462454ms 748.699208ms 748.699651ms 748.752212ms 748.787556ms 748.802564ms 748.832938ms 748.986463ms 748.991622ms 749.025412ms 749.060315ms 749.071526ms 749.077507ms 749.092388ms 749.106994ms 749.152632ms 749.177232ms 749.193675ms 749.19685ms 749.212286ms 749.325439ms 749.331252ms 749.341729ms 749.384369ms 749.388037ms 749.44023ms 749.480734ms 749.50101ms 749.513174ms 749.528911ms 749.571153ms 749.593134ms 749.601953ms 749.609062ms 749.611162ms 749.616121ms 749.629655ms 749.668755ms 749.704905ms 749.708658ms 749.740734ms 749.749463ms 749.752216ms 749.753202ms 749.829663ms 749.837128ms 749.866026ms 749.867505ms 749.885992ms 749.94323ms 749.956659ms 749.966631ms 750.019187ms 750.027951ms 750.123476ms 750.154762ms 750.157568ms 750.158125ms 750.215555ms 750.222385ms 750.222555ms 750.242891ms 750.24855ms 750.251851ms 750.258374ms 750.262711ms 750.287145ms 750.288343ms 750.332499ms 750.348858ms 750.379592ms 750.41235ms 750.41661ms 750.43567ms 750.45482ms 750.462573ms 750.503322ms 750.50452ms 750.588086ms 750.600006ms 750.600133ms 750.617423ms 750.640613ms 750.643528ms 750.674894ms 750.698103ms 750.71384ms 750.726184ms 750.736688ms 750.752239ms 750.756456ms 750.768424ms 750.77996ms 750.840112ms 750.863148ms 750.869176ms 750.994539ms 751.05108ms 751.05899ms 751.072251ms 751.119961ms 751.122219ms 751.193507ms 751.562953ms 751.584147ms 751.656449ms 751.93246ms 752.145908ms 752.274834ms 752.402285ms 752.77666ms 754.020499ms 757.469795ms 757.861936ms]
Dec 11 10:03:41.432: INFO: 50 %ile: 749.106994ms
Dec 11 10:03:41.432: INFO: 90 %ile: 750.863148ms
Dec 11 10:03:41.432: INFO: 99 %ile: 757.469795ms
Dec 11 10:03:41.432: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:03:41.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-8jxzr" for this suite.
Dec 11 10:03:59.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:03:59.517: INFO: namespace: e2e-tests-svc-latency-8jxzr, resource: bindings, ignored listing per whitelist
Dec 11 10:03:59.522: INFO: namespace e2e-tests-svc-latency-8jxzr deletion completed in 18.087134693s

• [SLOW TEST:28.946 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:03:59.522: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-145409d4-fd2c-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume configMaps
Dec 11 10:03:59.646: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1455ab9a-fd2c-11e8-897d-5ac57959ef46" in namespace "e2e-tests-projected-2cbtg" to be "success or failure"
Dec 11 10:03:59.648: INFO: Pod "pod-projected-configmaps-1455ab9a-fd2c-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027234ms
Dec 11 10:04:01.651: INFO: Pod "pod-projected-configmaps-1455ab9a-fd2c-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004837024s
STEP: Saw pod success
Dec 11 10:04:01.651: INFO: Pod "pod-projected-configmaps-1455ab9a-fd2c-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:04:01.653: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-projected-configmaps-1455ab9a-fd2c-11e8-897d-5ac57959ef46 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 10:04:01.680: INFO: Waiting for pod pod-projected-configmaps-1455ab9a-fd2c-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:04:01.682: INFO: Pod pod-projected-configmaps-1455ab9a-fd2c-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:04:01.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2cbtg" for this suite.
Dec 11 10:04:07.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:04:07.719: INFO: namespace: e2e-tests-projected-2cbtg, resource: bindings, ignored listing per whitelist
Dec 11 10:04:07.773: INFO: namespace e2e-tests-projected-2cbtg deletion completed in 6.088174676s

• [SLOW TEST:8.251 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:04:07.773: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Dec 11 10:04:07.883: INFO: Waiting up to 5m0s for pod "var-expansion-193e9dd3-fd2c-11e8-897d-5ac57959ef46" in namespace "e2e-tests-var-expansion-4z7l5" to be "success or failure"
Dec 11 10:04:07.885: INFO: Pod "var-expansion-193e9dd3-fd2c-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.936466ms
Dec 11 10:04:09.888: INFO: Pod "var-expansion-193e9dd3-fd2c-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004389615s
STEP: Saw pod success
Dec 11 10:04:09.888: INFO: Pod "var-expansion-193e9dd3-fd2c-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:04:09.890: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod var-expansion-193e9dd3-fd2c-11e8-897d-5ac57959ef46 container dapi-container: <nil>
STEP: delete the pod
Dec 11 10:04:09.919: INFO: Waiting for pod var-expansion-193e9dd3-fd2c-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:04:09.921: INFO: Pod var-expansion-193e9dd3-fd2c-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:04:09.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-4z7l5" for this suite.
Dec 11 10:04:15.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:04:15.995: INFO: namespace: e2e-tests-var-expansion-4z7l5, resource: bindings, ignored listing per whitelist
Dec 11 10:04:16.011: INFO: namespace e2e-tests-var-expansion-4z7l5 deletion completed in 6.086417307s

• [SLOW TEST:8.238 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:04:16.011: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-6s79c
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 11 10:04:16.113: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 11 10:04:38.211: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.111.88.3:8080/dial?request=hostName&protocol=http&host=100.122.170.120&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-6s79c PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 10:04:38.211: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
Dec 11 10:04:38.291: INFO: Waiting for endpoints: map[]
Dec 11 10:04:38.293: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.111.88.3:8080/dial?request=hostName&protocol=http&host=100.111.88.62&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-6s79c PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 10:04:38.293: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
Dec 11 10:04:38.370: INFO: Waiting for endpoints: map[]
Dec 11 10:04:38.372: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.111.88.3:8080/dial?request=hostName&protocol=http&host=100.111.240.235&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-6s79c PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 10:04:38.372: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
Dec 11 10:04:38.448: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:04:38.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-6s79c" for this suite.
Dec 11 10:05:00.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:05:00.534: INFO: namespace: e2e-tests-pod-network-test-6s79c, resource: bindings, ignored listing per whitelist
Dec 11 10:05:00.543: INFO: namespace e2e-tests-pod-network-test-6s79c deletion completed in 22.090973706s

• [SLOW TEST:44.532 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:05:00.543: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-bttd8/configmap-test-38b21a9c-fd2c-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume configMaps
Dec 11 10:05:00.661: INFO: Waiting up to 5m0s for pod "pod-configmaps-38b3eb8d-fd2c-11e8-897d-5ac57959ef46" in namespace "e2e-tests-configmap-bttd8" to be "success or failure"
Dec 11 10:05:00.663: INFO: Pod "pod-configmaps-38b3eb8d-fd2c-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.899151ms
Dec 11 10:05:02.665: INFO: Pod "pod-configmaps-38b3eb8d-fd2c-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004449879s
STEP: Saw pod success
Dec 11 10:05:02.665: INFO: Pod "pod-configmaps-38b3eb8d-fd2c-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:05:02.667: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-configmaps-38b3eb8d-fd2c-11e8-897d-5ac57959ef46 container env-test: <nil>
STEP: delete the pod
Dec 11 10:05:02.693: INFO: Waiting for pod pod-configmaps-38b3eb8d-fd2c-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:05:02.695: INFO: Pod pod-configmaps-38b3eb8d-fd2c-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:05:02.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-bttd8" for this suite.
Dec 11 10:05:08.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:05:08.795: INFO: namespace: e2e-tests-configmap-bttd8, resource: bindings, ignored listing per whitelist
Dec 11 10:05:08.795: INFO: namespace e2e-tests-configmap-bttd8 deletion completed in 6.096809261s

• [SLOW TEST:8.252 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:05:08.795: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:05:10.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-5sglx" for this suite.
Dec 11 10:05:17.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:05:17.012: INFO: namespace: e2e-tests-emptydir-wrapper-5sglx, resource: bindings, ignored listing per whitelist
Dec 11 10:05:17.072: INFO: namespace e2e-tests-emptydir-wrapper-5sglx deletion completed in 6.087255796s

• [SLOW TEST:8.277 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:05:17.073: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-428caa49-fd2c-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume configMaps
Dec 11 10:05:17.192: INFO: Waiting up to 5m0s for pod "pod-configmaps-428e3da6-fd2c-11e8-897d-5ac57959ef46" in namespace "e2e-tests-configmap-zrg98" to be "success or failure"
Dec 11 10:05:17.194: INFO: Pod "pod-configmaps-428e3da6-fd2c-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.181913ms
Dec 11 10:05:19.197: INFO: Pod "pod-configmaps-428e3da6-fd2c-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005156569s
STEP: Saw pod success
Dec 11 10:05:19.197: INFO: Pod "pod-configmaps-428e3da6-fd2c-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:05:19.199: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-configmaps-428e3da6-fd2c-11e8-897d-5ac57959ef46 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 10:05:19.228: INFO: Waiting for pod pod-configmaps-428e3da6-fd2c-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:05:19.230: INFO: Pod pod-configmaps-428e3da6-fd2c-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:05:19.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zrg98" for this suite.
Dec 11 10:05:25.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:05:25.343: INFO: namespace: e2e-tests-configmap-zrg98, resource: bindings, ignored listing per whitelist
Dec 11 10:05:25.362: INFO: namespace e2e-tests-configmap-zrg98 deletion completed in 6.128432783s

• [SLOW TEST:8.289 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:05:25.362: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 11 10:05:25.467: INFO: Waiting up to 5m0s for pod "downwardapi-volume-477cd259-fd2c-11e8-897d-5ac57959ef46" in namespace "e2e-tests-projected-xkc8n" to be "success or failure"
Dec 11 10:05:25.469: INFO: Pod "downwardapi-volume-477cd259-fd2c-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05018ms
Dec 11 10:05:27.471: INFO: Pod "downwardapi-volume-477cd259-fd2c-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004570773s
STEP: Saw pod success
Dec 11 10:05:27.471: INFO: Pod "downwardapi-volume-477cd259-fd2c-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:05:27.473: INFO: Trying to get logs from node ip-172-25-45-107.us-west-1.compute.internal pod downwardapi-volume-477cd259-fd2c-11e8-897d-5ac57959ef46 container client-container: <nil>
STEP: delete the pod
Dec 11 10:05:27.503: INFO: Waiting for pod downwardapi-volume-477cd259-fd2c-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:05:27.505: INFO: Pod downwardapi-volume-477cd259-fd2c-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:05:27.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xkc8n" for this suite.
Dec 11 10:05:33.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:05:33.531: INFO: namespace: e2e-tests-projected-xkc8n, resource: bindings, ignored listing per whitelist
Dec 11 10:05:33.597: INFO: namespace e2e-tests-projected-xkc8n deletion completed in 6.08927939s

• [SLOW TEST:8.236 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:05:33.598: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec 11 10:05:33.700: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:05:36.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-r59wn" for this suite.
Dec 11 10:05:42.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:05:42.424: INFO: namespace: e2e-tests-init-container-r59wn, resource: bindings, ignored listing per whitelist
Dec 11 10:05:42.430: INFO: namespace e2e-tests-init-container-r59wn deletion completed in 6.085978302s

• [SLOW TEST:8.832 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:05:42.430: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Dec 11 10:05:43.039: INFO: Waiting up to 5m0s for pod "pod-service-account-51f61e8a-fd2c-11e8-897d-5ac57959ef46-dbnsv" in namespace "e2e-tests-svcaccounts-nbb7d" to be "success or failure"
Dec 11 10:05:43.041: INFO: Pod "pod-service-account-51f61e8a-fd2c-11e8-897d-5ac57959ef46-dbnsv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04257ms
Dec 11 10:05:45.044: INFO: Pod "pod-service-account-51f61e8a-fd2c-11e8-897d-5ac57959ef46-dbnsv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005065292s
STEP: Saw pod success
Dec 11 10:05:45.044: INFO: Pod "pod-service-account-51f61e8a-fd2c-11e8-897d-5ac57959ef46-dbnsv" satisfied condition "success or failure"
Dec 11 10:05:45.046: INFO: Trying to get logs from node ip-172-25-45-107.us-west-1.compute.internal pod pod-service-account-51f61e8a-fd2c-11e8-897d-5ac57959ef46-dbnsv container token-test: <nil>
STEP: delete the pod
Dec 11 10:05:45.075: INFO: Waiting for pod pod-service-account-51f61e8a-fd2c-11e8-897d-5ac57959ef46-dbnsv to disappear
Dec 11 10:05:45.077: INFO: Pod pod-service-account-51f61e8a-fd2c-11e8-897d-5ac57959ef46-dbnsv no longer exists
STEP: Creating a pod to test consume service account root CA
Dec 11 10:05:45.088: INFO: Waiting up to 5m0s for pod "pod-service-account-51f61e8a-fd2c-11e8-897d-5ac57959ef46-2xvg9" in namespace "e2e-tests-svcaccounts-nbb7d" to be "success or failure"
Dec 11 10:05:45.090: INFO: Pod "pod-service-account-51f61e8a-fd2c-11e8-897d-5ac57959ef46-2xvg9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.335899ms
Dec 11 10:05:47.093: INFO: Pod "pod-service-account-51f61e8a-fd2c-11e8-897d-5ac57959ef46-2xvg9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005578759s
STEP: Saw pod success
Dec 11 10:05:47.094: INFO: Pod "pod-service-account-51f61e8a-fd2c-11e8-897d-5ac57959ef46-2xvg9" satisfied condition "success or failure"
Dec 11 10:05:47.096: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-service-account-51f61e8a-fd2c-11e8-897d-5ac57959ef46-2xvg9 container root-ca-test: <nil>
STEP: delete the pod
Dec 11 10:05:47.124: INFO: Waiting for pod pod-service-account-51f61e8a-fd2c-11e8-897d-5ac57959ef46-2xvg9 to disappear
Dec 11 10:05:47.126: INFO: Pod pod-service-account-51f61e8a-fd2c-11e8-897d-5ac57959ef46-2xvg9 no longer exists
STEP: Creating a pod to test consume service account namespace
Dec 11 10:05:47.136: INFO: Waiting up to 5m0s for pod "pod-service-account-51f61e8a-fd2c-11e8-897d-5ac57959ef46-dtpx4" in namespace "e2e-tests-svcaccounts-nbb7d" to be "success or failure"
Dec 11 10:05:47.138: INFO: Pod "pod-service-account-51f61e8a-fd2c-11e8-897d-5ac57959ef46-dtpx4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.943141ms
Dec 11 10:05:49.141: INFO: Pod "pod-service-account-51f61e8a-fd2c-11e8-897d-5ac57959ef46-dtpx4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005092223s
STEP: Saw pod success
Dec 11 10:05:49.141: INFO: Pod "pod-service-account-51f61e8a-fd2c-11e8-897d-5ac57959ef46-dtpx4" satisfied condition "success or failure"
Dec 11 10:05:49.144: INFO: Trying to get logs from node ip-172-25-45-107.us-west-1.compute.internal pod pod-service-account-51f61e8a-fd2c-11e8-897d-5ac57959ef46-dtpx4 container namespace-test: <nil>
STEP: delete the pod
Dec 11 10:05:49.172: INFO: Waiting for pod pod-service-account-51f61e8a-fd2c-11e8-897d-5ac57959ef46-dtpx4 to disappear
Dec 11 10:05:49.174: INFO: Pod pod-service-account-51f61e8a-fd2c-11e8-897d-5ac57959ef46-dtpx4 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:05:49.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-nbb7d" for this suite.
Dec 11 10:05:55.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:05:55.227: INFO: namespace: e2e-tests-svcaccounts-nbb7d, resource: bindings, ignored listing per whitelist
Dec 11 10:05:55.263: INFO: namespace e2e-tests-svcaccounts-nbb7d deletion completed in 6.085734983s

• [SLOW TEST:12.833 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:05:55.263: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 11 10:05:55.363: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:05:57.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-kn6vc" for this suite.
Dec 11 10:06:47.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:06:47.434: INFO: namespace: e2e-tests-pods-kn6vc, resource: bindings, ignored listing per whitelist
Dec 11 10:06:47.489: INFO: namespace e2e-tests-pods-kn6vc deletion completed in 50.090288631s

• [SLOW TEST:52.226 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:06:47.489: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 11 10:06:47.601: INFO: Waiting up to 5m0s for pod "downward-api-787185ee-fd2c-11e8-897d-5ac57959ef46" in namespace "e2e-tests-downward-api-rxr6z" to be "success or failure"
Dec 11 10:06:47.603: INFO: Pod "downward-api-787185ee-fd2c-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.200165ms
Dec 11 10:06:49.607: INFO: Pod "downward-api-787185ee-fd2c-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00550293s
STEP: Saw pod success
Dec 11 10:06:49.607: INFO: Pod "downward-api-787185ee-fd2c-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:06:49.609: INFO: Trying to get logs from node ip-172-25-45-107.us-west-1.compute.internal pod downward-api-787185ee-fd2c-11e8-897d-5ac57959ef46 container dapi-container: <nil>
STEP: delete the pod
Dec 11 10:06:49.643: INFO: Waiting for pod downward-api-787185ee-fd2c-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:06:49.646: INFO: Pod downward-api-787185ee-fd2c-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:06:49.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rxr6z" for this suite.
Dec 11 10:06:55.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:06:55.741: INFO: namespace: e2e-tests-downward-api-rxr6z, resource: bindings, ignored listing per whitelist
Dec 11 10:06:55.743: INFO: namespace e2e-tests-downward-api-rxr6z deletion completed in 6.093166944s

• [SLOW TEST:8.254 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:06:55.743: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Dec 11 10:06:55.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 cluster-info'
Dec 11 10:06:55.990: INFO: stderr: ""
Dec 11 10:06:55.990: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://100.64.0.1:443\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://100.64.0.1:443/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://100.64.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:06:55.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vd5hp" for this suite.
Dec 11 10:07:02.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:07:02.018: INFO: namespace: e2e-tests-kubectl-vd5hp, resource: bindings, ignored listing per whitelist
Dec 11 10:07:02.079: INFO: namespace e2e-tests-kubectl-vd5hp deletion completed in 6.085697315s

• [SLOW TEST:6.336 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:07:02.079: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 11 10:07:02.185: INFO: Waiting up to 5m0s for pod "downward-api-8122d59b-fd2c-11e8-897d-5ac57959ef46" in namespace "e2e-tests-downward-api-pq75l" to be "success or failure"
Dec 11 10:07:02.187: INFO: Pod "downward-api-8122d59b-fd2c-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.089086ms
Dec 11 10:07:04.190: INFO: Pod "downward-api-8122d59b-fd2c-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004813204s
STEP: Saw pod success
Dec 11 10:07:04.190: INFO: Pod "downward-api-8122d59b-fd2c-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:07:04.192: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod downward-api-8122d59b-fd2c-11e8-897d-5ac57959ef46 container dapi-container: <nil>
STEP: delete the pod
Dec 11 10:07:04.218: INFO: Waiting for pod downward-api-8122d59b-fd2c-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:07:04.220: INFO: Pod downward-api-8122d59b-fd2c-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:07:04.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pq75l" for this suite.
Dec 11 10:07:10.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:07:10.276: INFO: namespace: e2e-tests-downward-api-pq75l, resource: bindings, ignored listing per whitelist
Dec 11 10:07:10.319: INFO: namespace e2e-tests-downward-api-pq75l deletion completed in 6.095318865s

• [SLOW TEST:8.240 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:07:10.319: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Dec 11 10:07:10.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 --namespace=e2e-tests-kubectl-xstnt run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec 11 10:07:11.564: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec 11 10:07:11.564: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:07:13.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xstnt" for this suite.
Dec 11 10:07:19.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:07:19.652: INFO: namespace: e2e-tests-kubectl-xstnt, resource: bindings, ignored listing per whitelist
Dec 11 10:07:19.667: INFO: namespace e2e-tests-kubectl-xstnt deletion completed in 6.094506634s

• [SLOW TEST:9.348 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:07:19.667: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Dec 11 10:07:19.783: INFO: Waiting up to 5m0s for pod "client-containers-8ba03336-fd2c-11e8-897d-5ac57959ef46" in namespace "e2e-tests-containers-g4fds" to be "success or failure"
Dec 11 10:07:19.785: INFO: Pod "client-containers-8ba03336-fd2c-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.202791ms
Dec 11 10:07:21.788: INFO: Pod "client-containers-8ba03336-fd2c-11e8-897d-5ac57959ef46": Phase="Running", Reason="", readiness=true. Elapsed: 2.004927564s
Dec 11 10:07:23.791: INFO: Pod "client-containers-8ba03336-fd2c-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007828168s
STEP: Saw pod success
Dec 11 10:07:23.791: INFO: Pod "client-containers-8ba03336-fd2c-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:07:23.793: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod client-containers-8ba03336-fd2c-11e8-897d-5ac57959ef46 container test-container: <nil>
STEP: delete the pod
Dec 11 10:07:23.821: INFO: Waiting for pod client-containers-8ba03336-fd2c-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:07:23.823: INFO: Pod client-containers-8ba03336-fd2c-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:07:23.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-g4fds" for this suite.
Dec 11 10:07:29.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:07:29.862: INFO: namespace: e2e-tests-containers-g4fds, resource: bindings, ignored listing per whitelist
Dec 11 10:07:29.919: INFO: namespace e2e-tests-containers-g4fds deletion completed in 6.092672476s

• [SLOW TEST:10.252 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:07:29.919: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 11 10:07:30.034: INFO: Waiting up to 5m0s for pod "downward-api-91bc45c6-fd2c-11e8-897d-5ac57959ef46" in namespace "e2e-tests-downward-api-hjjrm" to be "success or failure"
Dec 11 10:07:30.036: INFO: Pod "downward-api-91bc45c6-fd2c-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064839ms
Dec 11 10:07:32.039: INFO: Pod "downward-api-91bc45c6-fd2c-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005132796s
STEP: Saw pod success
Dec 11 10:07:32.039: INFO: Pod "downward-api-91bc45c6-fd2c-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:07:32.041: INFO: Trying to get logs from node ip-172-25-45-107.us-west-1.compute.internal pod downward-api-91bc45c6-fd2c-11e8-897d-5ac57959ef46 container dapi-container: <nil>
STEP: delete the pod
Dec 11 10:07:32.070: INFO: Waiting for pod downward-api-91bc45c6-fd2c-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:07:32.072: INFO: Pod downward-api-91bc45c6-fd2c-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:07:32.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hjjrm" for this suite.
Dec 11 10:07:38.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:07:38.124: INFO: namespace: e2e-tests-downward-api-hjjrm, resource: bindings, ignored listing per whitelist
Dec 11 10:07:38.162: INFO: namespace e2e-tests-downward-api-hjjrm deletion completed in 6.08720048s

• [SLOW TEST:8.244 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:07:38.163: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-96a53947-fd2c-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume configMaps
Dec 11 10:07:38.281: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-96a6c768-fd2c-11e8-897d-5ac57959ef46" in namespace "e2e-tests-projected-dzw59" to be "success or failure"
Dec 11 10:07:38.283: INFO: Pod "pod-projected-configmaps-96a6c768-fd2c-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.086453ms
Dec 11 10:07:40.286: INFO: Pod "pod-projected-configmaps-96a6c768-fd2c-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004753907s
STEP: Saw pod success
Dec 11 10:07:40.286: INFO: Pod "pod-projected-configmaps-96a6c768-fd2c-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:07:40.288: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-projected-configmaps-96a6c768-fd2c-11e8-897d-5ac57959ef46 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 10:07:40.317: INFO: Waiting for pod pod-projected-configmaps-96a6c768-fd2c-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:07:40.319: INFO: Pod pod-projected-configmaps-96a6c768-fd2c-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:07:40.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dzw59" for this suite.
Dec 11 10:07:46.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:07:46.372: INFO: namespace: e2e-tests-projected-dzw59, resource: bindings, ignored listing per whitelist
Dec 11 10:07:46.414: INFO: namespace e2e-tests-projected-dzw59 deletion completed in 6.091749705s

• [SLOW TEST:8.251 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:07:46.414: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec 11 10:07:46.517: INFO: PodSpec: initContainers in spec.initContainers
Dec 11 10:08:33.693: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-9b914b6f-fd2c-11e8-897d-5ac57959ef46", GenerateName:"", Namespace:"e2e-tests-init-container-n4h4c", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-n4h4c/pods/pod-init-9b914b6f-fd2c-11e8-897d-5ac57959ef46", UID:"9b917423-fd2c-11e8-8e03-0681e6464a68", ResourceVersion:"21964765", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63680119666, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"517903613"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-d5bh4", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002bc7740), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-d5bh4", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-d5bh4", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-d5bh4", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0026b6f08), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-25-62-1.us-west-1.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0029a6600), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0026b6f90)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0026b6fb0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680119666, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680119666, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680119666, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.25.62.1", PodIP:"100.111.88.25", StartTime:(*v1.Time)(0xc002a9b220), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002296af0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002296b60)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:2a03a6059f21e150ae84b0973863609494aad70f0a80eaeb64bddd8d92465812", ContainerID:"docker://56cb547431711e1e4897d00ced0ec6519763e38859ba692cda7a478dd2ee1127"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002a9b260), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002a9b240), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:08:33.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-n4h4c" for this suite.
Dec 11 10:09:33.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:09:33.742: INFO: namespace: e2e-tests-init-container-n4h4c, resource: bindings, ignored listing per whitelist
Dec 11 10:09:33.784: INFO: namespace e2e-tests-init-container-n4h4c deletion completed in 1m0.087637902s

• [SLOW TEST:107.370 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:09:33.784: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Dec 11 10:09:33.886: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 11 10:09:33.892: INFO: Waiting for terminating namespaces to be deleted...
Dec 11 10:09:33.894: INFO: 
Logging pods the kubelet thinks is on node ip-172-25-45-107.us-west-1.compute.internal before test
Dec 11 10:09:33.904: INFO: prd-pf-activity-svc-platform-activity-svc-855df677b4-s5r9p from platform started at 2018-11-19 14:59:43 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.904: INFO: 	Container prd-pf-activity-svc-platform-activity-svc ready: true, restart count 0
Dec 11 10:09:33.904: INFO: prd-pf-audit-svc-platform-audit-svc-78f5998486-2rmn5 from platform started at 2018-11-19 14:59:44 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.904: INFO: 	Container prd-pf-audit-svc-platform-audit-svc ready: true, restart count 0
Dec 11 10:09:33.904: INFO: prd-dss-qni-illustration-svc-dss-qni-illustration-service-tjbw9 from platform started at 2018-11-26 11:18:56 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.904: INFO: 	Container prd-dss-qni-illustration-svc-dss-qni-illustration-service ready: true, restart count 0
Dec 11 10:09:33.904: INFO: prd-efk-elasticsearch-fluentd-sw94s from infra started at 2018-12-11 09:59:59 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container fluentd ready: false, restart count 0
Dec 11 10:09:33.904: INFO: prd-keycloak-pgpool-58b949979d-wllt4 from platform started at 2018-11-19 14:59:42 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container prd-keycloak-pgpool ready: true, restart count 2
Dec 11 10:09:33.904: INFO: prd-pf-sign-svc-platform-signup-svc-7dcfdd559-llx49 from platform started at 2018-11-19 14:59:48 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.904: INFO: 	Container prd-pf-sign-svc-platform-signup-svc ready: true, restart count 0
Dec 11 10:09:33.904: INFO: prd-botfactory-chatbot-ui-pfm-botfactory-chatbot-ui-7bd798pjt9m from platform started at 2018-11-21 10:41:40 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container pfm-botfactory-chatbot-ui ready: true, restart count 0
Dec 11 10:09:33.904: INFO: datadog-kube-state-metrics-7d48b4db57-9245w from infra started at 2018-11-19 14:59:40 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container kube-state-metrics ready: true, restart count 0
Dec 11 10:09:33.904: INFO: prd-dss-leadcloser-ui-658768bd4b-84zb9 from platform started at 2018-11-20 12:27:09 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container dss-leadcloser-ui ready: true, restart count 0
Dec 11 10:09:33.904: INFO: prd-ibf-botfactory-admin-svc-botfactory-admin-service-59f4n5m5f from platform started at 2018-11-21 11:08:42 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container botfactory-admin-service ready: true, restart count 0
Dec 11 10:09:33.904: INFO: prd-pf-doc-svc-platform-doc-svc-6bc8488db8-cncz8 from platform started at 2018-11-19 14:59:45 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.904: INFO: 	Container prd-pf-doc-svc-platform-doc-svc ready: true, restart count 0
Dec 11 10:09:33.904: INFO: tiller-deploy-f55c64689-4jfg5 from kube-system started at 2018-11-19 14:59:40 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container tiller ready: true, restart count 0
Dec 11 10:09:33.904: INFO: prd-dss-pm-profile-svc-dss-pm-profile-service-556b68d65-rlqgv from platform started at 2018-11-19 14:59:42 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container dss-pm-profile-service ready: true, restart count 0
Dec 11 10:09:33.904: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.904: INFO: default-http-backend-66b447d9cf-cvp7c from ingress-nginx started at 2018-11-19 14:59:42 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container default-http-backend ready: true, restart count 0
Dec 11 10:09:33.904: INFO: metrics-server-8555b5f58f-7qjkk from kube-system started at 2018-11-19 14:59:40 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container metrics-server ready: true, restart count 0
Dec 11 10:09:33.904: INFO: prd-ibf-botfactory-agent-svc-botfactory-agent-service-56f5mkg6f from platform started at 2018-11-21 10:57:49 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container botfactory-agent-service ready: true, restart count 0
Dec 11 10:09:33.904: INFO: prd-pf-iam-svc-platform-iam-svc-5d57975b5-vjrk6 from platform started at 2018-11-19 14:59:47 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.904: INFO: 	Container prd-pf-iam-svc-platform-iam-svc ready: true, restart count 0
Dec 11 10:09:33.904: INFO: prd-pf-notes-svc-platform-notes-svc-5c99df689c-bdfww from platform started at 2018-11-19 14:59:47 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.904: INFO: 	Container prd-pf-notes-svc-platform-notes-svc ready: true, restart count 0
Dec 11 10:09:33.904: INFO: dr-kong-kong-55df5b9f69-tn88c from platform started at 2018-11-19 14:59:40 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container dr-kong-kong ready: true, restart count 1
Dec 11 10:09:33.904: INFO: platform-utils-svc-5bb47f77bd-jjdgj from platform started at 2018-11-19 14:59:40 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container platform-utils-svc ready: true, restart count 0
Dec 11 10:09:33.904: INFO: prd-pf-calen-svc-platform-calen-svc-59dc958758-kgjtc from platform started at 2018-11-19 14:59:44 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.904: INFO: 	Container prd-pf-calen-svc-platform-calen-svc ready: true, restart count 0
Dec 11 10:09:33.904: INFO: ubuntu-5f89d47d59-pz2h8 from platform started at 2018-11-19 14:59:40 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container ubuntu ready: true, restart count 0
Dec 11 10:09:33.904: INFO: kube-dns-7c4d8456dd-k6dkm from kube-system started at 2018-11-19 14:59:40 +0000 UTC (3 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container dnsmasq ready: true, restart count 0
Dec 11 10:09:33.904: INFO: 	Container kubedns ready: true, restart count 0
Dec 11 10:09:33.904: INFO: 	Container sidecar ready: true, restart count 0
Dec 11 10:09:33.904: INFO: prd-pf-blkusrimp-svc-platform-blkusrimp-svc-7d8d5c459f-78l6p from platform started at 2018-11-19 14:59:44 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.904: INFO: 	Container prd-pf-blkusrimp-svc-platform-blkusrimp-svc ready: true, restart count 0
Dec 11 10:09:33.904: INFO: kube-proxy-ip-172-25-45-107.us-west-1.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Dec 11 10:09:33.904: INFO: datadog-datadog-5m28x from infra started at 2018-11-19 14:57:43 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container datadog ready: true, restart count 2
Dec 11 10:09:33.904: INFO: calico-node-j87ww from kube-system started at 2018-11-19 14:57:43 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container calico-node ready: true, restart count 0
Dec 11 10:09:33.904: INFO: 	Container install-cni ready: true, restart count 0
Dec 11 10:09:33.904: INFO: kube-dns-autoscaler-f4c47db64-rwllv from kube-system started at 2018-11-19 14:59:40 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container autoscaler ready: true, restart count 0
Dec 11 10:09:33.904: INFO: prd-pf-contact-svc-platform-contact-svc-7fdb7698d8-ksnzv from platform started at 2018-11-19 14:59:45 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.904: INFO: 	Container prd-pf-contact-svc-platform-contact-svc ready: true, restart count 0
Dec 11 10:09:33.904: INFO: prd-pf-email-svc-platform-email-svc-8696f76496-9gbn5 from platform started at 2018-11-19 14:59:45 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.904: INFO: 	Container prd-pf-email-svc-platform-email-svc ready: true, restart count 0
Dec 11 10:09:33.904: INFO: prd-pf-notif-svc-platform-notif-svc-84dd77bbd8-74825 from platform started at 2018-11-19 14:59:47 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.904: INFO: 	Container prd-pf-notif-svc-platform-notif-svc ready: true, restart count 0
Dec 11 10:09:33.904: INFO: prd-pfm-svc-data-6448cbb64-w464d from platform started at 2018-11-19 14:59:48 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.904: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.904: INFO: 	Container prd-pf-data-svc-prd-pfm-svc-data ready: true, restart count 0
Dec 11 10:09:33.904: INFO: 
Logging pods the kubelet thinks is on node ip-172-25-62-1.us-west-1.compute.internal before test
Dec 11 10:09:33.913: INFO: prd-dss-ppc-svc-ppc-svc-58f5d567d-8msxj from platform started at 2018-11-26 11:36:47 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.913: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.913: INFO: 	Container ppc-svc ready: true, restart count 0
Dec 11 10:09:33.913: INFO: prd-pf-conf-svc-platform-conf-svc-6f8c9c5649-hrx2v from platform started at 2018-11-20 08:43:48 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.913: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.913: INFO: 	Container prd-pf-conf-svc-platform-conf-svc ready: true, restart count 0
Dec 11 10:09:33.913: INFO: prd-pf-dashboard-ui-platform-dashboard-ui-859cf5d999-9qp8v from platform started at 2018-11-20 11:23:38 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.913: INFO: 	Container platform-dashboard-ui ready: true, restart count 0
Dec 11 10:09:33.913: INFO: prd-pf-admin-ui-platform-admin-ui-85c98dcc66-9vj7s from platform started at 2018-11-20 11:40:28 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.913: INFO: 	Container platform-admin-ui ready: true, restart count 0
Dec 11 10:09:33.913: INFO: prd-pf-prflmgmt-ui-platform-prflmgmt-ui-654ff59c99-tl62p from platform started at 2018-11-20 11:46:41 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.913: INFO: 	Container platform-prflmgmt-ui ready: true, restart count 0
Dec 11 10:09:33.913: INFO: prd-pf-dashboard-ui-platform-dashboard-ui-859cf5d999-mwwgd from platform started at 2018-11-20 11:23:32 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.913: INFO: 	Container platform-dashboard-ui ready: true, restart count 0
Dec 11 10:09:33.913: INFO: prd-pf-accmgmt-ui-platform-accmgmt-ui-5cbc4c9d66-krr5g from platform started at 2018-11-20 11:50:04 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.913: INFO: 	Container platform-accmgmt-ui ready: true, restart count 0
Dec 11 10:09:33.913: INFO: datadog-datadog-lqmmz from infra started at 2018-11-19 17:03:43 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.913: INFO: 	Container datadog ready: true, restart count 0
Dec 11 10:09:33.913: INFO: calico-node-trxzw from kube-system started at 2018-11-19 17:03:43 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.913: INFO: 	Container calico-node ready: true, restart count 0
Dec 11 10:09:33.913: INFO: 	Container install-cni ready: true, restart count 0
Dec 11 10:09:33.913: INFO: prd-efk-elasticsearch-client-8655b8d9b9-vbpbh from infra started at 2018-12-11 09:54:52 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.913: INFO: 	Container es-client ready: false, restart count 0
Dec 11 10:09:33.913: INFO: prd-dss-quote-ui-7475c4bdc-lg6c6 from platform started at 2018-11-21 10:07:09 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.913: INFO: 	Container dss-quote-ui ready: true, restart count 0
Dec 11 10:09:33.913: INFO: prd-botfactory-ui-pfm-botfactory-ui-7ff78b89f7-xnmkr from platform started at 2018-11-21 11:30:22 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.913: INFO: 	Container pfm-botfactory-ui ready: true, restart count 0
Dec 11 10:09:33.913: INFO: prd-dss-qni-quote-svc-dss-qni-quote-service-84cbc8c6c8-qm5jw from platform started at 2018-11-26 11:13:14 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.913: INFO: 	Container dss-qni-quote-service ready: true, restart count 0
Dec 11 10:09:33.913: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.913: INFO: prd-efk-elasticsearch-curator-1544317200-qxdt5 from infra started at 2018-12-09 01:00:06 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.913: INFO: 	Container curator ready: false, restart count 0
Dec 11 10:09:33.913: INFO: prd-dss-leadcloser-ui-658768bd4b-zbbdr from platform started at 2018-11-20 12:27:05 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.913: INFO: 	Container dss-leadcloser-ui ready: true, restart count 0
Dec 11 10:09:33.913: INFO: prd-dss-ppc-ratetables-ppc-svc-cfb7cd6b9-6qcrh from platform started at 2018-11-26 11:48:21 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.914: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.914: INFO: 	Container ppc-svc ready: true, restart count 0
Dec 11 10:09:33.914: INFO: prd-pf-apimgmt-ui-platform-apimgmt-ui-699d4df9d-nb79x from platform started at 2018-11-20 11:37:39 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.914: INFO: 	Container platform-apimgmt-ui ready: true, restart count 0
Dec 11 10:09:33.914: INFO: prd-dss-lc-svc-dss-lc-service-6c8748f77b-7sj75 from platform started at 2018-11-20 13:24:04 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.914: INFO: 	Container dss-lc-service ready: true, restart count 0
Dec 11 10:09:33.914: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.914: INFO: prd-ibf-botfactory-platform-svc-botfactory-platform-servicszx9g from platform started at 2018-11-21 11:04:39 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.914: INFO: 	Container botfactory-platform-service ready: true, restart count 0
Dec 11 10:09:33.914: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-11 09:12:13 +0000 UTC (3 container statuses recorded)
Dec 11 10:09:33.914: INFO: 	Container cleanup ready: true, restart count 0
Dec 11 10:09:33.914: INFO: 	Container forwarder ready: true, restart count 0
Dec 11 10:09:33.914: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 11 10:09:33.914: INFO: prd-efk-elasticsearch-curator-1544403600-dgbl8 from infra started at 2018-12-10 01:00:08 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.914: INFO: 	Container curator ready: false, restart count 0
Dec 11 10:09:33.914: INFO: prd-pf-signup-ui-platform-signup-ui-54ffdd6f94-pzb82 from platform started at 2018-11-20 11:30:55 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.914: INFO: 	Container platform-signup-ui ready: true, restart count 0
Dec 11 10:09:33.914: INFO: prd-efk-elasticsearch-curator-1544490000-4wpv9 from infra started at 2018-12-11 01:00:07 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.914: INFO: 	Container curator ready: false, restart count 0
Dec 11 10:09:33.914: INFO: prd-efk-elasticsearch-fluentd-g26g8 from infra started at 2018-12-11 09:59:59 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.914: INFO: 	Container fluentd ready: false, restart count 0
Dec 11 10:09:33.914: INFO: prd-dss-ppc-ui-64f9cf489c-zj4pk from platform started at 2018-11-20 14:04:47 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.914: INFO: 	Container dss-ppc-ui ready: true, restart count 0
Dec 11 10:09:33.914: INFO: prd-dss-ppc-masterdata-ppc-svc-7d8577dd7c-pb92m from platform started at 2018-11-26 11:42:41 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.914: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.914: INFO: 	Container ppc-svc ready: true, restart count 0
Dec 11 10:09:33.914: INFO: prd-ai-sentiment-eng-svc-ai-sentiment-svc-69bd5d994b-7wcr2 from ai started at 2018-11-20 13:34:13 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.914: INFO: 	Container prd-ai-sentiment-eng-svc-ai-sentiment-svc ready: true, restart count 0
Dec 11 10:09:33.914: INFO: prd-ibf-botfactory-adapter-svc-botfactory-adapter-service-p5vcf from platform started at 2018-11-21 11:11:42 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.914: INFO: 	Container botfactory-adapter-service ready: true, restart count 0
Dec 11 10:09:33.914: INFO: prd-efk-elasticsearch-kibana-654b6d5965-9qdfj from infra started at 2018-12-11 09:54:52 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.914: INFO: 	Container kibana ready: true, restart count 0
Dec 11 10:09:33.914: INFO: kube-proxy-ip-172-25-62-1.us-west-1.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Dec 11 10:09:33.914: INFO: prd-pfm-svc-telephony-55658c585-sp22g from platform started at 2018-11-20 08:24:26 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.914: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.914: INFO: 	Container prd-pf-telephony-svc-prd-pfm-svc-telephony ready: true, restart count 0
Dec 11 10:09:33.914: INFO: prd-pf-acc-svc-platform-acc-svc-56c66dc6bc-jl2qm from platform started at 2018-11-20 08:35:58 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.914: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.914: INFO: 	Container prd-pf-acc-svc-platform-acc-svc ready: true, restart count 0
Dec 11 10:09:33.914: INFO: 
Logging pods the kubelet thinks is on node ip-172-25-93-75.us-west-1.compute.internal before test
Dec 11 10:09:33.926: INFO: prd-pf-notif-svc-platform-notif-svc-84dd77bbd8-qhxw5 from platform started at 2018-11-19 16:59:29 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.926: INFO: 	Container prd-pf-notif-svc-platform-notif-svc ready: true, restart count 0
Dec 11 10:09:33.926: INFO: kube-dns-7c4d8456dd-np757 from kube-system started at 2018-11-19 16:59:29 +0000 UTC (3 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container dnsmasq ready: true, restart count 0
Dec 11 10:09:33.926: INFO: 	Container kubedns ready: true, restart count 0
Dec 11 10:09:33.926: INFO: 	Container sidecar ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-pf-audit-svc-platform-audit-svc-78f5998486-4vlp5 from platform started at 2018-11-19 16:59:29 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.926: INFO: 	Container prd-pf-audit-svc-platform-audit-svc ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-keycloak-pgpool-58b949979d-ndwgn from platform started at 2018-11-19 16:59:30 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container prd-keycloak-pgpool ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-pf-signup-ui-platform-signup-ui-54ffdd6f94-62xr7 from platform started at 2018-11-20 11:30:50 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container platform-signup-ui ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-pf-blkusrimp-svc-platform-blkusrimp-svc-7d8d5c459f-q24h8 from platform started at 2018-11-19 16:59:28 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.926: INFO: 	Container prd-pf-blkusrimp-svc-platform-blkusrimp-svc ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-botfactory-chatbot-ui-pfm-botfactory-chatbot-ui-7bd798cnb8c from platform started at 2018-11-21 10:41:40 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container pfm-botfactory-chatbot-ui ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-pf-admin-ui-platform-admin-ui-85c98dcc66-rbgt5 from platform started at 2018-11-20 11:40:24 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container platform-admin-ui ready: true, restart count 0
Dec 11 10:09:33.926: INFO: datadog-datadog-r4px7 from infra started at 2018-11-19 16:53:44 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container datadog ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-dss-pm-profile-svc-dss-pm-profile-service-556b68d65-qmntq from platform started at 2018-11-19 16:59:31 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container dss-pm-profile-service ready: true, restart count 0
Dec 11 10:09:33.926: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-pf-email-svc-platform-email-svc-8696f76496-wkzqt from platform started at 2018-11-19 16:59:31 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.926: INFO: 	Container prd-pf-email-svc-platform-email-svc ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-efk-elasticsearch-data-0 from infra started at 2018-12-11 10:02:34 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container es-data ready: false, restart count 0
Dec 11 10:09:33.926: INFO: prd-dss-qni-illustration-svc-dss-qni-illustration-service-r2rhd from platform started at 2018-11-26 11:18:56 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.926: INFO: 	Container prd-dss-qni-illustration-svc-dss-qni-illustration-service ready: true, restart count 0
Dec 11 10:09:33.926: INFO: calico-node-p7n2j from kube-system started at 2018-11-19 16:53:44 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container calico-node ready: true, restart count 0
Dec 11 10:09:33.926: INFO: 	Container install-cni ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-pf-notes-svc-platform-notes-svc-5c99df689c-vs8g5 from platform started at 2018-11-19 16:59:28 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.926: INFO: 	Container prd-pf-notes-svc-platform-notes-svc ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-keycloak-keycloak-78d64cbc4f-scj6l from platform started at 2018-11-19 16:59:29 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container prd-keycloak-keycloak ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-ai-sentiment-eng-svc-ai-sentiment-svc-69bd5d994b-vn2sr from ai started at 2018-11-20 13:34:13 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container prd-ai-sentiment-eng-svc-ai-sentiment-svc ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-botfactory-ui-pfm-botfactory-ui-7ff78b89f7-ljt45 from platform started at 2018-11-21 11:30:22 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container pfm-botfactory-ui ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-efk-elasticsearch-client-8655b8d9b9-t4lvs from infra started at 2018-12-11 09:54:52 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container es-client ready: false, restart count 0
Dec 11 10:09:33.926: INFO: kube-proxy-ip-172-25-93-75.us-west-1.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Dec 11 10:09:33.926: INFO: prd-pf-activity-svc-platform-activity-svc-855df677b4-htnqk from platform started at 2018-11-19 16:59:30 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.926: INFO: 	Container prd-pf-activity-svc-platform-activity-svc ready: true, restart count 0
Dec 11 10:09:33.926: INFO: nginx-ingress-controller-5ccb96dd7b-ldrbm from ingress-nginx started at 2018-11-19 17:11:11 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-pf-accmgmt-ui-platform-accmgmt-ui-5cbc4c9d66-g4wqj from platform started at 2018-11-20 11:49:59 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container platform-accmgmt-ui ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-pf-apimgmt-ui-platform-apimgmt-ui-699d4df9d-cd7lv from platform started at 2018-11-20 11:37:33 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container platform-apimgmt-ui ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-pf-contact-svc-platform-contact-svc-7fdb7698d8-6s89f from platform started at 2018-11-19 16:59:28 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.926: INFO: 	Container prd-pf-contact-svc-platform-contact-svc ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-dss-ppc-ui-64f9cf489c-r64qn from platform started at 2018-11-20 14:04:47 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container dss-ppc-ui ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-pf-calen-svc-platform-calen-svc-59dc958758-gq7dn from platform started at 2018-11-19 16:59:29 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.926: INFO: 	Container prd-pf-calen-svc-platform-calen-svc ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-pf-sign-svc-platform-signup-svc-7dcfdd559-c26zr from platform started at 2018-11-19 16:59:30 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.926: INFO: 	Container prd-pf-sign-svc-platform-signup-svc ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-efk-elasticsearch-master-0 from infra started at 2018-12-11 10:01:26 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container es-master ready: false, restart count 0
Dec 11 10:09:33.926: INFO: prd-pf-doc-svc-platform-doc-svc-6bc8488db8-b6mbr from platform started at 2018-11-19 16:59:28 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.926: INFO: 	Container prd-pf-doc-svc-platform-doc-svc ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-pf-prflmgmt-ui-platform-prflmgmt-ui-654ff59c99-mntgc from platform started at 2018-11-20 11:46:36 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container platform-prflmgmt-ui ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-pfm-svc-telephony-55658c585-l2cmb from platform started at 2018-11-20 08:24:26 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.926: INFO: 	Container prd-pf-telephony-svc-prd-pfm-svc-telephony ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-pf-acc-svc-platform-acc-svc-56c66dc6bc-c76pd from platform started at 2018-11-20 08:35:58 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.926: INFO: 	Container prd-pf-acc-svc-platform-acc-svc ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-pf-conf-svc-platform-conf-svc-6f8c9c5649-js8zv from platform started at 2018-11-20 08:43:48 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.926: INFO: 	Container prd-pf-conf-svc-platform-conf-svc ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-dss-lc-svc-dss-lc-service-6c8748f77b-tffh5 from platform started at 2018-11-20 13:24:04 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container dss-lc-service ready: true, restart count 0
Dec 11 10:09:33.926: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.926: INFO: heapster-6d9d49d496-zxs9t from kube-system started at 2018-11-19 16:59:28 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container heapster ready: true, restart count 0
Dec 11 10:09:33.926: INFO: 	Container heapster-nanny ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-efk-elasticsearch-fluentd-nxffc from infra started at 2018-12-11 09:59:59 +0000 UTC (1 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container fluentd ready: false, restart count 0
Dec 11 10:09:33.926: INFO: prd-pf-iam-svc-platform-iam-svc-5d57975b5-b8fcg from platform started at 2018-11-19 16:59:28 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.926: INFO: 	Container prd-pf-iam-svc-platform-iam-svc ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-pfm-svc-data-6448cbb64-djfdf from platform started at 2018-11-19 16:59:30 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:09:33.926: INFO: 	Container prd-pf-data-svc-prd-pfm-svc-data ready: true, restart count 0
Dec 11 10:09:33.926: INFO: prd-dss-lcbulk-svc-dss-lcbulk-service-77b5449544-6nkdr from platform started at 2018-11-19 16:59:28 +0000 UTC (2 container statuses recorded)
Dec 11 10:09:33.926: INFO: 	Container dss-lcbulk-service ready: true, restart count 0
Dec 11 10:09:33.926: INFO: 	Container filebeat ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-dcce6feb-fd2c-11e8-897d-5ac57959ef46 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-dcce6feb-fd2c-11e8-897d-5ac57959ef46 off the node ip-172-25-62-1.us-west-1.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-dcce6feb-fd2c-11e8-897d-5ac57959ef46
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:09:38.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-dvlhp" for this suite.
Dec 11 10:09:56.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:09:56.090: INFO: namespace: e2e-tests-sched-pred-dvlhp, resource: bindings, ignored listing per whitelist
Dec 11 10:09:56.114: INFO: namespace e2e-tests-sched-pred-dvlhp deletion completed in 18.08624965s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:22.330 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:09:56.114: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-8krl
STEP: Creating a pod to test atomic-volume-subpath
Dec 11 10:09:56.244: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-8krl" in namespace "e2e-tests-subpath-s2sk7" to be "success or failure"
Dec 11 10:09:56.246: INFO: Pod "pod-subpath-test-downwardapi-8krl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.225363ms
Dec 11 10:09:58.248: INFO: Pod "pod-subpath-test-downwardapi-8krl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004679176s
Dec 11 10:10:00.251: INFO: Pod "pod-subpath-test-downwardapi-8krl": Phase="Running", Reason="", readiness=false. Elapsed: 4.007276172s
Dec 11 10:10:02.254: INFO: Pod "pod-subpath-test-downwardapi-8krl": Phase="Running", Reason="", readiness=false. Elapsed: 6.010139781s
Dec 11 10:10:04.257: INFO: Pod "pod-subpath-test-downwardapi-8krl": Phase="Running", Reason="", readiness=false. Elapsed: 8.012935721s
Dec 11 10:10:06.259: INFO: Pod "pod-subpath-test-downwardapi-8krl": Phase="Running", Reason="", readiness=false. Elapsed: 10.015525105s
Dec 11 10:10:08.262: INFO: Pod "pod-subpath-test-downwardapi-8krl": Phase="Running", Reason="", readiness=false. Elapsed: 12.01809834s
Dec 11 10:10:10.265: INFO: Pod "pod-subpath-test-downwardapi-8krl": Phase="Running", Reason="", readiness=false. Elapsed: 14.021121884s
Dec 11 10:10:12.267: INFO: Pod "pod-subpath-test-downwardapi-8krl": Phase="Running", Reason="", readiness=false. Elapsed: 16.023701557s
Dec 11 10:10:14.270: INFO: Pod "pod-subpath-test-downwardapi-8krl": Phase="Running", Reason="", readiness=false. Elapsed: 18.026813857s
Dec 11 10:10:16.274: INFO: Pod "pod-subpath-test-downwardapi-8krl": Phase="Running", Reason="", readiness=false. Elapsed: 20.030004942s
Dec 11 10:10:18.276: INFO: Pod "pod-subpath-test-downwardapi-8krl": Phase="Running", Reason="", readiness=false. Elapsed: 22.032812197s
Dec 11 10:10:20.279: INFO: Pod "pod-subpath-test-downwardapi-8krl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.035478267s
STEP: Saw pod success
Dec 11 10:10:20.279: INFO: Pod "pod-subpath-test-downwardapi-8krl" satisfied condition "success or failure"
Dec 11 10:10:20.281: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-subpath-test-downwardapi-8krl container test-container-subpath-downwardapi-8krl: <nil>
STEP: delete the pod
Dec 11 10:10:20.310: INFO: Waiting for pod pod-subpath-test-downwardapi-8krl to disappear
Dec 11 10:10:20.312: INFO: Pod pod-subpath-test-downwardapi-8krl no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-8krl
Dec 11 10:10:20.312: INFO: Deleting pod "pod-subpath-test-downwardapi-8krl" in namespace "e2e-tests-subpath-s2sk7"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:10:20.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-s2sk7" for this suite.
Dec 11 10:10:26.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:10:26.351: INFO: namespace: e2e-tests-subpath-s2sk7, resource: bindings, ignored listing per whitelist
Dec 11 10:10:26.447: INFO: namespace e2e-tests-subpath-s2sk7 deletion completed in 6.130246833s

• [SLOW TEST:30.333 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:10:26.448: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-faf541e1-fd2c-11e8-897d-5ac57959ef46
STEP: Creating secret with name s-test-opt-upd-faf54221-fd2c-11e8-897d-5ac57959ef46
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-faf541e1-fd2c-11e8-897d-5ac57959ef46
STEP: Updating secret s-test-opt-upd-faf54221-fd2c-11e8-897d-5ac57959ef46
STEP: Creating secret with name s-test-opt-create-faf54238-fd2c-11e8-897d-5ac57959ef46
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:10:30.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4zj7s" for this suite.
Dec 11 10:10:52.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:10:52.726: INFO: namespace: e2e-tests-secrets-4zj7s, resource: bindings, ignored listing per whitelist
Dec 11 10:10:52.759: INFO: namespace e2e-tests-secrets-4zj7s deletion completed in 22.089683383s

• [SLOW TEST:26.312 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:10:52.759: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Dec 11 10:10:52.865: INFO: Waiting up to 5m0s for pod "client-containers-0aa1e03d-fd2d-11e8-897d-5ac57959ef46" in namespace "e2e-tests-containers-xgkmb" to be "success or failure"
Dec 11 10:10:52.867: INFO: Pod "client-containers-0aa1e03d-fd2d-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.869779ms
Dec 11 10:10:54.869: INFO: Pod "client-containers-0aa1e03d-fd2d-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004208927s
STEP: Saw pod success
Dec 11 10:10:54.869: INFO: Pod "client-containers-0aa1e03d-fd2d-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:10:54.871: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod client-containers-0aa1e03d-fd2d-11e8-897d-5ac57959ef46 container test-container: <nil>
STEP: delete the pod
Dec 11 10:10:54.897: INFO: Waiting for pod client-containers-0aa1e03d-fd2d-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:10:54.899: INFO: Pod client-containers-0aa1e03d-fd2d-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:10:54.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-xgkmb" for this suite.
Dec 11 10:11:00.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:11:01.005: INFO: namespace: e2e-tests-containers-xgkmb, resource: bindings, ignored listing per whitelist
Dec 11 10:11:01.031: INFO: namespace e2e-tests-containers-xgkmb deletion completed in 6.12900915s

• [SLOW TEST:8.272 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:11:01.031: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-0f904997-fd2d-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume secrets
Dec 11 10:11:01.149: INFO: Waiting up to 5m0s for pod "pod-secrets-0f91e57f-fd2d-11e8-897d-5ac57959ef46" in namespace "e2e-tests-secrets-2mztl" to be "success or failure"
Dec 11 10:11:01.151: INFO: Pod "pod-secrets-0f91e57f-fd2d-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.987628ms
Dec 11 10:11:03.153: INFO: Pod "pod-secrets-0f91e57f-fd2d-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004555654s
STEP: Saw pod success
Dec 11 10:11:03.153: INFO: Pod "pod-secrets-0f91e57f-fd2d-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:11:03.156: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-secrets-0f91e57f-fd2d-11e8-897d-5ac57959ef46 container secret-env-test: <nil>
STEP: delete the pod
Dec 11 10:11:03.182: INFO: Waiting for pod pod-secrets-0f91e57f-fd2d-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:11:03.185: INFO: Pod pod-secrets-0f91e57f-fd2d-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:11:03.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2mztl" for this suite.
Dec 11 10:11:09.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:11:09.229: INFO: namespace: e2e-tests-secrets-2mztl, resource: bindings, ignored listing per whitelist
Dec 11 10:11:09.275: INFO: namespace e2e-tests-secrets-2mztl deletion completed in 6.086703366s

• [SLOW TEST:8.243 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:11:09.275: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Dec 11 10:11:09.374: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-357251099 proxy --unix-socket=/tmp/kubectl-proxy-unix206001342/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:11:09.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7pkbg" for this suite.
Dec 11 10:11:15.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:11:15.476: INFO: namespace: e2e-tests-kubectl-7pkbg, resource: bindings, ignored listing per whitelist
Dec 11 10:11:15.508: INFO: namespace e2e-tests-kubectl-7pkbg deletion completed in 6.088467811s

• [SLOW TEST:6.233 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:11:15.508: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-18316e18-fd2d-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume configMaps
Dec 11 10:11:15.626: INFO: Waiting up to 5m0s for pod "pod-configmaps-1832f1cf-fd2d-11e8-897d-5ac57959ef46" in namespace "e2e-tests-configmap-vj5gq" to be "success or failure"
Dec 11 10:11:15.628: INFO: Pod "pod-configmaps-1832f1cf-fd2d-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.93661ms
Dec 11 10:11:17.631: INFO: Pod "pod-configmaps-1832f1cf-fd2d-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004949931s
STEP: Saw pod success
Dec 11 10:11:17.631: INFO: Pod "pod-configmaps-1832f1cf-fd2d-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:11:17.634: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-configmaps-1832f1cf-fd2d-11e8-897d-5ac57959ef46 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 10:11:17.661: INFO: Waiting for pod pod-configmaps-1832f1cf-fd2d-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:11:17.663: INFO: Pod pod-configmaps-1832f1cf-fd2d-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:11:17.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vj5gq" for this suite.
Dec 11 10:11:23.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:11:23.708: INFO: namespace: e2e-tests-configmap-vj5gq, resource: bindings, ignored listing per whitelist
Dec 11 10:11:23.757: INFO: namespace e2e-tests-configmap-vj5gq deletion completed in 6.090149037s

• [SLOW TEST:8.249 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:11:23.757: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 11 10:11:23.862: INFO: Waiting up to 5m0s for pod "downward-api-1d1bb832-fd2d-11e8-897d-5ac57959ef46" in namespace "e2e-tests-downward-api-srbz4" to be "success or failure"
Dec 11 10:11:23.864: INFO: Pod "downward-api-1d1bb832-fd2d-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018774ms
Dec 11 10:11:25.867: INFO: Pod "downward-api-1d1bb832-fd2d-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004811505s
STEP: Saw pod success
Dec 11 10:11:25.867: INFO: Pod "downward-api-1d1bb832-fd2d-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:11:25.869: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod downward-api-1d1bb832-fd2d-11e8-897d-5ac57959ef46 container dapi-container: <nil>
STEP: delete the pod
Dec 11 10:11:25.896: INFO: Waiting for pod downward-api-1d1bb832-fd2d-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:11:25.898: INFO: Pod downward-api-1d1bb832-fd2d-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:11:25.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-srbz4" for this suite.
Dec 11 10:11:31.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:11:31.928: INFO: namespace: e2e-tests-downward-api-srbz4, resource: bindings, ignored listing per whitelist
Dec 11 10:11:31.987: INFO: namespace e2e-tests-downward-api-srbz4 deletion completed in 6.085128932s

• [SLOW TEST:8.230 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:11:31.987: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-220378df-fd2d-11e8-897d-5ac57959ef46
Dec 11 10:11:32.093: INFO: Pod name my-hostname-basic-220378df-fd2d-11e8-897d-5ac57959ef46: Found 0 pods out of 1
Dec 11 10:11:37.096: INFO: Pod name my-hostname-basic-220378df-fd2d-11e8-897d-5ac57959ef46: Found 1 pods out of 1
Dec 11 10:11:37.096: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-220378df-fd2d-11e8-897d-5ac57959ef46" are running
Dec 11 10:11:37.098: INFO: Pod "my-hostname-basic-220378df-fd2d-11e8-897d-5ac57959ef46-m4s7c" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-11 10:11:32 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-11 10:11:33 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-11 10:11:32 +0000 UTC Reason: Message:}])
Dec 11 10:11:37.098: INFO: Trying to dial the pod
Dec 11 10:11:42.107: INFO: Controller my-hostname-basic-220378df-fd2d-11e8-897d-5ac57959ef46: Got expected result from replica 1 [my-hostname-basic-220378df-fd2d-11e8-897d-5ac57959ef46-m4s7c]: "my-hostname-basic-220378df-fd2d-11e8-897d-5ac57959ef46-m4s7c", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:11:42.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-kng8p" for this suite.
Dec 11 10:11:48.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:11:48.143: INFO: namespace: e2e-tests-replication-controller-kng8p, resource: bindings, ignored listing per whitelist
Dec 11 10:11:48.201: INFO: namespace e2e-tests-replication-controller-kng8p deletion completed in 6.090483673s

• [SLOW TEST:16.213 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:11:48.201: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 11 10:11:48.321: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Dec 11 10:11:48.325: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-7l5lc/daemonsets","resourceVersion":"21965370"},"items":null}

Dec 11 10:11:48.327: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-7l5lc/pods","resourceVersion":"21965370"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:11:48.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-7l5lc" for this suite.
Dec 11 10:11:54.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:11:54.418: INFO: namespace: e2e-tests-daemonsets-7l5lc, resource: bindings, ignored listing per whitelist
Dec 11 10:11:54.427: INFO: namespace e2e-tests-daemonsets-7l5lc deletion completed in 6.08591989s

S [SKIPPING] [6.226 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Dec 11 10:11:48.321: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:11:54.427: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Dec 11 10:11:54.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 api-versions'
Dec 11 10:11:54.583: INFO: stderr: ""
Dec 11 10:11:54.583: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:11:54.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-x89v2" for this suite.
Dec 11 10:12:00.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:12:00.620: INFO: namespace: e2e-tests-kubectl-x89v2, resource: bindings, ignored listing per whitelist
Dec 11 10:12:00.670: INFO: namespace e2e-tests-kubectl-x89v2 deletion completed in 6.08394569s

• [SLOW TEST:6.243 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:12:00.670: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-331c902d-fd2d-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume secrets
Dec 11 10:12:00.787: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-331e285c-fd2d-11e8-897d-5ac57959ef46" in namespace "e2e-tests-projected-4dcj4" to be "success or failure"
Dec 11 10:12:00.790: INFO: Pod "pod-projected-secrets-331e285c-fd2d-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.145707ms
Dec 11 10:12:02.792: INFO: Pod "pod-projected-secrets-331e285c-fd2d-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004774486s
STEP: Saw pod success
Dec 11 10:12:02.792: INFO: Pod "pod-projected-secrets-331e285c-fd2d-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:12:02.794: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-projected-secrets-331e285c-fd2d-11e8-897d-5ac57959ef46 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 11 10:12:02.821: INFO: Waiting for pod pod-projected-secrets-331e285c-fd2d-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:12:02.823: INFO: Pod pod-projected-secrets-331e285c-fd2d-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:12:02.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4dcj4" for this suite.
Dec 11 10:12:08.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:12:08.894: INFO: namespace: e2e-tests-projected-4dcj4, resource: bindings, ignored listing per whitelist
Dec 11 10:12:08.913: INFO: namespace e2e-tests-projected-4dcj4 deletion completed in 6.086025654s

• [SLOW TEST:8.242 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:12:08.913: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 11 10:12:09.020: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3805ee36-fd2d-11e8-897d-5ac57959ef46" in namespace "e2e-tests-projected-zx45h" to be "success or failure"
Dec 11 10:12:09.022: INFO: Pod "downwardapi-volume-3805ee36-fd2d-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.087782ms
Dec 11 10:12:11.025: INFO: Pod "downwardapi-volume-3805ee36-fd2d-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005157544s
STEP: Saw pod success
Dec 11 10:12:11.025: INFO: Pod "downwardapi-volume-3805ee36-fd2d-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:12:11.027: INFO: Trying to get logs from node ip-172-25-45-107.us-west-1.compute.internal pod downwardapi-volume-3805ee36-fd2d-11e8-897d-5ac57959ef46 container client-container: <nil>
STEP: delete the pod
Dec 11 10:12:11.055: INFO: Waiting for pod downwardapi-volume-3805ee36-fd2d-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:12:11.056: INFO: Pod downwardapi-volume-3805ee36-fd2d-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:12:11.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zx45h" for this suite.
Dec 11 10:12:17.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:12:17.144: INFO: namespace: e2e-tests-projected-zx45h, resource: bindings, ignored listing per whitelist
Dec 11 10:12:17.149: INFO: namespace e2e-tests-projected-zx45h deletion completed in 6.089212269s

• [SLOW TEST:8.236 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:12:17.149: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 11 10:12:17.257: INFO: Waiting up to 5m0s for pod "pod-3cef0b0b-fd2d-11e8-897d-5ac57959ef46" in namespace "e2e-tests-emptydir-b45bj" to be "success or failure"
Dec 11 10:12:17.259: INFO: Pod "pod-3cef0b0b-fd2d-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.916814ms
Dec 11 10:12:19.261: INFO: Pod "pod-3cef0b0b-fd2d-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004738599s
STEP: Saw pod success
Dec 11 10:12:19.261: INFO: Pod "pod-3cef0b0b-fd2d-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:12:19.264: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-3cef0b0b-fd2d-11e8-897d-5ac57959ef46 container test-container: <nil>
STEP: delete the pod
Dec 11 10:12:19.290: INFO: Waiting for pod pod-3cef0b0b-fd2d-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:12:19.292: INFO: Pod pod-3cef0b0b-fd2d-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:12:19.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-b45bj" for this suite.
Dec 11 10:12:25.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:12:25.344: INFO: namespace: e2e-tests-emptydir-b45bj, resource: bindings, ignored listing per whitelist
Dec 11 10:12:25.382: INFO: namespace e2e-tests-emptydir-b45bj deletion completed in 6.08706682s

• [SLOW TEST:8.233 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:12:25.383: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec 11 10:12:25.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 create -f - --namespace=e2e-tests-kubectl-pbgk7'
Dec 11 10:12:25.599: INFO: stderr: ""
Dec 11 10:12:25.599: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 11 10:12:25.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-pbgk7'
Dec 11 10:12:25.662: INFO: stderr: ""
Dec 11 10:12:25.662: INFO: stdout: "update-demo-nautilus-8ptpw update-demo-nautilus-z2qxg "
Dec 11 10:12:25.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-nautilus-8ptpw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pbgk7'
Dec 11 10:12:25.717: INFO: stderr: ""
Dec 11 10:12:25.717: INFO: stdout: ""
Dec 11 10:12:25.717: INFO: update-demo-nautilus-8ptpw is created but not running
Dec 11 10:12:30.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-pbgk7'
Dec 11 10:12:30.777: INFO: stderr: ""
Dec 11 10:12:30.777: INFO: stdout: "update-demo-nautilus-8ptpw update-demo-nautilus-z2qxg "
Dec 11 10:12:30.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-nautilus-8ptpw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pbgk7'
Dec 11 10:12:30.833: INFO: stderr: ""
Dec 11 10:12:30.834: INFO: stdout: "true"
Dec 11 10:12:30.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-nautilus-8ptpw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pbgk7'
Dec 11 10:12:30.890: INFO: stderr: ""
Dec 11 10:12:30.890: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 11 10:12:30.890: INFO: validating pod update-demo-nautilus-8ptpw
Dec 11 10:12:30.895: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 11 10:12:30.895: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 11 10:12:30.895: INFO: update-demo-nautilus-8ptpw is verified up and running
Dec 11 10:12:30.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-nautilus-z2qxg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pbgk7'
Dec 11 10:12:30.952: INFO: stderr: ""
Dec 11 10:12:30.952: INFO: stdout: "true"
Dec 11 10:12:30.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-nautilus-z2qxg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pbgk7'
Dec 11 10:12:31.009: INFO: stderr: ""
Dec 11 10:12:31.009: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 11 10:12:31.009: INFO: validating pod update-demo-nautilus-z2qxg
Dec 11 10:12:31.012: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 11 10:12:31.012: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 11 10:12:31.012: INFO: update-demo-nautilus-z2qxg is verified up and running
STEP: using delete to clean up resources
Dec 11 10:12:31.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-pbgk7'
Dec 11 10:12:31.079: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 11 10:12:31.079: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 11 10:12:31.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-pbgk7'
Dec 11 10:12:31.140: INFO: stderr: "No resources found.\n"
Dec 11 10:12:31.140: INFO: stdout: ""
Dec 11 10:12:31.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods -l name=update-demo --namespace=e2e-tests-kubectl-pbgk7 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 11 10:12:31.198: INFO: stderr: ""
Dec 11 10:12:31.198: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:12:31.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pbgk7" for this suite.
Dec 11 10:12:53.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:12:53.251: INFO: namespace: e2e-tests-kubectl-pbgk7, resource: bindings, ignored listing per whitelist
Dec 11 10:12:53.289: INFO: namespace e2e-tests-kubectl-pbgk7 deletion completed in 22.087397145s

• [SLOW TEST:27.906 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:12:53.289: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec 11 10:12:55.928: INFO: Successfully updated pod "annotationupdate5279b456-fd2d-11e8-897d-5ac57959ef46"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:12:57.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rsmqf" for this suite.
Dec 11 10:13:13.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:13:13.992: INFO: namespace: e2e-tests-downward-api-rsmqf, resource: bindings, ignored listing per whitelist
Dec 11 10:13:14.045: INFO: namespace e2e-tests-downward-api-rsmqf deletion completed in 16.100407377s

• [SLOW TEST:20.756 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:13:14.045: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-5edab370-fd2d-11e8-897d-5ac57959ef46
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:13:16.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5rxpp" for this suite.
Dec 11 10:14:36.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:14:36.255: INFO: namespace: e2e-tests-configmap-5rxpp, resource: bindings, ignored listing per whitelist
Dec 11 10:14:36.288: INFO: namespace e2e-tests-configmap-5rxpp deletion completed in 1m20.087697491s

• [SLOW TEST:82.243 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:14:36.288: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 11 10:14:36.384: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:14:45.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-q8tpz" for this suite.
Dec 11 10:14:51.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:14:51.524: INFO: namespace: e2e-tests-custom-resource-definition-q8tpz, resource: bindings, ignored listing per whitelist
Dec 11 10:14:51.540: INFO: namespace e2e-tests-custom-resource-definition-q8tpz deletion completed in 6.089173196s

• [SLOW TEST:15.252 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:14:51.540: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 11 10:14:51.662: INFO: Waiting up to 5m0s for pod "downwardapi-volume-98f7606b-fd2d-11e8-897d-5ac57959ef46" in namespace "e2e-tests-downward-api-mgbww" to be "success or failure"
Dec 11 10:14:51.664: INFO: Pod "downwardapi-volume-98f7606b-fd2d-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046704ms
Dec 11 10:14:53.667: INFO: Pod "downwardapi-volume-98f7606b-fd2d-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005039463s
STEP: Saw pod success
Dec 11 10:14:53.667: INFO: Pod "downwardapi-volume-98f7606b-fd2d-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:14:53.669: INFO: Trying to get logs from node ip-172-25-45-107.us-west-1.compute.internal pod downwardapi-volume-98f7606b-fd2d-11e8-897d-5ac57959ef46 container client-container: <nil>
STEP: delete the pod
Dec 11 10:14:53.697: INFO: Waiting for pod downwardapi-volume-98f7606b-fd2d-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:14:53.699: INFO: Pod downwardapi-volume-98f7606b-fd2d-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:14:53.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mgbww" for this suite.
Dec 11 10:14:59.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:14:59.748: INFO: namespace: e2e-tests-downward-api-mgbww, resource: bindings, ignored listing per whitelist
Dec 11 10:14:59.793: INFO: namespace e2e-tests-downward-api-mgbww deletion completed in 6.090002027s

• [SLOW TEST:8.253 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:14:59.793: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 11 10:14:59.890: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:15:01.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-crd7m" for this suite.
Dec 11 10:15:39.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:15:40.014: INFO: namespace: e2e-tests-pods-crd7m, resource: bindings, ignored listing per whitelist
Dec 11 10:15:40.068: INFO: namespace e2e-tests-pods-crd7m deletion completed in 38.085527324s

• [SLOW TEST:40.275 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:15:40.068: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 11 10:15:40.177: INFO: Waiting up to 5m0s for pod "pod-b5e23c2a-fd2d-11e8-897d-5ac57959ef46" in namespace "e2e-tests-emptydir-pkfp9" to be "success or failure"
Dec 11 10:15:40.179: INFO: Pod "pod-b5e23c2a-fd2d-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.909053ms
Dec 11 10:15:42.181: INFO: Pod "pod-b5e23c2a-fd2d-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004551091s
STEP: Saw pod success
Dec 11 10:15:42.181: INFO: Pod "pod-b5e23c2a-fd2d-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:15:42.184: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-b5e23c2a-fd2d-11e8-897d-5ac57959ef46 container test-container: <nil>
STEP: delete the pod
Dec 11 10:15:42.211: INFO: Waiting for pod pod-b5e23c2a-fd2d-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:15:42.213: INFO: Pod pod-b5e23c2a-fd2d-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:15:42.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pkfp9" for this suite.
Dec 11 10:15:48.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:15:48.310: INFO: namespace: e2e-tests-emptydir-pkfp9, resource: bindings, ignored listing per whitelist
Dec 11 10:15:48.310: INFO: namespace e2e-tests-emptydir-pkfp9 deletion completed in 6.093669685s

• [SLOW TEST:8.242 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:15:48.310: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-jrk82
Dec 11 10:15:50.422: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-jrk82
STEP: checking the pod's current state and verifying that restartCount is present
Dec 11 10:15:50.424: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:19:50.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-jrk82" for this suite.
Dec 11 10:19:56.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:19:56.876: INFO: namespace: e2e-tests-container-probe-jrk82, resource: bindings, ignored listing per whitelist
Dec 11 10:19:56.884: INFO: namespace e2e-tests-container-probe-jrk82 deletion completed in 6.097084496s

• [SLOW TEST:248.574 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:19:56.884: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-4ef610ef-fd2e-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume configMaps
Dec 11 10:19:57.009: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4ef7a881-fd2e-11e8-897d-5ac57959ef46" in namespace "e2e-tests-projected-m6rx9" to be "success or failure"
Dec 11 10:19:57.011: INFO: Pod "pod-projected-configmaps-4ef7a881-fd2e-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.261575ms
Dec 11 10:19:59.014: INFO: Pod "pod-projected-configmaps-4ef7a881-fd2e-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005472066s
STEP: Saw pod success
Dec 11 10:19:59.015: INFO: Pod "pod-projected-configmaps-4ef7a881-fd2e-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:19:59.017: INFO: Trying to get logs from node ip-172-25-45-107.us-west-1.compute.internal pod pod-projected-configmaps-4ef7a881-fd2e-11e8-897d-5ac57959ef46 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 10:19:59.047: INFO: Waiting for pod pod-projected-configmaps-4ef7a881-fd2e-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:19:59.049: INFO: Pod pod-projected-configmaps-4ef7a881-fd2e-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:19:59.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-m6rx9" for this suite.
Dec 11 10:20:05.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:20:05.140: INFO: namespace: e2e-tests-projected-m6rx9, resource: bindings, ignored listing per whitelist
Dec 11 10:20:05.172: INFO: namespace e2e-tests-projected-m6rx9 deletion completed in 6.118801018s

• [SLOW TEST:8.288 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:20:05.172: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:20:10.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-p8bdj" for this suite.
Dec 11 10:20:32.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:20:32.376: INFO: namespace: e2e-tests-replication-controller-p8bdj, resource: bindings, ignored listing per whitelist
Dec 11 10:20:32.391: INFO: namespace e2e-tests-replication-controller-p8bdj deletion completed in 22.085789787s

• [SLOW TEST:27.219 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:20:32.391: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Dec 11 10:20:32.488: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec 11 10:20:32.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 create -f - --namespace=e2e-tests-kubectl-xzmnp'
Dec 11 10:20:32.744: INFO: stderr: ""
Dec 11 10:20:32.744: INFO: stdout: "service/redis-slave created\n"
Dec 11 10:20:32.744: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec 11 10:20:32.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 create -f - --namespace=e2e-tests-kubectl-xzmnp'
Dec 11 10:20:32.887: INFO: stderr: ""
Dec 11 10:20:32.887: INFO: stdout: "service/redis-master created\n"
Dec 11 10:20:32.887: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec 11 10:20:32.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 create -f - --namespace=e2e-tests-kubectl-xzmnp'
Dec 11 10:20:33.033: INFO: stderr: ""
Dec 11 10:20:33.033: INFO: stdout: "service/frontend created\n"
Dec 11 10:20:33.033: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec 11 10:20:33.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 create -f - --namespace=e2e-tests-kubectl-xzmnp'
Dec 11 10:20:33.154: INFO: stderr: ""
Dec 11 10:20:33.154: INFO: stdout: "deployment.extensions/frontend created\n"
Dec 11 10:20:33.154: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 11 10:20:33.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 create -f - --namespace=e2e-tests-kubectl-xzmnp'
Dec 11 10:20:33.277: INFO: stderr: ""
Dec 11 10:20:33.277: INFO: stdout: "deployment.extensions/redis-master created\n"
Dec 11 10:20:33.277: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec 11 10:20:33.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 create -f - --namespace=e2e-tests-kubectl-xzmnp'
Dec 11 10:20:33.399: INFO: stderr: ""
Dec 11 10:20:33.399: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Dec 11 10:20:33.399: INFO: Waiting for all frontend pods to be Running.
Dec 11 10:20:53.450: INFO: Waiting for frontend to serve content.
Dec 11 10:20:58.461: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Dec 11 10:21:03.478: INFO: Trying to add a new entry to the guestbook.
Dec 11 10:21:03.491: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec 11 10:21:03.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xzmnp'
Dec 11 10:21:03.601: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 11 10:21:03.601: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec 11 10:21:03.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xzmnp'
Dec 11 10:21:03.706: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 11 10:21:03.706: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 11 10:21:03.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xzmnp'
Dec 11 10:21:03.805: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 11 10:21:03.806: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 11 10:21:03.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xzmnp'
Dec 11 10:21:03.873: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 11 10:21:03.873: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 11 10:21:03.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xzmnp'
Dec 11 10:21:03.941: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 11 10:21:03.941: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 11 10:21:03.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xzmnp'
Dec 11 10:21:04.009: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 11 10:21:04.009: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:21:04.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xzmnp" for this suite.
Dec 11 10:21:48.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:21:48.090: INFO: namespace: e2e-tests-kubectl-xzmnp, resource: bindings, ignored listing per whitelist
Dec 11 10:21:48.103: INFO: namespace e2e-tests-kubectl-xzmnp deletion completed in 44.09003765s

• [SLOW TEST:75.711 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:21:48.103: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 11 10:21:52.280: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 10:21:52.283: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 10:21:54.283: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 10:21:54.286: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 10:21:56.283: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 10:21:56.286: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 10:21:58.283: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 10:21:58.286: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 10:22:00.283: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 10:22:00.285: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 10:22:02.283: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 10:22:02.285: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 10:22:04.283: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 10:22:04.286: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 10:22:06.283: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 10:22:06.285: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 10:22:08.283: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 10:22:08.285: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 10:22:10.283: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 10:22:10.285: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 10:22:12.283: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 10:22:12.286: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 10:22:14.283: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 10:22:14.286: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:22:14.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-j25dz" for this suite.
Dec 11 10:22:36.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:22:36.354: INFO: namespace: e2e-tests-container-lifecycle-hook-j25dz, resource: bindings, ignored listing per whitelist
Dec 11 10:22:36.379: INFO: namespace e2e-tests-container-lifecycle-hook-j25dz deletion completed in 22.089667501s

• [SLOW TEST:48.276 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:22:36.379: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 11 10:22:36.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-cxrll'
Dec 11 10:22:36.556: INFO: stderr: ""
Dec 11 10:22:36.556: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Dec 11 10:22:36.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-cxrll'
Dec 11 10:22:43.141: INFO: stderr: ""
Dec 11 10:22:43.141: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:22:43.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cxrll" for this suite.
Dec 11 10:22:49.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:22:49.207: INFO: namespace: e2e-tests-kubectl-cxrll, resource: bindings, ignored listing per whitelist
Dec 11 10:22:49.232: INFO: namespace e2e-tests-kubectl-cxrll deletion completed in 6.086962994s

• [SLOW TEST:12.852 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:22:49.232: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-b5b029b3-fd2e-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume secrets
Dec 11 10:22:49.357: INFO: Waiting up to 5m0s for pod "pod-secrets-b5b1f849-fd2e-11e8-897d-5ac57959ef46" in namespace "e2e-tests-secrets-sqk5h" to be "success or failure"
Dec 11 10:22:49.359: INFO: Pod "pod-secrets-b5b1f849-fd2e-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.938384ms
Dec 11 10:22:51.361: INFO: Pod "pod-secrets-b5b1f849-fd2e-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004480656s
STEP: Saw pod success
Dec 11 10:22:51.361: INFO: Pod "pod-secrets-b5b1f849-fd2e-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:22:51.364: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-secrets-b5b1f849-fd2e-11e8-897d-5ac57959ef46 container secret-volume-test: <nil>
STEP: delete the pod
Dec 11 10:22:51.390: INFO: Waiting for pod pod-secrets-b5b1f849-fd2e-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:22:51.392: INFO: Pod pod-secrets-b5b1f849-fd2e-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:22:51.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-sqk5h" for this suite.
Dec 11 10:22:57.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:22:57.417: INFO: namespace: e2e-tests-secrets-sqk5h, resource: bindings, ignored listing per whitelist
Dec 11 10:22:57.482: INFO: namespace e2e-tests-secrets-sqk5h deletion completed in 6.087638562s

• [SLOW TEST:8.251 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:22:57.483: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 11 10:22:57.614: INFO: Waiting up to 5m0s for pod "pod-ba9da87f-fd2e-11e8-897d-5ac57959ef46" in namespace "e2e-tests-emptydir-k7lxx" to be "success or failure"
Dec 11 10:22:57.616: INFO: Pod "pod-ba9da87f-fd2e-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.922884ms
Dec 11 10:22:59.618: INFO: Pod "pod-ba9da87f-fd2e-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004409982s
STEP: Saw pod success
Dec 11 10:22:59.618: INFO: Pod "pod-ba9da87f-fd2e-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:22:59.620: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-ba9da87f-fd2e-11e8-897d-5ac57959ef46 container test-container: <nil>
STEP: delete the pod
Dec 11 10:22:59.649: INFO: Waiting for pod pod-ba9da87f-fd2e-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:22:59.651: INFO: Pod pod-ba9da87f-fd2e-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:22:59.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-k7lxx" for this suite.
Dec 11 10:23:05.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:23:05.723: INFO: namespace: e2e-tests-emptydir-k7lxx, resource: bindings, ignored listing per whitelist
Dec 11 10:23:05.746: INFO: namespace e2e-tests-emptydir-k7lxx deletion completed in 6.091285508s

• [SLOW TEST:8.263 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:23:05.746: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec 11 10:23:05.914: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-b8vdq,SelfLink:/api/v1/namespaces/e2e-tests-watch-b8vdq/configmaps/e2e-watch-test-resource-version,UID:bf8861a5-fd2e-11e8-8e03-0681e6464a68,ResourceVersion:21967468,Generation:0,CreationTimestamp:2018-12-11 10:23:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 11 10:23:05.915: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-b8vdq,SelfLink:/api/v1/namespaces/e2e-tests-watch-b8vdq/configmaps/e2e-watch-test-resource-version,UID:bf8861a5-fd2e-11e8-8e03-0681e6464a68,ResourceVersion:21967469,Generation:0,CreationTimestamp:2018-12-11 10:23:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:23:05.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-b8vdq" for this suite.
Dec 11 10:23:11.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:23:11.973: INFO: namespace: e2e-tests-watch-b8vdq, resource: bindings, ignored listing per whitelist
Dec 11 10:23:12.002: INFO: namespace e2e-tests-watch-b8vdq deletion completed in 6.083659633s

• [SLOW TEST:6.256 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:23:12.002: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec 11 10:23:12.105: INFO: Waiting up to 5m0s for pod "pod-c340fbf7-fd2e-11e8-897d-5ac57959ef46" in namespace "e2e-tests-emptydir-lwprn" to be "success or failure"
Dec 11 10:23:12.107: INFO: Pod "pod-c340fbf7-fd2e-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003891ms
Dec 11 10:23:14.109: INFO: Pod "pod-c340fbf7-fd2e-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004441427s
STEP: Saw pod success
Dec 11 10:23:14.109: INFO: Pod "pod-c340fbf7-fd2e-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:23:14.111: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-c340fbf7-fd2e-11e8-897d-5ac57959ef46 container test-container: <nil>
STEP: delete the pod
Dec 11 10:23:14.138: INFO: Waiting for pod pod-c340fbf7-fd2e-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:23:14.140: INFO: Pod pod-c340fbf7-fd2e-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:23:14.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lwprn" for this suite.
Dec 11 10:23:20.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:23:20.165: INFO: namespace: e2e-tests-emptydir-lwprn, resource: bindings, ignored listing per whitelist
Dec 11 10:23:20.229: INFO: namespace e2e-tests-emptydir-lwprn deletion completed in 6.086346045s

• [SLOW TEST:8.228 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:23:20.229: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 11 10:23:20.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 version'
Dec 11 10:23:20.378: INFO: stderr: ""
Dec 11 10:23:20.378: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"10\", GitVersion:\"v1.10.6\", GitCommit:\"a21fdbd78dde8f5447f5f6c331f7eb6f80bd684e\", GitTreeState:\"clean\", BuildDate:\"2018-07-26T10:04:08Z\", GoVersion:\"go1.9.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:23:20.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zg78b" for this suite.
Dec 11 10:23:26.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:23:26.468: INFO: namespace: e2e-tests-kubectl-zg78b, resource: bindings, ignored listing per whitelist
Dec 11 10:23:26.468: INFO: namespace e2e-tests-kubectl-zg78b deletion completed in 6.086722656s

• [SLOW TEST:6.239 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:23:26.468: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-cbe17439-fd2e-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume secrets
Dec 11 10:23:26.589: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-cbe30a10-fd2e-11e8-897d-5ac57959ef46" in namespace "e2e-tests-projected-fm6nj" to be "success or failure"
Dec 11 10:23:26.591: INFO: Pod "pod-projected-secrets-cbe30a10-fd2e-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.962742ms
Dec 11 10:23:28.594: INFO: Pod "pod-projected-secrets-cbe30a10-fd2e-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00478485s
STEP: Saw pod success
Dec 11 10:23:28.594: INFO: Pod "pod-projected-secrets-cbe30a10-fd2e-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:23:28.596: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-projected-secrets-cbe30a10-fd2e-11e8-897d-5ac57959ef46 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 11 10:23:28.626: INFO: Waiting for pod pod-projected-secrets-cbe30a10-fd2e-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:23:28.627: INFO: Pod pod-projected-secrets-cbe30a10-fd2e-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:23:28.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fm6nj" for this suite.
Dec 11 10:23:34.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:23:34.695: INFO: namespace: e2e-tests-projected-fm6nj, resource: bindings, ignored listing per whitelist
Dec 11 10:23:34.718: INFO: namespace e2e-tests-projected-fm6nj deletion completed in 6.087712317s

• [SLOW TEST:8.250 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:23:34.719: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-d0cbde79-fd2e-11e8-897d-5ac57959ef46
STEP: Creating secret with name secret-projected-all-test-volume-d0cbde65-fd2e-11e8-897d-5ac57959ef46
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec 11 10:23:34.846: INFO: Waiting up to 5m0s for pod "projected-volume-d0cbde39-fd2e-11e8-897d-5ac57959ef46" in namespace "e2e-tests-projected-m6xc6" to be "success or failure"
Dec 11 10:23:34.848: INFO: Pod "projected-volume-d0cbde39-fd2e-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.944519ms
Dec 11 10:23:36.851: INFO: Pod "projected-volume-d0cbde39-fd2e-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004445862s
STEP: Saw pod success
Dec 11 10:23:36.851: INFO: Pod "projected-volume-d0cbde39-fd2e-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:23:36.853: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod projected-volume-d0cbde39-fd2e-11e8-897d-5ac57959ef46 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec 11 10:23:36.880: INFO: Waiting for pod projected-volume-d0cbde39-fd2e-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:23:36.881: INFO: Pod projected-volume-d0cbde39-fd2e-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:23:36.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-m6xc6" for this suite.
Dec 11 10:23:42.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:23:42.968: INFO: namespace: e2e-tests-projected-m6xc6, resource: bindings, ignored listing per whitelist
Dec 11 10:23:42.970: INFO: namespace e2e-tests-projected-m6xc6 deletion completed in 6.085518988s

• [SLOW TEST:8.252 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:23:42.971: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-d5b7f9f7-fd2e-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume configMaps
Dec 11 10:23:43.094: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d5b97b24-fd2e-11e8-897d-5ac57959ef46" in namespace "e2e-tests-projected-2wpkz" to be "success or failure"
Dec 11 10:23:43.095: INFO: Pod "pod-projected-configmaps-d5b97b24-fd2e-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.934932ms
Dec 11 10:23:45.098: INFO: Pod "pod-projected-configmaps-d5b97b24-fd2e-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004694773s
STEP: Saw pod success
Dec 11 10:23:45.098: INFO: Pod "pod-projected-configmaps-d5b97b24-fd2e-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:23:45.101: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-projected-configmaps-d5b97b24-fd2e-11e8-897d-5ac57959ef46 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 10:23:45.140: INFO: Waiting for pod pod-projected-configmaps-d5b97b24-fd2e-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:23:45.142: INFO: Pod pod-projected-configmaps-d5b97b24-fd2e-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:23:45.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2wpkz" for this suite.
Dec 11 10:23:51.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:23:51.192: INFO: namespace: e2e-tests-projected-2wpkz, resource: bindings, ignored listing per whitelist
Dec 11 10:23:51.235: INFO: namespace e2e-tests-projected-2wpkz deletion completed in 6.089200024s

• [SLOW TEST:8.265 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:23:51.235: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 11 10:23:51.345: INFO: Waiting up to 5m0s for pod "downwardapi-volume-daa4a02b-fd2e-11e8-897d-5ac57959ef46" in namespace "e2e-tests-projected-zdmdh" to be "success or failure"
Dec 11 10:23:51.347: INFO: Pod "downwardapi-volume-daa4a02b-fd2e-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.986906ms
Dec 11 10:23:53.350: INFO: Pod "downwardapi-volume-daa4a02b-fd2e-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004658923s
STEP: Saw pod success
Dec 11 10:23:53.350: INFO: Pod "downwardapi-volume-daa4a02b-fd2e-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:23:53.353: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod downwardapi-volume-daa4a02b-fd2e-11e8-897d-5ac57959ef46 container client-container: <nil>
STEP: delete the pod
Dec 11 10:23:53.379: INFO: Waiting for pod downwardapi-volume-daa4a02b-fd2e-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:23:53.381: INFO: Pod downwardapi-volume-daa4a02b-fd2e-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:23:53.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zdmdh" for this suite.
Dec 11 10:23:59.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:23:59.450: INFO: namespace: e2e-tests-projected-zdmdh, resource: bindings, ignored listing per whitelist
Dec 11 10:23:59.473: INFO: namespace e2e-tests-projected-zdmdh deletion completed in 6.088263774s

• [SLOW TEST:8.237 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:23:59.473: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-56r44
Dec 11 10:24:01.588: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-56r44
STEP: checking the pod's current state and verifying that restartCount is present
Dec 11 10:24:01.590: INFO: Initial restart count of pod liveness-exec is 0
Dec 11 10:24:49.662: INFO: Restart count of pod e2e-tests-container-probe-56r44/liveness-exec is now 1 (48.072290348s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:24:49.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-56r44" for this suite.
Dec 11 10:24:55.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:24:55.722: INFO: namespace: e2e-tests-container-probe-56r44, resource: bindings, ignored listing per whitelist
Dec 11 10:24:55.776: INFO: namespace e2e-tests-container-probe-56r44 deletion completed in 6.088981994s

• [SLOW TEST:56.303 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:24:55.776: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-011c6794-fd2f-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume secrets
Dec 11 10:24:55.894: INFO: Waiting up to 5m0s for pod "pod-secrets-011deea7-fd2f-11e8-897d-5ac57959ef46" in namespace "e2e-tests-secrets-vkr2z" to be "success or failure"
Dec 11 10:24:55.896: INFO: Pod "pod-secrets-011deea7-fd2f-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.108559ms
Dec 11 10:24:57.900: INFO: Pod "pod-secrets-011deea7-fd2f-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005576674s
STEP: Saw pod success
Dec 11 10:24:57.900: INFO: Pod "pod-secrets-011deea7-fd2f-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:24:57.903: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-secrets-011deea7-fd2f-11e8-897d-5ac57959ef46 container secret-volume-test: <nil>
STEP: delete the pod
Dec 11 10:24:57.935: INFO: Waiting for pod pod-secrets-011deea7-fd2f-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:24:57.937: INFO: Pod pod-secrets-011deea7-fd2f-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:24:57.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vkr2z" for this suite.
Dec 11 10:25:03.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:25:04.014: INFO: namespace: e2e-tests-secrets-vkr2z, resource: bindings, ignored listing per whitelist
Dec 11 10:25:04.031: INFO: namespace e2e-tests-secrets-vkr2z deletion completed in 6.090577652s

• [SLOW TEST:8.255 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:25:04.031: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Dec 11 10:25:04.141: INFO: Waiting up to 5m0s for pod "client-containers-06084ba5-fd2f-11e8-897d-5ac57959ef46" in namespace "e2e-tests-containers-6c2m7" to be "success or failure"
Dec 11 10:25:04.143: INFO: Pod "client-containers-06084ba5-fd2f-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.898907ms
Dec 11 10:25:06.146: INFO: Pod "client-containers-06084ba5-fd2f-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005078255s
STEP: Saw pod success
Dec 11 10:25:06.146: INFO: Pod "client-containers-06084ba5-fd2f-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:25:06.148: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod client-containers-06084ba5-fd2f-11e8-897d-5ac57959ef46 container test-container: <nil>
STEP: delete the pod
Dec 11 10:25:06.176: INFO: Waiting for pod client-containers-06084ba5-fd2f-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:25:06.178: INFO: Pod client-containers-06084ba5-fd2f-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:25:06.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-6c2m7" for this suite.
Dec 11 10:25:12.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:25:12.258: INFO: namespace: e2e-tests-containers-6c2m7, resource: bindings, ignored listing per whitelist
Dec 11 10:25:12.280: INFO: namespace e2e-tests-containers-6c2m7 deletion completed in 6.098350086s

• [SLOW TEST:8.249 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:25:12.280: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 11 10:25:12.401: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0af47340-fd2f-11e8-897d-5ac57959ef46" in namespace "e2e-tests-downward-api-bdfws" to be "success or failure"
Dec 11 10:25:12.403: INFO: Pod "downwardapi-volume-0af47340-fd2f-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.25301ms
Dec 11 10:25:14.406: INFO: Pod "downwardapi-volume-0af47340-fd2f-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005034461s
STEP: Saw pod success
Dec 11 10:25:14.406: INFO: Pod "downwardapi-volume-0af47340-fd2f-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:25:14.408: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod downwardapi-volume-0af47340-fd2f-11e8-897d-5ac57959ef46 container client-container: <nil>
STEP: delete the pod
Dec 11 10:25:14.436: INFO: Waiting for pod downwardapi-volume-0af47340-fd2f-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:25:14.438: INFO: Pod downwardapi-volume-0af47340-fd2f-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:25:14.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bdfws" for this suite.
Dec 11 10:25:20.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:25:20.511: INFO: namespace: e2e-tests-downward-api-bdfws, resource: bindings, ignored listing per whitelist
Dec 11 10:25:20.529: INFO: namespace e2e-tests-downward-api-bdfws deletion completed in 6.088260663s

• [SLOW TEST:8.249 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:25:20.530: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec 11 10:25:26.662: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-r246d PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 10:25:26.662: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
Dec 11 10:25:26.736: INFO: Exec stderr: ""
Dec 11 10:25:26.736: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-r246d PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 10:25:26.737: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
Dec 11 10:25:26.809: INFO: Exec stderr: ""
Dec 11 10:25:26.809: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-r246d PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 10:25:26.809: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
Dec 11 10:25:26.881: INFO: Exec stderr: ""
Dec 11 10:25:26.881: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-r246d PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 10:25:26.881: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
Dec 11 10:25:26.953: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec 11 10:25:26.953: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-r246d PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 10:25:26.953: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
Dec 11 10:25:27.024: INFO: Exec stderr: ""
Dec 11 10:25:27.024: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-r246d PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 10:25:27.024: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
Dec 11 10:25:27.096: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec 11 10:25:27.096: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-r246d PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 10:25:27.096: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
Dec 11 10:25:27.172: INFO: Exec stderr: ""
Dec 11 10:25:27.172: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-r246d PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 10:25:27.172: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
Dec 11 10:25:27.249: INFO: Exec stderr: ""
Dec 11 10:25:27.249: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-r246d PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 10:25:27.249: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
Dec 11 10:25:27.328: INFO: Exec stderr: ""
Dec 11 10:25:27.328: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-r246d PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 10:25:27.328: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
Dec 11 10:25:27.403: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:25:27.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-r246d" for this suite.
Dec 11 10:26:17.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:26:17.482: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-r246d, resource: bindings, ignored listing per whitelist
Dec 11 10:26:17.499: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-r246d deletion completed in 50.092665425s

• [SLOW TEST:56.970 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:26:17.499: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Dec 11 10:26:17.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 create -f - --namespace=e2e-tests-kubectl-bt58x'
Dec 11 10:26:17.726: INFO: stderr: ""
Dec 11 10:26:17.726: INFO: stdout: "pod/pause created\n"
Dec 11 10:26:17.726: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec 11 10:26:17.726: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-bt58x" to be "running and ready"
Dec 11 10:26:17.728: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.203327ms
Dec 11 10:26:19.731: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.004935711s
Dec 11 10:26:19.731: INFO: Pod "pause" satisfied condition "running and ready"
Dec 11 10:26:19.731: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Dec 11 10:26:19.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-bt58x'
Dec 11 10:26:19.801: INFO: stderr: ""
Dec 11 10:26:19.801: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec 11 10:26:19.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pod pause -L testing-label --namespace=e2e-tests-kubectl-bt58x'
Dec 11 10:26:19.859: INFO: stderr: ""
Dec 11 10:26:19.859: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec 11 10:26:19.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 label pods pause testing-label- --namespace=e2e-tests-kubectl-bt58x'
Dec 11 10:26:19.930: INFO: stderr: ""
Dec 11 10:26:19.930: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec 11 10:26:19.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pod pause -L testing-label --namespace=e2e-tests-kubectl-bt58x'
Dec 11 10:26:19.987: INFO: stderr: ""
Dec 11 10:26:19.987: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Dec 11 10:26:19.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bt58x'
Dec 11 10:26:20.062: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 11 10:26:20.062: INFO: stdout: "pod \"pause\" force deleted\n"
Dec 11 10:26:20.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-bt58x'
Dec 11 10:26:20.122: INFO: stderr: "No resources found.\n"
Dec 11 10:26:20.122: INFO: stdout: ""
Dec 11 10:26:20.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods -l name=pause --namespace=e2e-tests-kubectl-bt58x -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 11 10:26:20.179: INFO: stderr: ""
Dec 11 10:26:20.179: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:26:20.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bt58x" for this suite.
Dec 11 10:26:26.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:26:26.271: INFO: namespace: e2e-tests-kubectl-bt58x, resource: bindings, ignored listing per whitelist
Dec 11 10:26:26.273: INFO: namespace e2e-tests-kubectl-bt58x deletion completed in 6.090814416s

• [SLOW TEST:8.774 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:26:26.273: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec 11 10:26:26.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 create -f - --namespace=e2e-tests-kubectl-fv5p8'
Dec 11 10:26:26.489: INFO: stderr: ""
Dec 11 10:26:26.489: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 11 10:26:26.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fv5p8'
Dec 11 10:26:26.554: INFO: stderr: ""
Dec 11 10:26:26.554: INFO: stdout: "update-demo-nautilus-mnv86 update-demo-nautilus-t75mt "
Dec 11 10:26:26.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-nautilus-mnv86 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fv5p8'
Dec 11 10:26:26.609: INFO: stderr: ""
Dec 11 10:26:26.609: INFO: stdout: ""
Dec 11 10:26:26.609: INFO: update-demo-nautilus-mnv86 is created but not running
Dec 11 10:26:31.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fv5p8'
Dec 11 10:26:31.669: INFO: stderr: ""
Dec 11 10:26:31.669: INFO: stdout: "update-demo-nautilus-mnv86 update-demo-nautilus-t75mt "
Dec 11 10:26:31.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-nautilus-mnv86 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fv5p8'
Dec 11 10:26:31.725: INFO: stderr: ""
Dec 11 10:26:31.725: INFO: stdout: "true"
Dec 11 10:26:31.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-nautilus-mnv86 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fv5p8'
Dec 11 10:26:31.784: INFO: stderr: ""
Dec 11 10:26:31.784: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 11 10:26:31.784: INFO: validating pod update-demo-nautilus-mnv86
Dec 11 10:26:31.789: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 11 10:26:31.789: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 11 10:26:31.789: INFO: update-demo-nautilus-mnv86 is verified up and running
Dec 11 10:26:31.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-nautilus-t75mt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fv5p8'
Dec 11 10:26:31.846: INFO: stderr: ""
Dec 11 10:26:31.846: INFO: stdout: "true"
Dec 11 10:26:31.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-nautilus-t75mt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fv5p8'
Dec 11 10:26:31.903: INFO: stderr: ""
Dec 11 10:26:31.903: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 11 10:26:31.903: INFO: validating pod update-demo-nautilus-t75mt
Dec 11 10:26:31.906: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 11 10:26:31.906: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 11 10:26:31.906: INFO: update-demo-nautilus-t75mt is verified up and running
STEP: scaling down the replication controller
Dec 11 10:26:31.907: INFO: scanned /root for discovery docs: <nil>
Dec 11 10:26:31.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-fv5p8'
Dec 11 10:26:32.990: INFO: stderr: ""
Dec 11 10:26:32.990: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 11 10:26:32.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fv5p8'
Dec 11 10:26:33.051: INFO: stderr: ""
Dec 11 10:26:33.051: INFO: stdout: "update-demo-nautilus-mnv86 update-demo-nautilus-t75mt "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 11 10:26:38.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fv5p8'
Dec 11 10:26:38.111: INFO: stderr: ""
Dec 11 10:26:38.111: INFO: stdout: "update-demo-nautilus-mnv86 update-demo-nautilus-t75mt "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 11 10:26:43.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fv5p8'
Dec 11 10:26:43.170: INFO: stderr: ""
Dec 11 10:26:43.170: INFO: stdout: "update-demo-nautilus-mnv86 update-demo-nautilus-t75mt "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 11 10:26:48.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fv5p8'
Dec 11 10:26:48.227: INFO: stderr: ""
Dec 11 10:26:48.227: INFO: stdout: "update-demo-nautilus-t75mt "
Dec 11 10:26:48.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-nautilus-t75mt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fv5p8'
Dec 11 10:26:48.284: INFO: stderr: ""
Dec 11 10:26:48.284: INFO: stdout: "true"
Dec 11 10:26:48.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-nautilus-t75mt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fv5p8'
Dec 11 10:26:48.342: INFO: stderr: ""
Dec 11 10:26:48.342: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 11 10:26:48.342: INFO: validating pod update-demo-nautilus-t75mt
Dec 11 10:26:48.345: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 11 10:26:48.345: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 11 10:26:48.345: INFO: update-demo-nautilus-t75mt is verified up and running
STEP: scaling up the replication controller
Dec 11 10:26:48.345: INFO: scanned /root for discovery docs: <nil>
Dec 11 10:26:48.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-fv5p8'
Dec 11 10:26:49.429: INFO: stderr: ""
Dec 11 10:26:49.430: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 11 10:26:49.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fv5p8'
Dec 11 10:26:49.487: INFO: stderr: ""
Dec 11 10:26:49.487: INFO: stdout: "update-demo-nautilus-4vlzp update-demo-nautilus-t75mt "
Dec 11 10:26:49.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-nautilus-4vlzp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fv5p8'
Dec 11 10:26:49.543: INFO: stderr: ""
Dec 11 10:26:49.543: INFO: stdout: ""
Dec 11 10:26:49.543: INFO: update-demo-nautilus-4vlzp is created but not running
Dec 11 10:26:54.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fv5p8'
Dec 11 10:26:54.604: INFO: stderr: ""
Dec 11 10:26:54.604: INFO: stdout: "update-demo-nautilus-4vlzp update-demo-nautilus-t75mt "
Dec 11 10:26:54.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-nautilus-4vlzp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fv5p8'
Dec 11 10:26:54.660: INFO: stderr: ""
Dec 11 10:26:54.660: INFO: stdout: "true"
Dec 11 10:26:54.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-nautilus-4vlzp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fv5p8'
Dec 11 10:26:54.715: INFO: stderr: ""
Dec 11 10:26:54.715: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 11 10:26:54.715: INFO: validating pod update-demo-nautilus-4vlzp
Dec 11 10:26:54.720: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 11 10:26:54.720: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 11 10:26:54.720: INFO: update-demo-nautilus-4vlzp is verified up and running
Dec 11 10:26:54.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-nautilus-t75mt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fv5p8'
Dec 11 10:26:54.776: INFO: stderr: ""
Dec 11 10:26:54.776: INFO: stdout: "true"
Dec 11 10:26:54.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods update-demo-nautilus-t75mt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fv5p8'
Dec 11 10:26:54.832: INFO: stderr: ""
Dec 11 10:26:54.832: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 11 10:26:54.832: INFO: validating pod update-demo-nautilus-t75mt
Dec 11 10:26:54.835: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 11 10:26:54.835: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 11 10:26:54.835: INFO: update-demo-nautilus-t75mt is verified up and running
STEP: using delete to clean up resources
Dec 11 10:26:54.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-fv5p8'
Dec 11 10:26:54.899: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 11 10:26:54.899: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 11 10:26:54.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-fv5p8'
Dec 11 10:26:54.961: INFO: stderr: "No resources found.\n"
Dec 11 10:26:54.961: INFO: stdout: ""
Dec 11 10:26:54.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods -l name=update-demo --namespace=e2e-tests-kubectl-fv5p8 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 11 10:26:55.022: INFO: stderr: ""
Dec 11 10:26:55.022: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:26:55.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fv5p8" for this suite.
Dec 11 10:27:17.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:27:17.088: INFO: namespace: e2e-tests-kubectl-fv5p8, resource: bindings, ignored listing per whitelist
Dec 11 10:27:17.115: INFO: namespace e2e-tests-kubectl-fv5p8 deletion completed in 22.089843814s

• [SLOW TEST:50.842 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:27:17.115: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-555bf182-fd2f-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume configMaps
Dec 11 10:27:17.239: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-555d6279-fd2f-11e8-897d-5ac57959ef46" in namespace "e2e-tests-projected-kh42l" to be "success or failure"
Dec 11 10:27:17.241: INFO: Pod "pod-projected-configmaps-555d6279-fd2f-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011049ms
Dec 11 10:27:19.244: INFO: Pod "pod-projected-configmaps-555d6279-fd2f-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004834189s
STEP: Saw pod success
Dec 11 10:27:19.244: INFO: Pod "pod-projected-configmaps-555d6279-fd2f-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:27:19.247: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-projected-configmaps-555d6279-fd2f-11e8-897d-5ac57959ef46 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 10:27:19.274: INFO: Waiting for pod pod-projected-configmaps-555d6279-fd2f-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:27:19.276: INFO: Pod pod-projected-configmaps-555d6279-fd2f-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:27:19.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kh42l" for this suite.
Dec 11 10:27:25.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:27:25.347: INFO: namespace: e2e-tests-projected-kh42l, resource: bindings, ignored listing per whitelist
Dec 11 10:27:25.365: INFO: namespace e2e-tests-projected-kh42l deletion completed in 6.085948919s

• [SLOW TEST:8.250 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:27:25.365: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1211 10:27:26.501031      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 11 10:27:26.501: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:27:26.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-f4lgt" for this suite.
Dec 11 10:27:32.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:27:32.528: INFO: namespace: e2e-tests-gc-f4lgt, resource: bindings, ignored listing per whitelist
Dec 11 10:27:32.590: INFO: namespace e2e-tests-gc-f4lgt deletion completed in 6.086011028s

• [SLOW TEST:7.225 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:27:32.590: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-5e9508bd-fd2f-11e8-897d-5ac57959ef46
STEP: Creating configMap with name cm-test-opt-upd-5e9508f3-fd2f-11e8-897d-5ac57959ef46
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-5e9508bd-fd2f-11e8-897d-5ac57959ef46
STEP: Updating configmap cm-test-opt-upd-5e9508f3-fd2f-11e8-897d-5ac57959ef46
STEP: Creating configMap with name cm-test-opt-create-5e950906-fd2f-11e8-897d-5ac57959ef46
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:27:36.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5dc8l" for this suite.
Dec 11 10:27:58.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:27:58.829: INFO: namespace: e2e-tests-configmap-5dc8l, resource: bindings, ignored listing per whitelist
Dec 11 10:27:58.898: INFO: namespace e2e-tests-configmap-5dc8l deletion completed in 22.094037751s

• [SLOW TEST:26.308 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:27:58.898: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-nrvhg
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 11 10:27:58.999: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 11 10:28:21.100: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.111.240.251:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-nrvhg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 10:28:21.100: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
Dec 11 10:28:21.176: INFO: Found all expected endpoints: [netserver-0]
Dec 11 10:28:21.178: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.122.170.73:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-nrvhg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 10:28:21.178: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
Dec 11 10:28:21.255: INFO: Found all expected endpoints: [netserver-1]
Dec 11 10:28:21.257: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.111.88.1:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-nrvhg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 10:28:21.257: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
Dec 11 10:28:21.333: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:28:21.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-nrvhg" for this suite.
Dec 11 10:28:43.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:28:43.359: INFO: namespace: e2e-tests-pod-network-test-nrvhg, resource: bindings, ignored listing per whitelist
Dec 11 10:28:43.423: INFO: namespace e2e-tests-pod-network-test-nrvhg deletion completed in 22.086692217s

• [SLOW TEST:44.525 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:28:43.423: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 11 10:28:43.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-nq5rq'
Dec 11 10:28:43.594: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 11 10:28:43.594: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Dec 11 10:28:43.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-nq5rq'
Dec 11 10:28:43.667: INFO: stderr: ""
Dec 11 10:28:43.668: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:28:43.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nq5rq" for this suite.
Dec 11 10:29:05.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:29:05.695: INFO: namespace: e2e-tests-kubectl-nq5rq, resource: bindings, ignored listing per whitelist
Dec 11 10:29:05.762: INFO: namespace e2e-tests-kubectl-nq5rq deletion completed in 22.090844248s

• [SLOW TEST:22.339 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:29:05.762: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:29:07.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-g97q9" for this suite.
Dec 11 10:29:57.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:29:57.953: INFO: namespace: e2e-tests-kubelet-test-g97q9, resource: bindings, ignored listing per whitelist
Dec 11 10:29:57.981: INFO: namespace e2e-tests-kubelet-test-g97q9 deletion completed in 50.094152255s

• [SLOW TEST:52.219 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:29:57.981: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 11 10:29:58.096: INFO: Waiting up to 5m0s for pod "pod-b53e3e46-fd2f-11e8-897d-5ac57959ef46" in namespace "e2e-tests-emptydir-fxjp2" to be "success or failure"
Dec 11 10:29:58.098: INFO: Pod "pod-b53e3e46-fd2f-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.923611ms
Dec 11 10:30:00.100: INFO: Pod "pod-b53e3e46-fd2f-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004434128s
STEP: Saw pod success
Dec 11 10:30:00.100: INFO: Pod "pod-b53e3e46-fd2f-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:30:00.102: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-b53e3e46-fd2f-11e8-897d-5ac57959ef46 container test-container: <nil>
STEP: delete the pod
Dec 11 10:30:00.130: INFO: Waiting for pod pod-b53e3e46-fd2f-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:30:00.132: INFO: Pod pod-b53e3e46-fd2f-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:30:00.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fxjp2" for this suite.
Dec 11 10:30:06.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:30:06.186: INFO: namespace: e2e-tests-emptydir-fxjp2, resource: bindings, ignored listing per whitelist
Dec 11 10:30:06.223: INFO: namespace e2e-tests-emptydir-fxjp2 deletion completed in 6.088076954s

• [SLOW TEST:8.242 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:30:06.223: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 11 10:30:06.341: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec 11 10:30:06.354: INFO: Number of nodes with available pods: 0
Dec 11 10:30:06.354: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec 11 10:30:06.376: INFO: Number of nodes with available pods: 0
Dec 11 10:30:06.376: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:07.379: INFO: Number of nodes with available pods: 0
Dec 11 10:30:07.379: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:08.378: INFO: Number of nodes with available pods: 1
Dec 11 10:30:08.378: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec 11 10:30:08.398: INFO: Number of nodes with available pods: 1
Dec 11 10:30:08.398: INFO: Number of running nodes: 0, number of available pods: 1
Dec 11 10:30:09.401: INFO: Number of nodes with available pods: 0
Dec 11 10:30:09.401: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec 11 10:30:09.415: INFO: Number of nodes with available pods: 0
Dec 11 10:30:09.415: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:10.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:10.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:11.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:11.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:12.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:12.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:13.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:13.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:14.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:14.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:15.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:15.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:16.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:16.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:17.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:17.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:18.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:18.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:19.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:19.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:20.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:20.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:21.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:21.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:22.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:22.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:23.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:23.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:24.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:24.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:25.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:25.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:26.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:26.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:27.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:27.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:28.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:28.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:29.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:29.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:30.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:30.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:31.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:31.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:32.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:32.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:33.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:33.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:34.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:34.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:35.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:35.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:36.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:36.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:37.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:37.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:38.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:38.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:39.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:39.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:40.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:40.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:41.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:41.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:42.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:42.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:43.418: INFO: Number of nodes with available pods: 0
Dec 11 10:30:43.418: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:30:44.418: INFO: Number of nodes with available pods: 1
Dec 11 10:30:44.418: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-99ftg, will wait for the garbage collector to delete the pods
Dec 11 10:30:44.486: INFO: Deleting DaemonSet.extensions daemon-set took: 12.070227ms
Dec 11 10:30:44.587: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.19598ms
Dec 11 10:31:18.189: INFO: Number of nodes with available pods: 0
Dec 11 10:31:18.189: INFO: Number of running nodes: 0, number of available pods: 0
Dec 11 10:31:18.191: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-99ftg/daemonsets","resourceVersion":"21969100"},"items":null}

Dec 11 10:31:18.193: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-99ftg/pods","resourceVersion":"21969100"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:31:18.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-99ftg" for this suite.
Dec 11 10:31:24.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:31:24.308: INFO: namespace: e2e-tests-daemonsets-99ftg, resource: bindings, ignored listing per whitelist
Dec 11 10:31:24.310: INFO: namespace e2e-tests-daemonsets-99ftg deletion completed in 6.088163347s

• [SLOW TEST:78.086 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:31:24.310: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-bgh7
STEP: Creating a pod to test atomic-volume-subpath
Dec 11 10:31:24.441: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-bgh7" in namespace "e2e-tests-subpath-rcqkz" to be "success or failure"
Dec 11 10:31:24.444: INFO: Pod "pod-subpath-test-configmap-bgh7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.244411ms
Dec 11 10:31:26.446: INFO: Pod "pod-subpath-test-configmap-bgh7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004873242s
Dec 11 10:31:28.449: INFO: Pod "pod-subpath-test-configmap-bgh7": Phase="Running", Reason="", readiness=false. Elapsed: 4.007662039s
Dec 11 10:31:30.452: INFO: Pod "pod-subpath-test-configmap-bgh7": Phase="Running", Reason="", readiness=false. Elapsed: 6.010893517s
Dec 11 10:31:32.455: INFO: Pod "pod-subpath-test-configmap-bgh7": Phase="Running", Reason="", readiness=false. Elapsed: 8.013657618s
Dec 11 10:31:34.458: INFO: Pod "pod-subpath-test-configmap-bgh7": Phase="Running", Reason="", readiness=false. Elapsed: 10.016258081s
Dec 11 10:31:36.461: INFO: Pod "pod-subpath-test-configmap-bgh7": Phase="Running", Reason="", readiness=false. Elapsed: 12.019073728s
Dec 11 10:31:38.464: INFO: Pod "pod-subpath-test-configmap-bgh7": Phase="Running", Reason="", readiness=false. Elapsed: 14.022035473s
Dec 11 10:31:40.467: INFO: Pod "pod-subpath-test-configmap-bgh7": Phase="Running", Reason="", readiness=false. Elapsed: 16.025000269s
Dec 11 10:31:42.470: INFO: Pod "pod-subpath-test-configmap-bgh7": Phase="Running", Reason="", readiness=false. Elapsed: 18.028167877s
Dec 11 10:31:44.472: INFO: Pod "pod-subpath-test-configmap-bgh7": Phase="Running", Reason="", readiness=false. Elapsed: 20.030933801s
Dec 11 10:31:46.475: INFO: Pod "pod-subpath-test-configmap-bgh7": Phase="Running", Reason="", readiness=false. Elapsed: 22.033494141s
Dec 11 10:31:48.478: INFO: Pod "pod-subpath-test-configmap-bgh7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.036291541s
STEP: Saw pod success
Dec 11 10:31:48.478: INFO: Pod "pod-subpath-test-configmap-bgh7" satisfied condition "success or failure"
Dec 11 10:31:48.480: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-subpath-test-configmap-bgh7 container test-container-subpath-configmap-bgh7: <nil>
STEP: delete the pod
Dec 11 10:31:48.508: INFO: Waiting for pod pod-subpath-test-configmap-bgh7 to disappear
Dec 11 10:31:48.510: INFO: Pod pod-subpath-test-configmap-bgh7 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-bgh7
Dec 11 10:31:48.510: INFO: Deleting pod "pod-subpath-test-configmap-bgh7" in namespace "e2e-tests-subpath-rcqkz"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:31:48.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-rcqkz" for this suite.
Dec 11 10:31:54.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:31:54.557: INFO: namespace: e2e-tests-subpath-rcqkz, resource: bindings, ignored listing per whitelist
Dec 11 10:31:54.605: INFO: namespace e2e-tests-subpath-rcqkz deletion completed in 6.08887637s

• [SLOW TEST:30.295 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:31:54.605: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 11 10:31:54.712: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fac078c5-fd2f-11e8-897d-5ac57959ef46" in namespace "e2e-tests-projected-qgdqp" to be "success or failure"
Dec 11 10:31:54.714: INFO: Pod "downwardapi-volume-fac078c5-fd2f-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003687ms
Dec 11 10:31:56.717: INFO: Pod "downwardapi-volume-fac078c5-fd2f-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005041361s
STEP: Saw pod success
Dec 11 10:31:56.717: INFO: Pod "downwardapi-volume-fac078c5-fd2f-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:31:56.720: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod downwardapi-volume-fac078c5-fd2f-11e8-897d-5ac57959ef46 container client-container: <nil>
STEP: delete the pod
Dec 11 10:31:56.748: INFO: Waiting for pod downwardapi-volume-fac078c5-fd2f-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:31:56.751: INFO: Pod downwardapi-volume-fac078c5-fd2f-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:31:56.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qgdqp" for this suite.
Dec 11 10:32:02.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:32:02.824: INFO: namespace: e2e-tests-projected-qgdqp, resource: bindings, ignored listing per whitelist
Dec 11 10:32:02.840: INFO: namespace e2e-tests-projected-qgdqp deletion completed in 6.085742088s

• [SLOW TEST:8.235 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:32:02.841: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Dec 11 10:32:04.954: INFO: Pod pod-hostip-ffa8a5e7-fd2f-11e8-897d-5ac57959ef46 has hostIP: 172.25.62.1
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:32:04.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-l6gbn" for this suite.
Dec 11 10:32:26.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:32:27.012: INFO: namespace: e2e-tests-pods-l6gbn, resource: bindings, ignored listing per whitelist
Dec 11 10:32:27.049: INFO: namespace e2e-tests-pods-l6gbn deletion completed in 22.091281307s

• [SLOW TEST:24.208 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:32:27.049: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 11 10:32:45.168: INFO: Container started at 2018-12-11 10:32:28 +0000 UTC, pod became ready at 2018-12-11 10:32:43 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:32:45.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-9w98t" for this suite.
Dec 11 10:33:07.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:33:07.202: INFO: namespace: e2e-tests-container-probe-9w98t, resource: bindings, ignored listing per whitelist
Dec 11 10:33:07.256: INFO: namespace e2e-tests-container-probe-9w98t deletion completed in 22.084740809s

• [SLOW TEST:40.207 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:33:07.256: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 11 10:33:07.414: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2615fd1e-fd30-11e8-897d-5ac57959ef46" in namespace "e2e-tests-downward-api-p54tk" to be "success or failure"
Dec 11 10:33:07.416: INFO: Pod "downwardapi-volume-2615fd1e-fd30-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022286ms
Dec 11 10:33:09.418: INFO: Pod "downwardapi-volume-2615fd1e-fd30-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004539237s
STEP: Saw pod success
Dec 11 10:33:09.418: INFO: Pod "downwardapi-volume-2615fd1e-fd30-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:33:09.421: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod downwardapi-volume-2615fd1e-fd30-11e8-897d-5ac57959ef46 container client-container: <nil>
STEP: delete the pod
Dec 11 10:33:09.450: INFO: Waiting for pod downwardapi-volume-2615fd1e-fd30-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:33:09.451: INFO: Pod downwardapi-volume-2615fd1e-fd30-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:33:09.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-p54tk" for this suite.
Dec 11 10:33:15.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:33:15.494: INFO: namespace: e2e-tests-downward-api-p54tk, resource: bindings, ignored listing per whitelist
Dec 11 10:33:15.540: INFO: namespace e2e-tests-downward-api-p54tk deletion completed in 6.085794533s

• [SLOW TEST:8.284 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:33:15.541: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec 11 10:33:17.656: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-2afe3bef-fd30-11e8-897d-5ac57959ef46,GenerateName:,Namespace:e2e-tests-events-nqm5j,SelfLink:/api/v1/namespaces/e2e-tests-events-nqm5j/pods/send-events-2afe3bef-fd30-11e8-897d-5ac57959ef46,UID:2afe50c7-fd30-11e8-8e03-0681e6464a68,ResourceVersion:21969461,Generation:0,CreationTimestamp:2018-12-11 10:33:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 636227969,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nkl79 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nkl79,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-nkl79 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-62-1.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001be6060} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001be6080}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:33:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:33:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:33:15 +0000 UTC  }],Message:,Reason:,HostIP:172.25.62.1,PodIP:100.111.88.52,StartTime:2018-12-11 10:33:15 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-12-11 10:33:16 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://c6f494c92534020b6c0dcd40ac07e711524bf21166b9f00d3b108c80ea432563}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Dec 11 10:33:19.659: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec 11 10:33:21.662: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:33:21.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-nqm5j" for this suite.
Dec 11 10:33:59.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:33:59.723: INFO: namespace: e2e-tests-events-nqm5j, resource: bindings, ignored listing per whitelist
Dec 11 10:33:59.764: INFO: namespace e2e-tests-events-nqm5j deletion completed in 38.086351862s

• [SLOW TEST:44.223 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:33:59.764: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:34:25.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-7skjl" for this suite.
Dec 11 10:34:31.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:34:31.126: INFO: namespace: e2e-tests-container-runtime-7skjl, resource: bindings, ignored listing per whitelist
Dec 11 10:34:31.161: INFO: namespace e2e-tests-container-runtime-7skjl deletion completed in 6.08651918s

• [SLOW TEST:31.397 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:34:31.161: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-581142d3-fd30-11e8-897d-5ac57959ef46
STEP: Creating configMap with name cm-test-opt-upd-5811430c-fd30-11e8-897d-5ac57959ef46
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-581142d3-fd30-11e8-897d-5ac57959ef46
STEP: Updating configmap cm-test-opt-upd-5811430c-fd30-11e8-897d-5ac57959ef46
STEP: Creating configMap with name cm-test-opt-create-58114321-fd30-11e8-897d-5ac57959ef46
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:36:03.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sd2mh" for this suite.
Dec 11 10:36:25.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:36:25.674: INFO: namespace: e2e-tests-projected-sd2mh, resource: bindings, ignored listing per whitelist
Dec 11 10:36:25.736: INFO: namespace e2e-tests-projected-sd2mh deletion completed in 22.084527884s

• [SLOW TEST:114.576 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:36:25.736: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 11 10:36:25.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-5pq8z'
Dec 11 10:36:26.026: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 11 10:36:26.026: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Dec 11 10:36:28.032: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-kwhg4]
Dec 11 10:36:28.032: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-kwhg4" in namespace "e2e-tests-kubectl-5pq8z" to be "running and ready"
Dec 11 10:36:28.034: INFO: Pod "e2e-test-nginx-rc-kwhg4": Phase="Running", Reason="", readiness=true. Elapsed: 2.03063ms
Dec 11 10:36:28.034: INFO: Pod "e2e-test-nginx-rc-kwhg4" satisfied condition "running and ready"
Dec 11 10:36:28.034: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-kwhg4]
Dec 11 10:36:28.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-5pq8z'
Dec 11 10:36:28.107: INFO: stderr: ""
Dec 11 10:36:28.107: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Dec 11 10:36:28.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-5pq8z'
Dec 11 10:36:28.177: INFO: stderr: ""
Dec 11 10:36:28.177: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:36:28.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5pq8z" for this suite.
Dec 11 10:36:34.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:36:34.248: INFO: namespace: e2e-tests-kubectl-5pq8z, resource: bindings, ignored listing per whitelist
Dec 11 10:36:34.272: INFO: namespace e2e-tests-kubectl-5pq8z deletion completed in 6.091472878s

• [SLOW TEST:8.535 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:36:34.272: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-a172485f-fd30-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume secrets
Dec 11 10:36:34.389: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a173d2e9-fd30-11e8-897d-5ac57959ef46" in namespace "e2e-tests-projected-84mjs" to be "success or failure"
Dec 11 10:36:34.391: INFO: Pod "pod-projected-secrets-a173d2e9-fd30-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.967749ms
Dec 11 10:36:36.394: INFO: Pod "pod-projected-secrets-a173d2e9-fd30-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004591298s
STEP: Saw pod success
Dec 11 10:36:36.394: INFO: Pod "pod-projected-secrets-a173d2e9-fd30-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:36:36.396: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-projected-secrets-a173d2e9-fd30-11e8-897d-5ac57959ef46 container secret-volume-test: <nil>
STEP: delete the pod
Dec 11 10:36:36.424: INFO: Waiting for pod pod-projected-secrets-a173d2e9-fd30-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:36:36.426: INFO: Pod pod-projected-secrets-a173d2e9-fd30-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:36:36.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-84mjs" for this suite.
Dec 11 10:36:42.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:36:42.496: INFO: namespace: e2e-tests-projected-84mjs, resource: bindings, ignored listing per whitelist
Dec 11 10:36:42.517: INFO: namespace e2e-tests-projected-84mjs deletion completed in 6.086874471s

• [SLOW TEST:8.245 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:36:42.517: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:37:42.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-nfl6r" for this suite.
Dec 11 10:38:04.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:38:04.711: INFO: namespace: e2e-tests-container-probe-nfl6r, resource: bindings, ignored listing per whitelist
Dec 11 10:38:04.716: INFO: namespace e2e-tests-container-probe-nfl6r deletion completed in 22.084853455s

• [SLOW TEST:82.200 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:38:04.717: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:38:04.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-crr9v" for this suite.
Dec 11 10:38:26.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:38:26.868: INFO: namespace: e2e-tests-pods-crr9v, resource: bindings, ignored listing per whitelist
Dec 11 10:38:26.917: INFO: namespace e2e-tests-pods-crr9v deletion completed in 22.089798744s

• [SLOW TEST:22.200 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:38:26.917: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-e497936a-fd30-11e8-897d-5ac57959ef46
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-e497936a-fd30-11e8-897d-5ac57959ef46
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:38:31.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-dtzt6" for this suite.
Dec 11 10:38:53.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:38:53.104: INFO: namespace: e2e-tests-configmap-dtzt6, resource: bindings, ignored listing per whitelist
Dec 11 10:38:53.164: INFO: namespace e2e-tests-configmap-dtzt6 deletion completed in 22.083552706s

• [SLOW TEST:26.247 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:38:53.165: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 11 10:38:53.273: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f43be3a8-fd30-11e8-897d-5ac57959ef46" in namespace "e2e-tests-downward-api-cr22x" to be "success or failure"
Dec 11 10:38:53.275: INFO: Pod "downwardapi-volume-f43be3a8-fd30-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.123431ms
Dec 11 10:38:55.278: INFO: Pod "downwardapi-volume-f43be3a8-fd30-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004742297s
STEP: Saw pod success
Dec 11 10:38:55.278: INFO: Pod "downwardapi-volume-f43be3a8-fd30-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:38:55.280: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod downwardapi-volume-f43be3a8-fd30-11e8-897d-5ac57959ef46 container client-container: <nil>
STEP: delete the pod
Dec 11 10:38:55.307: INFO: Waiting for pod downwardapi-volume-f43be3a8-fd30-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:38:55.309: INFO: Pod downwardapi-volume-f43be3a8-fd30-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:38:55.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cr22x" for this suite.
Dec 11 10:39:01.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:39:01.370: INFO: namespace: e2e-tests-downward-api-cr22x, resource: bindings, ignored listing per whitelist
Dec 11 10:39:01.396: INFO: namespace e2e-tests-downward-api-cr22x deletion completed in 6.083870875s

• [SLOW TEST:8.231 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:39:01.396: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec 11 10:39:04.025: INFO: Successfully updated pod "labelsupdatef9231463-fd30-11e8-897d-5ac57959ef46"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:39:08.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jn97h" for this suite.
Dec 11 10:39:30.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:39:30.077: INFO: namespace: e2e-tests-downward-api-jn97h, resource: bindings, ignored listing per whitelist
Dec 11 10:39:30.131: INFO: namespace e2e-tests-downward-api-jn97h deletion completed in 22.085443519s

• [SLOW TEST:28.735 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:39:30.131: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 11 10:39:30.232: INFO: (0) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.128007ms)
Dec 11 10:39:30.236: INFO: (1) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.051613ms)
Dec 11 10:39:30.239: INFO: (2) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.072768ms)
Dec 11 10:39:30.242: INFO: (3) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.969934ms)
Dec 11 10:39:30.245: INFO: (4) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.026403ms)
Dec 11 10:39:30.248: INFO: (5) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.905449ms)
Dec 11 10:39:30.251: INFO: (6) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.004613ms)
Dec 11 10:39:30.254: INFO: (7) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.944723ms)
Dec 11 10:39:30.257: INFO: (8) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.907043ms)
Dec 11 10:39:30.260: INFO: (9) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.995786ms)
Dec 11 10:39:30.262: INFO: (10) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.935638ms)
Dec 11 10:39:30.266: INFO: (11) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.149404ms)
Dec 11 10:39:30.269: INFO: (12) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.011275ms)
Dec 11 10:39:30.272: INFO: (13) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.967065ms)
Dec 11 10:39:30.275: INFO: (14) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.038744ms)
Dec 11 10:39:30.278: INFO: (15) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.97683ms)
Dec 11 10:39:30.281: INFO: (16) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.895011ms)
Dec 11 10:39:30.284: INFO: (17) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.005281ms)
Dec 11 10:39:30.287: INFO: (18) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.921876ms)
Dec 11 10:39:30.290: INFO: (19) /api/v1/nodes/ip-172-25-45-107.us-west-1.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.068856ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:39:30.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-67fqc" for this suite.
Dec 11 10:39:36.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:39:36.358: INFO: namespace: e2e-tests-proxy-67fqc, resource: bindings, ignored listing per whitelist
Dec 11 10:39:36.378: INFO: namespace e2e-tests-proxy-67fqc deletion completed in 6.084973413s

• [SLOW TEST:6.247 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:39:36.378: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-0dfd5534-fd31-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume configMaps
Dec 11 10:39:36.495: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0dfee466-fd31-11e8-897d-5ac57959ef46" in namespace "e2e-tests-projected-mmchd" to be "success or failure"
Dec 11 10:39:36.497: INFO: Pod "pod-projected-configmaps-0dfee466-fd31-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.957572ms
Dec 11 10:39:38.499: INFO: Pod "pod-projected-configmaps-0dfee466-fd31-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004644104s
STEP: Saw pod success
Dec 11 10:39:38.499: INFO: Pod "pod-projected-configmaps-0dfee466-fd31-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:39:38.501: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-projected-configmaps-0dfee466-fd31-11e8-897d-5ac57959ef46 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 10:39:38.528: INFO: Waiting for pod pod-projected-configmaps-0dfee466-fd31-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:39:38.530: INFO: Pod pod-projected-configmaps-0dfee466-fd31-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:39:38.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mmchd" for this suite.
Dec 11 10:39:44.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:39:44.593: INFO: namespace: e2e-tests-projected-mmchd, resource: bindings, ignored listing per whitelist
Dec 11 10:39:44.630: INFO: namespace e2e-tests-projected-mmchd deletion completed in 6.096520138s

• [SLOW TEST:8.252 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:39:44.630: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec 11 10:39:44.757: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-cgrtr,SelfLink:/api/v1/namespaces/e2e-tests-watch-cgrtr/configmaps/e2e-watch-test-watch-closed,UID:12e9e6c1-fd31-11e8-8e03-0681e6464a68,ResourceVersion:21970459,Generation:0,CreationTimestamp:2018-12-11 10:39:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 11 10:39:44.757: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-cgrtr,SelfLink:/api/v1/namespaces/e2e-tests-watch-cgrtr/configmaps/e2e-watch-test-watch-closed,UID:12e9e6c1-fd31-11e8-8e03-0681e6464a68,ResourceVersion:21970460,Generation:0,CreationTimestamp:2018-12-11 10:39:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec 11 10:39:44.781: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-cgrtr,SelfLink:/api/v1/namespaces/e2e-tests-watch-cgrtr/configmaps/e2e-watch-test-watch-closed,UID:12e9e6c1-fd31-11e8-8e03-0681e6464a68,ResourceVersion:21970461,Generation:0,CreationTimestamp:2018-12-11 10:39:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 11 10:39:44.782: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-cgrtr,SelfLink:/api/v1/namespaces/e2e-tests-watch-cgrtr/configmaps/e2e-watch-test-watch-closed,UID:12e9e6c1-fd31-11e8-8e03-0681e6464a68,ResourceVersion:21970462,Generation:0,CreationTimestamp:2018-12-11 10:39:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:39:44.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-cgrtr" for this suite.
Dec 11 10:39:50.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:39:50.830: INFO: namespace: e2e-tests-watch-cgrtr, resource: bindings, ignored listing per whitelist
Dec 11 10:39:50.869: INFO: namespace e2e-tests-watch-cgrtr deletion completed in 6.083485637s

• [SLOW TEST:6.238 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:39:50.869: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-fvksk/configmap-test-16a06475-fd31-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume configMaps
Dec 11 10:39:50.986: INFO: Waiting up to 5m0s for pod "pod-configmaps-16a20a95-fd31-11e8-897d-5ac57959ef46" in namespace "e2e-tests-configmap-fvksk" to be "success or failure"
Dec 11 10:39:50.988: INFO: Pod "pod-configmaps-16a20a95-fd31-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.913752ms
Dec 11 10:39:52.991: INFO: Pod "pod-configmaps-16a20a95-fd31-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004493089s
STEP: Saw pod success
Dec 11 10:39:52.991: INFO: Pod "pod-configmaps-16a20a95-fd31-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:39:52.993: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-configmaps-16a20a95-fd31-11e8-897d-5ac57959ef46 container env-test: <nil>
STEP: delete the pod
Dec 11 10:39:53.020: INFO: Waiting for pod pod-configmaps-16a20a95-fd31-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:39:53.022: INFO: Pod pod-configmaps-16a20a95-fd31-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:39:53.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fvksk" for this suite.
Dec 11 10:39:59.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:39:59.059: INFO: namespace: e2e-tests-configmap-fvksk, resource: bindings, ignored listing per whitelist
Dec 11 10:39:59.121: INFO: namespace e2e-tests-configmap-fvksk deletion completed in 6.095591393s

• [SLOW TEST:8.252 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:39:59.121: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-1b8c7458-fd31-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume configMaps
Dec 11 10:39:59.243: INFO: Waiting up to 5m0s for pod "pod-configmaps-1b8e02f6-fd31-11e8-897d-5ac57959ef46" in namespace "e2e-tests-configmap-tzdcr" to be "success or failure"
Dec 11 10:39:59.245: INFO: Pod "pod-configmaps-1b8e02f6-fd31-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.596777ms
Dec 11 10:40:01.248: INFO: Pod "pod-configmaps-1b8e02f6-fd31-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005662524s
STEP: Saw pod success
Dec 11 10:40:01.248: INFO: Pod "pod-configmaps-1b8e02f6-fd31-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:40:01.251: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-configmaps-1b8e02f6-fd31-11e8-897d-5ac57959ef46 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 10:40:01.278: INFO: Waiting for pod pod-configmaps-1b8e02f6-fd31-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:40:01.280: INFO: Pod pod-configmaps-1b8e02f6-fd31-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:40:01.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tzdcr" for this suite.
Dec 11 10:40:07.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:40:07.367: INFO: namespace: e2e-tests-configmap-tzdcr, resource: bindings, ignored listing per whitelist
Dec 11 10:40:07.379: INFO: namespace e2e-tests-configmap-tzdcr deletion completed in 6.095751455s

• [SLOW TEST:8.258 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:40:07.379: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-dkvk2
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Dec 11 10:40:07.504: INFO: Found 0 stateful pods, waiting for 3
Dec 11 10:40:17.507: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 11 10:40:17.507: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 11 10:40:17.507: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec 11 10:40:17.539: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec 11 10:40:27.574: INFO: Updating stateful set ss2
Dec 11 10:40:27.579: INFO: Waiting for Pod e2e-tests-statefulset-dkvk2/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Dec 11 10:40:37.639: INFO: Found 2 stateful pods, waiting for 3
Dec 11 10:40:47.642: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 11 10:40:47.642: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 11 10:40:47.642: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec 11 10:40:47.673: INFO: Updating stateful set ss2
Dec 11 10:40:47.677: INFO: Waiting for Pod e2e-tests-statefulset-dkvk2/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec 11 10:40:57.708: INFO: Updating stateful set ss2
Dec 11 10:40:57.713: INFO: Waiting for StatefulSet e2e-tests-statefulset-dkvk2/ss2 to complete update
Dec 11 10:40:57.713: INFO: Waiting for Pod e2e-tests-statefulset-dkvk2/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 11 10:41:07.718: INFO: Deleting all statefulset in ns e2e-tests-statefulset-dkvk2
Dec 11 10:41:07.720: INFO: Scaling statefulset ss2 to 0
Dec 11 10:41:37.746: INFO: Waiting for statefulset status.replicas updated to 0
Dec 11 10:41:37.748: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:41:37.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-dkvk2" for this suite.
Dec 11 10:41:43.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:41:43.852: INFO: namespace: e2e-tests-statefulset-dkvk2, resource: bindings, ignored listing per whitelist
Dec 11 10:41:43.859: INFO: namespace e2e-tests-statefulset-dkvk2 deletion completed in 6.089644285s

• [SLOW TEST:96.480 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:41:43.859: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-59f9ba40-fd31-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume secrets
Dec 11 10:41:44.035: INFO: Waiting up to 5m0s for pod "pod-secrets-5a04163f-fd31-11e8-897d-5ac57959ef46" in namespace "e2e-tests-secrets-lr4lg" to be "success or failure"
Dec 11 10:41:44.037: INFO: Pod "pod-secrets-5a04163f-fd31-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.970628ms
Dec 11 10:41:46.040: INFO: Pod "pod-secrets-5a04163f-fd31-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004593467s
STEP: Saw pod success
Dec 11 10:41:46.040: INFO: Pod "pod-secrets-5a04163f-fd31-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:41:46.042: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-secrets-5a04163f-fd31-11e8-897d-5ac57959ef46 container secret-volume-test: <nil>
STEP: delete the pod
Dec 11 10:41:46.070: INFO: Waiting for pod pod-secrets-5a04163f-fd31-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:41:46.072: INFO: Pod pod-secrets-5a04163f-fd31-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:41:46.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-lr4lg" for this suite.
Dec 11 10:41:52.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:41:52.128: INFO: namespace: e2e-tests-secrets-lr4lg, resource: bindings, ignored listing per whitelist
Dec 11 10:41:52.172: INFO: namespace e2e-tests-secrets-lr4lg deletion completed in 6.095535588s
STEP: Destroying namespace "e2e-tests-secret-namespace-8x6vk" for this suite.
Dec 11 10:41:58.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:41:58.240: INFO: namespace: e2e-tests-secret-namespace-8x6vk, resource: bindings, ignored listing per whitelist
Dec 11 10:41:58.258: INFO: namespace e2e-tests-secret-namespace-8x6vk deletion completed in 6.086707864s

• [SLOW TEST:14.399 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:41:58.259: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec 11 10:41:58.368: INFO: Pod name pod-release: Found 0 pods out of 1
Dec 11 10:42:03.371: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:42:04.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-n8j4q" for this suite.
Dec 11 10:42:10.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:42:10.472: INFO: namespace: e2e-tests-replication-controller-n8j4q, resource: bindings, ignored listing per whitelist
Dec 11 10:42:10.479: INFO: namespace e2e-tests-replication-controller-n8j4q deletion completed in 6.084760975s

• [SLOW TEST:12.220 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:42:10.479: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 11 10:42:10.586: INFO: Waiting up to 5m0s for pod "downwardapi-volume-69d75583-fd31-11e8-897d-5ac57959ef46" in namespace "e2e-tests-downward-api-mp64n" to be "success or failure"
Dec 11 10:42:10.588: INFO: Pod "downwardapi-volume-69d75583-fd31-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209553ms
Dec 11 10:42:12.591: INFO: Pod "downwardapi-volume-69d75583-fd31-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004824591s
STEP: Saw pod success
Dec 11 10:42:12.591: INFO: Pod "downwardapi-volume-69d75583-fd31-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:42:12.593: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod downwardapi-volume-69d75583-fd31-11e8-897d-5ac57959ef46 container client-container: <nil>
STEP: delete the pod
Dec 11 10:42:12.621: INFO: Waiting for pod downwardapi-volume-69d75583-fd31-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:42:12.624: INFO: Pod downwardapi-volume-69d75583-fd31-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:42:12.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mp64n" for this suite.
Dec 11 10:42:18.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:42:18.655: INFO: namespace: e2e-tests-downward-api-mp64n, resource: bindings, ignored listing per whitelist
Dec 11 10:42:18.724: INFO: namespace e2e-tests-downward-api-mp64n deletion completed in 6.096819996s

• [SLOW TEST:8.245 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:42:18.724: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec 11 10:42:21.355: INFO: Successfully updated pod "labelsupdate6ec0e769-fd31-11e8-897d-5ac57959ef46"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:42:25.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-87wtt" for this suite.
Dec 11 10:42:47.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:42:47.449: INFO: namespace: e2e-tests-projected-87wtt, resource: bindings, ignored listing per whitelist
Dec 11 10:42:47.468: INFO: namespace e2e-tests-projected-87wtt deletion completed in 22.090801697s

• [SLOW TEST:28.744 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:42:47.468: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-kn7fr
Dec 11 10:42:49.587: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-kn7fr
STEP: checking the pod's current state and verifying that restartCount is present
Dec 11 10:42:49.589: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:46:49.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-kn7fr" for this suite.
Dec 11 10:46:55.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:46:56.113: INFO: namespace: e2e-tests-container-probe-kn7fr, resource: bindings, ignored listing per whitelist
Dec 11 10:46:56.113: INFO: namespace e2e-tests-container-probe-kn7fr deletion completed in 6.132125014s

• [SLOW TEST:248.645 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:46:56.113: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 11 10:46:56.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-wfwj7'
Dec 11 10:46:56.407: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 11 10:46:56.407: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Dec 11 10:46:56.411: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Dec 11 10:46:56.423: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Dec 11 10:46:56.435: INFO: scanned /root for discovery docs: <nil>
Dec 11 10:46:56.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-wfwj7'
Dec 11 10:47:12.605: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 11 10:47:12.605: INFO: stdout: "Created e2e-test-nginx-rc-c1c51b761b9b1545dfb03ef526f714ae\nScaling up e2e-test-nginx-rc-c1c51b761b9b1545dfb03ef526f714ae from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-c1c51b761b9b1545dfb03ef526f714ae up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-c1c51b761b9b1545dfb03ef526f714ae to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Dec 11 10:47:12.605: INFO: stdout: "Created e2e-test-nginx-rc-c1c51b761b9b1545dfb03ef526f714ae\nScaling up e2e-test-nginx-rc-c1c51b761b9b1545dfb03ef526f714ae from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-c1c51b761b9b1545dfb03ef526f714ae up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-c1c51b761b9b1545dfb03ef526f714ae to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Dec 11 10:47:12.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-wfwj7'
Dec 11 10:47:12.664: INFO: stderr: ""
Dec 11 10:47:12.664: INFO: stdout: "e2e-test-nginx-rc-6rr6m e2e-test-nginx-rc-c1c51b761b9b1545dfb03ef526f714ae-8nt9l "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Dec 11 10:47:17.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-wfwj7'
Dec 11 10:47:17.723: INFO: stderr: ""
Dec 11 10:47:17.723: INFO: stdout: "e2e-test-nginx-rc-c1c51b761b9b1545dfb03ef526f714ae-8nt9l "
Dec 11 10:47:17.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods e2e-test-nginx-rc-c1c51b761b9b1545dfb03ef526f714ae-8nt9l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wfwj7'
Dec 11 10:47:17.780: INFO: stderr: ""
Dec 11 10:47:17.780: INFO: stdout: "true"
Dec 11 10:47:17.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 get pods e2e-test-nginx-rc-c1c51b761b9b1545dfb03ef526f714ae-8nt9l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wfwj7'
Dec 11 10:47:17.836: INFO: stderr: ""
Dec 11 10:47:17.836: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Dec 11 10:47:17.836: INFO: e2e-test-nginx-rc-c1c51b761b9b1545dfb03ef526f714ae-8nt9l is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Dec 11 10:47:17.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357251099 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-wfwj7'
Dec 11 10:47:17.904: INFO: stderr: ""
Dec 11 10:47:17.904: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:47:17.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wfwj7" for this suite.
Dec 11 10:47:39.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:47:39.979: INFO: namespace: e2e-tests-kubectl-wfwj7, resource: bindings, ignored listing per whitelist
Dec 11 10:47:40.002: INFO: namespace e2e-tests-kubectl-wfwj7 deletion completed in 22.094531746s

• [SLOW TEST:43.889 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:47:40.002: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Dec 11 10:47:42.132: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-2e4220e1-fd32-11e8-897d-5ac57959ef46", GenerateName:"", Namespace:"e2e-tests-pods-zbgdj", SelfLink:"/api/v1/namespaces/e2e-tests-pods-zbgdj/pods/pod-submit-remove-2e4220e1-fd32-11e8-897d-5ac57959ef46", UID:"2e42cb37-fd32-11e8-8e03-0681e6464a68", ResourceVersion:"21971785", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63680122060, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"107803126"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-qhbrq", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00074ec40), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-qhbrq", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002014278), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-25-62-1.us-west-1.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000e7dd40), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0020142b0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0020142d0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680122060, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680122061, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680122060, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.25.62.1", PodIP:"100.111.88.39", StartTime:(*v1.Time)(0xc001619f00), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc001619f20), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6", ContainerID:"docker://cc7f86ba0785b01e697ef9c96001983d2b22bbca4b48af601dad448c7eab8a25"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec 11 10:47:47.154: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:47:47.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-zbgdj" for this suite.
Dec 11 10:47:53.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:47:53.220: INFO: namespace: e2e-tests-pods-zbgdj, resource: bindings, ignored listing per whitelist
Dec 11 10:47:53.247: INFO: namespace e2e-tests-pods-zbgdj deletion completed in 6.086617135s

• [SLOW TEST:13.245 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:47:53.247: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 11 10:47:53.358: INFO: Waiting up to 5m0s for pod "pod-362652b1-fd32-11e8-897d-5ac57959ef46" in namespace "e2e-tests-emptydir-l95wp" to be "success or failure"
Dec 11 10:47:53.360: INFO: Pod "pod-362652b1-fd32-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.997298ms
Dec 11 10:47:55.363: INFO: Pod "pod-362652b1-fd32-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004627047s
STEP: Saw pod success
Dec 11 10:47:55.363: INFO: Pod "pod-362652b1-fd32-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:47:55.366: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-362652b1-fd32-11e8-897d-5ac57959ef46 container test-container: <nil>
STEP: delete the pod
Dec 11 10:47:55.395: INFO: Waiting for pod pod-362652b1-fd32-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:47:55.397: INFO: Pod pod-362652b1-fd32-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:47:55.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-l95wp" for this suite.
Dec 11 10:48:01.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:48:01.447: INFO: namespace: e2e-tests-emptydir-l95wp, resource: bindings, ignored listing per whitelist
Dec 11 10:48:01.486: INFO: namespace e2e-tests-emptydir-l95wp deletion completed in 6.086376037s

• [SLOW TEST:8.240 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:48:01.487: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec 11 10:48:01.577: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:48:05.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-psgqh" for this suite.
Dec 11 10:48:27.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:48:27.289: INFO: namespace: e2e-tests-init-container-psgqh, resource: bindings, ignored listing per whitelist
Dec 11 10:48:27.304: INFO: namespace e2e-tests-init-container-psgqh deletion completed in 22.088611012s

• [SLOW TEST:25.818 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:48:27.304: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 11 10:48:29.936: INFO: Successfully updated pod "pod-update-activedeadlineseconds-4a727dca-fd32-11e8-897d-5ac57959ef46"
Dec 11 10:48:29.936: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-4a727dca-fd32-11e8-897d-5ac57959ef46" in namespace "e2e-tests-pods-pvjxx" to be "terminated due to deadline exceeded"
Dec 11 10:48:29.938: INFO: Pod "pod-update-activedeadlineseconds-4a727dca-fd32-11e8-897d-5ac57959ef46": Phase="Running", Reason="", readiness=true. Elapsed: 2.195013ms
Dec 11 10:48:31.941: INFO: Pod "pod-update-activedeadlineseconds-4a727dca-fd32-11e8-897d-5ac57959ef46": Phase="Running", Reason="", readiness=true. Elapsed: 2.005055594s
Dec 11 10:48:33.943: INFO: Pod "pod-update-activedeadlineseconds-4a727dca-fd32-11e8-897d-5ac57959ef46": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.007554925s
Dec 11 10:48:33.943: INFO: Pod "pod-update-activedeadlineseconds-4a727dca-fd32-11e8-897d-5ac57959ef46" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:48:33.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-pvjxx" for this suite.
Dec 11 10:48:39.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:48:40.035: INFO: namespace: e2e-tests-pods-pvjxx, resource: bindings, ignored listing per whitelist
Dec 11 10:48:40.035: INFO: namespace e2e-tests-pods-pvjxx deletion completed in 6.088470791s

• [SLOW TEST:12.731 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:48:40.035: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-52094038-fd32-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume secrets
Dec 11 10:48:40.154: INFO: Waiting up to 5m0s for pod "pod-secrets-520ad714-fd32-11e8-897d-5ac57959ef46" in namespace "e2e-tests-secrets-fsfw2" to be "success or failure"
Dec 11 10:48:40.156: INFO: Pod "pod-secrets-520ad714-fd32-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.988251ms
Dec 11 10:48:42.159: INFO: Pod "pod-secrets-520ad714-fd32-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004750604s
STEP: Saw pod success
Dec 11 10:48:42.159: INFO: Pod "pod-secrets-520ad714-fd32-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:48:42.161: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-secrets-520ad714-fd32-11e8-897d-5ac57959ef46 container secret-volume-test: <nil>
STEP: delete the pod
Dec 11 10:48:42.188: INFO: Waiting for pod pod-secrets-520ad714-fd32-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:48:42.190: INFO: Pod pod-secrets-520ad714-fd32-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:48:42.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fsfw2" for this suite.
Dec 11 10:48:48.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:48:48.279: INFO: namespace: e2e-tests-secrets-fsfw2, resource: bindings, ignored listing per whitelist
Dec 11 10:48:48.281: INFO: namespace e2e-tests-secrets-fsfw2 deletion completed in 6.087757325s

• [SLOW TEST:8.245 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:48:48.281: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1211 10:48:54.417592      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 11 10:48:54.417: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:48:54.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-rmsn5" for this suite.
Dec 11 10:49:00.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:49:00.456: INFO: namespace: e2e-tests-gc-rmsn5, resource: bindings, ignored listing per whitelist
Dec 11 10:49:00.505: INFO: namespace e2e-tests-gc-rmsn5 deletion completed in 6.084524155s

• [SLOW TEST:12.224 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:49:00.505: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Dec 11 10:49:00.602: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 11 10:49:00.608: INFO: Waiting for terminating namespaces to be deleted...
Dec 11 10:49:00.610: INFO: 
Logging pods the kubelet thinks is on node ip-172-25-45-107.us-west-1.compute.internal before test
Dec 11 10:49:00.620: INFO: prd-dss-leadcloser-ui-658768bd4b-84zb9 from platform started at 2018-11-20 12:27:09 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container dss-leadcloser-ui ready: true, restart count 0
Dec 11 10:49:00.620: INFO: prd-ibf-botfactory-admin-svc-botfactory-admin-service-59f4n5m5f from platform started at 2018-11-21 11:08:42 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container botfactory-admin-service ready: true, restart count 0
Dec 11 10:49:00.620: INFO: datadog-kube-state-metrics-7d48b4db57-9245w from infra started at 2018-11-19 14:59:40 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container kube-state-metrics ready: true, restart count 0
Dec 11 10:49:00.620: INFO: prd-efk-elasticsearch-fluentd-nhmf2 from infra started at 2018-12-11 10:24:54 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container fluentd ready: false, restart count 0
Dec 11 10:49:00.620: INFO: prd-dss-pm-profile-svc-dss-pm-profile-service-556b68d65-rlqgv from platform started at 2018-11-19 14:59:42 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container dss-pm-profile-service ready: true, restart count 0
Dec 11 10:49:00.620: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.620: INFO: default-http-backend-66b447d9cf-cvp7c from ingress-nginx started at 2018-11-19 14:59:42 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container default-http-backend ready: true, restart count 0
Dec 11 10:49:00.620: INFO: prd-pf-doc-svc-platform-doc-svc-6bc8488db8-cncz8 from platform started at 2018-11-19 14:59:45 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.620: INFO: 	Container prd-pf-doc-svc-platform-doc-svc ready: true, restart count 0
Dec 11 10:49:00.620: INFO: tiller-deploy-f55c64689-4jfg5 from kube-system started at 2018-11-19 14:59:40 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container tiller ready: true, restart count 0
Dec 11 10:49:00.620: INFO: prd-ibf-botfactory-agent-svc-botfactory-agent-service-56f5mkg6f from platform started at 2018-11-21 10:57:49 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container botfactory-agent-service ready: true, restart count 0
Dec 11 10:49:00.620: INFO: prd-pf-iam-svc-platform-iam-svc-5d57975b5-vjrk6 from platform started at 2018-11-19 14:59:47 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.620: INFO: 	Container prd-pf-iam-svc-platform-iam-svc ready: true, restart count 0
Dec 11 10:49:00.620: INFO: metrics-server-8555b5f58f-7qjkk from kube-system started at 2018-11-19 14:59:40 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container metrics-server ready: true, restart count 0
Dec 11 10:49:00.620: INFO: dr-kong-kong-55df5b9f69-tn88c from platform started at 2018-11-19 14:59:40 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container dr-kong-kong ready: true, restart count 1
Dec 11 10:49:00.620: INFO: prd-pf-notes-svc-platform-notes-svc-5c99df689c-bdfww from platform started at 2018-11-19 14:59:47 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.620: INFO: 	Container prd-pf-notes-svc-platform-notes-svc ready: true, restart count 0
Dec 11 10:49:00.620: INFO: prd-pf-calen-svc-platform-calen-svc-59dc958758-kgjtc from platform started at 2018-11-19 14:59:44 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.620: INFO: 	Container prd-pf-calen-svc-platform-calen-svc ready: true, restart count 0
Dec 11 10:49:00.620: INFO: platform-utils-svc-5bb47f77bd-jjdgj from platform started at 2018-11-19 14:59:40 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container platform-utils-svc ready: true, restart count 0
Dec 11 10:49:00.620: INFO: calico-node-j87ww from kube-system started at 2018-11-19 14:57:43 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container calico-node ready: true, restart count 0
Dec 11 10:49:00.620: INFO: 	Container install-cni ready: true, restart count 0
Dec 11 10:49:00.620: INFO: kube-dns-autoscaler-f4c47db64-rwllv from kube-system started at 2018-11-19 14:59:40 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container autoscaler ready: true, restart count 0
Dec 11 10:49:00.620: INFO: ubuntu-5f89d47d59-pz2h8 from platform started at 2018-11-19 14:59:40 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container ubuntu ready: true, restart count 0
Dec 11 10:49:00.620: INFO: kube-dns-7c4d8456dd-k6dkm from kube-system started at 2018-11-19 14:59:40 +0000 UTC (3 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container dnsmasq ready: true, restart count 0
Dec 11 10:49:00.620: INFO: 	Container kubedns ready: true, restart count 0
Dec 11 10:49:00.620: INFO: 	Container sidecar ready: true, restart count 0
Dec 11 10:49:00.620: INFO: prd-pf-blkusrimp-svc-platform-blkusrimp-svc-7d8d5c459f-78l6p from platform started at 2018-11-19 14:59:44 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.620: INFO: 	Container prd-pf-blkusrimp-svc-platform-blkusrimp-svc ready: true, restart count 0
Dec 11 10:49:00.620: INFO: kube-proxy-ip-172-25-45-107.us-west-1.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Dec 11 10:49:00.620: INFO: datadog-datadog-5m28x from infra started at 2018-11-19 14:57:43 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container datadog ready: true, restart count 2
Dec 11 10:49:00.620: INFO: prd-pf-notif-svc-platform-notif-svc-84dd77bbd8-74825 from platform started at 2018-11-19 14:59:47 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.620: INFO: 	Container prd-pf-notif-svc-platform-notif-svc ready: true, restart count 0
Dec 11 10:49:00.620: INFO: prd-pfm-svc-data-6448cbb64-w464d from platform started at 2018-11-19 14:59:48 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.620: INFO: 	Container prd-pf-data-svc-prd-pfm-svc-data ready: true, restart count 0
Dec 11 10:49:00.620: INFO: prd-pf-contact-svc-platform-contact-svc-7fdb7698d8-ksnzv from platform started at 2018-11-19 14:59:45 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.620: INFO: 	Container prd-pf-contact-svc-platform-contact-svc ready: true, restart count 0
Dec 11 10:49:00.620: INFO: prd-pf-email-svc-platform-email-svc-8696f76496-9gbn5 from platform started at 2018-11-19 14:59:45 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.620: INFO: 	Container prd-pf-email-svc-platform-email-svc ready: true, restart count 0
Dec 11 10:49:00.620: INFO: prd-dss-qni-illustration-svc-dss-qni-illustration-service-tjbw9 from platform started at 2018-11-26 11:18:56 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.620: INFO: 	Container prd-dss-qni-illustration-svc-dss-qni-illustration-service ready: true, restart count 0
Dec 11 10:49:00.620: INFO: prd-pf-activity-svc-platform-activity-svc-855df677b4-s5r9p from platform started at 2018-11-19 14:59:43 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.620: INFO: 	Container prd-pf-activity-svc-platform-activity-svc ready: true, restart count 0
Dec 11 10:49:00.620: INFO: prd-pf-audit-svc-platform-audit-svc-78f5998486-2rmn5 from platform started at 2018-11-19 14:59:44 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.620: INFO: 	Container prd-pf-audit-svc-platform-audit-svc ready: true, restart count 0
Dec 11 10:49:00.620: INFO: prd-botfactory-chatbot-ui-pfm-botfactory-chatbot-ui-7bd798pjt9m from platform started at 2018-11-21 10:41:40 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container pfm-botfactory-chatbot-ui ready: true, restart count 0
Dec 11 10:49:00.620: INFO: prd-keycloak-pgpool-58b949979d-wllt4 from platform started at 2018-11-19 14:59:42 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container prd-keycloak-pgpool ready: true, restart count 2
Dec 11 10:49:00.620: INFO: prd-pf-sign-svc-platform-signup-svc-7dcfdd559-llx49 from platform started at 2018-11-19 14:59:48 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.620: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.620: INFO: 	Container prd-pf-sign-svc-platform-signup-svc ready: true, restart count 0
Dec 11 10:49:00.620: INFO: 
Logging pods the kubelet thinks is on node ip-172-25-62-1.us-west-1.compute.internal before test
Dec 11 10:49:00.629: INFO: prd-pf-signup-ui-platform-signup-ui-54ffdd6f94-pzb82 from platform started at 2018-11-20 11:30:55 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container platform-signup-ui ready: true, restart count 0
Dec 11 10:49:00.629: INFO: prd-efk-elasticsearch-curator-1544490000-4wpv9 from infra started at 2018-12-11 01:00:07 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container curator ready: false, restart count 0
Dec 11 10:49:00.629: INFO: prd-efk-elasticsearch-kibana-654b6d5965-9jhkp from infra started at 2018-12-11 10:21:42 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container kibana ready: true, restart count 0
Dec 11 10:49:00.629: INFO: prd-dss-ppc-ui-64f9cf489c-zj4pk from platform started at 2018-11-20 14:04:47 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container dss-ppc-ui ready: true, restart count 0
Dec 11 10:49:00.629: INFO: prd-dss-ppc-masterdata-ppc-svc-7d8577dd7c-pb92m from platform started at 2018-11-26 11:42:41 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.629: INFO: 	Container ppc-svc ready: true, restart count 0
Dec 11 10:49:00.629: INFO: prd-efk-elasticsearch-client-8655b8d9b9-kzmfn from infra started at 2018-12-11 10:21:42 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container es-client ready: false, restart count 0
Dec 11 10:49:00.629: INFO: prd-ai-sentiment-eng-svc-ai-sentiment-svc-69bd5d994b-7wcr2 from ai started at 2018-11-20 13:34:13 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container prd-ai-sentiment-eng-svc-ai-sentiment-svc ready: true, restart count 0
Dec 11 10:49:00.629: INFO: prd-ibf-botfactory-adapter-svc-botfactory-adapter-service-p5vcf from platform started at 2018-11-21 11:11:42 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container botfactory-adapter-service ready: true, restart count 0
Dec 11 10:49:00.629: INFO: prd-pf-acc-svc-platform-acc-svc-56c66dc6bc-jl2qm from platform started at 2018-11-20 08:35:58 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.629: INFO: 	Container prd-pf-acc-svc-platform-acc-svc ready: true, restart count 0
Dec 11 10:49:00.629: INFO: kube-proxy-ip-172-25-62-1.us-west-1.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Dec 11 10:49:00.629: INFO: prd-efk-elasticsearch-fluentd-mfn69 from infra started at 2018-12-11 10:24:53 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container fluentd ready: false, restart count 0
Dec 11 10:49:00.629: INFO: prd-pfm-svc-telephony-55658c585-sp22g from platform started at 2018-11-20 08:24:26 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.629: INFO: 	Container prd-pf-telephony-svc-prd-pfm-svc-telephony ready: true, restart count 0
Dec 11 10:49:00.629: INFO: prd-pf-admin-ui-platform-admin-ui-85c98dcc66-9vj7s from platform started at 2018-11-20 11:40:28 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container platform-admin-ui ready: true, restart count 0
Dec 11 10:49:00.629: INFO: prd-pf-prflmgmt-ui-platform-prflmgmt-ui-654ff59c99-tl62p from platform started at 2018-11-20 11:46:41 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container platform-prflmgmt-ui ready: true, restart count 0
Dec 11 10:49:00.629: INFO: prd-dss-ppc-svc-ppc-svc-58f5d567d-8msxj from platform started at 2018-11-26 11:36:47 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.629: INFO: 	Container ppc-svc ready: true, restart count 0
Dec 11 10:49:00.629: INFO: prd-pf-conf-svc-platform-conf-svc-6f8c9c5649-hrx2v from platform started at 2018-11-20 08:43:48 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.629: INFO: 	Container prd-pf-conf-svc-platform-conf-svc ready: true, restart count 0
Dec 11 10:49:00.629: INFO: prd-pf-dashboard-ui-platform-dashboard-ui-859cf5d999-9qp8v from platform started at 2018-11-20 11:23:38 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container platform-dashboard-ui ready: true, restart count 0
Dec 11 10:49:00.629: INFO: prd-pf-dashboard-ui-platform-dashboard-ui-859cf5d999-mwwgd from platform started at 2018-11-20 11:23:32 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container platform-dashboard-ui ready: true, restart count 0
Dec 11 10:49:00.629: INFO: prd-pf-accmgmt-ui-platform-accmgmt-ui-5cbc4c9d66-krr5g from platform started at 2018-11-20 11:50:04 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container platform-accmgmt-ui ready: true, restart count 0
Dec 11 10:49:00.629: INFO: prd-dss-quote-ui-7475c4bdc-lg6c6 from platform started at 2018-11-21 10:07:09 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container dss-quote-ui ready: true, restart count 0
Dec 11 10:49:00.629: INFO: prd-botfactory-ui-pfm-botfactory-ui-7ff78b89f7-xnmkr from platform started at 2018-11-21 11:30:22 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container pfm-botfactory-ui ready: true, restart count 0
Dec 11 10:49:00.629: INFO: prd-dss-qni-quote-svc-dss-qni-quote-service-84cbc8c6c8-qm5jw from platform started at 2018-11-26 11:13:14 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container dss-qni-quote-service ready: true, restart count 0
Dec 11 10:49:00.629: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.629: INFO: datadog-datadog-lqmmz from infra started at 2018-11-19 17:03:43 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container datadog ready: true, restart count 0
Dec 11 10:49:00.629: INFO: calico-node-trxzw from kube-system started at 2018-11-19 17:03:43 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container calico-node ready: true, restart count 0
Dec 11 10:49:00.629: INFO: 	Container install-cni ready: true, restart count 0
Dec 11 10:49:00.629: INFO: prd-dss-lc-svc-dss-lc-service-6c8748f77b-7sj75 from platform started at 2018-11-20 13:24:04 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container dss-lc-service ready: true, restart count 0
Dec 11 10:49:00.629: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.629: INFO: prd-ibf-botfactory-platform-svc-botfactory-platform-servicszx9g from platform started at 2018-11-21 11:04:39 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container botfactory-platform-service ready: true, restart count 0
Dec 11 10:49:00.629: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-11 09:12:13 +0000 UTC (3 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container cleanup ready: true, restart count 0
Dec 11 10:49:00.629: INFO: 	Container forwarder ready: true, restart count 0
Dec 11 10:49:00.629: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 11 10:49:00.629: INFO: prd-efk-elasticsearch-curator-1544317200-qxdt5 from infra started at 2018-12-09 01:00:06 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container curator ready: false, restart count 0
Dec 11 10:49:00.629: INFO: prd-dss-leadcloser-ui-658768bd4b-zbbdr from platform started at 2018-11-20 12:27:05 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container dss-leadcloser-ui ready: true, restart count 0
Dec 11 10:49:00.629: INFO: prd-dss-ppc-ratetables-ppc-svc-cfb7cd6b9-6qcrh from platform started at 2018-11-26 11:48:21 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.629: INFO: 	Container ppc-svc ready: true, restart count 0
Dec 11 10:49:00.629: INFO: prd-pf-apimgmt-ui-platform-apimgmt-ui-699d4df9d-nb79x from platform started at 2018-11-20 11:37:39 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container platform-apimgmt-ui ready: true, restart count 0
Dec 11 10:49:00.629: INFO: prd-efk-elasticsearch-curator-1544403600-dgbl8 from infra started at 2018-12-10 01:00:08 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.629: INFO: 	Container curator ready: false, restart count 0
Dec 11 10:49:00.629: INFO: 
Logging pods the kubelet thinks is on node ip-172-25-93-75.us-west-1.compute.internal before test
Dec 11 10:49:00.641: INFO: prd-pf-contact-svc-platform-contact-svc-7fdb7698d8-6s89f from platform started at 2018-11-19 16:59:28 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.641: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.641: INFO: 	Container prd-pf-contact-svc-platform-contact-svc ready: true, restart count 0
Dec 11 10:49:00.641: INFO: prd-dss-ppc-ui-64f9cf489c-r64qn from platform started at 2018-11-20 14:04:47 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.641: INFO: 	Container dss-ppc-ui ready: true, restart count 0
Dec 11 10:49:00.641: INFO: prd-pf-calen-svc-platform-calen-svc-59dc958758-gq7dn from platform started at 2018-11-19 16:59:29 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.641: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.641: INFO: 	Container prd-pf-calen-svc-platform-calen-svc ready: true, restart count 0
Dec 11 10:49:00.641: INFO: prd-pf-sign-svc-platform-signup-svc-7dcfdd559-c26zr from platform started at 2018-11-19 16:59:30 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.641: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.641: INFO: 	Container prd-pf-sign-svc-platform-signup-svc ready: true, restart count 0
Dec 11 10:49:00.641: INFO: prd-pf-apimgmt-ui-platform-apimgmt-ui-699d4df9d-cd7lv from platform started at 2018-11-20 11:37:33 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.641: INFO: 	Container platform-apimgmt-ui ready: true, restart count 0
Dec 11 10:49:00.641: INFO: prd-pfm-svc-telephony-55658c585-l2cmb from platform started at 2018-11-20 08:24:26 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.641: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.641: INFO: 	Container prd-pf-telephony-svc-prd-pfm-svc-telephony ready: true, restart count 0
Dec 11 10:49:00.641: INFO: prd-pf-acc-svc-platform-acc-svc-56c66dc6bc-c76pd from platform started at 2018-11-20 08:35:58 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.641: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.641: INFO: 	Container prd-pf-acc-svc-platform-acc-svc ready: true, restart count 0
Dec 11 10:49:00.641: INFO: prd-pf-conf-svc-platform-conf-svc-6f8c9c5649-js8zv from platform started at 2018-11-20 08:43:48 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.641: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.641: INFO: 	Container prd-pf-conf-svc-platform-conf-svc ready: true, restart count 0
Dec 11 10:49:00.641: INFO: prd-dss-lc-svc-dss-lc-service-6c8748f77b-tffh5 from platform started at 2018-11-20 13:24:04 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.641: INFO: 	Container dss-lc-service ready: true, restart count 0
Dec 11 10:49:00.641: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.641: INFO: prd-efk-elasticsearch-data-0 from infra started at 2018-12-11 10:24:24 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container es-data ready: false, restart count 0
Dec 11 10:49:00.642: INFO: heapster-6d9d49d496-zxs9t from kube-system started at 2018-11-19 16:59:28 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container heapster ready: true, restart count 0
Dec 11 10:49:00.642: INFO: 	Container heapster-nanny ready: true, restart count 0
Dec 11 10:49:00.642: INFO: prd-pf-doc-svc-platform-doc-svc-6bc8488db8-b6mbr from platform started at 2018-11-19 16:59:28 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.642: INFO: 	Container prd-pf-doc-svc-platform-doc-svc ready: true, restart count 0
Dec 11 10:49:00.642: INFO: prd-pf-prflmgmt-ui-platform-prflmgmt-ui-654ff59c99-mntgc from platform started at 2018-11-20 11:46:36 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container platform-prflmgmt-ui ready: true, restart count 0
Dec 11 10:49:00.642: INFO: prd-pf-iam-svc-platform-iam-svc-5d57975b5-b8fcg from platform started at 2018-11-19 16:59:28 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.642: INFO: 	Container prd-pf-iam-svc-platform-iam-svc ready: true, restart count 0
Dec 11 10:49:00.642: INFO: prd-efk-elasticsearch-client-8655b8d9b9-qmmf5 from infra started at 2018-12-11 10:21:42 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container es-client ready: false, restart count 0
Dec 11 10:49:00.642: INFO: prd-efk-elasticsearch-fluentd-25gg6 from infra started at 2018-12-11 10:24:54 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container fluentd ready: false, restart count 0
Dec 11 10:49:00.642: INFO: prd-dss-lcbulk-svc-dss-lcbulk-service-77b5449544-6nkdr from platform started at 2018-11-19 16:59:28 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container dss-lcbulk-service ready: true, restart count 0
Dec 11 10:49:00.642: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.642: INFO: prd-efk-elasticsearch-master-0 from infra started at 2018-12-11 10:24:24 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container es-master ready: false, restart count 0
Dec 11 10:49:00.642: INFO: prd-pfm-svc-data-6448cbb64-djfdf from platform started at 2018-11-19 16:59:30 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.642: INFO: 	Container prd-pf-data-svc-prd-pfm-svc-data ready: true, restart count 0
Dec 11 10:49:00.642: INFO: prd-pf-audit-svc-platform-audit-svc-78f5998486-4vlp5 from platform started at 2018-11-19 16:59:29 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.642: INFO: 	Container prd-pf-audit-svc-platform-audit-svc ready: true, restart count 0
Dec 11 10:49:00.642: INFO: prd-keycloak-pgpool-58b949979d-ndwgn from platform started at 2018-11-19 16:59:30 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container prd-keycloak-pgpool ready: true, restart count 0
Dec 11 10:49:00.642: INFO: prd-pf-signup-ui-platform-signup-ui-54ffdd6f94-62xr7 from platform started at 2018-11-20 11:30:50 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container platform-signup-ui ready: true, restart count 0
Dec 11 10:49:00.642: INFO: prd-pf-blkusrimp-svc-platform-blkusrimp-svc-7d8d5c459f-q24h8 from platform started at 2018-11-19 16:59:28 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.642: INFO: 	Container prd-pf-blkusrimp-svc-platform-blkusrimp-svc ready: true, restart count 0
Dec 11 10:49:00.642: INFO: prd-pf-notif-svc-platform-notif-svc-84dd77bbd8-qhxw5 from platform started at 2018-11-19 16:59:29 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.642: INFO: 	Container prd-pf-notif-svc-platform-notif-svc ready: true, restart count 0
Dec 11 10:49:00.642: INFO: kube-dns-7c4d8456dd-np757 from kube-system started at 2018-11-19 16:59:29 +0000 UTC (3 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container dnsmasq ready: true, restart count 0
Dec 11 10:49:00.642: INFO: 	Container kubedns ready: true, restart count 0
Dec 11 10:49:00.642: INFO: 	Container sidecar ready: true, restart count 0
Dec 11 10:49:00.642: INFO: prd-pf-admin-ui-platform-admin-ui-85c98dcc66-rbgt5 from platform started at 2018-11-20 11:40:24 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container platform-admin-ui ready: true, restart count 0
Dec 11 10:49:00.642: INFO: prd-botfactory-chatbot-ui-pfm-botfactory-chatbot-ui-7bd798cnb8c from platform started at 2018-11-21 10:41:40 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container pfm-botfactory-chatbot-ui ready: true, restart count 0
Dec 11 10:49:00.642: INFO: prd-pf-email-svc-platform-email-svc-8696f76496-wkzqt from platform started at 2018-11-19 16:59:31 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.642: INFO: 	Container prd-pf-email-svc-platform-email-svc ready: true, restart count 0
Dec 11 10:49:00.642: INFO: prd-dss-qni-illustration-svc-dss-qni-illustration-service-r2rhd from platform started at 2018-11-26 11:18:56 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.642: INFO: 	Container prd-dss-qni-illustration-svc-dss-qni-illustration-service ready: true, restart count 0
Dec 11 10:49:00.642: INFO: calico-node-p7n2j from kube-system started at 2018-11-19 16:53:44 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container calico-node ready: true, restart count 0
Dec 11 10:49:00.642: INFO: 	Container install-cni ready: true, restart count 0
Dec 11 10:49:00.642: INFO: datadog-datadog-r4px7 from infra started at 2018-11-19 16:53:44 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container datadog ready: true, restart count 0
Dec 11 10:49:00.642: INFO: prd-dss-pm-profile-svc-dss-pm-profile-service-556b68d65-qmntq from platform started at 2018-11-19 16:59:31 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container dss-pm-profile-service ready: true, restart count 0
Dec 11 10:49:00.642: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.642: INFO: prd-keycloak-keycloak-78d64cbc4f-scj6l from platform started at 2018-11-19 16:59:29 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container prd-keycloak-keycloak ready: true, restart count 0
Dec 11 10:49:00.642: INFO: prd-ai-sentiment-eng-svc-ai-sentiment-svc-69bd5d994b-vn2sr from ai started at 2018-11-20 13:34:13 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container prd-ai-sentiment-eng-svc-ai-sentiment-svc ready: true, restart count 0
Dec 11 10:49:00.642: INFO: prd-botfactory-ui-pfm-botfactory-ui-7ff78b89f7-ljt45 from platform started at 2018-11-21 11:30:22 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container pfm-botfactory-ui ready: true, restart count 0
Dec 11 10:49:00.642: INFO: kube-proxy-ip-172-25-93-75.us-west-1.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Dec 11 10:49:00.642: INFO: prd-pf-notes-svc-platform-notes-svc-5c99df689c-vs8g5 from platform started at 2018-11-19 16:59:28 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.642: INFO: 	Container prd-pf-notes-svc-platform-notes-svc ready: true, restart count 0
Dec 11 10:49:00.642: INFO: prd-pf-accmgmt-ui-platform-accmgmt-ui-5cbc4c9d66-g4wqj from platform started at 2018-11-20 11:49:59 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container platform-accmgmt-ui ready: true, restart count 0
Dec 11 10:49:00.642: INFO: prd-pf-activity-svc-platform-activity-svc-855df677b4-htnqk from platform started at 2018-11-19 16:59:30 +0000 UTC (2 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container filebeat ready: true, restart count 0
Dec 11 10:49:00.642: INFO: 	Container prd-pf-activity-svc-platform-activity-svc ready: true, restart count 0
Dec 11 10:49:00.642: INFO: nginx-ingress-controller-5ccb96dd7b-ldrbm from ingress-nginx started at 2018-11-19 17:11:11 +0000 UTC (1 container statuses recorded)
Dec 11 10:49:00.642: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.156f419d360355fd], Reason = [FailedScheduling], Message = [0/6 nodes are available: 6 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:49:01.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-9vhz4" for this suite.
Dec 11 10:49:07.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:49:07.766: INFO: namespace: e2e-tests-sched-pred-9vhz4, resource: bindings, ignored listing per whitelist
Dec 11 10:49:07.779: INFO: namespace e2e-tests-sched-pred-9vhz4 deletion completed in 6.089258824s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.275 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:49:07.780: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 11 10:49:07.912: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 10:49:07.912: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 10:49:07.912: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 10:49:07.914: INFO: Number of nodes with available pods: 0
Dec 11 10:49:07.914: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:49:08.918: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 10:49:08.918: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 10:49:08.918: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 10:49:08.920: INFO: Number of nodes with available pods: 1
Dec 11 10:49:08.920: INFO: Node ip-172-25-45-107.us-west-1.compute.internal is running more than one daemon pod
Dec 11 10:49:09.918: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 10:49:09.918: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 10:49:09.918: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 10:49:09.920: INFO: Number of nodes with available pods: 3
Dec 11 10:49:09.920: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec 11 10:49:09.940: INFO: DaemonSet pods can't tolerate node ip-172-25-61-224.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 10:49:09.940: INFO: DaemonSet pods can't tolerate node ip-172-25-62-180.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 10:49:09.940: INFO: DaemonSet pods can't tolerate node ip-172-25-84-67.us-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 10:49:09.942: INFO: Number of nodes with available pods: 3
Dec 11 10:49:09.942: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-fwlnx, will wait for the garbage collector to delete the pods
Dec 11 10:49:11.031: INFO: Deleting DaemonSet.extensions daemon-set took: 29.832122ms
Dec 11 10:49:11.131: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.275867ms
Dec 11 10:49:54.933: INFO: Number of nodes with available pods: 0
Dec 11 10:49:54.933: INFO: Number of running nodes: 0, number of available pods: 0
Dec 11 10:49:54.936: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-fwlnx/daemonsets","resourceVersion":"21972404"},"items":null}

Dec 11 10:49:54.938: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-fwlnx/pods","resourceVersion":"21972404"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:49:54.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-fwlnx" for this suite.
Dec 11 10:50:00.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:50:00.996: INFO: namespace: e2e-tests-daemonsets-fwlnx, resource: bindings, ignored listing per whitelist
Dec 11 10:50:01.080: INFO: namespace e2e-tests-daemonsets-fwlnx deletion completed in 6.128266563s

• [SLOW TEST:53.301 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:50:01.081: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 11 10:50:01.173: INFO: Creating deployment "nginx-deployment"
Dec 11 10:50:01.184: INFO: Waiting for observed generation 1
Dec 11 10:50:03.189: INFO: Waiting for all required pods to come up
Dec 11 10:50:03.192: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec 11 10:50:05.196: INFO: Waiting for deployment "nginx-deployment" to complete
Dec 11 10:50:05.201: INFO: Updating deployment "nginx-deployment" with a non-existent image
Dec 11 10:50:05.215: INFO: Updating deployment nginx-deployment
Dec 11 10:50:05.215: INFO: Waiting for observed generation 2
Dec 11 10:50:07.220: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec 11 10:50:07.222: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec 11 10:50:07.224: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec 11 10:50:07.230: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec 11 10:50:07.230: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec 11 10:50:07.232: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec 11 10:50:07.236: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Dec 11 10:50:07.236: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Dec 11 10:50:07.250: INFO: Updating deployment nginx-deployment
Dec 11 10:50:07.250: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Dec 11 10:50:07.254: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec 11 10:50:09.258: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 11 10:50:09.263: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z9jvz/deployments/nginx-deployment,UID:82570cd0-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972671,Generation:3,CreationTimestamp:2018-12-11 10:50:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2018-12-11 10:50:07 +0000 UTC 2018-12-11 10:50:07 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-12-11 10:50:07 +0000 UTC 2018-12-11 10:50:01 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-64f7c5c99b" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Dec 11 10:50:09.265: INFO: New ReplicaSet "nginx-deployment-64f7c5c99b" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-64f7c5c99b,GenerateName:,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z9jvz/replicasets/nginx-deployment-64f7c5c99b,UID:84bf9df6-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972670,Generation:3,CreationTimestamp:2018-12-11 10:50:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2093717556,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{extensions/v1beta1 Deployment nginx-deployment 82570cd0-fd32-11e8-8e03-0681e6464a68 0xc001f7fc1e 0xc001f7fc1f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 2093717556,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2093717556,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 11 10:50:09.265: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Dec 11 10:50:09.265: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5884c9456f,GenerateName:,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z9jvz/replicasets/nginx-deployment-5884c9456f,UID:8258df33-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972664,Generation:3,CreationTimestamp:2018-12-11 10:50:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 1440750129,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{extensions/v1beta1 Deployment nginx-deployment 82570cd0-fd32-11e8-8e03-0681e6464a68 0xc001f7f77e 0xc001f7f77f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 1440750129,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 1440750129,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Dec 11 10:50:09.270: INFO: Pod "nginx-deployment-5884c9456f-2drps" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5884c9456f-2drps,GenerateName:nginx-deployment-5884c9456f-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-5884c9456f-2drps,UID:85fbd5f1-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972641,Generation:0,CreationTimestamp:2018-12-11 10:50:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 1440750129,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-5884c9456f 8258df33-fd32-11e8-8e03-0681e6464a68 0xc001de555a 0xc001de555b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-45-107.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001de5a80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001de5ab0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.270: INFO: Pod "nginx-deployment-5884c9456f-2p98m" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5884c9456f-2p98m,GenerateName:nginx-deployment-5884c9456f-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-5884c9456f-2p98m,UID:825aca0e-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972527,Generation:0,CreationTimestamp:2018-12-11 10:50:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 1440750129,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-5884c9456f 8258df33-fd32-11e8-8e03-0681e6464a68 0xc001de5b3a 0xc001de5b3b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-62-1.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001de5f10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001de5f30}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:01 +0000 UTC  }],Message:,Reason:,HostIP:172.25.62.1,PodIP:100.111.88.48,StartTime:2018-12-11 10:50:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-11 10:50:02 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://f660bfc39a1ab87f53c0f87aaeac4715028e1dedc8fdb36f78db86c4dca6457c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.270: INFO: Pod "nginx-deployment-5884c9456f-5fxr6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5884c9456f-5fxr6,GenerateName:nginx-deployment-5884c9456f-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-5884c9456f-5fxr6,UID:85ff186c-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972657,Generation:0,CreationTimestamp:2018-12-11 10:50:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 1440750129,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-5884c9456f 8258df33-fd32-11e8-8e03-0681e6464a68 0xc000ca405a 0xc000ca405b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-45-107.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000ca45f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ca4610}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.270: INFO: Pod "nginx-deployment-5884c9456f-5gcsc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5884c9456f-5gcsc,GenerateName:nginx-deployment-5884c9456f-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-5884c9456f-5gcsc,UID:825c4cbe-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972515,Generation:0,CreationTimestamp:2018-12-11 10:50:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 1440750129,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-5884c9456f 8258df33-fd32-11e8-8e03-0681e6464a68 0xc000ca479a 0xc000ca479b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-45-107.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000ca4800} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ca4820}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:01 +0000 UTC  }],Message:,Reason:,HostIP:172.25.45.107,PodIP:100.111.240.193,StartTime:2018-12-11 10:50:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-11 10:50:02 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://538eb63f6f4b5623c309caf47c3b8c7944263d545c65f175c690004117f35532}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.270: INFO: Pod "nginx-deployment-5884c9456f-5x2pg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5884c9456f-5x2pg,GenerateName:nginx-deployment-5884c9456f-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-5884c9456f-5x2pg,UID:85fbc3e6-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972673,Generation:0,CreationTimestamp:2018-12-11 10:50:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 1440750129,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-5884c9456f 8258df33-fd32-11e8-8e03-0681e6464a68 0xc000ca4e6a 0xc000ca4e6b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-45-107.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000ca4ee0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ca4f10}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  }],Message:,Reason:,HostIP:172.25.45.107,PodIP:,StartTime:2018-12-11 10:50:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.270: INFO: Pod "nginx-deployment-5884c9456f-5zgx9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5884c9456f-5zgx9,GenerateName:nginx-deployment-5884c9456f-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-5884c9456f-5zgx9,UID:85f9c583-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972646,Generation:0,CreationTimestamp:2018-12-11 10:50:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 1440750129,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-5884c9456f 8258df33-fd32-11e8-8e03-0681e6464a68 0xc000ca518a 0xc000ca518b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-93-75.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000ca55c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ca55e0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  }],Message:,Reason:,HostIP:172.25.93.75,PodIP:,StartTime:2018-12-11 10:50:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.270: INFO: Pod "nginx-deployment-5884c9456f-8x7tc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5884c9456f-8x7tc,GenerateName:nginx-deployment-5884c9456f-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-5884c9456f-8x7tc,UID:825e4402-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972520,Generation:0,CreationTimestamp:2018-12-11 10:50:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 1440750129,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-5884c9456f 8258df33-fd32-11e8-8e03-0681e6464a68 0xc000ca596a 0xc000ca596b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-93-75.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a36070} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a36090}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:01 +0000 UTC  }],Message:,Reason:,HostIP:172.25.93.75,PodIP:100.122.170.82,StartTime:2018-12-11 10:50:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-11 10:50:02 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://61ea8f064a7e0b5f7a5c1ac750a4902da9f619b35876bc15ddd521b426763937}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.270: INFO: Pod "nginx-deployment-5884c9456f-ffwq6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5884c9456f-ffwq6,GenerateName:nginx-deployment-5884c9456f-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-5884c9456f-ffwq6,UID:8260ee46-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972519,Generation:0,CreationTimestamp:2018-12-11 10:50:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 1440750129,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-5884c9456f 8258df33-fd32-11e8-8e03-0681e6464a68 0xc001a362ea 0xc001a362eb}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-93-75.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a36400} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a36420}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:01 +0000 UTC  }],Message:,Reason:,HostIP:172.25.93.75,PodIP:100.122.170.72,StartTime:2018-12-11 10:50:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-11 10:50:02 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://06fa82265f9a3a778c9643b323075f4324820c4295651010aec544d9cd112949}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.270: INFO: Pod "nginx-deployment-5884c9456f-hhwkl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5884c9456f-hhwkl,GenerateName:nginx-deployment-5884c9456f-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-5884c9456f-hhwkl,UID:85ff09c8-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972667,Generation:0,CreationTimestamp:2018-12-11 10:50:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 1440750129,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-5884c9456f 8258df33-fd32-11e8-8e03-0681e6464a68 0xc001a3667a 0xc001a3667b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-93-75.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a366e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a36700}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  }],Message:,Reason:,HostIP:172.25.93.75,PodIP:,StartTime:2018-12-11 10:50:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.270: INFO: Pod "nginx-deployment-5884c9456f-hv9xt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5884c9456f-hv9xt,GenerateName:nginx-deployment-5884c9456f-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-5884c9456f-hv9xt,UID:85ff217d-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972672,Generation:0,CreationTimestamp:2018-12-11 10:50:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 1440750129,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-5884c9456f 8258df33-fd32-11e8-8e03-0681e6464a68 0xc001a3678a 0xc001a3678b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-93-75.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a367f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a36810}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  }],Message:,Reason:,HostIP:172.25.93.75,PodIP:,StartTime:2018-12-11 10:50:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.271: INFO: Pod "nginx-deployment-5884c9456f-jrv42" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5884c9456f-jrv42,GenerateName:nginx-deployment-5884c9456f-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-5884c9456f-jrv42,UID:8260fb66-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972525,Generation:0,CreationTimestamp:2018-12-11 10:50:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 1440750129,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-5884c9456f 8258df33-fd32-11e8-8e03-0681e6464a68 0xc001a3689a 0xc001a3689b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-62-1.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a36900} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a36920}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:01 +0000 UTC  }],Message:,Reason:,HostIP:172.25.62.1,PodIP:100.111.88.52,StartTime:2018-12-11 10:50:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-11 10:50:02 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://a515764e878639188c8cf1ec8383e9095808bd681455b654fb917b9c557fc745}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.271: INFO: Pod "nginx-deployment-5884c9456f-kbp5g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5884c9456f-kbp5g,GenerateName:nginx-deployment-5884c9456f-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-5884c9456f-kbp5g,UID:85ff2715-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972658,Generation:0,CreationTimestamp:2018-12-11 10:50:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 1440750129,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-5884c9456f 8258df33-fd32-11e8-8e03-0681e6464a68 0xc001a369ba 0xc001a369bb}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-45-107.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a36a20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a36a50}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.271: INFO: Pod "nginx-deployment-5884c9456f-lvt7m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5884c9456f-lvt7m,GenerateName:nginx-deployment-5884c9456f-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-5884c9456f-lvt7m,UID:85fbaac0-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972663,Generation:0,CreationTimestamp:2018-12-11 10:50:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 1440750129,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-5884c9456f 8258df33-fd32-11e8-8e03-0681e6464a68 0xc001a36aaa 0xc001a36aab}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-62-1.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a36b10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a36b30}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  }],Message:,Reason:,HostIP:172.25.62.1,PodIP:,StartTime:2018-12-11 10:50:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.271: INFO: Pod "nginx-deployment-5884c9456f-pl55x" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5884c9456f-pl55x,GenerateName:nginx-deployment-5884c9456f-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-5884c9456f-pl55x,UID:825e4f0e-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972530,Generation:0,CreationTimestamp:2018-12-11 10:50:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 1440750129,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-5884c9456f 8258df33-fd32-11e8-8e03-0681e6464a68 0xc001a36bba 0xc001a36bbb}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-62-1.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a36c20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a36c40}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:01 +0000 UTC  }],Message:,Reason:,HostIP:172.25.62.1,PodIP:100.111.88.50,StartTime:2018-12-11 10:50:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-11 10:50:02 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://667fd7f5fbd61b5eeaaa1028f15c7864e9fd8716687e030c85a8270acf850369}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.271: INFO: Pod "nginx-deployment-5884c9456f-sqqwk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5884c9456f-sqqwk,GenerateName:nginx-deployment-5884c9456f-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-5884c9456f-sqqwk,UID:825c3c31-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972543,Generation:0,CreationTimestamp:2018-12-11 10:50:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 1440750129,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-5884c9456f 8258df33-fd32-11e8-8e03-0681e6464a68 0xc001a36cda 0xc001a36cdb}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-93-75.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a36d40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a36d60}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:01 +0000 UTC  }],Message:,Reason:,HostIP:172.25.93.75,PodIP:100.122.170.89,StartTime:2018-12-11 10:50:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-11 10:50:02 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://7c40c35586907c2afd0905053218751cb4129c85ff85e8728b1c00d293c9e70d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.271: INFO: Pod "nginx-deployment-5884c9456f-stc5t" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5884c9456f-stc5t,GenerateName:nginx-deployment-5884c9456f-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-5884c9456f-stc5t,UID:825e60f6-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972540,Generation:0,CreationTimestamp:2018-12-11 10:50:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 1440750129,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-5884c9456f 8258df33-fd32-11e8-8e03-0681e6464a68 0xc001a36e0a 0xc001a36e0b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-93-75.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a36e90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a36eb0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:01 +0000 UTC  }],Message:,Reason:,HostIP:172.25.93.75,PodIP:100.122.170.65,StartTime:2018-12-11 10:50:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-11 10:50:02 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://62f2ee943a0e98574978c36da968fd62465884627cac0f278d3922768beae312}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.271: INFO: Pod "nginx-deployment-5884c9456f-tjhc4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5884c9456f-tjhc4,GenerateName:nginx-deployment-5884c9456f-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-5884c9456f-tjhc4,UID:85fbd7e1-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972668,Generation:0,CreationTimestamp:2018-12-11 10:50:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 1440750129,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-5884c9456f 8258df33-fd32-11e8-8e03-0681e6464a68 0xc001a36f5a 0xc001a36f5b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-62-1.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a37230} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a37250}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  }],Message:,Reason:,HostIP:172.25.62.1,PodIP:,StartTime:2018-12-11 10:50:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.271: INFO: Pod "nginx-deployment-5884c9456f-wtln4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5884c9456f-wtln4,GenerateName:nginx-deployment-5884c9456f-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-5884c9456f-wtln4,UID:85f9c017-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972647,Generation:0,CreationTimestamp:2018-12-11 10:50:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 1440750129,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-5884c9456f 8258df33-fd32-11e8-8e03-0681e6464a68 0xc001a372da 0xc001a372db}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-45-107.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a37340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a37360}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  }],Message:,Reason:,HostIP:172.25.45.107,PodIP:,StartTime:2018-12-11 10:50:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.271: INFO: Pod "nginx-deployment-5884c9456f-zh8k2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5884c9456f-zh8k2,GenerateName:nginx-deployment-5884c9456f-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-5884c9456f-zh8k2,UID:85fed5a7-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972653,Generation:0,CreationTimestamp:2018-12-11 10:50:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 1440750129,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-5884c9456f 8258df33-fd32-11e8-8e03-0681e6464a68 0xc001a3746a 0xc001a3746b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-45-107.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a374e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a37500}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.271: INFO: Pod "nginx-deployment-5884c9456f-zp9z2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5884c9456f-zp9z2,GenerateName:nginx-deployment-5884c9456f-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-5884c9456f-zp9z2,UID:85f7e01a-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972629,Generation:0,CreationTimestamp:2018-12-11 10:50:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 1440750129,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-5884c9456f 8258df33-fd32-11e8-8e03-0681e6464a68 0xc001a3756a 0xc001a3756b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-45-107.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a37900} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a37920}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  }],Message:,Reason:,HostIP:172.25.45.107,PodIP:,StartTime:2018-12-11 10:50:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.271: INFO: Pod "nginx-deployment-64f7c5c99b-48ps5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-64f7c5c99b-48ps5,GenerateName:nginx-deployment-64f7c5c99b-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-64f7c5c99b-48ps5,UID:84c1306b-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972561,Generation:0,CreationTimestamp:2018-12-11 10:50:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2093717556,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-64f7c5c99b 84bf9df6-fd32-11e8-8e03-0681e6464a68 0xc001a379ca 0xc001a379cb}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-62-1.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a37a40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a37a60}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:05 +0000 UTC  }],Message:,Reason:,HostIP:172.25.62.1,PodIP:,StartTime:2018-12-11 10:50:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.271: INFO: Pod "nginx-deployment-64f7c5c99b-4h9kv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-64f7c5c99b-4h9kv,GenerateName:nginx-deployment-64f7c5c99b-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-64f7c5c99b-4h9kv,UID:84cf2a40-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972696,Generation:0,CreationTimestamp:2018-12-11 10:50:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2093717556,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-64f7c5c99b 84bf9df6-fd32-11e8-8e03-0681e6464a68 0xc00190001a 0xc00190001b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-62-1.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001900080} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019000a0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:05 +0000 UTC  }],Message:,Reason:,HostIP:172.25.62.1,PodIP:,StartTime:2018-12-11 10:50:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.272: INFO: Pod "nginx-deployment-64f7c5c99b-4pgdn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-64f7c5c99b-4pgdn,GenerateName:nginx-deployment-64f7c5c99b-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-64f7c5c99b-4pgdn,UID:85fad9bc-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972654,Generation:0,CreationTimestamp:2018-12-11 10:50:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2093717556,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-64f7c5c99b 84bf9df6-fd32-11e8-8e03-0681e6464a68 0xc00190017a 0xc00190017b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-62-1.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019001e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001900200}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  }],Message:,Reason:,HostIP:172.25.62.1,PodIP:,StartTime:2018-12-11 10:50:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.272: INFO: Pod "nginx-deployment-64f7c5c99b-6t6n2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-64f7c5c99b-6t6n2,GenerateName:nginx-deployment-64f7c5c99b-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-64f7c5c99b-6t6n2,UID:84cc4395-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972577,Generation:0,CreationTimestamp:2018-12-11 10:50:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2093717556,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-64f7c5c99b 84bf9df6-fd32-11e8-8e03-0681e6464a68 0xc00190029a 0xc00190029b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-93-75.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001900370} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001900390}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:05 +0000 UTC  }],Message:,Reason:,HostIP:172.25.93.75,PodIP:,StartTime:2018-12-11 10:50:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.272: INFO: Pod "nginx-deployment-64f7c5c99b-75fj7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-64f7c5c99b-75fj7,GenerateName:nginx-deployment-64f7c5c99b-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-64f7c5c99b-75fj7,UID:85fd4a2d-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972651,Generation:0,CreationTimestamp:2018-12-11 10:50:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2093717556,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-64f7c5c99b 84bf9df6-fd32-11e8-8e03-0681e6464a68 0xc00190043a 0xc00190043b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-45-107.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019004a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019004c0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.272: INFO: Pod "nginx-deployment-64f7c5c99b-c4mts" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-64f7c5c99b-c4mts,GenerateName:nginx-deployment-64f7c5c99b-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-64f7c5c99b-c4mts,UID:85fd31d3-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972652,Generation:0,CreationTimestamp:2018-12-11 10:50:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2093717556,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-64f7c5c99b 84bf9df6-fd32-11e8-8e03-0681e6464a68 0xc00190051a 0xc00190051b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-45-107.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001900600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001900620}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.272: INFO: Pod "nginx-deployment-64f7c5c99b-cvs4t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-64f7c5c99b-cvs4t,GenerateName:nginx-deployment-64f7c5c99b-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-64f7c5c99b-cvs4t,UID:86005d0e-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972697,Generation:0,CreationTimestamp:2018-12-11 10:50:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2093717556,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-64f7c5c99b 84bf9df6-fd32-11e8-8e03-0681e6464a68 0xc00190067a 0xc00190067b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-93-75.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019006e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001900700}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  }],Message:,Reason:,HostIP:172.25.93.75,PodIP:,StartTime:2018-12-11 10:50:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.272: INFO: Pod "nginx-deployment-64f7c5c99b-dvc76" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-64f7c5c99b-dvc76,GenerateName:nginx-deployment-64f7c5c99b-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-64f7c5c99b-dvc76,UID:85fd4b4f-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972650,Generation:0,CreationTimestamp:2018-12-11 10:50:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2093717556,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-64f7c5c99b 84bf9df6-fd32-11e8-8e03-0681e6464a68 0xc0019008da 0xc0019008db}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-45-107.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001900940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001900960}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.272: INFO: Pod "nginx-deployment-64f7c5c99b-m8dpn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-64f7c5c99b-m8dpn,GenerateName:nginx-deployment-64f7c5c99b-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-64f7c5c99b-m8dpn,UID:85fad2fc-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972665,Generation:0,CreationTimestamp:2018-12-11 10:50:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2093717556,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-64f7c5c99b 84bf9df6-fd32-11e8-8e03-0681e6464a68 0xc0019009ba 0xc0019009bb}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-45-107.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001900ab0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001900ad0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  }],Message:,Reason:,HostIP:172.25.45.107,PodIP:,StartTime:2018-12-11 10:50:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.272: INFO: Pod "nginx-deployment-64f7c5c99b-r9mth" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-64f7c5c99b-r9mth,GenerateName:nginx-deployment-64f7c5c99b-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-64f7c5c99b-r9mth,UID:85fd4ca2-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972660,Generation:0,CreationTimestamp:2018-12-11 10:50:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2093717556,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-64f7c5c99b 84bf9df6-fd32-11e8-8e03-0681e6464a68 0xc001900b6a 0xc001900b6b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-93-75.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001900be0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001900c00}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  }],Message:,Reason:,HostIP:172.25.93.75,PodIP:,StartTime:2018-12-11 10:50:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.272: INFO: Pod "nginx-deployment-64f7c5c99b-t5hgh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-64f7c5c99b-t5hgh,GenerateName:nginx-deployment-64f7c5c99b-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-64f7c5c99b-t5hgh,UID:84c2aa80-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972565,Generation:0,CreationTimestamp:2018-12-11 10:50:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2093717556,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-64f7c5c99b 84bf9df6-fd32-11e8-8e03-0681e6464a68 0xc001900cfa 0xc001900cfb}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-93-75.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001900d60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001900d80}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:05 +0000 UTC  }],Message:,Reason:,HostIP:172.25.93.75,PodIP:,StartTime:2018-12-11 10:50:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.272: INFO: Pod "nginx-deployment-64f7c5c99b-trmp6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-64f7c5c99b-trmp6,GenerateName:nginx-deployment-64f7c5c99b-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-64f7c5c99b-trmp6,UID:84c2b1a0-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972566,Generation:0,CreationTimestamp:2018-12-11 10:50:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2093717556,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-64f7c5c99b 84bf9df6-fd32-11e8-8e03-0681e6464a68 0xc001900e1a 0xc001900e1b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-45-107.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001900e80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001900ea0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:05 +0000 UTC  }],Message:,Reason:,HostIP:172.25.45.107,PodIP:,StartTime:2018-12-11 10:50:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 10:50:09.272: INFO: Pod "nginx-deployment-64f7c5c99b-zvxkw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-64f7c5c99b-zvxkw,GenerateName:nginx-deployment-64f7c5c99b-,Namespace:e2e-tests-deployment-z9jvz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z9jvz/pods/nginx-deployment-64f7c5c99b-zvxkw,UID:85f956ab-fd32-11e8-8e03-0681e6464a68,ResourceVersion:21972636,Generation:0,CreationTimestamp:2018-12-11 10:50:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2093717556,},Annotations:map[string]string{},OwnerReferences:[{extensions/v1beta1 ReplicaSet nginx-deployment-64f7c5c99b 84bf9df6-fd32-11e8-8e03-0681e6464a68 0xc001900f3a 0xc001900f3b}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hvrvk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hvrvk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-hvrvk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-25-93-75.us-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001900fa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001900fc0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-11 10:50:07 +0000 UTC  }],Message:,Reason:,HostIP:172.25.93.75,PodIP:,StartTime:2018-12-11 10:50:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:50:09.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-z9jvz" for this suite.
Dec 11 10:50:17.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:50:17.330: INFO: namespace: e2e-tests-deployment-z9jvz, resource: bindings, ignored listing per whitelist
Dec 11 10:50:17.362: INFO: namespace e2e-tests-deployment-z9jvz deletion completed in 8.085872645s

• [SLOW TEST:16.281 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 11 10:50:17.362: INFO: >>> kubeConfig: /tmp/kubeconfig-357251099
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-8c0cb6ca-fd32-11e8-897d-5ac57959ef46
STEP: Creating a pod to test consume secrets
Dec 11 10:50:17.493: INFO: Waiting up to 5m0s for pod "pod-secrets-8c0e974a-fd32-11e8-897d-5ac57959ef46" in namespace "e2e-tests-secrets-mhxzs" to be "success or failure"
Dec 11 10:50:17.495: INFO: Pod "pod-secrets-8c0e974a-fd32-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.371224ms
Dec 11 10:50:19.497: INFO: Pod "pod-secrets-8c0e974a-fd32-11e8-897d-5ac57959ef46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00494747s
Dec 11 10:50:21.500: INFO: Pod "pod-secrets-8c0e974a-fd32-11e8-897d-5ac57959ef46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007744977s
STEP: Saw pod success
Dec 11 10:50:21.500: INFO: Pod "pod-secrets-8c0e974a-fd32-11e8-897d-5ac57959ef46" satisfied condition "success or failure"
Dec 11 10:50:21.503: INFO: Trying to get logs from node ip-172-25-62-1.us-west-1.compute.internal pod pod-secrets-8c0e974a-fd32-11e8-897d-5ac57959ef46 container secret-volume-test: <nil>
STEP: delete the pod
Dec 11 10:50:21.529: INFO: Waiting for pod pod-secrets-8c0e974a-fd32-11e8-897d-5ac57959ef46 to disappear
Dec 11 10:50:21.531: INFO: Pod pod-secrets-8c0e974a-fd32-11e8-897d-5ac57959ef46 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 11 10:50:21.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-mhxzs" for this suite.
Dec 11 10:50:27.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 10:50:27.563: INFO: namespace: e2e-tests-secrets-mhxzs, resource: bindings, ignored listing per whitelist
Dec 11 10:50:27.621: INFO: namespace e2e-tests-secrets-mhxzs deletion completed in 6.086563657s

• [SLOW TEST:10.260 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSDec 11 10:50:27.621: INFO: Running AfterSuite actions on all nodes
Dec 11 10:50:27.622: INFO: Running AfterSuite actions on node 1
Dec 11 10:50:27.622: INFO: Skipping dumping logs from cluster


Summarizing 1 Failure:

[Fail] [k8s.io] Kubelet when scheduling a busybox Pod with hostAliases [It] should write entries to /etc/hosts [NodeConformance] [Conformance] 
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:183

Ran 199 of 1946 Specs in 5878.428 seconds
FAIL! -- 198 Passed | 1 Failed | 0 Pending | 1747 Skipped --- FAIL: TestE2E (5878.54s)
FAIL

Ginkgo ran 1 suite in 1h37m58.986365902s
Test Suite Failed

